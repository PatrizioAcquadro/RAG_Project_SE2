[
  "def visualise_data(wavelength: int = None,\n                   path_to_hdf5_file: str = None,\n                   settings: Settings = None,\n                   path_manager: PathManager = None,\n                   show_absorption=False,\n                   show_scattering=False,\n                   show_anisotropy=False,\n                   show_speed_of_sound=False,\n                   show_tissue_density=False,\n                   show_fluence=False,\n                   show_initial_pressure=False,\n                   show_time_series_data=False,\n                   show_reconstructed_data=False,\n                   show_segmentation_map=False,\n                   show_oxygenation=False,\n                   show_linear_unmixing_sO2=False,\n                   show_diffuse_reflectance=False,\n                   log_scale=False,\n                   show_xz_only=False,\n                   save_path=None):\n\n    if settings is not None and Tags.WAVELENGTHS in settings:\n        if wavelength is None or wavelength not in settings[Tags.WAVELENGTHS]:\n            wavelength = settings[Tags.WAVELENGTHS][0]\n\n    if settings is not None and Tags.WAVELENGTH in settings:\n        wavelength = settings[Tags.WAVELENGTH]\n\n    if path_to_hdf5_file is None and (settings is None or path_manager is None):\n        raise ValueError(\"Either the path_to_hdf5_file or the given settings and path_manager must not be None!\")\n\n    if path_to_hdf5_file is None:\n        path_to_hdf5_file = path_manager.get_hdf5_file_save_path() + \"/\" + settings[Tags.VOLUME_NAME] + \".hdf5\"\n\n    logger = Logger()\n    file = load_hdf5(path_to_hdf5_file)\n\n    fluence = None\n    initial_pressure = None\n    time_series_data = None\n    reconstructed_data = None\n    oxygenation = None\n    linear_unmixing_sO2 = None\n    diffuse_reflectance = None\n    diffuse_reflectance_position = None\n\n    absorption = get_data_field_from_simpa_output(file, Tags.DATA_FIELD_ABSORPTION_PER_CM, wavelength)\n    scattering = get_data_field_from_simpa_output(file, Tags.DATA_FIELD_SCATTERING_PER_CM, wavelength)\n    anisotropy = get_data_field_from_simpa_output(file, Tags.DATA_FIELD_ANISOTROPY, wavelength)\n    segmentation_map = get_data_field_from_simpa_output(file, Tags.DATA_FIELD_SEGMENTATION)\n    speed_of_sound = get_data_field_from_simpa_output(file, Tags.DATA_FIELD_SPEED_OF_SOUND)\n    density = get_data_field_from_simpa_output(file, Tags.DATA_FIELD_DENSITY)\n\n    if show_fluence:\n        try:\n            fluence = get_data_field_from_simpa_output(file, Tags.DATA_FIELD_FLUENCE, wavelength)\n        except KeyError as e:\n            logger.critical(\"The key \" + str(Tags.DATA_FIELD_FLUENCE) + \" was not in the simpa output.\")\n            show_fluence = False\n            fluence = None\n\n    if show_diffuse_reflectance:\n        try:\n            diffuse_reflectance = get_data_field_from_simpa_output(file,\n                                                                   Tags.DATA_FIELD_DIFFUSE_REFLECTANCE,\n                                                                   wavelength)\n            diffuse_reflectance_position = get_data_field_from_simpa_output(file,\n                                                                            Tags.DATA_FIELD_DIFFUSE_REFLECTANCE_POS,\n                                                                            wavelength)\n        except KeyError as e:\n            logger.critical(\"The key \" + str(Tags.DATA_FIELD_FLUENCE) + \" was not in the simpa output.\")\n            show_fluence = False\n            fluence = None\n\n    if show_initial_pressure:\n        try:\n            initial_pressure = get_data_field_from_simpa_output(file, Tags.DATA_FIELD_INITIAL_PRESSURE, wavelength)\n        except KeyError as e:\n            logger.critical(\"The key \" + str(Tags.DATA_FIELD_INITIAL_PRESSURE) + \" was not in the simpa output.\")\n            show_initial_pressure = False\n            initial_pressure = None\n\n    if show_time_series_data:\n        try:\n            time_series_data = get_data_field_from_simpa_output(file, Tags.DATA_FIELD_TIME_SERIES_DATA, wavelength)\n        except KeyError as e:\n            logger.critical(\"The key \" + str(Tags.DATA_FIELD_TIME_SERIES_DATA) + \" was not in the simpa output.\")\n            show_time_series_data = False\n            time_series_data = None\n\n    if show_reconstructed_data:\n        try:\n            reconstructed_data = get_data_field_from_simpa_output(file, Tags.DATA_FIELD_RECONSTRUCTED_DATA, wavelength)\n        except KeyError as e:\n            logger.critical(\"The key \" + str(Tags.DATA_FIELD_RECONSTRUCTED_DATA) + \" was not in the simpa output.\")\n            show_reconstructed_data = False\n            reconstructed_data = None\n\n    if show_oxygenation:\n        try:\n            oxygenation = get_data_field_from_simpa_output(file, Tags.DATA_FIELD_OXYGENATION, wavelength)\n        except KeyError as e:\n            logger.critical(\"The key \" + str(Tags.DATA_FIELD_OXYGENATION) + \" was not in the simpa output.\")\n            show_oxygenation = False\n            oxygenation = None\n\n    if show_linear_unmixing_sO2:\n        try:\n            linear_unmixing_output = get_data_field_from_simpa_output(file, Tags.LINEAR_UNMIXING_RESULT)\n            linear_unmixing_sO2 = linear_unmixing_output[\"sO2\"]\n        except KeyError as e:\n            logger.critical(\"The key \" + str(Tags.LINEAR_UNMIXING_RESULT) + \" was not in the simpa output or blood \"\n                                                                            \"oxygen saturation was not computed.\")\n            show_linear_unmixing_sO2 = False\n            linear_unmixing_sO2 = None\n\n    cmap_label_names, cmap_label_values, cmap = get_segmentation_colormap()\n\n    data_to_show = []\n    data_item_names = []\n    cmaps = []\n    logscales = []\n\n    if diffuse_reflectance is not None and show_diffuse_reflectance:\n        fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n        plt.title(\"Diffuse reflectance\")\n        ax.scatter(diffuse_reflectance_position[:, 0],\n                   diffuse_reflectance_position[:, 1],\n                   diffuse_reflectance_position[:, 2],\n                   c=diffuse_reflectance,\n                   cmap='RdBu',\n                   antialiased=False)\n        ax.set_box_aspect((2, 1, 1))\n        plt.show()\n\n    if absorption is not None and show_absorption:\n        data_to_show.append(absorption)\n        data_item_names.append(\"Absorption Coefficient\")\n        cmaps.append(\"gray\")\n        logscales.append(True and log_scale)\n    if scattering is not None and show_scattering:\n        data_to_show.append(scattering)\n        data_item_names.append(\"Scattering Coefficient\")\n        cmaps.append(\"gray\")\n        logscales.append(True and log_scale)\n    if anisotropy is not None and show_anisotropy:\n        data_to_show.append(anisotropy)\n        data_item_names.append(\"Anisotropy\")\n        cmaps.append(\"gray\")\n        logscales.append(True and log_scale)\n    if speed_of_sound is not None and show_speed_of_sound:\n        data_to_show.append(speed_of_sound)\n        data_item_names.append(\"Speed of Sound\")\n        cmaps.append(\"gray\")\n        logscales.append(True and log_scale)\n    if density is not None and show_tissue_density:\n        data_to_show.append(density)\n        data_item_names.append(\"Density\")\n        cmaps.append(\"gray\")\n        logscales.append(True and log_scale)\n    if fluence is not None and show_fluence:\n        data_to_show.append(fluence)\n        data_item_names.append(\"Fluence\")\n        cmaps.append(\"viridis\")\n        logscales.append(True and log_scale)\n    if initial_pressure is not None and show_initial_pressure:\n        data_to_show.append(initial_pressure)\n        data_item_names.append(\"Initial Pressure\")\n        cmaps.append(\"viridis\")\n        logscales.append(True and log_scale)\n    if time_series_data is not None and show_time_series_data:\n        data_to_show.append(time_series_data)\n        data_item_names.append(\"Time Series Data\")\n        cmaps.append(\"gray\")\n        logscales.append(False and log_scale)\n    if reconstructed_data is not None and show_reconstructed_data:\n        data_to_show.append(reconstructed_data)\n        data_item_names.append(\"Reconstruction\")\n        cmaps.append(\"viridis\")\n        logscales.append(True and log_scale)\n    if oxygenation is not None and show_oxygenation:\n        data_to_show.append(oxygenation)\n        data_item_names.append(\"Oxygenation\")\n        cmaps.append(\"viridis\")\n        logscales.append(False and log_scale)\n    if linear_unmixing_sO2 is not None and show_linear_unmixing_sO2:\n        data_to_show.append(linear_unmixing_sO2)\n        data_item_names.append(\"Linear Unmixed Oxygenation\")\n        cmaps.append(\"viridis\")\n        logscales.append(False and log_scale)\n    if segmentation_map is not None and show_segmentation_map:\n        data_to_show.append(segmentation_map)\n        data_item_names.append(\"Segmentation Map\")\n        cmaps.append(cmap)\n        logscales.append(False)\n\n    if show_xz_only:\n        num_rows = 1\n    else:\n        num_rows = 2\n\n    plt.figure(figsize=(len(data_to_show)*4, num_rows*3.5))\n    for i in range(len(data_to_show)):\n\n        plt.subplot(num_rows, len(data_to_show), i+1)\n        plt.title(data_item_names[i])\n        if len(np.shape(data_to_show[i])) > 2:\n            pos = int(np.shape(data_to_show[i])[1] / 2) - 1\n            data = np.rot90(data_to_show[i][:, pos, :], -1)\n            plt.imshow(np.log10(data) if logscales[i] else data, cmap=cmaps[i])\n        else:\n            data = np.rot90(data_to_show[i][:, :], -1)\n            plt.imshow(np.log10(data) if logscales[i] else data, cmap=cmaps[i])\n        plt.colorbar()\n\n        if not show_xz_only:\n            plt.subplot(num_rows, len(data_to_show), i + 1 + len(data_to_show))\n            plt.title(data_item_names[i])\n            if len(np.shape(data_to_show[i])) > 2:\n                pos = int(np.shape(data_to_show[i])[0] / 2)\n                data = np.rot90(data_to_show[i][pos, :, :], -1)\n                plt.imshow(np.log10(data) if logscales[i] else data, cmap=cmaps[i])\n            else:\n                data = np.rot90(data_to_show[i][:, :], -1)\n                plt.imshow(np.log10(data) if logscales[i] else data, cmap=cmaps[i])\n            plt.colorbar()\n\n    plt.tight_layout()\n    if save_path is not None:\n        plt.savefig(save_path, dpi=500)\n    else:\n        plt.show()\n    plt.close()",
  "def get_segmentation_colormap():\n    values = []\n    names = []\n\n    for string in SegmentationClasses.__dict__:\n        if string[0:2] != \"__\":\n            values.append(SegmentationClasses.__dict__[string])\n            names.append(string)\n\n    values = np.asarray(values)\n    names = np.asarray(names)\n    sort_indexes = np.argsort(values)\n    values = values[sort_indexes]\n    names = names[sort_indexes]\n\n    colors = [list(np.random.random(3)) for _ in range(len(names))]\n    cmap = mpl.colors.LinearSegmentedColormap.from_list(\n        'Custom cmap', colors, len(names))\n\n    return names, values, cmap",
  "def visualise_device(device: PhotoacousticDevice, save_path=None):\n    settings = Settings()\n    settings[Tags.DIM_VOLUME_X_MM] = 100\n    settings[Tags.DIM_VOLUME_Y_MM] = 20\n    settings[Tags.DIM_VOLUME_Z_MM] = 100\n    settings[Tags.SPACING_MM] = 0.5\n    settings[Tags.STRUCTURES] = {}\n\n    positions = device.detection_geometry.get_detector_element_positions_accounting_for_device_position_mm()\n    detector_elements = device.detection_geometry.get_detector_element_orientations()\n\n    plt.figure(figsize=(8, 4))\n    plt.subplot(1, 2, 1)\n    plt.title(\"In volume\")\n    plt.scatter(positions[:, 0], positions[:, 2])\n    plt.quiver(positions[:, 0], positions[:, 2], detector_elements[:, 0], detector_elements[:, 2])\n    fov = device.detection_geometry.get_field_of_view_mm()\n    plt.plot([fov[0], fov[1], fov[1], fov[0], fov[0]], [fov[4], fov[4], fov[5], fov[5], fov[4]], color=\"red\")\n    plt.subplot(1, 2, 2)\n    plt.title(\"Baseline\")\n    positions = device.detection_geometry.get_detector_element_positions_base_mm()\n    fov = device.detection_geometry.field_of_view_extent_mm\n    plt.plot([fov[0], fov[1], fov[1], fov[0], fov[0]], [fov[4], fov[4], fov[5], fov[5], fov[4]], color=\"red\")\n    plt.scatter(positions[:, 0], positions[:, 2])\n    plt.quiver(positions[:, 0], positions[:, 2], detector_elements[:, 0], detector_elements[:, 2])\n    plt.tight_layout()\n\n    if save_path is None:\n        plt.show()\n    else:\n        plt.savefig(save_path)",
  "class SimulationModule:\n    \"\"\"\n    Defines a simulation module that is callable via the SIMPA core.simulation.simulate method.\n    \"\"\"\n\n    def __init__(self, global_settings):\n        \"\"\"\n         :param global_settings: The SIMPA settings dictionary\n         :type global_settings: Settings\n        \"\"\"\n        self.logger = Logger()\n        self.global_settings = global_settings\n\n    @abstractmethod\n    def run(self, digital_device_twin: DigitalDeviceTwinBase):\n        \"\"\"\n        Executes the respective simulation module\n\n        :param digital_device_twin: The digital twin that can be used by the digital device_twin.\n        \"\"\"\n        pass",
  "def __init__(self, global_settings):\n        \"\"\"\n         :param global_settings: The SIMPA settings dictionary\n         :type global_settings: Settings\n        \"\"\"\n        self.logger = Logger()\n        self.global_settings = global_settings",
  "def run(self, digital_device_twin: DigitalDeviceTwinBase):\n        \"\"\"\n        Executes the respective simulation module\n\n        :param digital_device_twin: The digital twin that can be used by the digital device_twin.\n        \"\"\"\n        pass",
  "def simulate(simulation_pipeline: list, settings: Settings, digital_device_twin: DigitalDeviceTwinBase):\n    \"\"\"\n    This method constitutes the staring point for the simulation pipeline\n    of the SIMPA toolkit.\n\n    :param simulation_pipeline: a list of callable functions\n    :param settings: settings dictionary containing the simulation instructions\n    :param digital_device_twin: a digital device twin of an imaging device as specified by the DigitalDeviceTwinBase\n        class.\n    :raises TypeError: if one of the given parameters is not of the correct type\n    :raises AssertionError: if the digital device twin is not able to simulate the settings specification\n    :return: list with the save paths of the simulated data within the HDF5 file.\n    \"\"\"\n    start_time = time.time()\n    logger = Logger()\n    if not isinstance(settings, Settings):\n        logger.critical(\"The second argument was not a settings instance!\")\n        raise TypeError(\"Use a Settings instance from simpa.utils.settings_generator as simulation input.\")\n\n    if not isinstance(simulation_pipeline, list):\n        logger.critical(\"The first argument was not a list with pipeline methods!\")\n        raise TypeError(\"The simulation pipeline must be a list that contains callable functions.\")\n\n    if not digital_device_twin.check_settings_prerequisites(settings):\n        msg = (\"The simulation settings do not work with the digital device twin chosen.\"\n               \"Please check the log for details.\")\n        logger.critical(msg)\n        raise AssertionError(msg)\n\n    simpa_output = dict()\n    path = settings[Tags.SIMULATION_PATH] + \"/\"\n    if not os.path.exists(path):\n        os.makedirs(path)\n\n    if Tags.SIMPA_OUTPUT_NAME in settings:\n        simpa_output_path = path + settings[Tags.SIMPA_OUTPUT_NAME]\n    else:\n        simpa_output_path = path + settings[Tags.VOLUME_NAME]\n\n    settings[Tags.SIMPA_OUTPUT_PATH] = simpa_output_path + \".hdf5\"\n\n    simpa_output[Tags.SETTINGS] = settings\n    simpa_output[Tags.DIGITAL_DEVICE] = digital_device_twin\n    simpa_output[Tags.SIMULATION_PIPELINE] = [type(x).__name__ for x in simulation_pipeline]\n\n    logger.debug(\"Saving settings dictionary...\")\n    save_hdf5(simpa_output, settings[Tags.SIMPA_OUTPUT_PATH])\n    logger.debug(\"Saving settings dictionary...[Done]\")\n\n    for wavelength in settings[Tags.WAVELENGTHS]:\n        logger.debug(f\"Running pipeline for wavelength {wavelength}nm...\")\n\n        if settings[Tags.RANDOM_SEED] is not None:\n            np.random.seed(settings[Tags.RANDOM_SEED])\n        else:\n            np.random.seed(None)\n\n        settings[Tags.WAVELENGTH] = wavelength\n\n        for pipeline_element in simulation_pipeline:\n            logger.debug(f\"Running {type(pipeline_element)}\")\n            pipeline_element.run(digital_device_twin)\n\n        logger.debug(f\"Running pipeline for wavelength {wavelength}nm... [Done]\")\n\n    # If the dimensions of the simulation results are changed after calling the respective module\n    # adapter / processing components, the amount of space on the hard drive that is allocated by the HDF5\n    # code does not dynamically change. This can be remedied by re-writing the file after the simulation\n    # terminates. As it might have a negative impact on simulation performance, it must be activated\n    # by the user manually. Active by default.\n    if not (Tags.DO_FILE_COMPRESSION in settings and\n            not settings[Tags.DO_FILE_COMPRESSION]):\n        all_data = load_hdf5(settings[Tags.SIMPA_OUTPUT_PATH])\n        if Tags.VOLUME_CREATION_MODEL_SETTINGS in all_data[Tags.SETTINGS] and \\\n                Tags.INPUT_SEGMENTATION_VOLUME in all_data[Tags.SETTINGS][Tags.VOLUME_CREATION_MODEL_SETTINGS]:\n            del all_data[Tags.SETTINGS][Tags.VOLUME_CREATION_MODEL_SETTINGS][Tags.INPUT_SEGMENTATION_VOLUME]\n        save_hdf5(all_data, settings[Tags.SIMPA_OUTPUT_PATH], file_compression=\"gzip\")\n\n    # Export simulation result to the IPASC format.\n    if Tags.DO_IPASC_EXPORT in settings and settings[Tags.DO_IPASC_EXPORT]:\n        logger.info(\"Exporting to IPASC....\")\n        export_to_ipasc(settings[Tags.SIMPA_OUTPUT_PATH], device=digital_device_twin)\n\n    logger.info(f\"The entire simulation pipeline required {time.time() - start_time} seconds.\")",
  "class SegmentationBasedVolumeCreationAdapter(VolumeCreatorModuleBase):\n    \"\"\"\n    This volume creator expects a np.ndarray to be in the settigs\n    under the Tags.INPUT_SEGMENTATION_VOLUME tag and uses this array\n    together with a SegmentationClass mapping which is a dict defined in\n    the settings under Tags.SEGMENTATION_CLASS_MAPPING.\n\n    With this, an even greater utility is warranted.\n    \"\"\"\n\n    def create_simulation_volume(self) -> dict:\n        volumes, x_dim_px, y_dim_px, z_dim_px = self.create_empty_volumes()\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n\n        segmentation_volume = self.component_settings[Tags.INPUT_SEGMENTATION_VOLUME]\n        segmentation_classes = np.unique(segmentation_volume, return_counts=False)\n        x_dim_seg_px, y_dim_seg_px, z_dim_seg_px = np.shape(segmentation_volume)\n\n        if x_dim_px != x_dim_seg_px:\n            raise ValueError(\"x_dim of volumes and segmentation must perfectly match but was {} and {}\"\n                             .format(x_dim_px, x_dim_seg_px))\n        if y_dim_px != y_dim_seg_px:\n            raise ValueError(\"y_dim of volumes and segmentation must perfectly match but was {} and {}\"\n                             .format(y_dim_px, y_dim_seg_px))\n        if z_dim_px != z_dim_seg_px:\n            raise ValueError(\"z_dim of volumes and segmentation must perfectly match but was {} and {}\"\n                             .format(z_dim_px, z_dim_seg_px))\n\n        class_mapping = self.component_settings[Tags.SEGMENTATION_CLASS_MAPPING]\n\n        for seg_class in segmentation_classes:\n            class_properties = class_mapping[seg_class].get_properties_for_wavelength(wavelength)\n            for prop_tag in TissueProperties.property_tags:\n                volumes[prop_tag][segmentation_volume == seg_class] = class_properties[prop_tag]\n\n        save_hdf5(self.global_settings, self.global_settings[Tags.SIMPA_OUTPUT_PATH], \"/settings/\")\n\n        return volumes",
  "def create_simulation_volume(self) -> dict:\n        volumes, x_dim_px, y_dim_px, z_dim_px = self.create_empty_volumes()\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n\n        segmentation_volume = self.component_settings[Tags.INPUT_SEGMENTATION_VOLUME]\n        segmentation_classes = np.unique(segmentation_volume, return_counts=False)\n        x_dim_seg_px, y_dim_seg_px, z_dim_seg_px = np.shape(segmentation_volume)\n\n        if x_dim_px != x_dim_seg_px:\n            raise ValueError(\"x_dim of volumes and segmentation must perfectly match but was {} and {}\"\n                             .format(x_dim_px, x_dim_seg_px))\n        if y_dim_px != y_dim_seg_px:\n            raise ValueError(\"y_dim of volumes and segmentation must perfectly match but was {} and {}\"\n                             .format(y_dim_px, y_dim_seg_px))\n        if z_dim_px != z_dim_seg_px:\n            raise ValueError(\"z_dim of volumes and segmentation must perfectly match but was {} and {}\"\n                             .format(z_dim_px, z_dim_seg_px))\n\n        class_mapping = self.component_settings[Tags.SEGMENTATION_CLASS_MAPPING]\n\n        for seg_class in segmentation_classes:\n            class_properties = class_mapping[seg_class].get_properties_for_wavelength(wavelength)\n            for prop_tag in TissueProperties.property_tags:\n                volumes[prop_tag][segmentation_volume == seg_class] = class_properties[prop_tag]\n\n        save_hdf5(self.global_settings, self.global_settings[Tags.SIMPA_OUTPUT_PATH], \"/settings/\")\n\n        return volumes",
  "class ModelBasedVolumeCreationAdapter(VolumeCreatorModuleBase):\n    \"\"\"\n    The model-based volume creator uses a set of rules how to generate structures\n    to create a simulation volume.\n    These structures are added to the dictionary and later combined by the algorithm::\n\n        # Initialise settings dictionaries\n        simulation_settings = Settings()\n        all_structures = Settings()\n        structure = Settings()\n\n        # Definition of en example structure.\n        # The concrete structure parameters will change depending on the\n        # structure type\n        structure[Tags.PRIORITY] = 1\n        structure[Tags.STRUCTURE_START_MM] = [0, 0, 0]\n        structure[Tags.STRUCTURE_END_MM] = [0, 0, 100]\n        structure[Tags.MOLECULE_COMPOSITION] = TISSUE_LIBRARY.muscle()\n        structure[Tags.CONSIDER_PARTIAL_VOLUME] = True\n        structure[Tags.ADHERE_TO_DEFORMATION] = True\n        structure[Tags.STRUCTURE_TYPE] = Tags.HORIZONTAL_LAYER_STRUCTURE\n\n        all_structures[\"arbitrary_identifier\"] = structure\n\n        simulation_settings[Tags.STRUCTURES] = all_structures\n\n        # ...\n        # Define further simulation settings\n        # ...\n\n        simulate(simulation_settings)\n\n\n    \"\"\"\n\n    def create_simulation_volume(self) -> dict:\n\n        if Tags.SIMULATE_DEFORMED_LAYERS in self.component_settings \\\n                and self.component_settings[Tags.SIMULATE_DEFORMED_LAYERS]:\n            self.logger.debug(\"Tags.SIMULATE_DEFORMED_LAYERS in self.component_settings is TRUE\")\n            if Tags.DEFORMED_LAYERS_SETTINGS not in self.component_settings:\n                np.random.seed(self.global_settings[Tags.RANDOM_SEED])\n                self.component_settings[Tags.DEFORMED_LAYERS_SETTINGS] = create_deformation_settings(\n                    bounds_mm=[[0, self.global_settings[Tags.DIM_VOLUME_X_MM]],\n                               [0, self.global_settings[Tags.DIM_VOLUME_Y_MM]]],\n                    maximum_z_elevation_mm=3,\n                    filter_sigma=0,\n                    cosine_scaling_factor=1)\n\n        volumes, x_dim_px, y_dim_px, z_dim_px = self.create_empty_volumes()\n        global_volume_fractions = np.zeros((x_dim_px, y_dim_px, z_dim_px))\n        max_added_fractions = np.zeros((x_dim_px, y_dim_px, z_dim_px))\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n\n        structure_list = Structures(self.global_settings, self.component_settings)\n        priority_sorted_structures = structure_list.sorted_structures\n\n        for structure in priority_sorted_structures:\n            self.logger.debug(type(structure))\n\n            structure_properties = structure.properties_for_wavelength(wavelength)\n\n            structure_volume_fractions = structure.geometrical_volume\n            structure_indexes_mask = structure_volume_fractions > 0\n            global_volume_fractions_mask = global_volume_fractions < 1\n            mask = structure_indexes_mask & global_volume_fractions_mask\n            added_volume_fraction = (global_volume_fractions + structure_volume_fractions)\n\n            added_volume_fraction[added_volume_fraction <= 1 & mask] = structure_volume_fractions[\n                added_volume_fraction <= 1 & mask]\n\n            selector_more_than_1 = added_volume_fraction > 1\n            if selector_more_than_1.any():\n                remaining_volume_fraction_to_fill = 1 - global_volume_fractions[selector_more_than_1]\n                fraction_to_be_filled = structure_volume_fractions[selector_more_than_1]\n                added_volume_fraction[selector_more_than_1] = np.min([remaining_volume_fraction_to_fill,\n                                                                      fraction_to_be_filled], axis=0)\n            for key in volumes.keys():\n                if structure_properties[key] is None:\n                    continue\n                if key == Tags.DATA_FIELD_SEGMENTATION:\n                    added_fraction_greater_than_any_added_fraction = added_volume_fraction > max_added_fractions\n                    volumes[key][added_fraction_greater_than_any_added_fraction & mask] = structure_properties[key]\n                    max_added_fractions[added_fraction_greater_than_any_added_fraction & mask] = \\\n                        added_volume_fraction[added_fraction_greater_than_any_added_fraction & mask]\n                else:\n                    volumes[key][mask] += added_volume_fraction[mask] * structure_properties[key]\n\n            global_volume_fractions[mask] += added_volume_fraction[mask]\n\n        return volumes",
  "def create_simulation_volume(self) -> dict:\n\n        if Tags.SIMULATE_DEFORMED_LAYERS in self.component_settings \\\n                and self.component_settings[Tags.SIMULATE_DEFORMED_LAYERS]:\n            self.logger.debug(\"Tags.SIMULATE_DEFORMED_LAYERS in self.component_settings is TRUE\")\n            if Tags.DEFORMED_LAYERS_SETTINGS not in self.component_settings:\n                np.random.seed(self.global_settings[Tags.RANDOM_SEED])\n                self.component_settings[Tags.DEFORMED_LAYERS_SETTINGS] = create_deformation_settings(\n                    bounds_mm=[[0, self.global_settings[Tags.DIM_VOLUME_X_MM]],\n                               [0, self.global_settings[Tags.DIM_VOLUME_Y_MM]]],\n                    maximum_z_elevation_mm=3,\n                    filter_sigma=0,\n                    cosine_scaling_factor=1)\n\n        volumes, x_dim_px, y_dim_px, z_dim_px = self.create_empty_volumes()\n        global_volume_fractions = np.zeros((x_dim_px, y_dim_px, z_dim_px))\n        max_added_fractions = np.zeros((x_dim_px, y_dim_px, z_dim_px))\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n\n        structure_list = Structures(self.global_settings, self.component_settings)\n        priority_sorted_structures = structure_list.sorted_structures\n\n        for structure in priority_sorted_structures:\n            self.logger.debug(type(structure))\n\n            structure_properties = structure.properties_for_wavelength(wavelength)\n\n            structure_volume_fractions = structure.geometrical_volume\n            structure_indexes_mask = structure_volume_fractions > 0\n            global_volume_fractions_mask = global_volume_fractions < 1\n            mask = structure_indexes_mask & global_volume_fractions_mask\n            added_volume_fraction = (global_volume_fractions + structure_volume_fractions)\n\n            added_volume_fraction[added_volume_fraction <= 1 & mask] = structure_volume_fractions[\n                added_volume_fraction <= 1 & mask]\n\n            selector_more_than_1 = added_volume_fraction > 1\n            if selector_more_than_1.any():\n                remaining_volume_fraction_to_fill = 1 - global_volume_fractions[selector_more_than_1]\n                fraction_to_be_filled = structure_volume_fractions[selector_more_than_1]\n                added_volume_fraction[selector_more_than_1] = np.min([remaining_volume_fraction_to_fill,\n                                                                      fraction_to_be_filled], axis=0)\n            for key in volumes.keys():\n                if structure_properties[key] is None:\n                    continue\n                if key == Tags.DATA_FIELD_SEGMENTATION:\n                    added_fraction_greater_than_any_added_fraction = added_volume_fraction > max_added_fractions\n                    volumes[key][added_fraction_greater_than_any_added_fraction & mask] = structure_properties[key]\n                    max_added_fractions[added_fraction_greater_than_any_added_fraction & mask] = \\\n                        added_volume_fraction[added_fraction_greater_than_any_added_fraction & mask]\n                else:\n                    volumes[key][mask] += added_volume_fraction[mask] * structure_properties[key]\n\n            global_volume_fractions[mask] += added_volume_fraction[mask]\n\n        return volumes",
  "class VolumeCreatorModuleBase(SimulationModule):\n    \"\"\"\n    Use this class to define your own volume creation adapter.\n\n    \"\"\"\n\n    def __init__(self, global_settings: Settings):\n        super(VolumeCreatorModuleBase, self).__init__(global_settings=global_settings)\n        self.component_settings = global_settings.get_volume_creation_settings()\n\n    def create_empty_volumes(self):\n        volumes = dict()\n        voxel_spacing = self.global_settings[Tags.SPACING_MM]\n        volume_x_dim = int(round(self.global_settings[Tags.DIM_VOLUME_X_MM] / voxel_spacing))\n        volume_y_dim = int(round(self.global_settings[Tags.DIM_VOLUME_Y_MM] / voxel_spacing))\n        volume_z_dim = int(round(self.global_settings[Tags.DIM_VOLUME_Z_MM] / voxel_spacing))\n        sizes = (volume_x_dim, volume_y_dim, volume_z_dim)\n\n        for key in TissueProperties.property_tags:\n            volumes[key] = np.zeros(sizes)\n\n        return volumes, volume_x_dim, volume_y_dim, volume_z_dim\n\n    @abstractmethod\n    def create_simulation_volume(self) -> dict:\n        \"\"\"\n        This method creates an in silico representation of a tissue as described in the settings file that is given.\n\n        :return: A dictionary containing optical and acoustic properties as well as other characteristics of the\n            simulated volume such as oxygenation, and a segmentation mask. All of these are given as 3d numpy arrays.\n        :rtype: dict\n        \"\"\"\n        pass\n\n    def run(self, device):\n        self.logger.info(\"VOLUME CREATION\")\n\n        volumes = self.create_simulation_volume()\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_equal_shapes(list(volumes.values()))\n            for _volume_name in volumes.keys():\n                if _volume_name == Tags.DATA_FIELD_OXYGENATION:\n                    # oxygenation can have NaN by definition\n                    continue\n                assert_array_well_defined(volumes[_volume_name], array_name=_volume_name)\n\n        save_volumes = dict()\n        for key, value in volumes.items():\n            if key in [Tags.DATA_FIELD_ABSORPTION_PER_CM, Tags.DATA_FIELD_SCATTERING_PER_CM,\n                       Tags.DATA_FIELD_ANISOTROPY]:\n                save_volumes[key] = {self.global_settings[Tags.WAVELENGTH]: value}\n            else:\n                save_volumes[key] = value\n\n        volume_path = generate_dict_path(Tags.SIMULATION_PROPERTIES, self.global_settings[Tags.WAVELENGTH])\n        save_hdf5(save_volumes, self.global_settings[Tags.SIMPA_OUTPUT_PATH], file_dictionary_path=volume_path)",
  "def __init__(self, global_settings: Settings):\n        super(VolumeCreatorModuleBase, self).__init__(global_settings=global_settings)\n        self.component_settings = global_settings.get_volume_creation_settings()",
  "def create_empty_volumes(self):\n        volumes = dict()\n        voxel_spacing = self.global_settings[Tags.SPACING_MM]\n        volume_x_dim = int(round(self.global_settings[Tags.DIM_VOLUME_X_MM] / voxel_spacing))\n        volume_y_dim = int(round(self.global_settings[Tags.DIM_VOLUME_Y_MM] / voxel_spacing))\n        volume_z_dim = int(round(self.global_settings[Tags.DIM_VOLUME_Z_MM] / voxel_spacing))\n        sizes = (volume_x_dim, volume_y_dim, volume_z_dim)\n\n        for key in TissueProperties.property_tags:\n            volumes[key] = np.zeros(sizes)\n\n        return volumes, volume_x_dim, volume_y_dim, volume_z_dim",
  "def create_simulation_volume(self) -> dict:\n        \"\"\"\n        This method creates an in silico representation of a tissue as described in the settings file that is given.\n\n        :return: A dictionary containing optical and acoustic properties as well as other characteristics of the\n            simulated volume such as oxygenation, and a segmentation mask. All of these are given as 3d numpy arrays.\n        :rtype: dict\n        \"\"\"\n        pass",
  "def run(self, device):\n        self.logger.info(\"VOLUME CREATION\")\n\n        volumes = self.create_simulation_volume()\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_equal_shapes(list(volumes.values()))\n            for _volume_name in volumes.keys():\n                if _volume_name == Tags.DATA_FIELD_OXYGENATION:\n                    # oxygenation can have NaN by definition\n                    continue\n                assert_array_well_defined(volumes[_volume_name], array_name=_volume_name)\n\n        save_volumes = dict()\n        for key, value in volumes.items():\n            if key in [Tags.DATA_FIELD_ABSORPTION_PER_CM, Tags.DATA_FIELD_SCATTERING_PER_CM,\n                       Tags.DATA_FIELD_ANISOTROPY]:\n                save_volumes[key] = {self.global_settings[Tags.WAVELENGTH]: value}\n            else:\n                save_volumes[key] = value\n\n        volume_path = generate_dict_path(Tags.SIMULATION_PROPERTIES, self.global_settings[Tags.WAVELENGTH])\n        save_hdf5(save_volumes, self.global_settings[Tags.SIMPA_OUTPUT_PATH], file_dictionary_path=volume_path)",
  "class DelayAndSumAdapter(ReconstructionAdapterBase):\n\n    def reconstruction_algorithm(self, time_series_sensor_data, detection_geometry: DetectionGeometryBase):\n        \"\"\"\n        Applies the Delay and Sum beamforming algorithm [1] to the time series sensor data (2D numpy array where the\n        first dimension corresponds to the sensor elements and the second to the recorded time steps) with the given\n        beamforming settings (dictionary).\n        A reconstructed image (2D numpy array) is returned.\n        This implementation uses PyTorch Tensors to perform computations and is able to run on GPUs.\n\n        [1] T. Kirchner et al. 2018, \"Signed Real-Time Delay Multiply and Sum Beamforming for Multispectral\n        Photoacoustic Imaging\", https://doi.org/10.3390/jimaging4100121\n        \"\"\"\n\n        time_series_sensor_data, sensor_positions, speed_of_sound_in_m_per_s, spacing_in_mm, time_spacing_in_ms, torch_device = preparing_reconstruction_and_obtaining_reconstruction_settings(\n            time_series_sensor_data, self.component_settings, self.global_settings, detection_geometry, self.logger)\n\n        ### ALGORITHM ITSELF ###\n\n        xdim, zdim, ydim, xdim_start, xdim_end, ydim_start, ydim_end, zdim_start, zdim_end = compute_image_dimensions(\n            detection_geometry, spacing_in_mm, self.logger)\n\n        if zdim == 1:\n            sensor_positions[:, 1] = 0  # Assume imaging plane\n\n        # construct output image\n        output = torch.zeros((xdim, ydim, zdim), dtype=torch.float32, device=torch_device)\n\n        values, _ = compute_delay_and_sum_values(time_series_sensor_data, sensor_positions, xdim,\n                                                 ydim, zdim, xdim_start, xdim_end, ydim_start, ydim_end, zdim_start, zdim_end, spacing_in_mm, speed_of_sound_in_m_per_s,\n                                                 time_spacing_in_ms, self.logger, torch_device,\n                                                 self.component_settings)\n\n        _sum = torch.sum(values, dim=3)\n        counter = torch.count_nonzero(values, dim=3)\n        torch.divide(_sum, counter, out=output)\n\n        reconstructed = output.cpu().numpy()\n\n        return reconstructed.squeeze()",
  "def reconstruct_delay_and_sum_pytorch(time_series_sensor_data: np.ndarray,\n                                      detection_geometry: DetectionGeometryBase,\n                                      speed_of_sound_in_m_per_s: int = 1540,\n                                      time_spacing_in_s: float = 2.5e-8,\n                                      sensor_spacing_in_mm: float = 0.1,\n                                      recon_mode: str = Tags.RECONSTRUCTION_MODE_PRESSURE,\n                                      apodization: str = Tags.RECONSTRUCTION_APODIZATION_BOX) -> np.ndarray:\n    \"\"\"\n    Convenience function for reconstructing time series data using Delay and Sum algorithm implemented in PyTorch\n\n    :param time_series_sensor_data: (2D numpy array) sensor data of shape (sensor elements, time steps)\n    :param detection_geometry: The DetectionGeometryBase that should be used to reconstruct the given time series data\n    :param speed_of_sound_in_m_per_s: (int) speed of sound in medium in meters per second (default: 1540 m/s)\n    :param time_spacing_in_s: (float) time between sampling points in seconds (default: 2.5e-8 s which is equal to 40 MHz)\n    :param sensor_spacing_in_mm: (float) space between sensor elements in millimeters (default: 0.1 mm)\n    :param recon_mode: SIMPA Tag defining the reconstruction mode - pressure default OR differential\n    :param apodization: SIMPA Tag defining the apodization function (default box)\n    :return: (2D numpy array) reconstructed image as 2D numpy array\n    \"\"\"\n    # create settings\n    settings = create_reconstruction_settings(speed_of_sound_in_m_per_s, time_spacing_in_s, sensor_spacing_in_mm,\n                                              recon_mode, apodization)\n    adapter = DelayAndSumAdapter(settings)\n    return adapter.reconstruction_algorithm(time_series_sensor_data, detection_geometry)",
  "def reconstruction_algorithm(self, time_series_sensor_data, detection_geometry: DetectionGeometryBase):\n        \"\"\"\n        Applies the Delay and Sum beamforming algorithm [1] to the time series sensor data (2D numpy array where the\n        first dimension corresponds to the sensor elements and the second to the recorded time steps) with the given\n        beamforming settings (dictionary).\n        A reconstructed image (2D numpy array) is returned.\n        This implementation uses PyTorch Tensors to perform computations and is able to run on GPUs.\n\n        [1] T. Kirchner et al. 2018, \"Signed Real-Time Delay Multiply and Sum Beamforming for Multispectral\n        Photoacoustic Imaging\", https://doi.org/10.3390/jimaging4100121\n        \"\"\"\n\n        time_series_sensor_data, sensor_positions, speed_of_sound_in_m_per_s, spacing_in_mm, time_spacing_in_ms, torch_device = preparing_reconstruction_and_obtaining_reconstruction_settings(\n            time_series_sensor_data, self.component_settings, self.global_settings, detection_geometry, self.logger)\n\n        ### ALGORITHM ITSELF ###\n\n        xdim, zdim, ydim, xdim_start, xdim_end, ydim_start, ydim_end, zdim_start, zdim_end = compute_image_dimensions(\n            detection_geometry, spacing_in_mm, self.logger)\n\n        if zdim == 1:\n            sensor_positions[:, 1] = 0  # Assume imaging plane\n\n        # construct output image\n        output = torch.zeros((xdim, ydim, zdim), dtype=torch.float32, device=torch_device)\n\n        values, _ = compute_delay_and_sum_values(time_series_sensor_data, sensor_positions, xdim,\n                                                 ydim, zdim, xdim_start, xdim_end, ydim_start, ydim_end, zdim_start, zdim_end, spacing_in_mm, speed_of_sound_in_m_per_s,\n                                                 time_spacing_in_ms, self.logger, torch_device,\n                                                 self.component_settings)\n\n        _sum = torch.sum(values, dim=3)\n        counter = torch.count_nonzero(values, dim=3)\n        torch.divide(_sum, counter, out=output)\n\n        reconstructed = output.cpu().numpy()\n\n        return reconstructed.squeeze()",
  "class TimeReversalAdapter(ReconstructionAdapterBase):\n    \"\"\"\n    The time reversal adapter includes the time reversal reconstruction\n    algorithm implemented by the k-Wave toolkit into SIMPA.\n\n    Time reversal reconstruction uses the time series data and computes the forward simulation model\n    backwards in time::\n\n        Treeby, Bradley E., Edward Z. Zhang, and Benjamin T. Cox.\n        \"Photoacoustic tomography in absorbing acoustic media using\n        time reversal.\" Inverse Problems 26.11 (2010): 115003.\n\n\n    \"\"\"\n\n    def get_acoustic_properties(self, input_data: dict, detection_geometry):\n        \"\"\"\n        This method extracts the acoustic tissue properties from the settings dictionary and\n        amends the information to the input_data.\n\n        :param input_data: a dictionary containing the information needed for time reversal.\n        :param detection_geometry: PA device that is used for reconstruction\n        \"\"\"\n\n        if Tags.ACOUSTIC_SIMULATION_3D not in self.component_settings or not \\\n                self.component_settings[Tags.ACOUSTIC_SIMULATION_3D]:\n            axes = (0, 1)\n        else:\n            axes = (0, 2)\n\n        pa_device = detection_geometry\n        pa_device.check_settings_prerequisites(self.global_settings)\n\n        # spacing\n        if Tags.SPACING_MM in self.component_settings and self.component_settings[Tags.SPACING_MM]:\n            spacing_in_mm = self.component_settings[Tags.SPACING_MM]\n        elif Tags.SPACING_MM in self.global_settings and self.global_settings[Tags.SPACING_MM]:\n            spacing_in_mm = self.global_settings[Tags.SPACING_MM]\n        else:\n            raise AttributeError(\"Please specify a value for SPACING_MM\")\n\n        detector_positions = detection_geometry.get_detector_element_positions_accounting_for_device_position_mm()\n        detector_positions_voxels = np.round(detector_positions / spacing_in_mm).astype(int)\n\n        # plus 2 because of off-\n        volume_x_dim = int(np.ceil(self.global_settings[Tags.DIM_VOLUME_X_MM] / spacing_in_mm) + 1)\n        # by-one error in matlab\n        volume_y_dim = int(np.ceil(self.global_settings[Tags.DIM_VOLUME_Y_MM] / spacing_in_mm) + 1)\n        volume_z_dim = int(np.ceil(self.global_settings[Tags.DIM_VOLUME_Z_MM] / spacing_in_mm) + 1)      # otherwise\n\n        if Tags.ACOUSTIC_SIMULATION_3D not in self.component_settings or not \\\n                self.component_settings[Tags.ACOUSTIC_SIMULATION_3D]:\n            sizes = (volume_z_dim, volume_x_dim)\n            sensor_map = np.zeros(sizes)\n            sensor_map[detector_positions_voxels[:, 2]+1, detector_positions_voxels[:, 0]+1] = 1\n        else:\n            sizes = (volume_z_dim, volume_y_dim, volume_x_dim)\n            sensor_map = np.zeros(sizes)\n            sensor_map[detector_positions_voxels[:, 2]+1,\n                       detector_positions_voxels[:, 1]+1,\n                       detector_positions_voxels[:, 0]+1] = 1\n\n        # check that the spacing is large enough for all detector elements to be on the sensor map\n        det_elements_sensor_map = np.count_nonzero(sensor_map)\n        if det_elements_sensor_map != pa_device.number_detector_elements:\n            raise AttributeError(\"The spacing is too large to fit every detector element on the sensor map.\"\n                                 \"Please increase it! \"\n                                 f\"Expected {pa_device.number_detector_elements} elements but it \"\n                                 f\"were {det_elements_sensor_map}.\")\n\n        # TODO: Include possibility to\n        possible_acoustic_properties = [Tags.DATA_FIELD_SPEED_OF_SOUND,\n                                        Tags.DATA_FIELD_DENSITY,\n                                        Tags.DATA_FIELD_ALPHA_COEFF\n                                        ]\n        input_data[Tags.KWAVE_PROPERTY_SENSOR_MASK] = sensor_map\n\n        for acoustic_property in possible_acoustic_properties:\n            if acoustic_property in self.component_settings:\n                try:\n                    input_data[acoustic_property] = self.component_settings[acoustic_property]\n                except ValueError or KeyError:\n                    self.logger.error(\"{} not specified.\".format(acoustic_property))\n\n        return input_data, spacing_in_mm\n\n    def reorder_time_series_data(self, time_series_sensor_data, detection_geometry):\n        \"\"\"\n        Reorders the time series data to match the order that is assumed by kwave\n        during image reconstruction with TimeReversal.\n\n        The main issue here is, that, while forward modelling allows for the definition of\n        3D cuboid bounding boxes for the detector elements, TimeReversal does not implement\n        this feature.\n        Instead, a binary mask is given and these are indexed in a column-row-wise manner in\n        the output.\n        The default np.argsort() method does not yield the same result as expected by\n        k-Wave. Hence, this workaround.\n        \"\"\"\n\n        detector_positions = detection_geometry.get_detector_element_positions_base_mm()\n        angles = np.arctan2(detector_positions[:, 2], detector_positions[:, 0])\n        matlab_order = np.argsort(angles)\n        return time_series_sensor_data[matlab_order]\n\n    def reconstruction_algorithm(self, time_series_sensor_data, detection_geometry):\n        input_data = dict()\n\n        # If the detecttion_geometry is something else than linear, the time series data have to be reordered for matlab\n        if not isinstance(detection_geometry, LinearArrayDetectionGeometry):\n            time_series_sensor_data = self.reorder_time_series_data(time_series_sensor_data, detection_geometry)\n\n        input_data[Tags.DATA_FIELD_TIME_SERIES_DATA] = time_series_sensor_data\n        input_data, spacing_in_mm = self.get_acoustic_properties(input_data, detection_geometry)\n        acoustic_path = self.global_settings[Tags.SIMPA_OUTPUT_PATH] + \".mat\"\n\n        possible_k_wave_parameters = [Tags.MODEL_SENSOR_FREQUENCY_RESPONSE,\n                                      Tags.KWAVE_PROPERTY_ALPHA_POWER, Tags.GPU, Tags.KWAVE_PROPERTY_PMLInside, Tags.KWAVE_PROPERTY_PMLAlpha, Tags.KWAVE_PROPERTY_PlotPML,\n                                      Tags.RECORDMOVIE, Tags.MOVIENAME,\n                                      Tags.SENSOR_DIRECTIVITY_PATTERN]\n\n        pa_device = detection_geometry\n        k_wave_settings = Settings({\n            Tags.SENSOR_NUM_ELEMENTS: pa_device.number_detector_elements,\n            Tags.SENSOR_DIRECTIVITY_SIZE_M: pa_device.detector_element_width_mm / 1000,\n            Tags.SENSOR_CENTER_FREQUENCY_HZ: pa_device.center_frequency_Hz,\n            Tags.SENSOR_BANDWIDTH_PERCENT: pa_device.bandwidth_percent,\n            Tags.SPACING_MM: spacing_in_mm\n        })\n\n        for parameter in possible_k_wave_parameters:\n            if parameter in self.component_settings:\n                k_wave_settings[parameter] = self.component_settings[parameter]\n            elif parameter in self.global_settings:\n                k_wave_settings[parameter] = self.global_settings[parameter]\n\n        if Tags.K_WAVE_SPECIFIC_DT in self.global_settings and Tags.K_WAVE_SPECIFIC_NT in self.global_settings:\n            k_wave_settings[\"dt\"] = self.global_settings[Tags.K_WAVE_SPECIFIC_DT]\n            k_wave_settings[\"Nt\"] = self.global_settings[Tags.K_WAVE_SPECIFIC_NT]\n        else:\n            num_samples = time_series_sensor_data.shape[1]\n            time_per_sample_s = 1 / (self.component_settings[Tags.SENSOR_SAMPLING_RATE_MHZ] * 1000000)\n            k_wave_settings[\"dt\"] = time_per_sample_s\n            k_wave_settings[\"Nt\"] = num_samples\n        input_data[\"settings\"] = k_wave_settings\n        sio.savemat(acoustic_path, input_data, long_field_names=True)\n\n        if Tags.ACOUSTIC_SIMULATION_3D in self.component_settings and \\\n                self.component_settings[Tags.ACOUSTIC_SIMULATION_3D]:\n            time_reversal_script = \"time_reversal_3D\"\n            axes = (0, 2)\n        else:\n            time_reversal_script = \"time_reversal_2D\"\n            axes = (0, 1)\n\n        base_script_path = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n\n        cmd = list()\n        cmd.append(self.component_settings[Tags.ACOUSTIC_MODEL_BINARY_PATH])\n        cmd.append(\"-nodisplay\")\n        cmd.append(\"-nosplash\")\n        cmd.append(\"-automation\")\n        cmd.append(\"-wait\")\n        cmd.append(\"-r\")\n        cmd.append(\"addpath('\" + base_script_path + \"');\" +\n                   time_reversal_script + \"('\" + acoustic_path + \"');exit;\")\n\n        cur_dir = os.getcwd()\n        os.chdir(self.global_settings[Tags.SIMULATION_PATH])\n        self.logger.info(cmd)\n        subprocess.run(cmd)\n\n        reconstructed_data = sio.loadmat(acoustic_path + \"tr.mat\")[Tags.DATA_FIELD_RECONSTRUCTED_DATA]\n\n        reconstructed_data = np.flipud(np.rot90(reconstructed_data, 1, axes))\n\n        field_of_view_mm = detection_geometry.get_field_of_view_mm()\n        field_of_view_voxels = (field_of_view_mm / spacing_in_mm).astype(np.int32)\n        self.logger.debug(f\"FOV (voxels): {field_of_view_voxels}\")\n        # In case it should be cropped from A to A, then crop from A to A+1\n        x_offset_correct = 1 if (field_of_view_voxels[1] - field_of_view_voxels[0]) < 1 else 0\n        y_offset_correct = 1 if (field_of_view_voxels[3] - field_of_view_voxels[2]) < 1 else 0\n        z_offset_correct = 1 if (field_of_view_voxels[5] - field_of_view_voxels[4]) < 1 else 0\n\n        if len(np.shape(reconstructed_data)) == 2:\n            reconstructed_data = np.squeeze(reconstructed_data[field_of_view_voxels[0]:field_of_view_voxels[1] + x_offset_correct,\n                                                               field_of_view_voxels[4]:field_of_view_voxels[5] + z_offset_correct])\n        elif len(np.shape(reconstructed_data)) == 3:\n            reconstructed_data = np.squeeze(reconstructed_data[field_of_view_voxels[0]:field_of_view_voxels[1] + x_offset_correct,\n                                                               field_of_view_voxels[2]:field_of_view_voxels[3] + y_offset_correct,\n                                                               field_of_view_voxels[4]:field_of_view_voxels[5] + z_offset_correct])\n        else:\n            self.logger.critical(\"Unexpected number of dimensions in reconstructed image. \"\n                                 f\"Expected 2 or 3 but was {len(np.shape(reconstructed_data))}\")\n\n        os.chdir(cur_dir)\n        os.remove(acoustic_path)\n        os.remove(acoustic_path + \"tr.mat\")\n\n        return reconstructed_data",
  "def get_acoustic_properties(self, input_data: dict, detection_geometry):\n        \"\"\"\n        This method extracts the acoustic tissue properties from the settings dictionary and\n        amends the information to the input_data.\n\n        :param input_data: a dictionary containing the information needed for time reversal.\n        :param detection_geometry: PA device that is used for reconstruction\n        \"\"\"\n\n        if Tags.ACOUSTIC_SIMULATION_3D not in self.component_settings or not \\\n                self.component_settings[Tags.ACOUSTIC_SIMULATION_3D]:\n            axes = (0, 1)\n        else:\n            axes = (0, 2)\n\n        pa_device = detection_geometry\n        pa_device.check_settings_prerequisites(self.global_settings)\n\n        # spacing\n        if Tags.SPACING_MM in self.component_settings and self.component_settings[Tags.SPACING_MM]:\n            spacing_in_mm = self.component_settings[Tags.SPACING_MM]\n        elif Tags.SPACING_MM in self.global_settings and self.global_settings[Tags.SPACING_MM]:\n            spacing_in_mm = self.global_settings[Tags.SPACING_MM]\n        else:\n            raise AttributeError(\"Please specify a value for SPACING_MM\")\n\n        detector_positions = detection_geometry.get_detector_element_positions_accounting_for_device_position_mm()\n        detector_positions_voxels = np.round(detector_positions / spacing_in_mm).astype(int)\n\n        # plus 2 because of off-\n        volume_x_dim = int(np.ceil(self.global_settings[Tags.DIM_VOLUME_X_MM] / spacing_in_mm) + 1)\n        # by-one error in matlab\n        volume_y_dim = int(np.ceil(self.global_settings[Tags.DIM_VOLUME_Y_MM] / spacing_in_mm) + 1)\n        volume_z_dim = int(np.ceil(self.global_settings[Tags.DIM_VOLUME_Z_MM] / spacing_in_mm) + 1)      # otherwise\n\n        if Tags.ACOUSTIC_SIMULATION_3D not in self.component_settings or not \\\n                self.component_settings[Tags.ACOUSTIC_SIMULATION_3D]:\n            sizes = (volume_z_dim, volume_x_dim)\n            sensor_map = np.zeros(sizes)\n            sensor_map[detector_positions_voxels[:, 2]+1, detector_positions_voxels[:, 0]+1] = 1\n        else:\n            sizes = (volume_z_dim, volume_y_dim, volume_x_dim)\n            sensor_map = np.zeros(sizes)\n            sensor_map[detector_positions_voxels[:, 2]+1,\n                       detector_positions_voxels[:, 1]+1,\n                       detector_positions_voxels[:, 0]+1] = 1\n\n        # check that the spacing is large enough for all detector elements to be on the sensor map\n        det_elements_sensor_map = np.count_nonzero(sensor_map)\n        if det_elements_sensor_map != pa_device.number_detector_elements:\n            raise AttributeError(\"The spacing is too large to fit every detector element on the sensor map.\"\n                                 \"Please increase it! \"\n                                 f\"Expected {pa_device.number_detector_elements} elements but it \"\n                                 f\"were {det_elements_sensor_map}.\")\n\n        # TODO: Include possibility to\n        possible_acoustic_properties = [Tags.DATA_FIELD_SPEED_OF_SOUND,\n                                        Tags.DATA_FIELD_DENSITY,\n                                        Tags.DATA_FIELD_ALPHA_COEFF\n                                        ]\n        input_data[Tags.KWAVE_PROPERTY_SENSOR_MASK] = sensor_map\n\n        for acoustic_property in possible_acoustic_properties:\n            if acoustic_property in self.component_settings:\n                try:\n                    input_data[acoustic_property] = self.component_settings[acoustic_property]\n                except ValueError or KeyError:\n                    self.logger.error(\"{} not specified.\".format(acoustic_property))\n\n        return input_data, spacing_in_mm",
  "def reorder_time_series_data(self, time_series_sensor_data, detection_geometry):\n        \"\"\"\n        Reorders the time series data to match the order that is assumed by kwave\n        during image reconstruction with TimeReversal.\n\n        The main issue here is, that, while forward modelling allows for the definition of\n        3D cuboid bounding boxes for the detector elements, TimeReversal does not implement\n        this feature.\n        Instead, a binary mask is given and these are indexed in a column-row-wise manner in\n        the output.\n        The default np.argsort() method does not yield the same result as expected by\n        k-Wave. Hence, this workaround.\n        \"\"\"\n\n        detector_positions = detection_geometry.get_detector_element_positions_base_mm()\n        angles = np.arctan2(detector_positions[:, 2], detector_positions[:, 0])\n        matlab_order = np.argsort(angles)\n        return time_series_sensor_data[matlab_order]",
  "def reconstruction_algorithm(self, time_series_sensor_data, detection_geometry):\n        input_data = dict()\n\n        # If the detecttion_geometry is something else than linear, the time series data have to be reordered for matlab\n        if not isinstance(detection_geometry, LinearArrayDetectionGeometry):\n            time_series_sensor_data = self.reorder_time_series_data(time_series_sensor_data, detection_geometry)\n\n        input_data[Tags.DATA_FIELD_TIME_SERIES_DATA] = time_series_sensor_data\n        input_data, spacing_in_mm = self.get_acoustic_properties(input_data, detection_geometry)\n        acoustic_path = self.global_settings[Tags.SIMPA_OUTPUT_PATH] + \".mat\"\n\n        possible_k_wave_parameters = [Tags.MODEL_SENSOR_FREQUENCY_RESPONSE,\n                                      Tags.KWAVE_PROPERTY_ALPHA_POWER, Tags.GPU, Tags.KWAVE_PROPERTY_PMLInside, Tags.KWAVE_PROPERTY_PMLAlpha, Tags.KWAVE_PROPERTY_PlotPML,\n                                      Tags.RECORDMOVIE, Tags.MOVIENAME,\n                                      Tags.SENSOR_DIRECTIVITY_PATTERN]\n\n        pa_device = detection_geometry\n        k_wave_settings = Settings({\n            Tags.SENSOR_NUM_ELEMENTS: pa_device.number_detector_elements,\n            Tags.SENSOR_DIRECTIVITY_SIZE_M: pa_device.detector_element_width_mm / 1000,\n            Tags.SENSOR_CENTER_FREQUENCY_HZ: pa_device.center_frequency_Hz,\n            Tags.SENSOR_BANDWIDTH_PERCENT: pa_device.bandwidth_percent,\n            Tags.SPACING_MM: spacing_in_mm\n        })\n\n        for parameter in possible_k_wave_parameters:\n            if parameter in self.component_settings:\n                k_wave_settings[parameter] = self.component_settings[parameter]\n            elif parameter in self.global_settings:\n                k_wave_settings[parameter] = self.global_settings[parameter]\n\n        if Tags.K_WAVE_SPECIFIC_DT in self.global_settings and Tags.K_WAVE_SPECIFIC_NT in self.global_settings:\n            k_wave_settings[\"dt\"] = self.global_settings[Tags.K_WAVE_SPECIFIC_DT]\n            k_wave_settings[\"Nt\"] = self.global_settings[Tags.K_WAVE_SPECIFIC_NT]\n        else:\n            num_samples = time_series_sensor_data.shape[1]\n            time_per_sample_s = 1 / (self.component_settings[Tags.SENSOR_SAMPLING_RATE_MHZ] * 1000000)\n            k_wave_settings[\"dt\"] = time_per_sample_s\n            k_wave_settings[\"Nt\"] = num_samples\n        input_data[\"settings\"] = k_wave_settings\n        sio.savemat(acoustic_path, input_data, long_field_names=True)\n\n        if Tags.ACOUSTIC_SIMULATION_3D in self.component_settings and \\\n                self.component_settings[Tags.ACOUSTIC_SIMULATION_3D]:\n            time_reversal_script = \"time_reversal_3D\"\n            axes = (0, 2)\n        else:\n            time_reversal_script = \"time_reversal_2D\"\n            axes = (0, 1)\n\n        base_script_path = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n\n        cmd = list()\n        cmd.append(self.component_settings[Tags.ACOUSTIC_MODEL_BINARY_PATH])\n        cmd.append(\"-nodisplay\")\n        cmd.append(\"-nosplash\")\n        cmd.append(\"-automation\")\n        cmd.append(\"-wait\")\n        cmd.append(\"-r\")\n        cmd.append(\"addpath('\" + base_script_path + \"');\" +\n                   time_reversal_script + \"('\" + acoustic_path + \"');exit;\")\n\n        cur_dir = os.getcwd()\n        os.chdir(self.global_settings[Tags.SIMULATION_PATH])\n        self.logger.info(cmd)\n        subprocess.run(cmd)\n\n        reconstructed_data = sio.loadmat(acoustic_path + \"tr.mat\")[Tags.DATA_FIELD_RECONSTRUCTED_DATA]\n\n        reconstructed_data = np.flipud(np.rot90(reconstructed_data, 1, axes))\n\n        field_of_view_mm = detection_geometry.get_field_of_view_mm()\n        field_of_view_voxels = (field_of_view_mm / spacing_in_mm).astype(np.int32)\n        self.logger.debug(f\"FOV (voxels): {field_of_view_voxels}\")\n        # In case it should be cropped from A to A, then crop from A to A+1\n        x_offset_correct = 1 if (field_of_view_voxels[1] - field_of_view_voxels[0]) < 1 else 0\n        y_offset_correct = 1 if (field_of_view_voxels[3] - field_of_view_voxels[2]) < 1 else 0\n        z_offset_correct = 1 if (field_of_view_voxels[5] - field_of_view_voxels[4]) < 1 else 0\n\n        if len(np.shape(reconstructed_data)) == 2:\n            reconstructed_data = np.squeeze(reconstructed_data[field_of_view_voxels[0]:field_of_view_voxels[1] + x_offset_correct,\n                                                               field_of_view_voxels[4]:field_of_view_voxels[5] + z_offset_correct])\n        elif len(np.shape(reconstructed_data)) == 3:\n            reconstructed_data = np.squeeze(reconstructed_data[field_of_view_voxels[0]:field_of_view_voxels[1] + x_offset_correct,\n                                                               field_of_view_voxels[2]:field_of_view_voxels[3] + y_offset_correct,\n                                                               field_of_view_voxels[4]:field_of_view_voxels[5] + z_offset_correct])\n        else:\n            self.logger.critical(\"Unexpected number of dimensions in reconstructed image. \"\n                                 f\"Expected 2 or 3 but was {len(np.shape(reconstructed_data))}\")\n\n        os.chdir(cur_dir)\n        os.remove(acoustic_path)\n        os.remove(acoustic_path + \"tr.mat\")\n\n        return reconstructed_data",
  "class DelayMultiplyAndSumAdapter(ReconstructionAdapterBase):\n\n    def reconstruction_algorithm(self, time_series_sensor_data, detection_geometry: DetectionGeometryBase):\n        \"\"\"\n        Applies the Delay Multiply and Sum beamforming algorithm [1] to the time series sensor data (2D numpy array where the\n        first dimension corresponds to the sensor elements and the second to the recorded time steps) with the given\n        beamforming settings (dictionary).\n        A reconstructed image (2D numpy array) is returned.\n        This implementation uses PyTorch Tensors to perform computations and is able to run on GPUs.\n\n        [1] T. Kirchner et al. 2018, \"Signed Real-Time Delay Multiply and Sum Beamforming for Multispectral\n        Photoacoustic Imaging\", https://doi.org/10.3390/jimaging4100121\n        \"\"\"\n\n        time_series_sensor_data, sensor_positions, speed_of_sound_in_m_per_s, spacing_in_mm, time_spacing_in_ms, torch_device = preparing_reconstruction_and_obtaining_reconstruction_settings(\n            time_series_sensor_data, self.component_settings, self.global_settings, detection_geometry, self.logger)\n\n        ### ALGORITHM ITSELF ###\n\n        xdim, zdim, ydim, xdim_start, xdim_end, ydim_start, ydim_end, zdim_start, zdim_end = compute_image_dimensions(\n            detection_geometry, spacing_in_mm, self.logger)\n\n        if zdim == 1:\n            sensor_positions[:, 1] = 0  # Assume imaging plane\n\n        # construct output image\n        output = torch.zeros((xdim, ydim, zdim), dtype=torch.float32, device=torch_device)\n\n        values, n_sensor_elements = compute_delay_and_sum_values(time_series_sensor_data, sensor_positions, xdim,\n                                                                 ydim, zdim, xdim_start, xdim_end, ydim_start, ydim_end,\n                                                                 zdim_start, zdim_end, spacing_in_mm, speed_of_sound_in_m_per_s,\n                                                                 time_spacing_in_ms, self.logger, torch_device,\n                                                                 self.component_settings)\n\n        for x in range(xdim):\n            yy, zz, nn, mm = torch.meshgrid(torch.arange(ydim, device=torch_device),\n                                            torch.arange(zdim, device=torch_device),\n                                            torch.arange(n_sensor_elements, device=torch_device),\n                                            torch.arange(n_sensor_elements, device=torch_device))\n            M = values[x, yy, zz, nn] * values[x, yy, zz, mm]\n            M = torch.sign(M) * torch.sqrt(torch.abs(M))\n            # only take upper triangle without diagonal and sum up along n and m axis (last two)\n            output[x] = torch.triu(M, diagonal=1).sum(dim=(-1, -2))\n\n        reconstructed = output.cpu().numpy()\n\n        return reconstructed.squeeze()",
  "def reconstruct_delay_multiply_and_sum_pytorch(time_series_sensor_data: np.ndarray,\n                                               detection_geometry: DetectionGeometryBase,\n                                               speed_of_sound_in_m_per_s: int = 1540,\n                                               time_spacing_in_s: float = 2.5e-8,\n                                               sensor_spacing_in_mm: float = 0.1,\n                                               recon_mode: str = Tags.RECONSTRUCTION_MODE_PRESSURE,\n                                               apodization: str = Tags.RECONSTRUCTION_APODIZATION_BOX) -> np.ndarray:\n    \"\"\"\n    Convenience function for reconstructing time series data using Delay and Sum algorithm implemented in PyTorch\n\n    :param time_series_sensor_data: (2D numpy array) sensor data of shape (sensor elements, time steps)\n    :param detection_geometry: The DetectioNGeometryBase to use for the reconstruction of the given time series data\n    :param speed_of_sound_in_m_per_s: (int) speed of sound in medium in meters per second (default: 1540 m/s)\n    :param time_spacing_in_s: (float) time between sampling points in seconds (default: 2.5e-8 s which is equal to 40 MHz)\n    :param sensor_spacing_in_mm: (float) space between sensor elements in millimeters (default: 0.1 mm)\n    :param recon_mode: SIMPA Tag defining the reconstruction mode - pressure default OR differential\n    :param apodization: SIMPA Tag defining the apodization function (default box)\n    :return: (2D numpy array) reconstructed image as 2D numpy array\n    \"\"\"\n    # create settings\n    settings = create_reconstruction_settings(speed_of_sound_in_m_per_s, time_spacing_in_s, sensor_spacing_in_mm,\n                                              recon_mode, apodization)\n    adapter = DelayMultiplyAndSumAdapter(settings)\n    return adapter.reconstruction_algorithm(time_series_sensor_data, detection_geometry)",
  "def reconstruction_algorithm(self, time_series_sensor_data, detection_geometry: DetectionGeometryBase):\n        \"\"\"\n        Applies the Delay Multiply and Sum beamforming algorithm [1] to the time series sensor data (2D numpy array where the\n        first dimension corresponds to the sensor elements and the second to the recorded time steps) with the given\n        beamforming settings (dictionary).\n        A reconstructed image (2D numpy array) is returned.\n        This implementation uses PyTorch Tensors to perform computations and is able to run on GPUs.\n\n        [1] T. Kirchner et al. 2018, \"Signed Real-Time Delay Multiply and Sum Beamforming for Multispectral\n        Photoacoustic Imaging\", https://doi.org/10.3390/jimaging4100121\n        \"\"\"\n\n        time_series_sensor_data, sensor_positions, speed_of_sound_in_m_per_s, spacing_in_mm, time_spacing_in_ms, torch_device = preparing_reconstruction_and_obtaining_reconstruction_settings(\n            time_series_sensor_data, self.component_settings, self.global_settings, detection_geometry, self.logger)\n\n        ### ALGORITHM ITSELF ###\n\n        xdim, zdim, ydim, xdim_start, xdim_end, ydim_start, ydim_end, zdim_start, zdim_end = compute_image_dimensions(\n            detection_geometry, spacing_in_mm, self.logger)\n\n        if zdim == 1:\n            sensor_positions[:, 1] = 0  # Assume imaging plane\n\n        # construct output image\n        output = torch.zeros((xdim, ydim, zdim), dtype=torch.float32, device=torch_device)\n\n        values, n_sensor_elements = compute_delay_and_sum_values(time_series_sensor_data, sensor_positions, xdim,\n                                                                 ydim, zdim, xdim_start, xdim_end, ydim_start, ydim_end,\n                                                                 zdim_start, zdim_end, spacing_in_mm, speed_of_sound_in_m_per_s,\n                                                                 time_spacing_in_ms, self.logger, torch_device,\n                                                                 self.component_settings)\n\n        for x in range(xdim):\n            yy, zz, nn, mm = torch.meshgrid(torch.arange(ydim, device=torch_device),\n                                            torch.arange(zdim, device=torch_device),\n                                            torch.arange(n_sensor_elements, device=torch_device),\n                                            torch.arange(n_sensor_elements, device=torch_device))\n            M = values[x, yy, zz, nn] * values[x, yy, zz, mm]\n            M = torch.sign(M) * torch.sqrt(torch.abs(M))\n            # only take upper triangle without diagonal and sum up along n and m axis (last two)\n            output[x] = torch.triu(M, diagonal=1).sum(dim=(-1, -2))\n\n        reconstructed = output.cpu().numpy()\n\n        return reconstructed.squeeze()",
  "def get_apodization_factor(apodization_method: str = Tags.RECONSTRUCTION_APODIZATION_BOX,\n                           dimensions: tuple = None, n_sensor_elements=None,\n                           device: torch.device = 'cpu') -> torch.tensor:\n    \"\"\"\n    Construct apodization factors according to `apodization_method` [hann, hamming or box apodization (default)]\n    for given dimensions and `n_sensor_elements`.\n\n    :param apodization_method: (str) Apodization method, one of Tags.RECONSTRUCTION_APODIZATION_HANN,\n                        Tags.RECONSTRUCTION_APODIZATION_HAMMING and Tags.RECONSTRUCTION_APODIZATION_BOX (default)\n    :param dimensions: (tuple) size of each dimension of reconstructed image as int, might have 2 or 3 entries.\n    :param n_sensor_elements: (int) number of sensor elements\n    :param device: (torch device) PyTorch tensor device\n    :return: (torch tensor) tensor with apodization factors which can be multipied with DAS values\n    \"\"\"\n\n    if dimensions is None or n_sensor_elements is None:\n        raise AttributeError(\"dimensions and n_sensor_elements must be specified and not be None\")\n\n    # hann window\n    if apodization_method == Tags.RECONSTRUCTION_APODIZATION_HANN:\n        hann = torch.hann_window(n_sensor_elements, device=device)\n        output = hann.expand(dimensions + (n_sensor_elements,))\n    # hamming window\n    elif apodization_method == Tags.RECONSTRUCTION_APODIZATION_HAMMING:\n        hamming = torch.hamming_window(n_sensor_elements, device=device)\n        output = hamming.expand(dimensions + (n_sensor_elements,))\n    # box window apodization as default\n    else:\n        output = torch.ones(dimensions + (n_sensor_elements,), device=device)\n\n    return output",
  "def bandpass_filter_with_settings(data: np.ndarray, global_settings: Settings, component_settings: Settings,\n                                  device: DetectionGeometryBase) -> np.ndarray:\n    \"\"\"\n    Applies corresponding bandpass filter which can be set in \n    `component_settings[Tags.BANDPASS_FILTER_METHOD]`, using Tukey window-based filter as default.\n\n    :param data: (numpy array) data to be filtered\n    :param global_settings: (Settings) settings for the whole simulation\n    :param component_settings: (Settings) settings for the reconstruction module\n    :param device:\n    :return: (numpy array) filtered data\n    \"\"\"\n\n    # select corresponding filtering method depending on tag in settings\n    if Tags.BANDPASS_FILTER_METHOD in component_settings:\n        if component_settings[Tags.BANDPASS_FILTER_METHOD] == Tags.TUKEY_BANDPASS_FILTER:\n            return tukey_bandpass_filtering_with_settings(data, global_settings, component_settings, device)\n        elif component_settings[Tags.BANDPASS_FILTER_METHOD] == Tags.BUTTERWORTH_BANDPASS_FILTER:\n            return butter_bandpass_filtering_with_settings(data, global_settings, component_settings, device)\n        else:\n            return tukey_bandpass_filtering_with_settings(data, global_settings, component_settings, device)\n    else:\n        return tukey_bandpass_filtering_with_settings(data, global_settings, component_settings, device)",
  "def butter_bandpass_filtering(data: np.array,  time_spacing_in_ms: float = None,\n                              cutoff_lowpass_in_Hz: int = int(8e6), cutoff_highpass_in_Hz: int = int(0.1e6),\n                              order: int = 1) -> np.ndarray:\n    \"\"\"\n    Apply a butterworth bandpass filter of `order` with cutoff values at `cutoff_lowpass_in_Hz`\n    and `cutoff_highpass_in_Hz` Hz on the `data` using the scipy.signal.butter filter.\n\n    :param data: (numpy array) data to be filtered\n    :param time_spacing_in_ms: (float) time spacing in milliseconds, e.g. 2.5e-5\n    :param cutoff_lowpass_in_Hz: (int) Signal above this value will be ignored (in Hz)\n    :param cutoff_highpass_in_Hz: (int) Signal below this value will be ignored (in Hz)\n    :param order: (int) order of the filter\n    :return: (numpy array) filtered data\n    \"\"\"\n\n    # determines nyquist frequency\n    nyquist = 0.5 / time_spacing_in_ms*1000\n\n    # computes the critical frequencies\n    if cutoff_lowpass_in_Hz is None:\n        low = 0.000001\n    else:\n        low = (cutoff_lowpass_in_Hz / nyquist)\n    if cutoff_highpass_in_Hz is None:\n        high = 0.999999999\n    else:\n        high = (cutoff_highpass_in_Hz / nyquist)\n\n    b, a = butter(N=order, Wn=[high, low], btype='band')\n    y = lfilter(b, a, data)\n\n    return y",
  "def butter_bandpass_filtering_with_settings(data: np.ndarray, global_settings: Settings, component_settings: Settings,\n                                            device: DetectionGeometryBase) -> np.ndarray:\n    \"\"\"\n    Apply a butterworth bandpass filter of `order` with cutoff values at `cutoff_lowpass_in_Hz`\n    and `cutoff_highpass_in_Hz` Hz on the `data` using the scipy.signal.butter filter.\n    Those values are obtained from the `global_settings`, `component_settings`, and `device`.\n\n    :param data: (numpy array) data to be filtered\n    :param global_settings: (Settings) settings for the whole simulation\n    :param component_settings: (Settings) settings for the reconstruction module\n    :param device:\n    :return: (numpy array) filtered data\n    \"\"\"\n\n    if Tags.K_WAVE_SPECIFIC_DT in global_settings and global_settings[Tags.K_WAVE_SPECIFIC_DT]:\n        time_spacing_in_ms = global_settings[Tags.K_WAVE_SPECIFIC_DT] * 1000\n    elif device.sampling_frequency_MHz is not None:\n        time_spacing_in_ms = 1.0 / (device.sampling_frequency_MHz * 1000)\n    else:\n        raise AttributeError(\"Please specify a value for SENSOR_SAMPLING_RATE_MHZ or K_WAVE_SPECIFIC_DT\")\n\n    cutoff_lowpass_in_Hz = component_settings[Tags.BANDPASS_CUTOFF_LOWPASS_IN_HZ] \\\n        if Tags.BANDPASS_CUTOFF_LOWPASS_IN_HZ in component_settings else int(8e6)\n    cutoff_highpass_in_Hz = component_settings[Tags.BANDPASS_CUTOFF_HIGHPASS_IN_HZ] \\\n        if Tags.BANDPASS_CUTOFF_HIGHPASS_IN_HZ in component_settings else int(0.1e6)\n    filter_order = component_settings[\n        Tags.BUTTERWORTH_FILTER_ORDER] if Tags.BUTTERWORTH_FILTER_ORDER in component_settings else 1\n\n    if data is None or time_spacing_in_ms is None:\n        raise AttributeError(\"data and time spacing must be specified\")\n\n    return butter_bandpass_filtering(data, time_spacing_in_ms, cutoff_lowpass_in_Hz, cutoff_highpass_in_Hz, filter_order)",
  "def tukey_bandpass_filtering(data: np.ndarray, time_spacing_in_ms: float = None,\n                             cutoff_lowpass_in_Hz: int = int(8e6), cutoff_highpass_in_Hz: int = int(0.1e6),\n                             tukey_alpha: float = 0.5, resampling_for_fft: bool = False) -> np.ndarray:\n    \"\"\"\n    Apply a tukey bandpass filter with cutoff values at `cutoff_lowpass_in_Hz` and `cutoff_highpass_in_Hz` Hz \n    and a tukey window with alpha value of `tukey_alpha` inbetween on the `data` in Fourier space.\n    Note that the filter operates only on positive frequencies using rfft (One can use rfft since we only use real valued data.).\n    Filtering is performed along the last dimension.\n\n    Warning: Depending on the number of data points and time spacing the represented frequencies may not be ideal which leads \n    to rounding issues.\n\n    :param data: (numpy array) data to be filtered\n    :param time_spacing_in_ms: (float) time spacing in milliseconds, e.g. 2.5e-5\n    :param cutoff_lowpass_in_Hz: (int) Signal above this value will be ignored, Signal at this value will be included as long as \n                                       it is represented in the freqeuency space (in Hz)\n    :param cutoff_highpass_in_Hz: (int) Signal below this value will be ignored, Signal at this value will be included as long as \n                                        it is represented in the freqeuency space (in Hz)\n    :param tukey_alpha: (float) transition value between 0 (rectangular) and 1 (Hann window)\n    :param resampling_for_fft: (bool) whether the data is resampled to a power of 2 in time dimension\n                                      before applying the FFT and resampled back after filtering\n    :return: (numpy array) filtered data\n    \"\"\"\n\n    # input checking\n    if cutoff_highpass_in_Hz > cutoff_lowpass_in_Hz:\n        raise ValueError(\"The highpass cutoff value must be lower than the lowpass cutoff value.\")\n\n    # no resampling by default\n    resampling_factor = 1\n    original_size = data.shape[-1]\n    target_size = original_size\n\n    # resampling if requested\n    if resampling_for_fft:\n        # resampling settings\n        order = 0\n        mode = 'constant'\n\n        target_size = int(2**(np.ceil(np.log2(original_size))))  # compute next larger power of 2\n        resampling_factor = original_size/target_size\n        zoom_factors = [1]*data.ndim  # resampling factor for each dimension\n        zoom_factors[-1] = 1.0/resampling_factor\n\n        data = zoom(data, zoom_factors, order=order, mode=mode)\n\n        time_spacing_in_ms *= resampling_factor\n\n    # create tukey window\n    window = tukey_window_function(target_size, time_spacing_in_ms, cutoff_lowpass_in_Hz,\n                                   cutoff_highpass_in_Hz, tukey_alpha)\n\n    # transform data into Fourier space, multiply filter and transform back\n    data_in_fourier_space = np.fft.rfft(data)\n    filtered_data_in_fourier_space = data_in_fourier_space * np.broadcast_to(window, np.shape(data_in_fourier_space))\n    filtered_data = np.fft.irfft(filtered_data_in_fourier_space, n=target_size).real\n\n    # resample back to original size if necessary\n    if resampling_for_fft:\n        inverse_zoom_factors = [1.0/factor for factor in zoom_factors]\n        return zoom(filtered_data, inverse_zoom_factors, order=order, mode=mode)\n    else:\n        return filtered_data",
  "def tukey_window_function(target_size: int, time_spacing_in_ms: float, cutoff_lowpass_in_Hz: int,\n                          cutoff_highpass_in_Hz: int, tukey_alpha: float) -> np.ndarray:\n    \"\"\"\n    Creates the tukey window in wanted frequency space for given cutoff frequencies and alpha value.\n\n    :param target_size: number of time steps in time series data\n    :type target_size: int\n    :param time_spacing_in_ms: time spacing in ms of time series data\n    :type time_spacing_in_ms: float\n    :param cutoff_lowpass_in_Hz: Signal above this value will be ignored, Signal at this value will be included as long as \n                                 it is represented in the freqeuency space (in Hz)\n    :type cutoff_lowpass_in_Hz: int\n    :param cutoff_highpass_in_Hz: Signal below this value will be ignored, Signal at this value will be included as long as \n                                  it is represented in the freqeuency space (in Hz)\n    :type cutoff_highpass_in_Hz: int\n    :param tukey_alpha: transition value between 0 (rectangular) and 1 (Hann window)\n    :type tukey_alpha: float\n    :return: tukey window for filtering time series data\n    :rtype: np.ndarray\n    \"\"\"\n    # array of frequencies in Hz corrsponding to rfft and irfft method\n    frequencies = np.fft.rfftfreq(target_size, time_spacing_in_ms/1000)\n    delta_f = frequencies[1]-frequencies[0]  # frequency step size\n    # compute closest indices for cutoff frequencies, limited by the Nyquist frequency\n    # floor in order to ignore all frequencies above given lowpass cutoff\n    large_index = np.floor(cutoff_lowpass_in_Hz/delta_f)\n    # ceil in order to ignore all frequencies below given highpass cutoff\n    small_index = np.ceil(cutoff_highpass_in_Hz/delta_f)\n    large_index = int(np.clip(large_index, 0, len(frequencies)-1))  # limit by Nyquist frequency index\n    small_index = int(np.clip(small_index, 0, len(frequencies)-1))  # limit by Nyquist frequency index\n\n    # construct bandpass filter given the cutoff values with tukey window (only in positive frequencies)\n    # + 1 needed in order to include cutoff indices in the window\n    win = tukey(large_index - small_index + 1, alpha=tukey_alpha)\n    window = np.zeros_like(frequencies)\n    window[small_index:large_index+1] = win\n    return window",
  "def tukey_bandpass_filtering_with_settings(data: np.ndarray, global_settings: Settings, component_settings: Settings,\n                                           device: DetectionGeometryBase) -> np.ndarray:\n    \"\"\"\n    Apply a tukey bandpass filter with cutoff values at `cutoff_lowpass_in_Hz` and `cutoff_highpass_in_Hz` Hz\n    and a tukey window with alpha value of `tukey_alpha` inbetween on the `data` in Fourier space.\n    Those values are obtained from the `global_settings`, `component_settings`, and `device`.\n    Note that the filter operates on both, negative and positive frequencies similarly.\n\n    :param data: (numpy array) data to be filtered\n    :param global_settings: (Settings) settings for the whole simulation\n    :param component_settings: (Settings) settings for the reconstruction module\n    :param device:\n    :return: (numpy array) filtered data\n    \"\"\"\n    if Tags.K_WAVE_SPECIFIC_DT in global_settings and global_settings[Tags.K_WAVE_SPECIFIC_DT]:\n        time_spacing_in_ms = global_settings[Tags.K_WAVE_SPECIFIC_DT] * 1000\n    elif device.sampling_frequency_MHz is not None:\n        time_spacing_in_ms = 1.0 / (device.sampling_frequency_MHz * 1000)\n    else:\n        raise AttributeError(\"Please specify a value for SENSOR_SAMPLING_RATE_MHZ or K_WAVE_SPECIFIC_DT\")\n    cutoff_lowpass_in_Hz = component_settings[Tags.BANDPASS_CUTOFF_LOWPASS_IN_HZ] \\\n        if Tags.BANDPASS_CUTOFF_LOWPASS_IN_HZ in component_settings else int(8e6)\n    cutoff_highpass_in_Hz = component_settings[Tags.BANDPASS_CUTOFF_HIGHPASS_IN_HZ] \\\n        if Tags.BANDPASS_CUTOFF_HIGHPASS_IN_HZ in component_settings else int(0.1e6)\n    tukey_alpha = component_settings[\n        Tags.TUKEY_WINDOW_ALPHA] if Tags.TUKEY_WINDOW_ALPHA in component_settings else 0.5\n    resampling_for_fft = component_settings[Tags.RECONSTRUCTION_PERFORM_RESAMPLING_FOR_FFT] \\\n        if Tags.RECONSTRUCTION_PERFORM_RESAMPLING_FOR_FFT in component_settings else False\n\n    if data is None or time_spacing_in_ms is None:\n        raise AttributeError(\"data and time spacing must be specified\")\n\n    return tukey_bandpass_filtering(data, time_spacing_in_ms, cutoff_lowpass_in_Hz, cutoff_highpass_in_Hz, tukey_alpha, resampling_for_fft)",
  "def apply_b_mode(data: np.ndarray = None, method: str = None) -> np.ndarray:\n    \"\"\"\n    Applies B-Mode specified method to data. Method is either\n    envelope detection using hilbert transform (Tags.RECONSTRUCTION_BMODE_METHOD_HILBERT_TRANSFORM),\n    absolute value (Tags.RECONSTRUCTION_BMODE_METHOD_ABS) or\n    none if nothing is specified is performed.\n\n    :param data: (numpy array) data used for applying B-Mode method\n    :param method: (str) Tags.RECONSTRUCTION_BMODE_METHOD_HILBERT_TRANSFORM or Tags.RECONSTRUCTION_BMODE_METHOD_ABS\n    :return: (numpy array) data with B-Mode method applied, all\n    \"\"\"\n    # input checks\n    if data is None:\n        raise AttributeError(\"data must be specified\")\n\n    if data.ndim < 2:\n        raise AttributeError(\"data must have at least two dimensions\")\n\n    if method == Tags.RECONSTRUCTION_BMODE_METHOD_HILBERT_TRANSFORM:\n        # perform envelope detection using hilbert transform in depth direction\n        hilbert_transformed = hilbert(data, axis=1)\n        output = np.abs(hilbert_transformed)\n    elif method == Tags.RECONSTRUCTION_BMODE_METHOD_ABS:\n        # perform envelope detection using absolute value\n        output = np.abs(data)\n    else:\n        print(\"You have not specified a B-mode method\")\n        output = data\n\n    # sanity check that no elements are below zero\n    if output[output < 0].sum() != 0:\n        print(\"There are still negative values in the data.\")\n\n    return output",
  "def reconstruction_mode_transformation(time_series_sensor_data: torch.tensor = None,\n                                       mode: str = Tags.RECONSTRUCTION_MODE_PRESSURE) -> torch.tensor:\n    \"\"\"\n    Transformes `time_series_sensor_data` for other modes, for example `Tags.RECONSTRUCTION_MODE_DIFFERENTIAL`.\n    Default mode is `Tags.RECONSTRUCTION_MODE_PRESSURE`.\n\n    :param time_series_sensor_data: (torch tensor) Time series data to be transformed\n    :param mode: (str) reconstruction mode: Tags.RECONSTRUCTION_MODE_PRESSURE (default)\n                or Tags.RECONSTRUCTION_MODE_DIFFERENTIAL\n    :return: (torch tensor) potentially transformed tensor\n    \"\"\"\n\n    # depending on mode use pressure data or its derivative\n    if mode == Tags.RECONSTRUCTION_MODE_DIFFERENTIAL:\n        zeros = torch.zeros([time_series_sensor_data.shape[0], 1], names=None).to(time_series_sensor_data.device)\n        time_vector = torch.arange(1, time_series_sensor_data.shape[1]+1).to(time_series_sensor_data.device)\n        time_derivative_pressure = time_series_sensor_data[:, 1:] - time_series_sensor_data[:, 0:-1]\n        time_derivative_pressure = torch.cat([time_derivative_pressure, zeros], dim=1)\n        time_derivative_pressure = torch.mul(time_derivative_pressure, time_vector)\n        output = time_derivative_pressure  # use time derivative pressure\n    elif mode == Tags.RECONSTRUCTION_MODE_PRESSURE:\n        output = time_series_sensor_data  # already in pressure format\n    else:\n        raise AttributeError(\n            \"An invalid reconstruction mode was set, only differential and pressure are supported.\")\n    return output",
  "def preparing_reconstruction_and_obtaining_reconstruction_settings(\n        time_series_sensor_data: np.ndarray, component_settings: Settings, global_settings: Settings,\n        detection_geometry: DetectionGeometryBase, logger: Logger) -> Tuple[torch.tensor, torch.tensor,\n                                                                            float, float, float,\n                                                                            torch.device]:\n    \"\"\"\n    Performs all preparation steps that need to be done before reconstructing an image:\n    - performs envelope detection of time series data if specified\n    - obtains speed of sound value from settings\n    - obtains time spacing value from settings or PA device\n    - obtain spacing from settings\n    - checks PA device prerequisites\n    - obtains sensor positions from PA device\n    - moves data arrays on correct torch device\n    - computed differential mode if specified\n    - perform bandpass filtering if specified\n\n    Returns:\n\n    time_series_sensor_data: (torch tensor) potentially preprocessed time series data\n    sensor_positions: (torch tensor) sensor element positions of PA device\n    speed_of_sound_in_m_per_s: (float) speed of sound in m/s\n    spacing_in_mm: (float) spacing of voxels in reconstructed image in mm\n    time_spacing_in_ms: (float) temporal spacing of the time series data in ms\n    torch_device: (torch device) either cpu or cuda GPU device used for the tensors\n    \"\"\"\n\n    ### INPUT CHECKING AND VALIDATION ###\n    # check settings dictionary for elements and read them in\n\n    # speed of sound: use given speed of sound, otherwise use average from simulation if specified\n    if Tags.DATA_FIELD_SPEED_OF_SOUND in component_settings and component_settings[Tags.DATA_FIELD_SPEED_OF_SOUND]:\n        speed_of_sound_in_m_per_s = component_settings[Tags.DATA_FIELD_SPEED_OF_SOUND]\n    elif Tags.WAVELENGTH in global_settings and global_settings[Tags.WAVELENGTH]:\n        sound_speed_m = load_data_field(global_settings[Tags.SIMPA_OUTPUT_PATH], Tags.DATA_FIELD_SPEED_OF_SOUND)\n        speed_of_sound_in_m_per_s = np.mean(sound_speed_m)\n    else:\n        raise AttributeError(\"Please specify a value for DATA_FIELD_SPEED_OF_SOUND \"\n                             \"or WAVELENGTH to obtain the average speed of sound\")\n\n    # time spacing: use kWave specific dt from simulation if set, otherwise sampling rate if specified,\n    if Tags.K_WAVE_SPECIFIC_DT in global_settings and global_settings[Tags.K_WAVE_SPECIFIC_DT]:\n        time_spacing_in_ms = global_settings[Tags.K_WAVE_SPECIFIC_DT] * 1000\n    elif detection_geometry.sampling_frequency_MHz is not None:\n        time_spacing_in_ms = 1.0 / (detection_geometry.sampling_frequency_MHz * 1000)\n    else:\n        raise AttributeError(\"Please specify a value for SENSOR_SAMPLING_RATE_MHZ or K_WAVE_SPECIFIC_DT\")\n\n    logger.debug(f\"Using a time_spacing of {time_spacing_in_ms}\")\n\n    # spacing\n    if Tags.SPACING_MM in component_settings and component_settings[Tags.SPACING_MM]:\n        spacing_in_mm = component_settings[Tags.SPACING_MM]\n        logger.debug(f\"Reconstructing with spacing from component_settings: {spacing_in_mm}\")\n    elif Tags.SPACING_MM in global_settings and global_settings[Tags.SPACING_MM]:\n        spacing_in_mm = global_settings[Tags.SPACING_MM]\n        logger.debug(f\"Reconstructing with spacing from global_settings: {spacing_in_mm}\")\n    else:\n        raise AttributeError(\"Please specify a value for SPACING_MM in either the component_settings or\"\n                             \"the global_settings.\")\n\n    # get device specific sensor positions\n    sensor_positions = detection_geometry.get_detector_element_positions_base_mm()\n\n    # time series sensor data must be numpy array\n    if isinstance(sensor_positions, np.ndarray):\n        sensor_positions = torch.from_numpy(sensor_positions)\n    if isinstance(time_series_sensor_data, np.ndarray):\n        time_series_sensor_data = torch.from_numpy(time_series_sensor_data)\n    assert isinstance(time_series_sensor_data, torch.Tensor), \\\n        'The time series sensor data must have been converted to a tensor'\n\n    # move tensors to GPU if available, otherwise use CPU\n    torch_device = get_processing_device(global_settings)\n\n    if torch_device == torch.device('cpu'):  # warn the user that CPU reconstruction is slow\n        logger.warning(f\"Reconstructing on CPU is slow. Check if cuda is available 'torch.cuda.is_available()'.\")\n\n    sensor_positions = sensor_positions.to(torch_device)\n    time_series_sensor_data = time_series_sensor_data.to(torch_device)\n\n    # array must be of correct dimension\n    assert time_series_sensor_data.ndim == 2, 'Time series data must have exactly 2 dimensions' \\\n                                              ', one for the sensor elements and one for time. ' \\\n                                              'Stack images and sensor positions for 3D reconstruction' \\\n                                              'Apply beamforming per wavelength if you have a 3D array. '\n\n    # check reconstruction mode - pressure by default\n    if Tags.RECONSTRUCTION_MODE in component_settings:\n        mode = component_settings[Tags.RECONSTRUCTION_MODE]\n    else:\n        mode = Tags.RECONSTRUCTION_MODE_PRESSURE\n    time_series_sensor_data = reconstruction_mode_transformation(time_series_sensor_data, mode=mode)\n\n    return (time_series_sensor_data, sensor_positions, speed_of_sound_in_m_per_s, spacing_in_mm,\n            time_spacing_in_ms, torch_device)",
  "def compute_image_dimensions(detection_geometry: DetectionGeometryBase, spacing_in_mm: float,\n                             logger: Logger) -> Tuple[int, int, int, np.float64, np.float64,\n                                                      np.float64, np.float64, np.float64, np.float64]:\n    \"\"\"\n    Computes size of beamformed image from field of view of detection geometry given the spacing.\n\n    :param detection_geometry: detection geometry with specified field of view\n    :type detection_geometry: DetectionGeometryBase\n    :param spacing_in_mm: space betwenn pixels in mm\n    :type spacing_in_mm: float\n    :param logger: logger for debugging purposes\n    :type logger: Logger\n    :returns: tuple with x,z,y dimensions of reconstructed image volume in pixels as well as the range for\n    each dimension as start and end pixels (xdim, zdim, ydim, xdim_start, xdim_end, ydim_start, ydim_end, \n    zdim_start, zdim_end)\n    :rtype: Tuple[int, int, int, np.float64, np.float64, np.float64, np.float64, np.float64, np.float64]\n    \"\"\"\n\n    field_of_view = detection_geometry.field_of_view_extent_mm\n    logger.debug(f\"Field of view: {field_of_view}\")\n\n    def compute_for_one_dimension(start_in_mm: float, end_in_mm: float) -> Tuple[int, np.float64, np.float64]:\n        \"\"\"\n        Helper function to compute the image dimensions for a single dimension given a start and end point in mm.\n        Makes sure that image dimesion is an integer by flooring. \n        Spaces the pixels symmetrically between start and end.\n\n        :param start_in_mm: lower limit of the field of view in this dimension\n        :type start_in_mm: float\n        :param start_in_mm: upper limit of the field of view in this dimension\n        :type start_in_mm: float\n        :returns: tuple with number of pixels in dimension, lower and upper limit in pixels\n        :rtype: Tuple[int, np.float64, np.float64]\n        \"\"\"\n\n        start_temp = start_in_mm / spacing_in_mm\n        end_temp = end_in_mm / spacing_in_mm\n        dim_temp = np.abs(end_temp - start_temp)\n        dim = int(np.floor(dim_temp))\n        diff = np.abs(dim_temp - dim)\n        start = start_temp - np.sign(start_temp) * diff/2\n        end = end_temp - np.sign(end_temp) * diff/2\n        return dim, start, end\n\n    xdim, xdim_start, xdim_end = compute_for_one_dimension(field_of_view[0], field_of_view[1])\n    zdim, zdim_start, zdim_end = compute_for_one_dimension(field_of_view[2], field_of_view[3])\n    ydim, ydim_start, ydim_end = compute_for_one_dimension(field_of_view[4], field_of_view[5])\n\n    if xdim < 1:\n        xdim = 1\n    if ydim < 1:\n        ydim = 1\n    if zdim < 1:\n        zdim = 1\n\n    logger.debug(f\"FOV X: {xdim_start * spacing_in_mm} - {xdim_end * spacing_in_mm}\")\n    logger.debug(f\"FOV Y: {ydim_start * spacing_in_mm} - {ydim_end * spacing_in_mm}\")\n    logger.debug(f\"FOV Z: {zdim_start * spacing_in_mm} - {zdim_end * spacing_in_mm}\")\n\n    return xdim, zdim, ydim, xdim_start, xdim_end, ydim_start, ydim_end, zdim_start, zdim_end",
  "def compute_delay_and_sum_values(time_series_sensor_data: Tensor, sensor_positions: torch.tensor, xdim: int,\n                                 ydim: int, zdim: int, xdim_start: int, xdim_end: int, ydim_start: int, ydim_end: int,\n                                 zdim_start: int, zdim_end: int, spacing_in_mm: float, speed_of_sound_in_m_per_s: float,\n                                 time_spacing_in_ms: float, logger: Logger, torch_device: torch.device,\n                                 component_settings: Settings) -> Tuple[torch.tensor, int]:\n    \"\"\"\n    Perform the core computation of Delay and Sum, without summing up the delay dependend values.\n\n    Returns\n    - values (torch tensor) of the time series data corrected for delay and sensor positioning, ready to be summed up\n    - and n_sensor_elements (int) which might be used for later computations\n    \"\"\"\n\n    if time_series_sensor_data.shape[0] < sensor_positions.shape[0]:\n        logger.warning(\"Warning: The time series data has less sensor element entries than the given sensor positions. \"\n                       \"This might be due to a low simulated resolution, please increase it.\")\n\n    n_sensor_elements = time_series_sensor_data.shape[0]\n\n    logger.debug(f'Number of pixels in X dimension: {xdim}, Y dimension: {ydim}, Z dimension: {zdim} '\n                 f',number of sensor elements: {n_sensor_elements}')\n\n    x_offset = 0.5 if xdim % 2 == 0 else 0  # to ensure pixels are symmetrically arranged around the 0 like the\n    # sensor positions, add an offset of 0.5 pixels if the dimension is even\n\n    x = xdim_start + torch.arange(xdim, device=torch_device, dtype=torch.float32) + x_offset\n    y = ydim_start + torch.arange(ydim, device=torch_device, dtype=torch.float32)\n    if zdim == 1:\n        z = torch.arange(zdim, device=torch_device, dtype=torch.float32)\n    else:\n        z = zdim_start + torch.arange(zdim, device=torch_device, dtype=torch.float32)\n    j = torch.arange(n_sensor_elements, device=torch_device, dtype=torch.float32)\n\n    xx, yy, zz, jj = torch.meshgrid(x, y, z, j)\n    jj = jj.long()\n\n    delays = torch.sqrt((yy * spacing_in_mm - sensor_positions[:, 2][jj]) ** 2 +\n                        (xx * spacing_in_mm - sensor_positions[:, 0][jj]) ** 2 +\n                        (zz * spacing_in_mm - sensor_positions[:, 1][jj]) ** 2) \\\n        / (speed_of_sound_in_m_per_s * time_spacing_in_ms)\n\n    # perform index validation\n    invalid_indices = torch.where(torch.logical_or(delays < 0, delays >= float(time_series_sensor_data.shape[1])))\n    torch.clip_(delays, min=0, max=time_series_sensor_data.shape[1] - 1)\n\n    # interpolation of delays\n    lower_delays = (torch.floor(delays)).long()\n    upper_delays = lower_delays + 1\n    torch.clip_(upper_delays, min=0, max=time_series_sensor_data.shape[1] - 1)\n    lower_values = time_series_sensor_data[jj, lower_delays]\n    upper_values = time_series_sensor_data[jj, upper_delays]\n    values = lower_values * (upper_delays - delays) + upper_values * (delays - lower_delays)\n\n    # perform apodization if specified\n    if Tags.RECONSTRUCTION_APODIZATION_METHOD in component_settings:\n        apodization = get_apodization_factor(apodization_method=component_settings[Tags.RECONSTRUCTION_APODIZATION_METHOD],\n                                             dimensions=(xdim, ydim, zdim), n_sensor_elements=n_sensor_elements,\n                                             device=torch_device)\n        values = values * apodization\n\n    # set values of invalid indices to 0 so that they don't influence the result\n    values[invalid_indices] = 0\n\n    del delays  # free memory of delays\n\n    return values, n_sensor_elements",
  "def compute_for_one_dimension(start_in_mm: float, end_in_mm: float) -> Tuple[int, np.float64, np.float64]:\n        \"\"\"\n        Helper function to compute the image dimensions for a single dimension given a start and end point in mm.\n        Makes sure that image dimesion is an integer by flooring. \n        Spaces the pixels symmetrically between start and end.\n\n        :param start_in_mm: lower limit of the field of view in this dimension\n        :type start_in_mm: float\n        :param start_in_mm: upper limit of the field of view in this dimension\n        :type start_in_mm: float\n        :returns: tuple with number of pixels in dimension, lower and upper limit in pixels\n        :rtype: Tuple[int, np.float64, np.float64]\n        \"\"\"\n\n        start_temp = start_in_mm / spacing_in_mm\n        end_temp = end_in_mm / spacing_in_mm\n        dim_temp = np.abs(end_temp - start_temp)\n        dim = int(np.floor(dim_temp))\n        diff = np.abs(dim_temp - dim)\n        start = start_temp - np.sign(start_temp) * diff/2\n        end = end_temp - np.sign(end_temp) * diff/2\n        return dim, start, end",
  "class SignedDelayMultiplyAndSumAdapter(ReconstructionAdapterBase):\n\n    def reconstruction_algorithm(self, time_series_sensor_data, detection_geometry: DetectionGeometryBase):\n        \"\"\"\n        Applies the signed Delay Multiply and Sum beamforming algorithm [1] to the time series sensor data\n        (2D numpy array where the\n        first dimension corresponds to the sensor elements and the second to the recorded time steps) with the given\n        beamforming settings (dictionary).\n        A reconstructed image (2D numpy array) is returned.\n        This implementation uses PyTorch Tensors to perform computations and is able to run on GPUs.\n\n        [1] T. Kirchner et al. 2018, \"Signed Real-Time Delay Multiply and Sum Beamforming for Multispectral\n        Photoacoustic Imaging\", https://doi.org/10.3390/jimaging4100121\n        \"\"\"\n\n        time_series_sensor_data, sensor_positions, speed_of_sound_in_m_per_s, spacing_in_mm, time_spacing_in_ms, torch_device = preparing_reconstruction_and_obtaining_reconstruction_settings(\n            time_series_sensor_data, self.component_settings, self.global_settings, detection_geometry, self.logger)\n\n        ### ALGORITHM ITSELF ###\n\n        xdim, zdim, ydim, xdim_start, xdim_end, ydim_start, ydim_end, zdim_start, zdim_end = compute_image_dimensions(\n            detection_geometry, spacing_in_mm, self.logger)\n\n        if zdim == 1:\n            sensor_positions[:, 1] = 0  # Assume imaging plane\n\n        # construct output image\n        output = torch.zeros((xdim, ydim, zdim), dtype=torch.float32, device=torch_device)\n\n        values, n_sensor_elements = compute_delay_and_sum_values(time_series_sensor_data, sensor_positions, xdim,\n                                                                 ydim, zdim, xdim_start, xdim_end, ydim_start, ydim_end,\n                                                                 zdim_start, zdim_end, spacing_in_mm, speed_of_sound_in_m_per_s,\n                                                                 time_spacing_in_ms, self.logger, torch_device,\n                                                                 self.component_settings)\n\n        DAS = torch.sum(values, dim=3)\n\n        for x in range(xdim):\n            yy, zz, nn, mm = torch.meshgrid(torch.arange(ydim, device=torch_device),\n                                            torch.arange(zdim, device=torch_device),\n                                            torch.arange(n_sensor_elements, device=torch_device),\n                                            torch.arange(n_sensor_elements, device=torch_device))\n            M = values[x, yy, zz, nn] * values[x, yy, zz, mm]\n            M = torch.sign(M) * torch.sqrt(torch.abs(M))\n            # only take upper triangle without diagonal and sum up along n and m axis (last two)\n            output[x] = torch.triu(M, diagonal=1).sum(dim=(-1, -2))\n        output = torch.sign(DAS) * output\n        reconstructed = output.cpu().numpy()\n\n        return reconstructed.squeeze()",
  "def reconstruct_signed_delay_multiply_and_sum_pytorch(time_series_sensor_data: np.ndarray,\n                                                      detection_geometry: DetectionGeometryBase,\n                                                      speed_of_sound_in_m_per_s: int = 1540,\n                                                      time_spacing_in_s: float = 2.5e-8,\n                                                      sensor_spacing_in_mm: float = 0.1,\n                                                      recon_mode: str = Tags.RECONSTRUCTION_MODE_PRESSURE,\n                                                      apodization: str = Tags.RECONSTRUCTION_APODIZATION_BOX\n                                                      ) -> np.ndarray:\n    \"\"\"\n    Convenience function for reconstructing time series data using Delay and Sum algorithm implemented in PyTorch\n\n    :param time_series_sensor_data: (2D numpy array) sensor data of shape (sensor elements, time steps)\n    :param speed_of_sound_in_m_per_s: (int) speed of sound in medium in meters per second (default: 1540 m/s)\n    :param time_spacing_in_s: (float) time between sampling points in seconds (default: 2.5e-8 s which is equal to 40 MHz)\n    :param sensor_spacing_in_mm: (float) space between sensor elements in millimeters (default: 0.1 mm)\n    :param recon_mode: SIMPA Tag defining the reconstruction mode - pressure default OR differential\n    :param apodization: SIMPA Tag defining the apodization function (default box)\n    :return: (2D numpy array) reconstructed image as 2D numpy array\n    \"\"\"\n    # create settings\n    settings = create_reconstruction_settings(speed_of_sound_in_m_per_s, time_spacing_in_s, sensor_spacing_in_mm,\n                                              recon_mode, apodization)\n    adapter = SignedDelayMultiplyAndSumAdapter(settings)\n    return adapter.reconstruction_algorithm(time_series_sensor_data, detection_geometry)",
  "def reconstruction_algorithm(self, time_series_sensor_data, detection_geometry: DetectionGeometryBase):\n        \"\"\"\n        Applies the signed Delay Multiply and Sum beamforming algorithm [1] to the time series sensor data\n        (2D numpy array where the\n        first dimension corresponds to the sensor elements and the second to the recorded time steps) with the given\n        beamforming settings (dictionary).\n        A reconstructed image (2D numpy array) is returned.\n        This implementation uses PyTorch Tensors to perform computations and is able to run on GPUs.\n\n        [1] T. Kirchner et al. 2018, \"Signed Real-Time Delay Multiply and Sum Beamforming for Multispectral\n        Photoacoustic Imaging\", https://doi.org/10.3390/jimaging4100121\n        \"\"\"\n\n        time_series_sensor_data, sensor_positions, speed_of_sound_in_m_per_s, spacing_in_mm, time_spacing_in_ms, torch_device = preparing_reconstruction_and_obtaining_reconstruction_settings(\n            time_series_sensor_data, self.component_settings, self.global_settings, detection_geometry, self.logger)\n\n        ### ALGORITHM ITSELF ###\n\n        xdim, zdim, ydim, xdim_start, xdim_end, ydim_start, ydim_end, zdim_start, zdim_end = compute_image_dimensions(\n            detection_geometry, spacing_in_mm, self.logger)\n\n        if zdim == 1:\n            sensor_positions[:, 1] = 0  # Assume imaging plane\n\n        # construct output image\n        output = torch.zeros((xdim, ydim, zdim), dtype=torch.float32, device=torch_device)\n\n        values, n_sensor_elements = compute_delay_and_sum_values(time_series_sensor_data, sensor_positions, xdim,\n                                                                 ydim, zdim, xdim_start, xdim_end, ydim_start, ydim_end,\n                                                                 zdim_start, zdim_end, spacing_in_mm, speed_of_sound_in_m_per_s,\n                                                                 time_spacing_in_ms, self.logger, torch_device,\n                                                                 self.component_settings)\n\n        DAS = torch.sum(values, dim=3)\n\n        for x in range(xdim):\n            yy, zz, nn, mm = torch.meshgrid(torch.arange(ydim, device=torch_device),\n                                            torch.arange(zdim, device=torch_device),\n                                            torch.arange(n_sensor_elements, device=torch_device),\n                                            torch.arange(n_sensor_elements, device=torch_device))\n            M = values[x, yy, zz, nn] * values[x, yy, zz, mm]\n            M = torch.sign(M) * torch.sqrt(torch.abs(M))\n            # only take upper triangle without diagonal and sum up along n and m axis (last two)\n            output[x] = torch.triu(M, diagonal=1).sum(dim=(-1, -2))\n        output = torch.sign(DAS) * output\n        reconstructed = output.cpu().numpy()\n\n        return reconstructed.squeeze()",
  "class ReconstructionAdapterBase(SimulationModule):\n    \"\"\"\n    This class is the main entry point to perform image reconstruction using the SIMPA toolkit.\n    All information necessary for the respective reconstruction method must be contained in the\n    respective settings dictionary.\n    \"\"\"\n\n    def __init__(self, global_settings: Settings):\n        super(ReconstructionAdapterBase, self).__init__(global_settings=global_settings)\n        self.component_settings = global_settings.get_reconstruction_settings()\n\n    @abstractmethod\n    def reconstruction_algorithm(self, time_series_sensor_data,\n                                 detection_geometry: DetectionGeometryBase) -> np.ndarray:\n        \"\"\"\n        A deriving class needs to implement this method according to its model.\n\n        :param time_series_sensor_data: the time series sensor data\n        :param detection_geometry:\n        :return: a reconstructed photoacoustic image\n        \"\"\"\n        pass\n\n    def run(self, device):\n        self.logger.info(\"Performing reconstruction...\")\n\n        time_series_sensor_data = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH],\n                                                  Tags.DATA_FIELD_TIME_SERIES_DATA, self.global_settings[Tags.WAVELENGTH])\n\n        _device = None\n        if isinstance(device, DetectionGeometryBase):\n            _device = device\n        elif isinstance(device, PhotoacousticDevice):\n            _device = device.get_detection_geometry()\n        else:\n            raise TypeError(f\"Type {type(device)} is not supported for performing image reconstruction.\")\n\n        if Tags.RECONSTRUCTION_PERFORM_BANDPASS_FILTERING in self.component_settings and \\\n                self.component_settings[Tags.RECONSTRUCTION_PERFORM_BANDPASS_FILTERING]:\n\n            time_series_sensor_data = bandpass_filter_with_settings(time_series_sensor_data,\n                                                                    self.global_settings,\n                                                                    self.component_settings,\n                                                                    _device)\n\n        # check for B-mode methods and perform envelope detection on time series data if specified\n        if Tags.RECONSTRUCTION_BMODE_BEFORE_RECONSTRUCTION in self.component_settings \\\n                and self.component_settings[Tags.RECONSTRUCTION_BMODE_BEFORE_RECONSTRUCTION] \\\n                and Tags.RECONSTRUCTION_BMODE_METHOD in self.component_settings:\n            time_series_sensor_data = apply_b_mode(\n                time_series_sensor_data, method=self.component_settings[Tags.RECONSTRUCTION_BMODE_METHOD])\n\n        reconstruction = self.reconstruction_algorithm(time_series_sensor_data, _device)\n\n        # check for B-mode methods and perform envelope detection on time series data if specified\n        if Tags.RECONSTRUCTION_BMODE_AFTER_RECONSTRUCTION in self.component_settings \\\n                and self.component_settings[Tags.RECONSTRUCTION_BMODE_AFTER_RECONSTRUCTION] \\\n                and Tags.RECONSTRUCTION_BMODE_METHOD in self.component_settings:\n            reconstruction = apply_b_mode(\n                reconstruction, method=self.component_settings[Tags.RECONSTRUCTION_BMODE_METHOD])\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(reconstruction, array_name=\"reconstruction\")\n\n        reconstruction_output_path = generate_dict_path(\n            Tags.DATA_FIELD_RECONSTRUCTED_DATA, self.global_settings[Tags.WAVELENGTH])\n\n        save_hdf5(reconstruction, self.global_settings[Tags.SIMPA_OUTPUT_PATH],\n                  reconstruction_output_path)\n\n        self.logger.info(\"Performing reconstruction...[Done]\")",
  "def create_reconstruction_settings(speed_of_sound_in_m_per_s: int = 1540, time_spacing_in_s: float = 2.5e-8,\n                                   sensor_spacing_in_mm: float = 0.1,\n                                   recon_mode: str = Tags.RECONSTRUCTION_MODE_PRESSURE,\n                                   apodization: str = Tags.RECONSTRUCTION_APODIZATION_BOX) -> Settings:\n    \"\"\"\n    Function that creates SIMPA settings for reconstruction convenience function.\n\n    :param speed_of_sound_in_m_per_s: (int) speed of sound in medium in meters per second (default: 1540 m/s)\n    :param time_spacing_in_s: (float) time between sampling points in seconds (default: 2.5e-8 s which is equal to 40 MHz)\n    :param sensor_spacing_in_mm: (float) space between sensor elements in millimeters (default: 0.1 mm)\n    :param recon_mode: SIMPA Tag defining the reconstruction mode - pressure default OR differential\n    :param apodization: SIMPA Tag defining the apodization function (default box)\n    :return: SIMPA settings\n    \"\"\"\n\n    settings = Settings()\n    settings.set_reconstruction_settings({\n        Tags.DATA_FIELD_SPEED_OF_SOUND: speed_of_sound_in_m_per_s,\n        Tags.SPACING_MM: sensor_spacing_in_mm,\n        Tags.RECONSTRUCTION_APODIZATION_METHOD: apodization,\n        Tags.RECONSTRUCTION_MODE: recon_mode,\n        Tags.SENSOR_SAMPLING_RATE_MHZ: (1.0 / time_spacing_in_s) / 1000000\n    })\n\n    return settings",
  "def __init__(self, global_settings: Settings):\n        super(ReconstructionAdapterBase, self).__init__(global_settings=global_settings)\n        self.component_settings = global_settings.get_reconstruction_settings()",
  "def reconstruction_algorithm(self, time_series_sensor_data,\n                                 detection_geometry: DetectionGeometryBase) -> np.ndarray:\n        \"\"\"\n        A deriving class needs to implement this method according to its model.\n\n        :param time_series_sensor_data: the time series sensor data\n        :param detection_geometry:\n        :return: a reconstructed photoacoustic image\n        \"\"\"\n        pass",
  "def run(self, device):\n        self.logger.info(\"Performing reconstruction...\")\n\n        time_series_sensor_data = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH],\n                                                  Tags.DATA_FIELD_TIME_SERIES_DATA, self.global_settings[Tags.WAVELENGTH])\n\n        _device = None\n        if isinstance(device, DetectionGeometryBase):\n            _device = device\n        elif isinstance(device, PhotoacousticDevice):\n            _device = device.get_detection_geometry()\n        else:\n            raise TypeError(f\"Type {type(device)} is not supported for performing image reconstruction.\")\n\n        if Tags.RECONSTRUCTION_PERFORM_BANDPASS_FILTERING in self.component_settings and \\\n                self.component_settings[Tags.RECONSTRUCTION_PERFORM_BANDPASS_FILTERING]:\n\n            time_series_sensor_data = bandpass_filter_with_settings(time_series_sensor_data,\n                                                                    self.global_settings,\n                                                                    self.component_settings,\n                                                                    _device)\n\n        # check for B-mode methods and perform envelope detection on time series data if specified\n        if Tags.RECONSTRUCTION_BMODE_BEFORE_RECONSTRUCTION in self.component_settings \\\n                and self.component_settings[Tags.RECONSTRUCTION_BMODE_BEFORE_RECONSTRUCTION] \\\n                and Tags.RECONSTRUCTION_BMODE_METHOD in self.component_settings:\n            time_series_sensor_data = apply_b_mode(\n                time_series_sensor_data, method=self.component_settings[Tags.RECONSTRUCTION_BMODE_METHOD])\n\n        reconstruction = self.reconstruction_algorithm(time_series_sensor_data, _device)\n\n        # check for B-mode methods and perform envelope detection on time series data if specified\n        if Tags.RECONSTRUCTION_BMODE_AFTER_RECONSTRUCTION in self.component_settings \\\n                and self.component_settings[Tags.RECONSTRUCTION_BMODE_AFTER_RECONSTRUCTION] \\\n                and Tags.RECONSTRUCTION_BMODE_METHOD in self.component_settings:\n            reconstruction = apply_b_mode(\n                reconstruction, method=self.component_settings[Tags.RECONSTRUCTION_BMODE_METHOD])\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(reconstruction, array_name=\"reconstruction\")\n\n        reconstruction_output_path = generate_dict_path(\n            Tags.DATA_FIELD_RECONSTRUCTED_DATA, self.global_settings[Tags.WAVELENGTH])\n\n        save_hdf5(reconstruction, self.global_settings[Tags.SIMPA_OUTPUT_PATH],\n                  reconstruction_output_path)\n\n        self.logger.info(\"Performing reconstruction...[Done]\")",
  "class ReconstructionModuleTestAdapter(ReconstructionAdapterBase):\n\n    def reconstruction_algorithm(self, time_series_sensor_data, detection_geometry):\n        return time_series_sensor_data / 10 + 5",
  "def reconstruction_algorithm(self, time_series_sensor_data, detection_geometry):\n        return time_series_sensor_data / 10 + 5",
  "class AcousticForwardModelTestAdapter(AcousticForwardModelBaseAdapter):\n\n    def forward_model(self, device) -> np.ndarray:\n\n        if Tags.ACOUSTIC_SIMULATION_3D in self.component_settings \\\n                and self.component_settings[Tags.ACOUSTIC_SIMULATION_3D]:\n            return np.random.random((128, 128, 3000))\n        else:\n            return np.random.random((128, 3000))",
  "def forward_model(self, device) -> np.ndarray:\n\n        if Tags.ACOUSTIC_SIMULATION_3D in self.component_settings \\\n                and self.component_settings[Tags.ACOUSTIC_SIMULATION_3D]:\n            return np.random.random((128, 128, 3000))\n        else:\n            return np.random.random((128, 3000))",
  "class KWaveAdapter(AcousticForwardModelBaseAdapter):\n    \"\"\"\n    The KwaveAcousticForwardModel adapter enables acoustic simulations to be run with the\n    k-wave MATLAB toolbox. k-Wave is a free toolbox (http://www.k-wave.org/) developed by Bradley Treeby\n    and Ben Cox (University College London) and Jiri Jaros (Brno University of Technology).\n\n    In order to use this toolbox, MATLAB needs to be installed on your system and the path to the\n    MATLAB binary needs to be specified in the settings dictionary.\n\n    In order to use the toolbox from with SIMPA, a number of parameters have to be specified in the\n    settings dictionary::\n\n        The initial pressure distribution:\n            Tags.OPTICAL_MODEL_INITIAL_PRESSURE\n        Acoustic tissue properties:\n            Tags.PROPERTY_SPEED_OF_SOUND\n            Tags.PROPERTY_DENSITY\n            Tags.PROPERTY_ALPHA_COEFF\n        The digital twin of the imaging device:\n            Tags.DIGITAL_DEVICE\n        Other parameters:\n            Tags.PERFORM_UPSAMPLING\n            Tags.SPACING_MM\n            Tags.UPSCALE_FACTOR\n            Tags.PROPERTY_ALPHA_POWER\n            Tags.GPU\n            Tags.PMLInside\n            Tags.PMLAlpha\n            Tags.PlotPML\n            Tags.RECORDMOVIE\n            Tags.MOVIENAME\n            Tags.ACOUSTIC_LOG_SCALE\n            Tags.SENSOR_DIRECTIVITY_PATTERN\n\n    Many of these will be set automatically by SIMPA, but you may use the\n    simpa.utils.settings_generator convenience methods to generate settings files that contain\n    sensible defaults for these parameters.\n\n    Please also refer to the simpa_examples scripts to see how the settings file can be\n    parametrized successfully.\n\n    \"\"\"\n\n    def forward_model(self, detection_geometry: DetectionGeometryBase) -> np.ndarray:\n        \"\"\"\n        Runs the acoustic forward model and performs reading parameters and values from an hdf5 file\n        before calling the actual algorithm and saves the updated settings afterwards.\n\n        :param detection_geometry:\n        :return: simulated time series data (numpy array)\n\n        \"\"\"\n\n        optical_path = generate_dict_path(Tags.OPTICAL_MODEL_OUTPUT_NAME,\n                                          wavelength=self.global_settings[Tags.WAVELENGTH])\n\n        self.logger.debug(f\"OPTICAL_PATH: {str(optical_path)}\")\n\n        data_dict = {}\n        file_path = self.global_settings[Tags.SIMPA_OUTPUT_PATH]\n        data_dict[Tags.DATA_FIELD_INITIAL_PRESSURE] = load_data_field(file_path, Tags.DATA_FIELD_INITIAL_PRESSURE)\n        data_dict[Tags.DATA_FIELD_SPEED_OF_SOUND] = load_data_field(file_path, Tags.DATA_FIELD_SPEED_OF_SOUND)\n        data_dict[Tags.DATA_FIELD_DENSITY] = load_data_field(file_path, Tags.DATA_FIELD_DENSITY)\n        data_dict[Tags.DATA_FIELD_ALPHA_COEFF] = load_data_field(file_path, Tags.DATA_FIELD_ALPHA_COEFF)\n\n        pa_device = detection_geometry\n        pa_device.check_settings_prerequisites(self.global_settings)\n        field_of_view_extent = pa_device.field_of_view_extent_mm\n        detector_positions_mm = pa_device.get_detector_element_positions_accounting_for_device_position_mm()\n        self.logger.debug(f\"field_of_view_extent: {field_of_view_extent}\")\n\n        detectors_are_aligned_along_x_axis = field_of_view_extent[2] == 0 and field_of_view_extent[3] == 0\n        detectors_are_aligned_along_y_axis = field_of_view_extent[0] == 0 and field_of_view_extent[1] == 0\n        if detectors_are_aligned_along_x_axis or detectors_are_aligned_along_y_axis:\n            axes = (0, 1)\n            if detectors_are_aligned_along_y_axis:\n                transducer_plane = int(round((detector_positions_mm[0, 0] / self.global_settings[Tags.SPACING_MM]))) - 1\n                image_slice = np.s_[transducer_plane, :, :]\n            else:\n                transducer_plane = int(round((detector_positions_mm[0, 1] / self.global_settings[Tags.SPACING_MM]))) - 1\n                image_slice = np.s_[:, transducer_plane, :]\n        else:\n            axes = (0, 2)\n            image_slice = np.s_[:]\n\n        wavelength = str(self.global_settings[Tags.WAVELENGTH])\n        data_dict[Tags.DATA_FIELD_SPEED_OF_SOUND] = np.rot90(data_dict[Tags.DATA_FIELD_SPEED_OF_SOUND][image_slice],\n                                                             3, axes=axes)\n        data_dict[Tags.DATA_FIELD_DENSITY] = np.rot90(data_dict[Tags.DATA_FIELD_DENSITY][image_slice],\n                                                      3, axes=axes)\n        data_dict[Tags.DATA_FIELD_ALPHA_COEFF] = np.rot90(data_dict[Tags.DATA_FIELD_ALPHA_COEFF][image_slice],\n                                                          3, axes=axes)\n        data_dict[Tags.DATA_FIELD_INITIAL_PRESSURE] = np.rot90(data_dict[Tags.DATA_FIELD_INITIAL_PRESSURE]\n                                                               [wavelength][image_slice], 3, axes=axes)\n\n        time_series_data, global_settings = self.k_wave_acoustic_forward_model(\n            detection_geometry,\n            data_dict[Tags.DATA_FIELD_SPEED_OF_SOUND],\n            data_dict[Tags.DATA_FIELD_DENSITY],\n            data_dict[Tags.DATA_FIELD_ALPHA_COEFF],\n            data_dict[Tags.DATA_FIELD_INITIAL_PRESSURE],\n            optical_path=self.global_settings[Tags.SIMPA_OUTPUT_PATH])\n        save_hdf5(global_settings, global_settings[Tags.SIMPA_OUTPUT_PATH], \"/settings/\")\n\n        return time_series_data\n\n    def k_wave_acoustic_forward_model(self, detection_geometry: DetectionGeometryBase,\n                                      speed_of_sound: float, density: float,\n                                      alpha_coeff: float, initial_pressure: np.ndarray,\n                                      optical_path: str = \"temporary\") -> tuple:\n        \"\"\"\n        Runs the acoustic forward model with the given parameters speed_of_sound (float), density (float),\n        alpha_coeff (float) for the initial_pressure distribution (numpy array) and a given detection geometry.\n        Uses the given optical_path (str) or if none is given a temporary one for saving temporary files.\n        Note, that in order to work properly, this function assumes that several settings mentioned above are set.\n        This can either be done by reading it from a settings file (e.g. when being called from forward_model) or\n        by parsing all settings individually as in the convenience function\n        (perform_k_wave_acoustic_forward_simulation).\n\n        :param detection_geometry:\n        :param speed_of_sound:\n        :param density:\n        :param alpha_coeff:\n        :param initial_pressure:\n        :param optical_path:\n        :return: time_series_data (numpy array): simulated time series data, global_settings (Settings): updated global\n            settings with new entries from the simulation\n\n        \"\"\"\n        data_dict = {}\n\n        pa_device = detection_geometry\n        field_of_view = pa_device.get_field_of_view_mm()\n        detector_positions_mm = pa_device.get_detector_element_positions_accounting_for_device_position_mm()\n\n        if not self.component_settings.get(Tags.ACOUSTIC_SIMULATION_3D):\n            detectors_are_aligned_along_x_axis = np.abs(field_of_view[2] - field_of_view[3]) < 1e-5\n            detectors_are_aligned_along_y_axis = np.abs(field_of_view[0] - field_of_view[1]) < 1e-5\n            if detectors_are_aligned_along_x_axis or detectors_are_aligned_along_y_axis:\n                simulate_2d = True\n            else:\n                simulate_2d = False\n        else:\n            simulate_2d = False\n\n        data_dict[Tags.DATA_FIELD_SPEED_OF_SOUND] = np.ones_like(initial_pressure) * speed_of_sound\n        data_dict[Tags.DATA_FIELD_DENSITY] = np.ones_like(initial_pressure) * density\n        data_dict[Tags.DATA_FIELD_ALPHA_COEFF] = np.ones_like(initial_pressure) * alpha_coeff\n        data_dict[Tags.DATA_FIELD_INITIAL_PRESSURE] = initial_pressure\n\n        if simulate_2d:\n            detector_positions_mm_2d = np.delete(detector_positions_mm, 1, axis=1)\n            detector_positions_mm_2d = np.moveaxis(detector_positions_mm_2d, 1, 0)\n            data_dict[Tags.SENSOR_ELEMENT_POSITIONS] = detector_positions_mm_2d[[1, 0]]\n            orientations = pa_device.get_detector_element_orientations()\n            angles = np.arccos(np.dot(orientations, np.array([1, 0, 0])))\n            data_dict[Tags.KWAVE_PROPERTY_DIRECTIVITY_ANGLE] = angles[::-1]\n        else:\n            detector_positions_mm = np.moveaxis(detector_positions_mm, 1, 0)\n            data_dict[Tags.SENSOR_ELEMENT_POSITIONS] = detector_positions_mm[[2, 1, 0]]\n            orientations = pa_device.get_detector_element_orientations()\n            x_angles = np.arccos(np.dot(orientations, np.array([1, 0, 0]))) * 360 / (2*np.pi)\n            y_angles = np.arccos(np.dot(orientations, np.array([0, 1, 0]))) * 360 / (2*np.pi)\n            z_angles = np.arccos(np.dot(orientations, np.array([0, 0, 1]))) * 360 / (2*np.pi)\n            intrinsic_euler_angles = list()\n            for orientation_vector in orientations:\n\n                mat = rotation_matrix_between_vectors(orientation_vector, np.array([0, 0, 1]))\n                rot = Rotation.from_matrix(mat)\n                euler_angles = rot.as_euler(\"XYZ\", degrees=True)\n                intrinsic_euler_angles.append(euler_angles)\n            intrinsic_euler_angles.reverse()\n            angles = np.array([z_angles[::-1], y_angles[::-1], x_angles[::-1]])\n            data_dict[Tags.KWAVE_PROPERTY_DIRECTIVITY_ANGLE] = angles\n            data_dict[Tags.KWAVE_PROPERTY_INTRINSIC_EULER_ANGLE] = intrinsic_euler_angles\n\n        optical_path = optical_path + \".mat\"\n        optical_path = os.path.abspath(optical_path)\n\n        possible_k_wave_parameters = [Tags.SPACING_MM, Tags.MODEL_SENSOR_FREQUENCY_RESPONSE,\n                                      Tags.KWAVE_PROPERTY_ALPHA_POWER, Tags.GPU, Tags.KWAVE_PROPERTY_PMLInside, Tags.KWAVE_PROPERTY_PMLAlpha, Tags.KWAVE_PROPERTY_PlotPML,\n                                      Tags.RECORDMOVIE, Tags.MOVIENAME, Tags.ACOUSTIC_LOG_SCALE,\n                                      Tags.SENSOR_DIRECTIVITY_PATTERN, Tags.KWAVE_PROPERTY_INITIAL_PRESSURE_SMOOTHING]\n\n        k_wave_settings = Settings({\n            Tags.SENSOR_NUM_ELEMENTS: pa_device.number_detector_elements,\n            Tags.DETECTOR_ELEMENT_WIDTH_MM: pa_device.detector_element_width_mm,\n            Tags.SENSOR_CENTER_FREQUENCY_HZ: pa_device.center_frequency_Hz,\n            Tags.SENSOR_BANDWIDTH_PERCENT: pa_device.bandwidth_percent,\n            Tags.SENSOR_SAMPLING_RATE_MHZ: pa_device.sampling_frequency_MHz\n        })\n        if isinstance(pa_device, CurvedArrayDetectionGeometry):\n            k_wave_settings[Tags.SENSOR_RADIUS_MM] = pa_device.radius_mm\n\n        for parameter in possible_k_wave_parameters:\n            if parameter in self.component_settings:\n                k_wave_settings[parameter] = self.component_settings[parameter]\n                self.logger.debug(f\"Added parameter {parameter} to kWave settings via component_settings\")\n            elif parameter in self.global_settings:\n                k_wave_settings[parameter] = self.global_settings[parameter]\n                self.logger.debug(f\"Added parameter {parameter} to kWave settings via global_settings\")\n            else:\n                self.logger.warning(f\"Did not find parameter {parameter} in any settings.\")\n\n        data_dict[\"settings\"] = k_wave_settings\n        sio.savemat(optical_path, data_dict, long_field_names=True)\n\n        del data_dict, k_wave_settings, detector_positions_mm, pa_device\n        gc.collect()\n\n        if not simulate_2d:\n            self.logger.info(\"Simulating 3D....\")\n            simulation_script_path = \"simulate_3D\"\n        else:\n            self.logger.info(\"Simulating 2D....\")\n            simulation_script_path = \"simulate_2D\"\n\n        base_script_path = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n\n        cmd = list()\n        cmd.append(self.component_settings[Tags.ACOUSTIC_MODEL_BINARY_PATH])\n        cmd.append(\"-nodisplay\")\n        cmd.append(\"-nosplash\")\n        cmd.append(\"-automation\")\n        cmd.append(\"-wait\")\n        cmd.append(\"-r\")\n        cmd.append(\"addpath('\" + base_script_path + \"');\" +\n                   simulation_script_path + \"('\" + optical_path + \"');exit;\")\n        cur_dir = os.getcwd()\n        self.logger.info(cmd)\n        subprocess.run(cmd)\n\n        raw_time_series_data = sio.loadmat(optical_path)[Tags.DATA_FIELD_TIME_SERIES_DATA]\n\n        # reverse the order of detector elements from matlab to python order\n        raw_time_series_data = raw_time_series_data[::-1, :]\n\n        time_grid = sio.loadmat(optical_path + \"dt.mat\")\n        num_time_steps = int(np.round(time_grid[\"number_time_steps\"]))\n\n        self.global_settings[Tags.K_WAVE_SPECIFIC_DT] = float(time_grid[\"time_step\"])\n        self.global_settings[Tags.K_WAVE_SPECIFIC_NT] = num_time_steps\n\n        os.remove(optical_path)\n        os.remove(optical_path + \"dt.mat\")\n        os.chdir(cur_dir)\n\n        return raw_time_series_data, self.global_settings",
  "def perform_k_wave_acoustic_forward_simulation(initial_pressure: np.array,\n                                               detection_geometry: DetectionGeometryBase,\n                                               speed_of_sound: float = 1540.0,\n                                               density: float = 1000.0,\n                                               alpha_coeff: float = 0.02,\n                                               acoustic_settings: Settings = None,\n                                               alpha_power: float = 0.0,\n                                               sensor_record: str = \"p\",\n                                               pml_inside: bool = False,\n                                               pml_alpha: float = 1.5,\n                                               plot_pml: bool = False,\n                                               record_movie: bool = False,\n                                               movie_name: str = \"visualization_log\",\n                                               acoustic_log_scale: bool = True,\n                                               gpu: bool = True,\n                                               spacing_mm: float = 0.5) -> np.array:\n    \"\"\"\n    Convenience function for performing a k-Wave acoustic forward simulation using a given detection geometry and\n    initial pressure distribution (numpy array) with the following parameters speed_of_sound (float), density (float),\n    alpha_coeff (float) as well as acoustic_settings (Settings). The acoustic settings may be parsed individually,\n    however, they will be overwritten if they are also set in the acoustic_settings.\n\n    :param initial_pressure:\n    :param detection_geometry:\n    :param speed_of_sound:\n    :param density:\n    :param alpha_coeff:\n    :param acoustic_settings:\n    :param alpha_power:\n    :param sensor_record:\n    :param pml_inside:\n    :param pml_alpha:\n    :param plot_pml:\n    :param record_movie:\n    :param movie_name:\n    :param acoustic_log_scale:\n    :param gpu:\n    :param spacing_mm:\n    :return: simulated time series data (numpy array)\n    \"\"\"\n\n    # check and set acoustic settings\n    if acoustic_settings is None:\n        acoustic_settings = Settings()\n\n    pm = PathManager()\n    if Tags.ACOUSTIC_MODEL_BINARY_PATH not in acoustic_settings or \\\n            acoustic_settings[Tags.ACOUSTIC_MODEL_BINARY_PATH] is None:\n        acoustic_settings[Tags.ACOUSTIC_MODEL_BINARY_PATH] = pm.get_matlab_binary_path()\n\n    if Tags.KWAVE_PROPERTY_ALPHA_POWER not in acoustic_settings or acoustic_settings[Tags.KWAVE_PROPERTY_ALPHA_POWER] is None:\n        acoustic_settings[Tags.KWAVE_PROPERTY_ALPHA_POWER] = alpha_power\n\n    if Tags.KWAVE_PROPERTY_SENSOR_RECORD not in acoustic_settings or acoustic_settings[Tags.KWAVE_PROPERTY_SENSOR_RECORD] is None:\n        acoustic_settings[Tags.KWAVE_PROPERTY_SENSOR_RECORD] = sensor_record\n\n    if Tags.KWAVE_PROPERTY_PMLInside not in acoustic_settings or acoustic_settings[Tags.KWAVE_PROPERTY_PMLInside] is None:\n        acoustic_settings[Tags.KWAVE_PROPERTY_PMLInside] = pml_inside\n\n    if Tags.KWAVE_PROPERTY_PMLAlpha not in acoustic_settings or acoustic_settings[Tags.KWAVE_PROPERTY_PMLAlpha] is None:\n        acoustic_settings[Tags.KWAVE_PROPERTY_PMLAlpha] = pml_alpha\n\n    if Tags.KWAVE_PROPERTY_PlotPML not in acoustic_settings or acoustic_settings[Tags.KWAVE_PROPERTY_PlotPML] is None:\n        acoustic_settings[Tags.KWAVE_PROPERTY_PlotPML] = plot_pml\n\n    if Tags.RECORDMOVIE not in acoustic_settings or acoustic_settings[Tags.RECORDMOVIE] is None:\n        acoustic_settings[Tags.RECORDMOVIE] = record_movie\n\n    if Tags.MOVIENAME not in acoustic_settings or acoustic_settings[Tags.MOVIENAME] is None:\n        acoustic_settings[Tags.MOVIENAME] = movie_name\n\n    if Tags.ACOUSTIC_LOG_SCALE not in acoustic_settings or acoustic_settings[Tags.ACOUSTIC_LOG_SCALE] is None:\n        acoustic_settings[Tags.ACOUSTIC_LOG_SCALE] = acoustic_log_scale\n\n    if Tags.GPU not in acoustic_settings or acoustic_settings[Tags.GPU] is None:\n        acoustic_settings[Tags.GPU] = gpu\n\n    if Tags.SPACING_MM not in acoustic_settings or acoustic_settings[Tags.SPACING_MM] is None:\n        acoustic_settings[Tags.SPACING_MM] = spacing_mm\n\n    settings = Settings()\n    settings.set_acoustic_settings(acoustic_settings)\n\n    # initialize adapter and run forward model\n    kWave = KWaveAdapter(settings)\n    time_series_data, updated_global_settings = kWave.k_wave_acoustic_forward_model(\n        detection_geometry, speed_of_sound, density, alpha_coeff, initial_pressure)\n    return time_series_data",
  "def forward_model(self, detection_geometry: DetectionGeometryBase) -> np.ndarray:\n        \"\"\"\n        Runs the acoustic forward model and performs reading parameters and values from an hdf5 file\n        before calling the actual algorithm and saves the updated settings afterwards.\n\n        :param detection_geometry:\n        :return: simulated time series data (numpy array)\n\n        \"\"\"\n\n        optical_path = generate_dict_path(Tags.OPTICAL_MODEL_OUTPUT_NAME,\n                                          wavelength=self.global_settings[Tags.WAVELENGTH])\n\n        self.logger.debug(f\"OPTICAL_PATH: {str(optical_path)}\")\n\n        data_dict = {}\n        file_path = self.global_settings[Tags.SIMPA_OUTPUT_PATH]\n        data_dict[Tags.DATA_FIELD_INITIAL_PRESSURE] = load_data_field(file_path, Tags.DATA_FIELD_INITIAL_PRESSURE)\n        data_dict[Tags.DATA_FIELD_SPEED_OF_SOUND] = load_data_field(file_path, Tags.DATA_FIELD_SPEED_OF_SOUND)\n        data_dict[Tags.DATA_FIELD_DENSITY] = load_data_field(file_path, Tags.DATA_FIELD_DENSITY)\n        data_dict[Tags.DATA_FIELD_ALPHA_COEFF] = load_data_field(file_path, Tags.DATA_FIELD_ALPHA_COEFF)\n\n        pa_device = detection_geometry\n        pa_device.check_settings_prerequisites(self.global_settings)\n        field_of_view_extent = pa_device.field_of_view_extent_mm\n        detector_positions_mm = pa_device.get_detector_element_positions_accounting_for_device_position_mm()\n        self.logger.debug(f\"field_of_view_extent: {field_of_view_extent}\")\n\n        detectors_are_aligned_along_x_axis = field_of_view_extent[2] == 0 and field_of_view_extent[3] == 0\n        detectors_are_aligned_along_y_axis = field_of_view_extent[0] == 0 and field_of_view_extent[1] == 0\n        if detectors_are_aligned_along_x_axis or detectors_are_aligned_along_y_axis:\n            axes = (0, 1)\n            if detectors_are_aligned_along_y_axis:\n                transducer_plane = int(round((detector_positions_mm[0, 0] / self.global_settings[Tags.SPACING_MM]))) - 1\n                image_slice = np.s_[transducer_plane, :, :]\n            else:\n                transducer_plane = int(round((detector_positions_mm[0, 1] / self.global_settings[Tags.SPACING_MM]))) - 1\n                image_slice = np.s_[:, transducer_plane, :]\n        else:\n            axes = (0, 2)\n            image_slice = np.s_[:]\n\n        wavelength = str(self.global_settings[Tags.WAVELENGTH])\n        data_dict[Tags.DATA_FIELD_SPEED_OF_SOUND] = np.rot90(data_dict[Tags.DATA_FIELD_SPEED_OF_SOUND][image_slice],\n                                                             3, axes=axes)\n        data_dict[Tags.DATA_FIELD_DENSITY] = np.rot90(data_dict[Tags.DATA_FIELD_DENSITY][image_slice],\n                                                      3, axes=axes)\n        data_dict[Tags.DATA_FIELD_ALPHA_COEFF] = np.rot90(data_dict[Tags.DATA_FIELD_ALPHA_COEFF][image_slice],\n                                                          3, axes=axes)\n        data_dict[Tags.DATA_FIELD_INITIAL_PRESSURE] = np.rot90(data_dict[Tags.DATA_FIELD_INITIAL_PRESSURE]\n                                                               [wavelength][image_slice], 3, axes=axes)\n\n        time_series_data, global_settings = self.k_wave_acoustic_forward_model(\n            detection_geometry,\n            data_dict[Tags.DATA_FIELD_SPEED_OF_SOUND],\n            data_dict[Tags.DATA_FIELD_DENSITY],\n            data_dict[Tags.DATA_FIELD_ALPHA_COEFF],\n            data_dict[Tags.DATA_FIELD_INITIAL_PRESSURE],\n            optical_path=self.global_settings[Tags.SIMPA_OUTPUT_PATH])\n        save_hdf5(global_settings, global_settings[Tags.SIMPA_OUTPUT_PATH], \"/settings/\")\n\n        return time_series_data",
  "def k_wave_acoustic_forward_model(self, detection_geometry: DetectionGeometryBase,\n                                      speed_of_sound: float, density: float,\n                                      alpha_coeff: float, initial_pressure: np.ndarray,\n                                      optical_path: str = \"temporary\") -> tuple:\n        \"\"\"\n        Runs the acoustic forward model with the given parameters speed_of_sound (float), density (float),\n        alpha_coeff (float) for the initial_pressure distribution (numpy array) and a given detection geometry.\n        Uses the given optical_path (str) or if none is given a temporary one for saving temporary files.\n        Note, that in order to work properly, this function assumes that several settings mentioned above are set.\n        This can either be done by reading it from a settings file (e.g. when being called from forward_model) or\n        by parsing all settings individually as in the convenience function\n        (perform_k_wave_acoustic_forward_simulation).\n\n        :param detection_geometry:\n        :param speed_of_sound:\n        :param density:\n        :param alpha_coeff:\n        :param initial_pressure:\n        :param optical_path:\n        :return: time_series_data (numpy array): simulated time series data, global_settings (Settings): updated global\n            settings with new entries from the simulation\n\n        \"\"\"\n        data_dict = {}\n\n        pa_device = detection_geometry\n        field_of_view = pa_device.get_field_of_view_mm()\n        detector_positions_mm = pa_device.get_detector_element_positions_accounting_for_device_position_mm()\n\n        if not self.component_settings.get(Tags.ACOUSTIC_SIMULATION_3D):\n            detectors_are_aligned_along_x_axis = np.abs(field_of_view[2] - field_of_view[3]) < 1e-5\n            detectors_are_aligned_along_y_axis = np.abs(field_of_view[0] - field_of_view[1]) < 1e-5\n            if detectors_are_aligned_along_x_axis or detectors_are_aligned_along_y_axis:\n                simulate_2d = True\n            else:\n                simulate_2d = False\n        else:\n            simulate_2d = False\n\n        data_dict[Tags.DATA_FIELD_SPEED_OF_SOUND] = np.ones_like(initial_pressure) * speed_of_sound\n        data_dict[Tags.DATA_FIELD_DENSITY] = np.ones_like(initial_pressure) * density\n        data_dict[Tags.DATA_FIELD_ALPHA_COEFF] = np.ones_like(initial_pressure) * alpha_coeff\n        data_dict[Tags.DATA_FIELD_INITIAL_PRESSURE] = initial_pressure\n\n        if simulate_2d:\n            detector_positions_mm_2d = np.delete(detector_positions_mm, 1, axis=1)\n            detector_positions_mm_2d = np.moveaxis(detector_positions_mm_2d, 1, 0)\n            data_dict[Tags.SENSOR_ELEMENT_POSITIONS] = detector_positions_mm_2d[[1, 0]]\n            orientations = pa_device.get_detector_element_orientations()\n            angles = np.arccos(np.dot(orientations, np.array([1, 0, 0])))\n            data_dict[Tags.KWAVE_PROPERTY_DIRECTIVITY_ANGLE] = angles[::-1]\n        else:\n            detector_positions_mm = np.moveaxis(detector_positions_mm, 1, 0)\n            data_dict[Tags.SENSOR_ELEMENT_POSITIONS] = detector_positions_mm[[2, 1, 0]]\n            orientations = pa_device.get_detector_element_orientations()\n            x_angles = np.arccos(np.dot(orientations, np.array([1, 0, 0]))) * 360 / (2*np.pi)\n            y_angles = np.arccos(np.dot(orientations, np.array([0, 1, 0]))) * 360 / (2*np.pi)\n            z_angles = np.arccos(np.dot(orientations, np.array([0, 0, 1]))) * 360 / (2*np.pi)\n            intrinsic_euler_angles = list()\n            for orientation_vector in orientations:\n\n                mat = rotation_matrix_between_vectors(orientation_vector, np.array([0, 0, 1]))\n                rot = Rotation.from_matrix(mat)\n                euler_angles = rot.as_euler(\"XYZ\", degrees=True)\n                intrinsic_euler_angles.append(euler_angles)\n            intrinsic_euler_angles.reverse()\n            angles = np.array([z_angles[::-1], y_angles[::-1], x_angles[::-1]])\n            data_dict[Tags.KWAVE_PROPERTY_DIRECTIVITY_ANGLE] = angles\n            data_dict[Tags.KWAVE_PROPERTY_INTRINSIC_EULER_ANGLE] = intrinsic_euler_angles\n\n        optical_path = optical_path + \".mat\"\n        optical_path = os.path.abspath(optical_path)\n\n        possible_k_wave_parameters = [Tags.SPACING_MM, Tags.MODEL_SENSOR_FREQUENCY_RESPONSE,\n                                      Tags.KWAVE_PROPERTY_ALPHA_POWER, Tags.GPU, Tags.KWAVE_PROPERTY_PMLInside, Tags.KWAVE_PROPERTY_PMLAlpha, Tags.KWAVE_PROPERTY_PlotPML,\n                                      Tags.RECORDMOVIE, Tags.MOVIENAME, Tags.ACOUSTIC_LOG_SCALE,\n                                      Tags.SENSOR_DIRECTIVITY_PATTERN, Tags.KWAVE_PROPERTY_INITIAL_PRESSURE_SMOOTHING]\n\n        k_wave_settings = Settings({\n            Tags.SENSOR_NUM_ELEMENTS: pa_device.number_detector_elements,\n            Tags.DETECTOR_ELEMENT_WIDTH_MM: pa_device.detector_element_width_mm,\n            Tags.SENSOR_CENTER_FREQUENCY_HZ: pa_device.center_frequency_Hz,\n            Tags.SENSOR_BANDWIDTH_PERCENT: pa_device.bandwidth_percent,\n            Tags.SENSOR_SAMPLING_RATE_MHZ: pa_device.sampling_frequency_MHz\n        })\n        if isinstance(pa_device, CurvedArrayDetectionGeometry):\n            k_wave_settings[Tags.SENSOR_RADIUS_MM] = pa_device.radius_mm\n\n        for parameter in possible_k_wave_parameters:\n            if parameter in self.component_settings:\n                k_wave_settings[parameter] = self.component_settings[parameter]\n                self.logger.debug(f\"Added parameter {parameter} to kWave settings via component_settings\")\n            elif parameter in self.global_settings:\n                k_wave_settings[parameter] = self.global_settings[parameter]\n                self.logger.debug(f\"Added parameter {parameter} to kWave settings via global_settings\")\n            else:\n                self.logger.warning(f\"Did not find parameter {parameter} in any settings.\")\n\n        data_dict[\"settings\"] = k_wave_settings\n        sio.savemat(optical_path, data_dict, long_field_names=True)\n\n        del data_dict, k_wave_settings, detector_positions_mm, pa_device\n        gc.collect()\n\n        if not simulate_2d:\n            self.logger.info(\"Simulating 3D....\")\n            simulation_script_path = \"simulate_3D\"\n        else:\n            self.logger.info(\"Simulating 2D....\")\n            simulation_script_path = \"simulate_2D\"\n\n        base_script_path = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n\n        cmd = list()\n        cmd.append(self.component_settings[Tags.ACOUSTIC_MODEL_BINARY_PATH])\n        cmd.append(\"-nodisplay\")\n        cmd.append(\"-nosplash\")\n        cmd.append(\"-automation\")\n        cmd.append(\"-wait\")\n        cmd.append(\"-r\")\n        cmd.append(\"addpath('\" + base_script_path + \"');\" +\n                   simulation_script_path + \"('\" + optical_path + \"');exit;\")\n        cur_dir = os.getcwd()\n        self.logger.info(cmd)\n        subprocess.run(cmd)\n\n        raw_time_series_data = sio.loadmat(optical_path)[Tags.DATA_FIELD_TIME_SERIES_DATA]\n\n        # reverse the order of detector elements from matlab to python order\n        raw_time_series_data = raw_time_series_data[::-1, :]\n\n        time_grid = sio.loadmat(optical_path + \"dt.mat\")\n        num_time_steps = int(np.round(time_grid[\"number_time_steps\"]))\n\n        self.global_settings[Tags.K_WAVE_SPECIFIC_DT] = float(time_grid[\"time_step\"])\n        self.global_settings[Tags.K_WAVE_SPECIFIC_NT] = num_time_steps\n\n        os.remove(optical_path)\n        os.remove(optical_path + \"dt.mat\")\n        os.chdir(cur_dir)\n\n        return raw_time_series_data, self.global_settings",
  "class AcousticForwardModelBaseAdapter(SimulationModule):\n    \"\"\"\n    This method is the entry method for running an acoustic forward model.\n    It is invoked in the *simpa.core.simulation.simulate* method, but can also be called\n    individually for the purposes of performing acoustic forward modeling only or in a different context.\n\n    The concrete will be chosen based on the::\n\n        Tags.ACOUSTIC_MODEL\n\n    tag in the settings dictionary.\n\n    :param settings: The settings dictionary containing key-value pairs that determine the simulation.\n        Here, it must contain the Tags.ACOUSTIC_MODEL tag and any tags that might be required by the specific\n        acoustic model.\n    :raises AssertionError: an assertion error is raised if the Tags.ACOUSTIC_MODEL tag is not given or\n        points to an unknown acoustic forward model.\n    \"\"\"\n\n    def __init__(self, global_settings: Settings):\n        super(AcousticForwardModelBaseAdapter, self).__init__(global_settings=global_settings)\n        self.component_settings = global_settings.get_acoustic_settings()\n\n    @abstractmethod\n    def forward_model(self, detection_geometry) -> np.ndarray:\n        \"\"\"\n        This method performs the acoustic forward modeling given the initial pressure\n        distribution and the acoustic tissue properties contained in the settings file.\n        A deriving class needs to implement this method according to its model.\n\n        :return: time series pressure data\n        \"\"\"\n        pass\n\n    def run(self, digital_device_twin):\n        \"\"\"\n        Call this method to invoke the simulation process.\n\n        :param digital_device_twin:\n        :return: a numpy array containing the time series pressure data per detection element\n        \"\"\"\n\n        self.logger.info(\"Simulating the acoustic forward process...\")\n\n        _device = None\n        if isinstance(digital_device_twin, DetectionGeometryBase):\n            _device = digital_device_twin\n        elif isinstance(digital_device_twin, PhotoacousticDevice):\n            _device = digital_device_twin.get_detection_geometry()\n        else:\n            raise TypeError(\n                f\"The optical forward modelling does not support devices of type {type(digital_device_twin)}\")\n\n        time_series_data = self.forward_model(_device)\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(time_series_data, array_name=\"time_series_data\")\n\n        acoustic_output_path = generate_dict_path(\n            Tags.DATA_FIELD_TIME_SERIES_DATA, wavelength=self.global_settings[Tags.WAVELENGTH])\n\n        save_hdf5(time_series_data, self.global_settings[Tags.SIMPA_OUTPUT_PATH], acoustic_output_path)\n\n        self.logger.info(\"Simulating the acoustic forward process...[Done]\")",
  "def __init__(self, global_settings: Settings):\n        super(AcousticForwardModelBaseAdapter, self).__init__(global_settings=global_settings)\n        self.component_settings = global_settings.get_acoustic_settings()",
  "def forward_model(self, detection_geometry) -> np.ndarray:\n        \"\"\"\n        This method performs the acoustic forward modeling given the initial pressure\n        distribution and the acoustic tissue properties contained in the settings file.\n        A deriving class needs to implement this method according to its model.\n\n        :return: time series pressure data\n        \"\"\"\n        pass",
  "def run(self, digital_device_twin):\n        \"\"\"\n        Call this method to invoke the simulation process.\n\n        :param digital_device_twin:\n        :return: a numpy array containing the time series pressure data per detection element\n        \"\"\"\n\n        self.logger.info(\"Simulating the acoustic forward process...\")\n\n        _device = None\n        if isinstance(digital_device_twin, DetectionGeometryBase):\n            _device = digital_device_twin\n        elif isinstance(digital_device_twin, PhotoacousticDevice):\n            _device = digital_device_twin.get_detection_geometry()\n        else:\n            raise TypeError(\n                f\"The optical forward modelling does not support devices of type {type(digital_device_twin)}\")\n\n        time_series_data = self.forward_model(_device)\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(time_series_data, array_name=\"time_series_data\")\n\n        acoustic_output_path = generate_dict_path(\n            Tags.DATA_FIELD_TIME_SERIES_DATA, wavelength=self.global_settings[Tags.WAVELENGTH])\n\n        save_hdf5(time_series_data, self.global_settings[Tags.SIMPA_OUTPUT_PATH], acoustic_output_path)\n\n        self.logger.info(\"Simulating the acoustic forward process...[Done]\")",
  "class MCXAdapter(OpticalForwardModuleBase):\n    \"\"\"\n    This class implements a bridge to the mcx framework to integrate mcx into SIMPA. This adapter only allows for\n    computation of fluence, for computations of diffuse reflectance, take a look at `simpa.ReflectanceMcxAdapter`\n\n    .. note::\n        MCX is a GPU-enabled Monte-Carlo model simulation of photon transport in tissue:\n        Fang, Qianqian, and David A. Boas. \"Monte Carlo simulation of photon migration in 3D\n        turbid media accelerated by graphics processing units.\"\n        Optics express 17.22 (2009): 20178-20190.\n\n    \"\"\"\n\n    def __init__(self, global_settings: Settings):\n        \"\"\"\n        initializes MCX-specific configuration and clean-up instances\n\n        :param global_settings: global settings used during simulations\n        \"\"\"\n        super(MCXAdapter, self).__init__(global_settings=global_settings)\n        self.mcx_json_config_file = None\n        self.mcx_volumetric_data_file = None\n        self.frames = None\n        self.mcx_output_suffixes = {'mcx_volumetric_data_file': '.mc2'}\n\n    def forward_model(self,\n                      absorption_cm: np.ndarray,\n                      scattering_cm: np.ndarray,\n                      anisotropy: np.ndarray,\n                      illumination_geometry: IlluminationGeometryBase) -> Dict:\n        \"\"\"\n        runs the MCX simulations. Binary file containing scattering and absorption volumes is temporarily created as\n        input for MCX. A JSON serializable file containing the configuration required by MCx is also generated.\n        The set of flags parsed to MCX is built based on the Tags declared in `self.component_settings`, the results\n        from MCX are used to populate an instance of Dict and returned.\n\n        :param absorption_cm: array containing the absorption of the tissue in `cm` units\n        :param scattering_cm: array containing the scattering of the tissue in `cm` units\n        :param anisotropy: array containing the anisotropy of the volume defined by `absorption_cm` and `scattering_cm`\n        :param illumination_geometry: and instance of `IlluminationGeometryBase` defining the illumination geometry\n        :return: `Dict` containing the results of optical simulations, the keys in this dictionary-like object\n            depend on the Tags defined in `self.component_settings`\n        \"\"\"\n        if Tags.MCX_ASSUMED_ANISOTROPY in self.component_settings:\n            _assumed_anisotropy = self.component_settings[Tags.MCX_ASSUMED_ANISOTROPY]\n        else:\n            _assumed_anisotropy = 0.9\n\n        self.generate_mcx_bin_input(absorption_cm=absorption_cm,\n                                    scattering_cm=scattering_cm,\n                                    anisotropy=anisotropy,\n                                    assumed_anisotropy=_assumed_anisotropy)\n\n        settings_dict = self.get_mcx_settings(illumination_geometry=illumination_geometry,\n                                              assumed_anisotropy=_assumed_anisotropy)\n\n        print(settings_dict)\n        self.generate_mcx_json_input(settings_dict=settings_dict)\n        # run the simulation\n        cmd = self.get_command()\n        self.run_mcx(cmd)\n\n        # Read output\n        results = self.read_mcx_output()\n\n        # clean temporary files\n        self.remove_mcx_output()\n        return results\n\n    def generate_mcx_json_input(self, settings_dict: Dict) -> None:\n        \"\"\"\n        generates JSON serializable file with settings needed by MCX to run simulations.\n\n        :param settings_dict: dictionary to be saved as .json\n        :return: None\n        \"\"\"\n        tmp_json_filename = self.global_settings[Tags.SIMULATION_PATH] + \"/\" + \\\n            self.global_settings[Tags.VOLUME_NAME] + \".json\"\n        self.mcx_json_config_file = tmp_json_filename\n        self.temporary_output_files.append(tmp_json_filename)\n        with open(tmp_json_filename, \"w\") as json_file:\n            json.dump(settings_dict, json_file, indent=\"\\t\")\n\n    def get_mcx_settings(self,\n                         illumination_geometry: IlluminationGeometryBase,\n                         assumed_anisotropy: np.ndarray,\n                         **kwargs) -> Dict:\n        \"\"\"\n        generates MCX-specific settings for simulations based on Tags in `self.global_settings` and\n        `self.component_settings` . Among others, it defines the volume type, dimensions and path to binary file.\n\n        :param illumination_geometry: and instance of `IlluminationGeometryBase` defining the illumination geometry\n        :param assumed_anisotropy:\n        :param kwargs: dummy, used for class inheritance\n        :return: dictionary with settings to be used by MCX\n        \"\"\"\n        mcx_volumetric_data_file = self.global_settings[Tags.SIMULATION_PATH] + \"/\" + \\\n            self.global_settings[Tags.VOLUME_NAME] + \"_output\"\n        for name, suffix in self.mcx_output_suffixes.items():\n            self.__setattr__(name, mcx_volumetric_data_file + suffix)\n            self.temporary_output_files.append(mcx_volumetric_data_file + suffix)\n        if Tags.TIME_STEP and Tags.TOTAL_TIME in self.component_settings:\n            dt = self.component_settings[Tags.TIME_STEP]\n            time = self.component_settings[Tags.TOTAL_TIME]\n        else:\n            time = 5e-09\n            dt = 5e-09\n        self.frames = int(time / dt)\n\n        source = illumination_geometry.get_mcx_illuminator_definition(self.global_settings)\n        settings_dict = {\n            \"Session\": {\n                \"ID\": mcx_volumetric_data_file,\n                \"DoAutoThread\": 1,\n                \"Photons\": self.component_settings[Tags.OPTICAL_MODEL_NUMBER_PHOTONS],\n                \"DoMismatch\": 0\n            },\n            \"Forward\": {\n                \"T0\": 0,\n                \"T1\": time,\n                \"Dt\": dt\n            },\n            \"Optode\": {\n                \"Source\": source\n            },\n            \"Domain\": {\n                \"OriginType\": 0,\n                \"LengthUnit\": self.global_settings[Tags.SPACING_MM],\n                \"Media\": [\n                    {\n                        \"mua\": 0,\n                        \"mus\": 0,\n                        \"g\": 1,\n                        \"n\": 1\n                    },\n                    {\n                        \"mua\": 1,\n                        \"mus\": 1,\n                        \"g\": assumed_anisotropy,\n                        \"n\": 1\n                    }\n                ],\n                \"MediaFormat\": \"muamus_float\",\n                \"Dim\": [self.nx, self.ny, self.nz],\n                \"VolumeFile\": self.global_settings[Tags.SIMULATION_PATH] + \"/\" +\n                self.global_settings[Tags.VOLUME_NAME] + \".bin\"\n            }}\n        if Tags.MCX_SEED not in self.component_settings:\n            if Tags.RANDOM_SEED in self.global_settings:\n                settings_dict[\"Session\"][\"RNGSeed\"] = self.global_settings[Tags.RANDOM_SEED]\n        else:\n            settings_dict[\"Session\"][\"RNGSeed\"] = self.component_settings[Tags.MCX_SEED]\n        return settings_dict\n\n    def get_command(self) -> List:\n        \"\"\"\n        generates list of commands to be parse to MCX in a subprocess\n\n        :return: list of MCX commands\n        \"\"\"\n        cmd = list()\n        cmd.append(self.component_settings[Tags.OPTICAL_MODEL_BINARY_PATH])\n        cmd.append(\"-f\")\n        cmd.append(self.mcx_json_config_file)\n        cmd.append(\"-O\")\n        cmd.append(\"F\")\n        return cmd\n\n    @staticmethod\n    def run_mcx(cmd: List) -> None:\n        \"\"\"\n        runs subprocess calling MCX with the flags built with `self.get_command`. Rises a `RuntimeError` if the code\n        exit of the subprocess is not 0.\n\n        :param cmd: list defining command to parse to `subprocess.run`\n        :return: None\n        \"\"\"\n        results = None\n        try:\n            results = subprocess.run(cmd)\n        except:\n            raise RuntimeError(f\"MCX failed to run: {cmd}, results: {results}\")\n\n    def generate_mcx_bin_input(self,\n                               absorption_cm: np.ndarray,\n                               scattering_cm: np.ndarray,\n                               anisotropy: np.ndarray,\n                               assumed_anisotropy: np.ndarray) -> None:\n        \"\"\"\n        generates binary file containing volume scattering and absorption as input for MCX\n\n        :param absorption_cm: Absorption in units of per centimeter\n        :param scattering_cm: Scattering in units of per centimeter\n        :param anisotropy: Dimensionless scattering anisotropy\n        :param assumed_anisotropy:\n        :return: None\n        \"\"\"\n        absorption_mm, scattering_mm = self.pre_process_volumes(**{'absorption_cm': absorption_cm,\n                                                                   'scattering_cm': scattering_cm,\n                                                                   'anisotropy': anisotropy,\n                                                                   'assumed_anisotropy': assumed_anisotropy})\n        op_array = np.asarray([absorption_mm, scattering_mm], dtype=np.float32)\n        [_, self.nx, self.ny, self.nz] = np.shape(op_array)\n        # # create a binary of the volume\n        tmp_input_path = self.global_settings[Tags.SIMULATION_PATH] + \"/\" + \\\n            self.global_settings[Tags.VOLUME_NAME] + \".bin\"\n        self.temporary_output_files.append(tmp_input_path)\n        # numpy tofile writes in 'C' order, so writing the transpose gives Fortran order\n        op_array.T.tofile(tmp_input_path)\n\n    def read_mcx_output(self, **kwargs) -> Dict:\n        \"\"\"\n        reads the temporary output generated with MCX\n\n        :param kwargs: dummy, used for class inheritance compatibility\n        :return: `Dict` instance containing the MCX output\n        \"\"\"\n        shape = [self.nx, self.ny, self.nz, self.frames]\n        fluence = np.fromfile(self.mcx_volumetric_data_file, dtype=np.float32).reshape(shape, order='F')\n        fluence *= 100  # Convert from J/mm^2 to J/cm^2\n        if np.shape(fluence)[3] == 1:\n            fluence = np.squeeze(fluence, 3)\n        results = dict()\n        results[Tags.DATA_FIELD_FLUENCE] = fluence\n        return results\n\n    def remove_mcx_output(self) -> None:\n        \"\"\"\n        deletes temporary MCX output files from the file system\n\n        :return: None\n        \"\"\"\n        for f in self.temporary_output_files:\n            if os.path.isfile(f):\n                os.remove(f)\n\n    def pre_process_volumes(self, **kwargs) -> Tuple:\n        \"\"\"\n        pre-process volumes before running simulations with MCX. The volumes are transformed to `mm` units\n\n        :param kwargs: dictionary containing at least the keys `scattering_cm, absorption_cm, anisotropy` and\n            `assumed_anisotropy`\n        :return: `Tuple` of volumes after transformation\n        \"\"\"\n        return self.volumes_to_mm(**kwargs)\n\n    @staticmethod\n    def volumes_to_mm(**kwargs) -> Tuple:\n        \"\"\"\n        transforms volumes into `mm` units\n\n        :param kwargs: dictionary containing at least the keys `scattering_cm, absorption_cm, anisotropy` and\n            `assumed_anisotropy`\n        :return: `Tuple` of volumes after transformation\n        \"\"\"\n        scattering_cm = kwargs.get('scattering_cm')\n        absorption_cm = kwargs.get('absorption_cm')\n        absorption_mm = absorption_cm / 10\n        scattering_mm = scattering_cm / 10\n\n        # FIXME Currently, mcx only accepts a single value for the anisotropy.\n        #   In order to use the correct reduced scattering coefficient throughout the simulation,\n        #   we adjust the scattering parameter to be more accurate in the diffuse regime.\n        #   This will lead to errors, especially in the quasi-ballistic regime.\n\n        given_reduced_scattering = (scattering_mm * (1 - kwargs.get('anisotropy')))\n\n        # If the anisotropy is 1, all scattering is forward scattering which is equal to no scattering at all\n        if kwargs.get(\"assumed_anisotropy\") == 1:\n            scattering_mm = given_reduced_scattering * 0\n        else:\n            scattering_mm = given_reduced_scattering / (1 - kwargs.get('assumed_anisotropy'))\n        scattering_mm[scattering_mm < 1e-10] = 1e-10\n        return absorption_mm, scattering_mm\n\n    @staticmethod\n    def post_process_volumes(**kwargs) -> Tuple:\n        \"\"\"\n        post-processes volumes after MCX simulations. Dummy function implemented for compatibility with inherited\n        classes\n\n        :param kwargs: dictionary containing at least the key `volumes` to be transformed\n        :return:\n        \"\"\"\n        arrays = kwargs.get('arrays')\n        return tuple(a for a in arrays)",
  "def __init__(self, global_settings: Settings):\n        \"\"\"\n        initializes MCX-specific configuration and clean-up instances\n\n        :param global_settings: global settings used during simulations\n        \"\"\"\n        super(MCXAdapter, self).__init__(global_settings=global_settings)\n        self.mcx_json_config_file = None\n        self.mcx_volumetric_data_file = None\n        self.frames = None\n        self.mcx_output_suffixes = {'mcx_volumetric_data_file': '.mc2'}",
  "def forward_model(self,\n                      absorption_cm: np.ndarray,\n                      scattering_cm: np.ndarray,\n                      anisotropy: np.ndarray,\n                      illumination_geometry: IlluminationGeometryBase) -> Dict:\n        \"\"\"\n        runs the MCX simulations. Binary file containing scattering and absorption volumes is temporarily created as\n        input for MCX. A JSON serializable file containing the configuration required by MCx is also generated.\n        The set of flags parsed to MCX is built based on the Tags declared in `self.component_settings`, the results\n        from MCX are used to populate an instance of Dict and returned.\n\n        :param absorption_cm: array containing the absorption of the tissue in `cm` units\n        :param scattering_cm: array containing the scattering of the tissue in `cm` units\n        :param anisotropy: array containing the anisotropy of the volume defined by `absorption_cm` and `scattering_cm`\n        :param illumination_geometry: and instance of `IlluminationGeometryBase` defining the illumination geometry\n        :return: `Dict` containing the results of optical simulations, the keys in this dictionary-like object\n            depend on the Tags defined in `self.component_settings`\n        \"\"\"\n        if Tags.MCX_ASSUMED_ANISOTROPY in self.component_settings:\n            _assumed_anisotropy = self.component_settings[Tags.MCX_ASSUMED_ANISOTROPY]\n        else:\n            _assumed_anisotropy = 0.9\n\n        self.generate_mcx_bin_input(absorption_cm=absorption_cm,\n                                    scattering_cm=scattering_cm,\n                                    anisotropy=anisotropy,\n                                    assumed_anisotropy=_assumed_anisotropy)\n\n        settings_dict = self.get_mcx_settings(illumination_geometry=illumination_geometry,\n                                              assumed_anisotropy=_assumed_anisotropy)\n\n        print(settings_dict)\n        self.generate_mcx_json_input(settings_dict=settings_dict)\n        # run the simulation\n        cmd = self.get_command()\n        self.run_mcx(cmd)\n\n        # Read output\n        results = self.read_mcx_output()\n\n        # clean temporary files\n        self.remove_mcx_output()\n        return results",
  "def generate_mcx_json_input(self, settings_dict: Dict) -> None:\n        \"\"\"\n        generates JSON serializable file with settings needed by MCX to run simulations.\n\n        :param settings_dict: dictionary to be saved as .json\n        :return: None\n        \"\"\"\n        tmp_json_filename = self.global_settings[Tags.SIMULATION_PATH] + \"/\" + \\\n            self.global_settings[Tags.VOLUME_NAME] + \".json\"\n        self.mcx_json_config_file = tmp_json_filename\n        self.temporary_output_files.append(tmp_json_filename)\n        with open(tmp_json_filename, \"w\") as json_file:\n            json.dump(settings_dict, json_file, indent=\"\\t\")",
  "def get_mcx_settings(self,\n                         illumination_geometry: IlluminationGeometryBase,\n                         assumed_anisotropy: np.ndarray,\n                         **kwargs) -> Dict:\n        \"\"\"\n        generates MCX-specific settings for simulations based on Tags in `self.global_settings` and\n        `self.component_settings` . Among others, it defines the volume type, dimensions and path to binary file.\n\n        :param illumination_geometry: and instance of `IlluminationGeometryBase` defining the illumination geometry\n        :param assumed_anisotropy:\n        :param kwargs: dummy, used for class inheritance\n        :return: dictionary with settings to be used by MCX\n        \"\"\"\n        mcx_volumetric_data_file = self.global_settings[Tags.SIMULATION_PATH] + \"/\" + \\\n            self.global_settings[Tags.VOLUME_NAME] + \"_output\"\n        for name, suffix in self.mcx_output_suffixes.items():\n            self.__setattr__(name, mcx_volumetric_data_file + suffix)\n            self.temporary_output_files.append(mcx_volumetric_data_file + suffix)\n        if Tags.TIME_STEP and Tags.TOTAL_TIME in self.component_settings:\n            dt = self.component_settings[Tags.TIME_STEP]\n            time = self.component_settings[Tags.TOTAL_TIME]\n        else:\n            time = 5e-09\n            dt = 5e-09\n        self.frames = int(time / dt)\n\n        source = illumination_geometry.get_mcx_illuminator_definition(self.global_settings)\n        settings_dict = {\n            \"Session\": {\n                \"ID\": mcx_volumetric_data_file,\n                \"DoAutoThread\": 1,\n                \"Photons\": self.component_settings[Tags.OPTICAL_MODEL_NUMBER_PHOTONS],\n                \"DoMismatch\": 0\n            },\n            \"Forward\": {\n                \"T0\": 0,\n                \"T1\": time,\n                \"Dt\": dt\n            },\n            \"Optode\": {\n                \"Source\": source\n            },\n            \"Domain\": {\n                \"OriginType\": 0,\n                \"LengthUnit\": self.global_settings[Tags.SPACING_MM],\n                \"Media\": [\n                    {\n                        \"mua\": 0,\n                        \"mus\": 0,\n                        \"g\": 1,\n                        \"n\": 1\n                    },\n                    {\n                        \"mua\": 1,\n                        \"mus\": 1,\n                        \"g\": assumed_anisotropy,\n                        \"n\": 1\n                    }\n                ],\n                \"MediaFormat\": \"muamus_float\",\n                \"Dim\": [self.nx, self.ny, self.nz],\n                \"VolumeFile\": self.global_settings[Tags.SIMULATION_PATH] + \"/\" +\n                self.global_settings[Tags.VOLUME_NAME] + \".bin\"\n            }}\n        if Tags.MCX_SEED not in self.component_settings:\n            if Tags.RANDOM_SEED in self.global_settings:\n                settings_dict[\"Session\"][\"RNGSeed\"] = self.global_settings[Tags.RANDOM_SEED]\n        else:\n            settings_dict[\"Session\"][\"RNGSeed\"] = self.component_settings[Tags.MCX_SEED]\n        return settings_dict",
  "def get_command(self) -> List:\n        \"\"\"\n        generates list of commands to be parse to MCX in a subprocess\n\n        :return: list of MCX commands\n        \"\"\"\n        cmd = list()\n        cmd.append(self.component_settings[Tags.OPTICAL_MODEL_BINARY_PATH])\n        cmd.append(\"-f\")\n        cmd.append(self.mcx_json_config_file)\n        cmd.append(\"-O\")\n        cmd.append(\"F\")\n        return cmd",
  "def run_mcx(cmd: List) -> None:\n        \"\"\"\n        runs subprocess calling MCX with the flags built with `self.get_command`. Rises a `RuntimeError` if the code\n        exit of the subprocess is not 0.\n\n        :param cmd: list defining command to parse to `subprocess.run`\n        :return: None\n        \"\"\"\n        results = None\n        try:\n            results = subprocess.run(cmd)\n        except:\n            raise RuntimeError(f\"MCX failed to run: {cmd}, results: {results}\")",
  "def generate_mcx_bin_input(self,\n                               absorption_cm: np.ndarray,\n                               scattering_cm: np.ndarray,\n                               anisotropy: np.ndarray,\n                               assumed_anisotropy: np.ndarray) -> None:\n        \"\"\"\n        generates binary file containing volume scattering and absorption as input for MCX\n\n        :param absorption_cm: Absorption in units of per centimeter\n        :param scattering_cm: Scattering in units of per centimeter\n        :param anisotropy: Dimensionless scattering anisotropy\n        :param assumed_anisotropy:\n        :return: None\n        \"\"\"\n        absorption_mm, scattering_mm = self.pre_process_volumes(**{'absorption_cm': absorption_cm,\n                                                                   'scattering_cm': scattering_cm,\n                                                                   'anisotropy': anisotropy,\n                                                                   'assumed_anisotropy': assumed_anisotropy})\n        op_array = np.asarray([absorption_mm, scattering_mm], dtype=np.float32)\n        [_, self.nx, self.ny, self.nz] = np.shape(op_array)\n        # # create a binary of the volume\n        tmp_input_path = self.global_settings[Tags.SIMULATION_PATH] + \"/\" + \\\n            self.global_settings[Tags.VOLUME_NAME] + \".bin\"\n        self.temporary_output_files.append(tmp_input_path)\n        # numpy tofile writes in 'C' order, so writing the transpose gives Fortran order\n        op_array.T.tofile(tmp_input_path)",
  "def read_mcx_output(self, **kwargs) -> Dict:\n        \"\"\"\n        reads the temporary output generated with MCX\n\n        :param kwargs: dummy, used for class inheritance compatibility\n        :return: `Dict` instance containing the MCX output\n        \"\"\"\n        shape = [self.nx, self.ny, self.nz, self.frames]\n        fluence = np.fromfile(self.mcx_volumetric_data_file, dtype=np.float32).reshape(shape, order='F')\n        fluence *= 100  # Convert from J/mm^2 to J/cm^2\n        if np.shape(fluence)[3] == 1:\n            fluence = np.squeeze(fluence, 3)\n        results = dict()\n        results[Tags.DATA_FIELD_FLUENCE] = fluence\n        return results",
  "def remove_mcx_output(self) -> None:\n        \"\"\"\n        deletes temporary MCX output files from the file system\n\n        :return: None\n        \"\"\"\n        for f in self.temporary_output_files:\n            if os.path.isfile(f):\n                os.remove(f)",
  "def pre_process_volumes(self, **kwargs) -> Tuple:\n        \"\"\"\n        pre-process volumes before running simulations with MCX. The volumes are transformed to `mm` units\n\n        :param kwargs: dictionary containing at least the keys `scattering_cm, absorption_cm, anisotropy` and\n            `assumed_anisotropy`\n        :return: `Tuple` of volumes after transformation\n        \"\"\"\n        return self.volumes_to_mm(**kwargs)",
  "def volumes_to_mm(**kwargs) -> Tuple:\n        \"\"\"\n        transforms volumes into `mm` units\n\n        :param kwargs: dictionary containing at least the keys `scattering_cm, absorption_cm, anisotropy` and\n            `assumed_anisotropy`\n        :return: `Tuple` of volumes after transformation\n        \"\"\"\n        scattering_cm = kwargs.get('scattering_cm')\n        absorption_cm = kwargs.get('absorption_cm')\n        absorption_mm = absorption_cm / 10\n        scattering_mm = scattering_cm / 10\n\n        # FIXME Currently, mcx only accepts a single value for the anisotropy.\n        #   In order to use the correct reduced scattering coefficient throughout the simulation,\n        #   we adjust the scattering parameter to be more accurate in the diffuse regime.\n        #   This will lead to errors, especially in the quasi-ballistic regime.\n\n        given_reduced_scattering = (scattering_mm * (1 - kwargs.get('anisotropy')))\n\n        # If the anisotropy is 1, all scattering is forward scattering which is equal to no scattering at all\n        if kwargs.get(\"assumed_anisotropy\") == 1:\n            scattering_mm = given_reduced_scattering * 0\n        else:\n            scattering_mm = given_reduced_scattering / (1 - kwargs.get('assumed_anisotropy'))\n        scattering_mm[scattering_mm < 1e-10] = 1e-10\n        return absorption_mm, scattering_mm",
  "def post_process_volumes(**kwargs) -> Tuple:\n        \"\"\"\n        post-processes volumes after MCX simulations. Dummy function implemented for compatibility with inherited\n        classes\n\n        :param kwargs: dictionary containing at least the key `volumes` to be transformed\n        :return:\n        \"\"\"\n        arrays = kwargs.get('arrays')\n        return tuple(a for a in arrays)",
  "class OpticalForwardModuleBase(SimulationModule):\n    \"\"\"\n    Use this class as a base for implementations of optical forward models.\n    This class has the attributes `self.temporary_output_files` which stores file paths that are temporarily created as\n    input to the optical simulator, e.g. MCX. The class attributes `nx, ny & nz` represent the volume dimensions\n    \"\"\"\n\n    def __init__(self, global_settings: Settings):\n        super(OpticalForwardModuleBase, self).__init__(global_settings=global_settings)\n        self.component_settings = self.global_settings.get_optical_settings()\n        self.nx = None\n        self.ny = None\n        self.nz = None\n        self.temporary_output_files = []\n\n    @abstractmethod\n    def forward_model(self,\n                      absorption_cm: np.ndarray,\n                      scattering_cm: np.ndarray,\n                      anisotropy: np.ndarray,\n                      illumination_geometry: IlluminationGeometryBase):\n        \"\"\"\n        A deriving class needs to implement this method according to its model.\n\n        :param absorption_cm: Absorption in units of per centimeter\n        :param scattering_cm: Scattering in units of per centimeter\n        :param anisotropy: Dimensionless scattering anisotropy\n        :param illumination_geometry: A device that represents a detection geometry\n        :return: Fluence in units of J/cm^2\n        \"\"\"\n        pass\n\n    def run(self, device: Union[IlluminationGeometryBase, PhotoacousticDevice]) -> None:\n        \"\"\"\n        runs optical simulations. Volumes are first loaded from HDF5 file and parsed to `self.forward_model`, the output\n        is aggregated in case multiple illuminations are defined by `device` and stored in the same HDF5 file.\n\n        :param device: Illumination or Photoacoustic device that defines the illumination geometry\n        :return: None\n        \"\"\"\n\n        self.logger.info(\"Simulating the optical forward process...\")\n\n        file_path = self.global_settings[Tags.SIMPA_OUTPUT_PATH]\n        wl = str(self.global_settings[Tags.WAVELENGTH])\n\n        absorption = load_data_field(file_path, Tags.DATA_FIELD_ABSORPTION_PER_CM, wl)\n        scattering = load_data_field(file_path, Tags.DATA_FIELD_SCATTERING_PER_CM, wl)\n        anisotropy = load_data_field(file_path, Tags.DATA_FIELD_ANISOTROPY, wl)\n        gruneisen_parameter = load_data_field(file_path, Tags.DATA_FIELD_GRUNEISEN_PARAMETER)\n\n        _device = None\n        if isinstance(device, IlluminationGeometryBase):\n            _device = device\n        elif isinstance(device, PhotoacousticDevice):\n            _device = device.get_illumination_geometry()\n        else:\n            raise TypeError(f\"The optical forward modelling does not support devices of type {type(device)}\")\n\n        results = self.run_forward_model(_device=_device,\n                                         device=device,\n                                         absorption=absorption,\n                                         scattering=scattering,\n                                         anisotropy=anisotropy)\n        fluence = results[Tags.DATA_FIELD_FLUENCE]\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(fluence, assume_non_negativity=True, array_name=\"fluence\")\n\n        if Tags.LASER_PULSE_ENERGY_IN_MILLIJOULE in self.component_settings:\n            units = Tags.UNITS_PRESSURE\n            # Initial pressure should be given in units of Pascale\n            conversion_factor = 1e6  # 1 J/cm^3 = 10^6 N/m^2 = 10^6 Pa\n            initial_pressure = (absorption * fluence * gruneisen_parameter *\n                                (self.component_settings[Tags.LASER_PULSE_ENERGY_IN_MILLIJOULE] / 1000)\n                                * conversion_factor)\n        else:\n            units = Tags.UNITS_ARBITRARY\n            initial_pressure = absorption * fluence\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(initial_pressure, assume_non_negativity=True, array_name=\"initial_pressure\")\n\n        results[Tags.DATA_FIELD_FLUENCE] = fluence\n        results[Tags.OPTICAL_MODEL_UNITS] = units\n        results[Tags.DATA_FIELD_INITIAL_PRESSURE] = initial_pressure\n        optical_output = {}\n        for k, item in results.items():\n            optical_output[k] = {self.global_settings[Tags.WAVELENGTH]: item}\n\n        optical_output_path = generate_dict_path(Tags.OPTICAL_MODEL_OUTPUT_NAME)\n        save_hdf5(optical_output, self.global_settings[Tags.SIMPA_OUTPUT_PATH], optical_output_path)\n        self.logger.info(\"Simulating the optical forward process...[Done]\")\n\n    def run_forward_model(self,\n                          _device,\n                          device: Union[IlluminationGeometryBase, PhotoacousticDevice],\n                          absorption: np.ndarray,\n                          scattering: np.ndarray,\n                          anisotropy: np.ndarray) -> Dict:\n        \"\"\"\n        runs `self.forward_model` as many times as defined by `device` and aggregates the results.\n\n        :param _device: device illumination geometry\n        :param device: class defining illumination\n        :param absorption: Absorption volume\n        :param scattering: Scattering volume\n        :param anisotropy: Dimensionless scattering anisotropy\n        :return:\n        \"\"\"\n        if isinstance(_device, list):\n            # per convention this list has at least two elements\n            results = self.forward_model(absorption_cm=absorption,\n                                         scattering_cm=scattering,\n                                         anisotropy=anisotropy,\n                                         illumination_geometry=_device[0])\n            fluence = results[Tags.DATA_FIELD_FLUENCE]\n            for idx in range(1, len(_device)):\n                # we already looked at the 0th element, so go from 1 to n-1\n                results = self.forward_model(absorption_cm=absorption,\n                                             scattering_cm=scattering,\n                                             anisotropy=anisotropy,\n                                             illumination_geometry=_device[idx])\n                fluence += results[Tags.DATA_FIELD_FLUENCE]\n\n            fluence = fluence / len(_device)\n\n        else:\n            results = self.forward_model(absorption_cm=absorption,\n                                         scattering_cm=scattering,\n                                         anisotropy=anisotropy,\n                                         illumination_geometry=_device)\n            fluence = results[Tags.DATA_FIELD_FLUENCE]\n        return {Tags.DATA_FIELD_FLUENCE: fluence}",
  "def __init__(self, global_settings: Settings):\n        super(OpticalForwardModuleBase, self).__init__(global_settings=global_settings)\n        self.component_settings = self.global_settings.get_optical_settings()\n        self.nx = None\n        self.ny = None\n        self.nz = None\n        self.temporary_output_files = []",
  "def forward_model(self,\n                      absorption_cm: np.ndarray,\n                      scattering_cm: np.ndarray,\n                      anisotropy: np.ndarray,\n                      illumination_geometry: IlluminationGeometryBase):\n        \"\"\"\n        A deriving class needs to implement this method according to its model.\n\n        :param absorption_cm: Absorption in units of per centimeter\n        :param scattering_cm: Scattering in units of per centimeter\n        :param anisotropy: Dimensionless scattering anisotropy\n        :param illumination_geometry: A device that represents a detection geometry\n        :return: Fluence in units of J/cm^2\n        \"\"\"\n        pass",
  "def run(self, device: Union[IlluminationGeometryBase, PhotoacousticDevice]) -> None:\n        \"\"\"\n        runs optical simulations. Volumes are first loaded from HDF5 file and parsed to `self.forward_model`, the output\n        is aggregated in case multiple illuminations are defined by `device` and stored in the same HDF5 file.\n\n        :param device: Illumination or Photoacoustic device that defines the illumination geometry\n        :return: None\n        \"\"\"\n\n        self.logger.info(\"Simulating the optical forward process...\")\n\n        file_path = self.global_settings[Tags.SIMPA_OUTPUT_PATH]\n        wl = str(self.global_settings[Tags.WAVELENGTH])\n\n        absorption = load_data_field(file_path, Tags.DATA_FIELD_ABSORPTION_PER_CM, wl)\n        scattering = load_data_field(file_path, Tags.DATA_FIELD_SCATTERING_PER_CM, wl)\n        anisotropy = load_data_field(file_path, Tags.DATA_FIELD_ANISOTROPY, wl)\n        gruneisen_parameter = load_data_field(file_path, Tags.DATA_FIELD_GRUNEISEN_PARAMETER)\n\n        _device = None\n        if isinstance(device, IlluminationGeometryBase):\n            _device = device\n        elif isinstance(device, PhotoacousticDevice):\n            _device = device.get_illumination_geometry()\n        else:\n            raise TypeError(f\"The optical forward modelling does not support devices of type {type(device)}\")\n\n        results = self.run_forward_model(_device=_device,\n                                         device=device,\n                                         absorption=absorption,\n                                         scattering=scattering,\n                                         anisotropy=anisotropy)\n        fluence = results[Tags.DATA_FIELD_FLUENCE]\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(fluence, assume_non_negativity=True, array_name=\"fluence\")\n\n        if Tags.LASER_PULSE_ENERGY_IN_MILLIJOULE in self.component_settings:\n            units = Tags.UNITS_PRESSURE\n            # Initial pressure should be given in units of Pascale\n            conversion_factor = 1e6  # 1 J/cm^3 = 10^6 N/m^2 = 10^6 Pa\n            initial_pressure = (absorption * fluence * gruneisen_parameter *\n                                (self.component_settings[Tags.LASER_PULSE_ENERGY_IN_MILLIJOULE] / 1000)\n                                * conversion_factor)\n        else:\n            units = Tags.UNITS_ARBITRARY\n            initial_pressure = absorption * fluence\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(initial_pressure, assume_non_negativity=True, array_name=\"initial_pressure\")\n\n        results[Tags.DATA_FIELD_FLUENCE] = fluence\n        results[Tags.OPTICAL_MODEL_UNITS] = units\n        results[Tags.DATA_FIELD_INITIAL_PRESSURE] = initial_pressure\n        optical_output = {}\n        for k, item in results.items():\n            optical_output[k] = {self.global_settings[Tags.WAVELENGTH]: item}\n\n        optical_output_path = generate_dict_path(Tags.OPTICAL_MODEL_OUTPUT_NAME)\n        save_hdf5(optical_output, self.global_settings[Tags.SIMPA_OUTPUT_PATH], optical_output_path)\n        self.logger.info(\"Simulating the optical forward process...[Done]\")",
  "def run_forward_model(self,\n                          _device,\n                          device: Union[IlluminationGeometryBase, PhotoacousticDevice],\n                          absorption: np.ndarray,\n                          scattering: np.ndarray,\n                          anisotropy: np.ndarray) -> Dict:\n        \"\"\"\n        runs `self.forward_model` as many times as defined by `device` and aggregates the results.\n\n        :param _device: device illumination geometry\n        :param device: class defining illumination\n        :param absorption: Absorption volume\n        :param scattering: Scattering volume\n        :param anisotropy: Dimensionless scattering anisotropy\n        :return:\n        \"\"\"\n        if isinstance(_device, list):\n            # per convention this list has at least two elements\n            results = self.forward_model(absorption_cm=absorption,\n                                         scattering_cm=scattering,\n                                         anisotropy=anisotropy,\n                                         illumination_geometry=_device[0])\n            fluence = results[Tags.DATA_FIELD_FLUENCE]\n            for idx in range(1, len(_device)):\n                # we already looked at the 0th element, so go from 1 to n-1\n                results = self.forward_model(absorption_cm=absorption,\n                                             scattering_cm=scattering,\n                                             anisotropy=anisotropy,\n                                             illumination_geometry=_device[idx])\n                fluence += results[Tags.DATA_FIELD_FLUENCE]\n\n            fluence = fluence / len(_device)\n\n        else:\n            results = self.forward_model(absorption_cm=absorption,\n                                         scattering_cm=scattering,\n                                         anisotropy=anisotropy,\n                                         illumination_geometry=_device)\n            fluence = results[Tags.DATA_FIELD_FLUENCE]\n        return {Tags.DATA_FIELD_FLUENCE: fluence}",
  "class MCXAdapterReflectance(MCXAdapter):\n    \"\"\"\n    This class implements a bridge to the mcx framework to integrate mcx into SIMPA. This class targets specifically\n    diffuse reflectance simulations. Specifically, it implements the capability to run diffuse reflectance simulations.\n\n    .. warning::\n        This MCX adapter requires a version of MCX containing the revision: `Rev::077060`, which was published in the\n        Nightly build  on `2022-01-26`.\n\n    .. note::\n        MCX is a GPU-enabled Monte-Carlo model simulation of photon transport in tissue:\n        Fang, Qianqian, and David A. Boas. \"Monte Carlo simulation of photon migration in 3D\n        turbid media accelerated by graphics processing units.\"\n        Optics express 17.22 (2009): 20178-20190.\n\n    \"\"\"\n\n    def __init__(self, global_settings: Settings):\n        \"\"\"\n        initializes MCX-specific configuration and clean-up instances\n\n        :param global_settings: global settings used during simulations\n        \"\"\"\n        super(MCXAdapterReflectance, self).__init__(global_settings=global_settings)\n        self.mcx_photon_data_file = None\n        self.padded = None\n        self.mcx_output_suffixes = {'mcx_volumetric_data_file': '.jnii',\n                                    'mcx_photon_data_file': '_detp.jdat'}\n\n    def forward_model(self,\n                      absorption_cm: np.ndarray,\n                      scattering_cm: np.ndarray,\n                      anisotropy: np.ndarray,\n                      illumination_geometry: IlluminationGeometryBase) -> Dict:\n        \"\"\"\n        runs the MCX simulations. Binary file containing scattering and absorption volumes is temporarily created as\n        input for MCX. A JSON serializable file containing the configuration required by MCx is also generated.\n        The set of flags parsed to MCX is built based on the Tags declared in `self.component_settings`, the results\n        from MCX are used to populate an instance of Settings and returned.\n\n        :param absorption_cm: array containing the absorption of the tissue in `cm` units\n        :param scattering_cm: array containing the scattering of the tissue in `cm` units\n        :param anisotropy: array containing the anisotropy of the volume defined by `absorption_cm` and `scattering_cm`\n        :param illumination_geometry: and instance of `IlluminationGeometryBase` defining the illumination geometry\n        :param probe_position_mm: position of a probe in `mm` units. This is parsed to\n            `illumination_geometry.get_mcx_illuminator_definition`\n        :return: `Settings` containing the results of optical simulations, the keys in this dictionary-like object\n            depend on the Tags defined in `self.component_settings`\n        \"\"\"\n        if Tags.MCX_ASSUMED_ANISOTROPY in self.component_settings:\n            _assumed_anisotropy = self.component_settings[Tags.MCX_ASSUMED_ANISOTROPY]\n        else:\n            _assumed_anisotropy = 0.9\n\n        self.generate_mcx_bin_input(absorption_cm=absorption_cm,\n                                    scattering_cm=scattering_cm,\n                                    anisotropy=_assumed_anisotropy,\n                                    assumed_anisotropy=_assumed_anisotropy)\n\n        settings_dict = self.get_mcx_settings(illumination_geometry=illumination_geometry,\n                                              assumed_anisotropy=_assumed_anisotropy,\n                                              )\n\n        print(settings_dict)\n        self.generate_mcx_json_input(settings_dict=settings_dict)\n        # run the simulation\n        cmd = self.get_command()\n        self.run_mcx(cmd)\n\n        # Read output\n        results = self.read_mcx_output()\n        struct._clearcache()\n\n        # clean temporary files\n        self.remove_mcx_output()\n        return results\n\n    def get_command(self) -> List:\n        \"\"\"\n        generates list of commands to be parse to MCX in a subprocess\n\n        :return: list of MCX commands\n        \"\"\"\n        cmd = list()\n        cmd.append(self.component_settings[Tags.OPTICAL_MODEL_BINARY_PATH])\n        cmd.append(\"-f\")\n        cmd.append(self.mcx_json_config_file)\n        cmd.append(\"-O\")\n        cmd.append(\"F\")\n        cmd.append(\"-F\")\n        cmd.append(\"jnii\")\n        if Tags.COMPUTE_PHOTON_DIRECTION_AT_EXIT in self.component_settings and \\\n                self.component_settings[Tags.COMPUTE_PHOTON_DIRECTION_AT_EXIT]:\n            cmd.append(\"-H\")\n            cmd.append(f\"{int(self.component_settings[Tags.OPTICAL_MODEL_NUMBER_PHOTONS])}\")\n            cmd.append(\"--bc\")  # save photon exit position and direction\n            cmd.append(\"______000010\")\n            cmd.append(\"--savedetflag\")\n            cmd.append(\"XV\")\n        if Tags.COMPUTE_DIFFUSE_REFLECTANCE in self.component_settings and \\\n                self.component_settings[Tags.COMPUTE_DIFFUSE_REFLECTANCE]:\n            cmd.append(\"--saveref\")  # save diffuse reflectance at 0 filled voxels outside of domain\n        return cmd\n\n    def read_mcx_output(self, **kwargs) -> Dict:\n        \"\"\"\n        reads the temporary output generated with MCX\n\n        :param kwargs: dummy, used for class inheritance compatibility\n        :return: `Settings` instance containing the MCX output\n        \"\"\"\n        results = dict()\n        if os.path.isfile(self.mcx_volumetric_data_file) and self.mcx_volumetric_data_file.endswith(\n                self.mcx_output_suffixes['mcx_volumetric_data_file']):\n            content = jdata.load(self.mcx_volumetric_data_file)\n            fluence = content['NIFTIData']\n            ref, ref_pos, fluence = self.extract_reflectance_from_fluence(fluence=fluence)\n            fluence = self.post_process_volumes(**{'arrays': (fluence,)})[0]\n            fluence *= 100  # Convert from J/mm^2 to J/cm^2\n            results[Tags.DATA_FIELD_FLUENCE] = fluence\n        else:\n            raise FileNotFoundError(f\"Could not find .jnii file for {self.mcx_volumetric_data_file}\")\n        if Tags.COMPUTE_DIFFUSE_REFLECTANCE in self.component_settings and \\\n                self.component_settings[Tags.COMPUTE_DIFFUSE_REFLECTANCE]:\n            results[Tags.DATA_FIELD_DIFFUSE_REFLECTANCE] = ref\n            results[Tags.DATA_FIELD_DIFFUSE_REFLECTANCE_POS] = ref_pos\n        if Tags.COMPUTE_PHOTON_DIRECTION_AT_EXIT in self.component_settings and \\\n                self.component_settings[Tags.COMPUTE_PHOTON_DIRECTION_AT_EXIT]:\n            content = jdata.load(self.mcx_photon_data_file)\n            photon_pos = content['MCXData']['PhotonData']['p']\n            photon_dir = content['MCXData']['PhotonData']['v']\n            results[Tags.DATA_FIELD_PHOTON_EXIT_POS] = photon_pos\n            results[Tags.DATA_FIELD_PHOTON_EXIT_DIR] = photon_dir\n        return results\n\n    @staticmethod\n    def extract_reflectance_from_fluence(fluence: np.ndarray) -> Tuple:\n        \"\"\"\n        extracts diffuse reflectance from volumes. MCX stores diffuse reflectance as negative values in the fluence\n        volume. The position where the reflectance is stored is also returned. If there are no negative values in the\n        fluence, `None` is returned instead of reflectance and reflectance position. Negative values in fluence are\n        set to `0` after extraction of the reflectance.\n\n        :param fluence: array containing fluence as generated by MCX\n        :return: tuple of reflectance, reflectance position and transformed fluence\n        \"\"\"\n        if np.any(fluence < 0):\n            pos = np.where(fluence < 0)\n            ref = fluence[pos] * -1\n            pos = np.array(pos).T  # reformatting to aggregate results after for multi illuminant geometries\n            fluence[fluence < 0] = 0\n            return ref, pos, fluence\n        else:\n            return None, None, fluence\n\n    def pre_process_volumes(self, **kwargs) -> Tuple:\n        \"\"\"\n        pre-process volumes before running simulations with MCX. The volumes are transformed to `mm` units and pads\n        a 0-values layer along the z-axis in order to save diffuse reflectance values. All 0-valued voxels are then\n        transformed to `np.nan`. This last transformation `0->np.nan` is a requirement form MCX.\n\n        :param kwargs: dictionary containing at least the keys `scattering_cm, absorption_cm, anisotropy` and\n            `assumed_anisotropy`\n        :return: `Tuple` of volumes after transformation\n        \"\"\"\n        arrays = self.volumes_to_mm(**kwargs)\n        assert np.all([len(a.shape) == 3] for a in arrays)\n        check_padding = (Tags.COMPUTE_DIFFUSE_REFLECTANCE in self.component_settings and\n                         self.component_settings[Tags.COMPUTE_DIFFUSE_REFLECTANCE]) or \\\n                        (Tags.COMPUTE_PHOTON_DIRECTION_AT_EXIT in self.component_settings and\n                         self.component_settings[Tags.COMPUTE_PHOTON_DIRECTION_AT_EXIT])\n        # check that all volumes on first layer along z have only 0 values\n        if np.any([np.any(a[:, :, 0] != 0)] for a in arrays) and check_padding:\n            results = tuple(np.pad(a, ((0, 0), (0, 0), (1, 0)), \"constant\", constant_values=0) for a in arrays)\n            self.padded = True\n        else:\n            results = tuple(arrays)\n            self.padded = False\n        for a in results:\n            # MCX requires NAN values to store photon direction and reflectance when using float mus and mua\n            a[a == 0] = np.nan\n        return results\n\n    def post_process_volumes(self, **kwargs):\n        \"\"\"\n        post-processes volumes after MCX simulations. Dummy function implemented for compatibility with inherited\n        classes. Removes layer padded by `self.pre_process_volumes` if it was added and transforms `np.nan -> 0`.\n\n        :param kwargs: dictionary containing at least the key `volumes` to be transformed\n        :return:\n        \"\"\"\n        arrays = kwargs.get('arrays')\n        if self.padded:\n            results = tuple(a[..., 1:] for a in arrays)\n        else:\n            results = tuple(arrays)\n        for a in results:\n            # revert nan transformation that was done while pre-processing volumes\n            a[np.isnan(a)] = 0.\n        return results\n\n    def run_forward_model(self,\n                          _device,\n                          device: Union[IlluminationGeometryBase, PhotoacousticDevice],\n                          absorption: np.ndarray,\n                          scattering: np.ndarray,\n                          anisotropy: np.ndarray\n                          ) -> Dict:\n        \"\"\"\n        runs `self.forward_model` as many times as defined by `device` and aggregates the results.\n\n        :param _device: device illumination geometry\n        :param device: class defining illumination\n        :param absorption: Absorption volume\n        :param scattering: Scattering volume\n        :param anisotropy: Dimensionless scattering anisotropy\n        :return:\n        \"\"\"\n        reflectance = []\n        reflectance_position = []\n        photon_position = []\n        photon_direction = []\n        if isinstance(_device, list):\n            # per convention this list has at least two elements\n            results = self.forward_model(absorption_cm=absorption,\n                                         scattering_cm=scattering,\n                                         anisotropy=anisotropy,\n                                         illumination_geometry=_device[0])\n            self._append_results(results=results,\n                                 reflectance=reflectance,\n                                 reflectance_position=reflectance_position,\n                                 photon_position=photon_position,\n                                 photon_direction=photon_direction)\n            fluence = results[Tags.DATA_FIELD_FLUENCE]\n            for idx in range(1, len(_device)):\n                # we already looked at the 0th element, so go from 1 to n-1\n                results = self.forward_model(absorption_cm=absorption,\n                                             scattering_cm=scattering,\n                                             anisotropy=anisotropy,\n                                             illumination_geometry=_device[idx])\n                self._append_results(results=results,\n                                     reflectance=reflectance,\n                                     reflectance_position=reflectance_position,\n                                     photon_position=photon_position,\n                                     photon_direction=photon_direction)\n                fluence += results[Tags.DATA_FIELD_FLUENCE]\n\n            fluence = fluence / len(_device)\n\n        else:\n            results = self.forward_model(absorption_cm=absorption,\n                                         scattering_cm=scattering,\n                                         anisotropy=anisotropy,\n                                         illumination_geometry=_device)\n            self._append_results(results=results,\n                                 reflectance=reflectance,\n                                 reflectance_position=reflectance_position,\n                                 photon_position=photon_position,\n                                 photon_direction=photon_direction)\n            fluence = results[Tags.DATA_FIELD_FLUENCE]\n        aggregated_results = dict()\n        aggregated_results[Tags.DATA_FIELD_FLUENCE] = fluence\n        if reflectance:\n            aggregated_results[Tags.DATA_FIELD_DIFFUSE_REFLECTANCE] = np.concatenate(reflectance, axis=0)\n            aggregated_results[Tags.DATA_FIELD_DIFFUSE_REFLECTANCE_POS] = np.concatenate(reflectance_position, axis=0)\n        if photon_position:\n            aggregated_results[Tags.DATA_FIELD_PHOTON_EXIT_POS] = np.concatenate(photon_position, axis=0)\n            aggregated_results[Tags.DATA_FIELD_PHOTON_EXIT_DIR] = np.concatenate(photon_direction, axis=0)\n        return aggregated_results\n\n    @staticmethod\n    def _append_results(results,\n                        reflectance,\n                        reflectance_position,\n                        photon_position,\n                        photon_direction):\n        if Tags.DATA_FIELD_DIFFUSE_REFLECTANCE in results:\n            reflectance.append(results[Tags.DATA_FIELD_DIFFUSE_REFLECTANCE])\n            reflectance_position.append(results[Tags.DATA_FIELD_DIFFUSE_REFLECTANCE_POS])\n        if Tags.DATA_FIELD_PHOTON_EXIT_POS in results:\n            photon_position.append(results[Tags.DATA_FIELD_PHOTON_EXIT_POS])\n            photon_direction.append(results[Tags.DATA_FIELD_PHOTON_EXIT_DIR])",
  "def __init__(self, global_settings: Settings):\n        \"\"\"\n        initializes MCX-specific configuration and clean-up instances\n\n        :param global_settings: global settings used during simulations\n        \"\"\"\n        super(MCXAdapterReflectance, self).__init__(global_settings=global_settings)\n        self.mcx_photon_data_file = None\n        self.padded = None\n        self.mcx_output_suffixes = {'mcx_volumetric_data_file': '.jnii',\n                                    'mcx_photon_data_file': '_detp.jdat'}",
  "def forward_model(self,\n                      absorption_cm: np.ndarray,\n                      scattering_cm: np.ndarray,\n                      anisotropy: np.ndarray,\n                      illumination_geometry: IlluminationGeometryBase) -> Dict:\n        \"\"\"\n        runs the MCX simulations. Binary file containing scattering and absorption volumes is temporarily created as\n        input for MCX. A JSON serializable file containing the configuration required by MCx is also generated.\n        The set of flags parsed to MCX is built based on the Tags declared in `self.component_settings`, the results\n        from MCX are used to populate an instance of Settings and returned.\n\n        :param absorption_cm: array containing the absorption of the tissue in `cm` units\n        :param scattering_cm: array containing the scattering of the tissue in `cm` units\n        :param anisotropy: array containing the anisotropy of the volume defined by `absorption_cm` and `scattering_cm`\n        :param illumination_geometry: and instance of `IlluminationGeometryBase` defining the illumination geometry\n        :param probe_position_mm: position of a probe in `mm` units. This is parsed to\n            `illumination_geometry.get_mcx_illuminator_definition`\n        :return: `Settings` containing the results of optical simulations, the keys in this dictionary-like object\n            depend on the Tags defined in `self.component_settings`\n        \"\"\"\n        if Tags.MCX_ASSUMED_ANISOTROPY in self.component_settings:\n            _assumed_anisotropy = self.component_settings[Tags.MCX_ASSUMED_ANISOTROPY]\n        else:\n            _assumed_anisotropy = 0.9\n\n        self.generate_mcx_bin_input(absorption_cm=absorption_cm,\n                                    scattering_cm=scattering_cm,\n                                    anisotropy=_assumed_anisotropy,\n                                    assumed_anisotropy=_assumed_anisotropy)\n\n        settings_dict = self.get_mcx_settings(illumination_geometry=illumination_geometry,\n                                              assumed_anisotropy=_assumed_anisotropy,\n                                              )\n\n        print(settings_dict)\n        self.generate_mcx_json_input(settings_dict=settings_dict)\n        # run the simulation\n        cmd = self.get_command()\n        self.run_mcx(cmd)\n\n        # Read output\n        results = self.read_mcx_output()\n        struct._clearcache()\n\n        # clean temporary files\n        self.remove_mcx_output()\n        return results",
  "def get_command(self) -> List:\n        \"\"\"\n        generates list of commands to be parse to MCX in a subprocess\n\n        :return: list of MCX commands\n        \"\"\"\n        cmd = list()\n        cmd.append(self.component_settings[Tags.OPTICAL_MODEL_BINARY_PATH])\n        cmd.append(\"-f\")\n        cmd.append(self.mcx_json_config_file)\n        cmd.append(\"-O\")\n        cmd.append(\"F\")\n        cmd.append(\"-F\")\n        cmd.append(\"jnii\")\n        if Tags.COMPUTE_PHOTON_DIRECTION_AT_EXIT in self.component_settings and \\\n                self.component_settings[Tags.COMPUTE_PHOTON_DIRECTION_AT_EXIT]:\n            cmd.append(\"-H\")\n            cmd.append(f\"{int(self.component_settings[Tags.OPTICAL_MODEL_NUMBER_PHOTONS])}\")\n            cmd.append(\"--bc\")  # save photon exit position and direction\n            cmd.append(\"______000010\")\n            cmd.append(\"--savedetflag\")\n            cmd.append(\"XV\")\n        if Tags.COMPUTE_DIFFUSE_REFLECTANCE in self.component_settings and \\\n                self.component_settings[Tags.COMPUTE_DIFFUSE_REFLECTANCE]:\n            cmd.append(\"--saveref\")  # save diffuse reflectance at 0 filled voxels outside of domain\n        return cmd",
  "def read_mcx_output(self, **kwargs) -> Dict:\n        \"\"\"\n        reads the temporary output generated with MCX\n\n        :param kwargs: dummy, used for class inheritance compatibility\n        :return: `Settings` instance containing the MCX output\n        \"\"\"\n        results = dict()\n        if os.path.isfile(self.mcx_volumetric_data_file) and self.mcx_volumetric_data_file.endswith(\n                self.mcx_output_suffixes['mcx_volumetric_data_file']):\n            content = jdata.load(self.mcx_volumetric_data_file)\n            fluence = content['NIFTIData']\n            ref, ref_pos, fluence = self.extract_reflectance_from_fluence(fluence=fluence)\n            fluence = self.post_process_volumes(**{'arrays': (fluence,)})[0]\n            fluence *= 100  # Convert from J/mm^2 to J/cm^2\n            results[Tags.DATA_FIELD_FLUENCE] = fluence\n        else:\n            raise FileNotFoundError(f\"Could not find .jnii file for {self.mcx_volumetric_data_file}\")\n        if Tags.COMPUTE_DIFFUSE_REFLECTANCE in self.component_settings and \\\n                self.component_settings[Tags.COMPUTE_DIFFUSE_REFLECTANCE]:\n            results[Tags.DATA_FIELD_DIFFUSE_REFLECTANCE] = ref\n            results[Tags.DATA_FIELD_DIFFUSE_REFLECTANCE_POS] = ref_pos\n        if Tags.COMPUTE_PHOTON_DIRECTION_AT_EXIT in self.component_settings and \\\n                self.component_settings[Tags.COMPUTE_PHOTON_DIRECTION_AT_EXIT]:\n            content = jdata.load(self.mcx_photon_data_file)\n            photon_pos = content['MCXData']['PhotonData']['p']\n            photon_dir = content['MCXData']['PhotonData']['v']\n            results[Tags.DATA_FIELD_PHOTON_EXIT_POS] = photon_pos\n            results[Tags.DATA_FIELD_PHOTON_EXIT_DIR] = photon_dir\n        return results",
  "def extract_reflectance_from_fluence(fluence: np.ndarray) -> Tuple:\n        \"\"\"\n        extracts diffuse reflectance from volumes. MCX stores diffuse reflectance as negative values in the fluence\n        volume. The position where the reflectance is stored is also returned. If there are no negative values in the\n        fluence, `None` is returned instead of reflectance and reflectance position. Negative values in fluence are\n        set to `0` after extraction of the reflectance.\n\n        :param fluence: array containing fluence as generated by MCX\n        :return: tuple of reflectance, reflectance position and transformed fluence\n        \"\"\"\n        if np.any(fluence < 0):\n            pos = np.where(fluence < 0)\n            ref = fluence[pos] * -1\n            pos = np.array(pos).T  # reformatting to aggregate results after for multi illuminant geometries\n            fluence[fluence < 0] = 0\n            return ref, pos, fluence\n        else:\n            return None, None, fluence",
  "def pre_process_volumes(self, **kwargs) -> Tuple:\n        \"\"\"\n        pre-process volumes before running simulations with MCX. The volumes are transformed to `mm` units and pads\n        a 0-values layer along the z-axis in order to save diffuse reflectance values. All 0-valued voxels are then\n        transformed to `np.nan`. This last transformation `0->np.nan` is a requirement form MCX.\n\n        :param kwargs: dictionary containing at least the keys `scattering_cm, absorption_cm, anisotropy` and\n            `assumed_anisotropy`\n        :return: `Tuple` of volumes after transformation\n        \"\"\"\n        arrays = self.volumes_to_mm(**kwargs)\n        assert np.all([len(a.shape) == 3] for a in arrays)\n        check_padding = (Tags.COMPUTE_DIFFUSE_REFLECTANCE in self.component_settings and\n                         self.component_settings[Tags.COMPUTE_DIFFUSE_REFLECTANCE]) or \\\n                        (Tags.COMPUTE_PHOTON_DIRECTION_AT_EXIT in self.component_settings and\n                         self.component_settings[Tags.COMPUTE_PHOTON_DIRECTION_AT_EXIT])\n        # check that all volumes on first layer along z have only 0 values\n        if np.any([np.any(a[:, :, 0] != 0)] for a in arrays) and check_padding:\n            results = tuple(np.pad(a, ((0, 0), (0, 0), (1, 0)), \"constant\", constant_values=0) for a in arrays)\n            self.padded = True\n        else:\n            results = tuple(arrays)\n            self.padded = False\n        for a in results:\n            # MCX requires NAN values to store photon direction and reflectance when using float mus and mua\n            a[a == 0] = np.nan\n        return results",
  "def post_process_volumes(self, **kwargs):\n        \"\"\"\n        post-processes volumes after MCX simulations. Dummy function implemented for compatibility with inherited\n        classes. Removes layer padded by `self.pre_process_volumes` if it was added and transforms `np.nan -> 0`.\n\n        :param kwargs: dictionary containing at least the key `volumes` to be transformed\n        :return:\n        \"\"\"\n        arrays = kwargs.get('arrays')\n        if self.padded:\n            results = tuple(a[..., 1:] for a in arrays)\n        else:\n            results = tuple(arrays)\n        for a in results:\n            # revert nan transformation that was done while pre-processing volumes\n            a[np.isnan(a)] = 0.\n        return results",
  "def run_forward_model(self,\n                          _device,\n                          device: Union[IlluminationGeometryBase, PhotoacousticDevice],\n                          absorption: np.ndarray,\n                          scattering: np.ndarray,\n                          anisotropy: np.ndarray\n                          ) -> Dict:\n        \"\"\"\n        runs `self.forward_model` as many times as defined by `device` and aggregates the results.\n\n        :param _device: device illumination geometry\n        :param device: class defining illumination\n        :param absorption: Absorption volume\n        :param scattering: Scattering volume\n        :param anisotropy: Dimensionless scattering anisotropy\n        :return:\n        \"\"\"\n        reflectance = []\n        reflectance_position = []\n        photon_position = []\n        photon_direction = []\n        if isinstance(_device, list):\n            # per convention this list has at least two elements\n            results = self.forward_model(absorption_cm=absorption,\n                                         scattering_cm=scattering,\n                                         anisotropy=anisotropy,\n                                         illumination_geometry=_device[0])\n            self._append_results(results=results,\n                                 reflectance=reflectance,\n                                 reflectance_position=reflectance_position,\n                                 photon_position=photon_position,\n                                 photon_direction=photon_direction)\n            fluence = results[Tags.DATA_FIELD_FLUENCE]\n            for idx in range(1, len(_device)):\n                # we already looked at the 0th element, so go from 1 to n-1\n                results = self.forward_model(absorption_cm=absorption,\n                                             scattering_cm=scattering,\n                                             anisotropy=anisotropy,\n                                             illumination_geometry=_device[idx])\n                self._append_results(results=results,\n                                     reflectance=reflectance,\n                                     reflectance_position=reflectance_position,\n                                     photon_position=photon_position,\n                                     photon_direction=photon_direction)\n                fluence += results[Tags.DATA_FIELD_FLUENCE]\n\n            fluence = fluence / len(_device)\n\n        else:\n            results = self.forward_model(absorption_cm=absorption,\n                                         scattering_cm=scattering,\n                                         anisotropy=anisotropy,\n                                         illumination_geometry=_device)\n            self._append_results(results=results,\n                                 reflectance=reflectance,\n                                 reflectance_position=reflectance_position,\n                                 photon_position=photon_position,\n                                 photon_direction=photon_direction)\n            fluence = results[Tags.DATA_FIELD_FLUENCE]\n        aggregated_results = dict()\n        aggregated_results[Tags.DATA_FIELD_FLUENCE] = fluence\n        if reflectance:\n            aggregated_results[Tags.DATA_FIELD_DIFFUSE_REFLECTANCE] = np.concatenate(reflectance, axis=0)\n            aggregated_results[Tags.DATA_FIELD_DIFFUSE_REFLECTANCE_POS] = np.concatenate(reflectance_position, axis=0)\n        if photon_position:\n            aggregated_results[Tags.DATA_FIELD_PHOTON_EXIT_POS] = np.concatenate(photon_position, axis=0)\n            aggregated_results[Tags.DATA_FIELD_PHOTON_EXIT_DIR] = np.concatenate(photon_direction, axis=0)\n        return aggregated_results",
  "def _append_results(results,\n                        reflectance,\n                        reflectance_position,\n                        photon_position,\n                        photon_direction):\n        if Tags.DATA_FIELD_DIFFUSE_REFLECTANCE in results:\n            reflectance.append(results[Tags.DATA_FIELD_DIFFUSE_REFLECTANCE])\n            reflectance_position.append(results[Tags.DATA_FIELD_DIFFUSE_REFLECTANCE_POS])\n        if Tags.DATA_FIELD_PHOTON_EXIT_POS in results:\n            photon_position.append(results[Tags.DATA_FIELD_PHOTON_EXIT_POS])\n            photon_direction.append(results[Tags.DATA_FIELD_PHOTON_EXIT_DIR])",
  "class OpticalForwardModelTestAdapter(OpticalForwardModuleBase):\n    \"\"\"\n    This Adapter was created for testing purposes and only\n    \"\"\"\n\n    def forward_model(self, absorption_cm, scattering_cm, anisotropy, illumination_geometry):\n        results = {Tags.DATA_FIELD_FLUENCE: absorption_cm / ((1 - anisotropy) * scattering_cm)}\n        return results",
  "def forward_model(self, absorption_cm, scattering_cm, anisotropy, illumination_geometry):\n        results = {Tags.DATA_FIELD_FLUENCE: absorption_cm / ((1 - anisotropy) * scattering_cm)}\n        return results",
  "class DigitalDeviceTwinBase(SerializableSIMPAClass):\n    \"\"\"\n    This class represents a device that can be used for illumination, detection or a combined photoacoustic device\n    which has representations of both.\n    \"\"\"\n\n    def __init__(self, device_position_mm=None, field_of_view_extent_mm=None):\n        \"\"\"\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of e.g. detector element positions or illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        if device_position_mm is None:\n            self.device_position_mm = np.array([0, 0, 0])\n        else:\n            self.device_position_mm = device_position_mm\n\n        if field_of_view_extent_mm is None:\n            self.field_of_view_extent_mm = np.asarray([-10, 10, -10, 10, -10, 10])\n        else:\n            self.field_of_view_extent_mm = field_of_view_extent_mm\n\n        self.logger = Logger()\n\n    def __eq__(self, other):\n        \"\"\"\n        Checks each key, value pair in the devices.\n        \"\"\"\n        if isinstance(other, DigitalDeviceTwinBase):\n            if self.__dict__.keys() != other.__dict__.keys():\n                return False\n            for self_key, self_value in self.__dict__.items():\n                other_value = other.__dict__[self_key]\n                if isinstance(self_value, np.ndarray):\n                    boolean = (other_value != self_value).all()\n                else:\n                    boolean = other_value != self_value\n                if boolean:\n                    return False\n                else:\n                    continue\n            return True\n        return False\n\n    @abstractmethod\n    def check_settings_prerequisites(self, global_settings) -> bool:\n        \"\"\"\n        It might be that certain device geometries need a certain dimensionality of the simulated PAI volume, or that\n        it requires the existence of certain Tags in the global global_settings.\n        To this end, a  PAI device should use this method to inform the user about a mismatch of the desired device and\n        throw a ValueError if that is the case.\n\n        :param global_settings: Settings for the entire simulation pipeline.\n        :type global_settings: Settings\n\n        :raises ValueError: raises a value error if the prerequisites are not matched.\n        :returns: True if the prerequisites are met, False if they are not met, but no exception has been raised.\n        :rtype: bool\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_settings_for_use_of_model_based_volume_creator(self, global_settings):\n        \"\"\"\n        This method can be overwritten by a PA device if the device poses special constraints to the\n        volume that should be considered by the model-based volume creator.\n\n        :param global_settings: Settings for the entire simulation pipeline.\n        :type global_settings: Settings\n        \"\"\"\n        pass\n\n    def get_field_of_view_mm(self) -> np.ndarray:\n        \"\"\"\n        Returns the absolute field of view in mm where the probe position is already\n        accounted for.\n        It is defined as a numpy array of the shape [xs, xe, ys, ye, zs, ze],\n        where x, y, and z denote the coordinate axes and s and e denote the start and end\n        positions.\n\n        :return: Absolute field of view in mm where the probe position is already accounted for.\n        :rtype: ndarray\n        \"\"\"\n        position = self.device_position_mm\n        field_of_view_extent = self.field_of_view_extent_mm\n\n        field_of_view = np.asarray([position[0] + field_of_view_extent[0],\n                                    position[0] + field_of_view_extent[1],\n                                    position[1] + field_of_view_extent[2],\n                                    position[1] + field_of_view_extent[3],\n                                    position[2] + field_of_view_extent[4],\n                                    position[2] + field_of_view_extent[5]\n                                    ])\n        if min(field_of_view) < 0:\n            self.logger.warning(f\"The field of view of the chosen device is not fully within the simulated volume, \"\n                                f\"field of view is: {field_of_view}\")\n            field_of_view[field_of_view < 0] = 0\n\n        return field_of_view\n\n    def generate_uuid(self):\n        \"\"\"\n        Generates a universally unique identifier (uuid) for each device.\n        :return:\n        \"\"\"\n        class_dict = self.__dict__\n        m = hashlib.md5()\n        m.update(str(class_dict).encode('utf-8'))\n        return str(uuid.UUID(m.hexdigest()))\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {\"DigitalDeviceTwinBase\": serialized_device}\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = DigitalDeviceTwinBase(\n            device_position_mm=dictionary_to_deserialize[\"device_position_mm\"],\n            field_of_view_extent_mm=dictionary_to_deserialize[\"field_of_view_extent_mm\"])\n        return deserialized_device",
  "class PhotoacousticDevice(DigitalDeviceTwinBase, ABC):\n    \"\"\"Base class of a photoacoustic device. It consists of one detection geometry that describes the geometry of the\n    single detector elements and a list of illuminators.\n\n    A Photoacoustic Device can be initialized as follows::\n\n        import simpa as sp\n        import numpy as np\n\n        # Initialise a PhotoacousticDevice with its position and field of view\n        device = sp.PhotoacousticDevice(device_position_mm=np.array([10, 10, 0]),\n            field_of_view_extent_mm=np.array([-20, 20, 0, 0, 0, 20]))\n\n        # Option 1) Set the detection geometry position relative to the PhotoacousticDevice\n        device.set_detection_geometry(sp.DetectionGeometry(),\n            detector_position_relative_to_pa_device=np.array([0, 0, -10]))\n\n        # Option 2) Set the detection geometry position absolute\n        device.set_detection_geometry(\n            sp.DetectionGeometryBase(device_position_mm=np.array([10, 10, -10])))\n\n        # Option 1) Add the illumination geometry position relative to the PhotoacousticDevice\n        device.add_illumination_geometry(sp.IlluminationGeometry(),\n            illuminator_position_relative_to_pa_device=np.array([0, 0, 0]))\n\n        # Option 2) Add the illumination geometry position absolute\n        device.add_illumination_geometry(\n            sp.IlluminationGeometryBase(device_position_mm=np.array([10, 10, 0]))\n\n    Attributes:\n        detection_geometry (DetectionGeometryBase): Geometry of the detector elements.\n        illumination_geometries (list): List of illuminations defined by :py:class:`IlluminationGeometryBase`.\n    \"\"\"\n\n    def __init__(self, device_position_mm=None, field_of_view_extent_mm=None):\n        \"\"\"\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of e.g. detector element positions or illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(PhotoacousticDevice, self).__init__(device_position_mm=device_position_mm,\n                                                  field_of_view_extent_mm=field_of_view_extent_mm)\n        self.detection_geometry = None\n        self.illumination_geometries = []\n\n    def set_detection_geometry(self, detection_geometry,\n                               detector_position_relative_to_pa_device=None):\n        \"\"\"Sets the detection geometry for the PA device. The detection geometry can be instantiated with an absolute\n        position or it can be instantiated without the device_position_mm argument but a position relative to the\n        position of the PhotoacousticDevice. If both absolute and relative positions are given, the absolute position\n        is chosen as position of the detection geometry.\n\n        :param detection_geometry: Detection geometry of the PA device.\n        :type detection_geometry: DetectionGeometryBase\n        :param detector_position_relative_to_pa_device: Position of the detection geometry relative to the PA device.\n        :type detector_position_relative_to_pa_device: ndarray\n        :raises ValueError: if the detection_geometry is None\n\n        \"\"\"\n        if detection_geometry is None:\n            msg = \"The given detection_geometry must not be None!\"\n            self.logger.critical(msg)\n            raise ValueError(msg)\n        if np.linalg.norm(detection_geometry.device_position_mm) == 0 and \\\n                detector_position_relative_to_pa_device is not None:\n            detection_geometry.device_position_mm = np.add(self.device_position_mm,\n                                                           detector_position_relative_to_pa_device)\n        self.detection_geometry = detection_geometry\n\n    def add_illumination_geometry(self, illumination_geometry, illuminator_position_relative_to_pa_device=None):\n        \"\"\"Adds an illuminator to the PA device. The illumination geometry can be instantiated with an absolute\n        position or it can be instantiated without the device_position_mm argument but a position relative to the\n        position of the PhotoacousticDevice. If both absolute and relative positions are given, the absolute position\n        is chosen as position of the illumination geometry.\n\n        :param illumination_geometry: Geometry of the illuminator.\n        :type illumination_geometry: IlluminationGeometryBase\n        :param illuminator_position_relative_to_pa_device: Position of the illuminator relative to the PA device.\n        :type illuminator_position_relative_to_pa_device: ndarray\n        :raises ValueError: if the illumination_geometry is None\n\n        \"\"\"\n        if illumination_geometry is None:\n            msg = \"The given illumination_geometry must not be None!\"\n            self.logger.critical(msg)\n            raise ValueError(msg)\n        if np.linalg.norm(illumination_geometry.device_position_mm) == 0:\n            if illuminator_position_relative_to_pa_device is not None:\n                illumination_geometry.device_position_mm = np.add(self.device_position_mm,\n                                                                  illuminator_position_relative_to_pa_device)\n            else:\n                illumination_geometry.device_position_mm = self.device_position_mm\n        self.illumination_geometries.append(illumination_geometry)\n\n    def get_detection_geometry(self):\n        \"\"\"\n        :return: None if no detection geometry was set or an instance of DetectionGeometryBase.\n        :rtype: None, DetectionGeometryBase\n        \"\"\"\n        return self.detection_geometry\n\n    def get_illumination_geometry(self):\n        \"\"\"\n        :return: None, if no illumination geometry was defined,\n            an instance of IlluminationGeometryBase if exactly one geometry was defined,\n            a list of IlluminationGeometryBase instances if more than one device was defined.\n        :rtype: None, IlluminationGeometryBase\n        \"\"\"\n        if len(self.illumination_geometries) == 0:\n            return None\n\n        if len(self.illumination_geometries) == 1:\n            return self.illumination_geometries[0]\n\n        return self.illumination_geometries\n\n    def check_settings_prerequisites(self, global_settings) -> bool:\n        _result = True\n        if self.detection_geometry is not None \\\n                and not self.detection_geometry.check_settings_prerequisites(global_settings):\n            _result = False\n        for illumination_geometry in self.illumination_geometries:\n            if illumination_geometry is not None \\\n                    and not illumination_geometry.check_settings_prerequisites(global_settings):\n                _result = False\n        return _result\n\n    def update_settings_for_use_of_model_based_volume_creator(self, global_settings):\n        pass\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"PhotoacousticDevice\": serialized_device}\n        return device_dict\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = PhotoacousticDevice(\n            device_position_mm=dictionary_to_deserialize[\"device_position_mm\"],\n            field_of_view_extent_mm=dictionary_to_deserialize[\"field_of_view_extent_mm\"])\n        det_geometry = dictionary_to_deserialize[\"detection_geometry\"]\n        if det_geometry != \"None\":\n            deserialized_device.set_detection_geometry(dictionary_to_deserialize[\"detection_geometry\"])\n        if \"illumination_geometries\" in dictionary_to_deserialize:\n            for illumination_geometry in dictionary_to_deserialize[\"illumination_geometries\"]:\n                deserialized_device.illumination_geometries.append(illumination_geometry)\n\n        return deserialized_device",
  "def __init__(self, device_position_mm=None, field_of_view_extent_mm=None):\n        \"\"\"\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of e.g. detector element positions or illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        if device_position_mm is None:\n            self.device_position_mm = np.array([0, 0, 0])\n        else:\n            self.device_position_mm = device_position_mm\n\n        if field_of_view_extent_mm is None:\n            self.field_of_view_extent_mm = np.asarray([-10, 10, -10, 10, -10, 10])\n        else:\n            self.field_of_view_extent_mm = field_of_view_extent_mm\n\n        self.logger = Logger()",
  "def __eq__(self, other):\n        \"\"\"\n        Checks each key, value pair in the devices.\n        \"\"\"\n        if isinstance(other, DigitalDeviceTwinBase):\n            if self.__dict__.keys() != other.__dict__.keys():\n                return False\n            for self_key, self_value in self.__dict__.items():\n                other_value = other.__dict__[self_key]\n                if isinstance(self_value, np.ndarray):\n                    boolean = (other_value != self_value).all()\n                else:\n                    boolean = other_value != self_value\n                if boolean:\n                    return False\n                else:\n                    continue\n            return True\n        return False",
  "def check_settings_prerequisites(self, global_settings) -> bool:\n        \"\"\"\n        It might be that certain device geometries need a certain dimensionality of the simulated PAI volume, or that\n        it requires the existence of certain Tags in the global global_settings.\n        To this end, a  PAI device should use this method to inform the user about a mismatch of the desired device and\n        throw a ValueError if that is the case.\n\n        :param global_settings: Settings for the entire simulation pipeline.\n        :type global_settings: Settings\n\n        :raises ValueError: raises a value error if the prerequisites are not matched.\n        :returns: True if the prerequisites are met, False if they are not met, but no exception has been raised.\n        :rtype: bool\n\n        \"\"\"\n        pass",
  "def update_settings_for_use_of_model_based_volume_creator(self, global_settings):\n        \"\"\"\n        This method can be overwritten by a PA device if the device poses special constraints to the\n        volume that should be considered by the model-based volume creator.\n\n        :param global_settings: Settings for the entire simulation pipeline.\n        :type global_settings: Settings\n        \"\"\"\n        pass",
  "def get_field_of_view_mm(self) -> np.ndarray:\n        \"\"\"\n        Returns the absolute field of view in mm where the probe position is already\n        accounted for.\n        It is defined as a numpy array of the shape [xs, xe, ys, ye, zs, ze],\n        where x, y, and z denote the coordinate axes and s and e denote the start and end\n        positions.\n\n        :return: Absolute field of view in mm where the probe position is already accounted for.\n        :rtype: ndarray\n        \"\"\"\n        position = self.device_position_mm\n        field_of_view_extent = self.field_of_view_extent_mm\n\n        field_of_view = np.asarray([position[0] + field_of_view_extent[0],\n                                    position[0] + field_of_view_extent[1],\n                                    position[1] + field_of_view_extent[2],\n                                    position[1] + field_of_view_extent[3],\n                                    position[2] + field_of_view_extent[4],\n                                    position[2] + field_of_view_extent[5]\n                                    ])\n        if min(field_of_view) < 0:\n            self.logger.warning(f\"The field of view of the chosen device is not fully within the simulated volume, \"\n                                f\"field of view is: {field_of_view}\")\n            field_of_view[field_of_view < 0] = 0\n\n        return field_of_view",
  "def generate_uuid(self):\n        \"\"\"\n        Generates a universally unique identifier (uuid) for each device.\n        :return:\n        \"\"\"\n        class_dict = self.__dict__\n        m = hashlib.md5()\n        m.update(str(class_dict).encode('utf-8'))\n        return str(uuid.UUID(m.hexdigest()))",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {\"DigitalDeviceTwinBase\": serialized_device}",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = DigitalDeviceTwinBase(\n            device_position_mm=dictionary_to_deserialize[\"device_position_mm\"],\n            field_of_view_extent_mm=dictionary_to_deserialize[\"field_of_view_extent_mm\"])\n        return deserialized_device",
  "def __init__(self, device_position_mm=None, field_of_view_extent_mm=None):\n        \"\"\"\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of e.g. detector element positions or illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(PhotoacousticDevice, self).__init__(device_position_mm=device_position_mm,\n                                                  field_of_view_extent_mm=field_of_view_extent_mm)\n        self.detection_geometry = None\n        self.illumination_geometries = []",
  "def set_detection_geometry(self, detection_geometry,\n                               detector_position_relative_to_pa_device=None):\n        \"\"\"Sets the detection geometry for the PA device. The detection geometry can be instantiated with an absolute\n        position or it can be instantiated without the device_position_mm argument but a position relative to the\n        position of the PhotoacousticDevice. If both absolute and relative positions are given, the absolute position\n        is chosen as position of the detection geometry.\n\n        :param detection_geometry: Detection geometry of the PA device.\n        :type detection_geometry: DetectionGeometryBase\n        :param detector_position_relative_to_pa_device: Position of the detection geometry relative to the PA device.\n        :type detector_position_relative_to_pa_device: ndarray\n        :raises ValueError: if the detection_geometry is None\n\n        \"\"\"\n        if detection_geometry is None:\n            msg = \"The given detection_geometry must not be None!\"\n            self.logger.critical(msg)\n            raise ValueError(msg)\n        if np.linalg.norm(detection_geometry.device_position_mm) == 0 and \\\n                detector_position_relative_to_pa_device is not None:\n            detection_geometry.device_position_mm = np.add(self.device_position_mm,\n                                                           detector_position_relative_to_pa_device)\n        self.detection_geometry = detection_geometry",
  "def add_illumination_geometry(self, illumination_geometry, illuminator_position_relative_to_pa_device=None):\n        \"\"\"Adds an illuminator to the PA device. The illumination geometry can be instantiated with an absolute\n        position or it can be instantiated without the device_position_mm argument but a position relative to the\n        position of the PhotoacousticDevice. If both absolute and relative positions are given, the absolute position\n        is chosen as position of the illumination geometry.\n\n        :param illumination_geometry: Geometry of the illuminator.\n        :type illumination_geometry: IlluminationGeometryBase\n        :param illuminator_position_relative_to_pa_device: Position of the illuminator relative to the PA device.\n        :type illuminator_position_relative_to_pa_device: ndarray\n        :raises ValueError: if the illumination_geometry is None\n\n        \"\"\"\n        if illumination_geometry is None:\n            msg = \"The given illumination_geometry must not be None!\"\n            self.logger.critical(msg)\n            raise ValueError(msg)\n        if np.linalg.norm(illumination_geometry.device_position_mm) == 0:\n            if illuminator_position_relative_to_pa_device is not None:\n                illumination_geometry.device_position_mm = np.add(self.device_position_mm,\n                                                                  illuminator_position_relative_to_pa_device)\n            else:\n                illumination_geometry.device_position_mm = self.device_position_mm\n        self.illumination_geometries.append(illumination_geometry)",
  "def get_detection_geometry(self):\n        \"\"\"\n        :return: None if no detection geometry was set or an instance of DetectionGeometryBase.\n        :rtype: None, DetectionGeometryBase\n        \"\"\"\n        return self.detection_geometry",
  "def get_illumination_geometry(self):\n        \"\"\"\n        :return: None, if no illumination geometry was defined,\n            an instance of IlluminationGeometryBase if exactly one geometry was defined,\n            a list of IlluminationGeometryBase instances if more than one device was defined.\n        :rtype: None, IlluminationGeometryBase\n        \"\"\"\n        if len(self.illumination_geometries) == 0:\n            return None\n\n        if len(self.illumination_geometries) == 1:\n            return self.illumination_geometries[0]\n\n        return self.illumination_geometries",
  "def check_settings_prerequisites(self, global_settings) -> bool:\n        _result = True\n        if self.detection_geometry is not None \\\n                and not self.detection_geometry.check_settings_prerequisites(global_settings):\n            _result = False\n        for illumination_geometry in self.illumination_geometries:\n            if illumination_geometry is not None \\\n                    and not illumination_geometry.check_settings_prerequisites(global_settings):\n                _result = False\n        return _result",
  "def update_settings_for_use_of_model_based_volume_creator(self, global_settings):\n        pass",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"PhotoacousticDevice\": serialized_device}\n        return device_dict",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = PhotoacousticDevice(\n            device_position_mm=dictionary_to_deserialize[\"device_position_mm\"],\n            field_of_view_extent_mm=dictionary_to_deserialize[\"field_of_view_extent_mm\"])\n        det_geometry = dictionary_to_deserialize[\"detection_geometry\"]\n        if det_geometry != \"None\":\n            deserialized_device.set_detection_geometry(dictionary_to_deserialize[\"detection_geometry\"])\n        if \"illumination_geometries\" in dictionary_to_deserialize:\n            for illumination_geometry in dictionary_to_deserialize[\"illumination_geometries\"]:\n                deserialized_device.illumination_geometries.append(illumination_geometry)\n\n        return deserialized_device",
  "class PencilBeamIlluminationGeometry(IlluminationGeometryBase):\n    \"\"\"\n    This class represents a pencil beam illumination geometry.\n    The device position is defined as the exact position of the pencil beam.\n    \"\"\"\n\n    def get_mcx_illuminator_definition(self, global_settings) -> dict:\n        source_type = Tags.ILLUMINATION_TYPE_PENCILARRAY\n\n        spacing = global_settings[Tags.SPACING_MM]\n\n        device_position = list(self.device_position_mm / spacing + 0.5)\n\n        source_direction = list(self.normalized_source_direction_vector)\n\n        source_param1 = [0, 0, 0, 0]\n\n        source_param2 = [0, 0, 0, 0]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": list(device_position),\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {\"PencilBeamIlluminationGeometry\": serialized_device}\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = PencilBeamIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def get_mcx_illuminator_definition(self, global_settings) -> dict:\n        source_type = Tags.ILLUMINATION_TYPE_PENCILARRAY\n\n        spacing = global_settings[Tags.SPACING_MM]\n\n        device_position = list(self.device_position_mm / spacing + 0.5)\n\n        source_direction = list(self.normalized_source_direction_vector)\n\n        source_param1 = [0, 0, 0, 0]\n\n        source_param2 = [0, 0, 0, 0]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": list(device_position),\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {\"PencilBeamIlluminationGeometry\": serialized_device}",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = PencilBeamIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class PencilArrayIlluminationGeometry(IlluminationGeometryBase):\n    \"\"\"\n    This class represents a pencil array illumination geometry.\n    The device position is defined as the middle of the array.\n    \"\"\"\n\n    def __init__(self, pitch_mm=0.5, number_illuminators_x=100, number_illuminators_y=100, device_position_mm=None,\n                 field_of_view_extent_mm=None):\n        \"\"\"\n        :param pitch_mm: Defines the x and y distance between the illumination positions\n        :type pitch_mm: float\n        :param number_illuminators_x: Defines the number of illuminators in the x direction\n        :type number_illuminators_x: int\n        :param number_illuminators_y: Defines the number of illuminators in the y direction\n        :type number_illuminators_y: int\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(PencilArrayIlluminationGeometry, self).__init__(device_position_mm=device_position_mm,\n                                                              field_of_view_extent_mm=field_of_view_extent_mm)\n\n        self.pitch_mm = pitch_mm\n        self.number_illuminators_x = number_illuminators_x\n        self.number_illuminators_y = number_illuminators_y\n\n    def get_mcx_illuminator_definition(self, global_settings) -> dict:\n        source_type = Tags.ILLUMINATION_TYPE_PENCILARRAY\n\n        spacing = global_settings[Tags.SPACING_MM]\n\n        device_position = list(self.device_position_mm / spacing + 0.5)\n\n        source_direction = list(self.normalized_source_direction_vector)\n\n        source_param1 = [(self.number_illuminators_x * self.pitch_mm) / spacing,\n                         0,\n                         0, self.number_illuminators_x]\n\n        source_param2 = [0,\n                         (self.number_illuminators_y * self.pitch_mm) / spacing,\n                         0, self.number_illuminators_y]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": device_position,\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"PencilArrayIlluminationGeometry\": serialized_device}\n        return device_dict\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = PencilArrayIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, pitch_mm=0.5, number_illuminators_x=100, number_illuminators_y=100, device_position_mm=None,\n                 field_of_view_extent_mm=None):\n        \"\"\"\n        :param pitch_mm: Defines the x and y distance between the illumination positions\n        :type pitch_mm: float\n        :param number_illuminators_x: Defines the number of illuminators in the x direction\n        :type number_illuminators_x: int\n        :param number_illuminators_y: Defines the number of illuminators in the y direction\n        :type number_illuminators_y: int\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(PencilArrayIlluminationGeometry, self).__init__(device_position_mm=device_position_mm,\n                                                              field_of_view_extent_mm=field_of_view_extent_mm)\n\n        self.pitch_mm = pitch_mm\n        self.number_illuminators_x = number_illuminators_x\n        self.number_illuminators_y = number_illuminators_y",
  "def get_mcx_illuminator_definition(self, global_settings) -> dict:\n        source_type = Tags.ILLUMINATION_TYPE_PENCILARRAY\n\n        spacing = global_settings[Tags.SPACING_MM]\n\n        device_position = list(self.device_position_mm / spacing + 0.5)\n\n        source_direction = list(self.normalized_source_direction_vector)\n\n        source_param1 = [(self.number_illuminators_x * self.pitch_mm) / spacing,\n                         0,\n                         0, self.number_illuminators_x]\n\n        source_param2 = [0,\n                         (self.number_illuminators_y * self.pitch_mm) / spacing,\n                         0, self.number_illuminators_y]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": device_position,\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"PencilArrayIlluminationGeometry\": serialized_device}\n        return device_dict",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = PencilArrayIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class SlitIlluminationGeometry(IlluminationGeometryBase):\n    \"\"\"\n    This class represents a slit illumination geometry.\n    The device position is defined as the middle of the slit.\n    \"\"\"\n\n    def __init__(self, slit_vector_mm=None, direction_vector_mm=None, device_position_mm=None,\n                 field_of_view_extent_mm=None):\n        \"\"\"\n        :param slit_vector_mm: Defines the slit in vector form. For example a slit along the x-axis with length 5mm\n            would be defined as [5, 0, 0].\n        :type slit_vector_mm: list\n        :param direction_vector_mm: Direction vector in which the slit illuminates.\n            Defined analogous to the slit vector.\n        :type direction_vector_mm: list\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(SlitIlluminationGeometry, self).__init__(device_position_mm=device_position_mm,\n                                                       field_of_view_extent_mm=field_of_view_extent_mm)\n\n        if slit_vector_mm is None:\n            slit_vector_mm = [5, 0, 0]\n\n        if direction_vector_mm is None:\n            direction_vector_mm = [0, 0, 1]\n\n        self.slit_vector_mm = slit_vector_mm\n        direction_vector_mm[0] = direction_vector_mm[0] / np.linalg.norm(direction_vector_mm)\n        direction_vector_mm[1] = direction_vector_mm[1] / np.linalg.norm(direction_vector_mm)\n        direction_vector_mm[2] = direction_vector_mm[2] / np.linalg.norm(direction_vector_mm)\n        self.direction_vector_norm = direction_vector_mm\n\n    def get_mcx_illuminator_definition(self, global_settings) -> dict:\n        source_type = Tags.ILLUMINATION_TYPE_SLIT\n\n        spacing = global_settings[Tags.SPACING_MM]\n\n        device_position = (self.device_position_mm/spacing) + 0.5 - 0.5 * np.array(self.slit_vector_mm)/spacing\n\n        self.logger.debug(device_position)\n\n        source_direction = list(self.normalized_source_direction_vector)\n\n        source_param1 = [self.slit_vector_mm[0]/spacing,\n                         self.slit_vector_mm[1]/spacing,\n                         self.slit_vector_mm[2]/spacing, 0]\n\n        source_param2 = [0, 0, 0, 0]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": list(device_position),\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"SlitIlluminationGeometry\": serialized_device}\n        return device_dict\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = SlitIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, slit_vector_mm=None, direction_vector_mm=None, device_position_mm=None,\n                 field_of_view_extent_mm=None):\n        \"\"\"\n        :param slit_vector_mm: Defines the slit in vector form. For example a slit along the x-axis with length 5mm\n            would be defined as [5, 0, 0].\n        :type slit_vector_mm: list\n        :param direction_vector_mm: Direction vector in which the slit illuminates.\n            Defined analogous to the slit vector.\n        :type direction_vector_mm: list\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(SlitIlluminationGeometry, self).__init__(device_position_mm=device_position_mm,\n                                                       field_of_view_extent_mm=field_of_view_extent_mm)\n\n        if slit_vector_mm is None:\n            slit_vector_mm = [5, 0, 0]\n\n        if direction_vector_mm is None:\n            direction_vector_mm = [0, 0, 1]\n\n        self.slit_vector_mm = slit_vector_mm\n        direction_vector_mm[0] = direction_vector_mm[0] / np.linalg.norm(direction_vector_mm)\n        direction_vector_mm[1] = direction_vector_mm[1] / np.linalg.norm(direction_vector_mm)\n        direction_vector_mm[2] = direction_vector_mm[2] / np.linalg.norm(direction_vector_mm)\n        self.direction_vector_norm = direction_vector_mm",
  "def get_mcx_illuminator_definition(self, global_settings) -> dict:\n        source_type = Tags.ILLUMINATION_TYPE_SLIT\n\n        spacing = global_settings[Tags.SPACING_MM]\n\n        device_position = (self.device_position_mm/spacing) + 0.5 - 0.5 * np.array(self.slit_vector_mm)/spacing\n\n        self.logger.debug(device_position)\n\n        source_direction = list(self.normalized_source_direction_vector)\n\n        source_param1 = [self.slit_vector_mm[0]/spacing,\n                         self.slit_vector_mm[1]/spacing,\n                         self.slit_vector_mm[2]/spacing, 0]\n\n        source_param2 = [0, 0, 0, 0]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": list(device_position),\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"SlitIlluminationGeometry\": serialized_device}\n        return device_dict",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = SlitIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class DiskIlluminationGeometry(IlluminationGeometryBase):\n    \"\"\"\n    This class represents a disk illumination geometry.\n    The device position is defined as the middle of the disk.\n    \"\"\"\n\n    def __init__(self, beam_radius_mm=None, device_position_mm=None, field_of_view_extent_mm=None):\n        \"\"\"\n        :param beam_radius_mm: Radius of the disk in mm.\n        :type beam_radius_mm: int, float\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(DiskIlluminationGeometry, self).__init__(device_position_mm=device_position_mm,\n                                                       field_of_view_extent_mm=field_of_view_extent_mm)\n        if beam_radius_mm is None:\n            beam_radius_mm = 1\n\n        self.beam_radius_mm = beam_radius_mm\n\n    def get_mcx_illuminator_definition(self, global_settings) -> dict:\n        source_type = Tags.ILLUMINATION_TYPE_DISK\n\n        spacing = global_settings[Tags.SPACING_MM]\n\n        device_position = list(self.device_position_mm / spacing + 0.5)\n\n        source_direction = list(self.normalized_source_direction_vector)\n\n        source_param1 = [int(round(self.beam_radius_mm / spacing)), 0, 0, 0]\n\n        source_param2 = [0, 0, 0, 0]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": device_position,\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"DiskIlluminationGeometry\": serialized_device}\n        return device_dict\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = DiskIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, beam_radius_mm=None, device_position_mm=None, field_of_view_extent_mm=None):\n        \"\"\"\n        :param beam_radius_mm: Radius of the disk in mm.\n        :type beam_radius_mm: int, float\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(DiskIlluminationGeometry, self).__init__(device_position_mm=device_position_mm,\n                                                       field_of_view_extent_mm=field_of_view_extent_mm)\n        if beam_radius_mm is None:\n            beam_radius_mm = 1\n\n        self.beam_radius_mm = beam_radius_mm",
  "def get_mcx_illuminator_definition(self, global_settings) -> dict:\n        source_type = Tags.ILLUMINATION_TYPE_DISK\n\n        spacing = global_settings[Tags.SPACING_MM]\n\n        device_position = list(self.device_position_mm / spacing + 0.5)\n\n        source_direction = list(self.normalized_source_direction_vector)\n\n        source_param1 = [int(round(self.beam_radius_mm / spacing)), 0, 0, 0]\n\n        source_param2 = [0, 0, 0, 0]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": device_position,\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"DiskIlluminationGeometry\": serialized_device}\n        return device_dict",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = DiskIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class GaussianBeamIlluminationGeometry(IlluminationGeometryBase):\n    \"\"\"\n    This class represents a Gaussian beam illumination geometry.\n    The position is defined as the middle of the beam.\n    \"\"\"\n\n    def __init__(self, beam_radius_mm=None, focal_length_mm=None, device_position_mm=None,\n                 field_of_view_extent_mm=None):\n        \"\"\"\n        :param beam_radius_mm: Initial radius of the gaussian beam at half maximum (full width at half maximum (FWHM))\n        in mm.\n        :type beam_radius_mm: int, float\n        :param focal_length_mm: Focal length of the gaussian beam in mm. Can be positive (focussed beam), negative\n        (cone-shaped beam) or None (collimated beam).\n        :type focal_length_mm: int, float\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(GaussianBeamIlluminationGeometry, self).__init__(device_position_mm=device_position_mm,\n                                                               field_of_view_extent_mm=field_of_view_extent_mm)\n\n        if beam_radius_mm is None:\n            beam_radius_mm = 0\n\n        self.beam_radius_mm = beam_radius_mm\n        self.focal_length_mm = focal_length_mm\n\n    def get_mcx_illuminator_definition(self, global_settings) -> dict:\n        source_type = Tags.ILLUMINATION_TYPE_GAUSSIAN\n\n        spacing = global_settings[Tags.SPACING_MM]\n\n        device_position = list(self.device_position_mm / spacing + 0.5)\n\n        source_direction = list(self.normalized_source_direction_vector)\n        if self.focal_length_mm is not None:  # the focal length can optionally be added as 4th parameter\n            source_direction.append(self.focal_length_mm / spacing)\n\n        # mcx takes the beam_radius in at the 1/e^2 (2 * sigma) threshold, but we use FWHM (sqrt(2*ln2))*sigma)\n        # by multiplying the input radius by (2 / sqrt(2 * log(2))) we can convert it\n        source_param1 = [self.beam_radius_mm / spacing * 2 / sqrt(2 * log(2)), 0, 0, 0]\n\n        source_param2 = [0, 0, 0, 0]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": device_position,\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"GaussianBeamIlluminationGeometry\": serialized_device}\n        return device_dict\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = GaussianBeamIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            if not isinstance(value, Sized) and value != 'None':\n                deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, beam_radius_mm=None, focal_length_mm=None, device_position_mm=None,\n                 field_of_view_extent_mm=None):\n        \"\"\"\n        :param beam_radius_mm: Initial radius of the gaussian beam at half maximum (full width at half maximum (FWHM))\n        in mm.\n        :type beam_radius_mm: int, float\n        :param focal_length_mm: Focal length of the gaussian beam in mm. Can be positive (focussed beam), negative\n        (cone-shaped beam) or None (collimated beam).\n        :type focal_length_mm: int, float\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(GaussianBeamIlluminationGeometry, self).__init__(device_position_mm=device_position_mm,\n                                                               field_of_view_extent_mm=field_of_view_extent_mm)\n\n        if beam_radius_mm is None:\n            beam_radius_mm = 0\n\n        self.beam_radius_mm = beam_radius_mm\n        self.focal_length_mm = focal_length_mm",
  "def get_mcx_illuminator_definition(self, global_settings) -> dict:\n        source_type = Tags.ILLUMINATION_TYPE_GAUSSIAN\n\n        spacing = global_settings[Tags.SPACING_MM]\n\n        device_position = list(self.device_position_mm / spacing + 0.5)\n\n        source_direction = list(self.normalized_source_direction_vector)\n        if self.focal_length_mm is not None:  # the focal length can optionally be added as 4th parameter\n            source_direction.append(self.focal_length_mm / spacing)\n\n        # mcx takes the beam_radius in at the 1/e^2 (2 * sigma) threshold, but we use FWHM (sqrt(2*ln2))*sigma)\n        # by multiplying the input radius by (2 / sqrt(2 * log(2))) we can convert it\n        source_param1 = [self.beam_radius_mm / spacing * 2 / sqrt(2 * log(2)), 0, 0, 0]\n\n        source_param2 = [0, 0, 0, 0]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": device_position,\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"GaussianBeamIlluminationGeometry\": serialized_device}\n        return device_dict",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = GaussianBeamIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            if not isinstance(value, Sized) and value != 'None':\n                deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class IlluminationGeometryBase(DigitalDeviceTwinBase):\n    \"\"\"\n    This class is the base class for representing all illumination geometries.\n    \"\"\"\n\n    def __init__(self, device_position_mm=None, source_direction_vector=None, field_of_view_extent_mm=None):\n        \"\"\"\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of illuminator positions.\n        :type device_position_mm: ndarray\n\n        :param source_direction_vector: Direction of the illumination source.\n        :type source_direction_vector: ndarray\n\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(IlluminationGeometryBase, self).__init__(device_position_mm=device_position_mm,\n                                                       field_of_view_extent_mm=field_of_view_extent_mm)\n\n        if source_direction_vector is None:\n            self.source_direction_vector = [0, 0, 1]\n        else:\n            self.source_direction_vector = source_direction_vector\n        self.normalized_source_direction_vector = self.source_direction_vector / np.linalg.norm(\n            self.source_direction_vector)\n\n    @abstractmethod\n    def get_mcx_illuminator_definition(self, global_settings) -> dict:\n        \"\"\"\n        IMPORTANT: This method creates a dictionary that contains tags as they are expected for the\n        mcx simulation tool to represent the illumination geometry of this device.\n\n        :param global_settings: The global_settings instance containing the simulation instructions.\n        :type global_settings: Settings\n\n        :return: Dictionary that includes all parameters needed for mcx.\n        :rtype: dict\n        \"\"\"\n        pass\n\n    def check_settings_prerequisites(self, global_settings) -> bool:\n        return True\n\n    def update_settings_for_use_of_model_based_volume_creator(self, global_settings) -> Settings:\n        return global_settings\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"IlluminationGeometryBase\": serialized_device}\n        return device_dict\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = IlluminationGeometryBase()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, device_position_mm=None, source_direction_vector=None, field_of_view_extent_mm=None):\n        \"\"\"\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of illuminator positions.\n        :type device_position_mm: ndarray\n\n        :param source_direction_vector: Direction of the illumination source.\n        :type source_direction_vector: ndarray\n\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(IlluminationGeometryBase, self).__init__(device_position_mm=device_position_mm,\n                                                       field_of_view_extent_mm=field_of_view_extent_mm)\n\n        if source_direction_vector is None:\n            self.source_direction_vector = [0, 0, 1]\n        else:\n            self.source_direction_vector = source_direction_vector\n        self.normalized_source_direction_vector = self.source_direction_vector / np.linalg.norm(\n            self.source_direction_vector)",
  "def get_mcx_illuminator_definition(self, global_settings) -> dict:\n        \"\"\"\n        IMPORTANT: This method creates a dictionary that contains tags as they are expected for the\n        mcx simulation tool to represent the illumination geometry of this device.\n\n        :param global_settings: The global_settings instance containing the simulation instructions.\n        :type global_settings: Settings\n\n        :return: Dictionary that includes all parameters needed for mcx.\n        :rtype: dict\n        \"\"\"\n        pass",
  "def check_settings_prerequisites(self, global_settings) -> bool:\n        return True",
  "def update_settings_for_use_of_model_based_volume_creator(self, global_settings) -> Settings:\n        return global_settings",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"IlluminationGeometryBase\": serialized_device}\n        return device_dict",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = IlluminationGeometryBase()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class MSOTAcuityIlluminationGeometry(IlluminationGeometryBase):\n    \"\"\"\n    This class represents the illumination geometry of the MSOT Acuity (Echo) photoacoustic device.\n    The position is defined as the middle of the illumination slit.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the illumination source.\n        \"\"\"\n        super().__init__()\n\n        # y position relative to the membrane:\n        # The laser is located 43.2 mm  behind the membrane with an angle of 22.4 degrees.\n        # However, the incident of laser and image plane is located 2.8 behind the membrane (outside of the device).\n        y_pos_relative_to_membrane = np.tan(np.deg2rad(22.4)) * (43.2 + 2.8)\n\n        direction_vector = np.array([0, y_pos_relative_to_membrane, 43.2 + 2.8])\n        self.source_direction_vector = direction_vector/np.linalg.norm(direction_vector)\n        self.normalized_source_direction_vector = self.source_direction_vector / np.linalg.norm(\n            self.source_direction_vector)\n\n    def get_mcx_illuminator_definition(self, global_settings: Settings):\n\n        source_type = Tags.ILLUMINATION_TYPE_MSOT_ACUITY_ECHO\n        spacing = global_settings[Tags.SPACING_MM]\n        device_position = list(self.device_position_mm / spacing + 0.5)\n\n        source_direction = list(self.normalized_source_direction_vector)\n\n        source_param1 = [30 / spacing, 0, 0, 0]\n\n        source_param2 = [0, 0, 0, 0]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": device_position,\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {\"MSOTAcuityIlluminationGeometry\": serialized_device}\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = MSOTAcuityIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self):\n        \"\"\"\n        Initializes the illumination source.\n        \"\"\"\n        super().__init__()\n\n        # y position relative to the membrane:\n        # The laser is located 43.2 mm  behind the membrane with an angle of 22.4 degrees.\n        # However, the incident of laser and image plane is located 2.8 behind the membrane (outside of the device).\n        y_pos_relative_to_membrane = np.tan(np.deg2rad(22.4)) * (43.2 + 2.8)\n\n        direction_vector = np.array([0, y_pos_relative_to_membrane, 43.2 + 2.8])\n        self.source_direction_vector = direction_vector/np.linalg.norm(direction_vector)\n        self.normalized_source_direction_vector = self.source_direction_vector / np.linalg.norm(\n            self.source_direction_vector)",
  "def get_mcx_illuminator_definition(self, global_settings: Settings):\n\n        source_type = Tags.ILLUMINATION_TYPE_MSOT_ACUITY_ECHO\n        spacing = global_settings[Tags.SPACING_MM]\n        device_position = list(self.device_position_mm / spacing + 0.5)\n\n        source_direction = list(self.normalized_source_direction_vector)\n\n        source_param1 = [30 / spacing, 0, 0, 0]\n\n        source_param2 = [0, 0, 0, 0]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": device_position,\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {\"MSOTAcuityIlluminationGeometry\": serialized_device}",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = MSOTAcuityIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class MSOTInVisionIlluminationGeometry(IlluminationGeometryBase):\n    \"\"\"\n    This class represents the illumination geometry of the MSOT InVision photoacoustic device.\n    \"\"\"\n\n    def __init__(self, invision_position=None, geometry_id=0):\n        \"\"\"\n        :param geometry_id: ID of the specific InVision illuminator.\n        :type geometry_id: int\n        \"\"\"\n        super().__init__()\n\n        if invision_position is None:\n            self.invision_position = [0, 0, 0]\n        else:\n            self.invision_position = invision_position\n\n        self.geometry_id = geometry_id\n\n        angle = 0.0\n        det_sep_half = 24.74 / 2\n        detector_iso_distance = 74.05 / 2\n        illumination_angle = -0.41608649\n\n        if geometry_id == 0:\n            angle = 0.0\n        elif geometry_id == 1:\n            angle = 0.0\n            det_sep_half = -det_sep_half\n            illumination_angle = -illumination_angle\n        elif geometry_id == 2:\n            angle = 1.25664\n        elif geometry_id == 3:\n            angle = 1.25664\n            det_sep_half = -det_sep_half\n            illumination_angle = -illumination_angle\n        elif geometry_id == 4:\n            angle = -1.25664\n        elif geometry_id == 5:\n            angle = -1.25664\n            det_sep_half = -det_sep_half\n            illumination_angle = -illumination_angle\n        elif geometry_id == 6:\n            angle = 2.51327\n        elif geometry_id == 7:\n            angle = 2.51327\n            det_sep_half = -det_sep_half\n            illumination_angle = -illumination_angle\n        elif geometry_id == 8:\n            angle = -2.51327\n        elif geometry_id == 9:\n            angle = -2.51327\n            det_sep_half = -det_sep_half\n            illumination_angle = -illumination_angle\n\n        self.device_position_mm = [self.invision_position[0] + np.sin(angle) * detector_iso_distance,\n                                   self.invision_position[1] + det_sep_half,\n                                   self.invision_position[2] + np.cos(angle) * detector_iso_distance]\n\n        self.source_direction_vector = np.array([-np.sin(angle),\n                                                 np.sin(illumination_angle),\n                                                 np.cos(angle)])\n\n        self.normalized_source_direction_vector = self.source_direction_vector / np.linalg.norm(\n            self.source_direction_vector)\n\n    def get_mcx_illuminator_definition(self, global_settings):\n        self.logger.debug(self.invision_position)\n        source_type = Tags.ILLUMINATION_TYPE_MSOT_INVISION\n\n        spacing = global_settings[Tags.SPACING_MM]\n\n        source_position = list(np.array(self.device_position_mm) / spacing + 1)\n\n        source_direction = list(self.normalized_source_direction_vector)\n\n        source_param1 = [spacing, self.geometry_id, 0, 0]\n\n        source_param2 = [0, 0, 0, 0]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": source_position,\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"MSOTInVisionIlluminationGeometry\": serialized_device}\n        return device_dict\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = MSOTInVisionIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, invision_position=None, geometry_id=0):\n        \"\"\"\n        :param geometry_id: ID of the specific InVision illuminator.\n        :type geometry_id: int\n        \"\"\"\n        super().__init__()\n\n        if invision_position is None:\n            self.invision_position = [0, 0, 0]\n        else:\n            self.invision_position = invision_position\n\n        self.geometry_id = geometry_id\n\n        angle = 0.0\n        det_sep_half = 24.74 / 2\n        detector_iso_distance = 74.05 / 2\n        illumination_angle = -0.41608649\n\n        if geometry_id == 0:\n            angle = 0.0\n        elif geometry_id == 1:\n            angle = 0.0\n            det_sep_half = -det_sep_half\n            illumination_angle = -illumination_angle\n        elif geometry_id == 2:\n            angle = 1.25664\n        elif geometry_id == 3:\n            angle = 1.25664\n            det_sep_half = -det_sep_half\n            illumination_angle = -illumination_angle\n        elif geometry_id == 4:\n            angle = -1.25664\n        elif geometry_id == 5:\n            angle = -1.25664\n            det_sep_half = -det_sep_half\n            illumination_angle = -illumination_angle\n        elif geometry_id == 6:\n            angle = 2.51327\n        elif geometry_id == 7:\n            angle = 2.51327\n            det_sep_half = -det_sep_half\n            illumination_angle = -illumination_angle\n        elif geometry_id == 8:\n            angle = -2.51327\n        elif geometry_id == 9:\n            angle = -2.51327\n            det_sep_half = -det_sep_half\n            illumination_angle = -illumination_angle\n\n        self.device_position_mm = [self.invision_position[0] + np.sin(angle) * detector_iso_distance,\n                                   self.invision_position[1] + det_sep_half,\n                                   self.invision_position[2] + np.cos(angle) * detector_iso_distance]\n\n        self.source_direction_vector = np.array([-np.sin(angle),\n                                                 np.sin(illumination_angle),\n                                                 np.cos(angle)])\n\n        self.normalized_source_direction_vector = self.source_direction_vector / np.linalg.norm(\n            self.source_direction_vector)",
  "def get_mcx_illuminator_definition(self, global_settings):\n        self.logger.debug(self.invision_position)\n        source_type = Tags.ILLUMINATION_TYPE_MSOT_INVISION\n\n        spacing = global_settings[Tags.SPACING_MM]\n\n        source_position = list(np.array(self.device_position_mm) / spacing + 1)\n\n        source_direction = list(self.normalized_source_direction_vector)\n\n        source_param1 = [spacing, self.geometry_id, 0, 0]\n\n        source_param2 = [0, 0, 0, 0]\n\n        return {\n            \"Type\": source_type,\n            \"Pos\": source_position,\n            \"Dir\": source_direction,\n            \"Param1\": source_param1,\n            \"Param2\": source_param2\n        }",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"MSOTInVisionIlluminationGeometry\": serialized_device}\n        return device_dict",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = MSOTInVisionIlluminationGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class InVision256TF(PhotoacousticDevice):\n    \"\"\"\n    This class represents a digital twin of the InVision 256-TF, manufactured by iThera Medical, Munich, Germany\n    (https://www.ithera-medical.com/products/msot-invision/). It is based on the real specifications of the device, but\n    due to the limitations of the possibilities how to represent a device in the software frameworks,\n    constitutes only an approximation.\n\n    Some important publications that showcase the use cases of the InVision series devices are::\n\n        Joseph, James, et al. \"Evaluation of precision in optoacoustic tomography\n        for preclinical imaging in living subjects.\"\n        Journal of Nuclear Medicine 58.5 (2017): 807-814.\n\n        Mer\u010dep, Elena, et al. \"Whole-body live mouse imaging by hybrid\n        reflection-mode ultrasound and optoacoustic tomography.\"\n        Optics letters 40.20 (2015): 4643-4646.\n\n    \"\"\"\n\n    def __init__(self, device_position_mm: np.ndarray = None,\n                 field_of_view_extent_mm: np.ndarray = np.asarray([-20, 20, 0, 0, -20, 20])):\n        \"\"\"\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of e.g. detector element positions or illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(InVision256TF, self).__init__(device_position_mm=device_position_mm,\n                                            field_of_view_extent_mm=field_of_view_extent_mm)\n\n        detection_geometry = CurvedArrayDetectionGeometry(pitch_mm=0.735,\n                                                          radius_mm=40,\n                                                          number_detector_elements=256,\n                                                          detector_element_width_mm=0.635,\n                                                          detector_element_length_mm=15,\n                                                          center_frequency_hz=5e6,\n                                                          bandwidth_percent=55,\n                                                          sampling_frequency_mhz=40,\n                                                          angular_origin_offset=0,\n                                                          device_position_mm=device_position_mm,\n                                                          field_of_view_extent_mm=field_of_view_extent_mm)\n\n        self.field_of_view_extent_mm = detection_geometry.field_of_view_extent_mm\n        self.set_detection_geometry(detection_geometry)\n        for i in range(10):\n            self.add_illumination_geometry(MSOTInVisionIlluminationGeometry(invision_position=self.device_position_mm,\n                                                                            geometry_id=i))\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"InVision256TF\": serialized_device}\n        return device_dict\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = InVision256TF()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, device_position_mm: np.ndarray = None,\n                 field_of_view_extent_mm: np.ndarray = np.asarray([-20, 20, 0, 0, -20, 20])):\n        \"\"\"\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of e.g. detector element positions or illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(InVision256TF, self).__init__(device_position_mm=device_position_mm,\n                                            field_of_view_extent_mm=field_of_view_extent_mm)\n\n        detection_geometry = CurvedArrayDetectionGeometry(pitch_mm=0.735,\n                                                          radius_mm=40,\n                                                          number_detector_elements=256,\n                                                          detector_element_width_mm=0.635,\n                                                          detector_element_length_mm=15,\n                                                          center_frequency_hz=5e6,\n                                                          bandwidth_percent=55,\n                                                          sampling_frequency_mhz=40,\n                                                          angular_origin_offset=0,\n                                                          device_position_mm=device_position_mm,\n                                                          field_of_view_extent_mm=field_of_view_extent_mm)\n\n        self.field_of_view_extent_mm = detection_geometry.field_of_view_extent_mm\n        self.set_detection_geometry(detection_geometry)\n        for i in range(10):\n            self.add_illumination_geometry(MSOTInVisionIlluminationGeometry(invision_position=self.device_position_mm,\n                                                                            geometry_id=i))",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"InVision256TF\": serialized_device}\n        return device_dict",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = InVision256TF()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class MSOTAcuityEcho(PhotoacousticDevice):\n    \"\"\"\n    This class represents a digital twin of the MSOT Acuity Echo, manufactured by iThera Medical, Munich, Germany\n    (https://www.ithera-medical.com/products/msot-acuity/). It is based on the real specifications of the device, but\n    due to the limitations of the possibilities how to represent a device in the software frameworks,\n    constitutes only an approximation.\n\n    The origin for this device is the center of the membrane at the point of contact between the membrane and the\n    tissue, i.e. the outer center of the membrane.\n\n    Some important publications that showcase the use cases of the MSOT Acuity and Acuity Echo device are::\n\n        Regensburger, Adrian P., et al. \"Detection of collagens by multispectral optoacoustic\n        tomography as an imaging biomarker for Duchenne muscular dystrophy.\"\n        Nature Medicine 25.12 (2019): 1905-1915.\n\n        Knieling, Ferdinand, et al. \"Multispectral Optoacoustic Tomography for Assessment of\n        Crohn's Disease Activity.\"\n        The New England journal of medicine 376.13 (2017): 1292.\n\n    \"\"\"\n\n    def __init__(self, device_position_mm: np.ndarray = None,\n                 field_of_view_extent_mm: np.ndarray = None):\n        \"\"\"\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of e.g. detector element positions or illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(MSOTAcuityEcho, self).__init__(device_position_mm=device_position_mm)\n\n        self.mediprene_membrane_height_mm = 1\n        self.probe_height_mm = 43.2\n        self.focus_in_field_of_view_mm = 8\n        self.detection_geometry_position_vector = np.add(self.device_position_mm,\n                                                         np.array([0, 0, self.focus_in_field_of_view_mm]))\n\n        if field_of_view_extent_mm is None:\n            self.field_of_view_extent_mm = np.asarray([-(2 * np.sin(0.34 / 40 * 128) * 40) / 2,\n                                                       (2 * np.sin(0.34 / 40 * 128) * 40) / 2,\n                                                       0, 0, 0, 50])\n        else:\n            self.field_of_view_extent_mm = field_of_view_extent_mm\n\n        self.field_of_view_extent_mm[4] -= self.focus_in_field_of_view_mm\n        self.field_of_view_extent_mm[5] -= self.focus_in_field_of_view_mm\n\n        detection_geometry = CurvedArrayDetectionGeometry(pitch_mm=0.34,\n                                                          radius_mm=40,\n                                                          number_detector_elements=256,\n                                                          detector_element_width_mm=0.24,\n                                                          detector_element_length_mm=13,\n                                                          center_frequency_hz=3.96e6,\n                                                          bandwidth_percent=55,\n                                                          sampling_frequency_mhz=40,\n                                                          angular_origin_offset=np.pi,\n                                                          device_position_mm=self.detection_geometry_position_vector,\n                                                          field_of_view_extent_mm=self.field_of_view_extent_mm)\n\n        self.set_detection_geometry(detection_geometry)\n        illumination_geometry = MSOTAcuityIlluminationGeometry()\n\n        # y position relative to the membrane:\n        # The laser is located 43.2 mm  behind the membrane with an angle of 22.4 degrees.\n        # However, the incident of laser and image plane is located 2.8 behind the membrane (outside of the device).\n        y_pos_relative_to_membrane = np.tan(np.deg2rad(22.4)) * (43.2 + 2.8)\n        self.add_illumination_geometry(illumination_geometry,\n                                       illuminator_position_relative_to_pa_device=np.array([0,\n                                                                                            -y_pos_relative_to_membrane,\n                                                                                            -43.2]))\n\n    def update_settings_for_use_of_model_based_volume_creator(self, global_settings):\n        \"\"\"\n        Updates the volume creation settings of the model based volume creator according to the size of the device.\n        :param global_settings: Settings for the entire simulation pipeline.\n        :type global_settings: Settings\n        \"\"\"\n        try:\n            volume_creator_settings = Settings(global_settings.get_volume_creation_settings())\n        except KeyError as e:\n            self.logger.warning(\"You called the update_settings_for_use_of_model_based_volume_creator method \"\n                                \"even though there are no volume creation settings defined in the \"\n                                \"settings dictionary.\")\n            return\n\n        probe_size_mm = self.probe_height_mm\n        mediprene_layer_height_mm = self.mediprene_membrane_height_mm\n        heavy_water_layer_height_mm = probe_size_mm - mediprene_layer_height_mm\n\n        if Tags.US_GEL in volume_creator_settings and volume_creator_settings[Tags.US_GEL]:\n            us_gel_thickness = np.random.normal(0.4, 0.1)\n        else:\n            us_gel_thickness = 0\n\n        z_dim_position_shift_mm = mediprene_layer_height_mm + heavy_water_layer_height_mm + us_gel_thickness\n\n        new_volume_height_mm = global_settings[Tags.DIM_VOLUME_Z_MM] + z_dim_position_shift_mm\n\n        # adjust the z-dim to msot probe height\n        global_settings[Tags.DIM_VOLUME_Z_MM] = new_volume_height_mm\n\n        # adjust the x-dim to msot probe width\n        # 1 voxel is added (0.5 on both sides) to make sure no rounding errors lead to a detector element being outside\n        # of the simulated volume.\n\n        if global_settings[Tags.DIM_VOLUME_X_MM] < round(self.detection_geometry.probe_width_mm) + \\\n                global_settings[Tags.SPACING_MM]:\n            width_shift_for_structures_mm = (round(self.detection_geometry.probe_width_mm) +\n                                             global_settings[Tags.SPACING_MM] -\n                                             global_settings[Tags.DIM_VOLUME_X_MM]) / 2\n            global_settings[Tags.DIM_VOLUME_X_MM] = round(self.detection_geometry.probe_width_mm) + \\\n                global_settings[Tags.SPACING_MM]\n            self.logger.debug(f\"Changed Tags.DIM_VOLUME_X_MM to {global_settings[Tags.DIM_VOLUME_X_MM]}\")\n        else:\n            width_shift_for_structures_mm = 0\n\n        self.logger.debug(volume_creator_settings)\n\n        for structure_key in volume_creator_settings[Tags.STRUCTURES]:\n            self.logger.debug(\"Adjusting \" + str(structure_key))\n            structure_dict = volume_creator_settings[Tags.STRUCTURES][structure_key]\n            if Tags.STRUCTURE_START_MM in structure_dict:\n                structure_dict[Tags.STRUCTURE_START_MM][0] = structure_dict[Tags.STRUCTURE_START_MM][\n                    0] + width_shift_for_structures_mm\n                structure_dict[Tags.STRUCTURE_START_MM][2] = structure_dict[Tags.STRUCTURE_START_MM][\n                    2] + z_dim_position_shift_mm\n            if Tags.STRUCTURE_END_MM in structure_dict:\n                structure_dict[Tags.STRUCTURE_END_MM][0] = structure_dict[Tags.STRUCTURE_END_MM][\n                    0] + width_shift_for_structures_mm\n                structure_dict[Tags.STRUCTURE_END_MM][2] = structure_dict[Tags.STRUCTURE_END_MM][\n                    2] + z_dim_position_shift_mm\n\n        if Tags.CONSIDER_PARTIAL_VOLUME_IN_DEVICE in volume_creator_settings:\n            consider_partial_volume = volume_creator_settings[Tags.CONSIDER_PARTIAL_VOLUME_IN_DEVICE]\n        else:\n            consider_partial_volume = False\n\n        if Tags.US_GEL in volume_creator_settings and volume_creator_settings[Tags.US_GEL]:\n            us_gel_layer_settings = Settings({\n                Tags.PRIORITY: 5,\n                Tags.STRUCTURE_START_MM: [0, 0,\n                                          heavy_water_layer_height_mm + mediprene_layer_height_mm],\n                Tags.STRUCTURE_END_MM: [0, 0,\n                                        heavy_water_layer_height_mm + mediprene_layer_height_mm + us_gel_thickness],\n                Tags.CONSIDER_PARTIAL_VOLUME: consider_partial_volume,\n                Tags.MOLECULE_COMPOSITION: TISSUE_LIBRARY.ultrasound_gel(),\n                Tags.STRUCTURE_TYPE: Tags.HORIZONTAL_LAYER_STRUCTURE\n            })\n\n            volume_creator_settings[Tags.STRUCTURES][\"us_gel\"] = us_gel_layer_settings\n\n        mediprene_layer_settings = Settings({\n            Tags.PRIORITY: 5,\n            Tags.STRUCTURE_START_MM: [0, 0, heavy_water_layer_height_mm],\n            Tags.STRUCTURE_END_MM: [0, 0, heavy_water_layer_height_mm + mediprene_layer_height_mm],\n            Tags.CONSIDER_PARTIAL_VOLUME: consider_partial_volume,\n            Tags.MOLECULE_COMPOSITION: TISSUE_LIBRARY.mediprene(),\n            Tags.STRUCTURE_TYPE: Tags.HORIZONTAL_LAYER_STRUCTURE\n        })\n\n        volume_creator_settings[Tags.STRUCTURES][\"mediprene\"] = mediprene_layer_settings\n\n        self.device_position_mm = np.add(self.device_position_mm, np.array([width_shift_for_structures_mm, 0,\n                                                                            probe_size_mm]))\n        self.detection_geometry_position_vector = np.add(self.device_position_mm,\n                                                         np.array([0, 0,\n                                                                   self.focus_in_field_of_view_mm]))\n        detection_geometry = CurvedArrayDetectionGeometry(pitch_mm=0.34,\n                                                          radius_mm=40,\n                                                          number_detector_elements=256,\n                                                          detector_element_width_mm=0.24,\n                                                          detector_element_length_mm=13,\n                                                          center_frequency_hz=3.96e6,\n                                                          bandwidth_percent=55,\n                                                          sampling_frequency_mhz=40,\n                                                          angular_origin_offset=np.pi,\n                                                          device_position_mm=self.detection_geometry_position_vector,\n                                                          field_of_view_extent_mm=self.field_of_view_extent_mm)\n\n        self.set_detection_geometry(detection_geometry)\n        for illumination_geom in self.illumination_geometries:\n            illumination_geom.device_position_mm = np.add(illumination_geom.device_position_mm,\n                                                          np.array([width_shift_for_structures_mm, 0, probe_size_mm]))\n\n        background_settings = Settings({\n            Tags.MOLECULE_COMPOSITION: TISSUE_LIBRARY.heavy_water(),\n            Tags.STRUCTURE_TYPE: Tags.BACKGROUND\n        })\n        volume_creator_settings[Tags.STRUCTURES][Tags.BACKGROUND] = background_settings\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"MSOTAcuityEcho\": serialized_device}\n        return device_dict\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = MSOTAcuityEcho()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, device_position_mm: np.ndarray = None,\n                 field_of_view_extent_mm: np.ndarray = None):\n        \"\"\"\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of e.g. detector element positions or illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(MSOTAcuityEcho, self).__init__(device_position_mm=device_position_mm)\n\n        self.mediprene_membrane_height_mm = 1\n        self.probe_height_mm = 43.2\n        self.focus_in_field_of_view_mm = 8\n        self.detection_geometry_position_vector = np.add(self.device_position_mm,\n                                                         np.array([0, 0, self.focus_in_field_of_view_mm]))\n\n        if field_of_view_extent_mm is None:\n            self.field_of_view_extent_mm = np.asarray([-(2 * np.sin(0.34 / 40 * 128) * 40) / 2,\n                                                       (2 * np.sin(0.34 / 40 * 128) * 40) / 2,\n                                                       0, 0, 0, 50])\n        else:\n            self.field_of_view_extent_mm = field_of_view_extent_mm\n\n        self.field_of_view_extent_mm[4] -= self.focus_in_field_of_view_mm\n        self.field_of_view_extent_mm[5] -= self.focus_in_field_of_view_mm\n\n        detection_geometry = CurvedArrayDetectionGeometry(pitch_mm=0.34,\n                                                          radius_mm=40,\n                                                          number_detector_elements=256,\n                                                          detector_element_width_mm=0.24,\n                                                          detector_element_length_mm=13,\n                                                          center_frequency_hz=3.96e6,\n                                                          bandwidth_percent=55,\n                                                          sampling_frequency_mhz=40,\n                                                          angular_origin_offset=np.pi,\n                                                          device_position_mm=self.detection_geometry_position_vector,\n                                                          field_of_view_extent_mm=self.field_of_view_extent_mm)\n\n        self.set_detection_geometry(detection_geometry)\n        illumination_geometry = MSOTAcuityIlluminationGeometry()\n\n        # y position relative to the membrane:\n        # The laser is located 43.2 mm  behind the membrane with an angle of 22.4 degrees.\n        # However, the incident of laser and image plane is located 2.8 behind the membrane (outside of the device).\n        y_pos_relative_to_membrane = np.tan(np.deg2rad(22.4)) * (43.2 + 2.8)\n        self.add_illumination_geometry(illumination_geometry,\n                                       illuminator_position_relative_to_pa_device=np.array([0,\n                                                                                            -y_pos_relative_to_membrane,\n                                                                                            -43.2]))",
  "def update_settings_for_use_of_model_based_volume_creator(self, global_settings):\n        \"\"\"\n        Updates the volume creation settings of the model based volume creator according to the size of the device.\n        :param global_settings: Settings for the entire simulation pipeline.\n        :type global_settings: Settings\n        \"\"\"\n        try:\n            volume_creator_settings = Settings(global_settings.get_volume_creation_settings())\n        except KeyError as e:\n            self.logger.warning(\"You called the update_settings_for_use_of_model_based_volume_creator method \"\n                                \"even though there are no volume creation settings defined in the \"\n                                \"settings dictionary.\")\n            return\n\n        probe_size_mm = self.probe_height_mm\n        mediprene_layer_height_mm = self.mediprene_membrane_height_mm\n        heavy_water_layer_height_mm = probe_size_mm - mediprene_layer_height_mm\n\n        if Tags.US_GEL in volume_creator_settings and volume_creator_settings[Tags.US_GEL]:\n            us_gel_thickness = np.random.normal(0.4, 0.1)\n        else:\n            us_gel_thickness = 0\n\n        z_dim_position_shift_mm = mediprene_layer_height_mm + heavy_water_layer_height_mm + us_gel_thickness\n\n        new_volume_height_mm = global_settings[Tags.DIM_VOLUME_Z_MM] + z_dim_position_shift_mm\n\n        # adjust the z-dim to msot probe height\n        global_settings[Tags.DIM_VOLUME_Z_MM] = new_volume_height_mm\n\n        # adjust the x-dim to msot probe width\n        # 1 voxel is added (0.5 on both sides) to make sure no rounding errors lead to a detector element being outside\n        # of the simulated volume.\n\n        if global_settings[Tags.DIM_VOLUME_X_MM] < round(self.detection_geometry.probe_width_mm) + \\\n                global_settings[Tags.SPACING_MM]:\n            width_shift_for_structures_mm = (round(self.detection_geometry.probe_width_mm) +\n                                             global_settings[Tags.SPACING_MM] -\n                                             global_settings[Tags.DIM_VOLUME_X_MM]) / 2\n            global_settings[Tags.DIM_VOLUME_X_MM] = round(self.detection_geometry.probe_width_mm) + \\\n                global_settings[Tags.SPACING_MM]\n            self.logger.debug(f\"Changed Tags.DIM_VOLUME_X_MM to {global_settings[Tags.DIM_VOLUME_X_MM]}\")\n        else:\n            width_shift_for_structures_mm = 0\n\n        self.logger.debug(volume_creator_settings)\n\n        for structure_key in volume_creator_settings[Tags.STRUCTURES]:\n            self.logger.debug(\"Adjusting \" + str(structure_key))\n            structure_dict = volume_creator_settings[Tags.STRUCTURES][structure_key]\n            if Tags.STRUCTURE_START_MM in structure_dict:\n                structure_dict[Tags.STRUCTURE_START_MM][0] = structure_dict[Tags.STRUCTURE_START_MM][\n                    0] + width_shift_for_structures_mm\n                structure_dict[Tags.STRUCTURE_START_MM][2] = structure_dict[Tags.STRUCTURE_START_MM][\n                    2] + z_dim_position_shift_mm\n            if Tags.STRUCTURE_END_MM in structure_dict:\n                structure_dict[Tags.STRUCTURE_END_MM][0] = structure_dict[Tags.STRUCTURE_END_MM][\n                    0] + width_shift_for_structures_mm\n                structure_dict[Tags.STRUCTURE_END_MM][2] = structure_dict[Tags.STRUCTURE_END_MM][\n                    2] + z_dim_position_shift_mm\n\n        if Tags.CONSIDER_PARTIAL_VOLUME_IN_DEVICE in volume_creator_settings:\n            consider_partial_volume = volume_creator_settings[Tags.CONSIDER_PARTIAL_VOLUME_IN_DEVICE]\n        else:\n            consider_partial_volume = False\n\n        if Tags.US_GEL in volume_creator_settings and volume_creator_settings[Tags.US_GEL]:\n            us_gel_layer_settings = Settings({\n                Tags.PRIORITY: 5,\n                Tags.STRUCTURE_START_MM: [0, 0,\n                                          heavy_water_layer_height_mm + mediprene_layer_height_mm],\n                Tags.STRUCTURE_END_MM: [0, 0,\n                                        heavy_water_layer_height_mm + mediprene_layer_height_mm + us_gel_thickness],\n                Tags.CONSIDER_PARTIAL_VOLUME: consider_partial_volume,\n                Tags.MOLECULE_COMPOSITION: TISSUE_LIBRARY.ultrasound_gel(),\n                Tags.STRUCTURE_TYPE: Tags.HORIZONTAL_LAYER_STRUCTURE\n            })\n\n            volume_creator_settings[Tags.STRUCTURES][\"us_gel\"] = us_gel_layer_settings\n\n        mediprene_layer_settings = Settings({\n            Tags.PRIORITY: 5,\n            Tags.STRUCTURE_START_MM: [0, 0, heavy_water_layer_height_mm],\n            Tags.STRUCTURE_END_MM: [0, 0, heavy_water_layer_height_mm + mediprene_layer_height_mm],\n            Tags.CONSIDER_PARTIAL_VOLUME: consider_partial_volume,\n            Tags.MOLECULE_COMPOSITION: TISSUE_LIBRARY.mediprene(),\n            Tags.STRUCTURE_TYPE: Tags.HORIZONTAL_LAYER_STRUCTURE\n        })\n\n        volume_creator_settings[Tags.STRUCTURES][\"mediprene\"] = mediprene_layer_settings\n\n        self.device_position_mm = np.add(self.device_position_mm, np.array([width_shift_for_structures_mm, 0,\n                                                                            probe_size_mm]))\n        self.detection_geometry_position_vector = np.add(self.device_position_mm,\n                                                         np.array([0, 0,\n                                                                   self.focus_in_field_of_view_mm]))\n        detection_geometry = CurvedArrayDetectionGeometry(pitch_mm=0.34,\n                                                          radius_mm=40,\n                                                          number_detector_elements=256,\n                                                          detector_element_width_mm=0.24,\n                                                          detector_element_length_mm=13,\n                                                          center_frequency_hz=3.96e6,\n                                                          bandwidth_percent=55,\n                                                          sampling_frequency_mhz=40,\n                                                          angular_origin_offset=np.pi,\n                                                          device_position_mm=self.detection_geometry_position_vector,\n                                                          field_of_view_extent_mm=self.field_of_view_extent_mm)\n\n        self.set_detection_geometry(detection_geometry)\n        for illumination_geom in self.illumination_geometries:\n            illumination_geom.device_position_mm = np.add(illumination_geom.device_position_mm,\n                                                          np.array([width_shift_for_structures_mm, 0, probe_size_mm]))\n\n        background_settings = Settings({\n            Tags.MOLECULE_COMPOSITION: TISSUE_LIBRARY.heavy_water(),\n            Tags.STRUCTURE_TYPE: Tags.BACKGROUND\n        })\n        volume_creator_settings[Tags.STRUCTURES][Tags.BACKGROUND] = background_settings",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"MSOTAcuityEcho\": serialized_device}\n        return device_dict",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = MSOTAcuityEcho()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class RSOMExplorerP50(PhotoacousticDevice):\n    \"\"\"\n    This class represents an approximation of the Raster-scanning Optoacoustic Mesoscopy (RSOM) device\n    built by iThera Medical (Munich, Germany). Please refer to the companie's website for more information\n    (https://www.ithera-medical.com/products/rsom-explorer-p50/).\n\n    Since simulating thousands of individual forward modeling steps to obtain a single raster-scanned image\n    is computationally not feasible, we approximate the process with a device design that has detection elements\n    across the entire field of view. Because of this limitation we also need to approximate the light source\n    with a homogeneous illumination across the field of view.\n\n    The digital device is modeled based on the reported specifications of the RSOM Explorer P50 system.\n    Technical details of the system can be found in the dissertation of Mathias Schwarz\n    (https://mediatum.ub.tum.de/doc/1324031/1324031.pdf) and you can find more details on\n    use cases of the device in the following literature sources::\n\n        Yew, Yik Weng, et al. \"Raster-scanning optoacoustic mesoscopy (RSOM) imaging\n        as an objective disease severity tool in atopic dermatitis patients.\"\n        Journal of the American Academy of Dermatology (2020).\n\n        Hindelang, B., et al. \"Non-invasive imaging in dermatology and the unique\n        potential of raster-scan optoacoustic mesoscopy.\"\n        Journal of the European Academy of Dermatology and Venereology\n        33.6 (2019): 1051-1061.\n\n    \"\"\"\n\n    def __init__(self, element_spacing_mm=0.02,\n                 number_elements_x=10,\n                 number_elements_y=10,\n                 device_position_mm: np.ndarray = None,\n                 field_of_view_extent_mm: np.ndarray = None):\n        \"\"\"\n        :param element_spacing_mm: Detection element pitch in both x- and y-direction. It is an isotropic spacing \\\n        assumed.\n        :type element_spacing_mm: float\n        :param number_elements_x: Number of detection elements in x-direction.\n        :type number_elements_x: int\n        :param number_elements_y: Number of detection elements in y-direction.\n        :type number_elements_y: int\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of e.g. detector element positions or illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(RSOMExplorerP50, self).__init__(device_position_mm=device_position_mm)\n\n        detection_geometry = PlanarArrayDetectionGeometry(pitch_mm=element_spacing_mm,\n                                                          number_detector_elements_x=number_elements_x,\n                                                          number_detector_elements_y=number_elements_y,\n                                                          center_frequency_hz=float(50e6),\n                                                          bandwidth_percent=100.0,\n                                                          sampling_frequency_mhz=500.0,\n                                                          detector_element_width_mm=1,\n                                                          detector_element_length_mm=1,\n                                                          device_position_mm=device_position_mm,\n                                                          field_of_view_extent_mm=field_of_view_extent_mm)\n\n        self.set_detection_geometry(detection_geometry)\n\n        illumination_geometry = PencilArrayIlluminationGeometry(pitch_mm=element_spacing_mm,\n                                                                number_illuminators_x=number_elements_x,\n                                                                number_illuminators_y=number_elements_y)\n\n        self.add_illumination_geometry(illumination_geometry)\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"RSOMExplorerP50\": serialized_device}\n        return device_dict\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = RSOMExplorerP50()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, element_spacing_mm=0.02,\n                 number_elements_x=10,\n                 number_elements_y=10,\n                 device_position_mm: np.ndarray = None,\n                 field_of_view_extent_mm: np.ndarray = None):\n        \"\"\"\n        :param element_spacing_mm: Detection element pitch in both x- and y-direction. It is an isotropic spacing \\\n        assumed.\n        :type element_spacing_mm: float\n        :param number_elements_x: Number of detection elements in x-direction.\n        :type number_elements_x: int\n        :param number_elements_y: Number of detection elements in y-direction.\n        :type number_elements_y: int\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of e.g. detector element positions or illuminator positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(RSOMExplorerP50, self).__init__(device_position_mm=device_position_mm)\n\n        detection_geometry = PlanarArrayDetectionGeometry(pitch_mm=element_spacing_mm,\n                                                          number_detector_elements_x=number_elements_x,\n                                                          number_detector_elements_y=number_elements_y,\n                                                          center_frequency_hz=float(50e6),\n                                                          bandwidth_percent=100.0,\n                                                          sampling_frequency_mhz=500.0,\n                                                          detector_element_width_mm=1,\n                                                          detector_element_length_mm=1,\n                                                          device_position_mm=device_position_mm,\n                                                          field_of_view_extent_mm=field_of_view_extent_mm)\n\n        self.set_detection_geometry(detection_geometry)\n\n        illumination_geometry = PencilArrayIlluminationGeometry(pitch_mm=element_spacing_mm,\n                                                                number_illuminators_x=number_elements_x,\n                                                                number_illuminators_y=number_elements_y)\n\n        self.add_illumination_geometry(illumination_geometry)",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        device_dict = {\"RSOMExplorerP50\": serialized_device}\n        return device_dict",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = RSOMExplorerP50()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class LinearArrayDetectionGeometry(DetectionGeometryBase):\n    \"\"\"\n    This class represents a digital twin of a ultrasound detection device\n    with a linear detection geometry. The origin for this device is the center of the linear array, so approximately\n    the position of the (number_detector_elements/2)th detector element.\n\n    \"\"\"\n\n    def __init__(self, pitch_mm=0.5,\n                 number_detector_elements=100,\n                 detector_element_width_mm=0.24,\n                 detector_element_length_mm=0.5,\n                 center_frequency_hz=3.96e6,\n                 bandwidth_percent=55,\n                 sampling_frequency_mhz=40,\n                 device_position_mm: np.ndarray = None,\n                 field_of_view_extent_mm: np.ndarray = None):\n        \"\"\"\n\n        :param pitch_mm:\n        :param number_detector_elements:\n        :param detector_element_width_mm:\n        :param detector_element_length_mm:\n        :param center_frequency_hz:\n        :param bandwidth_percent:\n        :param sampling_frequency_mhz:\n        :param device_position_mm: Center of the linear array.\n        \"\"\"\n        if field_of_view_extent_mm is None:\n            field_of_view_extent_mm = np.asarray([-number_detector_elements * pitch_mm / 2,\n                                                  number_detector_elements * pitch_mm / 2,\n                                                  0, 0, 0, 50])\n        super(LinearArrayDetectionGeometry, self).__init__(\n            number_detector_elements=number_detector_elements,\n            detector_element_width_mm=detector_element_width_mm,\n            detector_element_length_mm=detector_element_length_mm,\n            center_frequency_hz=center_frequency_hz,\n            bandwidth_percent=bandwidth_percent,\n            sampling_frequency_mhz=sampling_frequency_mhz,\n            device_position_mm=device_position_mm,\n            field_of_view_extent_mm=field_of_view_extent_mm)\n        self.pitch_mm = pitch_mm\n        self.probe_width_mm = (number_detector_elements - 1) * self.pitch_mm\n\n    def check_settings_prerequisites(self, global_settings: Settings) -> bool:\n        if global_settings[Tags.DIM_VOLUME_X_MM] < self.probe_width_mm + global_settings[Tags.SPACING_MM]:\n            self.logger.error(\"Volume x dimension is too small to encompass MSOT device in simulation!\"\n                              \"Must be at least {} mm but was {} mm\"\n                              .format(self.probe_width_mm + global_settings[Tags.SPACING_MM],\n                                      global_settings[Tags.DIM_VOLUME_X_MM]))\n            return False\n        return True\n\n    def update_settings_for_use_of_model_based_volume_creator(self, global_settings):\n        pass\n\n    def get_detector_element_positions_base_mm(self) -> np.ndarray:\n\n        detector_positions = np.zeros((self.number_detector_elements, 3))\n\n        if self.number_detector_elements > 1:\n            if self.number_detector_elements % 2 == 0:\n                # even number of detector elements\n                det_elements = np.arange(-int(self.number_detector_elements / 2),\n                                         int(self.number_detector_elements / 2)) * self.pitch_mm + 0.5 * self.pitch_mm\n            else:\n                # odd number of detector elements\n                det_elements = np.arange(-int(self.number_detector_elements / 2),\n                                         int(self.number_detector_elements / 2) + 1) * self.pitch_mm\n        else:\n            det_elements = 0\n\n        detector_positions[:, 0] = det_elements\n\n        return detector_positions\n\n    def get_detector_element_orientations(self) -> np.ndarray:\n        detector_orientations = np.zeros((self.number_detector_elements, 3))\n        detector_orientations[:, 2] = -1\n        return detector_orientations\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {\"LinearArrayDetectionGeometry\": serialized_device}\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = LinearArrayDetectionGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, pitch_mm=0.5,\n                 number_detector_elements=100,\n                 detector_element_width_mm=0.24,\n                 detector_element_length_mm=0.5,\n                 center_frequency_hz=3.96e6,\n                 bandwidth_percent=55,\n                 sampling_frequency_mhz=40,\n                 device_position_mm: np.ndarray = None,\n                 field_of_view_extent_mm: np.ndarray = None):\n        \"\"\"\n\n        :param pitch_mm:\n        :param number_detector_elements:\n        :param detector_element_width_mm:\n        :param detector_element_length_mm:\n        :param center_frequency_hz:\n        :param bandwidth_percent:\n        :param sampling_frequency_mhz:\n        :param device_position_mm: Center of the linear array.\n        \"\"\"\n        if field_of_view_extent_mm is None:\n            field_of_view_extent_mm = np.asarray([-number_detector_elements * pitch_mm / 2,\n                                                  number_detector_elements * pitch_mm / 2,\n                                                  0, 0, 0, 50])\n        super(LinearArrayDetectionGeometry, self).__init__(\n            number_detector_elements=number_detector_elements,\n            detector_element_width_mm=detector_element_width_mm,\n            detector_element_length_mm=detector_element_length_mm,\n            center_frequency_hz=center_frequency_hz,\n            bandwidth_percent=bandwidth_percent,\n            sampling_frequency_mhz=sampling_frequency_mhz,\n            device_position_mm=device_position_mm,\n            field_of_view_extent_mm=field_of_view_extent_mm)\n        self.pitch_mm = pitch_mm\n        self.probe_width_mm = (number_detector_elements - 1) * self.pitch_mm",
  "def check_settings_prerequisites(self, global_settings: Settings) -> bool:\n        if global_settings[Tags.DIM_VOLUME_X_MM] < self.probe_width_mm + global_settings[Tags.SPACING_MM]:\n            self.logger.error(\"Volume x dimension is too small to encompass MSOT device in simulation!\"\n                              \"Must be at least {} mm but was {} mm\"\n                              .format(self.probe_width_mm + global_settings[Tags.SPACING_MM],\n                                      global_settings[Tags.DIM_VOLUME_X_MM]))\n            return False\n        return True",
  "def update_settings_for_use_of_model_based_volume_creator(self, global_settings):\n        pass",
  "def get_detector_element_positions_base_mm(self) -> np.ndarray:\n\n        detector_positions = np.zeros((self.number_detector_elements, 3))\n\n        if self.number_detector_elements > 1:\n            if self.number_detector_elements % 2 == 0:\n                # even number of detector elements\n                det_elements = np.arange(-int(self.number_detector_elements / 2),\n                                         int(self.number_detector_elements / 2)) * self.pitch_mm + 0.5 * self.pitch_mm\n            else:\n                # odd number of detector elements\n                det_elements = np.arange(-int(self.number_detector_elements / 2),\n                                         int(self.number_detector_elements / 2) + 1) * self.pitch_mm\n        else:\n            det_elements = 0\n\n        detector_positions[:, 0] = det_elements\n\n        return detector_positions",
  "def get_detector_element_orientations(self) -> np.ndarray:\n        detector_orientations = np.zeros((self.number_detector_elements, 3))\n        detector_orientations[:, 2] = -1\n        return detector_orientations",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {\"LinearArrayDetectionGeometry\": serialized_device}",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = LinearArrayDetectionGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class CurvedArrayDetectionGeometry(DetectionGeometryBase):\n    \"\"\"\n    This class represents a digital twin of a ultrasound detection device\n    with a curved detection geometry. The origin for this device is the center (focus) of the curved array.\n    \"\"\"\n\n    def __init__(self, pitch_mm=0.5,\n                 radius_mm=40,\n                 number_detector_elements=256,\n                 detector_element_width_mm=0.24,\n                 detector_element_length_mm=13,\n                 center_frequency_hz=3.96e6,\n                 bandwidth_percent=55,\n                 sampling_frequency_mhz=40,\n                 angular_origin_offset=np.pi,\n                 device_position_mm=None,\n                 field_of_view_extent_mm=None):\n        \"\"\"\n\n        :param pitch_mm: In-plane distance between the beginning of one detector element to the next detector element.\n        :param radius_mm:\n        :param number_detector_elements:\n        :param detector_element_width_mm:\n        :param detector_element_length_mm:\n        :param center_frequency_hz:\n        :param bandwidth_percent:\n        :param sampling_frequency_mhz:\n        :param angular_origin_offset:\n        :param device_position_mm: Center (focus) of the curved array.\n        \"\"\"\n\n        super(CurvedArrayDetectionGeometry, self).__init__(\n            number_detector_elements=number_detector_elements,\n            detector_element_width_mm=detector_element_width_mm,\n            detector_element_length_mm=detector_element_length_mm,\n            center_frequency_hz=center_frequency_hz,\n            bandwidth_percent=bandwidth_percent,\n            sampling_frequency_mhz=sampling_frequency_mhz,\n            device_position_mm=device_position_mm)\n\n        self.pitch_mm = pitch_mm\n        self.radius_mm = radius_mm\n        self.angular_origin_offset = angular_origin_offset\n\n        detector_positions = self.get_detector_element_positions_base_mm()\n        min_x_coordinate = np.min(detector_positions[:, 0])\n        max_x_coordinate = np.max(detector_positions[:, 0])\n        self.probe_width_mm = max_x_coordinate - min_x_coordinate\n\n        min_z_coordinate = np.min(detector_positions[:, 2])\n        max_z_coordinate = np.max(detector_positions[:, 2])\n        self.probe_height_mm = max_z_coordinate - min_z_coordinate\n\n        if field_of_view_extent_mm is None:\n            self.field_of_view_extent_mm = np.asarray([-self.probe_width_mm/2,\n                                                       self.probe_width_mm/2,\n                                                       0, 0, 0, 100])\n        else:\n            self.field_of_view_extent_mm = field_of_view_extent_mm\n\n    def check_settings_prerequisites(self, global_settings) -> bool:\n        if global_settings[Tags.DIM_VOLUME_Z_MM] < (self.probe_height_mm + global_settings[Tags.SPACING_MM]):\n            self.logger.error(\"Volume z dimension is too small to encompass the device in simulation!\"\n                              \"Must be at least {} mm but was {} mm\"\n                              .format((self.probe_height_mm + global_settings[Tags.SPACING_MM]),\n                                      global_settings[Tags.DIM_VOLUME_Z_MM]))\n            return False\n        if global_settings[Tags.DIM_VOLUME_X_MM] < (self.probe_width_mm + global_settings[Tags.SPACING_MM]):\n            self.logger.error(\"Volume x dimension is too small to encompass MSOT device in simulation!\"\n                              \"Must be at least {} mm but was {} mm\"\n                              .format(self.probe_width_mm, global_settings[Tags.DIM_VOLUME_X_MM]))\n            return False\n        return True\n\n    def update_settings_for_use_of_model_based_volume_creator(self, global_settings):\n        pass\n\n    def get_detector_element_positions_base_mm(self) -> np.ndarray:\n\n        pitch_angle = self.pitch_mm / self.radius_mm\n        detector_radius = self.radius_mm\n        detector_positions = np.zeros((self.number_detector_elements, 3))\n        det_elements = np.arange(-int(self.number_detector_elements / 2) + 0.5,\n                                 int(self.number_detector_elements / 2) + 0.5)\n        detector_positions[:, 0] = np.sin(pitch_angle * det_elements - self.angular_origin_offset) * detector_radius\n        detector_positions[:, 2] = np.cos(pitch_angle * det_elements - self.angular_origin_offset) * detector_radius\n\n        return detector_positions\n\n    def get_detector_element_orientations(self) -> np.ndarray:\n        detector_positions = self.get_detector_element_positions_base_mm()\n        detector_orientations = np.subtract(0, detector_positions)\n        norm = np.linalg.norm(detector_orientations, axis=-1)\n        for dim in range(3):\n            detector_orientations[:, dim] = detector_orientations[:, dim] / norm\n        return detector_orientations\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {\"CurvedArrayDetectionGeometry\": serialized_device}\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = CurvedArrayDetectionGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, pitch_mm=0.5,\n                 radius_mm=40,\n                 number_detector_elements=256,\n                 detector_element_width_mm=0.24,\n                 detector_element_length_mm=13,\n                 center_frequency_hz=3.96e6,\n                 bandwidth_percent=55,\n                 sampling_frequency_mhz=40,\n                 angular_origin_offset=np.pi,\n                 device_position_mm=None,\n                 field_of_view_extent_mm=None):\n        \"\"\"\n\n        :param pitch_mm: In-plane distance between the beginning of one detector element to the next detector element.\n        :param radius_mm:\n        :param number_detector_elements:\n        :param detector_element_width_mm:\n        :param detector_element_length_mm:\n        :param center_frequency_hz:\n        :param bandwidth_percent:\n        :param sampling_frequency_mhz:\n        :param angular_origin_offset:\n        :param device_position_mm: Center (focus) of the curved array.\n        \"\"\"\n\n        super(CurvedArrayDetectionGeometry, self).__init__(\n            number_detector_elements=number_detector_elements,\n            detector_element_width_mm=detector_element_width_mm,\n            detector_element_length_mm=detector_element_length_mm,\n            center_frequency_hz=center_frequency_hz,\n            bandwidth_percent=bandwidth_percent,\n            sampling_frequency_mhz=sampling_frequency_mhz,\n            device_position_mm=device_position_mm)\n\n        self.pitch_mm = pitch_mm\n        self.radius_mm = radius_mm\n        self.angular_origin_offset = angular_origin_offset\n\n        detector_positions = self.get_detector_element_positions_base_mm()\n        min_x_coordinate = np.min(detector_positions[:, 0])\n        max_x_coordinate = np.max(detector_positions[:, 0])\n        self.probe_width_mm = max_x_coordinate - min_x_coordinate\n\n        min_z_coordinate = np.min(detector_positions[:, 2])\n        max_z_coordinate = np.max(detector_positions[:, 2])\n        self.probe_height_mm = max_z_coordinate - min_z_coordinate\n\n        if field_of_view_extent_mm is None:\n            self.field_of_view_extent_mm = np.asarray([-self.probe_width_mm/2,\n                                                       self.probe_width_mm/2,\n                                                       0, 0, 0, 100])\n        else:\n            self.field_of_view_extent_mm = field_of_view_extent_mm",
  "def check_settings_prerequisites(self, global_settings) -> bool:\n        if global_settings[Tags.DIM_VOLUME_Z_MM] < (self.probe_height_mm + global_settings[Tags.SPACING_MM]):\n            self.logger.error(\"Volume z dimension is too small to encompass the device in simulation!\"\n                              \"Must be at least {} mm but was {} mm\"\n                              .format((self.probe_height_mm + global_settings[Tags.SPACING_MM]),\n                                      global_settings[Tags.DIM_VOLUME_Z_MM]))\n            return False\n        if global_settings[Tags.DIM_VOLUME_X_MM] < (self.probe_width_mm + global_settings[Tags.SPACING_MM]):\n            self.logger.error(\"Volume x dimension is too small to encompass MSOT device in simulation!\"\n                              \"Must be at least {} mm but was {} mm\"\n                              .format(self.probe_width_mm, global_settings[Tags.DIM_VOLUME_X_MM]))\n            return False\n        return True",
  "def update_settings_for_use_of_model_based_volume_creator(self, global_settings):\n        pass",
  "def get_detector_element_positions_base_mm(self) -> np.ndarray:\n\n        pitch_angle = self.pitch_mm / self.radius_mm\n        detector_radius = self.radius_mm\n        detector_positions = np.zeros((self.number_detector_elements, 3))\n        det_elements = np.arange(-int(self.number_detector_elements / 2) + 0.5,\n                                 int(self.number_detector_elements / 2) + 0.5)\n        detector_positions[:, 0] = np.sin(pitch_angle * det_elements - self.angular_origin_offset) * detector_radius\n        detector_positions[:, 2] = np.cos(pitch_angle * det_elements - self.angular_origin_offset) * detector_radius\n\n        return detector_positions",
  "def get_detector_element_orientations(self) -> np.ndarray:\n        detector_positions = self.get_detector_element_positions_base_mm()\n        detector_orientations = np.subtract(0, detector_positions)\n        norm = np.linalg.norm(detector_orientations, axis=-1)\n        for dim in range(3):\n            detector_orientations[:, dim] = detector_orientations[:, dim] / norm\n        return detector_orientations",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {\"CurvedArrayDetectionGeometry\": serialized_device}",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = CurvedArrayDetectionGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class DetectionGeometryBase(DigitalDeviceTwinBase):\n    \"\"\"\n    This class is the base class for representing all detector geometries.\n    \"\"\"\n\n    def __init__(self, number_detector_elements, detector_element_width_mm,\n                 detector_element_length_mm, center_frequency_hz, bandwidth_percent,\n                 sampling_frequency_mhz, device_position_mm: np.ndarray = None,\n                 field_of_view_extent_mm: np.ndarray = None):\n        \"\"\"\n\n        :param number_detector_elements: Total number of detector elements.\n        :type number_detector_elements: int\n        :param detector_element_width_mm: In-plane width of one detector element (pitch - distance between two\n            elements) in mm.\n        :type detector_element_width_mm: int, float\n        :param detector_element_length_mm: Out-of-plane length of one detector element in mm.\n        :type detector_element_length_mm: int, float\n        :param center_frequency_hz: Center frequency of the detector with approximately gaussian frequency response in\n            Hz.\n        :type center_frequency_hz: int, float\n        :param bandwidth_percent: Full width at half maximum in percent of the center frequency.\n        :type bandwidth_percent: int, float\n        :param sampling_frequency_mhz: Sampling frequency of the detector in MHz.\n        :type sampling_frequency_mhz: int, float\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of detector positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(DetectionGeometryBase, self).__init__(device_position_mm=device_position_mm,\n                                                    field_of_view_extent_mm=field_of_view_extent_mm)\n        self.number_detector_elements = number_detector_elements\n        self.detector_element_width_mm = detector_element_width_mm\n        self.detector_element_length_mm = detector_element_length_mm\n        self.center_frequency_Hz = center_frequency_hz\n        self.bandwidth_percent = bandwidth_percent\n        self.sampling_frequency_MHz = sampling_frequency_mhz\n\n    @abstractmethod\n    def get_detector_element_positions_base_mm(self) -> np.ndarray:\n        \"\"\"\n        Defines the abstract positions of the detection elements in an arbitrary coordinate system.\n        Typically, the center of the field of view is defined as the origin.\n\n        To obtain the positions in an interpretable coordinate system, please use the other method::\n\n            get_detector_element_positions_accounting_for_device_position_mm\n\n        :returns: A numpy array containing the position vectors of the detection elements.\n\n        \"\"\"\n        pass\n\n    def get_detector_element_positions_accounting_for_device_position_mm(self) -> np.ndarray:\n        \"\"\"\n        Similar to::\n\n            get_detector_element_positions_base_mm\n\n        This method returns the absolute positions of the detection elements relative to the device\n        position in the imaged volume, where the device position is defined by the following tag::\n\n            Tags.DIGITAL_DEVICE_POSITION\n\n        :returns: A numpy array containing the coordinates of the detection elements\n\n        \"\"\"\n        abstract_element_positions = self.get_detector_element_positions_base_mm()\n        device_position = self.device_position_mm\n        return np.add(abstract_element_positions, device_position)\n\n    def get_detector_element_positions_accounting_for_field_of_view(self) -> np.ndarray:\n        \"\"\"\n        Similar to::\n\n            get_detector_element_positions_base_mm\n\n        This method returns the absolute positions of the detection elements relative to the device\n        position in the imaged volume, where the device position is defined by the following tag::\n\n            Tags.DIGITAL_DEVICE_POSITION\n\n        :returns: A numpy array containing the coordinates of the detection elements\n\n        \"\"\"\n        abstract_element_positions = np.copy(self.get_detector_element_positions_base_mm())\n        field_of_view = self.field_of_view_extent_mm\n        x_half = (field_of_view[1] - field_of_view[0]) / 2\n        y_half = (field_of_view[3] - field_of_view[2]) / 2\n        if np.abs(x_half) < 1e-10:\n            abstract_element_positions[:, 0] = 0\n        if np.abs(y_half) < 1e-10:\n            abstract_element_positions[:, 1] = 0\n\n        abstract_element_positions[:, 0] += x_half\n        abstract_element_positions[:, 1] += y_half\n        abstract_element_positions[:, 2] += field_of_view[4]\n        return abstract_element_positions\n\n    @abstractmethod\n    def get_detector_element_orientations(self) -> np.ndarray:\n        \"\"\"\n        This method yields a normalised orientation vector for each detection element. The length of\n        this vector is the same as the one obtained via the position methods::\n\n            get_detector_element_positions_base_mm\n            get_detector_element_positions_accounting_for_device_position_mm\n\n        :returns: a numpy array that contains normalised orientation vectors for each detection element\n\n        \"\"\"\n        pass\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {DetectionGeometryBase: serialized_device}\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = DetectionGeometryBase()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, number_detector_elements, detector_element_width_mm,\n                 detector_element_length_mm, center_frequency_hz, bandwidth_percent,\n                 sampling_frequency_mhz, device_position_mm: np.ndarray = None,\n                 field_of_view_extent_mm: np.ndarray = None):\n        \"\"\"\n\n        :param number_detector_elements: Total number of detector elements.\n        :type number_detector_elements: int\n        :param detector_element_width_mm: In-plane width of one detector element (pitch - distance between two\n            elements) in mm.\n        :type detector_element_width_mm: int, float\n        :param detector_element_length_mm: Out-of-plane length of one detector element in mm.\n        :type detector_element_length_mm: int, float\n        :param center_frequency_hz: Center frequency of the detector with approximately gaussian frequency response in\n            Hz.\n        :type center_frequency_hz: int, float\n        :param bandwidth_percent: Full width at half maximum in percent of the center frequency.\n        :type bandwidth_percent: int, float\n        :param sampling_frequency_mhz: Sampling frequency of the detector in MHz.\n        :type sampling_frequency_mhz: int, float\n        :param device_position_mm: Each device has an internal position which serves as origin for internal \\\n        representations of detector positions.\n        :type device_position_mm: ndarray\n        :param field_of_view_extent_mm: Field of view which is defined as a numpy array of the shape \\\n        [xs, xe, ys, ye, zs, ze], where x, y, and z denote the coordinate axes and s and e denote the start and end \\\n        positions.\n        :type field_of_view_extent_mm: ndarray\n        \"\"\"\n        super(DetectionGeometryBase, self).__init__(device_position_mm=device_position_mm,\n                                                    field_of_view_extent_mm=field_of_view_extent_mm)\n        self.number_detector_elements = number_detector_elements\n        self.detector_element_width_mm = detector_element_width_mm\n        self.detector_element_length_mm = detector_element_length_mm\n        self.center_frequency_Hz = center_frequency_hz\n        self.bandwidth_percent = bandwidth_percent\n        self.sampling_frequency_MHz = sampling_frequency_mhz",
  "def get_detector_element_positions_base_mm(self) -> np.ndarray:\n        \"\"\"\n        Defines the abstract positions of the detection elements in an arbitrary coordinate system.\n        Typically, the center of the field of view is defined as the origin.\n\n        To obtain the positions in an interpretable coordinate system, please use the other method::\n\n            get_detector_element_positions_accounting_for_device_position_mm\n\n        :returns: A numpy array containing the position vectors of the detection elements.\n\n        \"\"\"\n        pass",
  "def get_detector_element_positions_accounting_for_device_position_mm(self) -> np.ndarray:\n        \"\"\"\n        Similar to::\n\n            get_detector_element_positions_base_mm\n\n        This method returns the absolute positions of the detection elements relative to the device\n        position in the imaged volume, where the device position is defined by the following tag::\n\n            Tags.DIGITAL_DEVICE_POSITION\n\n        :returns: A numpy array containing the coordinates of the detection elements\n\n        \"\"\"\n        abstract_element_positions = self.get_detector_element_positions_base_mm()\n        device_position = self.device_position_mm\n        return np.add(abstract_element_positions, device_position)",
  "def get_detector_element_positions_accounting_for_field_of_view(self) -> np.ndarray:\n        \"\"\"\n        Similar to::\n\n            get_detector_element_positions_base_mm\n\n        This method returns the absolute positions of the detection elements relative to the device\n        position in the imaged volume, where the device position is defined by the following tag::\n\n            Tags.DIGITAL_DEVICE_POSITION\n\n        :returns: A numpy array containing the coordinates of the detection elements\n\n        \"\"\"\n        abstract_element_positions = np.copy(self.get_detector_element_positions_base_mm())\n        field_of_view = self.field_of_view_extent_mm\n        x_half = (field_of_view[1] - field_of_view[0]) / 2\n        y_half = (field_of_view[3] - field_of_view[2]) / 2\n        if np.abs(x_half) < 1e-10:\n            abstract_element_positions[:, 0] = 0\n        if np.abs(y_half) < 1e-10:\n            abstract_element_positions[:, 1] = 0\n\n        abstract_element_positions[:, 0] += x_half\n        abstract_element_positions[:, 1] += y_half\n        abstract_element_positions[:, 2] += field_of_view[4]\n        return abstract_element_positions",
  "def get_detector_element_orientations(self) -> np.ndarray:\n        \"\"\"\n        This method yields a normalised orientation vector for each detection element. The length of\n        this vector is the same as the one obtained via the position methods::\n\n            get_detector_element_positions_base_mm\n            get_detector_element_positions_accounting_for_device_position_mm\n\n        :returns: a numpy array that contains normalised orientation vectors for each detection element\n\n        \"\"\"\n        pass",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {DetectionGeometryBase: serialized_device}",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = DetectionGeometryBase()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class PlanarArrayDetectionGeometry(DetectionGeometryBase):\n    \"\"\"\n    This class represents a digital twin of a ultrasound detection device\n    with a linear detection geometry. The origin for this device is the center of the planar array.\n\n    \"\"\"\n\n    def __init__(self, pitch_mm=0.5,\n                 number_detector_elements_x=100,\n                 number_detector_elements_y=100,\n                 detector_element_width_mm=0.24,\n                 detector_element_length_mm=0.5,\n                 center_frequency_hz=3.96e6,\n                 bandwidth_percent=55,\n                 sampling_frequency_mhz=40,\n                 device_position_mm: np.ndarray = None,\n                 field_of_view_extent_mm: np.ndarray = None):\n        \"\"\"\n\n        :param pitch_mm:\n        :param number_detector_elements_x:\n        :param number_detector_elements_y:\n        :param detector_element_width_mm:\n        :param detector_element_length_mm:\n        :param center_frequency_hz:\n        :param bandwidth_percent:\n        :param sampling_frequency_mhz:\n        :param device_position_mm: Center of the planar array.\n        \"\"\"\n        if field_of_view_extent_mm is None:\n            field_of_view_extent_mm = np.asarray([-number_detector_elements_x * pitch_mm / 2,\n                                                  number_detector_elements_x * pitch_mm / 2,\n                                                  -number_detector_elements_y * pitch_mm / 2,\n                                                  number_detector_elements_y * pitch_mm / 2,\n                                                  0, 100])\n\n        super(PlanarArrayDetectionGeometry, self).__init__(\n            number_detector_elements=number_detector_elements_x * number_detector_elements_y,\n            detector_element_width_mm=detector_element_width_mm,\n            detector_element_length_mm=detector_element_length_mm,\n            center_frequency_hz=center_frequency_hz,\n            bandwidth_percent=bandwidth_percent,\n            sampling_frequency_mhz=sampling_frequency_mhz,\n            device_position_mm=device_position_mm,\n            field_of_view_extent_mm=field_of_view_extent_mm)\n        self.pitch_mm = pitch_mm\n        self.number_detector_elements_x = number_detector_elements_x\n        self.number_detector_elements_y = number_detector_elements_y\n        self.probe_depth_mm = number_detector_elements_y * pitch_mm\n        self.probe_width_mm = number_detector_elements_x * pitch_mm\n\n    def get_field_of_view_extent_mm(self) -> np.ndarray:\n        return np.asarray([-self.number_detector_elements_x*self.pitch_mm/2,\n                           self.number_detector_elements_x*self.pitch_mm/2,\n                           -self.number_detector_elements_y * self.pitch_mm / 2,\n                           self.number_detector_elements_y * self.pitch_mm / 2,\n                           0, 100])\n\n    def check_settings_prerequisites(self, global_settings: Settings) -> bool:\n        if global_settings[Tags.DIM_VOLUME_X_MM] < self.probe_width_mm + global_settings[Tags.SPACING_MM]:\n            self.logger.error(f\"Volume x dimension is too small to encompass RSOM device in simulation!\"\n                              f\"Must be at least {self.probe_width_mm + global_settings[Tags.SPACING_MM]} mm but \"\n                              f\"was {global_settings[Tags.DIM_VOLUME_X_MM]} mm\")\n            return False\n        if global_settings[Tags.DIM_VOLUME_Y_MM] < self.probe_depth_mm + global_settings[Tags.SPACING_MM]:\n            self.logger.error(f\"Volume y dimension is too small to encompass RSOM device in simulation!\"\n                              f\"Must be at least {self.probe_depth_mm + global_settings[Tags.SPACING_MM]} mm but \"\n                              f\"was {global_settings[Tags.DIM_VOLUME_X_MM]} mm\")\n            return False\n        return True\n\n    def update_settings_for_use_of_model_based_volume_creator(self, global_settings):\n        pass\n\n    def get_detector_element_positions_base_mm(self) -> np.ndarray:\n        detector_element_positions_mm = np.zeros((self.number_detector_elements, 3))\n        for x in range(self.number_detector_elements_x):\n            for y in range(self.number_detector_elements_y):\n                detector_element_positions_mm[x + y*self.number_detector_elements_x] = \\\n                    [(x - self.number_detector_elements_x/2 + 0.5) * self.pitch_mm,\n                     (y - self.number_detector_elements_y/2 + 0.5) * self.pitch_mm,\n                     0]\n        return detector_element_positions_mm\n\n    def get_detector_element_orientations(self) -> np.ndarray:\n        detector_element_orientations = np.zeros((self.number_detector_elements, 3))\n        detector_element_orientations[:, 2] = 1\n        return detector_element_orientations\n\n    def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {\"PlanarArrayDetectionGeometry\": serialized_device}\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_device = PlanarArrayDetectionGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "def __init__(self, pitch_mm=0.5,\n                 number_detector_elements_x=100,\n                 number_detector_elements_y=100,\n                 detector_element_width_mm=0.24,\n                 detector_element_length_mm=0.5,\n                 center_frequency_hz=3.96e6,\n                 bandwidth_percent=55,\n                 sampling_frequency_mhz=40,\n                 device_position_mm: np.ndarray = None,\n                 field_of_view_extent_mm: np.ndarray = None):\n        \"\"\"\n\n        :param pitch_mm:\n        :param number_detector_elements_x:\n        :param number_detector_elements_y:\n        :param detector_element_width_mm:\n        :param detector_element_length_mm:\n        :param center_frequency_hz:\n        :param bandwidth_percent:\n        :param sampling_frequency_mhz:\n        :param device_position_mm: Center of the planar array.\n        \"\"\"\n        if field_of_view_extent_mm is None:\n            field_of_view_extent_mm = np.asarray([-number_detector_elements_x * pitch_mm / 2,\n                                                  number_detector_elements_x * pitch_mm / 2,\n                                                  -number_detector_elements_y * pitch_mm / 2,\n                                                  number_detector_elements_y * pitch_mm / 2,\n                                                  0, 100])\n\n        super(PlanarArrayDetectionGeometry, self).__init__(\n            number_detector_elements=number_detector_elements_x * number_detector_elements_y,\n            detector_element_width_mm=detector_element_width_mm,\n            detector_element_length_mm=detector_element_length_mm,\n            center_frequency_hz=center_frequency_hz,\n            bandwidth_percent=bandwidth_percent,\n            sampling_frequency_mhz=sampling_frequency_mhz,\n            device_position_mm=device_position_mm,\n            field_of_view_extent_mm=field_of_view_extent_mm)\n        self.pitch_mm = pitch_mm\n        self.number_detector_elements_x = number_detector_elements_x\n        self.number_detector_elements_y = number_detector_elements_y\n        self.probe_depth_mm = number_detector_elements_y * pitch_mm\n        self.probe_width_mm = number_detector_elements_x * pitch_mm",
  "def get_field_of_view_extent_mm(self) -> np.ndarray:\n        return np.asarray([-self.number_detector_elements_x*self.pitch_mm/2,\n                           self.number_detector_elements_x*self.pitch_mm/2,\n                           -self.number_detector_elements_y * self.pitch_mm / 2,\n                           self.number_detector_elements_y * self.pitch_mm / 2,\n                           0, 100])",
  "def check_settings_prerequisites(self, global_settings: Settings) -> bool:\n        if global_settings[Tags.DIM_VOLUME_X_MM] < self.probe_width_mm + global_settings[Tags.SPACING_MM]:\n            self.logger.error(f\"Volume x dimension is too small to encompass RSOM device in simulation!\"\n                              f\"Must be at least {self.probe_width_mm + global_settings[Tags.SPACING_MM]} mm but \"\n                              f\"was {global_settings[Tags.DIM_VOLUME_X_MM]} mm\")\n            return False\n        if global_settings[Tags.DIM_VOLUME_Y_MM] < self.probe_depth_mm + global_settings[Tags.SPACING_MM]:\n            self.logger.error(f\"Volume y dimension is too small to encompass RSOM device in simulation!\"\n                              f\"Must be at least {self.probe_depth_mm + global_settings[Tags.SPACING_MM]} mm but \"\n                              f\"was {global_settings[Tags.DIM_VOLUME_X_MM]} mm\")\n            return False\n        return True",
  "def update_settings_for_use_of_model_based_volume_creator(self, global_settings):\n        pass",
  "def get_detector_element_positions_base_mm(self) -> np.ndarray:\n        detector_element_positions_mm = np.zeros((self.number_detector_elements, 3))\n        for x in range(self.number_detector_elements_x):\n            for y in range(self.number_detector_elements_y):\n                detector_element_positions_mm[x + y*self.number_detector_elements_x] = \\\n                    [(x - self.number_detector_elements_x/2 + 0.5) * self.pitch_mm,\n                     (y - self.number_detector_elements_y/2 + 0.5) * self.pitch_mm,\n                     0]\n        return detector_element_positions_mm",
  "def get_detector_element_orientations(self) -> np.ndarray:\n        detector_element_orientations = np.zeros((self.number_detector_elements, 3))\n        detector_element_orientations[:, 2] = 1\n        return detector_element_orientations",
  "def serialize(self) -> dict:\n        serialized_device = self.__dict__\n        return {\"PlanarArrayDetectionGeometry\": serialized_device}",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_device = PlanarArrayDetectionGeometry()\n        for key, value in dictionary_to_deserialize.items():\n            deserialized_device.__dict__[key] = value\n        return deserialized_device",
  "class ProcessingComponent(SimulationModule, ABC):\n    \"\"\"\n    Defines a simulation component, which can be used to pre- or post-process simulation data.\n    \"\"\"\n\n    def __init__(self, global_settings, component_settings_key: str):\n        \"\"\"\n        Initialises the ProcessingComponent.\n\n        :param component_settings_key: The key where the component settings are stored in\n        \"\"\"\n        super(ProcessingComponent, self).__init__(global_settings=global_settings)\n        self.component_settings = global_settings[component_settings_key]",
  "def __init__(self, global_settings, component_settings_key: str):\n        \"\"\"\n        Initialises the ProcessingComponent.\n\n        :param component_settings_key: The key where the component settings are stored in\n        \"\"\"\n        super(ProcessingComponent, self).__init__(global_settings=global_settings)\n        self.component_settings = global_settings[component_settings_key]",
  "class LinearUnmixing(MultispectralProcessingAlgorithm):\n    \"\"\"\n    Performs linear spectral unmixing (LU) using Fast Linear Unmixing for PhotoAcoustic Imaging (FLUPAI)\n    on the defined data field for each chromophore specified in the component settings.\n\n    If tag LINEAR_UNMIXING_NON_NEGATIVE is set to True non-negative linear unmixing is performed, which solves the\n    KKT (Karush-Kuhn-Tucker) conditions for the non-negative least squares problem.\n\n    This component saves a dictionary containing the chromophore concentrations and corresponding wavelengths for\n    each chromophore. If the tag LINEAR_UNMIXING_COMPUTE_SO2 is set True the blood oxygen saturation\n    is saved as well, however, this is only possible if the chromophores oxy- and deoxyhemoglobin are specified.\n    IMPORTANT:\n    Linear unmixing should only be performed with at least two wavelengths:\n    e.g. Tags.WAVELENGTHS: [750, 800]\n\n    Parameters:\n    Tags.DATA_FIELD (required)\n    Tags.LINEAR_UNMIXING_SPECTRA (required)\n    Tags.WAVELENGTHS (default: None, if None, then settings[Tags.WAVELENGTHS] will be used.)\n    Tags.LINEAR_UNMIXING_COMPUTE_SO2 (default: False)\n    Tags.LINEAR_UNMIXING_NON_NEGATIVE (default: False)\n    global_settings (required)\n    component_settings_key (required)\n    \"\"\"\n\n    def __init__(self, global_settings, component_settings_key: str):\n        super(LinearUnmixing, self).__init__(global_settings=global_settings,\n                                             component_settings_key=component_settings_key)\n\n        self.chromophore_spectra_dict = {}  # dictionary containing the spectrum for each chromophore and wavelength\n        self.absorption_matrix = []  # endmember matrix needed in LU\n        self.pseudo_inverse_absorption_matrix = []\n\n        self.chromophore_concentrations = []  # list of LU results\n        self.chromophore_concentrations_dict = {}  # dictionary of LU results\n        self.wavelengths = []  # list of wavelengths\n\n    def run(self):\n\n        self.logger.info(\"Performing linear spectral unmixing...\")\n\n        if Tags.WAVELENGTHS in self.component_settings:\n            self.wavelengths = self.component_settings[Tags.WAVELENGTHS]\n        else:\n            if Tags.WAVELENGTHS in self.global_settings:\n                self.wavelengths = self.global_settings[Tags.WAVELENGTHS]\n            else:\n                msg = \"Was not able to get wavelengths from component_settings or global_settings.\"\n                self.logger.critical(msg)\n                raise AssertionError(msg)\n\n        if len(self.wavelengths) < 2:\n            msg = \"Linear unmixing should be performed with at least two wavelengths!\"\n            self.logger.critical(msg)\n            raise AssertionError(msg)\n\n        # Build internal list of spectra based on Tags.LINEAR_UNMIXING_SPECTRA\n        self.build_chromophore_spectra_dict()\n\n        # check if absorption dictionary contains any spectra\n        if self.chromophore_spectra_dict == {}:\n            raise KeyError(\"Linear unmixing must be performed for at least one chromophore. \"\n                           \"Please specify at least one chromophore in the component settings by setting \"\n                           \"the corresponding tag.\")\n\n        # check if non-negative contraint should be used for linear unmixing\n        non_negative = False\n        if Tags.LINEAR_UNMIXING_NON_NEGATIVE in self.component_settings:\n            non_negative = Tags.LINEAR_UNMIXING_NON_NEGATIVE\n\n        # create the absorption matrix needed by FLUPAI\n        # the matrix should have the shape [#global wavelengths, #chromophores]\n        self.absorption_matrix = self.create_absorption_matrix()\n        self.logger.debug(f\"The absorption matrix has shape {np.shape(self.absorption_matrix)}.\")\n\n        # perform fast linear unmixing FLUPAI\n        # the result saved in self.chromophore_concentrations is a list with the unmixed images\n        # containing the chromophore concentration\n        self.chromophore_concentrations = self.flupai(non_negative=non_negative)\n        self.logger.debug(f\"The unmixing result has shape {np.shape(self.chromophore_concentrations)}.\")\n\n        # split results to create dictionary which contains linear unmixing result for each chromophore\n        for index, chromophore in enumerate(self.chromophore_spectra_dict.keys()):\n            self.chromophore_concentrations_dict[chromophore] = self.chromophore_concentrations[index]\n        self.logger.info(f\"The chromophore concentration was computed for chromophores: \"\n                         f\"{self.chromophore_concentrations_dict.keys()}\")\n\n        # compute blood oxygen saturation if selected\n        save_dict = {\n            \"chromophore_concentrations\": self.chromophore_concentrations_dict,\n            \"wavelengths\": self.wavelengths\n        }\n        if Tags.LINEAR_UNMIXING_COMPUTE_SO2 in self.component_settings:\n            if self.component_settings[Tags.LINEAR_UNMIXING_COMPUTE_SO2]:\n                self.logger.info(\"Blood oxygen saturation is calculated and saved.\")\n                save_dict[\"sO2\"] = self.calculate_sO2()\n\n        # save linear unmixing result in hdf5\n        save_data_field(save_dict, self.global_settings[Tags.SIMPA_OUTPUT_PATH],\n                        Tags.LINEAR_UNMIXING_RESULT, wavelength=None)\n\n        self.logger.info(\"Performing linear spectral unmixing......[Done]\")\n\n    def build_chromophore_spectra_dict(self):\n        \"\"\"\n        This function builds the absorption spectra dictionary for each chromophore using SIMPAs spectral library\n        and saves the result in self.chromophore_spectra_dict.\n        This function might have to change drastically if the design of the spectral library changes in the future!\n        \"\"\"\n\n        if Tags.LINEAR_UNMIXING_SPECTRA in self.component_settings:\n            spectra = self.component_settings[Tags.LINEAR_UNMIXING_SPECTRA]\n            if len(spectra) < 2:\n                raise AssertionError(f\"Need at least two endmembers for unmixing! You provided {len(spectra)}.\")\n            for spectrum in spectra:\n                self.create_chromophore_spectra_entry(spectrum)\n        else:\n            raise AssertionError(\"Tried to unmix without spectra definitions. Make sure that the\"\n                                 \" Tags.LINEAR_UNMIXING_SPECTRA tag is set in the linear unmixing settings.\")\n\n    def create_chromophore_spectra_entry(self, spectrum: Spectrum):\n        \"\"\"\n        This function builds the spectra for a chromophore specified by tag and name and saves it in\n        self.chromophore_spectra_dict and creates a dictionary containing the corresponding wavelengths.\n        The name must match the ones used in the spectral library of SIMPA.\n        \"\"\"\n\n        self.chromophore_spectra_dict[spectrum.spectrum_name] = [spectrum.get_value_for_wavelength(wavelength)\n                                                                 for wavelength in self.wavelengths]\n\n    def create_absorption_matrix(self) -> np.ndarray:\n        \"\"\"\n        Method that returns the absorption (endmember) matrix needed for linear unmixing.\n\n        :return: absorption matrix\n        \"\"\"\n\n        numberWavelengths = len(self.wavelengths)\n        numberChromophores = len(self.chromophore_spectra_dict.keys())\n\n        # prepare matrix\n        endmemberMatrix = np.zeros((numberWavelengths, numberChromophores))\n\n        # write absorption data for each chromophore and the corresponding wavelength into an array (matrix)\n        for index, key in enumerate(self.chromophore_spectra_dict.keys()):\n            for wave in range(numberWavelengths):\n                endmemberMatrix[wave][index] = self.chromophore_spectra_dict[key][wave]\n\n        return endmemberMatrix\n\n    def flupai(self, non_negative=False) -> list:\n        \"\"\"\n        Fast Linear Unmixing for PhotoAcoustic Imaging (FLUPAI) is based on\n        SVD decomposition with a pseudo inverse, which is equivalent to a least squares\n        ansatz for linear spectral unmixing of multi-spectral photoacoustic images.\n\n        :return: list with unmixed images containing the chromophore concentration.\n        :raise: SystemExit.\n        \"\"\"\n\n        # reshape image data to [number of wavelength, number of pixel]\n        dims_raw = np.shape(self.data)\n        try:\n            reshapedData = np.reshape(self.data, (dims_raw[0], -1))\n        except Exception:\n            self.logger.critical(f\"FLUPAI failed probably caused by wrong input dimensions of {dims_raw}!\")\n            raise ValueError(\"Reshaping of input data failed. FLUPAI expects a 4 dimensional numpy array, \"\n                             \"where the first dimension represents the wavelengths and the second, third and fourth \"\n                             \"dimension are representing a single wavelength PA image.\")\n\n        # if non_negative is False, matmul of x = PI * b with x chromophore information,\n        # PI pseudo inverse with absorber information and b containing the measured pixel,\n        # else non-negative least squares is performed.\n        try:\n            if non_negative:\n                output = []\n                for i in range(np.shape(reshapedData)[1]):\n                    foo, ris = nnls(np.array(self.absorption_matrix), reshapedData[:, i])\n                    output.append(foo)\n\n                output = np.swapaxes(output, axis1=0, axis2=1)\n            else:\n                self.pseudo_inverse_absorption_matrix = linalg.pinv(self.absorption_matrix)\n                output = np.matmul(self.pseudo_inverse_absorption_matrix, reshapedData)\n\n        except Exception as e:\n            self.logger.critical(f\"Matrix multiplication failed probably caused by mismatching dimensions of absorption\"\n                                 f\"matrix ({len(self.absorption_matrix[1])}) and \"\n                                 f\"input data ({dims_raw[0]})!\")\n            print(e)\n            raise ValueError(\"Absorption matrix and input data must have matching sizes...\")\n\n    # write output into list of images containing the chromophore information\n        numberChromophores = np.shape(output)[0]\n        chromophores_concentrations = []\n        for chromophore in range(numberChromophores):\n            chromophores_concentrations.append(np.reshape(output[chromophore, :], (dims_raw[1:])))\n        return chromophores_concentrations\n\n    def calculate_sO2(self) -> np.ndarray:\n        \"\"\"\n        Function calculates sO2 (blood oxygen saturation) values for given concentrations\n        of oxyhemoglobin and deoxyhemoglobin. Of course this is only possible if the concentrations of both\n        chromophores were calculated by this component/were specified in settings.\n        \"\"\"\n\n        try:\n            concentration_oxy = self.chromophore_concentrations_dict[\"Oxyhemoglobin\"]\n            concentration_deoxy = self.chromophore_concentrations_dict[\"Deoxyhemoglobin\"]\n\n            sO2 = concentration_oxy / (concentration_oxy + concentration_deoxy)\n            # if total hemoglobin is zero handle NaN by setting sO2 to zero\n            where_are_NaNs = np.isnan(sO2)\n            sO2[where_are_NaNs] = 0\n            return sO2\n\n        except Exception:\n            raise KeyError(\"Chromophores oxy- and/or deoxyhemoglobin were not specified in component settings, \"\n                           \"so so2 cannot be calculated!\")",
  "def __init__(self, global_settings, component_settings_key: str):\n        super(LinearUnmixing, self).__init__(global_settings=global_settings,\n                                             component_settings_key=component_settings_key)\n\n        self.chromophore_spectra_dict = {}  # dictionary containing the spectrum for each chromophore and wavelength\n        self.absorption_matrix = []  # endmember matrix needed in LU\n        self.pseudo_inverse_absorption_matrix = []\n\n        self.chromophore_concentrations = []  # list of LU results\n        self.chromophore_concentrations_dict = {}  # dictionary of LU results\n        self.wavelengths = []",
  "def run(self):\n\n        self.logger.info(\"Performing linear spectral unmixing...\")\n\n        if Tags.WAVELENGTHS in self.component_settings:\n            self.wavelengths = self.component_settings[Tags.WAVELENGTHS]\n        else:\n            if Tags.WAVELENGTHS in self.global_settings:\n                self.wavelengths = self.global_settings[Tags.WAVELENGTHS]\n            else:\n                msg = \"Was not able to get wavelengths from component_settings or global_settings.\"\n                self.logger.critical(msg)\n                raise AssertionError(msg)\n\n        if len(self.wavelengths) < 2:\n            msg = \"Linear unmixing should be performed with at least two wavelengths!\"\n            self.logger.critical(msg)\n            raise AssertionError(msg)\n\n        # Build internal list of spectra based on Tags.LINEAR_UNMIXING_SPECTRA\n        self.build_chromophore_spectra_dict()\n\n        # check if absorption dictionary contains any spectra\n        if self.chromophore_spectra_dict == {}:\n            raise KeyError(\"Linear unmixing must be performed for at least one chromophore. \"\n                           \"Please specify at least one chromophore in the component settings by setting \"\n                           \"the corresponding tag.\")\n\n        # check if non-negative contraint should be used for linear unmixing\n        non_negative = False\n        if Tags.LINEAR_UNMIXING_NON_NEGATIVE in self.component_settings:\n            non_negative = Tags.LINEAR_UNMIXING_NON_NEGATIVE\n\n        # create the absorption matrix needed by FLUPAI\n        # the matrix should have the shape [#global wavelengths, #chromophores]\n        self.absorption_matrix = self.create_absorption_matrix()\n        self.logger.debug(f\"The absorption matrix has shape {np.shape(self.absorption_matrix)}.\")\n\n        # perform fast linear unmixing FLUPAI\n        # the result saved in self.chromophore_concentrations is a list with the unmixed images\n        # containing the chromophore concentration\n        self.chromophore_concentrations = self.flupai(non_negative=non_negative)\n        self.logger.debug(f\"The unmixing result has shape {np.shape(self.chromophore_concentrations)}.\")\n\n        # split results to create dictionary which contains linear unmixing result for each chromophore\n        for index, chromophore in enumerate(self.chromophore_spectra_dict.keys()):\n            self.chromophore_concentrations_dict[chromophore] = self.chromophore_concentrations[index]\n        self.logger.info(f\"The chromophore concentration was computed for chromophores: \"\n                         f\"{self.chromophore_concentrations_dict.keys()}\")\n\n        # compute blood oxygen saturation if selected\n        save_dict = {\n            \"chromophore_concentrations\": self.chromophore_concentrations_dict,\n            \"wavelengths\": self.wavelengths\n        }\n        if Tags.LINEAR_UNMIXING_COMPUTE_SO2 in self.component_settings:\n            if self.component_settings[Tags.LINEAR_UNMIXING_COMPUTE_SO2]:\n                self.logger.info(\"Blood oxygen saturation is calculated and saved.\")\n                save_dict[\"sO2\"] = self.calculate_sO2()\n\n        # save linear unmixing result in hdf5\n        save_data_field(save_dict, self.global_settings[Tags.SIMPA_OUTPUT_PATH],\n                        Tags.LINEAR_UNMIXING_RESULT, wavelength=None)\n\n        self.logger.info(\"Performing linear spectral unmixing......[Done]\")",
  "def build_chromophore_spectra_dict(self):\n        \"\"\"\n        This function builds the absorption spectra dictionary for each chromophore using SIMPAs spectral library\n        and saves the result in self.chromophore_spectra_dict.\n        This function might have to change drastically if the design of the spectral library changes in the future!\n        \"\"\"\n\n        if Tags.LINEAR_UNMIXING_SPECTRA in self.component_settings:\n            spectra = self.component_settings[Tags.LINEAR_UNMIXING_SPECTRA]\n            if len(spectra) < 2:\n                raise AssertionError(f\"Need at least two endmembers for unmixing! You provided {len(spectra)}.\")\n            for spectrum in spectra:\n                self.create_chromophore_spectra_entry(spectrum)\n        else:\n            raise AssertionError(\"Tried to unmix without spectra definitions. Make sure that the\"\n                                 \" Tags.LINEAR_UNMIXING_SPECTRA tag is set in the linear unmixing settings.\")",
  "def create_chromophore_spectra_entry(self, spectrum: Spectrum):\n        \"\"\"\n        This function builds the spectra for a chromophore specified by tag and name and saves it in\n        self.chromophore_spectra_dict and creates a dictionary containing the corresponding wavelengths.\n        The name must match the ones used in the spectral library of SIMPA.\n        \"\"\"\n\n        self.chromophore_spectra_dict[spectrum.spectrum_name] = [spectrum.get_value_for_wavelength(wavelength)\n                                                                 for wavelength in self.wavelengths]",
  "def create_absorption_matrix(self) -> np.ndarray:\n        \"\"\"\n        Method that returns the absorption (endmember) matrix needed for linear unmixing.\n\n        :return: absorption matrix\n        \"\"\"\n\n        numberWavelengths = len(self.wavelengths)\n        numberChromophores = len(self.chromophore_spectra_dict.keys())\n\n        # prepare matrix\n        endmemberMatrix = np.zeros((numberWavelengths, numberChromophores))\n\n        # write absorption data for each chromophore and the corresponding wavelength into an array (matrix)\n        for index, key in enumerate(self.chromophore_spectra_dict.keys()):\n            for wave in range(numberWavelengths):\n                endmemberMatrix[wave][index] = self.chromophore_spectra_dict[key][wave]\n\n        return endmemberMatrix",
  "def flupai(self, non_negative=False) -> list:\n        \"\"\"\n        Fast Linear Unmixing for PhotoAcoustic Imaging (FLUPAI) is based on\n        SVD decomposition with a pseudo inverse, which is equivalent to a least squares\n        ansatz for linear spectral unmixing of multi-spectral photoacoustic images.\n\n        :return: list with unmixed images containing the chromophore concentration.\n        :raise: SystemExit.\n        \"\"\"\n\n        # reshape image data to [number of wavelength, number of pixel]\n        dims_raw = np.shape(self.data)\n        try:\n            reshapedData = np.reshape(self.data, (dims_raw[0], -1))\n        except Exception:\n            self.logger.critical(f\"FLUPAI failed probably caused by wrong input dimensions of {dims_raw}!\")\n            raise ValueError(\"Reshaping of input data failed. FLUPAI expects a 4 dimensional numpy array, \"\n                             \"where the first dimension represents the wavelengths and the second, third and fourth \"\n                             \"dimension are representing a single wavelength PA image.\")\n\n        # if non_negative is False, matmul of x = PI * b with x chromophore information,\n        # PI pseudo inverse with absorber information and b containing the measured pixel,\n        # else non-negative least squares is performed.\n        try:\n            if non_negative:\n                output = []\n                for i in range(np.shape(reshapedData)[1]):\n                    foo, ris = nnls(np.array(self.absorption_matrix), reshapedData[:, i])\n                    output.append(foo)\n\n                output = np.swapaxes(output, axis1=0, axis2=1)\n            else:\n                self.pseudo_inverse_absorption_matrix = linalg.pinv(self.absorption_matrix)\n                output = np.matmul(self.pseudo_inverse_absorption_matrix, reshapedData)\n\n        except Exception as e:\n            self.logger.critical(f\"Matrix multiplication failed probably caused by mismatching dimensions of absorption\"\n                                 f\"matrix ({len(self.absorption_matrix[1])}) and \"\n                                 f\"input data ({dims_raw[0]})!\")\n            print(e)\n            raise ValueError(\"Absorption matrix and input data must have matching sizes...\")\n\n    # write output into list of images containing the chromophore information\n        numberChromophores = np.shape(output)[0]\n        chromophores_concentrations = []\n        for chromophore in range(numberChromophores):\n            chromophores_concentrations.append(np.reshape(output[chromophore, :], (dims_raw[1:])))\n        return chromophores_concentrations",
  "def calculate_sO2(self) -> np.ndarray:\n        \"\"\"\n        Function calculates sO2 (blood oxygen saturation) values for given concentrations\n        of oxyhemoglobin and deoxyhemoglobin. Of course this is only possible if the concentrations of both\n        chromophores were calculated by this component/were specified in settings.\n        \"\"\"\n\n        try:\n            concentration_oxy = self.chromophore_concentrations_dict[\"Oxyhemoglobin\"]\n            concentration_deoxy = self.chromophore_concentrations_dict[\"Deoxyhemoglobin\"]\n\n            sO2 = concentration_oxy / (concentration_oxy + concentration_deoxy)\n            # if total hemoglobin is zero handle NaN by setting sO2 to zero\n            where_are_NaNs = np.isnan(sO2)\n            sO2[where_are_NaNs] = 0\n            return sO2\n\n        except Exception:\n            raise KeyError(\"Chromophores oxy- and/or deoxyhemoglobin were not specified in component settings, \"\n                           \"so so2 cannot be calculated!\")",
  "class MultispectralProcessingAlgorithm(ABC):\n    \"\"\"\n    A MultispectralProcessingAlgorithm class represents an algorithm that works with multispectral input data.\n    \"\"\"\n\n    def __init__(self, global_settings, component_settings_key: str):\n        \"\"\"\n        Instantiates a multispectral processing algorithm.\n\n        Per default, this methods loads all data from a certain\n        Tags.DATA_FIELD into a data array for all\n        Tags.WAVELENGTHS.\n\n        \"\"\"\n        if component_settings_key is None:\n            raise KeyError(\"The component settings must be set for a multispectral\"\n                           \"processing algorithm!\")\n        self.component_settings = global_settings[component_settings_key]\n\n        if Tags.WAVELENGTHS not in self.component_settings:\n            raise KeyError(\"Tags.WAVELENGTHS must be in the component_settings of a multispectral processing algorithm\")\n\n        if Tags.DATA_FIELD not in self.component_settings:\n            raise KeyError(\"Tags.DATA_FIELD must be in the component_settings of a multispectral processing algorithm\")\n\n        self.logger = Logger()\n        self.global_settings = global_settings\n        self.wavelengths = self.component_settings[Tags.WAVELENGTHS]\n        self.data_field = self.component_settings[Tags.DATA_FIELD]\n\n        self.data = list()\n        for i in range(len(self.wavelengths)):\n            self.data.append(load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH],\n                                             self.data_field,\n                                             self.wavelengths[i]))\n\n        self.data = np.asarray(self.data)\n        if Tags.SIGNAL_THRESHOLD in self.component_settings:\n            self.data[self.data < self.component_settings[Tags.SIGNAL_THRESHOLD]*np.max(self.data)] = 0\n\n    @abstractmethod\n    def run(self):\n        \"\"\"\n        This method must be implemented by the multispectral algorithm, such that\n        any multispectral algorithm can be executed by invoking the run method.\n        \"\"\"\n        pass",
  "def __init__(self, global_settings, component_settings_key: str):\n        \"\"\"\n        Instantiates a multispectral processing algorithm.\n\n        Per default, this methods loads all data from a certain\n        Tags.DATA_FIELD into a data array for all\n        Tags.WAVELENGTHS.\n\n        \"\"\"\n        if component_settings_key is None:\n            raise KeyError(\"The component settings must be set for a multispectral\"\n                           \"processing algorithm!\")\n        self.component_settings = global_settings[component_settings_key]\n\n        if Tags.WAVELENGTHS not in self.component_settings:\n            raise KeyError(\"Tags.WAVELENGTHS must be in the component_settings of a multispectral processing algorithm\")\n\n        if Tags.DATA_FIELD not in self.component_settings:\n            raise KeyError(\"Tags.DATA_FIELD must be in the component_settings of a multispectral processing algorithm\")\n\n        self.logger = Logger()\n        self.global_settings = global_settings\n        self.wavelengths = self.component_settings[Tags.WAVELENGTHS]\n        self.data_field = self.component_settings[Tags.DATA_FIELD]\n\n        self.data = list()\n        for i in range(len(self.wavelengths)):\n            self.data.append(load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH],\n                                             self.data_field,\n                                             self.wavelengths[i]))\n\n        self.data = np.asarray(self.data)\n        if Tags.SIGNAL_THRESHOLD in self.component_settings:\n            self.data[self.data < self.component_settings[Tags.SIGNAL_THRESHOLD]*np.max(self.data)] = 0",
  "def run(self):\n        \"\"\"\n        This method must be implemented by the multispectral algorithm, such that\n        any multispectral algorithm can be executed by invoking the run method.\n        \"\"\"\n        pass",
  "class FieldOfViewCropping(ProcessingComponent):\n\n    def __init__(self, global_settings, settings_key=None):\n        if settings_key is None:\n            # TODO Extract from global settings all the fields that should be cropped\n            global_settings[\"FieldOfViewCropping\"] = Settings({\n                Tags.DATA_FIELD: TissueProperties.property_tags +\n                [Tags.DATA_FIELD_FLUENCE,\n                 Tags.DATA_FIELD_INITIAL_PRESSURE]})\n        super(FieldOfViewCropping, self).__init__(global_settings, \"FieldOfViewCropping\")\n    \"\"\"\n    Applies Gaussian noise to the defined data field.\n    The noise will be applied to all wavelengths.\n    Component Settings\n       **Tags.DATA_FIELD required\n    \"\"\"\n\n    def run(self, device: DigitalDeviceTwinBase):\n        self.logger.info(\"Cropping field of view...\")\n\n        if Tags.DATA_FIELD not in self.component_settings.keys():\n            msg = f\"The field {Tags.DATA_FIELD} must be set in order to use the fov cropping.\"\n            self.logger.critical(msg)\n            raise KeyError(msg)\n\n        if not isinstance(self.component_settings[Tags.DATA_FIELD], list):\n            msg = f\"The field {Tags.DATA_FIELD} must be of type list.\"\n            self.logger.critical(msg)\n            raise TypeError(msg)\n\n        data_fields = self.component_settings[Tags.DATA_FIELD]\n\n        if isinstance(device, PhotoacousticDevice):\n            field_of_view_mm = device.detection_geometry.get_field_of_view_mm()\n        else:\n            field_of_view_mm = device.get_field_of_view_mm()\n        self.logger.debug(f\"FOV (mm): {field_of_view_mm}\")\n        field_of_view_voxels = np.round(field_of_view_mm / self.global_settings[Tags.SPACING_MM]).astype(np.int32)\n        self.logger.debug(f\"FOV (voxels): {field_of_view_voxels}\")\n\n        # In case it should be cropped from A to A, then crop from A to A+1\n        x_offset_correct = 1 if (field_of_view_voxels[1] - field_of_view_voxels[0]) < 1 else 0\n        y_offset_correct = 1 if (field_of_view_voxels[3] - field_of_view_voxels[2]) < 1 else 0\n        z_offset_correct = 1 if (field_of_view_voxels[5] - field_of_view_voxels[4]) < 1 else 0\n\n        self.logger.debug(f\"field of view to crop: {field_of_view_voxels}\")\n\n        for data_field in data_fields:\n            self.logger.debug(f\"Cropping data field {data_field}...\")\n\n            # load\n            wavelength = self.global_settings[Tags.WAVELENGTH]\n            data_array = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n            self.logger.debug(f\"data array shape before cropping: {np.shape(data_array)}\")\n            self.logger.debug(f\"data array shape len: {len(np.shape(data_array))}\")\n\n            # input validation\n            if not isinstance(data_array, np.ndarray):\n                self.logger.warning(f\"The data field {data_field} was not of type np.ndarray. Skipping...\")\n                continue\n            data_field_shape = np.shape(data_array)\n            if len(data_field_shape) == 3:\n                if ((np.array([field_of_view_voxels[1] - field_of_view_voxels[0],\n                              field_of_view_voxels[3] - field_of_view_voxels[2],\n                              field_of_view_voxels[5] - field_of_view_voxels[4]]) - data_field_shape) == 0).all():\n                    self.logger.warning(f\"The data field {data_field} is already cropped. Skipping...\")\n                    continue\n\n                # crop\n                data_array = np.squeeze(data_array[field_of_view_voxels[0]:field_of_view_voxels[1] + x_offset_correct,\n                                        field_of_view_voxels[2]:field_of_view_voxels[3] + y_offset_correct,\n                                        field_of_view_voxels[4]:field_of_view_voxels[5] + z_offset_correct])\n\n            elif len(data_field_shape) == 2:\n                # Assumption that the data field is already in 2D shape in the y-plane\n                if (np.array([field_of_view_voxels[1] - field_of_view_voxels[0],\n                              field_of_view_voxels[5] - field_of_view_voxels[4]]) - data_field_shape == 0).all():\n                    self.logger.warning(f\"The data field {data_field} is already cropped. Skipping...\")\n                    continue\n\n                # crop\n                data_array = np.squeeze(data_array[field_of_view_voxels[0]:field_of_view_voxels[1] + x_offset_correct,\n                                        field_of_view_voxels[4]:field_of_view_voxels[5] + z_offset_correct])\n\n            self.logger.debug(f\"data array shape after cropping: {np.shape(data_array)}\")\n            # save\n            save_data_field(data_array, self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        self.logger.info(\"Cropping field of view...[Done]\")",
  "def __init__(self, global_settings, settings_key=None):\n        if settings_key is None:\n            # TODO Extract from global settings all the fields that should be cropped\n            global_settings[\"FieldOfViewCropping\"] = Settings({\n                Tags.DATA_FIELD: TissueProperties.property_tags +\n                [Tags.DATA_FIELD_FLUENCE,\n                 Tags.DATA_FIELD_INITIAL_PRESSURE]})\n        super(FieldOfViewCropping, self).__init__(global_settings, \"FieldOfViewCropping\")",
  "def run(self, device: DigitalDeviceTwinBase):\n        self.logger.info(\"Cropping field of view...\")\n\n        if Tags.DATA_FIELD not in self.component_settings.keys():\n            msg = f\"The field {Tags.DATA_FIELD} must be set in order to use the fov cropping.\"\n            self.logger.critical(msg)\n            raise KeyError(msg)\n\n        if not isinstance(self.component_settings[Tags.DATA_FIELD], list):\n            msg = f\"The field {Tags.DATA_FIELD} must be of type list.\"\n            self.logger.critical(msg)\n            raise TypeError(msg)\n\n        data_fields = self.component_settings[Tags.DATA_FIELD]\n\n        if isinstance(device, PhotoacousticDevice):\n            field_of_view_mm = device.detection_geometry.get_field_of_view_mm()\n        else:\n            field_of_view_mm = device.get_field_of_view_mm()\n        self.logger.debug(f\"FOV (mm): {field_of_view_mm}\")\n        field_of_view_voxels = np.round(field_of_view_mm / self.global_settings[Tags.SPACING_MM]).astype(np.int32)\n        self.logger.debug(f\"FOV (voxels): {field_of_view_voxels}\")\n\n        # In case it should be cropped from A to A, then crop from A to A+1\n        x_offset_correct = 1 if (field_of_view_voxels[1] - field_of_view_voxels[0]) < 1 else 0\n        y_offset_correct = 1 if (field_of_view_voxels[3] - field_of_view_voxels[2]) < 1 else 0\n        z_offset_correct = 1 if (field_of_view_voxels[5] - field_of_view_voxels[4]) < 1 else 0\n\n        self.logger.debug(f\"field of view to crop: {field_of_view_voxels}\")\n\n        for data_field in data_fields:\n            self.logger.debug(f\"Cropping data field {data_field}...\")\n\n            # load\n            wavelength = self.global_settings[Tags.WAVELENGTH]\n            data_array = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n            self.logger.debug(f\"data array shape before cropping: {np.shape(data_array)}\")\n            self.logger.debug(f\"data array shape len: {len(np.shape(data_array))}\")\n\n            # input validation\n            if not isinstance(data_array, np.ndarray):\n                self.logger.warning(f\"The data field {data_field} was not of type np.ndarray. Skipping...\")\n                continue\n            data_field_shape = np.shape(data_array)\n            if len(data_field_shape) == 3:\n                if ((np.array([field_of_view_voxels[1] - field_of_view_voxels[0],\n                              field_of_view_voxels[3] - field_of_view_voxels[2],\n                              field_of_view_voxels[5] - field_of_view_voxels[4]]) - data_field_shape) == 0).all():\n                    self.logger.warning(f\"The data field {data_field} is already cropped. Skipping...\")\n                    continue\n\n                # crop\n                data_array = np.squeeze(data_array[field_of_view_voxels[0]:field_of_view_voxels[1] + x_offset_correct,\n                                        field_of_view_voxels[2]:field_of_view_voxels[3] + y_offset_correct,\n                                        field_of_view_voxels[4]:field_of_view_voxels[5] + z_offset_correct])\n\n            elif len(data_field_shape) == 2:\n                # Assumption that the data field is already in 2D shape in the y-plane\n                if (np.array([field_of_view_voxels[1] - field_of_view_voxels[0],\n                              field_of_view_voxels[5] - field_of_view_voxels[4]]) - data_field_shape == 0).all():\n                    self.logger.warning(f\"The data field {data_field} is already cropped. Skipping...\")\n                    continue\n\n                # crop\n                data_array = np.squeeze(data_array[field_of_view_voxels[0]:field_of_view_voxels[1] + x_offset_correct,\n                                        field_of_view_voxels[4]:field_of_view_voxels[5] + z_offset_correct])\n\n            self.logger.debug(f\"data array shape after cropping: {np.shape(data_array)}\")\n            # save\n            save_data_field(data_array, self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        self.logger.info(\"Cropping field of view...[Done]\")",
  "class IterativeqPAI(ProcessingComponent):\n    \"\"\"\n    Applies iterative qPAI Algorithm [1] on simulated initial pressure map and saves the\n    reconstruction result in the hdf5 output file. If a 2-d map of initial_pressure is passed the algorithm saves\n    the reconstructed absorption coefficients as a 2-d map, else a 3-d absorption reconstruction is\n    saved.\n    The reconstruction result is saved as an image processing entry \"iterative_qpai_result\" in the hdf5 output file.\n    If intended (e.g. for testing) a list of intermediate iteration updates (only 2-d middle slices) can be saved\n    as a npy file.\n    To run the reconstruction the scattering coefficients must be known a priori.\n    Parameters:\n    Tags.DOWNSCALE_FACTOR (default: 0.73)\n    Tags.ITERATIVE_RECONSTRUCTION_CONSTANT_REGULARIZATION (default: False)\n    Tags.ITERATIVE_RECONSTRUCTION_MAX_ITERATION_NUMBER (default: 10)\n    Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA (default: 0.01)\n    Tags.ITERATIVE_RECONSTRUCTION_SAVE_INTERMEDIATE_RESULTS (default: False)\n    Tags.ITERATIVE_RECONSTRUCTION_STOPPING_LEVEL (default: 0.03)\n    global_settings (required)\n    component_settings_key (required)\n\n    [1] B. T. Cox et al. 2006, \"Two-dimensional quantitative photoacoustic image reconstruction of absorption\n    distributions in scattering media by use of a simple iterative method\", https://doi.org/10.1364/ao.45.001866\n    \"\"\"\n\n    def __init__(self, global_settings, component_settings_key: str):\n        super(ProcessingComponent, self).__init__(global_settings=global_settings)\n\n        self.global_settings = global_settings\n        self.optical_settings = global_settings.get_optical_settings()\n        self.iterative_method_settings = Settings(global_settings[component_settings_key])\n\n        # must be extracted due to resampling\n        self.original_spacing = global_settings[Tags.SPACING_MM]\n        if Tags.DOWNSCALE_FACTOR in self.iterative_method_settings:\n            self.downscale_factor = self.iterative_method_settings[Tags.DOWNSCALE_FACTOR]\n        else:\n            self.downscale_factor = 0.73\n\n    def run(self, pa_device):\n        self.logger.info(\"Reconstructing absorption using iterative qPAI method...\")\n\n        # check if simulation_path and optical_model_binary_path exist\n        self.logger.debug(f\"Simulation path: {self.global_settings[Tags.SIMULATION_PATH]}\")\n        self.logger.debug(f\"Optical model binary path: {self.optical_settings[Tags.OPTICAL_MODEL_BINARY_PATH]}\")\n\n        if not os.path.exists(self.global_settings[Tags.SIMULATION_PATH]):\n            print(\"Tags.SIMULATION_PATH tag in settings cannot be found.\")\n\n        if not os.path.exists(self.optical_settings[Tags.OPTICAL_MODEL_BINARY_PATH]):\n            print(\"Tags.OPTICAL_MODEL_BINARY_PATH tag in settings cannot be found.\")\n\n        # debug reconstruction settings\n        self.logger.debug(f\"Resampling factor: {self.downscale_factor}\")\n\n        if Tags.ITERATIVE_RECONSTRUCTION_MAX_ITERATION_NUMBER in self.iterative_method_settings:\n            self.logger.debug(f\"Maximum number of iterations:\"\n                              f\" {self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_MAX_ITERATION_NUMBER]}\")\n        else:\n            self.logger.debug(\"Maximum number of iterations: 10\")\n\n        if Tags.ITERATIVE_RECONSTRUCTION_SAVE_INTERMEDIATE_RESULTS in self.iterative_method_settings:\n            self.logger.debug(f\"Save intermediate absorptions:\"\n                              f\" {self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_SAVE_INTERMEDIATE_RESULTS]}\")\n        else:\n            self.logger.debug(\"Save intermediate absorptions: False\")\n\n        # bypass JSON-dump error by manually caching seeds as int()\n        if Tags.RANDOM_SEED in self.global_settings:\n            self.global_settings[Tags.RANDOM_SEED] = int(self.global_settings[Tags.RANDOM_SEED])\n        if Tags.MCX_SEED in self.optical_settings:\n            self.optical_settings[Tags.MCX_SEED] = int(self.optical_settings[Tags.MCX_SEED])\n\n        # run reconstruction\n        reconstructed_absorption, list_of_intermediate_absorptions = self.iterative_absorption_reconstruction(pa_device)\n\n        # make sure that settings are not changed due to resampling\n        if self.global_settings[Tags.SPACING_MM] != self.original_spacing:\n            self.global_settings[Tags.SPACING_MM] = self.original_spacing\n\n        # save absorption update of last iteration step in hdf5 data field\n        # bypass wavelength error resulting from loading settings from existing hdf5 file\n        if Tags.WAVELENGTH in self.global_settings:\n            wavelength = self.global_settings[Tags.WAVELENGTH]\n        else:\n            wavelength = self.global_settings[Tags.WAVELENGTHS][0]\n        data_field = Tags.ITERATIVE_qPAI_RESULT\n        save_data_field(reconstructed_absorption, self.global_settings[Tags.SIMPA_OUTPUT_PATH],\n                        data_field, wavelength)\n\n        # save a list of all intermediate absorption (2-d only) updates in npy file if intended\n        # (e.g. for testing algorithm)\n        if Tags.ITERATIVE_RECONSTRUCTION_SAVE_INTERMEDIATE_RESULTS in self.iterative_method_settings:\n            if self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_SAVE_INTERMEDIATE_RESULTS]:\n                dst = self.global_settings[Tags.SIMULATION_PATH] + \"/List_reconstructed_qpai_absorptions_\" \\\n                    + str(wavelength) + \"_\"\n                np.save(dst + self.global_settings[Tags.VOLUME_NAME] + \".npy\", list_of_intermediate_absorptions)\n\n        self.logger.info(\"Reconstructing absorption using iterative qPAI method...[Done]\")\n\n    def iterative_absorption_reconstruction(self, pa_device) -> Tuple[np.ndarray, list]:\n        \"\"\"\n        Performs quantitative photoacoustic image reconstruction of absorption distribution by use of an\n        iterative method. The distribution of scattering coefficients must be known a priori.\n\n        :return: Reconstructed absorption coefficients in 1/cm.\n        :raises: TypeError: if input data are not passed as a certain type\n                 ValueError: if input data cannot be used for reconstruction due to shape or value\n                 FileNotFoundError: if paths stored in settings cannot be accessed\n                 AssertionError: is Tags.MAX_NUMBER_ITERATIVE_RECONSTRUCTION tag is zero\n        \"\"\"\n\n        # extract \"measured\" initial pressure and a priori scattering data\n        target_intial_pressure, scattering, anisotropy = self.extract_initial_data_from_hdf5()\n\n        # checking input data\n        if not isinstance(target_intial_pressure, np.ndarray):\n            raise TypeError(\"Image data is not a numpy ndarray.\")\n        elif target_intial_pressure.size == 0:\n            raise ValueError(\"Image data is empty.\")\n        elif (len(target_intial_pressure.shape) < 2) or (len(target_intial_pressure.shape) > 3):\n            raise ValueError(\"Image data is invalid. Data must be two or three dimensional.\")\n\n        if not isinstance(scattering, np.ndarray):\n            raise TypeError(\"Scattering input is not a numpy ndarray.\")\n        elif scattering.shape != target_intial_pressure.shape:\n            raise ValueError(\"Shape of scattering data is invalid. Scattering must have the same shape as image_data.\")\n\n        # get optical properties necessary for simulation\n        optical_properties_dict = self.standard_optical_properties(target_intial_pressure)\n        if scattering is None:\n            scattering = optical_properties_dict[\"scattering\"]\n        if anisotropy is None:\n            anisotropy = optical_properties_dict[\"anisotropy\"]\n\n        # preprocessing for iterative qPAI method and mcx_adapter\n        target_intial_pressure, scattering, anisotropy, stacked_to_volume = self.preprocessing_for_iterative_qpai(\n            intial_pressure=target_intial_pressure,\n            scattering=scattering,\n            anisotropy=anisotropy)\n\n        # regularization parameter sigma\n        sigma = self.regularization_sigma(target_intial_pressure, stacked_to_volume)\n\n        # initialization\n        absorption = 1e-16 * np.ones(np.shape(target_intial_pressure))\n        y_pos = int(np.shape(absorption)[1] / 2)  # to extract middle slice\n        list_of_intermediate_absorptions = []  # if intentional all intermediate iteration updates can be returned\n        error_list = []\n\n        nmax = 10\n        if Tags.ITERATIVE_RECONSTRUCTION_MAX_ITERATION_NUMBER in self.iterative_method_settings:\n            if self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_MAX_ITERATION_NUMBER] == 0:\n                raise AssertionError(\"Tags.MAX_NUMBER_ITERATIVE_RECONSTRUCTION tag is invalid (equals zero).\")\n            nmax = int(self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_MAX_ITERATION_NUMBER])\n\n        # run algorithm\n        start_time = time.time()\n\n        i = 0\n        while i < nmax:\n            print(\"Iteration: \", i)\n            # core method\n            fluence = self.forward_model_fluence(absorption, scattering, anisotropy, pa_device)\n            error_list.append(self.log_sum_squared_error(target_intial_pressure, absorption, fluence, sigma))\n            absorption = self.update_absorption_estimate(target_intial_pressure, fluence, sigma)\n\n            est_p0 = absorption * fluence\n\n            # only store middle slice (2-d image instead of 3-d volume) in iteration list for better performance\n            list_of_intermediate_absorptions.append(absorption[:, y_pos, :])\n\n            # check if current error did not change significantly in comparison to preceding error\n            if self.convergence_stopping_criterion(error_list, iteration=i):\n                if Tags.ITERATIVE_RECONSTRUCTION_SAVE_LAST_FLUENCE:\n                    dst = self.global_settings[Tags.SIMULATION_PATH] + \"/last_fluence\" + \"_\"\n                    np.save(dst + self.global_settings[Tags.VOLUME_NAME] + \".npy\", fluence)\n                break\n            i += 1\n\n        print(\"--- %s seconds/iteration ---\" % round((time.time() - start_time) / (i + 1), 2))\n\n        # extracting field of view if input initial pressure was passed as a 2-d array\n        if stacked_to_volume:\n            absorption = absorption[:, y_pos, :]\n\n        # function returns the last iteration result as a numpy array and all iteration results in a list\n        return absorption, list_of_intermediate_absorptions\n\n    def extract_initial_data_from_hdf5(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Extract necessary information - initial pressure and scattering coefficients -\n        from settings dictionaries. The setting dictionaries is extracted from a hdf5 file.\n\n        :return: Initial pressure and a priori known scattering coefficients.\n        \"\"\"\n\n        # get simulation output which contains initial pressure and scattering\n        # bypass wavelength error resulting from loading settings from existing hdf5 file\n        if Tags.WAVELENGTH in self.global_settings:\n            wavelength = self.global_settings[Tags.WAVELENGTH]\n        else:\n            wavelength = self.global_settings[Tags.WAVELENGTHS][0]\n        self.logger.debug(f\"Wavelength: {wavelength}\")\n        # get initial pressure and scattering\n        initial_pressure = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH],\n                                           Tags.DATA_FIELD_INITIAL_PRESSURE,\n                                           wavelength)\n        scattering = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], Tags.DATA_FIELD_SCATTERING_PER_CM,\n                                     wavelength)\n\n        anisotropy = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], Tags.DATA_FIELD_ANISOTROPY,\n                                     wavelength)\n\n        # function returns the last iteration result as a numpy array and all iteration results in a list\n        return initial_pressure, scattering, anisotropy\n\n    def preprocessing_for_iterative_qpai(self, intial_pressure: np.ndarray,\n                                         scattering: np.ndarray,\n                                         anisotropy: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, bool]:\n        \"\"\"\n        Preprocesses image data and scattering distribution for iterative algorithm using mcx.\n        The preprocessing step includes:\n        1. Stacking the input data from 2-d to 3-d if necessary, since the mcx adapter can only perform\n           a Monte Carlo Simulation of fluence given 3-d volumes of absorption, scattering, and anisotropy\n        2. Resampling the input data to mitigate the inverse crime\n\n        :param intial_pressure: Raw input image of initial pressure.\n        :param scattering: Map of scattering coefficients known a priori.\n        :return: Resampled and (if necessary) stacked volume of noisy\n                 initial pressure, scattering and bool indicating if image had to be stacked to 3-d.\n        \"\"\"\n\n        if len(np.shape(intial_pressure)) == 2:\n            if Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA in self.iterative_method_settings:\n                sigma = self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA]\n            else:\n                sigma = 1e-2\n            self.logger.warning(\"Input data is 2 dimensional and will be stacked to 3 dimensions. \"\n                                \"Algorithm is attempted with a %s illumination source and a \"\n                                f\"constant sigma of {sigma}. User caution is advised!\")\n            stacked_to_volume = True\n            intial_pressure = self.stacking_to_3d(intial_pressure)\n            scattering = self.stacking_to_3d(scattering)\n        else:\n            stacked_to_volume = False\n\n        intial_pressure, scattering, anisotropy = self.resampling_for_iterative_qpai(intial_pressure, scattering,\n                                                                                     anisotropy)\n\n        return intial_pressure, scattering, anisotropy, stacked_to_volume\n\n    def stacking_to_3d(self, input_data: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Stacks the input map in sequence along axis=1 to build 3-d volume.\n\n        :param input_data: 2-d image data.\n        :return: Volume of stacked input image.\n        \"\"\"\n\n        spacing = self.global_settings[Tags.DIM_VOLUME_X_MM] / np.shape(input_data)[0]\n        num_repeats = int(self.global_settings[Tags.DIM_VOLUME_Y_MM] / spacing)\n\n        stacked_volume = np.stack([input_data] * num_repeats, axis=1)\n        return stacked_volume\n\n    def resampling_for_iterative_qpai(self, initial_pressure: np.ndarray,\n                                      scattering: np.ndarray,\n                                      anisotropy: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Downscales the input image and scattering map by a given scale (downscale factor) to avoid inverse crime.\n\n        :param initial_pressure: Raw input image of initial pressure.\n        :param scattering: Map of scattering coefficients.\n        :param anisotropy: Map of anisotropies.\n        :return: Downscaled image and scattering map.\n        \"\"\"\n\n        downscaling_method = \"nearest\"\n\n        downscaled_initial_pressure = zoom(initial_pressure, self.downscale_factor, order=0, mode=downscaling_method)\n        downscaled_scattering = zoom(scattering, self.downscale_factor, order=0, mode=downscaling_method)\n        downscaled_anisotropy = zoom(anisotropy, self.downscale_factor, order=0, mode=downscaling_method)\n\n        new_spacing = self.global_settings[Tags.SPACING_MM] / self.downscale_factor\n        self.global_settings[Tags.SPACING_MM] = new_spacing\n\n        return downscaled_initial_pressure, downscaled_scattering, downscaled_anisotropy\n\n    def regularization_sigma(self, input_image: np.ndarray, stacked_to_volume) -> [np.ndarray, int, float]:\n        \"\"\"\n        Computes spatial (same shape as input image) or constant regularization parameter sigma.\n\n        :param input_image: Noisy input image.\n        :param stacked_to_volume: If True input data was 2 dimensional and a constant sigma should be used.\n        :return: Regularization parameter.\n        :raises: ValueError: if estimated noise is zero, so SNR cannot be computed.\n        \"\"\"\n\n        noise = float(estimate_sigma(input_image))\n\n        if noise == 0.0:\n            raise ValueError(\"An estimated noise level of zero cannot be used to compute a signal to noise ratio.\")\n\n        signal_noise_ratio = input_image / noise\n\n        if Tags.ITERATIVE_RECONSTRUCTION_CONSTANT_REGULARIZATION in self.iterative_method_settings:\n            if self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_CONSTANT_REGULARIZATION]:\n                sigma = 1e-2\n                if Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA in self.iterative_method_settings:\n                    sigma = self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA]\n                self.logger.debug(f\"Regularization parameter: {sigma}\")\n            elif stacked_to_volume:\n                sigma = 1e-2\n                if Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA in self.iterative_method_settings:\n                    sigma = self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA]\n                self.logger.debug(f\"Regularization parameter: {sigma}\")\n            else:\n                self.logger.debug(\"Regularization: SNR/spatially dependent\")\n                sigma = 1 / signal_noise_ratio\n                sigma[sigma > 1e8] = 1e8\n                sigma[sigma < 1e-8] = 1e-8\n        elif stacked_to_volume:\n            sigma = 1e-2\n            if Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA in self.iterative_method_settings:\n                sigma = self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA]\n            self.logger.debug(f\"Regularization parameter: {sigma}\")\n        else:\n            self.logger.debug(\"Regularization: SNR/spatially dependent\")\n            sigma = 1 / signal_noise_ratio\n            sigma[sigma > 1e8] = 1e8\n            sigma[sigma < 1e-8] = 1e-8\n\n        return sigma\n\n    def standard_optical_properties(self, image_data: np.ndarray) -> dict:\n        \"\"\"\n        Returns a optical properties dictionary containing scattering coefficients and anisotropy.\n\n        :param image_data: Measured image data.\n        :return: Optical properties (scattering and anisotropy).\n        \"\"\"\n\n        shape = np.shape(image_data)\n\n        # scattering must be known a priori at the moment.\n        if Tags.DATA_FIELD_SCATTERING_PER_CM in self.global_settings:\n            scattering = float(self.global_settings[Tags.DATA_FIELD_SCATTERING_PER_CM]) * np.ones(shape)\n        else:\n            background_dict = TISSUE_LIBRARY.muscle()\n            scattering = float(MolecularComposition.get_properties_for_wavelength(background_dict,\n                                                                                  wavelength=800)[\"mus\"])\n            scattering = scattering * np.ones(shape)\n\n        if Tags.DATA_FIELD_ANISOTROPY in self.global_settings:\n            anisotropy = float(self.global_settings[Tags.DATA_FIELD_ANISOTROPY]) * np.ones(shape)\n        else:\n            anisotropy = float(OpticalTissueProperties.STANDARD_ANISOTROPY) * np.ones(shape)\n\n        optical_properties = {\n            \"scattering\": scattering,\n            \"anisotropy\": anisotropy\n        }\n\n        return optical_properties\n\n    def forward_model_fluence(self, absorption: np.ndarray,\n                              scattering: np.ndarray, anisotropy: np.ndarray,\n                              pa_device) -> np.ndarray:\n        \"\"\"\n        Simulates photon propagation in 3-d volume and returns simulated fluence map in units of J/cm^2.\n\n        :param absorption: Volume of absorption coefficients in 1/cm for Monte Carlo Simulation.\n        :param scattering: Volume of scattering coefficients in 1/cm for Monte Carlo Simulation.\n        :param anisotropy: Volume of anisotropy data for Monte Carlo Simulation.\n        :param pa_device: The simulation device.\n        :return: Fluence map.\n        :raises: AssertionError: if Tags.OPTICAL_MODEL tag was not or incorrectly defined in settings.\n        \"\"\"\n\n        if Tags.OPTICAL_MODEL not in self.optical_settings:\n            raise AssertionError(\"Tags.OPTICAL_MODEL tag was not specified in the settings.\")\n        model = self.optical_settings[Tags.OPTICAL_MODEL]\n\n        self.global_settings.get_optical_settings()[Tags.MCX_ASSUMED_ANISOTROPY] = np.mean(anisotropy)\n\n        if model == Tags.OPTICAL_MODEL_MCX:\n            forward_model_implementation = MCXAdapter(self.global_settings)\n        else:\n            raise AssertionError(\"Tags.OPTICAL_MODEL tag must be Tags.OPTICAL_MODEL_MCX.\")\n\n        _device = pa_device.get_illumination_geometry()\n\n        if isinstance(_device, list):\n            # per convention this list has at least two elements\n            results = forward_model_implementation.forward_model(absorption_cm=absorption,\n                                                                 scattering_cm=scattering,\n                                                                 anisotropy=anisotropy,\n                                                                 illumination_geometry=_device[0])\n            fluence = results[Tags.DATA_FIELD_FLUENCE]\n            for idx in range(1, len(_device)):\n                # we already looked at the 0th element, so go from 1 to n-1\n                results = forward_model_implementation.forward_model(absorption_cm=absorption,\n                                                                     scattering_cm=scattering,\n                                                                     anisotropy=anisotropy,\n                                                                     illumination_geometry=_device[idx + 1])\n                fluence += results[Tags.DATA_FIELD_FLUENCE]\n\n            fluence = fluence / len(_device)\n\n        else:\n            results = forward_model_implementation.forward_model(absorption_cm=absorption,\n                                                                 scattering_cm=scattering,\n                                                                 anisotropy=anisotropy,\n                                                                 illumination_geometry=_device)\n            fluence = results[Tags.DATA_FIELD_FLUENCE]\n\n        print(\"Simulating the optical forward process...[Done]\")\n\n        return fluence\n\n    def update_absorption_estimate(self, image_data: np.ndarray, fluence: np.ndarray,\n                                   sigma: [np.ndarray, int, float]) -> np.ndarray:\n        \"\"\"\n        Reconstructs map of absorption coefficients in 1/cm given measured data and simulated fluence.\n\n        :param image_data: Measured image data (initial pressure) used for reconstruction.\n        :param fluence: Simulated fluence map in J/cm^2.\n        :param sigma: Regularization factor to avoid instability if the fluence is low.\n        :return: Reconstructed absorption.\n        \"\"\"\n\n        if Tags.LASER_PULSE_ENERGY_IN_MILLIJOULE in self.optical_settings:\n            if Tags.DATA_FIELD_GRUNEISEN_PARAMETER in self.global_settings:\n                gamma = self.global_settings[Tags.DATA_FIELD_GRUNEISEN_PARAMETER] * np.ones(np.shape(image_data))\n            else:\n                gamma = calculate_gruneisen_parameter_from_temperature(StandardProperties.BODY_TEMPERATURE_CELCIUS)\n                gamma = gamma * np.ones(np.shape(image_data))\n            factor = (self.optical_settings[Tags.LASER_PULSE_ENERGY_IN_MILLIJOULE] / 1000) * 1e6\n            absorption = np.array(image_data / ((fluence + sigma) * gamma * factor))\n        else:\n            absorption = image_data / (fluence + sigma)\n\n        return absorption\n\n    def log_sum_squared_error(self, image_data: np.ndarray, absorption: np.ndarray, fluence: np.ndarray,\n                              sigma: [np.ndarray, int, float]) -> float:\n        \"\"\"\n        Computes log (base 10) of the sum of squared error between image and reconstructed pressure map in middle slice.\n\n        :param image_data: Measured image data used for reconstruction.\n        :param absorption: Reconstructed map of absorption coefficients in 1/cm.\n        :param fluence: Simulated fluence map in J/cm^2.\n        :param sigma: Regularization parameter to avoid instability if the fluence is low.\n        :return: sse error.\n        \"\"\"\n\n        if Tags.LASER_PULSE_ENERGY_IN_MILLIJOULE in self.optical_settings:\n            if Tags.DATA_FIELD_GRUNEISEN_PARAMETER in self.global_settings:\n                gamma = self.global_settings[Tags.DATA_FIELD_GRUNEISEN_PARAMETER] * np.ones(np.shape(image_data))\n            else:\n                gamma = calculate_gruneisen_parameter_from_temperature(StandardProperties.BODY_TEMPERATURE_CELCIUS)\n                gamma = gamma * np.ones(np.shape(image_data))\n            factor = (self.optical_settings[Tags.LASER_PULSE_ENERGY_IN_MILLIJOULE] / 1000) * 1e6\n            predicted_pressure = absorption * (fluence + sigma) * gamma * factor\n        else:\n            predicted_pressure = absorption * (fluence + sigma)\n\n        y_pos = int(image_data.shape[1] / 2)\n        sse = np.sum(np.square(image_data[:, y_pos, :] - predicted_pressure[:, y_pos, :]))\n\n        return np.log10(sse)\n\n    def convergence_stopping_criterion(self, errors: list, iteration: int) -> bool:\n        \"\"\"\n        Serves as a stopping criterion for the iterative algorithm. If False the iterative algorithm continues.\n\n        :param errors: List of log (base 10) sum of squared errors.\n        :param iteration: Iteration number.\n        :return: if iteration method should be stopped.\n        :raises: AssertionError: if Tags.ITERATIVE_RECONSTRUCTION_STOPPING_LEVEL tag is zero\n        \"\"\"\n        epsilon = 0.03\n\n        if Tags.ITERATIVE_RECONSTRUCTION_STOPPING_LEVEL in self.iterative_method_settings:\n            if self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_STOPPING_LEVEL] == 0:\n                raise AssertionError(\"Tags.ITERATIVE_RECONSTRUCTION_STOPPING_LEVEL should be greater than zero.\")\n            epsilon = self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_STOPPING_LEVEL]\n\n        if iteration == 0:\n            return False\n        elif iteration > 0:\n            share = np.abs(errors[iteration - 1] - errors[iteration]) / errors[iteration - 1]\n            if share <= epsilon:\n                return True\n            else:\n                return False\n        else:\n            raise ValueError(\"Iteration number is negative.\")",
  "def __init__(self, global_settings, component_settings_key: str):\n        super(ProcessingComponent, self).__init__(global_settings=global_settings)\n\n        self.global_settings = global_settings\n        self.optical_settings = global_settings.get_optical_settings()\n        self.iterative_method_settings = Settings(global_settings[component_settings_key])\n\n        # must be extracted due to resampling\n        self.original_spacing = global_settings[Tags.SPACING_MM]\n        if Tags.DOWNSCALE_FACTOR in self.iterative_method_settings:\n            self.downscale_factor = self.iterative_method_settings[Tags.DOWNSCALE_FACTOR]\n        else:\n            self.downscale_factor = 0.73",
  "def run(self, pa_device):\n        self.logger.info(\"Reconstructing absorption using iterative qPAI method...\")\n\n        # check if simulation_path and optical_model_binary_path exist\n        self.logger.debug(f\"Simulation path: {self.global_settings[Tags.SIMULATION_PATH]}\")\n        self.logger.debug(f\"Optical model binary path: {self.optical_settings[Tags.OPTICAL_MODEL_BINARY_PATH]}\")\n\n        if not os.path.exists(self.global_settings[Tags.SIMULATION_PATH]):\n            print(\"Tags.SIMULATION_PATH tag in settings cannot be found.\")\n\n        if not os.path.exists(self.optical_settings[Tags.OPTICAL_MODEL_BINARY_PATH]):\n            print(\"Tags.OPTICAL_MODEL_BINARY_PATH tag in settings cannot be found.\")\n\n        # debug reconstruction settings\n        self.logger.debug(f\"Resampling factor: {self.downscale_factor}\")\n\n        if Tags.ITERATIVE_RECONSTRUCTION_MAX_ITERATION_NUMBER in self.iterative_method_settings:\n            self.logger.debug(f\"Maximum number of iterations:\"\n                              f\" {self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_MAX_ITERATION_NUMBER]}\")\n        else:\n            self.logger.debug(\"Maximum number of iterations: 10\")\n\n        if Tags.ITERATIVE_RECONSTRUCTION_SAVE_INTERMEDIATE_RESULTS in self.iterative_method_settings:\n            self.logger.debug(f\"Save intermediate absorptions:\"\n                              f\" {self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_SAVE_INTERMEDIATE_RESULTS]}\")\n        else:\n            self.logger.debug(\"Save intermediate absorptions: False\")\n\n        # bypass JSON-dump error by manually caching seeds as int()\n        if Tags.RANDOM_SEED in self.global_settings:\n            self.global_settings[Tags.RANDOM_SEED] = int(self.global_settings[Tags.RANDOM_SEED])\n        if Tags.MCX_SEED in self.optical_settings:\n            self.optical_settings[Tags.MCX_SEED] = int(self.optical_settings[Tags.MCX_SEED])\n\n        # run reconstruction\n        reconstructed_absorption, list_of_intermediate_absorptions = self.iterative_absorption_reconstruction(pa_device)\n\n        # make sure that settings are not changed due to resampling\n        if self.global_settings[Tags.SPACING_MM] != self.original_spacing:\n            self.global_settings[Tags.SPACING_MM] = self.original_spacing\n\n        # save absorption update of last iteration step in hdf5 data field\n        # bypass wavelength error resulting from loading settings from existing hdf5 file\n        if Tags.WAVELENGTH in self.global_settings:\n            wavelength = self.global_settings[Tags.WAVELENGTH]\n        else:\n            wavelength = self.global_settings[Tags.WAVELENGTHS][0]\n        data_field = Tags.ITERATIVE_qPAI_RESULT\n        save_data_field(reconstructed_absorption, self.global_settings[Tags.SIMPA_OUTPUT_PATH],\n                        data_field, wavelength)\n\n        # save a list of all intermediate absorption (2-d only) updates in npy file if intended\n        # (e.g. for testing algorithm)\n        if Tags.ITERATIVE_RECONSTRUCTION_SAVE_INTERMEDIATE_RESULTS in self.iterative_method_settings:\n            if self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_SAVE_INTERMEDIATE_RESULTS]:\n                dst = self.global_settings[Tags.SIMULATION_PATH] + \"/List_reconstructed_qpai_absorptions_\" \\\n                    + str(wavelength) + \"_\"\n                np.save(dst + self.global_settings[Tags.VOLUME_NAME] + \".npy\", list_of_intermediate_absorptions)\n\n        self.logger.info(\"Reconstructing absorption using iterative qPAI method...[Done]\")",
  "def iterative_absorption_reconstruction(self, pa_device) -> Tuple[np.ndarray, list]:\n        \"\"\"\n        Performs quantitative photoacoustic image reconstruction of absorption distribution by use of an\n        iterative method. The distribution of scattering coefficients must be known a priori.\n\n        :return: Reconstructed absorption coefficients in 1/cm.\n        :raises: TypeError: if input data are not passed as a certain type\n                 ValueError: if input data cannot be used for reconstruction due to shape or value\n                 FileNotFoundError: if paths stored in settings cannot be accessed\n                 AssertionError: is Tags.MAX_NUMBER_ITERATIVE_RECONSTRUCTION tag is zero\n        \"\"\"\n\n        # extract \"measured\" initial pressure and a priori scattering data\n        target_intial_pressure, scattering, anisotropy = self.extract_initial_data_from_hdf5()\n\n        # checking input data\n        if not isinstance(target_intial_pressure, np.ndarray):\n            raise TypeError(\"Image data is not a numpy ndarray.\")\n        elif target_intial_pressure.size == 0:\n            raise ValueError(\"Image data is empty.\")\n        elif (len(target_intial_pressure.shape) < 2) or (len(target_intial_pressure.shape) > 3):\n            raise ValueError(\"Image data is invalid. Data must be two or three dimensional.\")\n\n        if not isinstance(scattering, np.ndarray):\n            raise TypeError(\"Scattering input is not a numpy ndarray.\")\n        elif scattering.shape != target_intial_pressure.shape:\n            raise ValueError(\"Shape of scattering data is invalid. Scattering must have the same shape as image_data.\")\n\n        # get optical properties necessary for simulation\n        optical_properties_dict = self.standard_optical_properties(target_intial_pressure)\n        if scattering is None:\n            scattering = optical_properties_dict[\"scattering\"]\n        if anisotropy is None:\n            anisotropy = optical_properties_dict[\"anisotropy\"]\n\n        # preprocessing for iterative qPAI method and mcx_adapter\n        target_intial_pressure, scattering, anisotropy, stacked_to_volume = self.preprocessing_for_iterative_qpai(\n            intial_pressure=target_intial_pressure,\n            scattering=scattering,\n            anisotropy=anisotropy)\n\n        # regularization parameter sigma\n        sigma = self.regularization_sigma(target_intial_pressure, stacked_to_volume)\n\n        # initialization\n        absorption = 1e-16 * np.ones(np.shape(target_intial_pressure))\n        y_pos = int(np.shape(absorption)[1] / 2)  # to extract middle slice\n        list_of_intermediate_absorptions = []  # if intentional all intermediate iteration updates can be returned\n        error_list = []\n\n        nmax = 10\n        if Tags.ITERATIVE_RECONSTRUCTION_MAX_ITERATION_NUMBER in self.iterative_method_settings:\n            if self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_MAX_ITERATION_NUMBER] == 0:\n                raise AssertionError(\"Tags.MAX_NUMBER_ITERATIVE_RECONSTRUCTION tag is invalid (equals zero).\")\n            nmax = int(self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_MAX_ITERATION_NUMBER])\n\n        # run algorithm\n        start_time = time.time()\n\n        i = 0\n        while i < nmax:\n            print(\"Iteration: \", i)\n            # core method\n            fluence = self.forward_model_fluence(absorption, scattering, anisotropy, pa_device)\n            error_list.append(self.log_sum_squared_error(target_intial_pressure, absorption, fluence, sigma))\n            absorption = self.update_absorption_estimate(target_intial_pressure, fluence, sigma)\n\n            est_p0 = absorption * fluence\n\n            # only store middle slice (2-d image instead of 3-d volume) in iteration list for better performance\n            list_of_intermediate_absorptions.append(absorption[:, y_pos, :])\n\n            # check if current error did not change significantly in comparison to preceding error\n            if self.convergence_stopping_criterion(error_list, iteration=i):\n                if Tags.ITERATIVE_RECONSTRUCTION_SAVE_LAST_FLUENCE:\n                    dst = self.global_settings[Tags.SIMULATION_PATH] + \"/last_fluence\" + \"_\"\n                    np.save(dst + self.global_settings[Tags.VOLUME_NAME] + \".npy\", fluence)\n                break\n            i += 1\n\n        print(\"--- %s seconds/iteration ---\" % round((time.time() - start_time) / (i + 1), 2))\n\n        # extracting field of view if input initial pressure was passed as a 2-d array\n        if stacked_to_volume:\n            absorption = absorption[:, y_pos, :]\n\n        # function returns the last iteration result as a numpy array and all iteration results in a list\n        return absorption, list_of_intermediate_absorptions",
  "def extract_initial_data_from_hdf5(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Extract necessary information - initial pressure and scattering coefficients -\n        from settings dictionaries. The setting dictionaries is extracted from a hdf5 file.\n\n        :return: Initial pressure and a priori known scattering coefficients.\n        \"\"\"\n\n        # get simulation output which contains initial pressure and scattering\n        # bypass wavelength error resulting from loading settings from existing hdf5 file\n        if Tags.WAVELENGTH in self.global_settings:\n            wavelength = self.global_settings[Tags.WAVELENGTH]\n        else:\n            wavelength = self.global_settings[Tags.WAVELENGTHS][0]\n        self.logger.debug(f\"Wavelength: {wavelength}\")\n        # get initial pressure and scattering\n        initial_pressure = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH],\n                                           Tags.DATA_FIELD_INITIAL_PRESSURE,\n                                           wavelength)\n        scattering = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], Tags.DATA_FIELD_SCATTERING_PER_CM,\n                                     wavelength)\n\n        anisotropy = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], Tags.DATA_FIELD_ANISOTROPY,\n                                     wavelength)\n\n        # function returns the last iteration result as a numpy array and all iteration results in a list\n        return initial_pressure, scattering, anisotropy",
  "def preprocessing_for_iterative_qpai(self, intial_pressure: np.ndarray,\n                                         scattering: np.ndarray,\n                                         anisotropy: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, bool]:\n        \"\"\"\n        Preprocesses image data and scattering distribution for iterative algorithm using mcx.\n        The preprocessing step includes:\n        1. Stacking the input data from 2-d to 3-d if necessary, since the mcx adapter can only perform\n           a Monte Carlo Simulation of fluence given 3-d volumes of absorption, scattering, and anisotropy\n        2. Resampling the input data to mitigate the inverse crime\n\n        :param intial_pressure: Raw input image of initial pressure.\n        :param scattering: Map of scattering coefficients known a priori.\n        :return: Resampled and (if necessary) stacked volume of noisy\n                 initial pressure, scattering and bool indicating if image had to be stacked to 3-d.\n        \"\"\"\n\n        if len(np.shape(intial_pressure)) == 2:\n            if Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA in self.iterative_method_settings:\n                sigma = self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA]\n            else:\n                sigma = 1e-2\n            self.logger.warning(\"Input data is 2 dimensional and will be stacked to 3 dimensions. \"\n                                \"Algorithm is attempted with a %s illumination source and a \"\n                                f\"constant sigma of {sigma}. User caution is advised!\")\n            stacked_to_volume = True\n            intial_pressure = self.stacking_to_3d(intial_pressure)\n            scattering = self.stacking_to_3d(scattering)\n        else:\n            stacked_to_volume = False\n\n        intial_pressure, scattering, anisotropy = self.resampling_for_iterative_qpai(intial_pressure, scattering,\n                                                                                     anisotropy)\n\n        return intial_pressure, scattering, anisotropy, stacked_to_volume",
  "def stacking_to_3d(self, input_data: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Stacks the input map in sequence along axis=1 to build 3-d volume.\n\n        :param input_data: 2-d image data.\n        :return: Volume of stacked input image.\n        \"\"\"\n\n        spacing = self.global_settings[Tags.DIM_VOLUME_X_MM] / np.shape(input_data)[0]\n        num_repeats = int(self.global_settings[Tags.DIM_VOLUME_Y_MM] / spacing)\n\n        stacked_volume = np.stack([input_data] * num_repeats, axis=1)\n        return stacked_volume",
  "def resampling_for_iterative_qpai(self, initial_pressure: np.ndarray,\n                                      scattering: np.ndarray,\n                                      anisotropy: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Downscales the input image and scattering map by a given scale (downscale factor) to avoid inverse crime.\n\n        :param initial_pressure: Raw input image of initial pressure.\n        :param scattering: Map of scattering coefficients.\n        :param anisotropy: Map of anisotropies.\n        :return: Downscaled image and scattering map.\n        \"\"\"\n\n        downscaling_method = \"nearest\"\n\n        downscaled_initial_pressure = zoom(initial_pressure, self.downscale_factor, order=0, mode=downscaling_method)\n        downscaled_scattering = zoom(scattering, self.downscale_factor, order=0, mode=downscaling_method)\n        downscaled_anisotropy = zoom(anisotropy, self.downscale_factor, order=0, mode=downscaling_method)\n\n        new_spacing = self.global_settings[Tags.SPACING_MM] / self.downscale_factor\n        self.global_settings[Tags.SPACING_MM] = new_spacing\n\n        return downscaled_initial_pressure, downscaled_scattering, downscaled_anisotropy",
  "def regularization_sigma(self, input_image: np.ndarray, stacked_to_volume) -> [np.ndarray, int, float]:\n        \"\"\"\n        Computes spatial (same shape as input image) or constant regularization parameter sigma.\n\n        :param input_image: Noisy input image.\n        :param stacked_to_volume: If True input data was 2 dimensional and a constant sigma should be used.\n        :return: Regularization parameter.\n        :raises: ValueError: if estimated noise is zero, so SNR cannot be computed.\n        \"\"\"\n\n        noise = float(estimate_sigma(input_image))\n\n        if noise == 0.0:\n            raise ValueError(\"An estimated noise level of zero cannot be used to compute a signal to noise ratio.\")\n\n        signal_noise_ratio = input_image / noise\n\n        if Tags.ITERATIVE_RECONSTRUCTION_CONSTANT_REGULARIZATION in self.iterative_method_settings:\n            if self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_CONSTANT_REGULARIZATION]:\n                sigma = 1e-2\n                if Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA in self.iterative_method_settings:\n                    sigma = self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA]\n                self.logger.debug(f\"Regularization parameter: {sigma}\")\n            elif stacked_to_volume:\n                sigma = 1e-2\n                if Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA in self.iterative_method_settings:\n                    sigma = self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA]\n                self.logger.debug(f\"Regularization parameter: {sigma}\")\n            else:\n                self.logger.debug(\"Regularization: SNR/spatially dependent\")\n                sigma = 1 / signal_noise_ratio\n                sigma[sigma > 1e8] = 1e8\n                sigma[sigma < 1e-8] = 1e-8\n        elif stacked_to_volume:\n            sigma = 1e-2\n            if Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA in self.iterative_method_settings:\n                sigma = self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA]\n            self.logger.debug(f\"Regularization parameter: {sigma}\")\n        else:\n            self.logger.debug(\"Regularization: SNR/spatially dependent\")\n            sigma = 1 / signal_noise_ratio\n            sigma[sigma > 1e8] = 1e8\n            sigma[sigma < 1e-8] = 1e-8\n\n        return sigma",
  "def standard_optical_properties(self, image_data: np.ndarray) -> dict:\n        \"\"\"\n        Returns a optical properties dictionary containing scattering coefficients and anisotropy.\n\n        :param image_data: Measured image data.\n        :return: Optical properties (scattering and anisotropy).\n        \"\"\"\n\n        shape = np.shape(image_data)\n\n        # scattering must be known a priori at the moment.\n        if Tags.DATA_FIELD_SCATTERING_PER_CM in self.global_settings:\n            scattering = float(self.global_settings[Tags.DATA_FIELD_SCATTERING_PER_CM]) * np.ones(shape)\n        else:\n            background_dict = TISSUE_LIBRARY.muscle()\n            scattering = float(MolecularComposition.get_properties_for_wavelength(background_dict,\n                                                                                  wavelength=800)[\"mus\"])\n            scattering = scattering * np.ones(shape)\n\n        if Tags.DATA_FIELD_ANISOTROPY in self.global_settings:\n            anisotropy = float(self.global_settings[Tags.DATA_FIELD_ANISOTROPY]) * np.ones(shape)\n        else:\n            anisotropy = float(OpticalTissueProperties.STANDARD_ANISOTROPY) * np.ones(shape)\n\n        optical_properties = {\n            \"scattering\": scattering,\n            \"anisotropy\": anisotropy\n        }\n\n        return optical_properties",
  "def forward_model_fluence(self, absorption: np.ndarray,\n                              scattering: np.ndarray, anisotropy: np.ndarray,\n                              pa_device) -> np.ndarray:\n        \"\"\"\n        Simulates photon propagation in 3-d volume and returns simulated fluence map in units of J/cm^2.\n\n        :param absorption: Volume of absorption coefficients in 1/cm for Monte Carlo Simulation.\n        :param scattering: Volume of scattering coefficients in 1/cm for Monte Carlo Simulation.\n        :param anisotropy: Volume of anisotropy data for Monte Carlo Simulation.\n        :param pa_device: The simulation device.\n        :return: Fluence map.\n        :raises: AssertionError: if Tags.OPTICAL_MODEL tag was not or incorrectly defined in settings.\n        \"\"\"\n\n        if Tags.OPTICAL_MODEL not in self.optical_settings:\n            raise AssertionError(\"Tags.OPTICAL_MODEL tag was not specified in the settings.\")\n        model = self.optical_settings[Tags.OPTICAL_MODEL]\n\n        self.global_settings.get_optical_settings()[Tags.MCX_ASSUMED_ANISOTROPY] = np.mean(anisotropy)\n\n        if model == Tags.OPTICAL_MODEL_MCX:\n            forward_model_implementation = MCXAdapter(self.global_settings)\n        else:\n            raise AssertionError(\"Tags.OPTICAL_MODEL tag must be Tags.OPTICAL_MODEL_MCX.\")\n\n        _device = pa_device.get_illumination_geometry()\n\n        if isinstance(_device, list):\n            # per convention this list has at least two elements\n            results = forward_model_implementation.forward_model(absorption_cm=absorption,\n                                                                 scattering_cm=scattering,\n                                                                 anisotropy=anisotropy,\n                                                                 illumination_geometry=_device[0])\n            fluence = results[Tags.DATA_FIELD_FLUENCE]\n            for idx in range(1, len(_device)):\n                # we already looked at the 0th element, so go from 1 to n-1\n                results = forward_model_implementation.forward_model(absorption_cm=absorption,\n                                                                     scattering_cm=scattering,\n                                                                     anisotropy=anisotropy,\n                                                                     illumination_geometry=_device[idx + 1])\n                fluence += results[Tags.DATA_FIELD_FLUENCE]\n\n            fluence = fluence / len(_device)\n\n        else:\n            results = forward_model_implementation.forward_model(absorption_cm=absorption,\n                                                                 scattering_cm=scattering,\n                                                                 anisotropy=anisotropy,\n                                                                 illumination_geometry=_device)\n            fluence = results[Tags.DATA_FIELD_FLUENCE]\n\n        print(\"Simulating the optical forward process...[Done]\")\n\n        return fluence",
  "def update_absorption_estimate(self, image_data: np.ndarray, fluence: np.ndarray,\n                                   sigma: [np.ndarray, int, float]) -> np.ndarray:\n        \"\"\"\n        Reconstructs map of absorption coefficients in 1/cm given measured data and simulated fluence.\n\n        :param image_data: Measured image data (initial pressure) used for reconstruction.\n        :param fluence: Simulated fluence map in J/cm^2.\n        :param sigma: Regularization factor to avoid instability if the fluence is low.\n        :return: Reconstructed absorption.\n        \"\"\"\n\n        if Tags.LASER_PULSE_ENERGY_IN_MILLIJOULE in self.optical_settings:\n            if Tags.DATA_FIELD_GRUNEISEN_PARAMETER in self.global_settings:\n                gamma = self.global_settings[Tags.DATA_FIELD_GRUNEISEN_PARAMETER] * np.ones(np.shape(image_data))\n            else:\n                gamma = calculate_gruneisen_parameter_from_temperature(StandardProperties.BODY_TEMPERATURE_CELCIUS)\n                gamma = gamma * np.ones(np.shape(image_data))\n            factor = (self.optical_settings[Tags.LASER_PULSE_ENERGY_IN_MILLIJOULE] / 1000) * 1e6\n            absorption = np.array(image_data / ((fluence + sigma) * gamma * factor))\n        else:\n            absorption = image_data / (fluence + sigma)\n\n        return absorption",
  "def log_sum_squared_error(self, image_data: np.ndarray, absorption: np.ndarray, fluence: np.ndarray,\n                              sigma: [np.ndarray, int, float]) -> float:\n        \"\"\"\n        Computes log (base 10) of the sum of squared error between image and reconstructed pressure map in middle slice.\n\n        :param image_data: Measured image data used for reconstruction.\n        :param absorption: Reconstructed map of absorption coefficients in 1/cm.\n        :param fluence: Simulated fluence map in J/cm^2.\n        :param sigma: Regularization parameter to avoid instability if the fluence is low.\n        :return: sse error.\n        \"\"\"\n\n        if Tags.LASER_PULSE_ENERGY_IN_MILLIJOULE in self.optical_settings:\n            if Tags.DATA_FIELD_GRUNEISEN_PARAMETER in self.global_settings:\n                gamma = self.global_settings[Tags.DATA_FIELD_GRUNEISEN_PARAMETER] * np.ones(np.shape(image_data))\n            else:\n                gamma = calculate_gruneisen_parameter_from_temperature(StandardProperties.BODY_TEMPERATURE_CELCIUS)\n                gamma = gamma * np.ones(np.shape(image_data))\n            factor = (self.optical_settings[Tags.LASER_PULSE_ENERGY_IN_MILLIJOULE] / 1000) * 1e6\n            predicted_pressure = absorption * (fluence + sigma) * gamma * factor\n        else:\n            predicted_pressure = absorption * (fluence + sigma)\n\n        y_pos = int(image_data.shape[1] / 2)\n        sse = np.sum(np.square(image_data[:, y_pos, :] - predicted_pressure[:, y_pos, :]))\n\n        return np.log10(sse)",
  "def convergence_stopping_criterion(self, errors: list, iteration: int) -> bool:\n        \"\"\"\n        Serves as a stopping criterion for the iterative algorithm. If False the iterative algorithm continues.\n\n        :param errors: List of log (base 10) sum of squared errors.\n        :param iteration: Iteration number.\n        :return: if iteration method should be stopped.\n        :raises: AssertionError: if Tags.ITERATIVE_RECONSTRUCTION_STOPPING_LEVEL tag is zero\n        \"\"\"\n        epsilon = 0.03\n\n        if Tags.ITERATIVE_RECONSTRUCTION_STOPPING_LEVEL in self.iterative_method_settings:\n            if self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_STOPPING_LEVEL] == 0:\n                raise AssertionError(\"Tags.ITERATIVE_RECONSTRUCTION_STOPPING_LEVEL should be greater than zero.\")\n            epsilon = self.iterative_method_settings[Tags.ITERATIVE_RECONSTRUCTION_STOPPING_LEVEL]\n\n        if iteration == 0:\n            return False\n        elif iteration > 0:\n            share = np.abs(errors[iteration - 1] - errors[iteration]) / errors[iteration - 1]\n            if share <= epsilon:\n                return True\n            else:\n                return False\n        else:\n            raise ValueError(\"Iteration number is negative.\")",
  "class PoissonNoise(ProcessingComponent):\n    \"\"\"\n    Applies Gaussian noise to the defined data field.\n    The noise will be applied to all wavelengths.\n\n    Component Settings::\n\n       Tags.NOISE_MEAN (default: 3)\n       Tags.NOISE_MODE (default: Tags.NOISE_MODE_ADDITIVE)\n       Tags.DATA_FIELD (required)\n    \"\"\"\n\n    def run(self, device):\n        self.logger.info(\"Applying Poisson Noise Model...\")\n        mean = 3\n        mode = Tags.NOISE_MODE_ADDITIVE\n\n        if Tags.DATA_FIELD not in self.component_settings.keys():\n            msg = f\"The field {Tags.DATA_FIELD} must be set in order to use the poisson_noise field.\"\n            self.logger.critical(msg)\n            raise KeyError(msg)\n\n        data_field = self.component_settings[Tags.DATA_FIELD]\n\n        if Tags.NOISE_MEAN in self.component_settings.keys():\n            mean = self.component_settings[Tags.NOISE_MEAN]\n\n        if Tags.NOISE_MODE in self.component_settings.keys():\n            mode = self.component_settings[Tags.NOISE_MODE]\n\n        self.logger.debug(f\"Noise model mode: {mode}\")\n        self.logger.debug(f\"Noise model mean: {mean}\")\n\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n        data_array = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        if mode == Tags.NOISE_MODE_ADDITIVE:\n            data_array = data_array + np.random.poisson(mean, size=np.shape(data_array))\n        elif mode == Tags.NOISE_MODE_MULTIPLICATIVE:\n            data_array = data_array * np.random.poisson(mean, size=np.shape(data_array))\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(data_array)\n\n        save_data_field(data_array, self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        self.logger.info(\"Applying Poisson Noise Model...[Done]\")",
  "def run(self, device):\n        self.logger.info(\"Applying Poisson Noise Model...\")\n        mean = 3\n        mode = Tags.NOISE_MODE_ADDITIVE\n\n        if Tags.DATA_FIELD not in self.component_settings.keys():\n            msg = f\"The field {Tags.DATA_FIELD} must be set in order to use the poisson_noise field.\"\n            self.logger.critical(msg)\n            raise KeyError(msg)\n\n        data_field = self.component_settings[Tags.DATA_FIELD]\n\n        if Tags.NOISE_MEAN in self.component_settings.keys():\n            mean = self.component_settings[Tags.NOISE_MEAN]\n\n        if Tags.NOISE_MODE in self.component_settings.keys():\n            mode = self.component_settings[Tags.NOISE_MODE]\n\n        self.logger.debug(f\"Noise model mode: {mode}\")\n        self.logger.debug(f\"Noise model mean: {mean}\")\n\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n        data_array = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        if mode == Tags.NOISE_MODE_ADDITIVE:\n            data_array = data_array + np.random.poisson(mean, size=np.shape(data_array))\n        elif mode == Tags.NOISE_MODE_MULTIPLICATIVE:\n            data_array = data_array * np.random.poisson(mean, size=np.shape(data_array))\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(data_array)\n\n        save_data_field(data_array, self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        self.logger.info(\"Applying Poisson Noise Model...[Done]\")",
  "class SaltAndPepperNoise(ProcessingComponent):\n    \"\"\"\n    Applies salt and pepper noise to the defined data field.\n    The noise will be applied to all wavelengths.\n\n    The noise will be 50% salt and 50% pepper noise, but both can be set to the same value using the\n    NOISE_MIN and NOISE_MAX fields.\n\n    Component Settings::\n\n       Tags.NOISE_MIN (default: min(data_field))\n       Tags.NOISE_MAX (default: max(data_field))\n       Tags.NOISE_FREQUENCY (default: 0.01)\n       Tags.DATA_FIELD (required)\n    \"\"\"\n\n    def run(self, device):\n        self.logger.info(\"Applying Salt And Pepper Noise Model...\")\n\n        if Tags.DATA_FIELD not in self.component_settings.keys():\n            msg = f\"The field {Tags.DATA_FIELD} must be set in order to use the\" \\\n                  f\"salt_and_pepper_noise component.\"\n            self.logger.critical(msg)\n            raise KeyError(msg)\n\n        data_field = self.component_settings[Tags.DATA_FIELD]\n\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n        data_array = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        min_noise = np.min(data_array)\n        max_noise = np.max(data_array)\n        noise_frequency = 0.01\n\n        if Tags.NOISE_FREQUENCY in self.component_settings.keys():\n            noise_frequency = self.component_settings[Tags.NOISE_FREQUENCY]\n\n        if Tags.NOISE_MIN in self.component_settings.keys():\n            min_noise = self.component_settings[Tags.NOISE_MIN]\n\n        if Tags.NOISE_MAX in self.component_settings.keys():\n            max_noise = self.component_settings[Tags.NOISE_MAX]\n\n        self.logger.debug(f\"Noise model min: {min_noise}\")\n        self.logger.debug(f\"Noise model max: {max_noise}\")\n        self.logger.debug(f\"Noise model frequency: {noise_frequency}\")\n\n        shape = np.shape(data_array)\n        num_data_points = int(np.round(np.prod(shape) * noise_frequency / 2))\n\n        coords_min = tuple([np.random.randint(0, i - 1, int(num_data_points)) for i in shape])\n        coords_max = tuple([np.random.randint(0, i - 1, int(num_data_points)) for i in shape])\n\n        data_array[coords_min] = min_noise\n        data_array[coords_max] = max_noise\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(data_array)\n\n        save_data_field(data_array, self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        self.logger.info(\"Applying Salt And Pepper Noise Model...[Done]\")",
  "def run(self, device):\n        self.logger.info(\"Applying Salt And Pepper Noise Model...\")\n\n        if Tags.DATA_FIELD not in self.component_settings.keys():\n            msg = f\"The field {Tags.DATA_FIELD} must be set in order to use the\" \\\n                  f\"salt_and_pepper_noise component.\"\n            self.logger.critical(msg)\n            raise KeyError(msg)\n\n        data_field = self.component_settings[Tags.DATA_FIELD]\n\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n        data_array = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        min_noise = np.min(data_array)\n        max_noise = np.max(data_array)\n        noise_frequency = 0.01\n\n        if Tags.NOISE_FREQUENCY in self.component_settings.keys():\n            noise_frequency = self.component_settings[Tags.NOISE_FREQUENCY]\n\n        if Tags.NOISE_MIN in self.component_settings.keys():\n            min_noise = self.component_settings[Tags.NOISE_MIN]\n\n        if Tags.NOISE_MAX in self.component_settings.keys():\n            max_noise = self.component_settings[Tags.NOISE_MAX]\n\n        self.logger.debug(f\"Noise model min: {min_noise}\")\n        self.logger.debug(f\"Noise model max: {max_noise}\")\n        self.logger.debug(f\"Noise model frequency: {noise_frequency}\")\n\n        shape = np.shape(data_array)\n        num_data_points = int(np.round(np.prod(shape) * noise_frequency / 2))\n\n        coords_min = tuple([np.random.randint(0, i - 1, int(num_data_points)) for i in shape])\n        coords_max = tuple([np.random.randint(0, i - 1, int(num_data_points)) for i in shape])\n\n        data_array[coords_min] = min_noise\n        data_array[coords_max] = max_noise\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(data_array)\n\n        save_data_field(data_array, self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        self.logger.info(\"Applying Salt And Pepper Noise Model...[Done]\")",
  "class GammaNoise(ProcessingComponent):\n    \"\"\"\n    Applies Gaussian noise to the defined data field.\n    The noise will be applied to all wavelengths.\n\n    Component Settings::\n\n       Tags.NOISE_SHAPE (default: 2)\n       Tags.NOISE_SCALE (default: 2)\n       Tags.NOISE_MODE (default: Tags.NOISE_MODE_ADDITIVE)\n       Tags.DATA_FIELD (required)\n    \"\"\"\n\n    def run(self, device):\n        self.logger.info(\"Applying Gamma Noise Model...\")\n        shape = 2\n        scale = 2\n        mode = Tags.NOISE_MODE_ADDITIVE\n\n        if Tags.DATA_FIELD not in self.component_settings.keys():\n            msg = f\"The field {Tags.DATA_FIELD} must be set in order to use the gamma_noise field.\"\n            self.logger.critical(msg)\n            raise KeyError(msg)\n\n        data_field = self.component_settings[Tags.DATA_FIELD]\n\n        if Tags.NOISE_SHAPE in self.component_settings.keys():\n            shape = self.component_settings[Tags.NOISE_SHAPE]\n\n        if Tags.NOISE_SCALE in self.component_settings.keys():\n            scale = self.component_settings[Tags.NOISE_SCALE]\n\n        if Tags.NOISE_MODE in self.component_settings.keys():\n            mode = self.component_settings[Tags.NOISE_MODE]\n\n        self.logger.debug(f\"Noise model mode: {mode}\")\n        self.logger.debug(f\"Noise model shape: {shape}\")\n        self.logger.debug(f\"Noise model scale: {scale}\")\n\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n        data_array = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        if mode == Tags.NOISE_MODE_ADDITIVE:\n            data_array = data_array + np.random.gamma(shape, scale, size=np.shape(data_array))\n        elif mode == Tags.NOISE_MODE_MULTIPLICATIVE:\n            data_array = data_array * np.random.gamma(shape, scale, size=np.shape(data_array))\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(data_array)\n\n        save_data_field(data_array, self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        self.logger.info(\"Applying Gamma Noise Model...[Done]\")",
  "def run(self, device):\n        self.logger.info(\"Applying Gamma Noise Model...\")\n        shape = 2\n        scale = 2\n        mode = Tags.NOISE_MODE_ADDITIVE\n\n        if Tags.DATA_FIELD not in self.component_settings.keys():\n            msg = f\"The field {Tags.DATA_FIELD} must be set in order to use the gamma_noise field.\"\n            self.logger.critical(msg)\n            raise KeyError(msg)\n\n        data_field = self.component_settings[Tags.DATA_FIELD]\n\n        if Tags.NOISE_SHAPE in self.component_settings.keys():\n            shape = self.component_settings[Tags.NOISE_SHAPE]\n\n        if Tags.NOISE_SCALE in self.component_settings.keys():\n            scale = self.component_settings[Tags.NOISE_SCALE]\n\n        if Tags.NOISE_MODE in self.component_settings.keys():\n            mode = self.component_settings[Tags.NOISE_MODE]\n\n        self.logger.debug(f\"Noise model mode: {mode}\")\n        self.logger.debug(f\"Noise model shape: {shape}\")\n        self.logger.debug(f\"Noise model scale: {scale}\")\n\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n        data_array = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        if mode == Tags.NOISE_MODE_ADDITIVE:\n            data_array = data_array + np.random.gamma(shape, scale, size=np.shape(data_array))\n        elif mode == Tags.NOISE_MODE_MULTIPLICATIVE:\n            data_array = data_array * np.random.gamma(shape, scale, size=np.shape(data_array))\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(data_array)\n\n        save_data_field(data_array, self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        self.logger.info(\"Applying Gamma Noise Model...[Done]\")",
  "class GaussianNoise(ProcessingComponent):\n    \"\"\"\n    Applies Gaussian noise to the defined data field.\n    The noise will be applied to all wavelengths.\n    Component Settings::\n\n       Tags.NOISE_MEAN (default: 0)\n       Tags.NOISE_STD (default: 1)\n       Tags.NOISE_MODE (default: Tags.NOISE_MODE_ADDITIVE)\n       Tags.NOISE_NON_NEGATIVITY_CONSTRAINT (default: False)\n       Tags.DATA_FIELD (required)\n    \"\"\"\n\n    def run(self, device):\n        self.logger.info(\"Applying Gaussian Noise Model...\")\n        mean = 0\n        std = 1\n        mode = Tags.NOISE_MODE_ADDITIVE\n        non_negative = False\n\n        if Tags.DATA_FIELD not in self.component_settings.keys():\n            msg = f\"The field {Tags.DATA_FIELD} must be set in order to use the gaussian_noise field.\"\n            self.logger.critical(msg)\n            raise KeyError(msg)\n\n        data_field = self.component_settings[Tags.DATA_FIELD]\n\n        if Tags.NOISE_MEAN in self.component_settings.keys():\n            mean = self.component_settings[Tags.NOISE_MEAN]\n\n        if Tags.NOISE_STD in self.component_settings.keys():\n            std = self.component_settings[Tags.NOISE_STD]\n\n        if Tags.NOISE_MODE in self.component_settings.keys():\n            mode = self.component_settings[Tags.NOISE_MODE]\n\n        if Tags.NOISE_NON_NEGATIVITY_CONSTRAINT in self.component_settings.keys():\n            non_negative = self.component_settings[Tags.NOISE_NON_NEGATIVITY_CONSTRAINT]\n\n        self.logger.debug(f\"Noise model mode: {mode}\")\n        self.logger.debug(f\"Noise model mean: {mean}\")\n        self.logger.debug(f\"Noise model std: {std}\")\n        self.logger.debug(f\"Noise model non-negative: {non_negative}\")\n\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n        data_array = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        if mode == Tags.NOISE_MODE_ADDITIVE:\n            data_array = data_array + np.random.normal(mean, std, size=np.shape(data_array))\n        elif mode == Tags.NOISE_MODE_MULTIPLICATIVE:\n            data_array = data_array * np.random.normal(mean, std, size=np.shape(data_array))\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(data_array)\n\n        if non_negative:\n            data_array[data_array < EPS] = EPS\n        save_data_field(data_array, self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        self.logger.info(\"Applying Gaussian Noise Model...[Done]\")",
  "def run(self, device):\n        self.logger.info(\"Applying Gaussian Noise Model...\")\n        mean = 0\n        std = 1\n        mode = Tags.NOISE_MODE_ADDITIVE\n        non_negative = False\n\n        if Tags.DATA_FIELD not in self.component_settings.keys():\n            msg = f\"The field {Tags.DATA_FIELD} must be set in order to use the gaussian_noise field.\"\n            self.logger.critical(msg)\n            raise KeyError(msg)\n\n        data_field = self.component_settings[Tags.DATA_FIELD]\n\n        if Tags.NOISE_MEAN in self.component_settings.keys():\n            mean = self.component_settings[Tags.NOISE_MEAN]\n\n        if Tags.NOISE_STD in self.component_settings.keys():\n            std = self.component_settings[Tags.NOISE_STD]\n\n        if Tags.NOISE_MODE in self.component_settings.keys():\n            mode = self.component_settings[Tags.NOISE_MODE]\n\n        if Tags.NOISE_NON_NEGATIVITY_CONSTRAINT in self.component_settings.keys():\n            non_negative = self.component_settings[Tags.NOISE_NON_NEGATIVITY_CONSTRAINT]\n\n        self.logger.debug(f\"Noise model mode: {mode}\")\n        self.logger.debug(f\"Noise model mean: {mean}\")\n        self.logger.debug(f\"Noise model std: {std}\")\n        self.logger.debug(f\"Noise model non-negative: {non_negative}\")\n\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n        data_array = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        if mode == Tags.NOISE_MODE_ADDITIVE:\n            data_array = data_array + np.random.normal(mean, std, size=np.shape(data_array))\n        elif mode == Tags.NOISE_MODE_MULTIPLICATIVE:\n            data_array = data_array * np.random.normal(mean, std, size=np.shape(data_array))\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(data_array)\n\n        if non_negative:\n            data_array[data_array < EPS] = EPS\n        save_data_field(data_array, self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        self.logger.info(\"Applying Gaussian Noise Model...[Done]\")",
  "class UniformNoise(ProcessingComponent):\n    \"\"\"\n    Applies uniform noise to the defined data field.\n    The noise will be applied to all wavelengths.\n\n    The noise will be uniformly distributed between [min, max[.\n\n    Component Settings::\n\n       Tags.NOISE_MIN (default: 0)\n       Tags.NOISE_MAX (default: 1)\n       Tags.NOISE_MODE (default: Tags.NOISE_MODE_ADDITIVE)\n       Tags.DATA_FIELD (required)\n    \"\"\"\n\n    def run(self, device):\n        self.logger.info(\"Applying Uniform Noise Model...\")\n        min_noise = 0\n        max_noise = 1\n        mode = Tags.NOISE_MODE_ADDITIVE\n\n        if Tags.DATA_FIELD not in self.component_settings.keys():\n            msg = f\"The field {Tags.DATA_FIELD} must be set in order to use the uniform_noise component.\"\n            self.logger.critical(msg)\n            raise KeyError(msg)\n\n        data_field = self.component_settings[Tags.DATA_FIELD]\n\n        if Tags.NOISE_MIN in self.component_settings.keys():\n            min_noise = self.component_settings[Tags.NOISE_MIN]\n\n        if Tags.NOISE_MAX in self.component_settings.keys():\n            max_noise = self.component_settings[Tags.NOISE_MAX]\n\n        if Tags.NOISE_MODE in self.component_settings.keys():\n            mode = self.component_settings[Tags.NOISE_MODE]\n\n        self.logger.debug(f\"Noise model mode: {mode}\")\n        self.logger.debug(f\"Noise model min: {min_noise}\")\n        self.logger.debug(f\"Noise model max: {max_noise}\")\n\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n        data_array = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        if mode == Tags.NOISE_MODE_ADDITIVE:\n            data_array = data_array + (np.random.random(size=np.shape(data_array)) * (max_noise-min_noise) + min_noise)\n        elif mode == Tags.NOISE_MODE_MULTIPLICATIVE:\n            data_array = data_array * (np.random.random(size=np.shape(data_array)) * (max_noise-min_noise) + min_noise)\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(data_array)\n\n        save_data_field(data_array, self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        self.logger.info(\"Applying Uniform Noise Model...[Done]\")",
  "def run(self, device):\n        self.logger.info(\"Applying Uniform Noise Model...\")\n        min_noise = 0\n        max_noise = 1\n        mode = Tags.NOISE_MODE_ADDITIVE\n\n        if Tags.DATA_FIELD not in self.component_settings.keys():\n            msg = f\"The field {Tags.DATA_FIELD} must be set in order to use the uniform_noise component.\"\n            self.logger.critical(msg)\n            raise KeyError(msg)\n\n        data_field = self.component_settings[Tags.DATA_FIELD]\n\n        if Tags.NOISE_MIN in self.component_settings.keys():\n            min_noise = self.component_settings[Tags.NOISE_MIN]\n\n        if Tags.NOISE_MAX in self.component_settings.keys():\n            max_noise = self.component_settings[Tags.NOISE_MAX]\n\n        if Tags.NOISE_MODE in self.component_settings.keys():\n            mode = self.component_settings[Tags.NOISE_MODE]\n\n        self.logger.debug(f\"Noise model mode: {mode}\")\n        self.logger.debug(f\"Noise model min: {min_noise}\")\n        self.logger.debug(f\"Noise model max: {max_noise}\")\n\n        wavelength = self.global_settings[Tags.WAVELENGTH]\n        data_array = load_data_field(self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        if mode == Tags.NOISE_MODE_ADDITIVE:\n            data_array = data_array + (np.random.random(size=np.shape(data_array)) * (max_noise-min_noise) + min_noise)\n        elif mode == Tags.NOISE_MODE_MULTIPLICATIVE:\n            data_array = data_array * (np.random.random(size=np.shape(data_array)) * (max_noise-min_noise) + min_noise)\n\n        if not (Tags.IGNORE_QA_ASSERTIONS in self.global_settings and Tags.IGNORE_QA_ASSERTIONS):\n            assert_array_well_defined(data_array)\n\n        save_data_field(data_array, self.global_settings[Tags.SIMPA_OUTPUT_PATH], data_field, wavelength)\n\n        self.logger.info(\"Applying Uniform Noise Model...[Done]\")",
  "class SegmentationClasses:\n    \"\"\"\n    The segmentation classes define which \"tissue types\" are modelled in the simulation volumes.\n    \"\"\"\n    GENERIC = -1\n    AIR = 0\n    MUSCLE = 1\n    BONE = 2\n    BLOOD = 3\n    EPIDERMIS = 4\n    DERMIS = 5\n    FAT = 6\n    ULTRASOUND_GEL = 7\n    WATER = 8\n    HEAVY_WATER = 9\n    COUPLING_ARTIFACT = 10\n    MEDIPRENE = 11\n    SOFT_TISSUE = 12\n    LYMPH_NODE = 13",
  "class SerializableSIMPAClass(ABC):\n    \"\"\"\n    TODO\n    \"\"\"\n\n    @abstractmethod\n    def serialize(self) -> dict:\n        pass\n\n    @staticmethod\n    @abstractmethod\n    def deserialize(dictionary_to_deserialize: dict):\n        pass",
  "def serialize(self) -> dict:\n        pass",
  "def deserialize(dictionary_to_deserialize: dict):\n        pass",
  "def generate_dict_path(data_field, wavelength: (int, float) = None) -> str:\n    \"\"\"\n    Generates a path within an hdf5 file in the SIMPA convention\n\n    :param data_field: Data field that is supposed to be stored in an hdf5 file.\n    :param wavelength: Wavelength of the current simulation.\n    :return: String which defines the path to the data_field.\n    \"\"\"\n\n    if data_field in [Tags.SIMULATIONS, Tags.SETTINGS, Tags.DIGITAL_DEVICE, Tags.SIMULATION_PIPELINE]:\n        return \"/\" + data_field + \"/\"\n\n    wavelength_dependent_properties = [Tags.DATA_FIELD_ABSORPTION_PER_CM,\n                                       Tags.DATA_FIELD_SCATTERING_PER_CM,\n                                       Tags.DATA_FIELD_ANISOTROPY]\n\n    wavelength_independent_properties = [Tags.DATA_FIELD_OXYGENATION,\n                                         Tags.DATA_FIELD_SEGMENTATION,\n                                         Tags.DATA_FIELD_GRUNEISEN_PARAMETER,\n                                         Tags.DATA_FIELD_SPEED_OF_SOUND,\n                                         Tags.DATA_FIELD_DENSITY,\n                                         Tags.DATA_FIELD_ALPHA_COEFF,\n                                         Tags.KWAVE_PROPERTY_SENSOR_MASK,\n                                         Tags.KWAVE_PROPERTY_DIRECTIVITY_ANGLE]\n\n    simulation_output = [Tags.DATA_FIELD_FLUENCE,\n                         Tags.DATA_FIELD_INITIAL_PRESSURE,\n                         Tags.OPTICAL_MODEL_UNITS,\n                         Tags.DATA_FIELD_TIME_SERIES_DATA,\n                         Tags.DATA_FIELD_RECONSTRUCTED_DATA,\n                         Tags.DATA_FIELD_DIFFUSE_REFLECTANCE,\n                         Tags.DATA_FIELD_DIFFUSE_REFLECTANCE_POS,\n                         Tags.DATA_FIELD_PHOTON_EXIT_POS,\n                         Tags.DATA_FIELD_PHOTON_EXIT_DIR]\n\n    simulation_output_fields = [Tags.OPTICAL_MODEL_OUTPUT_NAME,\n                                Tags.SIMULATION_PROPERTIES]\n\n    wavelength_dependent_image_processing_output = [Tags.ITERATIVE_qPAI_RESULT]\n\n    wavelength_independent_image_processing_output = [Tags.LINEAR_UNMIXING_RESULT]\n\n    if wavelength is not None:\n        wl = \"/{}/\".format(wavelength)\n\n    if data_field in wavelength_dependent_properties:\n        if wavelength is not None:\n            dict_path = \"/\" + Tags.SIMULATIONS + \"/\" + Tags.SIMULATION_PROPERTIES + \"/\" + data_field + wl\n        else:\n            dict_path = \"/\" + Tags.SIMULATIONS + \"/\" + Tags.SIMULATION_PROPERTIES + \"/\" + data_field\n    elif data_field in simulation_output:\n        if data_field in [Tags.DATA_FIELD_FLUENCE, Tags.DATA_FIELD_INITIAL_PRESSURE, Tags.OPTICAL_MODEL_UNITS,\n                          Tags.DATA_FIELD_DIFFUSE_REFLECTANCE, Tags.DATA_FIELD_DIFFUSE_REFLECTANCE_POS,\n                          Tags.DATA_FIELD_PHOTON_EXIT_POS, Tags.DATA_FIELD_PHOTON_EXIT_DIR]:\n            if wavelength is not None:\n                dict_path = \"/\" + Tags.SIMULATIONS + \"/\" + Tags.OPTICAL_MODEL_OUTPUT_NAME + \"/\" + data_field + wl\n            else:\n                dict_path = \"/\" + Tags.SIMULATIONS + \"/\" + Tags.OPTICAL_MODEL_OUTPUT_NAME + \"/\" + data_field\n        else:\n            if wavelength is not None:\n                dict_path = \"/\" + Tags.SIMULATIONS + \"/\" + data_field + wl\n            else:\n                dict_path = \"/\" + Tags.SIMULATIONS + \"/\" + data_field\n\n    elif data_field in wavelength_independent_properties:\n        dict_path = \"/\" + Tags.SIMULATIONS + \"/\" + Tags.SIMULATION_PROPERTIES + \"/\" + data_field + \"/\"\n    elif data_field in simulation_output_fields:\n        dict_path = \"/\" + Tags.SIMULATIONS + \"/\" + data_field + \"/\"\n    elif data_field in wavelength_dependent_image_processing_output:\n        if wavelength is not None:\n            dict_path = \"/\" + Tags.IMAGE_PROCESSING + \"/\" + data_field + wl\n        else:\n            dict_path = \"/\" + Tags.IMAGE_PROCESSING + \"/\" + data_field\n\n    elif data_field in wavelength_independent_image_processing_output:\n        dict_path = \"/\" + Tags.IMAGE_PROCESSING + \"/\" + data_field + \"/\"\n    else:\n        raise ValueError(\"The requested data_field is not a valid argument. Please specify a valid data_field using \"\n                         \"the Tags from simpa/utils/tags.py!\")\n\n    return dict_path",
  "def get_data_field_from_simpa_output(simpa_output: dict, data_field: (tuple, str), wavelength: (int, float) = None):\n    \"\"\"\n    Navigates through a dictionary in the standard simpa output format to a specific data field.\n\n    :param simpa_output: Dictionary that is in the standard simpa output format.\n    :param data_field: Data field that is contained in simpa_output.\n    :param wavelength: Wavelength of the current simulation.\n    :return: Queried data_field.\n    \"\"\"\n\n    dict_path = generate_dict_path(data_field, wavelength)\n    keys_to_data_field = dict_path.split(\"/\")\n    current_dict = simpa_output\n    for key in keys_to_data_field:\n        if key == \"\":\n            continue\n        current_dict = current_dict[key]\n\n    return current_dict",
  "def get_processing_device(global_settings: Settings = None) -> torch.device:\n    \"\"\"\n    Get device (CPU/GPU) for data processing. By default use GPU for fast computation, unless the user manually sets it to CPU. Of course, GPU is only used if available. The user receives a warning if GPU was specified but is not available, in this case processing is done on CPU as fall-back.\n    :param global_settings: global settings defined by user\n    :type global_settings: Settings\n    :return: torch device for processing\n    \"\"\"\n\n    logger = Logger()\n\n    dev = \"cuda\"  # by default, the GPU is used\n\n    # if the user has specified to use a CPU, do so\n    if global_settings is not None:\n        if Tags.GPU in global_settings:\n            if not global_settings[Tags.GPU]:\n                dev = \"cpu\"\n\n    # if no GPU is available, use the CPU and inform the user\n    if dev == \"cuda\" and not torch.cuda.is_available():\n        dev = \"cpu\"\n        if global_settings is not None:\n            if Tags.GPU in global_settings:\n                logger.warning(\n                    'Cuda is not available! Check your torch/cuda version. Processing will be done on CPU instead.')\n\n    logger.debug(f\"Processing is done on {dev}\")\n\n    return torch.device(dev)",
  "class Settings(dict, SerializableSIMPAClass):\n    \"\"\"\n    The Settings class is a dictionary that contains all relevant settings for running a simulation in the SIMPA\n    toolkit. It includes an automatic sanity check for input parameters using the simpa.utils.Tags class. \\n\n    Usage: Settings({Tags.KEY1: value1, Tags.KEY2: value2, ...})\n    \"\"\"\n\n    def __init__(self, dictionary: dict = None, verbose: bool = True):\n        super(Settings, self).__init__()\n        self.logger = Logger()\n        self.verbose = verbose\n        if dictionary is None:\n            dictionary = {}\n        for key, value in dictionary.items():\n            self.__setitem__(key, value)\n\n    def __setitem__(self, key, value):\n        if isinstance(key, str):\n            super().__setitem__(key, value)\n            if self.verbose:\n                self.logger.warning(\"The key for the Settings dictionary should be a tuple in the form of \"\n                                    \"('{}', (data_type_1, data_type_2, ...)). \"\n                                    \"The tuple of data types specifies all possible types, the value can have.\\n\"\n                                    \"The key '{}' has been given the value {}\".format(key, key, value))\n            return\n        elif not isinstance(key, tuple):\n            raise TypeError(\"The key for the Settings dictionary has to be a tuple in the form of \"\n                            \"('{}', (data_type_1, data_type_2, ...)). \"\n                            \"The tuple of data types specifies all possible types, the value can have.\".format(key))\n        if isinstance(value, key[1]):\n            super().__setitem__(key[0], value)\n        else:\n            raise ValueError(\"The value {} ({}) for the key '{}' has to be an instance of: \"\n                             \"{}\".format(value, type(value), key[0], key[1]))\n\n    def __contains__(self, item):\n        if super().__contains__(item) is True:\n            return True\n        elif isinstance(item, str) is False and super().__contains__(item[0]) is True:\n            return True\n        else:\n            return False\n\n    def __getitem__(self, item):\n        if super().__contains__(item) is True:\n            return super().__getitem__(item)\n        else:\n            try:\n                return super().__getitem__(item[0])\n            except KeyError:\n                key = item[0] if isinstance(item, tuple) else item\n                raise KeyError(\"The key '{}' is not in the Settings dictionary\".format(key)) from None\n\n    def __delitem__(self, key):\n        if super().__contains__(key) is True:\n            return super().__delitem__(key)\n        else:\n            try:\n                return super().__delitem__(key[0])\n            except KeyError:\n                raise KeyError(\"The key '{}' is not in the Settings dictionary\".format(key)) from None\n\n    def get_optical_settings(self):\n        \"\"\"\"\n        Returns the settings for the optical forward model that are saved in this settings dictionary\n        \"\"\"\n        optical_settings = self[Tags.OPTICAL_MODEL_SETTINGS]\n        if isinstance(optical_settings, Settings):\n            return optical_settings\n        else:\n            return Settings(optical_settings)\n\n    def set_optical_settings(self, optical_settings: dict):\n        \"\"\"\n        Replaces the currently stored optical settings with the given dictionary\n\n        :param optical_settings: a dictionary containing the optical settings\n        \"\"\"\n        self[Tags.OPTICAL_MODEL_SETTINGS] = Settings(optical_settings)\n\n    def get_volume_creation_settings(self):\n        \"\"\"\"\n        Returns the settings for the optical forward model that are saved in this settings dictionary\n        \"\"\"\n        volume_creation_settings = self[Tags.VOLUME_CREATION_MODEL_SETTINGS]\n        if isinstance(volume_creation_settings, Settings):\n            return volume_creation_settings\n        else:\n            return Settings(volume_creation_settings)\n\n    def set_volume_creation_settings(self, volume_settings: dict):\n        \"\"\"\n        Replaces the currently stored volume creation settings with the given dictionary\n\n        :param volume_settings: a dictionary containing the volume creator settings\n        \"\"\"\n        self[Tags.VOLUME_CREATION_MODEL_SETTINGS] = Settings(volume_settings)\n\n    def get_acoustic_settings(self):\n        \"\"\"\"\n        Returns the settings for the acoustic forward model that are saved in this settings dictionary\n        \"\"\"\n        acoustic_settings = self[Tags.ACOUSTIC_MODEL_SETTINGS]\n        if isinstance(acoustic_settings, Settings):\n            return acoustic_settings\n        else:\n            return Settings(acoustic_settings)\n\n    def set_acoustic_settings(self, acoustic_settings: dict):\n        \"\"\"\n        Replaces the currently stored acoustic forward model settings with the given dictionary\n\n        :param acoustic_settings: a dictionary containing the acoustic model settings\n        \"\"\"\n        self[Tags.ACOUSTIC_MODEL_SETTINGS] = Settings(acoustic_settings)\n\n    def get_reconstruction_settings(self):\n        \"\"\"\"\n        Returns the settings for the reconstruction model that are saved in this settings dictionary\n        \"\"\"\n        reconstruction_settings = self[Tags.RECONSTRUCTION_MODEL_SETTINGS]\n        if isinstance(reconstruction_settings, Settings):\n            return reconstruction_settings\n        else:\n            return Settings(reconstruction_settings)\n\n    def set_reconstruction_settings(self, reconstruction_settings: dict):\n        \"\"\"\n        Replaces the currently stored reconstruction model settings with the given dictionary\n\n        :param reconstruction_settings: a dictionary containing the reconstruction model settings\n        \"\"\"\n        self[Tags.RECONSTRUCTION_MODEL_SETTINGS] = Settings(reconstruction_settings)\n\n    def serialize(self):\n        return {\"Settings\": dict(self)}\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize: dict):\n        return Settings(dictionary_to_deserialize, verbose=False)",
  "def __init__(self, dictionary: dict = None, verbose: bool = True):\n        super(Settings, self).__init__()\n        self.logger = Logger()\n        self.verbose = verbose\n        if dictionary is None:\n            dictionary = {}\n        for key, value in dictionary.items():\n            self.__setitem__(key, value)",
  "def __setitem__(self, key, value):\n        if isinstance(key, str):\n            super().__setitem__(key, value)\n            if self.verbose:\n                self.logger.warning(\"The key for the Settings dictionary should be a tuple in the form of \"\n                                    \"('{}', (data_type_1, data_type_2, ...)). \"\n                                    \"The tuple of data types specifies all possible types, the value can have.\\n\"\n                                    \"The key '{}' has been given the value {}\".format(key, key, value))\n            return\n        elif not isinstance(key, tuple):\n            raise TypeError(\"The key for the Settings dictionary has to be a tuple in the form of \"\n                            \"('{}', (data_type_1, data_type_2, ...)). \"\n                            \"The tuple of data types specifies all possible types, the value can have.\".format(key))\n        if isinstance(value, key[1]):\n            super().__setitem__(key[0], value)\n        else:\n            raise ValueError(\"The value {} ({}) for the key '{}' has to be an instance of: \"\n                             \"{}\".format(value, type(value), key[0], key[1]))",
  "def __contains__(self, item):\n        if super().__contains__(item) is True:\n            return True\n        elif isinstance(item, str) is False and super().__contains__(item[0]) is True:\n            return True\n        else:\n            return False",
  "def __getitem__(self, item):\n        if super().__contains__(item) is True:\n            return super().__getitem__(item)\n        else:\n            try:\n                return super().__getitem__(item[0])\n            except KeyError:\n                key = item[0] if isinstance(item, tuple) else item\n                raise KeyError(\"The key '{}' is not in the Settings dictionary\".format(key)) from None",
  "def __delitem__(self, key):\n        if super().__contains__(key) is True:\n            return super().__delitem__(key)\n        else:\n            try:\n                return super().__delitem__(key[0])\n            except KeyError:\n                raise KeyError(\"The key '{}' is not in the Settings dictionary\".format(key)) from None",
  "def get_optical_settings(self):\n        \"\"\"\"\n        Returns the settings for the optical forward model that are saved in this settings dictionary\n        \"\"\"\n        optical_settings = self[Tags.OPTICAL_MODEL_SETTINGS]\n        if isinstance(optical_settings, Settings):\n            return optical_settings\n        else:\n            return Settings(optical_settings)",
  "def set_optical_settings(self, optical_settings: dict):\n        \"\"\"\n        Replaces the currently stored optical settings with the given dictionary\n\n        :param optical_settings: a dictionary containing the optical settings\n        \"\"\"\n        self[Tags.OPTICAL_MODEL_SETTINGS] = Settings(optical_settings)",
  "def get_volume_creation_settings(self):\n        \"\"\"\"\n        Returns the settings for the optical forward model that are saved in this settings dictionary\n        \"\"\"\n        volume_creation_settings = self[Tags.VOLUME_CREATION_MODEL_SETTINGS]\n        if isinstance(volume_creation_settings, Settings):\n            return volume_creation_settings\n        else:\n            return Settings(volume_creation_settings)",
  "def set_volume_creation_settings(self, volume_settings: dict):\n        \"\"\"\n        Replaces the currently stored volume creation settings with the given dictionary\n\n        :param volume_settings: a dictionary containing the volume creator settings\n        \"\"\"\n        self[Tags.VOLUME_CREATION_MODEL_SETTINGS] = Settings(volume_settings)",
  "def get_acoustic_settings(self):\n        \"\"\"\"\n        Returns the settings for the acoustic forward model that are saved in this settings dictionary\n        \"\"\"\n        acoustic_settings = self[Tags.ACOUSTIC_MODEL_SETTINGS]\n        if isinstance(acoustic_settings, Settings):\n            return acoustic_settings\n        else:\n            return Settings(acoustic_settings)",
  "def set_acoustic_settings(self, acoustic_settings: dict):\n        \"\"\"\n        Replaces the currently stored acoustic forward model settings with the given dictionary\n\n        :param acoustic_settings: a dictionary containing the acoustic model settings\n        \"\"\"\n        self[Tags.ACOUSTIC_MODEL_SETTINGS] = Settings(acoustic_settings)",
  "def get_reconstruction_settings(self):\n        \"\"\"\"\n        Returns the settings for the reconstruction model that are saved in this settings dictionary\n        \"\"\"\n        reconstruction_settings = self[Tags.RECONSTRUCTION_MODEL_SETTINGS]\n        if isinstance(reconstruction_settings, Settings):\n            return reconstruction_settings\n        else:\n            return Settings(reconstruction_settings)",
  "def set_reconstruction_settings(self, reconstruction_settings: dict):\n        \"\"\"\n        Replaces the currently stored reconstruction model settings with the given dictionary\n\n        :param reconstruction_settings: a dictionary containing the reconstruction model settings\n        \"\"\"\n        self[Tags.RECONSTRUCTION_MODEL_SETTINGS] = Settings(reconstruction_settings)",
  "def serialize(self):\n        return {\"Settings\": dict(self)}",
  "def deserialize(dictionary_to_deserialize: dict):\n        return Settings(dictionary_to_deserialize, verbose=False)",
  "class Tags:\n    \"\"\"\n    This class contains all 'Tags' for the use in the settings dictionary as well as strings that are used in SIMPA\n    as naming conventions.\n    Every Tag that is intended to be used as a key in the settings dictionary is represented by a tuple.\n    The first element of the tuple is a string that corresponds to the name of the Tag.\n    The second element of the tuple is a data type or a tuple of data types.\n    The values that are assigned to the keys in the settings should match these data types.\n    Their usage within the SIMPA package is divided in \"SIMPA package\", \"module X\", \"adapter Y\", \"class Z\" and\n    \"naming convention\".\n    \"\"\"\n\n    \"\"\"\n    General settings\n    \"\"\"\n\n    SIMULATION_PATH = (\"simulation_path\", str)\n    \"\"\"\n    Absolute path to the folder where the SIMPA output is saved.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    SIMULATION_PIPELINE = \"simulation_pipeline\"\n    \"\"\"\n    List of SimulationModules that are used within a simulation pipeline.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    VOLUME_NAME = (\"volume_name\", str)\n    \"\"\"\n    Name of the SIMPA output file.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    WAVELENGTHS = (\"wavelengths\", (list, range, tuple, np.ndarray))\n    \"\"\"\n    Iterable of all the wavelengths used for the simulation.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    WAVELENGTH = (\"wavelength\", Number)\n    \"\"\"\n    Single wavelength used for the current simulation.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    RANDOM_SEED = (\"random_seed\", Number)\n    \"\"\"\n    Random seed for numpy and torch.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    TISSUE_PROPERTIES_OUPUT_NAME = \"properties\"\n    \"\"\"\n    Name of the simulation properties field in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    GPU = (\"gpu\", (bool, np.bool_))\n    \"\"\"\n    If True, uses all available gpu options of the used modules.\\n\n    Usage: SIMPA package \n    \"\"\"\n\n    ACOUSTIC_SIMULATION_3D = (\"acoustic_simulation_3d\", bool)\n    \"\"\"\n    If True, simulates the acoustic forward model in 3D.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    MEDIUM_TEMPERATURE_CELCIUS = (\"medium_temperature\", Number)\n    \"\"\"\n    Temperature of the simulated volume.\\n\n    Usage: module noise_simulation\n    \"\"\"\n\n    DO_FILE_COMPRESSION = (\"minimize_file_size\", (bool, np.bool_))\n    \"\"\"\n    If not set to False, the HDF5 file will be optimised after the simulations are done.\n    Usage: simpa.core.simulation.simulate\n    \"\"\"\n\n    \"\"\"\n    Volume Creation Settings\n    \"\"\"\n\n    VOLUME_CREATOR = (\"volume_creator\", str)\n    \"\"\"\n    Choice of the volume creator adapter.\\n \n    Usage: module volume_creation_module, module device_digital_twins\n    \"\"\"\n\n    VOLUME_CREATOR_VERSATILE = \"volume_creator_versatile\"\n    \"\"\"\n    Corresponds to the ModelBasedVolumeCreator.\\n\n    Usage: module volume_creation_module, naming convention\n    \"\"\"\n\n    VOLUME_CREATOR_SEGMENTATION_BASED = \"volume_creator_segmentation_based\"\n    \"\"\"\n    Corresponds to the SegmentationBasedVolumeCreator.\\n\n    Usage: module volume_creation_module, naming convention\n    \"\"\"\n\n    INPUT_SEGMENTATION_VOLUME = (\"input_segmentation_volume\", np.ndarray)\n    \"\"\"\n    Array that defines a segmented volume.\\n\n    Usage: adapter segmentation_based_volume_creator\n    \"\"\"\n\n    SEGMENTATION_CLASS_MAPPING = (\"segmentation_class_mapping\", dict)\n    \"\"\"\n    Mapping that assigns every class in the INPUT_SEGMENTATION_VOLUME a MOLECULE_COMPOSITION.\\n\n    Usage: adapter segmentation_based_volume_creator\n    \"\"\"\n\n    PRIORITY = (\"priority\", Number)\n    \"\"\"\n    Number that corresponds to a priority of the assigned structure. If another structure occupies the same voxel \n    in a volume, the structure with a higher priority will be preferred.\\n\n    Usage: adapter versatile_volume_creator\n    \"\"\"\n\n    MOLECULE_COMPOSITION = (\"molecule_composition\", list)\n    \"\"\"\n    List that contains all the molecules within a structure.\\n\n    Usage: module volume_creation_module\n    \"\"\"\n\n    SIMULATE_DEFORMED_LAYERS = (\"simulate_deformed_layers\", bool)\n    \"\"\"\n    If True, the horizontal layers are deformed according to the DEFORMED_LAYERS_SETTINGS.\\n\n    Usage: adapter versatile_volume_creation\n    \"\"\"\n\n    DEFORMED_LAYERS_SETTINGS = (\"deformed_layers_settings\", dict)\n    \"\"\"\n    Settings that contain the functional which defines the deformation of the layers.\\n\n    Usage: adapter versatile_volume_creation\n    \"\"\"\n\n    BACKGROUND = \"Background\"\n    \"\"\"\n    Corresponds to the name of a structure.\\n\n    Usage: adapter versatile_volume_creation, naming convention\n    \"\"\"\n\n    ADHERE_TO_DEFORMATION = (\"adhere_to_deformation\", bool)\n    \"\"\"\n    If True, a structure will be shifted according to the deformation.\\n\n    Usage: adapter versatile_volume_creation\n    \"\"\"\n\n    DEFORMATION_X_COORDINATES_MM = \"deformation_x_coordinates\"\n    \"\"\"\n    Mesh that defines the x coordinates of the deformation.\\n\n    Usage: adapter versatile_volume_creation, naming convention\n    \"\"\"\n\n    DEFORMATION_Y_COORDINATES_MM = \"deformation_y_coordinates\"\n    \"\"\"\n    Mesh that defines the y coordinates of the deformation.\\n\n    Usage: adapter versatile_volume_creation, naming convention\n    \"\"\"\n\n    DEFORMATION_Z_ELEVATIONS_MM = \"deformation_z_elevation\"\n    \"\"\"\n    Mesh that defines the z coordinates of the deformation.\\n\n    Usage: adapter versatile_volume_creation, naming convention\n    \"\"\"\n\n    MAX_DEFORMATION_MM = \"max_deformation\"\n    \"\"\"\n    Maximum deformation in z-direction.\\n\n    Usage: adapter versatile_volume_creation, naming convention\n    \"\"\"\n\n    \"\"\"\n    Structure Settings\n    \"\"\"\n\n    CONSIDER_PARTIAL_VOLUME = (\"consider_partial_volume\", bool)\n    \"\"\"\n    If True, the structure will be generated with its edges only occupying a partial volume of the voxel.\\n\n    Usage: adapter versatile_volume_creation\n    \"\"\"\n    CONSIDER_PARTIAL_VOLUME_IN_DEVICE = (\"consider_partial_volume_in_device\", bool)\n    \"\"\"\n    If True, the structures inside the device (i.e. US gel and membrane) will be generated with its edges\n    only occupying a partial volume of the voxel. \\n\n    Usage: adapter versatile_volume_creation \n    \"\"\"\n\n    STRUCTURE_START_MM = (\"structure_start\", (list, tuple, np.ndarray))\n    \"\"\"\n    Beginning of the structure as [x, y, z] coordinates in the generated volume.\\n\n    Usage: adapter versatile_volume_creation, class GeometricalStructure\n    \"\"\"\n\n    STRUCTURE_END_MM = (\"structure_end\", (list, tuple, np.ndarray))\n    \"\"\"\n    Ending of the structure as [x, y, z] coordinates in the generated volume.\\n\n    Usage: adapter versatile_volume_creation, class GeometricalStructure\n    \"\"\"\n\n    STRUCTURE_RADIUS_MM = (\"structure_radius\", (Number, np.ndarray))\n    \"\"\"\n    Radius of the structure.\\n\n    Usage: adapter versatile_volume_creation, class GeometricalStructure\n    \"\"\"\n\n    STRUCTURE_ECCENTRICITY = (\"structure_excentricity\", (Number, np.ndarray))\n    \"\"\"\n    Eccentricity of the structure.\\n\n    Usage: adapter versatile_volume_creation, class EllipticalTubularStructure\n    \"\"\"\n\n    STRUCTURE_FIRST_EDGE_MM = (\"structure_first_edge_mm\", (list, tuple, np.ndarray))\n    \"\"\"\n    Edge of the structure as [x, y, z] vector starting from STRUCTURE_START_MM in the generated volume.\\n\n    Usage: adapter versatile_volume_creation, class ParallelepipedStructure\n    \"\"\"\n\n    STRUCTURE_SECOND_EDGE_MM = (\"structure_second_edge_mm\", (list, tuple, np.ndarray))\n    \"\"\"\n    Edge of the structure as [x, y, z] vector starting from STRUCTURE_START_MM in the generated volume.\\n\n    Usage: adapter versatile_volume_creation, class ParallelepipedStructure\n    \"\"\"\n\n    STRUCTURE_THIRD_EDGE_MM = (\"structure_third_edge_mm\", (list, tuple, np.ndarray))\n    \"\"\"\n    Edge of the structure as [x, y, z] vector starting from STRUCTURE_START_MM in the generated volume.\\n\n    Usage: adapter versatile_volume_creation, class ParallelepipedStructure\n    \"\"\"\n\n    STRUCTURE_X_EXTENT_MM = (\"structure_x_extent_mm\", Number)\n    \"\"\"\n    X-extent of the structure in the generated volume.\\n\n    Usage: adapter versatile_volume_creation, class RectangularCuboidStructure\n    \"\"\"\n\n    STRUCTURE_Y_EXTENT_MM = (\"structure_y_extent_mm\", Number)\n    \"\"\"\n    Y-extent of the structure in the generated volume.\\n\n    Usage: adapter versatile_volume_creation, class RectangularCuboidStructure\n    \"\"\"\n\n    STRUCTURE_Z_EXTENT_MM = (\"structure_z_extent_mm\", Number)\n    \"\"\"\n    Z-extent of the structure in the generated volume.\\n\n    Usage: adapter versatile_volume_creation, class RectangularCuboidStructure\n    \"\"\"\n\n    STRUCTURE_BIFURCATION_LENGTH_MM = (\"structure_bifurcation_length_mm\", Number)\n    \"\"\"\n    Length after which a VesselStructure will bifurcate.\\n\n    Usage: adapter versatile_volume_creation, class VesselStructure\n    \"\"\"\n\n    STRUCTURE_CURVATURE_FACTOR = (\"structure_curvature_factor\", Number)\n    \"\"\"\n    Factor that determines how strongly a vessel tree is curved.\\n\n    Usage: adapter versatile_volume_creation, class VesselStructure\n    \"\"\"\n\n    STRUCTURE_RADIUS_VARIATION_FACTOR = (\"structure_radius_variation_factor\", Number)\n    \"\"\"\n    Factor that determines how strongly a the radius of vessel tree varies.\\n\n    Usage: adapter versatile_volume_creation, class VesselStructure\n    \"\"\"\n\n    STRUCTURE_DIRECTION = (\"structure_direction\", (list, tuple, np.ndarray))\n    \"\"\"\n    Direction as [x, y, z] vector starting from STRUCTURE_START_MM in which the vessel will grow.\\n\n    Usage: adapter versatile_volume_creation, class VesselStructure\n    \"\"\"\n\n    VESSEL_STRUCTURE = \"VesselStructure\"\n\n    \"\"\"\n    Digital Device Twin Settings\n    \"\"\"\n\n    DIGITAL_DEVICE = \"digital_device\"\n    \"\"\"\n    Digital device that is chosen as illumination source and detector for the simulation.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    DIGITAL_DEVICE_MSOT_ACUITY = \"digital_device_msot\"\n    \"\"\"\n    Corresponds to the MSOTAcuityEcho device.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n\n    DIGITAL_DEVICE_RSOM = \"digital_device_rsom\"\n    \"\"\"\n    Corresponds to the RSOMExplorerP50 device.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n\n    DIGITAL_DEVICE_MSOT_INVISION = \"digital_device_invision\"\n    \"\"\"\n    Corresponds to the InVision 256-TF device.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n\n    DIGITAL_DEVICE_SLIT_ILLUMINATION_LINEAR_DETECTOR = \"digital_device_slit_illumination_linear_detector\"\n    \"\"\"\n    Corresponds to a PA device with a slit as illumination and a linear array as detection geometry.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n\n    DIGITAL_DEVICE_POSITION = (\"digital_device_position\", (list, tuple, np.ndarray))\n    \"\"\"\n    Position in [x, y, z] coordinates of the device in the generated volume.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    US_GEL = (\"us_gel\", bool)\n    \"\"\"\n    If True, us gel is placed between the PA device and the simulated volume.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    OPTICAL_MODEL_SETTINGS = (\"optical_model_settings\", dict)\n    \"\"\"\n    Optical model settings\n    \"\"\"\n\n    OPTICAL_MODEL_OUTPUT_NAME = \"optical_forward_model_output\"\n    \"\"\"\n    Name of the optical forward model output field in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    OPTICAL_MODEL_BINARY_PATH = (\"optical_model_binary_path\", str)\n    \"\"\"\n    Absolute path of the location of the optical forward model binary.\\n\n    Usage: module optical_simulation_module\n    \"\"\"\n\n    OPTICAL_MODEL_NUMBER_PHOTONS = (\"optical_model_number_of_photons\", Number)\n    \"\"\"\n    Number of photons used in the optical simulation.\\n\n    Usage: module optical_simulation_module\n    \"\"\"\n\n    OPTICAL_MODEL_ILLUMINATION_GEOMETRY_JSON_FILE = (\"optical_model_illumination_geometry_json_file\", str)\n    \"\"\"\n    Absolute path of the location of the JSON file containing the IPASC-formatted optical forward \n    model illumination geometry.\\n\n    Usage: module optical_simulation_module\n    \"\"\"\n\n    LASER_PULSE_ENERGY_IN_MILLIJOULE = (\"laser_pulse_energy_in_millijoule\", (int, np.integer, float, list,\n                                                                             range, tuple, np.ndarray))\n    \"\"\"\n    Laser pulse energy used in the optical simulation.\\n\n    Usage: module optical_simulation_module\n    \"\"\"\n\n    DATA_FIELD_FLUENCE = \"fluence\"\n    \"\"\"\n    Name of the optical forward model output fluence field in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    DATA_FIELD_INITIAL_PRESSURE = \"initial_pressure\"\n    \"\"\"\n    Name of the optical forward model output initial pressure field in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    OPTICAL_MODEL_UNITS = \"units\"\n    \"\"\"\n    Name of the optical forward model output units field in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    MCX_SEED = (\"mcx_seed\", (int, np.integer))\n    \"\"\"\n    Specific seed for random initialisation in mcx.\\n\n    if not set, Tags.RANDOM_SEED will be used instead.\n    Usage: module optical_modelling, adapter mcx_adapter\n    \"\"\"\n\n    MCX_ASSUMED_ANISOTROPY = (\"mcx_assumed_anisotropy\", (int, float))\n    \"\"\"\n    The anisotropy that should be assumed for the mcx simulations.\n    If not set, a default value of 0.9 will be assumed.\n    Usage: module optical_modelling, adapter mcx_adapter\n    \"\"\"\n\n    ILLUMINATION_TYPE = (\"optical_model_illumination_type\", str)\n    \"\"\"\n    Type of the illumination geometry used in mcx.\\n\n    Usage: module optical_modelling, adapter mcx_adapter\n    \"\"\"\n\n    # Illumination parameters\n    ILLUMINATION_POSITION = (\"illumination_position\", (list, tuple, np.ndarray))\n    \"\"\"\n    Position of the photon source in [x, y, z] coordinates used in mcx.\\n\n    Usage: module optical_modelling, adapter mcx_adapter\n    \"\"\"\n\n    ILLUMINATION_DIRECTION = (\"illumination_direction\", (list, tuple, np.ndarray))\n    \"\"\"\n    Direction of the photon source as [x, y, z] vector used in mcx.\\n\n    Usage: module optical_modelling, adapter mcx_adapter\n    \"\"\"\n\n    ILLUMINATION_PARAM1 = (\"illumination_param1\", (list, tuple, np.ndarray))\n    \"\"\"\n    First parameter group of the specified illumination type as [x, y, z, w] vector used in mcx.\\n\n    Usage: module optical_modelling, adapter mcx_adapter\n    \"\"\"\n\n    ILLUMINATION_PARAM2 = (\"illumination_param2\", (list, tuple, np.ndarray))\n    \"\"\"\n    Second parameter group of the specified illumination type as [x, y, z, w] vector used in mcx.\\n\n    Usage: module optical_modelling, adapter mcx_adapter\n    \"\"\"\n\n    TIME_STEP = (\"time_step\", Number)\n    \"\"\"\n    Temporal resolution of mcx.\\n\n    Usage: adapter mcx_adapter\n    \"\"\"\n\n    TOTAL_TIME = (\"total_time\", Number)\n    \"\"\"\n    Total simulated time in mcx.\\n\n    Usage: adapter mcx_adapter\n    \"\"\"\n\n    # Supported illumination types - implemented in mcx\n    ILLUMINATION_TYPE_PENCIL = \"pencil\"\n    \"\"\"\n    Corresponds to pencil source in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_PENCILARRAY = \"pencilarray\"\n    \"\"\"\n    Corresponds to pencilarray source in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_DISK = \"disk\"\n    \"\"\"\n    Corresponds to disk source in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_SLIT = \"slit\"\n    \"\"\"\n    Corresponds to slit source in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_GAUSSIAN = \"gaussian\"\n    \"\"\"\n    Corresponds to gaussian source in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_PATTERN = \"pattern\"\n    \"\"\"\n    Corresponds to pattern source in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_PATTERN_3D = \"pattern3d\"\n    \"\"\"\n    Corresponds to pattern3d source in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_PLANAR = \"planar\"\n    \"\"\"\n    Corresponds to planar source in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_FOURIER = \"fourier\"\n    \"\"\"\n    Corresponds to fourier source in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_FOURIER_X = \"fourierx\"\n    \"\"\"\n    Corresponds to fourierx source in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_FOURIER_X_2D = \"fourierx2d\"\n    \"\"\"\n    Corresponds to fourierx2d source in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_DKFZ_PAUS = \"pasetup\"  # TODO more explanatory rename of pasetup\n    \"\"\"\n    Corresponds to pasetup source in mcx. The geometrical definition is described in:\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_MSOT_ACUITY_ECHO = \"msot_acuity_echo\"\n    \"\"\"s\n    Corresponds to msot_acuity_echo source in mcx. The device is manufactured by iThera Medical, Munich, Germany\n    (https: // www.ithera-medical.com / products / msot-acuity /).\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_MSOT_INVISION = \"invision\"\n    \"\"\"\n    Corresponds to a source definition in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_RING = \"ring\"\n    \"\"\"\n    Corresponds to ring source in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    ILLUMINATION_TYPE_IPASC_DEFINITION = \"ipasc\"\n    \"\"\"\n    Corresponds to a source definition in mcx.\\n\n    Usage: adapter mcx_adapter, naming convention\n    \"\"\"\n\n    # Supported optical models\n    OPTICAL_MODEL = (\"optical_model\", str)\n    \"\"\"\n    Choice of the used optical model.\\n\n    Usage: module optical_simulation_module\n    \"\"\"\n\n    OPTICAL_MODEL_MCX = \"mcx\"\n    \"\"\"\n    Corresponds to the mcx simulation.\\n\n    Usage: module optical_simulation_module, naming convention\n    \"\"\"\n\n    OPTICAL_MODEL_TEST = \"simpa_tests\"\n    \"\"\"\n    Corresponds to an adapter for testing purposes only.\\n\n    Usage: module optical_simulation_module, naming convention\n    \"\"\"\n\n    # Supported acoustic models\n    ACOUSTIC_MODEL = (\"acoustic_model\", str)\n    \"\"\"\n    Choice of the used acoustic model.\\n\n    Usage: module acoustic_forward_module\n    \"\"\"\n\n    ACOUSTIC_MODEL_K_WAVE = \"kwave\"\n    \"\"\"\n    Corresponds to the kwave simulaiton.\\n\n    Usage: module acoustic_forward_module, naming convention\n    \"\"\"\n\n    K_WAVE_SPECIFIC_DT = (\"dt_acoustic_sim\", Number)\n    \"\"\"\n    Temporal resolution of kwave.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter\n    \"\"\"\n\n    K_WAVE_SPECIFIC_NT = (\"Nt_acoustic_sim\", Number)\n    \"\"\"\n    Total time steps simulated by kwave.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter\n    \"\"\"\n\n    ACOUSTIC_MODEL_TEST = \"simpa_tests\"\n    \"\"\"\n    Corresponds to an adapter for testing purposes only.\\n\n    Usage: module acoustic_forward_module, naming convention\n    \"\"\"\n\n    ACOUSTIC_MODEL_SETTINGS = (\"acoustic_model_settings\", dict)\n    \"\"\"\n    Acoustic model settings.\n    \"\"\"\n\n    ACOUSTIC_MODEL_BINARY_PATH = (\"acoustic_model_binary_path\", str)\n    \"\"\"\n    Absolute path of the location of the acoustic forward model binary.\\n\n    Usage: module optical_simulation_module\n    \"\"\"\n\n    ACOUSTIC_MODEL_OUTPUT_NAME = \"acoustic_forward_model_output\"\n    \"\"\"\n    Name of the acoustic forward model output field in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    RECORDMOVIE = (\"record_movie\", (bool, np.bool_))\n    \"\"\"\n    If True, a movie of the kwave simulation will be recorded.\\n\n    Usage: adapter KwaveAcousticForwardModel\n    \"\"\"\n\n    MOVIENAME = (\"movie_name\", str)\n    \"\"\"\n    Name of the movie recorded by kwave.\\n\n    Usage: adapter KwaveAcousticForwardModel\n    \"\"\"\n\n    ACOUSTIC_LOG_SCALE = (\"acoustic_log_scale\", (bool, np.bool_))\n    \"\"\"\n    If True, the movie of the kwave simulation will be recorded in a log scale.\\n\n    Usage: adapter KwaveAcousticForwardModel\n    \"\"\"\n\n    DATA_FIELD_TIME_SERIES_DATA = \"time_series_data\"\n    \"\"\"\n    Name of the time series data field in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    RECONSTRUCTION_MODEL_SETTINGS = (\"reconstruction_model_settings\", dict)\n    \"\"\"\"\n    Reconstruction Model Settings\n    \"\"\"\n\n    RECONSTRUCTION_OUTPUT_NAME = (\"reconstruction_result\", str)\n    \"\"\"\n    Absolute path of the image reconstruction result.\\n\n    Usage: adapter MitkBeamformingAdapter\n    \"\"\"\n\n    RECONSTRUCTION_ALGORITHM = (\"reconstruction_algorithm\", str)\n    \"\"\"\n    Choice of the used reconstruction algorithm.\\n\n    Usage: module reconstruction_module\n    \"\"\"\n\n    RECONSTRUCTION_ALGORITHM_DAS = \"DAS\"\n    \"\"\"\n    Corresponds to the reconstruction algorithm DAS with the MitkBeamformingAdapter.\\n\n    Usage: module reconstruction_module, naming convention\n    \"\"\"\n\n    RECONSTRUCTION_ALGORITHM_DMAS = \"DMAS\"\n    \"\"\"\n    Corresponds to the reconstruction algorithm DMAS with the MitkBeamformingAdapter.\\n\n    Usage: module reconstruction_module, naming convention\n    \"\"\"\n\n    RECONSTRUCTION_ALGORITHM_SDMAS = \"sDMAS\"\n    \"\"\"\n    Corresponds to the reconstruction algorithm sDMAS with the MitkBeamformingAdapter.\\n\n    Usage: module reconstruction_module, naming convention\n    \"\"\"\n\n    RECONSTRUCTION_ALGORITHM_TIME_REVERSAL = \"time_reversal\"\n    \"\"\"\n    Corresponds to the reconstruction algorithm Time Reversal with TimeReversalAdapter.\\n\n    Usage: module reconstruction_module, naming convention\n    \"\"\"\n\n    RECONSTRUCTION_ALGORITHM_TEST = \"TEST\"\n    \"\"\"\n    Corresponds to an adapter for testing purposes only.\\n\n    Usage: module reconstruction_module, naming convention\n    \"\"\"\n\n    RECONSTRUCTION_INVERSE_CRIME = (\"reconstruction_inverse_crime\", (bool, np.bool_))\n    \"\"\"\n    If True, the Time Reversal reconstruction will commit the \"inverse crime\".\\n\n    Usage: TimeReversalAdapter\n    \"\"\"\n\n    RECONSTRUCTION_MITK_BINARY_PATH = (\"reconstruction_mitk_binary_path\", str)\n    \"\"\"\n    Absolute path to the Mitk Beamforming script.\\n\n    Usage: adapter MitkBeamformingAdapter\n    \"\"\"\n\n    RECONSTRUCTION_MITK_SETTINGS_XML = (\"reconstruction_mitk_settings_xml\", str)\n    \"\"\"\n    Absolute path to the Mitk Beamforming script settings.\\n\n    Usage: adapter MitkBeamformingAdapter\n    \"\"\"\n\n    RECONSTRUCTION_BMODE_METHOD = (\"reconstruction_bmode_method\", str)\n    \"\"\"\n    Choice of the B-Mode method used in the Mitk Beamforming.\\n\n    Usage: adapter MitkBeamformingAdapter\n    \"\"\"\n\n    RECONSTRUCTION_BMODE_METHOD_ABS = \"Abs\"\n    \"\"\"\n    Corresponds to the absolute value as the B-Mode method used in the Mitk Beamforming.\\n\n    Usage: adapter MitkBeamformingAdapter, naming convention\n    \"\"\"\n\n    RECONSTRUCTION_BMODE_METHOD_HILBERT_TRANSFORM = \"EnvelopeDetection\"\n    \"\"\"\n    Corresponds to the Hilbert transform as the B-Mode method used in the Mitk Beamforming.\\n\n    Usage: adapter MitkBeamformingAdapter, naming convention\n    \"\"\"\n\n    RECONSTRUCTION_BMODE_BEFORE_RECONSTRUCTION = (\"Envelope_Detection_before_Reconstruction\", (bool, np.bool_))\n    \"\"\"\n    Specifies whether an envelope detection should be performed before reconstruction, default is False\n    Usage: adapter PyTorchDASAdapter, naming convention\n    \"\"\"\n\n    RECONSTRUCTION_BMODE_AFTER_RECONSTRUCTION = (\"Envelope_Detection_after_Reconstruction\", (bool, np.bool_))\n    \"\"\"\n    Specifies whether an envelope detection should be performed after reconstruction, default is False\n    Usage: adapter PyTorchDASAdapter\n    \"\"\"\n\n    RECONSTRUCTION_APODIZATION_METHOD = (\"reconstruction_apodization_method\", str)\n    \"\"\"\n    Choice of the apodization method used, i.e. window functions .\\n\n    Usage: adapter PyTorchDASAdapter\n    \"\"\"\n\n    RECONSTRUCTION_APODIZATION_BOX = \"BoxApodization\"\n    \"\"\"\n    Corresponds to the box window function for apodization.\\n\n    Usage: adapter PyTorchDASAdapter, naming convention\n    \"\"\"\n\n    RECONSTRUCTION_APODIZATION_HANN = \"HannApodization\"\n    \"\"\"\n    Corresponds to the Hann window function for apodization.\\n\n    Usage: adapter PyTorchDASAdapter, naming convention\n    \"\"\"\n\n    RECONSTRUCTION_APODIZATION_HAMMING = \"HammingApodization\"\n    \"\"\"\n    Corresponds to the Hamming window function for apodization.\\n\n    Usage: adapter PyTorchDASAdapter, naming convention\n    \"\"\"\n\n    RECONSTRUCTION_PERFORM_BANDPASS_FILTERING = (\"reconstruction_perform_bandpass_filtering\",\n                                                 (bool, np.bool_))\n    \"\"\"\n    Whether bandpass filtering should be applied or not. Default should be True\\n\n    Usage: adapter PyTorchDASAdapter\n    \"\"\"\n\n    RECONSTRUCTION_PERFORM_RESAMPLING_FOR_FFT = (\"reconstruction_perform_resampling_for_fft\",\n                                                 (bool, np.bool_))\n    \"\"\"\n    Whether the data is resampled to a power of 2 in time dimension before applying the FFT \n    and resampled back after filtering for performance reasons. Default should be False\\n\n    Usage: adapter reconstruction_utils\n    \"\"\"\n\n    BANDPASS_FILTER_METHOD = (\"bandpass_filtering_method\", str)\n    \"\"\"\n    Choice of the bandpass filtering method used, i.e. tukey or butterworth filter .\\n\n    Usage: ReconstructionAdapterBase\n    \"\"\"\n\n    TUKEY_BANDPASS_FILTER = \"tukey_bandpass_filter\"\n    \"\"\"\n    Corresponds to the tukey bandpass filter\\n\n    Usage: reconstruction utils\n    \"\"\"\n\n    BUTTERWORTH_BANDPASS_FILTER = \"butterworth_bandpass_filter\"\n    \"\"\"\n    Corresponds to the tukey bandpass filter\\n\n    Usage: reconstruction utils\n    \"\"\"\n\n    TUKEY_WINDOW_ALPHA = (\"tukey_window_alpha\", Number)\n    \"\"\"\n    Sets alpha value of Tukey window between 0 (similar to box window) and 1 (similar to Hann window).\n    Default is 0.5\\n\n    Usage: adapter PyTorchDASAdapter\n    \"\"\"\n\n    BUTTERWORTH_FILTER_ORDER = (\"butterworth_filter_order\", (int, np.integer))\n    \"\"\"\n    Sets the order of the filter, usually between 1 and 5.\n    Default is 1\\n\n    Usage: reconstruction utils\n    \"\"\"\n\n    BANDPASS_CUTOFF_LOWPASS_IN_HZ = (\"bandpass_cuttoff_lowpass_in_HZ\", Number)\n    \"\"\"\n    Sets the cutoff threshold in Hz for lowpass filtering, i.e. upper limit of the tukey filter. Default is 8 MHz\\n\n    Usage: adapter PyTorchDASAdapter\n    \"\"\"\n\n    BANDPASS_CUTOFF_HIGHPASS_IN_HZ = (\"bandpass_cuttoff_highpass_in_HZ\", Number)\n    \"\"\"\n    Sets the cutoff threshold in Hz for highpass filtering, i.e. lower limit of the tukey filter. Default is 0.1 MHz\\n\n    Usage: adapter PyTorchDASAdapter\n    \"\"\"\n\n    DATA_FIELD_RECONSTRUCTED_DATA = \"reconstructed_data\"\n    \"\"\"\n    Name of the reconstructed data field in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    RECONSTRUCTION_MODE = (\"reconstruction_mode\", str)\n    \"\"\"\n    Choice of the reconstruction mode used in the Backprojection.\\n\n    Usage: adapter BackprojectionAdapter\n    \"\"\"\n\n    RECONSTRUCTION_MODE_DIFFERENTIAL = \"differential\"\n    \"\"\"\n    Corresponds to the differential mode used in the Backprojection.\\n\n    Usage: adapter BackprojectionAdapter, naming_convention\n    \"\"\"\n\n    RECONSTRUCTION_MODE_PRESSURE = \"pressure\"\n    \"\"\"\n    Corresponds to the pressure mode used in the Backprojection.\\n\n    Usage: adapter BackprojectionAdapter, naming_convention\n    \"\"\"\n\n    RECONSTRUCTION_MODE_FULL = \"full\"\n    \"\"\"\n    Corresponds to the full mode used in the Backprojection.\\n\n    Usage: adapter BackprojectionAdapter, naming_convention\n    \"\"\"\n\n    # physical property volume types\n    DATA_FIELD_ABSORPTION_PER_CM = \"mua\"\n    \"\"\"\n    Optical absorption of the generated volume/structure in 1/cm.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n\n    DATA_FIELD_SCATTERING_PER_CM = \"mus\"\n    \"\"\"\n    Optical scattering (NOT REDUCED SCATTERING mus'! mus'=mus*(1-g) ) of the generated volume/structure in 1/cm.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n\n    DATA_FIELD_ANISOTROPY = \"g\"\n    \"\"\"\n    Optical scattering anisotropy of the generated volume/structure.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n\n    DATA_FIELD_OXYGENATION = \"oxy\"\n    \"\"\"\n    Oxygenation of the generated volume/structure.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n\n    DATA_FIELD_SEGMENTATION = \"seg\"\n    \"\"\"\n    Segmentation of the generated volume/structure.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n\n    DATA_FIELD_GRUNEISEN_PARAMETER = \"gamma\"\n    \"\"\"\n    We define PROPERTY_GRUNEISEN_PARAMETER to contain all wavelength-independent constituents of the PA signal.\n    This means that it contains the percentage of absorbed light converted into heat.\n    Naturally, one could make an argument that this should not be the case, however, it simplifies the usage of \n    this tool.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n\n    DATA_FIELD_SPEED_OF_SOUND = \"sos\"\n    \"\"\"\n    Speed of sound of the generated volume/structure in m/s.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n\n    DATA_FIELD_DENSITY = \"density\"\n    \"\"\"\n    Density of the generated volume/structure in kg/m\u00b3.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n\n    DATA_FIELD_ALPHA_COEFF = \"alpha_coeff\"\n    \"\"\"\n    Acoustic attenuation of kwave of the generated volume/structure in dB/cm/MHz.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    KWAVE_PROPERTY_SENSOR_MASK = \"sensor_mask\"\n    \"\"\"\n    Sensor mask of kwave of the used PA device.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    KWAVE_PROPERTY_DIRECTIVITY_ANGLE = \"directivity_angle\"\n    \"\"\"\n    Directionality of the sensors in kwave of the used PA device.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    KWAVE_PROPERTY_INTRINSIC_EULER_ANGLE = \"intrinsic_euler_angle\"\n    \"\"\"\n    Intrinsic euler angles of the detector elements in the kWaveArray.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    KWAVE_PROPERTY_ALPHA_POWER = (\"medium_alpha_power\", Number)\n    \"\"\"\n    Exponent of the exponential acoustic attenuation law of kwave.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    # Volume geometry settings\n    SPACING_MM = (\"voxel_spacing_mm\", Number)\n    \"\"\"\n    Isotropic extent of one voxels in mm in the generated volume.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    DIM_VOLUME_X_MM = (\"volume_x_dim_mm\", Number)\n    \"\"\"\n    Extent of the x-axis of the generated volume.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    DIM_VOLUME_Y_MM = (\"volume_y_dim_mm\", Number)\n    \"\"\"\n    Extent of the y-axis of the generated volume.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    DIM_VOLUME_Z_MM = (\"volume_z_dim_mm\", Number)\n    \"\"\"\n    Extent of the z-axis of the generated volume.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    # PML parameters\n    KWAVE_PROPERTY_PMLSize = (\"pml_size\", (list, tuple, np.ndarray))\n    \"\"\"\n    Size of the \"perfectly matched layer\" (PML) around the simulated volume in kwave.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    KWAVE_PROPERTY_PMLAlpha = (\"pml_alpha\", Number)\n    \"\"\"\n    Alpha coefficient of the \"perfectly matched layer\" (PML) around the simulated volume in kwave.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    KWAVE_PROPERTY_PMLInside = (\"pml_inside\", bool)\n    \"\"\"\n    If True, the \"perfectly matched layer\" (PML) in kwave is located inside the volume.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    KWAVE_PROPERTY_PlotPML = (\"plot_pml\", bool)\n    \"\"\"\n    If True, the \"perfectly matched layer\" (PML) around the simulated volume in kwave is plotted.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    KWAVE_PROPERTY_INITIAL_PRESSURE_SMOOTHING = (\"initial_pressure_smoothing\", bool)\n    \"\"\"\n    If True, the initial pressure is smoothed before simulated in kwave.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    # Acoustic Sensor Properties\n    KWAVE_PROPERTY_SENSOR_RECORD = (\"sensor_record\", str)\n    \"\"\"\n    Sensor Record mode of the sensor in kwave. Default should be \"p\".\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    MODEL_SENSOR_FREQUENCY_RESPONSE = (\"model_sensor_frequency_response\", bool)\n    \"\"\"\n    Boolean to decide whether to model the sensor frequency response in kwave.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    SENSOR_CENTER_FREQUENCY_HZ = (\"sensor_center_frequency\", Number)\n    \"\"\"\n    Sensor center frequency in kwave.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    SENSOR_BANDWIDTH_PERCENT = (\"sensor_bandwidth\", Number)\n    \"\"\"\n    Sensor bandwidth in kwave.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    SENSOR_DIRECTIVITY_SIZE_M = (\"sensor_directivity_size\", Number)\n    \"\"\"\n    Size of each detector element in kwave.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    SENSOR_DIRECTIVITY_PATTERN = \"sensor_directivity_pattern\"\n    \"\"\"\n    Sensor directivity pattern of the sensor in kwave. Default should be \"pressure\".\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    SENSOR_SAMPLING_RATE_MHZ = (\"sensor_sampling_rate_mhz\", Number)\n    \"\"\"\n    Sampling rate of the used PA device.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    SENSOR_NUM_ELEMENTS = (\"sensor_num_elements\", (int, np.integer))\n    \"\"\"\n    Number of detector elements for kwave if no device was selected.\\n\n    Usage: adapter KwaveAcousticForwardModel, adapter TimeReversalAdapter, naming convention\n    \"\"\"\n\n    SENSOR_NUM_USED_ELEMENTS = (\"sensor_num_used_elements\", (int, np.integer))\n    \"\"\"\n    Number of detector elements that fit into the generated volume if the dimensions and/or spacing of the generated \n    volume were not highly resolved enough to be sufficient for the selected PA device.\\n\n    Usage: module acoustic_forward_module, naming convention\n    \"\"\"\n\n    SENSOR_ELEMENT_POSITIONS = \"sensor_element_positions\"\n    \"\"\"\n    Number of detector elements that fit into the generated volume if the dimensions and/or spacing of the generated \n    volume were not highly resolved enough to be sufficient for the selected PA device.\\n\n    Usage: module acoustic_forward_module, naming convention\n    \"\"\"\n\n    DETECTOR_ELEMENT_WIDTH_MM = \"detector_element_width_mm\"\n    \"\"\"\n    Width of a detector element. Corresponds to the pitch - the distance between two detector element borders.\\n\n    Usage: module acoustic_forward_module, naming convention\n    \"\"\"\n\n    SENSOR_CONCAVE = \"concave\"\n    \"\"\"\n    Indicates that the geometry of the used PA device in the Mitk Beamforming is concave.\\n\n    Usage: adapter MitkBeamformingAdapter, naming convention\n    \"\"\"\n\n    SENSOR_LINEAR = \"linear\"\n    \"\"\"\n    Indicates that the geometry of the used PA device in the Mitk Beamforming is linear.\\n\n    Usage: adapter MitkBeamformingAdapter, naming convention\n    \"\"\"\n\n    SENSOR_RADIUS_MM = \"sensor_radius_mm\"\n    \"\"\"\n    Radius of a concave geometry of the used PA device.\\n\n    Usage: adapter KWaveAdapter, naming convention\n    \"\"\"\n\n    SENSOR_PITCH_MM = \"sensor_pitch_mm\"\n    \"\"\"\n    Pitch of detector elements of the used PA device.\\n\n    Usage: adapter KWaveAdapter, naming convention\n    \"\"\"\n\n    # Pipelining parameters\n\n    DATA_FIELD = \"data_field\"\n    \"\"\"\n    Defines which data field a certain function shall be applied to.\\n \n    Usage: module core.processing_components\n    \"\"\"\n\n    # Noise properties\n\n    NOISE_SHAPE = \"noise_shape\"\n    \"\"\"\n    Shape of a noise model.\\n \n    Usage: module core.processing_components.noise\n    \"\"\"\n\n    NOISE_SCALE = \"noise_scale\"\n    \"\"\"\n    Scale of a noise model.\\n \n    Usage: module core.processing_components.noise\n    \"\"\"\n\n    NOISE_FREQUENCY = \"noise_frequency\"\n    \"\"\"\n    Frequency of the noise model.\\n \n    Usage: module core.processing_components.noise\n    \"\"\"\n\n    NOISE_MIN = \"noise_min\"\n    \"\"\"\n    Min of a noise model.\\n \n    Usage: module core.processing_components.noise\n    \"\"\"\n\n    NOISE_MAX = \"noise_max\"\n    \"\"\"\n    Max of a noise model.\\n \n    Usage: module core.processing_components.noise\n    \"\"\"\n\n    NOISE_MEAN = \"noise_mean\"\n    \"\"\"\n    Mean of a noise model.\\n \n    Usage: module core.processing_components.noise\n    \"\"\"\n\n    NOISE_STD = \"noise_std\"\n    \"\"\"\n    Standard deviation of a noise model.\\n \n    Usage: module core.processing_components.noise\n    \"\"\"\n\n    NOISE_MODE = \"noise_mode\"\n    \"\"\"\n    The mode tag of a noise model is used to differentiate between\\n\n    Tags.NOISE_MODE_ADDITIVE and Tags.NOISE_MODE_MULTIPLICATIVE.\\n  \n    Usage: module core.processing_components.noise\n    \"\"\"\n\n    NOISE_MODE_ADDITIVE = \"noise_mode_additive\"\n    \"\"\"\n    A noise model shall be applied additively s_n = s + n.\\n  \n    Usage: module core.processing_components.noise\n    \"\"\"\n\n    NOISE_MODE_MULTIPLICATIVE = \"noise_mode_multiplicative\"\n    \"\"\"\n    A noise model shall be applied multiplicatively s_n = s * n.\\n  \n    Usage: module core.processing_components.noise\n    \"\"\"\n\n    NOISE_NON_NEGATIVITY_CONSTRAINT = \"noise_non_negativity_constraint\"\n    \"\"\"\n    Defines if after the noise model negative values shall be allowed.\\n  \n    Usage: module core.processing_components.noise\n    \"\"\"\n\n    VOLUME_CREATION_MODEL_SETTINGS = (\"volume_creation_model_settings\", dict)\n    \"\"\"\"\n    Volume Creation Model Settings\n    \"\"\"\n\n    # Structures\n    STRUCTURES = (\"structures\", dict)\n    \"\"\"\n    Settings dictionary which contains all the structures that should be generated inside the volume.\\n\n    Usage: module volume_creation_module\n    \"\"\"\n\n    CHILD_STRUCTURES = (\"child_structures\", dict)\n    \"\"\"\n    Settings dictionary which contains all the child structures of a parent structure.\\n\n    Usage: module volume_creation_module\n    \"\"\"\n\n    HORIZONTAL_LAYER_STRUCTURE = \"HorizontalLayerStructure\"\n    \"\"\"\n    Corresponds to the HorizontalLayerStructure in the structure_library.\\n\n    Usage: module volume_creation_module, naming_convention\n    \"\"\"\n\n    CIRCULAR_TUBULAR_STRUCTURE = \"CircularTubularStructure\"\n    \"\"\"\n    Corresponds to the CircularTubularStructure in the structure_library.\\n\n    Usage: module volume_creation_module, naming_convention\n    \"\"\"\n\n    ELLIPTICAL_TUBULAR_STRUCTURE = \"EllipticalTubularStructure\"\n    \"\"\"\n    Corresponds to the EllipticalTubularStructure in the structure_library.\\n\n    Usage: module volume_creation_module, naming_convention\n    \"\"\"\n\n    SPHERICAL_STRUCTURE = \"SphericalStructure\"\n    \"\"\"\n    Corresponds to the SphericalStructure in the structure_library.\\n\n    Usage: module volume_creation_module, naming_convention\n    \"\"\"\n\n    PARALLELEPIPED_STRUCTURE = \"ParallelepipedStructure\"\n    \"\"\"\n    Corresponds to the ParallelepipedStructure in the structure_library.\\n\n    Usage: module volume_creation_module, naming_convention\n    \"\"\"\n\n    RECTANGULAR_CUBOID_STRUCTURE = \"RectangularCuboidStructure\"\n    \"\"\"\n    Corresponds to the RectangularCuboidStructure in the structure_library.\\n\n    Usage: module volume_creation_module, naming_convention\n    \"\"\"\n\n    STRUCTURE_TYPE = (\"structure_type\", str)\n    \"\"\"\n    Defines the structure type to one structure in the structure_library.\\n\n    Usage: module volume_creation_module\n    \"\"\"\n\n    STRUCTURE_SEGMENTATION_TYPE = \"structure_segmentation_type\"\n    \"\"\"\n    Defines the structure segmentation type to one segmentation type in SegmentationClasses.\\n\n    Usage: module volume_creation_module, naming convention\n    \"\"\"\n\n    UNITS_ARBITRARY = \"arbitrary_unity\"\n    \"\"\"\n    Define arbitrary units if no units were given in the settings.\\n\n    Usage: module optical_simulation_module, naming convention\n    \"\"\"\n\n    UNITS_PRESSURE = \"newton_per_meters_squared\"\n    \"\"\"\n    Standard units used in the SIMPA framework.\\n\n    Usage: module optical_simulation_module, naming convention\n    \"\"\"\n\n    \"\"\"\n    IO settings\n    \"\"\"\n\n    SIMPA_OUTPUT_PATH = (\"simpa_output_path\", str)\n    \"\"\"\n    Default path of the SIMPA output if not specified otherwise.\\n\n    Usage: SIMPA package\n    \"\"\"\n\n    SIMPA_OUTPUT_NAME = \"simpa_output.hdf5\"\n    \"\"\"\n    Default filename of the SIMPA output if not specified otherwise.\\n\n    Usage: SIMPA package, naming convention\n    \"\"\"\n    SIMPA_VERSION = (\"simpa_version\", str)\n    \"\"\"\n    Version number of the currently installed simpa package\n    Usage: SIMPA package\n    \"\"\"\n\n    SETTINGS = \"settings\"\n    \"\"\"\n    Location of the simulation settings in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    SIMULATION_PROPERTIES = \"simulation_properties\"\n    \"\"\"\n    Location of the simulation properties in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    SIMULATIONS = \"simulations\"\n    \"\"\"\n    Location of the simulation outputs in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    UPSAMPLED_DATA = \"upsampled_data\"\n    \"\"\"\n    Name of the simulation outputs as upsampled data in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    ORIGINAL_DATA = \"original_data\"\n    \"\"\"\n    Name of the simulation outputs as original data in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    \"\"\"\n    Image Processing\n    \"\"\"\n\n    IMAGE_PROCESSING = \"image_processing\"\n    \"\"\"\n    Location of the image algorithms outputs in the SIMPA output file.\\n\n    Usage: naming convention\n    \"\"\"\n\n    ITERATIVE_qPAI_RESULT = \"iterative_qpai_result\"\n    \"\"\"\n    Name of the data field in which the iterative qPAI result will be stored.\\n\n    Usage: naming convention\n    \"\"\"\n\n    LINEAR_UNMIXING_RESULT = \"linear_unmixing_result\"\n    \"\"\"\n    Name of the data field in which the linear unmixing result will be stored.\\n\n    Usage: naming convention\n    \"\"\"\n\n    \"\"\"\n    Iterative qPAI Reconstruction\n    \"\"\"\n\n    ITERATIVE_RECONSTRUCTION_CONSTANT_REGULARIZATION = (\"constant_regularization\", (bool, np.bool_))\n    \"\"\"\n    If True, the fluence regularization will be constant.\\n\n    Usage: module algorithms (iterative_qPAI_algorithm.py)\n    \"\"\"\n\n    DOWNSCALE_FACTOR = (\"downscale_factor\", (int, float, np.int_))\n    \"\"\"\n    Downscale factor of the resampling in the qPAI reconstruction\\n\n    Usage: module algorithms (iterative_qPAI_algorithm.py)\n    \"\"\"\n\n    ITERATIVE_RECONSTRUCTION_MAX_ITERATION_NUMBER = (\"maximum_iteration_number\", (int, np.integer))\n    \"\"\"\n    Maximum number of iterations performed in iterative reconstruction if stopping criterion is not reached.\\n\n    Usage: module algorithms (iterative_qPAI_algorithm.py)\n    \"\"\"\n\n    ITERATIVE_RECONSTRUCTION_REGULARIZATION_SIGMA = (\"regularization_sigma\", Number)\n    \"\"\"\n    Sigma value used for constant regularization of fluence.\\n\n    Usage: module algorithms (iterative_qPAI_algorithm.py)\n    \"\"\"\n\n    ITERATIVE_RECONSTRUCTION_SAVE_INTERMEDIATE_RESULTS = (\"save_intermediate_results\", (bool, np.bool_))\n    \"\"\"\n    If True, a list of all intermediate absorption updates (middle slices only) will be saved in a numpy file.\\n\n    Usage: module algorithms (iterative_qPAI_algorithm.py)\n    \"\"\"\n\n    ITERATIVE_RECONSTRUCTION_SAVE_LAST_FLUENCE = (\"save_last_fluence\", (bool, np.bool_))\n    \"\"\"\n    If True, the last simulated fluence before the stopping criterion will be saved in a numpy file.\\n\n    Usage: module algorithms (iterative_qPAI_algorithm.py)\n    \"\"\"\n\n    ITERATIVE_RECONSTRUCTION_STOPPING_LEVEL = (\"iteration_stopping_level\", Number)\n    \"\"\"\n    Ratio of improvement and preceding error at which iteration method stops. \n    Usage: module algorithms (iterative_qPAI_algorithm.py)\n    \"\"\"\n\n    LINEAR_UNMIXING_NON_NEGATIVE = (\"linear_unmixing_nonnegative\", bool)\n    \"\"\"\n    If True, non-negative linear unmixing is performed which solves the \n    KKT (Karush-Kuhn-Tucker) conditions for the non-negative least squares problem. \\n\n    Usage: module algorithms, linear unmixing\n    \"\"\"\n\n    SIMPA_NAMED_ABSORPTION_SPECTRUM_OXYHEMOGLOBIN = \"Oxyhemoglobin\"\n    \"\"\"\n    Name of the spectrum file for oxyhemoglobin chromophore.\\n\n    Usage: module algorithms, spectra_library, linear_unmixing\n    \"\"\"\n\n    SIMPA_NAMED_ABSORPTION_SPECTRUM_DEOXYHEMOGLOBIN = \"Deoxyhemoglobin\"\n    \"\"\"\n    List of wavelengths used in linear unmixing for deoxyhemoglobin chromophore.\\n\n    Usage: module algorithms (linear_unmixing)\n    \"\"\"\n\n    SIMPA_NAMED_ABSORPTION_SPECTRUM_WATER = \"Water\"\n    \"\"\"\n    List of wavelengths used in linear unmixing for water chromophore.\\n\n    Usage: module algorithms (linear_unmixing)\n    \"\"\"\n\n    SIMPA_NAMED_ABSORPTION_SPECTRUM_FAT = \"Fat\"\n    \"\"\"\n    List of wavelengths used in linear unmixing for fat chromophore.\\n\n    Usage: module algorithms (linear_unmixing)\n    \"\"\"\n\n    SIMPA_NAMED_ABSORPTION_SPECTRUM_MELANIN = \"Melanin\"\n    \"\"\"\n    List of wavelengths used in linear unmixing for melanin chromophore.\\n\n    Usage: module algorithms (linear_unmixing)\n    \"\"\"\n\n    SIMPA_NAMED_ABSORPTION_SPECTRUM_NICKEL_SULPHIDE = \"Nickel_Sulphide\"\n    \"\"\"\n    List of wavelengths used in linear unmixing for nickel sulphide chromophore.\\n\n    Usage: module algorithms (linear_unmixing)\n    \"\"\"\n\n    SIMPA_NAMED_ABSORPTION_SPECTRUM_COPPER_SULPHIDE = \"Copper_Sulphide\"\n    \"\"\"\n    List of wavelengths used in linear unmixing for copper sulphide chromophore.\\n\n    Usage: module algorithms (linear_unmixing)\n    \"\"\"\n\n    LINEAR_UNMIXING_SPECTRA = (\"linear_unmixing_spectra\", list)\n    \"\"\"\n    List of spectra to use for linear unmixing.\\n\n    Usage: module algorithms (linear_unmixing)\n    \"\"\"\n\n    LINEAR_UNMIXING_COMPUTE_SO2 = (\"linear_unmixing_compute_so2\", bool)\n    \"\"\"\n    If True the blood oxygen saturation is calculated and saved. This is only possible \\n\n    if the OXYHEMOGLOBIN and DEOXYHEMOGLOBIN spectra are used.\\n\n    Usage: module algorithms (linear_unmixing)\n    \"\"\"\n\n    SIGNAL_THRESHOLD = (\"linear_unmixing_signal_threshold\", Number)\n    \"\"\"\n    Number that specifies which fraction of the signal intensity is used for the specified processing algorithm.\\n\n    Usage: module algorithms (linear_unmixing)\n    \"\"\"\n\n    DO_IPASC_EXPORT = (\"do_ipasc_export\", (bool, np.bool_))\n    \"\"\"\n    Flag which determines whether the simulated time series data (if available) will be\n    exported into the IPASC data format.\n    Usage: module io_handling, core\n    \"\"\"\n\n    IGNORE_QA_ASSERTIONS = (\"ignore_qa_assertions\", bool)\n    \"\"\"\n    Flag which presents any quality assessment to run during the simulation.\n    False by default. Only set to True if the pipeline is thoroughly tested.\n    Usage: core\n    \"\"\"\n\n    COMPUTE_DIFFUSE_REFLECTANCE = \"save_diffuse_reflectance\"\n    \"\"\"\n    Flag that indicates if the diffuse reflectance should be stored in voxels that are filled with 0 in the surrounding\n    of the volume. \n    Usage: simpa.core.simulation_modules.optical_simulation_module.optical_forward_model_mcx_reflectance_adapter\n    \"\"\"\n\n    COMPUTE_PHOTON_DIRECTION_AT_EXIT = \"save_dir_at_exit\"\n    \"\"\"\n    Flag that indicates if the direction of photons when they exit the volume should be stored\n    Usage: simpa.core.simulation_modules.optical_simulation_module.optical_forward_model_mcx_reflectance_adapter\n    \"\"\"\n\n    DATA_FIELD_DIFFUSE_REFLECTANCE = \"diffuse_reflectance\"\n    \"\"\"\n    Identifier for the diffuse reflectance values at the surface of the volume (interface to 0-values voxels) \n    Usage: simpa.core.simulation_modules.optical_simulation_module.optical_forward_model_mcx_reflectance_adapter\n  \"\"\"\n\n    DATA_FIELD_DIFFUSE_REFLECTANCE_POS = \"diffuse_reflectance_pos\"\n    \"\"\"\n    Identified for the position within the volumes where the diffuse reflectance was originally stored, interface to\n    0-values voxels\n    Usage: simpa.core.simulation_modules.optical_simulation_module.optical_forward_model_mcx_reflectance_adapter\n    \"\"\"\n\n    DATA_FIELD_PHOTON_EXIT_POS = \"photon_exit_pos\"\n    \"\"\"\n    Identifier for the position where photons exit the volume. Currently only photon exiting along the Z axis are\n    detected. \n    Usage: simpa.core.simulation_modules.optical_simulation_module.optical_forward_model_mcx_reflectance_adapter\n    \"\"\"\n\n    DATA_FIELD_PHOTON_EXIT_DIR = \"photon_exit_dir\"\n    \"\"\"\n    Identifier for the direction of photons when they exit the volume. Currently only photon exiting along the Z axis \n    are detected.\n    Usage: simpa.core.simulation_modules.optical_simulation_module.optical_forward_model_mcx_reflectance_adapter\n    \"\"\"",
  "class PathManager:\n    \"\"\"\n    As a pipelining tool that serves as a communication layer between different numerical forward models and\n    processing tools, SIMPA needs to be configured with the paths to these tools on your local hard drive.\n    To this end, we have implemented the `PathManager` class that you can import to your project using\n    `from simpa.utils import PathManager`. The PathManager looks for a `path_config.env` file (just like the\n    one we provided in the `simpa_examples`) in the following places in this order:\n\n        1. The optional path you give the PathManager\n        2. Your $HOME$ directory\n        3. The current working directory\n        4. The SIMPA home directory path\n    \"\"\"\n\n    def __init__(self, environment_path=None):\n        \"\"\"\n\n        :param environment_path: Per default, the config with the environment variables is located in /HOME/path_config.env\n        \"\"\"\n        self.logger = Logger()\n        self.path_config_file_name = 'path_config.env'\n        if environment_path is None:\n            environment_path = os.path.join(str(Path.home()), self.path_config_file_name)\n            self.logger.debug(f\"Using $HOME$ path to search for config file: {environment_path}\")\n            if not os.path.exists(environment_path) or not os.path.isfile(environment_path):\n                self.logger.debug(f\"Did not find path config in $HOME$: {environment_path}\")\n                environment_path = self.detect_local_path_config()\n        else:\n            if not os.path.isfile(environment_path):\n                self.logger.debug(f\"No file was supplied. Assuming a folder was given and looking \"\n                                  f\"for {self.path_config_file_name}\")\n                environment_path = os.path.join(environment_path, self.path_config_file_name)\n            self.logger.debug(f\"Using supplied path to search for config file: {environment_path}\")\n\n        if environment_path is None or not os.path.exists(environment_path) or not os.path.isfile(environment_path):\n            error_message = f\"Did not find a { self.path_config_file_name} file in any of the standard directories...\"\n            self.logger.critical(error_message)\n            raise FileNotFoundError(error_message)\n\n        self.environment_path = environment_path\n        load_dotenv(environment_path, override=True)\n\n    def detect_local_path_config(self):\n        \"\"\"\n        This methods looks in the default local paths for a path_config.env file.\n        \"\"\"\n\n        # Look in current working directory\n        self.logger.debug(\"Searching for path config in current working directory...\")\n        current_working_directory = os.path.join(os.getcwd(), self.path_config_file_name)\n        if os.path.exists(current_working_directory):\n            self.logger.debug(f\"Found {self.path_config_file_name} in current working directory: \"\n                              f\"{current_working_directory}\")\n            return current_working_directory\n\n        # Look in the SIMPA base directory\n        self.logger.debug(\"Searching for path config in SIMPA base directory...\")\n        current_file_path = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n        simpa_home = os.path.join(current_file_path, \"..\", \"..\", self.path_config_file_name)\n\n        if os.path.exists(simpa_home):\n            self.logger.debug(f\"Found {self.path_config_file_name} in current working directory: \"\n                              f\"{simpa_home}\")\n            return simpa_home\n\n        return None\n\n    def get_hdf5_file_save_path(self):\n        path = self.get_path_from_environment('SAVE_PATH')\n        self.logger.debug(f\"Retrieved SAVE_PATH={path}\")\n        return path\n\n    def get_mcx_binary_path(self):\n        path = self.get_path_from_environment('MCX_BINARY_PATH')\n        self.logger.debug(f\"Retrieved MCX_BINARY_PATH={path}\")\n        return path\n\n    def get_matlab_binary_path(self):\n        path = self.get_path_from_environment('MATLAB_BINARY_PATH')\n        self.logger.debug(f\"Retrieved MATLAB_BINARY_PATH={path}\")\n        return path\n\n    def get_path_from_environment(self, env_variable_name):\n        env_variable_content = os.environ.get(env_variable_name)\n        if env_variable_content is None:\n            error_string = f\"The desired environment path variable {env_variable_name} is not available in\"\\\n                f\" the given config path {self.environment_path}\"\n            self.logger.critical(error_string)\n            raise FileNotFoundError(error_string)\n        return env_variable_content",
  "def __init__(self, environment_path=None):\n        \"\"\"\n\n        :param environment_path: Per default, the config with the environment variables is located in /HOME/path_config.env\n        \"\"\"\n        self.logger = Logger()\n        self.path_config_file_name = 'path_config.env'\n        if environment_path is None:\n            environment_path = os.path.join(str(Path.home()), self.path_config_file_name)\n            self.logger.debug(f\"Using $HOME$ path to search for config file: {environment_path}\")\n            if not os.path.exists(environment_path) or not os.path.isfile(environment_path):\n                self.logger.debug(f\"Did not find path config in $HOME$: {environment_path}\")\n                environment_path = self.detect_local_path_config()\n        else:\n            if not os.path.isfile(environment_path):\n                self.logger.debug(f\"No file was supplied. Assuming a folder was given and looking \"\n                                  f\"for {self.path_config_file_name}\")\n                environment_path = os.path.join(environment_path, self.path_config_file_name)\n            self.logger.debug(f\"Using supplied path to search for config file: {environment_path}\")\n\n        if environment_path is None or not os.path.exists(environment_path) or not os.path.isfile(environment_path):\n            error_message = f\"Did not find a { self.path_config_file_name} file in any of the standard directories...\"\n            self.logger.critical(error_message)\n            raise FileNotFoundError(error_message)\n\n        self.environment_path = environment_path\n        load_dotenv(environment_path, override=True)",
  "def detect_local_path_config(self):\n        \"\"\"\n        This methods looks in the default local paths for a path_config.env file.\n        \"\"\"\n\n        # Look in current working directory\n        self.logger.debug(\"Searching for path config in current working directory...\")\n        current_working_directory = os.path.join(os.getcwd(), self.path_config_file_name)\n        if os.path.exists(current_working_directory):\n            self.logger.debug(f\"Found {self.path_config_file_name} in current working directory: \"\n                              f\"{current_working_directory}\")\n            return current_working_directory\n\n        # Look in the SIMPA base directory\n        self.logger.debug(\"Searching for path config in SIMPA base directory...\")\n        current_file_path = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n        simpa_home = os.path.join(current_file_path, \"..\", \"..\", self.path_config_file_name)\n\n        if os.path.exists(simpa_home):\n            self.logger.debug(f\"Found {self.path_config_file_name} in current working directory: \"\n                              f\"{simpa_home}\")\n            return simpa_home\n\n        return None",
  "def get_hdf5_file_save_path(self):\n        path = self.get_path_from_environment('SAVE_PATH')\n        self.logger.debug(f\"Retrieved SAVE_PATH={path}\")\n        return path",
  "def get_mcx_binary_path(self):\n        path = self.get_path_from_environment('MCX_BINARY_PATH')\n        self.logger.debug(f\"Retrieved MCX_BINARY_PATH={path}\")\n        return path",
  "def get_matlab_binary_path(self):\n        path = self.get_path_from_environment('MATLAB_BINARY_PATH')\n        self.logger.debug(f\"Retrieved MATLAB_BINARY_PATH={path}\")\n        return path",
  "def get_path_from_environment(self, env_variable_name):\n        env_variable_content = os.environ.get(env_variable_name)\n        if env_variable_content is None:\n            error_string = f\"The desired environment path variable {env_variable_name} is not available in\"\\\n                f\" the given config path {self.environment_path}\"\n            self.logger.critical(error_string)\n            raise FileNotFoundError(error_string)\n        return env_variable_content",
  "def calculate_oxygenation(molecule_list):\n    \"\"\"\n    :return: an oxygenation value between 0 and 1 if possible, or None, if not computable.\n    \"\"\"\n    hb = None\n    hbO2 = None\n\n    for molecule in molecule_list:\n        if molecule.spectrum.spectrum_name == \"Deoxyhemoglobin\":\n            hb = molecule.volume_fraction\n        if molecule.spectrum.spectrum_name == \"Oxyhemoglobin\":\n            hbO2 = molecule.volume_fraction\n\n    if hb is None and hbO2 is None:\n        return None\n\n    if hb is None:\n        hb = 0\n    elif hbO2 is None:\n        hbO2 = 0\n\n    if hb + hbO2 < 1e-10:  # negative values are not allowed and division by (approx) zero\n        return None        # will lead to negative side effects.\n\n    return hbO2 / (hb + hbO2)",
  "def create_spline_for_range(xmin_mm=0, xmax_mm=10, maximum_y_elevation_mm=1, spacing=0.1):\n    \"\"\"\n    Creates a functional that simulates distortion along the y position\n    between the minimum and maximum x positions. The elevation can never be\n    smaller than 0 or bigger than maximum_y_elevation_mm.\n\n    :param xmin_mm: the minimum x axis value the return functional is defined in\n    :param xmax_mm: the maximum x axis value the return functional is defined in\n    :param maximum_y_elevation_mm: the maximum y axis value the return functional will yield\n    :return: a functional that describes a distortion field along the y axis\n\n    \"\"\"\n    # Convert units from mm spacing to voxel spacing.\n    xmax_voxels = xmax_mm / spacing\n    maximum_y_elevation_mm = -maximum_y_elevation_mm\n\n    # Create initial guesses left and right position\n    left_boundary = np.random.random() * maximum_y_elevation_mm\n    right_boundary = np.random.random() * maximum_y_elevation_mm\n\n    # Define the number of division knots\n    divisions = np.random.randint(1, 5)\n    order = divisions\n    if order > 3:\n        order = 3\n\n    # Create x and y value pairs that should be fit by the spline (needs to be division knots + 2)\n    locations = np.linspace(xmin_mm, xmax_mm, divisions + 1)\n    constraints = np.linspace(left_boundary, right_boundary, divisions + 1)\n\n    # Add random permutations to the y-axis of the division knots\n    for i in range(0, divisions + 1):\n        scaling_value = np.sqrt(2 - ((i - (divisions / 2)) / (divisions / 2)) ** 2)\n\n        constraints[i] = np.random.normal(scaling_value, 0.2) * constraints[i]\n        if constraints[i] < maximum_y_elevation_mm:\n            constraints[i] = maximum_y_elevation_mm\n        if constraints[i] > 0:\n            constraints[i] = 0\n\n    constraints = constraints - np.max(constraints)\n\n    spline = interp1d(locations, constraints, order)\n\n    max_el = np.min(spline(np.arange(0, int(round(xmax_voxels)), 1) * spacing))\n\n    return spline, max_el",
  "def spline_evaluator2d_voxel(x, y, spline, offset_voxel, thickness_voxel):\n    elevation = spline[x]\n    y_value = np.round(elevation + offset_voxel)\n    if y_value <= y < thickness_voxel + y_value:\n        return True\n    else:\n        return False",
  "def calculate_gruneisen_parameter_from_temperature(temperature_in_celcius):\n    \"\"\"\n    This function returns the dimensionless gruneisen parameter based on a heuristic formula that\n    was determined experimentally::\n\n        @book{wang2012biomedical,\n            title={Biomedical optics: principles and imaging},\n            author={Wang, Lihong V and Wu, Hsin-i},\n            year={2012},\n            publisher={John Wiley & Sons}\n        }\n\n    :param temperature_in_celcius: the temperature in degrees celcius\n    :return: a floating point number, if temperature_in_celcius is a number or a float array, if temperature_in_celcius\n        is an array\n\n    \"\"\"\n    return 0.0043 + 0.0053 * temperature_in_celcius",
  "def randomize_uniform(min_value: float, max_value: float):\n    \"\"\"\n    returns a uniformly drawn random number in [min_value, max_value[\n\n    :param min_value: minimum value\n    :param max_value: maximum value\n    :return: random number in [min_value, max_value[\n\n    \"\"\"\n    return (np.random.random() * (max_value-min_value)) + min_value",
  "def rotation_x(theta):\n    \"\"\"\n    Rotation matrix around the x-axis with angle theta.\n\n    :param theta: Angle through which the matrix is supposed to rotate.\n    :return: rotation matrix\n    \"\"\"\n    return np.array([[1, 0, 0],\n                    [0, np.cos(theta), -np.sin(theta)],\n                    [0, np.sin(theta), np.cos(theta)]])",
  "def rotation_y(theta):\n    \"\"\"\n    Rotation matrix around the y-axis with angle theta.\n\n    :param theta: Angle through which the matrix is supposed to rotate.\n    :return: rotation matrix\n    \"\"\"\n    return np.array([[np.cos(theta), 0, np.sin(theta)],\n                    [0, 1, 0],\n                    [-np.sin(theta), 0, np.cos(theta)]])",
  "def rotation_z(theta):\n    \"\"\"\n    Rotation matrix around the z-axis with angle theta.\n\n    :param theta: Angle through which the matrix is supposed to rotate.\n    :return: rotation matrix\n    \"\"\"\n    return np.array([[np.cos(theta), -np.sin(theta), 0],\n                    [np.sin(theta), np.cos(theta), 0],\n                    [0, 0, 1]])",
  "def rotation(angles):\n    \"\"\"\n    Rotation matrix around the x-, y-, and z-axis with angles [theta_x, theta_y, theta_z].\n\n    :param angles: Angles through which the matrix is supposed to rotate in the form of [theta_x, theta_y, theta_z].\n    :return: rotation matrix\n    \"\"\"\n    return rotation_x(angles[0]) * rotation_y(angles[1]) * rotation_z(angles[2])",
  "def rotation_matrix_between_vectors(a, b):\n    \"\"\"\n    Returns the rotation matrix from a to b\n\n    :param a: 3D vector to rotate\n    :param b: 3D target vector\n    :return: rotation matrix\n    \"\"\"\n    a_norm, b_norm = (a / np.linalg.norm(a)).reshape(3), (b / np.linalg.norm(b)).reshape(3)\n    cross_product = np.cross(a_norm, b_norm)\n    if np.abs(cross_product.all()) < 1e-10:\n        return np.zeros([3, 3])\n    dot_product = np.dot(a_norm, b_norm)\n    s = np.linalg.norm(cross_product)\n    mat = np.array([[0, -cross_product[2], cross_product[1]],\n                    [cross_product[2], 0, -cross_product[0]],\n                    [-cross_product[1], cross_product[0], 0]])\n    rotation_matrix = np.eye(3) + mat + mat.dot(mat) * ((1 - dot_product) / (s ** 2))\n    return rotation_matrix",
  "def min_max_normalization(data: np.ndarray = None) -> np.ndarray:\n    \"\"\"\n    Normalizes the given data by applying min max normalization.\n    The resulting array has values between 0 and 1 inclusive.\n\n    :param data: (numpy array) data to be normalized\n    :return: (numpy array) normalized array\n    \"\"\"\n\n    if data is None:\n        raise AttributeError(\"Data must not be none in order to normalize it.\")\n\n    _min = np.min(data)\n    _max = np.max(data)\n    output = (data - _min) / (_max - _min)\n\n    return output",
  "def positive_gauss(mean, std) -> float:\n    \"\"\"\n    Generates a non-negative random sample (scalar) from a normal (Gaussian) distribution.\n\n    :param mean : float defining the mean (\"centre\") of the distribution. \n    :param std: float defining the standard deviation (spread or \"width\") of the distribution. Must be non-negative.\n    :return: non-negative random sample from a normal (Gaussian) distribution.\n    \"\"\"\n    random_value = np.random.normal(mean, std)\n    if random_value <= 0:\n        return positive_gauss(mean, std)\n    else:\n        return random_value",
  "class TissueProperties(dict):\n\n    property_tags = [Tags.DATA_FIELD_ABSORPTION_PER_CM,\n                     Tags.DATA_FIELD_SCATTERING_PER_CM,\n                     Tags.DATA_FIELD_ANISOTROPY,\n                     Tags.DATA_FIELD_GRUNEISEN_PARAMETER,\n                     Tags.DATA_FIELD_SEGMENTATION,\n                     Tags.DATA_FIELD_OXYGENATION,\n                     Tags.DATA_FIELD_DENSITY,\n                     Tags.DATA_FIELD_SPEED_OF_SOUND,\n                     Tags.DATA_FIELD_ALPHA_COEFF]\n\n    def __init__(self):\n        super().__init__()\n        self.volume_fraction = 0\n        for key in TissueProperties.property_tags:\n            self[key] = 0\n\n    @staticmethod\n    def normalized_merge(property_list: list):\n        return_property = TissueProperties.weighted_merge(property_list)\n        for key in return_property.property_tags:\n            return_property[key] = return_property[key] / return_property.volume_fraction\n        return return_property\n\n    @staticmethod\n    def weighted_merge(property_list: list):\n        return_property = TissueProperties()\n        for target_property in property_list:\n            for key in return_property.property_tags:\n                if target_property[key] is not None:\n                    return_property[key] += target_property.volume_fraction * target_property[key]\n            return_property.volume_fraction += target_property.volume_fraction\n        return return_property",
  "def __init__(self):\n        super().__init__()\n        self.volume_fraction = 0\n        for key in TissueProperties.property_tags:\n            self[key] = 0",
  "def normalized_merge(property_list: list):\n        return_property = TissueProperties.weighted_merge(property_list)\n        for key in return_property.property_tags:\n            return_property[key] = return_property[key] / return_property.volume_fraction\n        return return_property",
  "def weighted_merge(property_list: list):\n        return_property = TissueProperties()\n        for target_property in property_list:\n            for key in return_property.property_tags:\n                if target_property[key] is not None:\n                    return_property[key] += target_property.volume_fraction * target_property[key]\n            return_property.volume_fraction += target_property.volume_fraction\n        return return_property",
  "def create_deformation_settings(bounds_mm, maximum_z_elevation_mm=1, filter_sigma=1, cosine_scaling_factor=4):\n    \"\"\"\n    FIXME\n    \"\"\"\n    deformation_settings = dict()\n\n    number_of_boundary_points = np.random.randint(4, 6, size=2)\n    surface_elevations = np.random.random(size=(number_of_boundary_points[0],\n                                                number_of_boundary_points[1]))\n    surface_elevations = gaussian_filter(surface_elevations, sigma=filter_sigma)\n    surface_elevations = surface_elevations / np.max(surface_elevations)\n\n    x_positions_vector = np.linspace(bounds_mm[0][0], bounds_mm[0][1], number_of_boundary_points[0])\n    y_positions_vector = np.linspace(bounds_mm[1][0], bounds_mm[1][1], number_of_boundary_points[1])\n\n    xx, yy = np.meshgrid(x_positions_vector, y_positions_vector, indexing='ij')\n\n    # Add random permutations to the y-axis of the division knots\n    for x_idx, x_position in enumerate(x_positions_vector):\n        for y_idx, y_position in enumerate(y_positions_vector):\n            scaling_value = (np.cos(x_position / (bounds_mm[0][1] * (cosine_scaling_factor / np.pi)) -\n                                    np.pi/(cosine_scaling_factor * 2)) ** 2 *\n                             np.cos(y_position / (bounds_mm[1][1] * (cosine_scaling_factor / np.pi)) -\n                                    np.pi/(cosine_scaling_factor * 2)) ** 2)\n\n            surface_elevations[x_idx, y_idx] = scaling_value * surface_elevations[x_idx, y_idx]\n\n    # This rescales and sets the maximum to 0.\n    surface_elevations = surface_elevations * maximum_z_elevation_mm\n    de_facto_max_elevation = np.max(surface_elevations)\n    surface_elevations = surface_elevations - de_facto_max_elevation\n\n    deformation_settings[Tags.DEFORMATION_X_COORDINATES_MM] = xx\n    deformation_settings[Tags.DEFORMATION_Y_COORDINATES_MM] = yy\n    deformation_settings[Tags.DEFORMATION_Z_ELEVATIONS_MM] = surface_elevations\n    deformation_settings[Tags.MAX_DEFORMATION_MM] = de_facto_max_elevation\n\n    return deformation_settings",
  "def get_functional_from_deformation_settings(deformation_settings: dict):\n    \"\"\"\n    FIXME\n    \"\"\"\n\n    if Tags.DEFORMATION_X_COORDINATES_MM not in deformation_settings:\n        raise KeyError(\"x coordinates not defined in deformation settings\")\n    if Tags.DEFORMATION_Y_COORDINATES_MM not in deformation_settings:\n        raise KeyError(\"y coordinates not defined in deformation settings\")\n    if Tags.DEFORMATION_Z_ELEVATIONS_MM not in deformation_settings:\n        raise KeyError(\"z elevations not defined in deformation settings\")\n\n    x_coordinates_mm = deformation_settings[Tags.DEFORMATION_X_COORDINATES_MM]\n    y_coordinates_mm = deformation_settings[Tags.DEFORMATION_Y_COORDINATES_MM]\n    z_elevations_mm = deformation_settings[Tags.DEFORMATION_Z_ELEVATIONS_MM]\n    order = \"cubic\"\n\n    functional_mm = interp2d(x_coordinates_mm, y_coordinates_mm, z_elevations_mm, kind=order)\n    return functional_mm",
  "class Spectrum(SerializableSIMPAClass, object):\n    \"\"\"\n    An instance of this class represents the absorption spectrum over wavelength for a particular\n    \"\"\"\n\n    def __init__(self, spectrum_name: str, wavelengths: np.ndarray, values: np.ndarray):\n        \"\"\"\n        :param spectrum_name:\n        :param wavelengths:\n        :param values:\n        \"\"\"\n        self.spectrum_name = spectrum_name\n        self.wavelengths = wavelengths\n        self.max_wavelength = int(np.max(wavelengths))\n        self.min_wavelength = int(np.min(wavelengths))\n        self.values = values\n\n        if np.shape(wavelengths) != np.shape(values):\n            raise ValueError(\"The shape of the wavelengths and the absorption coefficients did not match: \" +\n                             str(np.shape(wavelengths)) + \" vs \" + str(np.shape(values)))\n\n        new_wavelengths = np.arange(self.min_wavelength, self.max_wavelength+1, 1)\n        self.new_absorptions = np.interp(new_wavelengths, self.wavelengths, self.values)\n\n    def get_value_over_wavelength(self):\n        \"\"\"\n        :return: numpy array with the available wavelengths and the corresponding absorption properties\n        \"\"\"\n        return np.asarray([self.wavelengths, self.values])\n\n    def get_value_for_wavelength(self, wavelength: int) -> float:\n        \"\"\"\n        :param wavelength: the wavelength to retrieve a optical absorption value for [cm^{-1}].\n                           Must be an integer value between the minimum and maximum wavelength.\n        :return: the best matching linearly interpolated absorption value for the given wavelength.\n        \"\"\"\n        return self.new_absorptions[wavelength-self.min_wavelength]\n\n    def __eq__(self, other):\n        if isinstance(other, Spectrum):\n            return (self.spectrum_name == other.spectrum_name,\n                    self.wavelengths == other.wavelengths,\n                    self.values == other.values)\n        else:\n            return super().__eq__(other)\n\n    def serialize(self) -> dict:\n        serialized_spectrum = self.__dict__\n        return {\"Spectrum\": serialized_spectrum}\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize: dict):\n        deserialized_spectrum = Spectrum(spectrum_name=dictionary_to_deserialize[\"spectrum_name\"],\n                                         wavelengths=dictionary_to_deserialize[\"wavelengths\"],\n                                         values=dictionary_to_deserialize[\"values\"])\n        return deserialized_spectrum",
  "class SpectraLibrary(object):\n\n    def __init__(self, folder_name: str, additional_folder_path: str = None):\n        self.spectra = list()\n        self.add_spectra_from_folder(folder_name)\n        if additional_folder_path is not None:\n            self.add_spectra_from_folder(additional_folder_path)\n\n    def add_spectra_from_folder(self, folder_name):\n        base_path = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n        for absorption_spectrum in glob.glob(os.path.join(base_path, folder_name, \"*.npz\")):\n            name = absorption_spectrum.split(os.path.sep)[-1][:-4]\n            numpy_data = np.load(absorption_spectrum)\n            values = numpy_data[\"values\"]\n            wavelengths = numpy_data[\"wavelengths\"]\n            self.spectra.append(Spectrum(spectrum_name=name, values=values, wavelengths=wavelengths))\n\n    def __next__(self):\n        if self.i > 0:\n            self.i -= 1\n            return self.spectra[self.i]\n        raise StopIteration()\n\n    def __iter__(self):\n        self.i = len(self.spectra)\n        return self\n\n    def get_spectra_names(self):\n        return [spectrum.spectrum_name for spectrum in self]\n\n    def get_spectrum_by_name(self, spectrum_name: str) -> Spectrum:\n        for spectrum in self:\n            if spectrum.spectrum_name == spectrum_name:\n                return spectrum\n\n        raise LookupError(\n            f\"No spectrum for the given name exists ({spectrum_name}). Try one of: {self.get_spectra_names()}\")",
  "class AnisotropySpectrumLibrary(SpectraLibrary):\n\n    def __init__(self, additional_folder_path: str = None):\n        super(AnisotropySpectrumLibrary, self).__init__(\"anisotropy_spectra_data\", additional_folder_path)\n\n    @staticmethod\n    def CONSTANT_ANISOTROPY_ARBITRARY(anisotropy: float = 1):\n        return Spectrum(\"Constant Anisotropy (arb)\", np.asarray([450, 1000]),\n                        np.asarray([anisotropy, anisotropy]))",
  "class ScatteringSpectrumLibrary(SpectraLibrary):\n\n    def __init__(self, additional_folder_path: str = None):\n        super(ScatteringSpectrumLibrary, self).__init__(\"scattering_spectra_data\", additional_folder_path)\n\n    @staticmethod\n    def CONSTANT_SCATTERING_ARBITRARY(scattering: float = 1):\n        return Spectrum(\"Constant Scattering (arb)\", np.asarray([450, 1000]),\n                        np.asarray([scattering, scattering]))\n\n    @staticmethod\n    def scattering_from_rayleigh_and_mie_theory(name: str, mus_at_500_nm: float = 1.0, fraction_rayleigh_scattering: float = 0.0,\n                                                mie_power_law_coefficient: float = 0.0):\n        wavelengths = np.arange(450, 1001, 1)\n        scattering = (mus_at_500_nm * (fraction_rayleigh_scattering * (wavelengths / 500) ** 1e-4 +\n                      (1 - fraction_rayleigh_scattering) * (wavelengths / 500) ** -mie_power_law_coefficient))\n        return Spectrum(name, wavelengths, scattering)",
  "class AbsorptionSpectrumLibrary(SpectraLibrary):\n\n    def __init__(self, additional_folder_path: str = None):\n        super(AbsorptionSpectrumLibrary, self).__init__(\"absorption_spectra_data\", additional_folder_path)\n\n    @staticmethod\n    def CONSTANT_ABSORBER_ARBITRARY(absorption_coefficient: float = 1):\n        return Spectrum(\"Constant Absorber (arb)\", np.asarray([450, 1000]),\n                        np.asarray([absorption_coefficient, absorption_coefficient]))",
  "def get_simpa_internal_absorption_spectra_by_names(absorption_spectrum_names: list):\n    lib = AbsorptionSpectrumLibrary()\n    spectra = []\n    for spectrum_name in absorption_spectrum_names:\n        spectra.append(lib.get_spectrum_by_name(spectrum_name))\n    return spectra",
  "def view_saved_spectra(save_path=None, mode=\"absorption\"):\n    \"\"\"\n    Opens a matplotlib plot and visualizes the available absorption spectra.\n\n    :param save_path: If not None, then the figure will be saved as a png file to the destination.\n    :param mode: string that is \"absorption\", \"scattering\", or \"anisotropy\"\n    \"\"\"\n    plt.figure(figsize=(11, 8))\n    if mode == \"absorption\":\n        for spectrum in AbsorptionSpectrumLibrary():\n            plt.semilogy(spectrum.wavelengths,\n                         spectrum.values,\n                         label=spectrum.spectrum_name)\n    if mode == \"scattering\":\n        for spectrum in ScatteringSpectrumLibrary():\n            plt.semilogy(spectrum.wavelengths,\n                         spectrum.values,\n                         label=spectrum.spectrum_name)\n    if mode == \"anisotropy\":\n        for spectrum in AnisotropySpectrumLibrary():\n            plt.semilogy(spectrum.wavelengths,\n                         spectrum.values,\n                         label=spectrum.spectrum_name)\n    ax = plt.gca()\n    box = ax.get_position()\n    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n    ax.set_ylabel(mode)\n    ax.set_xlabel(\"Wavelength [nm]\")\n    ax.set_title(f\"{mode} spectra for all absorbers present in the library\")\n    # ax.hlines([1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3], 450, 1000, linestyles=\"dashed\", colors=[\"#EEEEEE88\"])\n    ax.legend(loc='best', bbox_to_anchor=(1, 0.5))\n    if save_path is not None:\n        plt.savefig(save_path + f\"{mode}_spectra.png\")\n    plt.show()\n    plt.close()",
  "def __init__(self, spectrum_name: str, wavelengths: np.ndarray, values: np.ndarray):\n        \"\"\"\n        :param spectrum_name:\n        :param wavelengths:\n        :param values:\n        \"\"\"\n        self.spectrum_name = spectrum_name\n        self.wavelengths = wavelengths\n        self.max_wavelength = int(np.max(wavelengths))\n        self.min_wavelength = int(np.min(wavelengths))\n        self.values = values\n\n        if np.shape(wavelengths) != np.shape(values):\n            raise ValueError(\"The shape of the wavelengths and the absorption coefficients did not match: \" +\n                             str(np.shape(wavelengths)) + \" vs \" + str(np.shape(values)))\n\n        new_wavelengths = np.arange(self.min_wavelength, self.max_wavelength+1, 1)\n        self.new_absorptions = np.interp(new_wavelengths, self.wavelengths, self.values)",
  "def get_value_over_wavelength(self):\n        \"\"\"\n        :return: numpy array with the available wavelengths and the corresponding absorption properties\n        \"\"\"\n        return np.asarray([self.wavelengths, self.values])",
  "def get_value_for_wavelength(self, wavelength: int) -> float:\n        \"\"\"\n        :param wavelength: the wavelength to retrieve a optical absorption value for [cm^{-1}].\n                           Must be an integer value between the minimum and maximum wavelength.\n        :return: the best matching linearly interpolated absorption value for the given wavelength.\n        \"\"\"\n        return self.new_absorptions[wavelength-self.min_wavelength]",
  "def __eq__(self, other):\n        if isinstance(other, Spectrum):\n            return (self.spectrum_name == other.spectrum_name,\n                    self.wavelengths == other.wavelengths,\n                    self.values == other.values)\n        else:\n            return super().__eq__(other)",
  "def serialize(self) -> dict:\n        serialized_spectrum = self.__dict__\n        return {\"Spectrum\": serialized_spectrum}",
  "def deserialize(dictionary_to_deserialize: dict):\n        deserialized_spectrum = Spectrum(spectrum_name=dictionary_to_deserialize[\"spectrum_name\"],\n                                         wavelengths=dictionary_to_deserialize[\"wavelengths\"],\n                                         values=dictionary_to_deserialize[\"values\"])\n        return deserialized_spectrum",
  "def __init__(self, folder_name: str, additional_folder_path: str = None):\n        self.spectra = list()\n        self.add_spectra_from_folder(folder_name)\n        if additional_folder_path is not None:\n            self.add_spectra_from_folder(additional_folder_path)",
  "def add_spectra_from_folder(self, folder_name):\n        base_path = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n        for absorption_spectrum in glob.glob(os.path.join(base_path, folder_name, \"*.npz\")):\n            name = absorption_spectrum.split(os.path.sep)[-1][:-4]\n            numpy_data = np.load(absorption_spectrum)\n            values = numpy_data[\"values\"]\n            wavelengths = numpy_data[\"wavelengths\"]\n            self.spectra.append(Spectrum(spectrum_name=name, values=values, wavelengths=wavelengths))",
  "def __next__(self):\n        if self.i > 0:\n            self.i -= 1\n            return self.spectra[self.i]\n        raise StopIteration()",
  "def __iter__(self):\n        self.i = len(self.spectra)\n        return self",
  "def get_spectra_names(self):\n        return [spectrum.spectrum_name for spectrum in self]",
  "def get_spectrum_by_name(self, spectrum_name: str) -> Spectrum:\n        for spectrum in self:\n            if spectrum.spectrum_name == spectrum_name:\n                return spectrum\n\n        raise LookupError(\n            f\"No spectrum for the given name exists ({spectrum_name}). Try one of: {self.get_spectra_names()}\")",
  "def __init__(self, additional_folder_path: str = None):\n        super(AnisotropySpectrumLibrary, self).__init__(\"anisotropy_spectra_data\", additional_folder_path)",
  "def CONSTANT_ANISOTROPY_ARBITRARY(anisotropy: float = 1):\n        return Spectrum(\"Constant Anisotropy (arb)\", np.asarray([450, 1000]),\n                        np.asarray([anisotropy, anisotropy]))",
  "def __init__(self, additional_folder_path: str = None):\n        super(ScatteringSpectrumLibrary, self).__init__(\"scattering_spectra_data\", additional_folder_path)",
  "def CONSTANT_SCATTERING_ARBITRARY(scattering: float = 1):\n        return Spectrum(\"Constant Scattering (arb)\", np.asarray([450, 1000]),\n                        np.asarray([scattering, scattering]))",
  "def scattering_from_rayleigh_and_mie_theory(name: str, mus_at_500_nm: float = 1.0, fraction_rayleigh_scattering: float = 0.0,\n                                                mie_power_law_coefficient: float = 0.0):\n        wavelengths = np.arange(450, 1001, 1)\n        scattering = (mus_at_500_nm * (fraction_rayleigh_scattering * (wavelengths / 500) ** 1e-4 +\n                      (1 - fraction_rayleigh_scattering) * (wavelengths / 500) ** -mie_power_law_coefficient))\n        return Spectrum(name, wavelengths, scattering)",
  "def __init__(self, additional_folder_path: str = None):\n        super(AbsorptionSpectrumLibrary, self).__init__(\"absorption_spectra_data\", additional_folder_path)",
  "def CONSTANT_ABSORBER_ARBITRARY(absorption_coefficient: float = 1):\n        return Spectrum(\"Constant Absorber (arb)\", np.asarray([450, 1000]),\n                        np.asarray([absorption_coefficient, absorption_coefficient]))",
  "class TissueLibrary(object):\n    \"\"\"\n    TODO\n    \"\"\"\n\n    def get_blood_volume_fractions(self, total_blood_volume_fraction=1e-10, oxygenation=1e-10):\n        \"\"\"\n        TODO\n        \"\"\"\n        return [total_blood_volume_fraction*oxygenation, total_blood_volume_fraction*(1-oxygenation)]\n\n    def constant(self, mua=1e-10, mus=1e-10, g=1e-10):\n        \"\"\"\n        TODO\n        \"\"\"\n        return (MolecularCompositionGenerator().append(Molecule(name=\"constant_mua_mus_g\",\n                                                                absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(mua),\n                                                                volume_fraction=1.0,\n                                                                scattering_spectrum=ScatteringSpectrumLibrary.\n                                                                CONSTANT_SCATTERING_ARBITRARY(mus),\n                                                                anisotropy_spectrum=AnisotropySpectrumLibrary.\n                                                                CONSTANT_ANISOTROPY_ARBITRARY(g)))\n                .get_molecular_composition(SegmentationClasses.GENERIC))\n\n    def muscle(self, background_oxy=None, blood_volume_fraction=None):\n        \"\"\"\n\n        :return: a settings dictionary containing all min and max parameters fitting for muscle tissue.\n        \"\"\"\n\n        # Determine muscle oxygenation\n        if background_oxy is None:\n            oxy = 0.175\n        else:\n            oxy = background_oxy\n\n        # Get the blood volume fractions for oxyhemoglobin and deoxyhemoglobin\n        if blood_volume_fraction is None:\n            bvf = 0.06\n        else:\n            bvf = blood_volume_fraction\n\n        [fraction_oxy, fraction_deoxy] = self.get_blood_volume_fractions(bvf, oxy)\n\n        # Get the water volume fraction\n        water_volume_fraction = OpticalTissueProperties.WATER_VOLUME_FRACTION_HUMAN_BODY\n\n        custom_water = MOLECULE_LIBRARY.water(water_volume_fraction)\n        custom_water.anisotropy_spectrum = AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n            OpticalTissueProperties.STANDARD_ANISOTROPY - 0.005)\n        custom_water.alpha_coefficient = 1.58\n        custom_water.speed_of_sound = StandardProperties.SPEED_OF_SOUND_MUSCLE + 16\n        custom_water.density = StandardProperties.DENSITY_MUSCLE + 41\n        custom_water.mus500 = OpticalTissueProperties.MUS500_MUSCLE_TISSUE\n        custom_water.b_mie = OpticalTissueProperties.BMIE_MUSCLE_TISSUE\n        custom_water.f_ray = OpticalTissueProperties.FRAY_MUSCLE_TISSUE\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.oxyhemoglobin(fraction_oxy))\n                .append(MOLECULE_LIBRARY.deoxyhemoglobin(fraction_deoxy))\n                .append(value=MOLECULE_LIBRARY.muscle_scatterer(\n                        volume_fraction=1 - fraction_oxy - fraction_deoxy - water_volume_fraction),\n                        key=\"muscle_scatterers\")\n                .append(custom_water)\n                .get_molecular_composition(SegmentationClasses.MUSCLE))\n\n    def soft_tissue(self, background_oxy=None, blood_volume_fraction=None):\n        \"\"\"\n        IMPORTANT! This tissue is not tested and it is not based on a specific real tissue type.\n        It is a mixture of muscle (mostly optical properties) and water (mostly acoustic properties).\n        This tissue type roughly resembles the generic background tissue that we see in real PA images.\n        :return: a settings dictionary containing all min and max parameters fitting for generic soft tissue.\n        \"\"\"\n\n        # Determine muscle oxygenation\n        if background_oxy is None:\n            oxy = OpticalTissueProperties.BACKGROUND_OXYGENATION\n        else:\n            oxy = background_oxy\n\n        # Get the blood volume fractions for oxyhemoglobin and deoxyhemoglobin\n        if blood_volume_fraction is None:\n            bvf = OpticalTissueProperties.BLOOD_VOLUME_FRACTION_MUSCLE_TISSUE\n        else:\n            bvf = blood_volume_fraction\n\n        [fraction_oxy, fraction_deoxy] = self.get_blood_volume_fractions(bvf, oxy)\n\n        # Get the water volume fraction\n        water_volume_fraction = OpticalTissueProperties.WATER_VOLUME_FRACTION_HUMAN_BODY\n\n        custom_water = MOLECULE_LIBRARY.water(water_volume_fraction)\n        custom_water.anisotropy_spectrum = AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n            OpticalTissueProperties.STANDARD_ANISOTROPY - 0.005)\n        custom_water.alpha_coefficient = 0.08\n        custom_water.speed_of_sound = StandardProperties.SPEED_OF_SOUND_WATER\n        custom_water.density = StandardProperties.DENSITY_WATER\n        custom_water.mus500 = OpticalTissueProperties.MUS500_MUSCLE_TISSUE\n        custom_water.b_mie = OpticalTissueProperties.BMIE_MUSCLE_TISSUE\n        custom_water.f_ray = OpticalTissueProperties.FRAY_MUSCLE_TISSUE\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.oxyhemoglobin(fraction_oxy))\n                .append(MOLECULE_LIBRARY.deoxyhemoglobin(fraction_deoxy))\n                .append(value=MOLECULE_LIBRARY.muscle_scatterer(\n                        volume_fraction=1 - fraction_oxy - fraction_deoxy - water_volume_fraction),\n                        key=\"muscle_scatterers\")\n                .append(custom_water)\n                .get_molecular_composition(SegmentationClasses.SOFT_TISSUE))\n\n    def epidermis(self, melanosom_volume_fraction=None):\n        \"\"\"\n\n        :return: a settings dictionary containing all min and max parameters fitting for epidermis tissue.\n        \"\"\"\n\n        # Get melanin volume fraction\n        if melanosom_volume_fraction is None:\n            melanin_volume_fraction = 0.014\n        else:\n            melanin_volume_fraction = melanosom_volume_fraction\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.melanin(melanin_volume_fraction))\n                .append(MOLECULE_LIBRARY.epidermal_scatterer(1 - melanin_volume_fraction))\n                .get_molecular_composition(SegmentationClasses.EPIDERMIS))\n\n    def dermis(self, background_oxy=None, blood_volume_fraction=None):\n        \"\"\"\n\n        :return: a settings dictionary containing all min and max parameters fitting for dermis tissue.\n        \"\"\"\n\n        # Determine muscle oxygenation\n        if background_oxy is None:\n            oxy = 0.5\n        else:\n            oxy = background_oxy\n\n        if blood_volume_fraction is None:\n            bvf = 0.002\n        else:\n            bvf = blood_volume_fraction\n\n        # Get the bloood volume fractions for oxyhemoglobin and deoxyhemoglobin\n        [fraction_oxy, fraction_deoxy] = self.get_blood_volume_fractions(bvf, oxy)\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.oxyhemoglobin(fraction_oxy))\n                .append(MOLECULE_LIBRARY.deoxyhemoglobin(fraction_deoxy))\n                .append(MOLECULE_LIBRARY.dermal_scatterer(1.0 - bvf))\n                .get_molecular_composition(SegmentationClasses.DERMIS))\n\n    def subcutaneous_fat(self, oxy=OpticalTissueProperties.BACKGROUND_OXYGENATION):\n        \"\"\"\n\n        :return: a settings dictionary containing all min and max parameters fitting for subcutaneous fat tissue.\n        \"\"\"\n\n        # Get water volume fraction\n        water_volume_fraction = OpticalTissueProperties.WATER_VOLUME_FRACTION_HUMAN_BODY\n\n        # Get the bloood volume fractions for oxyhemoglobin and deoxyhemoglobin\n        [fraction_oxy, fraction_deoxy] = self.get_blood_volume_fractions(\n            OpticalTissueProperties.BLOOD_VOLUME_FRACTION_MUSCLE_TISSUE, oxy)\n\n        # Determine fat volume fraction\n        fat_volume_fraction = randomize_uniform(0.2, 1 - (water_volume_fraction + fraction_oxy + fraction_deoxy))\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.oxyhemoglobin(fraction_oxy))\n                .append(MOLECULE_LIBRARY.deoxyhemoglobin(fraction_deoxy))\n                .append(MOLECULE_LIBRARY.fat(fat_volume_fraction))\n                .append(MOLECULE_LIBRARY.soft_tissue_scatterer(\n                        1 - (fat_volume_fraction + water_volume_fraction + fraction_oxy + fraction_deoxy)))\n                .append(MOLECULE_LIBRARY.water(water_volume_fraction))\n                .get_molecular_composition(SegmentationClasses.FAT))\n\n    def blood(self, oxygenation=None):\n        \"\"\"\n\n        :return: a settings dictionary containing all min and max parameters fitting for full blood.\n        \"\"\"\n\n        # Get the bloood volume fractions for oxyhemoglobin and deoxyhemoglobin\n        if oxygenation is None:\n            oxygenation = randomize_uniform(0.0, 1.0)\n\n        [fraction_oxy, fraction_deoxy] = self.get_blood_volume_fractions(1.0, oxygenation)\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.oxyhemoglobin(fraction_oxy))\n                .append(MOLECULE_LIBRARY.deoxyhemoglobin(fraction_deoxy))\n                .get_molecular_composition(SegmentationClasses.BLOOD))\n\n    def bone(self):\n        \"\"\"\n\n            :return: a settings dictionary containing all min and max parameters fitting for full blood.\n            \"\"\"\n        # Get water volume fraction\n        water_volume_fraction = randomize_uniform(OpticalTissueProperties.WATER_VOLUME_FRACTION_BONE_MEAN -\n                                                  OpticalTissueProperties.WATER_VOLUME_FRACTION_BONE_STD,\n                                                  OpticalTissueProperties.WATER_VOLUME_FRACTION_BONE_MEAN +\n                                                  OpticalTissueProperties.WATER_VOLUME_FRACTION_BONE_STD\n                                                  )\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.bone(1 - water_volume_fraction))\n                .append(MOLECULE_LIBRARY.water(water_volume_fraction))\n                .get_molecular_composition(SegmentationClasses.BONE))\n\n    def mediprene(self):\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.mediprene())\n                .get_molecular_composition(SegmentationClasses.MEDIPRENE))\n\n    def heavy_water(self):\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.heavy_water())\n                .get_molecular_composition(SegmentationClasses.HEAVY_WATER))\n\n    def ultrasound_gel(self):\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.water())\n                .get_molecular_composition(SegmentationClasses.ULTRASOUND_GEL))\n\n    def lymph_node(self, oxy=None, blood_volume_fraction=None):\n        \"\"\"\n        IMPORTANT! This tissue is not tested and it is not based on a specific real tissue type.\n        It is a mixture of oxyhemoglobin, deoxyhemoglobin, and lymph node customized water.\n        :return: a settings dictionary fitting for generic lymph node tissue.\n        \"\"\"\n\n        # Determine muscle oxygenation\n        if oxy is None:\n            oxy = OpticalTissueProperties.LYMPH_NODE_OXYGENATION\n\n        # Get the blood volume fractions for oxyhemoglobin and deoxyhemoglobin\n        if blood_volume_fraction is None:\n            blood_volume_fraction = OpticalTissueProperties.BLOOD_VOLUME_FRACTION_LYMPH_NODE\n\n        [fraction_oxy, fraction_deoxy] = self.get_blood_volume_fractions(blood_volume_fraction, oxy)\n\n        # Get the water volume fraction\n        # water_volume_fraction = OpticalTissueProperties.WATER_VOLUME_FRACTION_HUMAN_BODY\n\n        lymphatic_fluid = MOLECULE_LIBRARY.water(1 - fraction_deoxy - fraction_oxy)\n        lymphatic_fluid.speed_of_sound = StandardProperties.SPEED_OF_SOUND_LYMPH_NODE + 1.22\n        lymphatic_fluid.density = StandardProperties.DENSITY_LYMPH_NODE - 2.30\n        lymphatic_fluid.alpha_coefficient = StandardProperties.ALPHA_COEFF_LYMPH_NODE + 0.36\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.oxyhemoglobin(fraction_oxy))\n                .append(MOLECULE_LIBRARY.deoxyhemoglobin(fraction_deoxy))\n                .append(lymphatic_fluid)\n                .get_molecular_composition(SegmentationClasses.LYMPH_NODE))",
  "def get_blood_volume_fractions(self, total_blood_volume_fraction=1e-10, oxygenation=1e-10):\n        \"\"\"\n        TODO\n        \"\"\"\n        return [total_blood_volume_fraction*oxygenation, total_blood_volume_fraction*(1-oxygenation)]",
  "def constant(self, mua=1e-10, mus=1e-10, g=1e-10):\n        \"\"\"\n        TODO\n        \"\"\"\n        return (MolecularCompositionGenerator().append(Molecule(name=\"constant_mua_mus_g\",\n                                                                absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(mua),\n                                                                volume_fraction=1.0,\n                                                                scattering_spectrum=ScatteringSpectrumLibrary.\n                                                                CONSTANT_SCATTERING_ARBITRARY(mus),\n                                                                anisotropy_spectrum=AnisotropySpectrumLibrary.\n                                                                CONSTANT_ANISOTROPY_ARBITRARY(g)))\n                .get_molecular_composition(SegmentationClasses.GENERIC))",
  "def muscle(self, background_oxy=None, blood_volume_fraction=None):\n        \"\"\"\n\n        :return: a settings dictionary containing all min and max parameters fitting for muscle tissue.\n        \"\"\"\n\n        # Determine muscle oxygenation\n        if background_oxy is None:\n            oxy = 0.175\n        else:\n            oxy = background_oxy\n\n        # Get the blood volume fractions for oxyhemoglobin and deoxyhemoglobin\n        if blood_volume_fraction is None:\n            bvf = 0.06\n        else:\n            bvf = blood_volume_fraction\n\n        [fraction_oxy, fraction_deoxy] = self.get_blood_volume_fractions(bvf, oxy)\n\n        # Get the water volume fraction\n        water_volume_fraction = OpticalTissueProperties.WATER_VOLUME_FRACTION_HUMAN_BODY\n\n        custom_water = MOLECULE_LIBRARY.water(water_volume_fraction)\n        custom_water.anisotropy_spectrum = AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n            OpticalTissueProperties.STANDARD_ANISOTROPY - 0.005)\n        custom_water.alpha_coefficient = 1.58\n        custom_water.speed_of_sound = StandardProperties.SPEED_OF_SOUND_MUSCLE + 16\n        custom_water.density = StandardProperties.DENSITY_MUSCLE + 41\n        custom_water.mus500 = OpticalTissueProperties.MUS500_MUSCLE_TISSUE\n        custom_water.b_mie = OpticalTissueProperties.BMIE_MUSCLE_TISSUE\n        custom_water.f_ray = OpticalTissueProperties.FRAY_MUSCLE_TISSUE\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.oxyhemoglobin(fraction_oxy))\n                .append(MOLECULE_LIBRARY.deoxyhemoglobin(fraction_deoxy))\n                .append(value=MOLECULE_LIBRARY.muscle_scatterer(\n                        volume_fraction=1 - fraction_oxy - fraction_deoxy - water_volume_fraction),\n                        key=\"muscle_scatterers\")\n                .append(custom_water)\n                .get_molecular_composition(SegmentationClasses.MUSCLE))",
  "def soft_tissue(self, background_oxy=None, blood_volume_fraction=None):\n        \"\"\"\n        IMPORTANT! This tissue is not tested and it is not based on a specific real tissue type.\n        It is a mixture of muscle (mostly optical properties) and water (mostly acoustic properties).\n        This tissue type roughly resembles the generic background tissue that we see in real PA images.\n        :return: a settings dictionary containing all min and max parameters fitting for generic soft tissue.\n        \"\"\"\n\n        # Determine muscle oxygenation\n        if background_oxy is None:\n            oxy = OpticalTissueProperties.BACKGROUND_OXYGENATION\n        else:\n            oxy = background_oxy\n\n        # Get the blood volume fractions for oxyhemoglobin and deoxyhemoglobin\n        if blood_volume_fraction is None:\n            bvf = OpticalTissueProperties.BLOOD_VOLUME_FRACTION_MUSCLE_TISSUE\n        else:\n            bvf = blood_volume_fraction\n\n        [fraction_oxy, fraction_deoxy] = self.get_blood_volume_fractions(bvf, oxy)\n\n        # Get the water volume fraction\n        water_volume_fraction = OpticalTissueProperties.WATER_VOLUME_FRACTION_HUMAN_BODY\n\n        custom_water = MOLECULE_LIBRARY.water(water_volume_fraction)\n        custom_water.anisotropy_spectrum = AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n            OpticalTissueProperties.STANDARD_ANISOTROPY - 0.005)\n        custom_water.alpha_coefficient = 0.08\n        custom_water.speed_of_sound = StandardProperties.SPEED_OF_SOUND_WATER\n        custom_water.density = StandardProperties.DENSITY_WATER\n        custom_water.mus500 = OpticalTissueProperties.MUS500_MUSCLE_TISSUE\n        custom_water.b_mie = OpticalTissueProperties.BMIE_MUSCLE_TISSUE\n        custom_water.f_ray = OpticalTissueProperties.FRAY_MUSCLE_TISSUE\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.oxyhemoglobin(fraction_oxy))\n                .append(MOLECULE_LIBRARY.deoxyhemoglobin(fraction_deoxy))\n                .append(value=MOLECULE_LIBRARY.muscle_scatterer(\n                        volume_fraction=1 - fraction_oxy - fraction_deoxy - water_volume_fraction),\n                        key=\"muscle_scatterers\")\n                .append(custom_water)\n                .get_molecular_composition(SegmentationClasses.SOFT_TISSUE))",
  "def epidermis(self, melanosom_volume_fraction=None):\n        \"\"\"\n\n        :return: a settings dictionary containing all min and max parameters fitting for epidermis tissue.\n        \"\"\"\n\n        # Get melanin volume fraction\n        if melanosom_volume_fraction is None:\n            melanin_volume_fraction = 0.014\n        else:\n            melanin_volume_fraction = melanosom_volume_fraction\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.melanin(melanin_volume_fraction))\n                .append(MOLECULE_LIBRARY.epidermal_scatterer(1 - melanin_volume_fraction))\n                .get_molecular_composition(SegmentationClasses.EPIDERMIS))",
  "def dermis(self, background_oxy=None, blood_volume_fraction=None):\n        \"\"\"\n\n        :return: a settings dictionary containing all min and max parameters fitting for dermis tissue.\n        \"\"\"\n\n        # Determine muscle oxygenation\n        if background_oxy is None:\n            oxy = 0.5\n        else:\n            oxy = background_oxy\n\n        if blood_volume_fraction is None:\n            bvf = 0.002\n        else:\n            bvf = blood_volume_fraction\n\n        # Get the bloood volume fractions for oxyhemoglobin and deoxyhemoglobin\n        [fraction_oxy, fraction_deoxy] = self.get_blood_volume_fractions(bvf, oxy)\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.oxyhemoglobin(fraction_oxy))\n                .append(MOLECULE_LIBRARY.deoxyhemoglobin(fraction_deoxy))\n                .append(MOLECULE_LIBRARY.dermal_scatterer(1.0 - bvf))\n                .get_molecular_composition(SegmentationClasses.DERMIS))",
  "def subcutaneous_fat(self, oxy=OpticalTissueProperties.BACKGROUND_OXYGENATION):\n        \"\"\"\n\n        :return: a settings dictionary containing all min and max parameters fitting for subcutaneous fat tissue.\n        \"\"\"\n\n        # Get water volume fraction\n        water_volume_fraction = OpticalTissueProperties.WATER_VOLUME_FRACTION_HUMAN_BODY\n\n        # Get the bloood volume fractions for oxyhemoglobin and deoxyhemoglobin\n        [fraction_oxy, fraction_deoxy] = self.get_blood_volume_fractions(\n            OpticalTissueProperties.BLOOD_VOLUME_FRACTION_MUSCLE_TISSUE, oxy)\n\n        # Determine fat volume fraction\n        fat_volume_fraction = randomize_uniform(0.2, 1 - (water_volume_fraction + fraction_oxy + fraction_deoxy))\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.oxyhemoglobin(fraction_oxy))\n                .append(MOLECULE_LIBRARY.deoxyhemoglobin(fraction_deoxy))\n                .append(MOLECULE_LIBRARY.fat(fat_volume_fraction))\n                .append(MOLECULE_LIBRARY.soft_tissue_scatterer(\n                        1 - (fat_volume_fraction + water_volume_fraction + fraction_oxy + fraction_deoxy)))\n                .append(MOLECULE_LIBRARY.water(water_volume_fraction))\n                .get_molecular_composition(SegmentationClasses.FAT))",
  "def blood(self, oxygenation=None):\n        \"\"\"\n\n        :return: a settings dictionary containing all min and max parameters fitting for full blood.\n        \"\"\"\n\n        # Get the bloood volume fractions for oxyhemoglobin and deoxyhemoglobin\n        if oxygenation is None:\n            oxygenation = randomize_uniform(0.0, 1.0)\n\n        [fraction_oxy, fraction_deoxy] = self.get_blood_volume_fractions(1.0, oxygenation)\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.oxyhemoglobin(fraction_oxy))\n                .append(MOLECULE_LIBRARY.deoxyhemoglobin(fraction_deoxy))\n                .get_molecular_composition(SegmentationClasses.BLOOD))",
  "def bone(self):\n        \"\"\"\n\n            :return: a settings dictionary containing all min and max parameters fitting for full blood.\n            \"\"\"\n        # Get water volume fraction\n        water_volume_fraction = randomize_uniform(OpticalTissueProperties.WATER_VOLUME_FRACTION_BONE_MEAN -\n                                                  OpticalTissueProperties.WATER_VOLUME_FRACTION_BONE_STD,\n                                                  OpticalTissueProperties.WATER_VOLUME_FRACTION_BONE_MEAN +\n                                                  OpticalTissueProperties.WATER_VOLUME_FRACTION_BONE_STD\n                                                  )\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.bone(1 - water_volume_fraction))\n                .append(MOLECULE_LIBRARY.water(water_volume_fraction))\n                .get_molecular_composition(SegmentationClasses.BONE))",
  "def mediprene(self):\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.mediprene())\n                .get_molecular_composition(SegmentationClasses.MEDIPRENE))",
  "def heavy_water(self):\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.heavy_water())\n                .get_molecular_composition(SegmentationClasses.HEAVY_WATER))",
  "def ultrasound_gel(self):\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.water())\n                .get_molecular_composition(SegmentationClasses.ULTRASOUND_GEL))",
  "def lymph_node(self, oxy=None, blood_volume_fraction=None):\n        \"\"\"\n        IMPORTANT! This tissue is not tested and it is not based on a specific real tissue type.\n        It is a mixture of oxyhemoglobin, deoxyhemoglobin, and lymph node customized water.\n        :return: a settings dictionary fitting for generic lymph node tissue.\n        \"\"\"\n\n        # Determine muscle oxygenation\n        if oxy is None:\n            oxy = OpticalTissueProperties.LYMPH_NODE_OXYGENATION\n\n        # Get the blood volume fractions for oxyhemoglobin and deoxyhemoglobin\n        if blood_volume_fraction is None:\n            blood_volume_fraction = OpticalTissueProperties.BLOOD_VOLUME_FRACTION_LYMPH_NODE\n\n        [fraction_oxy, fraction_deoxy] = self.get_blood_volume_fractions(blood_volume_fraction, oxy)\n\n        # Get the water volume fraction\n        # water_volume_fraction = OpticalTissueProperties.WATER_VOLUME_FRACTION_HUMAN_BODY\n\n        lymphatic_fluid = MOLECULE_LIBRARY.water(1 - fraction_deoxy - fraction_oxy)\n        lymphatic_fluid.speed_of_sound = StandardProperties.SPEED_OF_SOUND_LYMPH_NODE + 1.22\n        lymphatic_fluid.density = StandardProperties.DENSITY_LYMPH_NODE - 2.30\n        lymphatic_fluid.alpha_coefficient = StandardProperties.ALPHA_COEFF_LYMPH_NODE + 0.36\n\n        # generate the tissue dictionary\n        return (MolecularCompositionGenerator()\n                .append(MOLECULE_LIBRARY.oxyhemoglobin(fraction_oxy))\n                .append(MOLECULE_LIBRARY.deoxyhemoglobin(fraction_deoxy))\n                .append(lymphatic_fluid)\n                .get_molecular_composition(SegmentationClasses.LYMPH_NODE))",
  "class MolecularComposition(SerializableSIMPAClass, list):\n\n    def __init__(self, segmentation_type=None, molecular_composition_settings=None):\n        super().__init__()\n        self.segmentation_type = segmentation_type\n        self.internal_properties = TissueProperties()\n\n        if molecular_composition_settings is None:\n            return\n\n        _keys = molecular_composition_settings.keys()\n        for molecule_name in _keys:\n            self.append(molecular_composition_settings[molecule_name])\n\n    def update_internal_properties(self):\n        \"\"\"\n        FIXME\n        \"\"\"\n        self.internal_properties = TissueProperties()\n        self.internal_properties[Tags.DATA_FIELD_SEGMENTATION] = self.segmentation_type\n        self.internal_properties[Tags.DATA_FIELD_OXYGENATION] = calculate_oxygenation(self)\n        for molecule in self:\n            self.internal_properties.volume_fraction += molecule.volume_fraction\n            self.internal_properties[Tags.DATA_FIELD_GRUNEISEN_PARAMETER] += \\\n                molecule.volume_fraction * molecule.gruneisen_parameter\n            self.internal_properties[Tags.DATA_FIELD_DENSITY] += molecule.volume_fraction * molecule.density\n            self.internal_properties[Tags.DATA_FIELD_SPEED_OF_SOUND] += molecule.volume_fraction * \\\n                molecule.speed_of_sound\n            self.internal_properties[Tags.DATA_FIELD_ALPHA_COEFF] += molecule.volume_fraction * \\\n                molecule.alpha_coefficient\n\n        if np.abs(self.internal_properties.volume_fraction - 1.0) > 1e-3:\n            raise AssertionError(\"Invalid Molecular composition! The volume fractions of all molecules must be\"\n                                 \"exactly 100%!\")\n\n    def get_properties_for_wavelength(self, wavelength) -> TissueProperties:\n\n        self.update_internal_properties()\n        self.internal_properties[Tags.DATA_FIELD_ABSORPTION_PER_CM] = 0\n        self.internal_properties[Tags.DATA_FIELD_SCATTERING_PER_CM] = 0\n        self.internal_properties[Tags.DATA_FIELD_ANISOTROPY] = 0\n\n        for molecule in self:\n            self.internal_properties[Tags.DATA_FIELD_ABSORPTION_PER_CM] += \\\n                (molecule.volume_fraction * molecule.spectrum.get_value_for_wavelength(wavelength))\n\n            self.internal_properties[Tags.DATA_FIELD_SCATTERING_PER_CM] += \\\n                (molecule.volume_fraction * (molecule.scattering_spectrum.get_value_for_wavelength(wavelength)))\n\n            self.internal_properties[Tags.DATA_FIELD_ANISOTROPY] += \\\n                molecule.volume_fraction * molecule.anisotropy_spectrum.get_value_for_wavelength(wavelength)\n\n        return self.internal_properties\n\n    def serialize(self) -> dict:\n        dict_items = self.__dict__\n        list_items = [molecule for molecule in self]\n        return {\"MolecularComposition\": {\"dict_items\": dict_items, \"list_items\": list_items}}\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize: dict):\n        deserialized_molecular_composition = MolecularCompositionGenerator()\n        for molecule in dictionary_to_deserialize[\"list_items\"]:\n            deserialized_molecular_composition.append(molecule)\n        deserialized_molecular_composition = deserialized_molecular_composition.get_molecular_composition(\n            dictionary_to_deserialize[\"dict_items\"][\"segmentation_type\"]\n        )\n        return deserialized_molecular_composition",
  "class Molecule(SerializableSIMPAClass, object):\n\n    def __init__(self, name: str = None,\n                 absorption_spectrum: Spectrum = None,\n                 volume_fraction: float = None,\n                 scattering_spectrum: Spectrum = None,\n                 anisotropy_spectrum: Spectrum = None, gruneisen_parameter: float = None,\n                 density: float = None, speed_of_sound: float = None,\n                 alpha_coefficient: float = None):\n        \"\"\"\n        :param name: str\n        :param absorption_spectrum: Spectrum\n        :param volume_fraction: float\n        :param scattering_spectrum: Spectrum\n        :param anisotropy_spectrum: Spectrum\n        :param gruneisen_parameter: float\n        :param density: float\n        :param speed_of_sound: float\n        :param alpha_coefficient: float\n        \"\"\"\n        if name is None:\n            name = \"GenericMoleculeName\"\n        if not isinstance(name, str):\n            if isinstance(name, bytes):\n                name = name.decode(\"utf-8\")\n            else:\n                raise TypeError(\"Molecule name must be of type str or bytes instead of {}!\".format(type(name)))\n        self.name = name\n\n        if absorption_spectrum is None:\n            absorption_spectrum = AbsorptionSpectrumLibrary.CONSTANT_ABSORBER_ZERO\n        if isinstance(absorption_spectrum, dict):\n            absorption_spectrum = absorption_spectrum[list(absorption_spectrum.keys())[0]]\n        if not isinstance(absorption_spectrum, Spectrum):\n            raise TypeError(f\"The given spectrum was not of type AbsorptionSpectrum! Instead: \"\n                            f\"{type(absorption_spectrum)} and reads: {absorption_spectrum}\")\n        self.spectrum = absorption_spectrum\n\n        if volume_fraction is None:\n            volume_fraction = 0.0\n        if not isinstance(volume_fraction, (int, float, np.int64)):\n            raise TypeError(f\"The given volume_fraction was not of type float instead of {type(volume_fraction)}!\")\n        self.volume_fraction = volume_fraction\n\n        if scattering_spectrum is None:\n            scattering_spectrum = ScatteringSpectrumLibrary.CONSTANT_SCATTERING_ARBITRARY(1e-15)\n        if not isinstance(scattering_spectrum, Spectrum):\n            raise TypeError(f\"The given scattering_spectrum was not of type Spectrum instead of \"\n                            f\"{type(scattering_spectrum)}!\")\n        self.scattering_spectrum = scattering_spectrum\n\n        if anisotropy_spectrum is None:\n            anisotropy_spectrum = 0.0\n        if not isinstance(anisotropy_spectrum, Spectrum):\n            raise TypeError(f\"The given anisotropy was not of type Spectrum instead of {type(anisotropy_spectrum)}!\")\n        self.anisotropy_spectrum = anisotropy_spectrum\n\n        if gruneisen_parameter is None:\n            gruneisen_parameter = calculate_gruneisen_parameter_from_temperature(\n                StandardProperties.BODY_TEMPERATURE_CELCIUS)\n        if not isinstance(gruneisen_parameter, (int, float)):\n            raise TypeError(f\"The given gruneisen_parameter was not of type int or float instead \"\n                            f\"of {type(gruneisen_parameter)}!\")\n        self.gruneisen_parameter = gruneisen_parameter\n\n        if density is None:\n            density = StandardProperties.DENSITY_GENERIC\n        if not isinstance(density, (np.int32, np.int64, int, float)):\n            raise TypeError(f\"The given density was not of type int or float instead of {type(density)}!\")\n        self.density = density\n\n        if speed_of_sound is None:\n            speed_of_sound = StandardProperties.SPEED_OF_SOUND_GENERIC\n        if not isinstance(speed_of_sound, (np.int32, np.int64, int, float)):\n            raise TypeError(\"The given speed_of_sound was not of type int or float instead of {}!\"\n                            .format(type(speed_of_sound)))\n        self.speed_of_sound = speed_of_sound\n\n        if alpha_coefficient is None:\n            alpha_coefficient = StandardProperties.ALPHA_COEFF_GENERIC\n        if not isinstance(alpha_coefficient, (int, float)):\n            raise TypeError(\"The given alpha_coefficient was not of type int or float instead of {}!\"\n                            .format(type(alpha_coefficient)))\n        self.alpha_coefficient = alpha_coefficient\n\n    def __eq__(self, other):\n        if isinstance(other, Molecule):\n            return (self.name == other.name and\n                    self.spectrum == other.spectrum and\n                    self.volume_fraction == other.volume_fraction and\n                    self.scattering_spectrum == other.scattering_spectrum and\n                    self.alpha_coefficient == other.alpha_coefficient and\n                    self.speed_of_sound == other.speed_of_sound and\n                    self.gruneisen_parameter == other.gruneisen_parameter and\n                    self.anisotropy_spectrum == other.anisotropy_spectrum and\n                    self.density == other.density\n                    )\n        else:\n            return super().__eq__(other)\n\n    def serialize(self):\n        serialized_molecule = self.__dict__\n        return {\"Molecule\": serialized_molecule}\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize: dict):\n        deserialized_molecule = Molecule(name=dictionary_to_deserialize[\"name\"],\n                                         absorption_spectrum=dictionary_to_deserialize[\"spectrum\"],\n                                         volume_fraction=dictionary_to_deserialize[\"volume_fraction\"],\n                                         scattering_spectrum=dictionary_to_deserialize[\"scattering_spectrum\"],\n                                         alpha_coefficient=dictionary_to_deserialize[\"alpha_coefficient\"],\n                                         speed_of_sound=dictionary_to_deserialize[\"speed_of_sound\"],\n                                         gruneisen_parameter=dictionary_to_deserialize[\"gruneisen_parameter\"],\n                                         anisotropy_spectrum=dictionary_to_deserialize[\"anisotropy_spectrum\"],\n                                         density=dictionary_to_deserialize[\"density\"])\n        return deserialized_molecule",
  "class MoleculeLibrary(object):\n\n    # Main absorbers\n    @staticmethod\n    def water(volume_fraction: float = 1.0):\n        return Molecule(name=\"water\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().get_spectrum_by_name(\"Water\"),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.CONSTANT_SCATTERING_ARBITRARY(\n                            StandardProperties.WATER_MUS),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            StandardProperties.WATER_G),\n                        density=StandardProperties.DENSITY_WATER,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_WATER,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_WATER\n                        )\n\n    @staticmethod\n    def oxyhemoglobin(volume_fraction: float = 1.0):\n        return Molecule(name=\"oxyhemoglobin\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().get_spectrum_by_name(\"Oxyhemoglobin\"),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary().get_spectrum_by_name(\"blood_scattering\"),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.BLOOD_ANISOTROPY),\n                        density=StandardProperties.DENSITY_BLOOD,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_BLOOD,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_BLOOD\n                        )\n\n    @staticmethod\n    def deoxyhemoglobin(volume_fraction: float = 1.0):\n        return Molecule(name=\"deoxyhemoglobin\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().get_spectrum_by_name(\"Deoxyhemoglobin\"),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary().get_spectrum_by_name(\"blood_scattering\"),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.BLOOD_ANISOTROPY),\n                        density=StandardProperties.DENSITY_BLOOD,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_BLOOD,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_BLOOD\n                        )\n\n    @staticmethod\n    def melanin(volume_fraction: float = 1.0):\n        return Molecule(name=\"melanin\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().get_spectrum_by_name(\"Melanin\"),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.scattering_from_rayleigh_and_mie_theory(\n                            \"epidermis\", OpticalTissueProperties.MUS500_EPIDERMIS, OpticalTissueProperties.FRAY_EPIDERMIS,\n                            OpticalTissueProperties.BMIE_EPIDERMIS),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary().get_spectrum_by_name(\"Epidermis_Anisotropy\"),\n                        density=StandardProperties.DENSITY_SKIN,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_SKIN,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_SKIN\n                        )\n\n    @staticmethod\n    def fat(volume_fraction: float = 1.0):\n        return Molecule(name=\"fat\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().get_spectrum_by_name(\"Fat\"),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary().get_spectrum_by_name(\"fat_scattering\"),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.STANDARD_ANISOTROPY),\n                        density=StandardProperties.DENSITY_FAT,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_FAT,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_FAT\n                        )\n\n    # Scatterers\n    @staticmethod\n    def constant_scatterer(scattering_coefficient: float = 100.0, anisotropy: float = 0.9,\n                           volume_fraction: float = 1.0):\n        return Molecule(name=\"constant_scatterer\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(1e-20),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.CONSTANT_SCATTERING_ARBITRARY(\n                            scattering_coefficient),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(anisotropy),\n                        density=StandardProperties.DENSITY_GENERIC,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_GENERIC,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_GENERIC\n                        )\n\n    @staticmethod\n    def soft_tissue_scatterer(volume_fraction: float = 1.0):\n        return Molecule(name=\"soft_tissue_scatterer\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(1e-20),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary().get_spectrum_by_name(\"background_scattering\"),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.STANDARD_ANISOTROPY),\n                        density=StandardProperties.DENSITY_GENERIC,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_GENERIC,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_GENERIC\n                        )\n\n    @staticmethod\n    def muscle_scatterer(volume_fraction: float = 1.0):\n        return Molecule(name=\"muscle_scatterer\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(1e-20),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary().get_spectrum_by_name(\"muscle_scattering\"),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.STANDARD_ANISOTROPY),\n                        density=StandardProperties.DENSITY_GENERIC,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_GENERIC,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_GENERIC\n                        )\n\n    @staticmethod\n    def epidermal_scatterer(volume_fraction: float = 1.0):\n        return Molecule(name=\"epidermal_scatterer\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(1e-20),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.scattering_from_rayleigh_and_mie_theory(\n                            \"epidermis\", OpticalTissueProperties.MUS500_EPIDERMIS, OpticalTissueProperties.FRAY_EPIDERMIS,\n                            OpticalTissueProperties.BMIE_EPIDERMIS),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary().get_spectrum_by_name(\"Epidermis_Anisotropy\"),\n                        density=StandardProperties.DENSITY_SKIN,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_SKIN,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_SKIN\n                        )\n\n    @staticmethod\n    def dermal_scatterer(volume_fraction: float = 1.0):\n        return Molecule(name=\"dermal_scatterer\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().get_spectrum_by_name(\"Skin_Baseline\"),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.scattering_from_rayleigh_and_mie_theory(\n                            \"dermis\", OpticalTissueProperties.MUS500_DERMIS, OpticalTissueProperties.FRAY_DERMIS,\n                            OpticalTissueProperties.BMIE_DERMIS),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.DERMIS_ANISOTROPY),\n                        density=StandardProperties.DENSITY_SKIN,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_SKIN,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_SKIN\n                        )\n\n    @staticmethod\n    def bone(volume_fraction: float = 1.0):\n        return Molecule(name=\"bone\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(\n                            OpticalTissueProperties.BONE_ABSORPTION),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary().get_spectrum_by_name(\"bone_scattering\"),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.STANDARD_ANISOTROPY),\n                        density=StandardProperties.DENSITY_BONE,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_BONE,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_BONE\n                        )\n\n    @staticmethod\n    def mediprene(volume_fraction: float = 1.0):\n        return Molecule(name=\"mediprene\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(-np.log(0.85) / 10),  # FIXME\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.CONSTANT_SCATTERING_ARBITRARY((-np.log(0.85)) -\n                                                                                                    (-np.log(0.85) / 10)),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(0.9),\n                        density=StandardProperties.DENSITY_GEL_PAD,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_GEL_PAD,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_GEL_PAD\n                        )\n\n    @staticmethod\n    def heavy_water(volume_fraction: float = 1.0):\n        return Molecule(name=\"heavy_water\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(\n                            StandardProperties.HEAVY_WATER_MUA),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.CONSTANT_SCATTERING_ARBITRARY(\n                            StandardProperties.WATER_MUS),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            StandardProperties.WATER_G),\n                        density=StandardProperties.DENSITY_HEAVY_WATER,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_HEAVY_WATER,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_WATER\n                        )\n\n    @staticmethod\n    def air(volume_fraction: float = 1.0):\n        return Molecule(name=\"air\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(\n                            StandardProperties.AIR_MUA),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.CONSTANT_SCATTERING_ARBITRARY(\n                            StandardProperties.AIR_MUS),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            StandardProperties.AIR_G),\n                        density=StandardProperties.DENSITY_AIR,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_AIR,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_AIR\n                        )",
  "class MolecularCompositionGenerator(object):\n    \"\"\"\n    The MolecularCompositionGenerator is a helper class to facilitate the creation of a\n    MolecularComposition instance.\n    \"\"\"\n\n    def __init__(self):\n        self.molecular_composition_dictionary = dict()\n\n    def append(self, value: Molecule = None, key: str = None):\n        if key is None:\n            key = value.name\n        if key in self.molecular_composition_dictionary:\n            raise KeyError(key + \" already in the molecular composition!\")\n        self.molecular_composition_dictionary[key] = value\n        return self\n\n    def get_molecular_composition(self, segmentation_type):\n        return MolecularComposition(segmentation_type=segmentation_type,\n                                    molecular_composition_settings=self.molecular_composition_dictionary)",
  "def __init__(self, segmentation_type=None, molecular_composition_settings=None):\n        super().__init__()\n        self.segmentation_type = segmentation_type\n        self.internal_properties = TissueProperties()\n\n        if molecular_composition_settings is None:\n            return\n\n        _keys = molecular_composition_settings.keys()\n        for molecule_name in _keys:\n            self.append(molecular_composition_settings[molecule_name])",
  "def update_internal_properties(self):\n        \"\"\"\n        FIXME\n        \"\"\"\n        self.internal_properties = TissueProperties()\n        self.internal_properties[Tags.DATA_FIELD_SEGMENTATION] = self.segmentation_type\n        self.internal_properties[Tags.DATA_FIELD_OXYGENATION] = calculate_oxygenation(self)\n        for molecule in self:\n            self.internal_properties.volume_fraction += molecule.volume_fraction\n            self.internal_properties[Tags.DATA_FIELD_GRUNEISEN_PARAMETER] += \\\n                molecule.volume_fraction * molecule.gruneisen_parameter\n            self.internal_properties[Tags.DATA_FIELD_DENSITY] += molecule.volume_fraction * molecule.density\n            self.internal_properties[Tags.DATA_FIELD_SPEED_OF_SOUND] += molecule.volume_fraction * \\\n                molecule.speed_of_sound\n            self.internal_properties[Tags.DATA_FIELD_ALPHA_COEFF] += molecule.volume_fraction * \\\n                molecule.alpha_coefficient\n\n        if np.abs(self.internal_properties.volume_fraction - 1.0) > 1e-3:\n            raise AssertionError(\"Invalid Molecular composition! The volume fractions of all molecules must be\"\n                                 \"exactly 100%!\")",
  "def get_properties_for_wavelength(self, wavelength) -> TissueProperties:\n\n        self.update_internal_properties()\n        self.internal_properties[Tags.DATA_FIELD_ABSORPTION_PER_CM] = 0\n        self.internal_properties[Tags.DATA_FIELD_SCATTERING_PER_CM] = 0\n        self.internal_properties[Tags.DATA_FIELD_ANISOTROPY] = 0\n\n        for molecule in self:\n            self.internal_properties[Tags.DATA_FIELD_ABSORPTION_PER_CM] += \\\n                (molecule.volume_fraction * molecule.spectrum.get_value_for_wavelength(wavelength))\n\n            self.internal_properties[Tags.DATA_FIELD_SCATTERING_PER_CM] += \\\n                (molecule.volume_fraction * (molecule.scattering_spectrum.get_value_for_wavelength(wavelength)))\n\n            self.internal_properties[Tags.DATA_FIELD_ANISOTROPY] += \\\n                molecule.volume_fraction * molecule.anisotropy_spectrum.get_value_for_wavelength(wavelength)\n\n        return self.internal_properties",
  "def serialize(self) -> dict:\n        dict_items = self.__dict__\n        list_items = [molecule for molecule in self]\n        return {\"MolecularComposition\": {\"dict_items\": dict_items, \"list_items\": list_items}}",
  "def deserialize(dictionary_to_deserialize: dict):\n        deserialized_molecular_composition = MolecularCompositionGenerator()\n        for molecule in dictionary_to_deserialize[\"list_items\"]:\n            deserialized_molecular_composition.append(molecule)\n        deserialized_molecular_composition = deserialized_molecular_composition.get_molecular_composition(\n            dictionary_to_deserialize[\"dict_items\"][\"segmentation_type\"]\n        )\n        return deserialized_molecular_composition",
  "def __init__(self, name: str = None,\n                 absorption_spectrum: Spectrum = None,\n                 volume_fraction: float = None,\n                 scattering_spectrum: Spectrum = None,\n                 anisotropy_spectrum: Spectrum = None, gruneisen_parameter: float = None,\n                 density: float = None, speed_of_sound: float = None,\n                 alpha_coefficient: float = None):\n        \"\"\"\n        :param name: str\n        :param absorption_spectrum: Spectrum\n        :param volume_fraction: float\n        :param scattering_spectrum: Spectrum\n        :param anisotropy_spectrum: Spectrum\n        :param gruneisen_parameter: float\n        :param density: float\n        :param speed_of_sound: float\n        :param alpha_coefficient: float\n        \"\"\"\n        if name is None:\n            name = \"GenericMoleculeName\"\n        if not isinstance(name, str):\n            if isinstance(name, bytes):\n                name = name.decode(\"utf-8\")\n            else:\n                raise TypeError(\"Molecule name must be of type str or bytes instead of {}!\".format(type(name)))\n        self.name = name\n\n        if absorption_spectrum is None:\n            absorption_spectrum = AbsorptionSpectrumLibrary.CONSTANT_ABSORBER_ZERO\n        if isinstance(absorption_spectrum, dict):\n            absorption_spectrum = absorption_spectrum[list(absorption_spectrum.keys())[0]]\n        if not isinstance(absorption_spectrum, Spectrum):\n            raise TypeError(f\"The given spectrum was not of type AbsorptionSpectrum! Instead: \"\n                            f\"{type(absorption_spectrum)} and reads: {absorption_spectrum}\")\n        self.spectrum = absorption_spectrum\n\n        if volume_fraction is None:\n            volume_fraction = 0.0\n        if not isinstance(volume_fraction, (int, float, np.int64)):\n            raise TypeError(f\"The given volume_fraction was not of type float instead of {type(volume_fraction)}!\")\n        self.volume_fraction = volume_fraction\n\n        if scattering_spectrum is None:\n            scattering_spectrum = ScatteringSpectrumLibrary.CONSTANT_SCATTERING_ARBITRARY(1e-15)\n        if not isinstance(scattering_spectrum, Spectrum):\n            raise TypeError(f\"The given scattering_spectrum was not of type Spectrum instead of \"\n                            f\"{type(scattering_spectrum)}!\")\n        self.scattering_spectrum = scattering_spectrum\n\n        if anisotropy_spectrum is None:\n            anisotropy_spectrum = 0.0\n        if not isinstance(anisotropy_spectrum, Spectrum):\n            raise TypeError(f\"The given anisotropy was not of type Spectrum instead of {type(anisotropy_spectrum)}!\")\n        self.anisotropy_spectrum = anisotropy_spectrum\n\n        if gruneisen_parameter is None:\n            gruneisen_parameter = calculate_gruneisen_parameter_from_temperature(\n                StandardProperties.BODY_TEMPERATURE_CELCIUS)\n        if not isinstance(gruneisen_parameter, (int, float)):\n            raise TypeError(f\"The given gruneisen_parameter was not of type int or float instead \"\n                            f\"of {type(gruneisen_parameter)}!\")\n        self.gruneisen_parameter = gruneisen_parameter\n\n        if density is None:\n            density = StandardProperties.DENSITY_GENERIC\n        if not isinstance(density, (np.int32, np.int64, int, float)):\n            raise TypeError(f\"The given density was not of type int or float instead of {type(density)}!\")\n        self.density = density\n\n        if speed_of_sound is None:\n            speed_of_sound = StandardProperties.SPEED_OF_SOUND_GENERIC\n        if not isinstance(speed_of_sound, (np.int32, np.int64, int, float)):\n            raise TypeError(\"The given speed_of_sound was not of type int or float instead of {}!\"\n                            .format(type(speed_of_sound)))\n        self.speed_of_sound = speed_of_sound\n\n        if alpha_coefficient is None:\n            alpha_coefficient = StandardProperties.ALPHA_COEFF_GENERIC\n        if not isinstance(alpha_coefficient, (int, float)):\n            raise TypeError(\"The given alpha_coefficient was not of type int or float instead of {}!\"\n                            .format(type(alpha_coefficient)))\n        self.alpha_coefficient = alpha_coefficient",
  "def __eq__(self, other):\n        if isinstance(other, Molecule):\n            return (self.name == other.name and\n                    self.spectrum == other.spectrum and\n                    self.volume_fraction == other.volume_fraction and\n                    self.scattering_spectrum == other.scattering_spectrum and\n                    self.alpha_coefficient == other.alpha_coefficient and\n                    self.speed_of_sound == other.speed_of_sound and\n                    self.gruneisen_parameter == other.gruneisen_parameter and\n                    self.anisotropy_spectrum == other.anisotropy_spectrum and\n                    self.density == other.density\n                    )\n        else:\n            return super().__eq__(other)",
  "def serialize(self):\n        serialized_molecule = self.__dict__\n        return {\"Molecule\": serialized_molecule}",
  "def deserialize(dictionary_to_deserialize: dict):\n        deserialized_molecule = Molecule(name=dictionary_to_deserialize[\"name\"],\n                                         absorption_spectrum=dictionary_to_deserialize[\"spectrum\"],\n                                         volume_fraction=dictionary_to_deserialize[\"volume_fraction\"],\n                                         scattering_spectrum=dictionary_to_deserialize[\"scattering_spectrum\"],\n                                         alpha_coefficient=dictionary_to_deserialize[\"alpha_coefficient\"],\n                                         speed_of_sound=dictionary_to_deserialize[\"speed_of_sound\"],\n                                         gruneisen_parameter=dictionary_to_deserialize[\"gruneisen_parameter\"],\n                                         anisotropy_spectrum=dictionary_to_deserialize[\"anisotropy_spectrum\"],\n                                         density=dictionary_to_deserialize[\"density\"])\n        return deserialized_molecule",
  "def water(volume_fraction: float = 1.0):\n        return Molecule(name=\"water\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().get_spectrum_by_name(\"Water\"),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.CONSTANT_SCATTERING_ARBITRARY(\n                            StandardProperties.WATER_MUS),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            StandardProperties.WATER_G),\n                        density=StandardProperties.DENSITY_WATER,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_WATER,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_WATER\n                        )",
  "def oxyhemoglobin(volume_fraction: float = 1.0):\n        return Molecule(name=\"oxyhemoglobin\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().get_spectrum_by_name(\"Oxyhemoglobin\"),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary().get_spectrum_by_name(\"blood_scattering\"),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.BLOOD_ANISOTROPY),\n                        density=StandardProperties.DENSITY_BLOOD,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_BLOOD,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_BLOOD\n                        )",
  "def deoxyhemoglobin(volume_fraction: float = 1.0):\n        return Molecule(name=\"deoxyhemoglobin\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().get_spectrum_by_name(\"Deoxyhemoglobin\"),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary().get_spectrum_by_name(\"blood_scattering\"),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.BLOOD_ANISOTROPY),\n                        density=StandardProperties.DENSITY_BLOOD,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_BLOOD,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_BLOOD\n                        )",
  "def melanin(volume_fraction: float = 1.0):\n        return Molecule(name=\"melanin\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().get_spectrum_by_name(\"Melanin\"),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.scattering_from_rayleigh_and_mie_theory(\n                            \"epidermis\", OpticalTissueProperties.MUS500_EPIDERMIS, OpticalTissueProperties.FRAY_EPIDERMIS,\n                            OpticalTissueProperties.BMIE_EPIDERMIS),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary().get_spectrum_by_name(\"Epidermis_Anisotropy\"),\n                        density=StandardProperties.DENSITY_SKIN,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_SKIN,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_SKIN\n                        )",
  "def fat(volume_fraction: float = 1.0):\n        return Molecule(name=\"fat\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().get_spectrum_by_name(\"Fat\"),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary().get_spectrum_by_name(\"fat_scattering\"),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.STANDARD_ANISOTROPY),\n                        density=StandardProperties.DENSITY_FAT,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_FAT,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_FAT\n                        )",
  "def constant_scatterer(scattering_coefficient: float = 100.0, anisotropy: float = 0.9,\n                           volume_fraction: float = 1.0):\n        return Molecule(name=\"constant_scatterer\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(1e-20),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.CONSTANT_SCATTERING_ARBITRARY(\n                            scattering_coefficient),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(anisotropy),\n                        density=StandardProperties.DENSITY_GENERIC,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_GENERIC,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_GENERIC\n                        )",
  "def soft_tissue_scatterer(volume_fraction: float = 1.0):\n        return Molecule(name=\"soft_tissue_scatterer\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(1e-20),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary().get_spectrum_by_name(\"background_scattering\"),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.STANDARD_ANISOTROPY),\n                        density=StandardProperties.DENSITY_GENERIC,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_GENERIC,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_GENERIC\n                        )",
  "def muscle_scatterer(volume_fraction: float = 1.0):\n        return Molecule(name=\"muscle_scatterer\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(1e-20),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary().get_spectrum_by_name(\"muscle_scattering\"),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.STANDARD_ANISOTROPY),\n                        density=StandardProperties.DENSITY_GENERIC,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_GENERIC,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_GENERIC\n                        )",
  "def epidermal_scatterer(volume_fraction: float = 1.0):\n        return Molecule(name=\"epidermal_scatterer\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(1e-20),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.scattering_from_rayleigh_and_mie_theory(\n                            \"epidermis\", OpticalTissueProperties.MUS500_EPIDERMIS, OpticalTissueProperties.FRAY_EPIDERMIS,\n                            OpticalTissueProperties.BMIE_EPIDERMIS),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary().get_spectrum_by_name(\"Epidermis_Anisotropy\"),\n                        density=StandardProperties.DENSITY_SKIN,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_SKIN,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_SKIN\n                        )",
  "def dermal_scatterer(volume_fraction: float = 1.0):\n        return Molecule(name=\"dermal_scatterer\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().get_spectrum_by_name(\"Skin_Baseline\"),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.scattering_from_rayleigh_and_mie_theory(\n                            \"dermis\", OpticalTissueProperties.MUS500_DERMIS, OpticalTissueProperties.FRAY_DERMIS,\n                            OpticalTissueProperties.BMIE_DERMIS),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.DERMIS_ANISOTROPY),\n                        density=StandardProperties.DENSITY_SKIN,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_SKIN,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_SKIN\n                        )",
  "def bone(volume_fraction: float = 1.0):\n        return Molecule(name=\"bone\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(\n                            OpticalTissueProperties.BONE_ABSORPTION),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary().get_spectrum_by_name(\"bone_scattering\"),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            OpticalTissueProperties.STANDARD_ANISOTROPY),\n                        density=StandardProperties.DENSITY_BONE,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_BONE,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_BONE\n                        )",
  "def mediprene(volume_fraction: float = 1.0):\n        return Molecule(name=\"mediprene\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(-np.log(0.85) / 10),  # FIXME\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.CONSTANT_SCATTERING_ARBITRARY((-np.log(0.85)) -\n                                                                                                    (-np.log(0.85) / 10)),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(0.9),\n                        density=StandardProperties.DENSITY_GEL_PAD,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_GEL_PAD,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_GEL_PAD\n                        )",
  "def heavy_water(volume_fraction: float = 1.0):\n        return Molecule(name=\"heavy_water\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(\n                            StandardProperties.HEAVY_WATER_MUA),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.CONSTANT_SCATTERING_ARBITRARY(\n                            StandardProperties.WATER_MUS),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            StandardProperties.WATER_G),\n                        density=StandardProperties.DENSITY_HEAVY_WATER,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_HEAVY_WATER,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_WATER\n                        )",
  "def air(volume_fraction: float = 1.0):\n        return Molecule(name=\"air\",\n                        absorption_spectrum=AbsorptionSpectrumLibrary().CONSTANT_ABSORBER_ARBITRARY(\n                            StandardProperties.AIR_MUA),\n                        volume_fraction=volume_fraction,\n                        scattering_spectrum=ScatteringSpectrumLibrary.CONSTANT_SCATTERING_ARBITRARY(\n                            StandardProperties.AIR_MUS),\n                        anisotropy_spectrum=AnisotropySpectrumLibrary.CONSTANT_ANISOTROPY_ARBITRARY(\n                            StandardProperties.AIR_G),\n                        density=StandardProperties.DENSITY_AIR,\n                        speed_of_sound=StandardProperties.SPEED_OF_SOUND_AIR,\n                        alpha_coefficient=StandardProperties.ALPHA_COEFF_AIR\n                        )",
  "def __init__(self):\n        self.molecular_composition_dictionary = dict()",
  "def append(self, value: Molecule = None, key: str = None):\n        if key is None:\n            key = value.name\n        if key in self.molecular_composition_dictionary:\n            raise KeyError(key + \" already in the molecular composition!\")\n        self.molecular_composition_dictionary[key] = value\n        return self",
  "def get_molecular_composition(self, segmentation_type):\n        return MolecularComposition(segmentation_type=segmentation_type,\n                                    molecular_composition_settings=self.molecular_composition_dictionary)",
  "class StandardProperties:\n    \"\"\"\n    This class contains a listing of default parameters that can be used.\n    These values are sensible default values but are generally not backed up by proper scientific references,\n    or are rather specific for internal use cases.\n    \"\"\"\n    AIR_MUA = 1e-10\n    AIR_MUS = 1e-10\n    AIR_G = 1.0\n    GELPAD_MUA = 1e-10\n    GELPAD_MUS = 1e-10\n    GELPAD_G = 1.0\n\n    # @article{Zhang:09,\n    # author = {Xiaodong Zhang and Lianbo Hu and Ming-Xia He},\n    # journal = {Opt. Express},\n    # number = {7},\n    # pages = {5698--5710},\n    # publisher = {OSA},\n    # title = {Scattering by pure seawater: Effect of salinity},\n    # volume = {17},\n    # month = {Mar},\n    # year = {2009},\n    # doi = {10.1364/OE.17.005698},\n    # and https://www.oceanopticsbook.info/view/optical-constituents-of-the-ocean/water\n    WATER_MUS = 1e-10\n    WATER_G = 1.0\n\n    # @article{Kedenburg:12,\n    # author = {S. Kedenburg and M. Vieweg and T. Gissibl and H. Giessen},\n    # journal = {Opt. Mater. Express},\n    # number = {11},\n    # pages = {1588--1611},\n    # publisher = {OSA},\n    # title = {Linear refractive index and absorption measurements of nonlinear optical liquids in the visible and near-infrared spectral region},\n    # volume = {2},\n    # month = {Nov},\n    # year = {2012},\n    # url = {http://www.osapublishing.org/ome/abstract.cfm?URI=ome-2-11-1588},\n    # doi = {10.1364/OME.2.001588},\n\n    HEAVY_WATER_MUA = 0.0008\n\n    # @book{marx2013rosen,\n    #   title={Rosen's Emergency Medicine-Concepts and Clinical Practice E-Book},\n    #   author={Marx, John and Walls, Ron and Hockberger, Robert},\n    #   year={2013},\n    #   publisher={Elsevier Health Sciences}\n    # }\n    BODY_TEMPERATURE_CELCIUS = 37.0\n\n    # @techreport{hasgall2018database,\n    #     title = {IT\u2019IS Database for thermal and electromagnetic parameters of biological tissues.\n    #     Version 4.0, May 15, 2018. doi: 10.13099},\n    #     author = {Hasgall, PA and Di Gennaro, F and Baumgartner, C and Neufeld, E and Lloyd, B and Gosselin,\n    #               MC and Payne, D and Klingenb{\\\"o}ck, A and Kuster, N},\n    #     year = {2018},\n    #     institution = {VIP21000 - 04 - 0.Onl: www.itis.ethz.ch / database}\n    # }\n    DENSITY_GENERIC = 1000     # kg/m\u00b3\n    DENSITY_AIR = 1.16\n    DENSITY_MUSCLE = 1090.4\n    DENSITY_BONE = 1908    # Cortical Bone\n    DENSITY_BLOOD = 1049.75\n    DENSITY_SKIN = 1109\n    DENSITY_FAT = 911\n    DENSITY_GEL_PAD = 890\n    DENSITY_WATER = 1000\n    DENSITY_HEAVY_WATER = 1107\n    DENSITY_LYMPH_NODE = 1035\n\n    SPEED_OF_SOUND_GENERIC = 1540.0   # m/s\n    SPEED_OF_SOUND_AIR = 343.0\n    SPEED_OF_SOUND_MUSCLE = 1588.4\n    SPEED_OF_SOUND_BONE = 3514.9      # Cortical bone\n    SPEED_OF_SOUND_BLOOD = 1578.2\n    SPEED_OF_SOUND_SKIN = 1624.0\n    SPEED_OF_SOUND_FAT = 1440.2\n    SPEED_OF_SOUND_GEL_PAD = 1583.0\n    SPEED_OF_SOUND_WATER = 1482.3\n    SPEED_OF_SOUND_HEAVY_WATER = 1540\n    SPEED_OF_SOUND_LYMPH_NODE = 1586\n\n    ALPHA_COEFF_GENERIC = 0.02  # dB/cm/MHz\n    ALPHA_COEFF_AIR = 3.3875e-3\n    ALPHA_COEFF_MUSCLE = 0.6175\n    ALPHA_COEFF_BONE = 4.7385  # Cortical bone\n    ALPHA_COEFF_BLOOD = 0.20\n    ALPHA_COEFF_SKIN = 0.35\n    ALPHA_COEFF_FAT = 0.3785\n    ALPHA_COEFF_GEL_PAD = 0.277\n    ALPHA_COEFF_WATER = 2.1976e-3\n    ALPHA_COEFF_LYMPH_NODE = 2.50",
  "class OpticalTissueProperties:\n    \"\"\"\n    This class contains a listing of optical tissue parameters as reported in literature.\n    The listing is not the result of a meta analysis, but rather uses the best fitting paper at\n    the time pf implementation.\n    Each of the fields is annotated with a literature reference or a descriptions of how the particular\n    values were derived for tissue modelling.\n    \"\"\"\n\n    # Background oxygenation assumed arbitrarily, to cover a large range of oxygenation values\n    BACKGROUND_OXYGENATION = 0.5\n    BACKGROUND_OXYGENATION_VARIATION = 0.5\n\n    # Venous blood parameters taken from the referenced literature. <60% SvO2 were reported as critical. Normal values\n    # are reported as 70%.\n    # @article{molnar2018monitoring,\n    #   title={Monitoring of tissue oxygenation: an everyday clinical challenge},\n    #   author={Molnar, Zsolt and Nemeth, Marton},\n    #   journal={Frontiers in medicine},\n    #   volume={4},\n    #   pages={247},\n    #   year={2018},\n    #   publisher={Frontiers}\n    # }\n    VENOUS_OXYGENATION = 0.7\n    VENOUS_OXYGENATION_VARIATION = 0.1\n\n    # Arterial blood parameters taken from the referenced literature.\n    # @article{merrick1976continuous,\n    #   title={Continuous, non-invasive measurements of arterial blood oxygen levels},\n    #   author={Merrick, Edwin B and Hayes, Thomas J},\n    #   journal={Hewlett-packard J},\n    #   volume={28},\n    #   number={2},\n    #   pages={2--9},\n    #   year={1976}\n    # }\n    ARTERIAL_OXYGENATION = 0.95\n    ARTERIAL_OXYGENATION_VARIATION = 0.05\n\n    # Tissue Property derived from the meta analysis by Steve Jacques in 2013:\n    # @article{jacques2013optical,\n    #   title={Optical properties of biological tissues: a review},\n    #   author={Jacques, Steven L},\n    #   journal={Physics in Medicine \\& Biology},\n    #   volume={58},\n    #   number={11},\n    #   pages={R37},\n    #   year={2013},\n    #   publisher={IOP Publishing}\n    # }\n    MUS500_BACKGROUND_TISSUE = 191.0  # Table 2: Average over all other soft tissue\n    FRAY_BACKGROUND_TISSUE = 0.153  # Table 2: Average over all other soft tissue\n    BMIE_BACKGROUND_TISSUE = 1.091  # Table 2: Average over all other soft tissue\n\n    MUS500_MUSCLE_TISSUE = 161.0  # Table 2: Average over all other soft tissue\n    FRAY_MUSCLE_TISSUE = 0.21  # Table 2: Average over all other soft tissue\n    BMIE_MUSCLE_TISSUE = 1.5  # Table 2: Average over all other soft tissue\n\n    MUS500_EPIDERMIS = 93.01  # Bashkatov et al. 2011 but adjusted for epidermis anisotropy\n    FRAY_EPIDERMIS = 0.29  # Table 1; Salomatina et al 2006; One value for epidermis\n    BMIE_EPIDERMIS = 2.8  # Table 1; Salomatina et al 2006; One value for epidermis\n    MUS500_DERMIS = 175.0  # Bashkatov et al. 2011 but adjusted for DERMIS_ANISOTROPY\n    FRAY_DERMIS = 0.1  # Table 1; Salomatina et al 2006; One value for dermis\n    BMIE_DERMIS = 3.5  # Table 1; Salomatina et al 2006; One value for dermis\n    MUS500_FAT = 193.0  # Table 2 average fatty tissue\n    FRAY_FAT = 0.174  # Table 2 average fatty tissue\n    BMIE_FAT = 0.447  # Table 2 average fatty tissue\n    MUS500_BLOOD = 1170  # Table 1 Alexandrakis et al 2005\n    FRAY_BLOOD = 0.0  # Table 1 Alexandrakis et al 2005\n    BMIE_BLOOD = 0.93  # Table 1 Alexandrakis et al 2005\n    MUS500_BONE = 153.0  # Table 2 Mean for bone\n    FRAY_BONE = 0.022  # Table 2 Mean for bone\n    BMIE_BONE = 0.326  # Table 2 Mean for bone\n    STANDARD_ANISOTROPY = 0.9  # Average anisotropy of measured values presented in paper\n    DERMIS_ANISOTROPY = 0.715\n    BLOOD_ANISOTROPY = 0.98\n\n    # Water content of bone:\n    # @article{timmins1977bone,\n    #   title={Bone water},\n    #   author={Timmins, PA and Wall, JC},\n    #   journal={Calcified tissue research},\n    #   volume={23},\n    #   number={1},\n    #   pages={1--5},\n    #   year={1977},\n    #   publisher={Springer}\n    # }\n    WATER_VOLUME_FRACTION_BONE_MEAN = 0.19\n    WATER_VOLUME_FRACTION_BONE_STD = 0.01\n\n    # Adult body composition derived values\n    # @article{forbes1953composition,\n    #   title={The composition of the adult human body as determined by chemical analysis},\n    #   author={Forbes, RM and Cooper, AR and Mitchell, HH and others},\n    #   journal={J Biol Chem},\n    #   volume={203},\n    #   number={1},\n    #   pages={359--366},\n    #   year={1953}\n    # }\n    WATER_VOLUME_FRACTION_SKIN = 0.58\n    WATER_VOLUME_FRACTION_HUMAN_BODY = 0.68\n\n    # Muscle tissue blood volume fraction:\n    # @article{vankana1998mechanical,\n    #   title={Mechanical blood-tissue interaction in contracting muscles: a model study},\n    #   author={Vankana, WJ and Huyghe, Jacques M and van Donkelaar, Corrinus C and Drost, Maarten R and Janssen,\n    # Jan D and Huson, A},\n    #   journal={Journal of Biomechanics},\n    #   volume={31},\n    #   number={5},\n    #   pages={401--409},\n    #   year={1998},\n    #   publisher={Elsevier}\n    # }\n    BLOOD_VOLUME_FRACTION_MUSCLE_TISSUE = 0.01  # Value of arterial bvf at t0 in fig 3.\n\n    BLOOD_PLASMA_FRACTION = 0.55    # This value seems to be widely accepted.\n\n    # Mean and spread calculated from europeans from figure 2C, averaged over both\n    # photoexposed and photoprotected simpa_examples.\n    # @article{alaluf2002ethnic,\n    #   title={Ethnic variation in melanin content and composition in photoexposed and photoprotected human skin},\n    #   author={Alaluf, Simon and Atkins, Derek and Barrett, Karen and Blount, Margaret and Carter,\n    # Nik and Heath, Alan},\n    #   journal={Pigment Cell Research},\n    #   volume={15},\n    #   number={2},\n    #   pages={112--118},\n    #   year={2002},\n    #   publisher={Wiley Online Library}\n    # }\n\n    MELANIN_VOLUME_FRACTION_MEAN = 0.014\n    MELANIN_VOLUME_FRACTION_STD = 0.003\n\n    # Approximated mean of figure 3\n    # @inproceedings{antunes2019optical,\n    #   title = {Optical Properties on Bone Analysis: An Approach to Biomaterials},\n    #   author = {Antunes, Andrea and Pontes, Jos{\\'e} HL and Monte, Adamo FG and Barbosa, Alcimar and Ferreira,\n    # Nuno MF},\n    #   booktitle = {Multidisciplinary Digital Publishing Institute Proceedings},\n    #   volume = {27},\n    #   number = {1},\n    #   pages = {36},\n    #   year = {2019}\n    # }\n    BONE_ABSORPTION = 1.8\n\n    # Approximated table 2 with gaussian fit\n    # @article{bugter2021detecting,\n    # title={Detecting head and neck lymph node metastases with white light reflectance spectroscopy; a pilot study},\n    # author={Bugter, Ois{\\'\\i}n and Aaboubout, Yassine and Algoe, Mahesh and de Bruijn, Henri{\\\"e}tte S and Keereweer, Stijn and Sewnaik, Aniel and Monserez, Dominiek A and Koljenovi{\\'c}, Senada and Hardillo, Jose AU and Robinson, Dominic J and others},\n    # journal={Oral Oncology},\n    # volume={123},\n    # pages={105627},\n    # year={2021},\n    # publisher={Elsevier}\n    # }\n    BLOOD_VOLUME_FRACTION_LYMPH_NODE = 0.14\n    BLOOD_VOLUME_FRACTION_LYMPH_NODE_VARIATION = 0.07\n    LYMPH_NODE_OXYGENATION = 0.73\n    LYMPH_NODE_OXYGENATION_VARIATION = 0.15",
  "class MorphologicalTissueProperties:\n    \"\"\"\n    This class contains a listing of morphological tissue parameters as reported in literature.\n    The listing is not the result of a meta analysis, but rather uses the best fitting paper at\n    the time pf implementation.\n    Each of the fields is annotated with a literature reference or a descriptions of how the particular\n    values were derived for tissue modelling.\n    \"\"\"\n\n    # @article{ashraf2010size,\n    #     title={Size of radial and ulnar artery in local population},\n    #     author={Ashraf, Tariq and Panhwar, Ziauddin and Habib, Sultana and Memon, Muhammad Anis and Shamsi,\n    #             Fahad and Arif, Javed},\n    #     journal={JPMA-Journal of the Pakistan Medical Association},\n    #     volume={60},\n    #     number={10},\n    #     pages={817},\n    #     year={2010}\n    # }\n    RADIAL_ARTERY_DIAMETER_MEAN_MM = 2.25\n    RADIAL_ARTERY_DIAMETER_STD_MM = 0.4\n    ULNAR_ARTERY_DIAMETER_MEAN_MM = 2.35\n    ULNAR_ARTERY_DIAMETER_STD_MM = 0.35\n\n    # Accompanying veins diameter reference. They specifically only mention the ulnar accompanying vein properties.\n    # We assume a non-significant similarity for the radial accompanying vein.\n    # @incollection{yang_ulnar_2018,\n    #   title = {Ulnar {Artery} to {Superficial} {Arch} {Bypass} with a {Vein} {Graft}},\n    #   booktitle = {Operative {Techniques}: {Hand} and {Wrist} {Surgery}},\n    #   author = {Yang, Guang and Chung, Kevin C.},\n    #   year = {2018},\n    #   doi = {10.1016/B978-0-323-40191-3.00081-0},\n    #   pages = {732--737},\n    # }\n    RADIAL_VEIN_DIAMETER_MEAN_MM = 1.0\n    RADIAL_VEIN_DIAMETER_STD_MM = 0.2\n    ULNAR_VEIN_DIAMETER_MEAN_MM = 1.0\n    ULNAR_VEIN_DIAMETER_STD_MM = 0.2\n\n    # Median artery diameter reference (at the P2 point):\n    # @article{hubmer2004posterior,\n    #   title={The posterior interosseous artery in the distal part of the forearm. Is the term \u2018recurrent branch of\n    # the anterior interosseous artery\u2019justified?},\n    #   author={Hubmer, Martin G and Fasching, Thomas and Haas, Franz and Koch, Horst and Schwarzl, Franz and Weiglein,\n    # Andreas and Scharnagl, Erwin},\n    #   journal={British journal of plastic surgery},\n    #   volume={57},\n    #   number={7},\n    #   pages={638--644},\n    #   year={2004},\n    #   publisher={Elsevier}\n    # }\n    MEDIAN_ARTERY_DIAMETER_MEAN_MM = 0.6\n    MEDIAN_ARTERY_DIAMETER_STD_MM = 0.25\n\n    # TODO CITE\n    # Assumption: about half the size of the radial and ulnar accompanying veins due to size of the respective\n    # artery in comparison to the radial and ulna artery\n    MEDIAN_VEIN_DIAMETER_MEAN_MM = 0.5\n    MEDIAN_VEIN_DIAMETER_STD_MM = 0.1\n\n    # Thickness of the dermis and epidermis approximated with values for the hand. Averaged for\n    # @article{oltulu2018measurement,\n    #   title={Measurement of epidermis, dermis, and total skin thicknesses from six different body regions\n    # with a new ethical histometric technique},\n    #   author={Oltulu, Pembe and Ince, Bilsev and Kokbudak, Naile and Findik, Sidika and Kilinc, Fahriye and others},\n    #   journal={Turkish Journal of Plastic Surgery},\n    #   volume={26},\n    #   number={2},\n    #   pages={56},\n    #   year={2018},\n    #   publisher={Medknow Publications}\n    # }\n    DERMIS_THICKNESS_MEAN_MM = 2.3\n    DERMIS_THICKNESS_STD_MM = 1.2\n    EPIDERMIS_THICKNESS_MEAN_MM = 0.22\n    EPIDERMIS_THICKNESS_STD_MM = 0.1\n\n    # Distance of radius and ulnar at resting position, when bones are not crossed\n    # @article{christensen1968study,\n    #   title={A study of the interosseous distance between the radius and ulna during rotation of the forearm},\n    #   author={Christensen, John B and Adams, John P and Cho, KO and Miller, Lawrence},\n    #   journal={The Anatomical Record},\n    #   volume={160},\n    #   number={2},\n    #   pages={261--271},\n    #   year={1968},\n    #   publisher={Wiley Online Library}\n    # }\n    RADIUS_ULNA_BONE_SEPARATION_MEAN_MM = 32.0\n    RADIUS_ULNA_BONE_POSITION_STD_MM = 2.0\n\n    # Subcutaneous veins depth measurements are extrapolated from graphs in table 3.\n    # The diameter measurement are supposed to resemble the approximate range from figure 15.\n    # @article{goh2017subcutaneous,\n    #   title={Subcutaneous veins depth measurement using diffuse reflectance images},\n    #   author={Goh, CM and Subramaniam, R and Saad, NM and Ali, SA and Meriaudeau, F},\n    #   journal={Optics express},\n    #   volume={25},\n    #   number={21},\n    #   pages={25741--25759},\n    #   year={2017},\n    #   publisher={Optical Society of America}\n    # }\n    SUBCUTANEOUS_VEIN_DEPTH_MEAN_MM = 1.5\n    SUBCUTANEOUS_VEIN_DEPTH_STD_MM = 0.7\n    SUBCUTANEOUS_VEIN_DIAMETER_MEAN_MM = 0.8\n    SUBCUTANEOUS_VEIN_DIAMETER_STD_MM = 0.6\n\n    # The following properties were experimentally determined based on data sets provided by Janek Groehl\n    # (Photoacoustic forearm images) and Andr\u00e9 Klein (Forearm CT images from full body CTs)\n\n    RADIAL_ARTERY_DEPTH_MEAN_MM = 6.0\n    RADIAL_ARTERY_DEPTH_STD_MM = 0.5\n    ULNAR_ARTERY_DEPTH_MEAN_MM = 6.0\n    ULNAR_ARTERY_DEPTH_STD_MM = 0.5\n\n    DISTANCE_RADIAL_AND_ULNA_ARTERY_MEAN_MM = 30\n    DISTANCE_RADIAL_AND_ULNA_ARTERY_STD_MM = 5\n    RADIUS_BONE_DIAMETER_MEAN_MM = 20.0\n    RADIUS_BONE_DIAMETER_STD_MM = 2.0\n    ULNA_BONE_DIAMETER_MEAN_MM = 15.0\n    ULNA_BONE_DIAMETER_STD_MM = 2.0\n    MEDIAN_ARTERY_DEPTH_MEAN_MM = 19.0\n    MEDIAN_ARTERY_DEPTH_STD_MM = 1.0\n    ACCOMPANYING_VEIN_MEDIAN_DISTANCE_MEAN_MM = 1.0\n    ACCOMPANYING_VEIN_MEDIAN_DISTANCE_STD_MM = 0.2\n    ACCOMPANYING_VEIN_DISTANCE_MEAN_MM = 2.5\n    ACCOMPANYING_VEIN_DISTANCE_STD_MM = 0.4\n    ACCOMPANYING_VEIN_DEPTH_STD_MM = 1.5\n    RADIUS_BONE_DEPTH_MEAN_MM = 22.0\n    RADIUS_BONE_DEPTH_STD_MM = 2.0\n    ULNA_BONE_DEPTH_MEAN_MM = 22.0\n    ULNA_BONE_DEPTH_STD_MM = 2.0\n\n    # Arbitrary position constants based on the respective coordinate systems\n    RADIAL_ARTERY_X_POSITION_MEAN_MM = 7.5\n    ULNAR_ARTERY_X_POSITION_MEAN_MM = RADIAL_ARTERY_X_POSITION_MEAN_MM + DISTANCE_RADIAL_AND_ULNA_ARTERY_MEAN_MM\n    MEDIAN_ARTERY_X_POSITION_MEAN_MM = RADIAL_ARTERY_X_POSITION_MEAN_MM + DISTANCE_RADIAL_AND_ULNA_ARTERY_MEAN_MM / 2\n    ARTERY_X_POSITION_UNCERTAINTY_MM = DISTANCE_RADIAL_AND_ULNA_ARTERY_STD_MM / (2**(1/2))",
  "class GeometricalStructure:\n    \"\"\"\n    Base class for all model-based structures for ModelBasedVolumeCreator. A GeometricalStructure has an internal\n    representation of its own geometry. This is represented by self.geometrical_volume which is a 3D array that defines\n    for every voxel within the simulation volume if it is enclosed in the GeometricalStructure or if it is outside.\n    Most of the GeometricalStructures implement a partial volume effect. So if a voxel has the value 1, it is completely\n    enclosed by the GeometricalStructure. If a voxel has a value between 0 and 1, that fraction of the volume is\n    occupied by the GeometricalStructure. If a voxel has the value 0, it is outside of the GeometricalStructure.\n    \"\"\"\n\n    def __init__(self, global_settings: Settings,\n                 single_structure_settings: Settings = None):\n\n        self.logger = Logger()\n\n        self.voxel_spacing = global_settings[Tags.SPACING_MM]\n        volume_x_dim = int(np.round(global_settings[Tags.DIM_VOLUME_X_MM] / self.voxel_spacing))\n        volume_y_dim = int(np.round(global_settings[Tags.DIM_VOLUME_Y_MM] / self.voxel_spacing))\n        volume_z_dim = int(np.round(global_settings[Tags.DIM_VOLUME_Z_MM] / self.voxel_spacing))\n        self.volume_dimensions_voxels = np.asarray([volume_x_dim, volume_y_dim, volume_z_dim])\n\n        self.volume_dimensions_mm = self.volume_dimensions_voxels * self.voxel_spacing\n        self.do_deformation = (Tags.SIMULATE_DEFORMED_LAYERS in global_settings.get_volume_creation_settings() and\n                               global_settings.get_volume_creation_settings()[Tags.SIMULATE_DEFORMED_LAYERS])\n\n        if (Tags.ADHERE_TO_DEFORMATION in single_structure_settings and\n                not single_structure_settings[Tags.ADHERE_TO_DEFORMATION]):\n            self.do_deformation = False\n\n        self.logger.debug(f\"This structure will simulate deformations: {self.do_deformation}\")\n\n        if self.do_deformation and Tags.DEFORMED_LAYERS_SETTINGS in global_settings.get_volume_creation_settings():\n            self.deformation_functional_mm = get_functional_from_deformation_settings(\n                global_settings.get_volume_creation_settings()[Tags.DEFORMED_LAYERS_SETTINGS])\n        else:\n            self.deformation_functional_mm = None\n\n        self.logger.debug(f\"This structure's deformation functional: {self.deformation_functional_mm}\")\n\n        if single_structure_settings is None:\n            self.molecule_composition = MolecularComposition()\n            self.priority = 0\n            return\n\n        if Tags.PRIORITY in single_structure_settings:\n            self.priority = single_structure_settings[Tags.PRIORITY]\n\n        if Tags.CONSIDER_PARTIAL_VOLUME in single_structure_settings:\n            self.partial_volume = single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME]\n        else:\n            self.partial_volume = False\n\n        self.molecule_composition = single_structure_settings[Tags.MOLECULE_COMPOSITION]\n        self.molecule_composition.update_internal_properties()\n\n        self.geometrical_volume = np.zeros(self.volume_dimensions_voxels)\n        self.params = self.get_params_from_settings(single_structure_settings)\n        self.fill_internal_volume()\n\n    def fill_internal_volume(self):\n        \"\"\"\n        Fills self.geometrical_volume of the GeometricalStructure.\n        \"\"\"\n        indices, values = self.get_enclosed_indices()\n        self.geometrical_volume[indices] = values\n\n    @abstractmethod\n    def get_enclosed_indices(self):\n        \"\"\"\n        Gets indices of the voxels that are either entirely or partially occupied by the GeometricalStructure.\n        :return: mask for a numpy array\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_params_from_settings(self, single_structure_settings):\n        \"\"\"\n        Gets all the parameters required for the specific GeometricalStructure.\n        :param single_structure_settings: Settings which describe the specific GeometricalStructure.\n        :return: Tuple of parameters\n        \"\"\"\n        pass\n\n    def properties_for_wavelength(self, wavelength) -> TissueProperties:\n        \"\"\"\n        Returns the values corresponding to each optical/acoustic property used in SIMPA.\n        :param wavelength: Wavelength of the queried properties\n        :return: optical/acoustic properties\n        \"\"\"\n        return self.molecule_composition.get_properties_for_wavelength(wavelength)\n\n    @abstractmethod\n    def to_settings(self) -> Settings:\n        \"\"\"\n        Creates a Settings dictionary which contains all the parameters needed to create the same GeometricalStructure\n        again.\n        :return : A tuple containing the settings key and the needed entries\n        \"\"\"\n        settings_dict = Settings()\n        settings_dict[Tags.PRIORITY] = self.priority\n        settings_dict[Tags.STRUCTURE_TYPE] = self.__class__.__name__\n        settings_dict[Tags.CONSIDER_PARTIAL_VOLUME] = self.partial_volume\n        settings_dict[Tags.MOLECULE_COMPOSITION] = self.molecule_composition\n        return settings_dict",
  "def __init__(self, global_settings: Settings,\n                 single_structure_settings: Settings = None):\n\n        self.logger = Logger()\n\n        self.voxel_spacing = global_settings[Tags.SPACING_MM]\n        volume_x_dim = int(np.round(global_settings[Tags.DIM_VOLUME_X_MM] / self.voxel_spacing))\n        volume_y_dim = int(np.round(global_settings[Tags.DIM_VOLUME_Y_MM] / self.voxel_spacing))\n        volume_z_dim = int(np.round(global_settings[Tags.DIM_VOLUME_Z_MM] / self.voxel_spacing))\n        self.volume_dimensions_voxels = np.asarray([volume_x_dim, volume_y_dim, volume_z_dim])\n\n        self.volume_dimensions_mm = self.volume_dimensions_voxels * self.voxel_spacing\n        self.do_deformation = (Tags.SIMULATE_DEFORMED_LAYERS in global_settings.get_volume_creation_settings() and\n                               global_settings.get_volume_creation_settings()[Tags.SIMULATE_DEFORMED_LAYERS])\n\n        if (Tags.ADHERE_TO_DEFORMATION in single_structure_settings and\n                not single_structure_settings[Tags.ADHERE_TO_DEFORMATION]):\n            self.do_deformation = False\n\n        self.logger.debug(f\"This structure will simulate deformations: {self.do_deformation}\")\n\n        if self.do_deformation and Tags.DEFORMED_LAYERS_SETTINGS in global_settings.get_volume_creation_settings():\n            self.deformation_functional_mm = get_functional_from_deformation_settings(\n                global_settings.get_volume_creation_settings()[Tags.DEFORMED_LAYERS_SETTINGS])\n        else:\n            self.deformation_functional_mm = None\n\n        self.logger.debug(f\"This structure's deformation functional: {self.deformation_functional_mm}\")\n\n        if single_structure_settings is None:\n            self.molecule_composition = MolecularComposition()\n            self.priority = 0\n            return\n\n        if Tags.PRIORITY in single_structure_settings:\n            self.priority = single_structure_settings[Tags.PRIORITY]\n\n        if Tags.CONSIDER_PARTIAL_VOLUME in single_structure_settings:\n            self.partial_volume = single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME]\n        else:\n            self.partial_volume = False\n\n        self.molecule_composition = single_structure_settings[Tags.MOLECULE_COMPOSITION]\n        self.molecule_composition.update_internal_properties()\n\n        self.geometrical_volume = np.zeros(self.volume_dimensions_voxels)\n        self.params = self.get_params_from_settings(single_structure_settings)\n        self.fill_internal_volume()",
  "def fill_internal_volume(self):\n        \"\"\"\n        Fills self.geometrical_volume of the GeometricalStructure.\n        \"\"\"\n        indices, values = self.get_enclosed_indices()\n        self.geometrical_volume[indices] = values",
  "def get_enclosed_indices(self):\n        \"\"\"\n        Gets indices of the voxels that are either entirely or partially occupied by the GeometricalStructure.\n        :return: mask for a numpy array\n        \"\"\"\n        pass",
  "def get_params_from_settings(self, single_structure_settings):\n        \"\"\"\n        Gets all the parameters required for the specific GeometricalStructure.\n        :param single_structure_settings: Settings which describe the specific GeometricalStructure.\n        :return: Tuple of parameters\n        \"\"\"\n        pass",
  "def properties_for_wavelength(self, wavelength) -> TissueProperties:\n        \"\"\"\n        Returns the values corresponding to each optical/acoustic property used in SIMPA.\n        :param wavelength: Wavelength of the queried properties\n        :return: optical/acoustic properties\n        \"\"\"\n        return self.molecule_composition.get_properties_for_wavelength(wavelength)",
  "def to_settings(self) -> Settings:\n        \"\"\"\n        Creates a Settings dictionary which contains all the parameters needed to create the same GeometricalStructure\n        again.\n        :return : A tuple containing the settings key and the needed entries\n        \"\"\"\n        settings_dict = Settings()\n        settings_dict[Tags.PRIORITY] = self.priority\n        settings_dict[Tags.STRUCTURE_TYPE] = self.__class__.__name__\n        settings_dict[Tags.CONSIDER_PARTIAL_VOLUME] = self.partial_volume\n        settings_dict[Tags.MOLECULE_COMPOSITION] = self.molecule_composition\n        return settings_dict",
  "class ParallelepipedStructure(GeometricalStructure):\n    \"\"\"\n    Defines a parallelepiped which is defined by a start point and three edge vectors which originate from the start\n    point. This structure currently does not implement partial volume effects.\n    Example usage:\n\n        # single_structure_settings initialization\n        structure = Settings()\n\n        structure[Tags.PRIORITY] = 9\n        structure[Tags.STRUCTURE_START_MM] = [25, 25, 25]\n        structure[Tags.STRUCTURE_FIRST_EDGE_MM] = [5, 1, 1]\n        structure[Tags.STRUCTURE_SECOND_EDGE_MM] = [1, 5, 1]\n        structure[Tags.STRUCTURE_THIRD_EDGE_MM] = [1, 1, 5]\n        structure[Tags.MOLECULE_COMPOSITION] = TISSUE_LIBRARY.muscle()\n        structure[Tags.STRUCTURE_TYPE] = Tags.PARALLELEPIPED_STRUCTURE\n\n    \"\"\"\n\n    def get_params_from_settings(self, single_structure_settings):\n        params = (np.asarray(single_structure_settings[Tags.STRUCTURE_START_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_FIRST_EDGE_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_SECOND_EDGE_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_THIRD_EDGE_MM]))\n        return params\n\n    def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_FIRST_EDGE_MM] = self.params[1]\n        settings[Tags.STRUCTURE_SECOND_EDGE_MM] = self.params[2]\n        settings[Tags.STRUCTURE_THIRD_EDGE_MM] = self.params[3]\n        return settings\n\n    def get_enclosed_indices(self):\n        start_mm, x_edge_mm, y_edge_mm, z_edge_mm = self.params\n        start_voxels = start_mm / self.voxel_spacing\n        x_edge_voxels = np.array(x_edge_mm / self.voxel_spacing)\n        y_edge_voxels = np.array(y_edge_mm / self.voxel_spacing)\n        z_edge_voxels = np.array(z_edge_mm / self.voxel_spacing)\n\n        x, y, z = np.meshgrid(np.arange(self.volume_dimensions_voxels[0]),\n                              np.arange(self.volume_dimensions_voxels[1]),\n                              np.arange(self.volume_dimensions_voxels[2]),\n                              indexing='ij')\n\n        target_vector = np.subtract(np.stack([x, y, z], axis=-1), start_voxels)\n\n        matrix = np.array([x_edge_voxels, y_edge_voxels, z_edge_voxels])\n\n        inverse_matrix = np.linalg.inv(matrix)\n\n        result = np.matmul(target_vector, inverse_matrix)\n\n        norm_vector = np.array([1/np.linalg.norm(x_edge_voxels),\n                                1/np.linalg.norm(y_edge_voxels),\n                                1/np.linalg.norm(z_edge_voxels)])\n\n        filled_mask_bool = (0 <= result) & (result <= 1 - norm_vector)\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n        filled_mask = np.all(filled_mask_bool, axis=-1)\n\n        volume_fractions[filled_mask] = 1\n\n        return filled_mask, volume_fractions[filled_mask]",
  "def define_parallelepiped_structure_settings(start_mm: list, edge_a_mm: list, edge_b_mm: list, edge_c_mm: list,\n                                             molecular_composition: MolecularComposition, priority: int = 10,\n                                             consider_partial_volume: bool = False,\n                                             adhere_to_deformation: bool = False):\n    \"\"\"\n    TODO\n    \"\"\"\n\n    return {\n        Tags.STRUCTURE_START_MM: start_mm,\n        Tags.STRUCTURE_FIRST_EDGE_MM: edge_a_mm,\n        Tags.STRUCTURE_SECOND_EDGE_MM: edge_b_mm,\n        Tags.STRUCTURE_THIRD_EDGE_MM: edge_c_mm,\n        Tags.PRIORITY: priority,\n        Tags.MOLECULE_COMPOSITION: molecular_composition,\n        Tags.CONSIDER_PARTIAL_VOLUME: consider_partial_volume,\n        Tags.ADHERE_TO_DEFORMATION: adhere_to_deformation,\n        Tags.STRUCTURE_TYPE: Tags.PARALLELEPIPED_STRUCTURE\n    }",
  "def get_params_from_settings(self, single_structure_settings):\n        params = (np.asarray(single_structure_settings[Tags.STRUCTURE_START_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_FIRST_EDGE_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_SECOND_EDGE_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_THIRD_EDGE_MM]))\n        return params",
  "def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_FIRST_EDGE_MM] = self.params[1]\n        settings[Tags.STRUCTURE_SECOND_EDGE_MM] = self.params[2]\n        settings[Tags.STRUCTURE_THIRD_EDGE_MM] = self.params[3]\n        return settings",
  "def get_enclosed_indices(self):\n        start_mm, x_edge_mm, y_edge_mm, z_edge_mm = self.params\n        start_voxels = start_mm / self.voxel_spacing\n        x_edge_voxels = np.array(x_edge_mm / self.voxel_spacing)\n        y_edge_voxels = np.array(y_edge_mm / self.voxel_spacing)\n        z_edge_voxels = np.array(z_edge_mm / self.voxel_spacing)\n\n        x, y, z = np.meshgrid(np.arange(self.volume_dimensions_voxels[0]),\n                              np.arange(self.volume_dimensions_voxels[1]),\n                              np.arange(self.volume_dimensions_voxels[2]),\n                              indexing='ij')\n\n        target_vector = np.subtract(np.stack([x, y, z], axis=-1), start_voxels)\n\n        matrix = np.array([x_edge_voxels, y_edge_voxels, z_edge_voxels])\n\n        inverse_matrix = np.linalg.inv(matrix)\n\n        result = np.matmul(target_vector, inverse_matrix)\n\n        norm_vector = np.array([1/np.linalg.norm(x_edge_voxels),\n                                1/np.linalg.norm(y_edge_voxels),\n                                1/np.linalg.norm(z_edge_voxels)])\n\n        filled_mask_bool = (0 <= result) & (result <= 1 - norm_vector)\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n        filled_mask = np.all(filled_mask_bool, axis=-1)\n\n        volume_fractions[filled_mask] = 1\n\n        return filled_mask, volume_fractions[filled_mask]",
  "class SphericalStructure(GeometricalStructure):\n    \"\"\"\n    Defines a sphere which is defined by a start point and a radius. This structure implements\n    partial volume effects. The sphere can be set to adhere to a deformation defined by the\n    simpa.utils.deformation_manager. The start point of the sphere will then be shifted along the z-axis\n    accordingly.\n    Example usage:\n\n        # single_structure_settings initialization\n        structure = Settings()\n\n        structure[Tags.PRIORITY] = 9\n        structure[Tags.STRUCTURE_START_MM] = [50, 50, 50]\n        structure[Tags.STRUCTURE_RADIUS_MM] = 10\n        structure[Tags.MOLECULE_COMPOSITION] = TISSUE_LIBRARY.blood()\n        structure[Tags.CONSIDER_PARTIAL_VOLUME] = True\n        structure[Tags.ADHERE_TO_DEFORMATION] = True\n        structure[Tags.STRUCTURE_TYPE] = Tags.SPHERICAL_STRUCTURE\n\n    \"\"\"\n\n    def get_params_from_settings(self, single_structure_settings):\n        params = (np.asarray(single_structure_settings[Tags.STRUCTURE_START_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_RADIUS_MM]),\n                  single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME])\n        return params\n\n    def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_RADIUS_MM] = self.params[1]\n        return settings\n\n    def get_enclosed_indices(self):\n        start_mm, radius_mm, partial_volume = self.params\n        start_voxels = start_mm / self.voxel_spacing\n        radius_voxels = radius_mm / self.voxel_spacing\n        x, y, z = np.meshgrid(np.arange(self.volume_dimensions_voxels[0]),\n                              np.arange(self.volume_dimensions_voxels[1]),\n                              np.arange(self.volume_dimensions_voxels[2]),\n                              indexing='ij')\n\n        x = x + 0.5\n        y = y + 0.5\n        z = z + 0.5\n\n        if partial_volume:\n            radius_margin = 0.5\n        else:\n            radius_margin = 0.7071\n\n        target_vector = np.subtract(np.stack([x, y, z], axis=-1), start_voxels)\n        target_radius = np.linalg.norm(target_vector, axis=-1)\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n        filled_mask = target_radius <= radius_voxels - 1 + radius_margin\n        border_mask = (target_radius > radius_voxels - 1 + radius_margin) & \\\n                      (target_radius < radius_voxels + 2 * radius_margin)\n\n        volume_fractions[filled_mask] = 1\n        volume_fractions[border_mask] = 1 - (target_radius - (radius_voxels-radius_margin))[border_mask]\n        volume_fractions[volume_fractions < 0] = 0\n\n        if partial_volume:\n            mask = filled_mask | border_mask\n        else:\n            mask = filled_mask\n\n        return mask, volume_fractions[mask]",
  "def define_spherical_structure_settings(start_mm: list, molecular_composition: MolecularComposition,\n                                        radius_mm: float = 1, priority: int = 10,\n                                        consider_partial_volume: bool = False,\n                                        adhere_to_deformation: bool = False):\n    \"\"\"\n    TODO\n    \"\"\"\n    return {\n        Tags.STRUCTURE_START_MM: start_mm,\n        Tags.STRUCTURE_RADIUS_MM: radius_mm,\n        Tags.PRIORITY: priority,\n        Tags.MOLECULE_COMPOSITION: molecular_composition,\n        Tags.CONSIDER_PARTIAL_VOLUME: consider_partial_volume,\n        Tags.ADHERE_TO_DEFORMATION: adhere_to_deformation,\n        Tags.STRUCTURE_TYPE: Tags.SPHERICAL_STRUCTURE\n    }",
  "def get_params_from_settings(self, single_structure_settings):\n        params = (np.asarray(single_structure_settings[Tags.STRUCTURE_START_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_RADIUS_MM]),\n                  single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME])\n        return params",
  "def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_RADIUS_MM] = self.params[1]\n        return settings",
  "def get_enclosed_indices(self):\n        start_mm, radius_mm, partial_volume = self.params\n        start_voxels = start_mm / self.voxel_spacing\n        radius_voxels = radius_mm / self.voxel_spacing\n        x, y, z = np.meshgrid(np.arange(self.volume_dimensions_voxels[0]),\n                              np.arange(self.volume_dimensions_voxels[1]),\n                              np.arange(self.volume_dimensions_voxels[2]),\n                              indexing='ij')\n\n        x = x + 0.5\n        y = y + 0.5\n        z = z + 0.5\n\n        if partial_volume:\n            radius_margin = 0.5\n        else:\n            radius_margin = 0.7071\n\n        target_vector = np.subtract(np.stack([x, y, z], axis=-1), start_voxels)\n        target_radius = np.linalg.norm(target_vector, axis=-1)\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n        filled_mask = target_radius <= radius_voxels - 1 + radius_margin\n        border_mask = (target_radius > radius_voxels - 1 + radius_margin) & \\\n                      (target_radius < radius_voxels + 2 * radius_margin)\n\n        volume_fractions[filled_mask] = 1\n        volume_fractions[border_mask] = 1 - (target_radius - (radius_voxels-radius_margin))[border_mask]\n        volume_fractions[volume_fractions < 0] = 0\n\n        if partial_volume:\n            mask = filled_mask | border_mask\n        else:\n            mask = filled_mask\n\n        return mask, volume_fractions[mask]",
  "class RectangularCuboidStructure(GeometricalStructure):\n    \"\"\"\n    Defines a rectangular cuboid (box) which is defined by a start point its extent along the x-, y-, and z-axis.\n    This structure implements partial volume effects. The box can be set to adhere to a deformation defined by the\n    simpa.utils.deformation_manager. The start point of the box will then be shifted along the z-axis\n    accordingly.\n    Example usage:\n\n        # single_structure_settings initialization\n        structure = Settings()\n\n        structure[Tags.PRIORITY] = 9\n        structure[Tags.STRUCTURE_START_MM] = [25, 25, 25]\n        structure[Tags.STRUCTURE_X_EXTENT_MM] = 40\n        structure[Tags.STRUCTURE_Y_EXTENT_MM] = 50\n        structure[Tags.STRUCTURE_Z_EXTENT_MM] = 60\n        structure[Tags.MOLECULE_COMPOSITION] = TISSUE_LIBRARY.muscle()\n        structure[Tags.CONSIDER_PARTIAL_VOLUME] = True\n        structure[Tags.ADHERE_TO_DEFORMATION] = True\n        structure[Tags.STRUCTURE_TYPE] = Tags.RECTANGULAR_CUBOID_STRUCTURE\n\n    \"\"\"\n\n    def get_params_from_settings(self, single_structure_settings):\n        params = (np.asarray(single_structure_settings[Tags.STRUCTURE_START_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_X_EXTENT_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_Y_EXTENT_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_Z_EXTENT_MM]),\n                  single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME])\n        return params\n\n    def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_X_EXTENT_MM] = self.params[1]\n        settings[Tags.STRUCTURE_Y_EXTENT_MM] = self.params[2]\n        settings[Tags.STRUCTURE_Z_EXTENT_MM] = self.params[3]\n        settings[Tags.CONSIDER_PARTIAL_VOLUME] = self.params[4]\n        return settings\n\n    def get_enclosed_indices(self):\n        start_mm, x_edge_mm, y_edge_mm, z_edge_mm, partial_volume = self.params\n        start_voxels = start_mm / self.voxel_spacing\n        x_edge_voxels = np.array([x_edge_mm / self.voxel_spacing, 0, 0])\n        y_edge_voxels = np.array([0, y_edge_mm / self.voxel_spacing, 0])\n        z_edge_voxels = np.array([0, 0, z_edge_mm / self.voxel_spacing])\n\n        x, y, z = np.meshgrid(np.arange(self.volume_dimensions_voxels[0]),\n                              np.arange(self.volume_dimensions_voxels[1]),\n                              np.arange(self.volume_dimensions_voxels[2]),\n                              indexing='ij')\n\n        target_vector = np.subtract(np.stack([x, y, z], axis=-1), start_voxels)\n\n        matrix = np.array([x_edge_voxels, y_edge_voxels, z_edge_voxels])\n\n        inverse_matrix = np.linalg.inv(matrix)\n\n        result = np.matmul(target_vector, inverse_matrix)\n\n        norm_vector = np.array([1/np.linalg.norm(x_edge_voxels),\n                                1/np.linalg.norm(y_edge_voxels),\n                                1/np.linalg.norm(z_edge_voxels)])\n\n        filled_mask_bool = (0 <= result) & (result <= 1 - norm_vector)\n        border_bool = (0 - norm_vector < result) & (result <= 1)\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n        filled_mask = np.all(filled_mask_bool, axis=-1)\n\n        border_mask = np.all(border_bool, axis=-1)\n\n        border_mask = np.logical_xor(border_mask, filled_mask)\n\n        edge_values = result[border_mask]\n\n        fraction_values = np.matmul(edge_values, matrix)\n\n        larger_fraction_values = (x_edge_voxels + y_edge_voxels + z_edge_voxels) - fraction_values\n\n        small_bool = fraction_values > 0\n        large_bool = larger_fraction_values >= 1\n\n        fraction_values[small_bool & large_bool] = 0\n        fraction_values[fraction_values <= 0] = 1 + fraction_values[fraction_values <= 0]\n        fraction_values[larger_fraction_values < 1] = larger_fraction_values[larger_fraction_values < 1]\n\n        fraction_values = np.abs(np.prod(fraction_values, axis=-1))\n\n        volume_fractions[filled_mask] = 1\n        volume_fractions[border_mask] = fraction_values\n\n        if partial_volume:\n            mask = filled_mask | border_mask\n        else:\n            mask = filled_mask\n\n        return mask, volume_fractions[mask]",
  "def define_rectangular_cuboid_structure_settings(start_mm: list, extent_mm: (int, list),\n                                                 molecular_composition: MolecularComposition, priority: int = 10,\n                                                 consider_partial_volume: bool = False,\n                                                 adhere_to_deformation: bool = False):\n    \"\"\"\n    TODO\n    \"\"\"\n    if isinstance(extent_mm, int):\n        extent_mm = [extent_mm, extent_mm, extent_mm]\n\n    return {\n        Tags.STRUCTURE_START_MM: start_mm,\n        Tags.STRUCTURE_X_EXTENT_MM: extent_mm[0],\n        Tags.STRUCTURE_Y_EXTENT_MM: extent_mm[1],\n        Tags.STRUCTURE_Z_EXTENT_MM: extent_mm[2],\n        Tags.PRIORITY: priority,\n        Tags.MOLECULE_COMPOSITION: molecular_composition,\n        Tags.CONSIDER_PARTIAL_VOLUME: consider_partial_volume,\n        Tags.ADHERE_TO_DEFORMATION: adhere_to_deformation,\n        Tags.STRUCTURE_TYPE: Tags.RECTANGULAR_CUBOID_STRUCTURE\n    }",
  "def get_params_from_settings(self, single_structure_settings):\n        params = (np.asarray(single_structure_settings[Tags.STRUCTURE_START_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_X_EXTENT_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_Y_EXTENT_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_Z_EXTENT_MM]),\n                  single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME])\n        return params",
  "def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_X_EXTENT_MM] = self.params[1]\n        settings[Tags.STRUCTURE_Y_EXTENT_MM] = self.params[2]\n        settings[Tags.STRUCTURE_Z_EXTENT_MM] = self.params[3]\n        settings[Tags.CONSIDER_PARTIAL_VOLUME] = self.params[4]\n        return settings",
  "def get_enclosed_indices(self):\n        start_mm, x_edge_mm, y_edge_mm, z_edge_mm, partial_volume = self.params\n        start_voxels = start_mm / self.voxel_spacing\n        x_edge_voxels = np.array([x_edge_mm / self.voxel_spacing, 0, 0])\n        y_edge_voxels = np.array([0, y_edge_mm / self.voxel_spacing, 0])\n        z_edge_voxels = np.array([0, 0, z_edge_mm / self.voxel_spacing])\n\n        x, y, z = np.meshgrid(np.arange(self.volume_dimensions_voxels[0]),\n                              np.arange(self.volume_dimensions_voxels[1]),\n                              np.arange(self.volume_dimensions_voxels[2]),\n                              indexing='ij')\n\n        target_vector = np.subtract(np.stack([x, y, z], axis=-1), start_voxels)\n\n        matrix = np.array([x_edge_voxels, y_edge_voxels, z_edge_voxels])\n\n        inverse_matrix = np.linalg.inv(matrix)\n\n        result = np.matmul(target_vector, inverse_matrix)\n\n        norm_vector = np.array([1/np.linalg.norm(x_edge_voxels),\n                                1/np.linalg.norm(y_edge_voxels),\n                                1/np.linalg.norm(z_edge_voxels)])\n\n        filled_mask_bool = (0 <= result) & (result <= 1 - norm_vector)\n        border_bool = (0 - norm_vector < result) & (result <= 1)\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n        filled_mask = np.all(filled_mask_bool, axis=-1)\n\n        border_mask = np.all(border_bool, axis=-1)\n\n        border_mask = np.logical_xor(border_mask, filled_mask)\n\n        edge_values = result[border_mask]\n\n        fraction_values = np.matmul(edge_values, matrix)\n\n        larger_fraction_values = (x_edge_voxels + y_edge_voxels + z_edge_voxels) - fraction_values\n\n        small_bool = fraction_values > 0\n        large_bool = larger_fraction_values >= 1\n\n        fraction_values[small_bool & large_bool] = 0\n        fraction_values[fraction_values <= 0] = 1 + fraction_values[fraction_values <= 0]\n        fraction_values[larger_fraction_values < 1] = larger_fraction_values[larger_fraction_values < 1]\n\n        fraction_values = np.abs(np.prod(fraction_values, axis=-1))\n\n        volume_fractions[filled_mask] = 1\n        volume_fractions[border_mask] = fraction_values\n\n        if partial_volume:\n            mask = filled_mask | border_mask\n        else:\n            mask = filled_mask\n\n        return mask, volume_fractions[mask]",
  "class CircularTubularStructure(GeometricalStructure):\n    \"\"\"\n    Defines a circular tube which is defined by a start and end point as well as a radius. This structure implements\n    partial volume effects. The tube can be set to adhere to a deformation defined by the\n    simpa.utils.deformation_manager. The start and end points of the tube will then be shifted along the z-axis\n    accordingly.\n    Example usage:\n\n        # single_structure_settings initialization\n        structure = Settings()\n\n        structure[Tags.PRIORITY] = 9\n        structure[Tags.STRUCTURE_START_MM] = [50, 0, 50]\n        structure[Tags.STRUCTURE_END_MM] = [50, 100, 50]\n        structure[Tags.STRUCTURE_RADIUS_MM] = 5\n        structure[Tags.MOLECULE_COMPOSITION] = TISSUE_LIBRARY.blood()\n        structure[Tags.CONSIDER_PARTIAL_VOLUME] = True\n        structure[Tags.ADHERE_TO_DEFORMATION] = True\n        structure[Tags.STRUCTURE_TYPE] = Tags.CIRCULAR_TUBULAR_STRUCTURE\n\n    \"\"\"\n\n    def get_params_from_settings(self, single_structure_settings):\n        params = (np.asarray(single_structure_settings[Tags.STRUCTURE_START_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_END_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_RADIUS_MM]),\n                  single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME])\n        return params\n\n    def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_END_MM] = self.params[1]\n        settings[Tags.STRUCTURE_RADIUS_MM] = self.params[2]\n        return settings\n\n    def get_enclosed_indices(self):\n        start_mm, end_mm, radius_mm, partial_volume = self.params\n        start_voxels = start_mm / self.voxel_spacing\n        end_voxels = end_mm / self.voxel_spacing\n        radius_voxels = radius_mm / self.voxel_spacing\n\n        x, y, z = np.meshgrid(np.arange(self.volume_dimensions_voxels[0]),\n                              np.arange(self.volume_dimensions_voxels[1]),\n                              np.arange(self.volume_dimensions_voxels[2]),\n                              indexing='ij')\n\n        x = x + 0.5\n        y = y + 0.5\n        z = z + 0.5\n\n        if partial_volume:\n            radius_margin = 0.5\n        else:\n            radius_margin = 0.7071\n\n        target_vector = np.subtract(np.stack([x, y, z], axis=-1), start_voxels)\n        if self.do_deformation:\n            # the deformation functional needs mm as inputs and returns the result in reverse indexing order...\n            deformation_values_mm = self.deformation_functional_mm(np.arange(self.volume_dimensions_voxels[0], step=1) *\n                                                                   self.voxel_spacing,\n                                                                   np.arange(self.volume_dimensions_voxels[1], step=1) *\n                                                                   self.voxel_spacing).T\n            deformation_values_mm = deformation_values_mm.reshape(self.volume_dimensions_voxels[0],\n                                                                  self.volume_dimensions_voxels[1], 1, 1)\n            deformation_values_mm = np.tile(deformation_values_mm, (1, 1, self.volume_dimensions_voxels[2], 3))\n            target_vector = target_vector + (deformation_values_mm / self.voxel_spacing)\n        cylinder_vector = np.subtract(end_voxels, start_voxels)\n\n        target_radius = np.linalg.norm(target_vector, axis=-1) * np.sin(\n            np.arccos((np.dot(target_vector, cylinder_vector)) /\n                      (np.linalg.norm(target_vector, axis=-1) * np.linalg.norm(cylinder_vector))))\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n\n        filled_mask = target_radius <= radius_voxels - 1 + radius_margin\n        border_mask = (target_radius > radius_voxels - 1 + radius_margin) & \\\n                      (target_radius < radius_voxels + 2 * radius_margin)\n\n        volume_fractions[filled_mask] = 1\n        volume_fractions[border_mask] = 1 - (target_radius - (radius_voxels - radius_margin))[border_mask]\n        volume_fractions[volume_fractions < 0] = 0\n\n        if partial_volume:\n            mask = filled_mask | border_mask\n        else:\n            mask = filled_mask\n\n        return mask, volume_fractions[mask]",
  "def define_circular_tubular_structure_settings(tube_start_mm: list,\n                                               tube_end_mm: list,\n                                               molecular_composition: MolecularComposition,\n                                               radius_mm: float = 2,\n                                               priority: int = 10,\n                                               consider_partial_volume: bool = False,\n                                               adhere_to_deformation: bool = False):\n    \"\"\"\n    TODO\n    \"\"\"\n    return {\n        Tags.STRUCTURE_START_MM: tube_start_mm,\n        Tags.STRUCTURE_END_MM: tube_end_mm,\n        Tags.STRUCTURE_RADIUS_MM: radius_mm,\n        Tags.PRIORITY: priority,\n        Tags.MOLECULE_COMPOSITION: molecular_composition,\n        Tags.CONSIDER_PARTIAL_VOLUME: consider_partial_volume,\n        Tags.ADHERE_TO_DEFORMATION: adhere_to_deformation,\n        Tags.STRUCTURE_TYPE: Tags.CIRCULAR_TUBULAR_STRUCTURE\n    }",
  "def get_params_from_settings(self, single_structure_settings):\n        params = (np.asarray(single_structure_settings[Tags.STRUCTURE_START_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_END_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_RADIUS_MM]),\n                  single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME])\n        return params",
  "def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_END_MM] = self.params[1]\n        settings[Tags.STRUCTURE_RADIUS_MM] = self.params[2]\n        return settings",
  "def get_enclosed_indices(self):\n        start_mm, end_mm, radius_mm, partial_volume = self.params\n        start_voxels = start_mm / self.voxel_spacing\n        end_voxels = end_mm / self.voxel_spacing\n        radius_voxels = radius_mm / self.voxel_spacing\n\n        x, y, z = np.meshgrid(np.arange(self.volume_dimensions_voxels[0]),\n                              np.arange(self.volume_dimensions_voxels[1]),\n                              np.arange(self.volume_dimensions_voxels[2]),\n                              indexing='ij')\n\n        x = x + 0.5\n        y = y + 0.5\n        z = z + 0.5\n\n        if partial_volume:\n            radius_margin = 0.5\n        else:\n            radius_margin = 0.7071\n\n        target_vector = np.subtract(np.stack([x, y, z], axis=-1), start_voxels)\n        if self.do_deformation:\n            # the deformation functional needs mm as inputs and returns the result in reverse indexing order...\n            deformation_values_mm = self.deformation_functional_mm(np.arange(self.volume_dimensions_voxels[0], step=1) *\n                                                                   self.voxel_spacing,\n                                                                   np.arange(self.volume_dimensions_voxels[1], step=1) *\n                                                                   self.voxel_spacing).T\n            deformation_values_mm = deformation_values_mm.reshape(self.volume_dimensions_voxels[0],\n                                                                  self.volume_dimensions_voxels[1], 1, 1)\n            deformation_values_mm = np.tile(deformation_values_mm, (1, 1, self.volume_dimensions_voxels[2], 3))\n            target_vector = target_vector + (deformation_values_mm / self.voxel_spacing)\n        cylinder_vector = np.subtract(end_voxels, start_voxels)\n\n        target_radius = np.linalg.norm(target_vector, axis=-1) * np.sin(\n            np.arccos((np.dot(target_vector, cylinder_vector)) /\n                      (np.linalg.norm(target_vector, axis=-1) * np.linalg.norm(cylinder_vector))))\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n\n        filled_mask = target_radius <= radius_voxels - 1 + radius_margin\n        border_mask = (target_radius > radius_voxels - 1 + radius_margin) & \\\n                      (target_radius < radius_voxels + 2 * radius_margin)\n\n        volume_fractions[filled_mask] = 1\n        volume_fractions[border_mask] = 1 - (target_radius - (radius_voxels - radius_margin))[border_mask]\n        volume_fractions[volume_fractions < 0] = 0\n\n        if partial_volume:\n            mask = filled_mask | border_mask\n        else:\n            mask = filled_mask\n\n        return mask, volume_fractions[mask]",
  "class EllipticalTubularStructure(GeometricalStructure):\n    \"\"\"\n    Defines a elliptical tube which is defined by a start and end point as well as a radius and an eccentricity. The\n    elliptical geometry corresponds to a circular tube of the specified radius which is compressed along the z-axis\n    until it reaches the specified eccentricity under the assumption of a constant volume. This structure implements\n    partial volume effects. The tube can be set to adhere to a deformation defined by the\n    simpa.utils.deformation_manager. The start and end points of the tube will then be shifted along the z-axis\n    accordingly.\n    Example usage:\n\n        # single_structure_settings initialization\n        structure = Settings()\n\n        structure[Tags.PRIORITY] = 9\n        structure[Tags.STRUCTURE_START_MM] = [50, 0, 50]\n        structure[Tags.STRUCTURE_END_MM] = [50, 100, 50]\n        structure[Tags.STRUCTURE_RADIUS_MM] = 5\n        structure[Tags.STRUCTURE_ECCENTRICITY] = 0.8\n        structure[Tags.MOLECULE_COMPOSITION] = TISSUE_LIBRARY.blood()\n        structure[Tags.CONSIDER_PARTIAL_VOLUME] = True\n        structure[Tags.ADHERE_TO_DEFORMATION] = True\n        structure[Tags.STRUCTURE_TYPE] = Tags.ELLIPTICAL_TUBULAR_STRUCTURE\n\n    \"\"\"\n\n    def get_params_from_settings(self, single_structure_settings):\n        params = (np.asarray(single_structure_settings[Tags.STRUCTURE_START_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_END_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_RADIUS_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_ECCENTRICITY]),\n                  np.asarray(single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME]))\n        return params\n\n    def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_END_MM] = self.params[1]\n        settings[Tags.STRUCTURE_RADIUS_MM] = self.params[2]\n        settings[Tags.STRUCTURE_ECCENTRICITY] = self.params[3]\n        settings[Tags.CONSIDER_PARTIAL_VOLUME] = self.params[4]\n        return settings\n\n    def get_enclosed_indices(self):\n        start_mm, end_mm, radius_mm, eccentricity, partial_volume = self.params\n\n        start_voxels = start_mm / self.voxel_spacing\n        end_voxels = end_mm / self.voxel_spacing\n        radius_voxels = radius_mm / self.voxel_spacing\n\n        x, y, z = np.meshgrid(np.arange(self.volume_dimensions_voxels[0]),\n                              np.arange(self.volume_dimensions_voxels[1]),\n                              np.arange(self.volume_dimensions_voxels[2]),\n                              indexing='ij')\n\n        x = x + 0.5\n        y = y + 0.5\n        z = z + 0.5\n\n        if partial_volume:\n            radius_margin = 0.5\n        else:\n            radius_margin = 0.7071\n\n        target_vector = np.subtract(np.stack([x, y, z], axis=-1), start_voxels)\n        if self.do_deformation:\n            # the deformation functional needs mm as inputs and returns the result in reverse indexing order...\n            deformation_values_mm = self.deformation_functional_mm(np.arange(self.volume_dimensions_voxels[0], step=1) *\n                                                                   self.voxel_spacing,\n                                                                   np.arange(self.volume_dimensions_voxels[1], step=1) *\n                                                                   self.voxel_spacing).T\n            deformation_values_mm = deformation_values_mm.reshape(self.volume_dimensions_voxels[0],\n                                                                  self.volume_dimensions_voxels[1], 1, 1)\n            deformation_values_mm = np.tile(deformation_values_mm, (1, 1, self.volume_dimensions_voxels[2], 3))\n            target_vector = target_vector + (deformation_values_mm / self.voxel_spacing)\n        cylinder_vector = np.subtract(end_voxels, start_voxels)\n\n        main_axis_length = radius_voxels/(1-eccentricity**2)**0.25\n        main_axis_vector = np.array([cylinder_vector[1], -cylinder_vector[0], 0])\n        main_axis_vector = main_axis_vector/np.linalg.norm(main_axis_vector) * main_axis_length\n\n        minor_axis_length = main_axis_length*np.sqrt(1-eccentricity**2)\n        minor_axis_vector = np.cross(cylinder_vector, main_axis_vector)\n        minor_axis_vector = minor_axis_vector / np.linalg.norm(minor_axis_vector) * minor_axis_length\n\n        dot_product = np.dot(target_vector, cylinder_vector)/np.linalg.norm(cylinder_vector)\n\n        target_vector_projection = np.multiply(dot_product[:, :, :, np.newaxis], cylinder_vector)\n        target_vector_from_projection = target_vector - target_vector_projection\n\n        main_projection = np.dot(target_vector_from_projection, main_axis_vector) / main_axis_length\n\n        minor_projection = np.dot(target_vector_from_projection, minor_axis_vector) / minor_axis_length\n\n        radius_crit = np.sqrt(((main_projection/main_axis_length)**2 + (minor_projection/minor_axis_length)**2) *\n                              radius_voxels**2)\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n        filled_mask = radius_crit <= radius_voxels - 1 + radius_margin\n        border_mask = (radius_crit > radius_voxels - 1 + radius_margin) & \\\n                      (radius_crit < radius_voxels + 2 * radius_margin)\n\n        volume_fractions[filled_mask] = 1\n        volume_fractions[border_mask] = 1 - (radius_crit - (radius_voxels - radius_margin))[border_mask]\n        volume_fractions[volume_fractions < 0] = 0\n        volume_fractions[volume_fractions < 0] = 0\n\n        if partial_volume:\n\n            mask = filled_mask | border_mask\n        else:\n            mask = filled_mask\n\n        return mask, volume_fractions[mask]",
  "def define_elliptical_tubular_structure_settings(tube_start_mm: list,\n                                                 tube_end_mm: list,\n                                                 molecular_composition: MolecularComposition,\n                                                 radius_mm: float = 2,\n                                                 eccentricity: float = 0.5,\n                                                 priority: int = 10,\n                                                 consider_partial_volume: bool = False,\n                                                 adhere_to_deformation: bool = False):\n    \"\"\"\n    TODO\n    \"\"\"\n    return {\n        Tags.STRUCTURE_START_MM: tube_start_mm,\n        Tags.STRUCTURE_END_MM: tube_end_mm,\n        Tags.STRUCTURE_RADIUS_MM: radius_mm,\n        Tags.STRUCTURE_ECCENTRICITY: eccentricity,\n        Tags.PRIORITY: priority,\n        Tags.MOLECULE_COMPOSITION: molecular_composition,\n        Tags.CONSIDER_PARTIAL_VOLUME: consider_partial_volume,\n        Tags.ADHERE_TO_DEFORMATION: adhere_to_deformation,\n        Tags.STRUCTURE_TYPE: Tags.ELLIPTICAL_TUBULAR_STRUCTURE\n    }",
  "def get_params_from_settings(self, single_structure_settings):\n        params = (np.asarray(single_structure_settings[Tags.STRUCTURE_START_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_END_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_RADIUS_MM]),\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_ECCENTRICITY]),\n                  np.asarray(single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME]))\n        return params",
  "def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_END_MM] = self.params[1]\n        settings[Tags.STRUCTURE_RADIUS_MM] = self.params[2]\n        settings[Tags.STRUCTURE_ECCENTRICITY] = self.params[3]\n        settings[Tags.CONSIDER_PARTIAL_VOLUME] = self.params[4]\n        return settings",
  "def get_enclosed_indices(self):\n        start_mm, end_mm, radius_mm, eccentricity, partial_volume = self.params\n\n        start_voxels = start_mm / self.voxel_spacing\n        end_voxels = end_mm / self.voxel_spacing\n        radius_voxels = radius_mm / self.voxel_spacing\n\n        x, y, z = np.meshgrid(np.arange(self.volume_dimensions_voxels[0]),\n                              np.arange(self.volume_dimensions_voxels[1]),\n                              np.arange(self.volume_dimensions_voxels[2]),\n                              indexing='ij')\n\n        x = x + 0.5\n        y = y + 0.5\n        z = z + 0.5\n\n        if partial_volume:\n            radius_margin = 0.5\n        else:\n            radius_margin = 0.7071\n\n        target_vector = np.subtract(np.stack([x, y, z], axis=-1), start_voxels)\n        if self.do_deformation:\n            # the deformation functional needs mm as inputs and returns the result in reverse indexing order...\n            deformation_values_mm = self.deformation_functional_mm(np.arange(self.volume_dimensions_voxels[0], step=1) *\n                                                                   self.voxel_spacing,\n                                                                   np.arange(self.volume_dimensions_voxels[1], step=1) *\n                                                                   self.voxel_spacing).T\n            deformation_values_mm = deformation_values_mm.reshape(self.volume_dimensions_voxels[0],\n                                                                  self.volume_dimensions_voxels[1], 1, 1)\n            deformation_values_mm = np.tile(deformation_values_mm, (1, 1, self.volume_dimensions_voxels[2], 3))\n            target_vector = target_vector + (deformation_values_mm / self.voxel_spacing)\n        cylinder_vector = np.subtract(end_voxels, start_voxels)\n\n        main_axis_length = radius_voxels/(1-eccentricity**2)**0.25\n        main_axis_vector = np.array([cylinder_vector[1], -cylinder_vector[0], 0])\n        main_axis_vector = main_axis_vector/np.linalg.norm(main_axis_vector) * main_axis_length\n\n        minor_axis_length = main_axis_length*np.sqrt(1-eccentricity**2)\n        minor_axis_vector = np.cross(cylinder_vector, main_axis_vector)\n        minor_axis_vector = minor_axis_vector / np.linalg.norm(minor_axis_vector) * minor_axis_length\n\n        dot_product = np.dot(target_vector, cylinder_vector)/np.linalg.norm(cylinder_vector)\n\n        target_vector_projection = np.multiply(dot_product[:, :, :, np.newaxis], cylinder_vector)\n        target_vector_from_projection = target_vector - target_vector_projection\n\n        main_projection = np.dot(target_vector_from_projection, main_axis_vector) / main_axis_length\n\n        minor_projection = np.dot(target_vector_from_projection, minor_axis_vector) / minor_axis_length\n\n        radius_crit = np.sqrt(((main_projection/main_axis_length)**2 + (minor_projection/minor_axis_length)**2) *\n                              radius_voxels**2)\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n        filled_mask = radius_crit <= radius_voxels - 1 + radius_margin\n        border_mask = (radius_crit > radius_voxels - 1 + radius_margin) & \\\n                      (radius_crit < radius_voxels + 2 * radius_margin)\n\n        volume_fractions[filled_mask] = 1\n        volume_fractions[border_mask] = 1 - (radius_crit - (radius_voxels - radius_margin))[border_mask]\n        volume_fractions[volume_fractions < 0] = 0\n        volume_fractions[volume_fractions < 0] = 0\n\n        if partial_volume:\n\n            mask = filled_mask | border_mask\n        else:\n            mask = filled_mask\n\n        return mask, volume_fractions[mask]",
  "class VesselStructure(GeometricalStructure):\n    \"\"\"\n    Defines a vessel tree that is generated randomly in the simulation volume. The generation process begins at the\n    start with a specified radius. The vessel grows roughly in the specified direction. The deviation is specified by\n    the curvature factor. Furthermore, the radius of the vessel can vary depending on the specified radius variation\n    factor. The bifurcation length defines how long a vessel can get until it will bifurcate. This structure implements\n    partial volume effects.\n    Example usage:\n\n        # single_structure_settings initialization\n        structure_settings = Settings()\n\n        structure_settings[Tags.PRIORITY] = 10\n        structure_settings[Tags.STRUCTURE_START_MM] = [50, 0, 50]\n        structure_settings[Tags.STRUCTURE_DIRECTION] = [0, 1, 0]\n        structure_settings[Tags.STRUCTURE_RADIUS_MM] = 4\n        structure_settings[Tags.STRUCTURE_CURVATURE_FACTOR] = 0.05\n        structure_settings[Tags.STRUCTURE_RADIUS_VARIATION_FACTOR] = 1\n        structure_settings[Tags.STRUCTURE_BIFURCATION_LENGTH_MM] = 70\n        structure_settings[Tags.MOLECULE_COMPOSITION] = TISSUE_LIBRARY.blood()\n        structure_settings[Tags.CONSIDER_PARTIAL_VOLUME] = True\n        structure_settings[Tags.STRUCTURE_TYPE] = Tags.VESSEL_STRUCTURE\n\n    \"\"\"\n\n    def get_params_from_settings(self, single_structure_settings):\n        params = (np.asarray(single_structure_settings[Tags.STRUCTURE_START_MM]),\n                  single_structure_settings[Tags.STRUCTURE_RADIUS_MM],\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_DIRECTION]),\n                  single_structure_settings[Tags.STRUCTURE_BIFURCATION_LENGTH_MM],\n                  single_structure_settings[Tags.STRUCTURE_CURVATURE_FACTOR],\n                  single_structure_settings[Tags.STRUCTURE_RADIUS_VARIATION_FACTOR],\n                  single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME])\n        return params\n\n    def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_RADIUS_MM] = self.params[1]\n        settings[Tags.STRUCTURE_DIRECTION] = self.params[2]\n        settings[Tags.STRUCTURE_BIFURCATION_LENGTH_MM] = self.params[3]\n        settings[Tags.STRUCTURE_CURVATURE_FACTOR] = self.params[4]\n        settings[Tags.STRUCTURE_RADIUS_VARIATION_FACTOR] = self.params[5]\n        settings[Tags.CONSIDER_PARTIAL_VOLUME] = self.params[6]\n        return settings\n\n    def fill_internal_volume(self):\n        self.geometrical_volume = self.get_enclosed_indices()\n\n    def calculate_vessel_samples(self, position, direction, bifurcation_length, radius, radius_variation,\n                                 volume_dimensions, curvature_factor):\n        position_array = [position]\n        radius_array = [radius]\n        samples = 0\n\n        while np.all(position < volume_dimensions) and np.all(0 <= position):\n            if samples >= bifurcation_length:\n                vessel_branch_positions1 = position\n                vessel_branch_positions2 = position\n                angles = np.random.normal(np.pi / 16, np.pi / 8, 3)\n                vessel_branch_directions1 = np.squeeze(np.array(np.matmul(rotation(angles), direction)))\n                vessel_branch_directions2 = np.squeeze(np.array(np.matmul(rotation(-angles), direction)))\n                vessel_branch_radius1 = 1 / np.sqrt(2) * radius\n                vessel_branch_radius2 = 1 / np.sqrt(2) * radius\n                vessel_branch_radius_variation1 = 1 / np.sqrt(2) * radius_variation\n                vessel_branch_radius_variation2 = 1 / np.sqrt(2) * radius_variation\n\n                if vessel_branch_radius1 >= 0.5:\n                    vessel1_pos, vessel1_rad = self.calculate_vessel_samples(vessel_branch_positions1,\n                                                                             vessel_branch_directions1,\n                                                                             bifurcation_length,\n                                                                             vessel_branch_radius1,\n                                                                             vessel_branch_radius_variation1,\n                                                                             volume_dimensions, curvature_factor)\n                    position_array += vessel1_pos\n                    radius_array += vessel1_rad\n\n                if vessel_branch_radius2 >= 0.5:\n                    vessel2_pos, vessel2_rad = self.calculate_vessel_samples(vessel_branch_positions2,\n                                                                             vessel_branch_directions2,\n                                                                             bifurcation_length,\n                                                                             vessel_branch_radius2,\n                                                                             vessel_branch_radius_variation2,\n                                                                             volume_dimensions, curvature_factor)\n                    position_array += vessel2_pos\n                    radius_array += vessel2_rad\n                break\n\n            position = np.add(position, direction)\n            position_array.append(position)\n            radius_array.append(np.random.uniform(-1, 1) * radius_variation + radius)\n\n            step_vector = np.random.uniform(-1, 1, 3)\n            step_vector = direction + curvature_factor * step_vector\n            direction = step_vector / np.linalg.norm(step_vector)\n            samples += 1\n\n        return position_array, radius_array\n\n    def get_enclosed_indices(self):\n        start_mm, radius_mm, direction_mm, bifurcation_length_mm, curvature_factor, \\\n            radius_variation_factor, partial_volume = self.params\n        start_voxels = start_mm / self.voxel_spacing\n        radius_voxels = radius_mm / self.voxel_spacing\n        direction_voxels = direction_mm / self.voxel_spacing\n        direction_vector_voxels = direction_voxels / np.linalg.norm(direction_voxels)\n        bifurcation_length_voxels = bifurcation_length_mm / self.voxel_spacing\n\n        position_array, radius_array = self.calculate_vessel_samples(start_voxels, direction_vector_voxels,\n                                                                     bifurcation_length_voxels, radius_voxels,\n                                                                     radius_variation_factor,\n                                                                     self.volume_dimensions_voxels,\n                                                                     curvature_factor)\n\n        position_array = np.array(position_array)\n\n        x, y, z = np.ogrid[0:self.volume_dimensions_voxels[0],\n                           0:self.volume_dimensions_voxels[1],\n                           0:self.volume_dimensions_voxels[2]]\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n\n        if partial_volume:\n            radius_margin = 0.5\n        else:\n            radius_margin = 0.7071\n\n        for position, radius in zip(position_array, radius_array):\n            target_radius = np.sqrt((x - position[0]) ** 2 + (y - position[1]) ** 2 + (z - position[2]) ** 2)\n\n            filled_mask = target_radius <= radius - 1 + radius_margin\n            border_mask = (target_radius > radius - 1 + radius_margin) & \\\n                          (target_radius < radius + 2 * radius_margin)\n\n            volume_fractions[filled_mask] = 1\n            old_border_values = volume_fractions[border_mask]\n            new_border_values = 1 - (target_radius - (radius - radius_margin))[border_mask]\n            volume_fractions[border_mask] = np.maximum(old_border_values, new_border_values)\n\n        return volume_fractions",
  "def define_vessel_structure_settings(vessel_start_mm: list,\n                                     vessel_direction_mm: list,\n                                     molecular_composition: MolecularComposition,\n                                     radius_mm: float = 2,\n                                     curvature_factor: float = 0.05,\n                                     radius_variation_factor: float = 1.0,\n                                     bifurcation_length_mm: float = 7,\n                                     priority: int = 10,\n                                     consider_partial_volume: bool = False,\n                                     adhere_to_deformation: bool = False):\n    \"\"\"\n    TODO\n    \"\"\"\n    return {\n        Tags.STRUCTURE_START_MM: vessel_start_mm,\n        Tags.STRUCTURE_DIRECTION: vessel_direction_mm,\n        Tags.STRUCTURE_RADIUS_MM: radius_mm,\n        Tags.STRUCTURE_CURVATURE_FACTOR: curvature_factor,\n        Tags.STRUCTURE_RADIUS_VARIATION_FACTOR: radius_variation_factor,\n        Tags.STRUCTURE_BIFURCATION_LENGTH_MM: bifurcation_length_mm,\n        Tags.PRIORITY: priority,\n        Tags.MOLECULE_COMPOSITION: molecular_composition,\n        Tags.CONSIDER_PARTIAL_VOLUME: consider_partial_volume,\n        Tags.ADHERE_TO_DEFORMATION: adhere_to_deformation,\n        Tags.STRUCTURE_TYPE: Tags.VESSEL_STRUCTURE\n    }",
  "def get_params_from_settings(self, single_structure_settings):\n        params = (np.asarray(single_structure_settings[Tags.STRUCTURE_START_MM]),\n                  single_structure_settings[Tags.STRUCTURE_RADIUS_MM],\n                  np.asarray(single_structure_settings[Tags.STRUCTURE_DIRECTION]),\n                  single_structure_settings[Tags.STRUCTURE_BIFURCATION_LENGTH_MM],\n                  single_structure_settings[Tags.STRUCTURE_CURVATURE_FACTOR],\n                  single_structure_settings[Tags.STRUCTURE_RADIUS_VARIATION_FACTOR],\n                  single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME])\n        return params",
  "def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_RADIUS_MM] = self.params[1]\n        settings[Tags.STRUCTURE_DIRECTION] = self.params[2]\n        settings[Tags.STRUCTURE_BIFURCATION_LENGTH_MM] = self.params[3]\n        settings[Tags.STRUCTURE_CURVATURE_FACTOR] = self.params[4]\n        settings[Tags.STRUCTURE_RADIUS_VARIATION_FACTOR] = self.params[5]\n        settings[Tags.CONSIDER_PARTIAL_VOLUME] = self.params[6]\n        return settings",
  "def fill_internal_volume(self):\n        self.geometrical_volume = self.get_enclosed_indices()",
  "def calculate_vessel_samples(self, position, direction, bifurcation_length, radius, radius_variation,\n                                 volume_dimensions, curvature_factor):\n        position_array = [position]\n        radius_array = [radius]\n        samples = 0\n\n        while np.all(position < volume_dimensions) and np.all(0 <= position):\n            if samples >= bifurcation_length:\n                vessel_branch_positions1 = position\n                vessel_branch_positions2 = position\n                angles = np.random.normal(np.pi / 16, np.pi / 8, 3)\n                vessel_branch_directions1 = np.squeeze(np.array(np.matmul(rotation(angles), direction)))\n                vessel_branch_directions2 = np.squeeze(np.array(np.matmul(rotation(-angles), direction)))\n                vessel_branch_radius1 = 1 / np.sqrt(2) * radius\n                vessel_branch_radius2 = 1 / np.sqrt(2) * radius\n                vessel_branch_radius_variation1 = 1 / np.sqrt(2) * radius_variation\n                vessel_branch_radius_variation2 = 1 / np.sqrt(2) * radius_variation\n\n                if vessel_branch_radius1 >= 0.5:\n                    vessel1_pos, vessel1_rad = self.calculate_vessel_samples(vessel_branch_positions1,\n                                                                             vessel_branch_directions1,\n                                                                             bifurcation_length,\n                                                                             vessel_branch_radius1,\n                                                                             vessel_branch_radius_variation1,\n                                                                             volume_dimensions, curvature_factor)\n                    position_array += vessel1_pos\n                    radius_array += vessel1_rad\n\n                if vessel_branch_radius2 >= 0.5:\n                    vessel2_pos, vessel2_rad = self.calculate_vessel_samples(vessel_branch_positions2,\n                                                                             vessel_branch_directions2,\n                                                                             bifurcation_length,\n                                                                             vessel_branch_radius2,\n                                                                             vessel_branch_radius_variation2,\n                                                                             volume_dimensions, curvature_factor)\n                    position_array += vessel2_pos\n                    radius_array += vessel2_rad\n                break\n\n            position = np.add(position, direction)\n            position_array.append(position)\n            radius_array.append(np.random.uniform(-1, 1) * radius_variation + radius)\n\n            step_vector = np.random.uniform(-1, 1, 3)\n            step_vector = direction + curvature_factor * step_vector\n            direction = step_vector / np.linalg.norm(step_vector)\n            samples += 1\n\n        return position_array, radius_array",
  "def get_enclosed_indices(self):\n        start_mm, radius_mm, direction_mm, bifurcation_length_mm, curvature_factor, \\\n            radius_variation_factor, partial_volume = self.params\n        start_voxels = start_mm / self.voxel_spacing\n        radius_voxels = radius_mm / self.voxel_spacing\n        direction_voxels = direction_mm / self.voxel_spacing\n        direction_vector_voxels = direction_voxels / np.linalg.norm(direction_voxels)\n        bifurcation_length_voxels = bifurcation_length_mm / self.voxel_spacing\n\n        position_array, radius_array = self.calculate_vessel_samples(start_voxels, direction_vector_voxels,\n                                                                     bifurcation_length_voxels, radius_voxels,\n                                                                     radius_variation_factor,\n                                                                     self.volume_dimensions_voxels,\n                                                                     curvature_factor)\n\n        position_array = np.array(position_array)\n\n        x, y, z = np.ogrid[0:self.volume_dimensions_voxels[0],\n                           0:self.volume_dimensions_voxels[1],\n                           0:self.volume_dimensions_voxels[2]]\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n\n        if partial_volume:\n            radius_margin = 0.5\n        else:\n            radius_margin = 0.7071\n\n        for position, radius in zip(position_array, radius_array):\n            target_radius = np.sqrt((x - position[0]) ** 2 + (y - position[1]) ** 2 + (z - position[2]) ** 2)\n\n            filled_mask = target_radius <= radius - 1 + radius_margin\n            border_mask = (target_radius > radius - 1 + radius_margin) & \\\n                          (target_radius < radius + 2 * radius_margin)\n\n            volume_fractions[filled_mask] = 1\n            old_border_values = volume_fractions[border_mask]\n            new_border_values = 1 - (target_radius - (radius - radius_margin))[border_mask]\n            volume_fractions[border_mask] = np.maximum(old_border_values, new_border_values)\n\n        return volume_fractions",
  "class Background(GeometricalStructure):\n    \"\"\"\n    Defines a background that fills the whole simulation volume. It is always given the priority of 0 so that other\n    structures can overwrite it when necessary.\n\n    Example usage::\n\n        background_dictionary = Settings()\n        background_dictionary[Tags.MOLECULE_COMPOSITION] = TISSUE_LIBRARY.constant(0.1, 100.0, 0.9)\n        background_dictionary[Tags.STRUCTURE_TYPE] = Tags.BACKGROUND\n    \"\"\"\n\n    def get_enclosed_indices(self):\n        array = np.ones((self.volume_dimensions_voxels[0],\n                         self.volume_dimensions_voxels[1],\n                         self.volume_dimensions_voxels[2]))\n        return array == 1, 1\n\n    def get_params_from_settings(self, single_structure_settings):\n        return None\n\n    def __init__(self, global_settings: Settings, background_settings: Settings = None):\n\n        if background_settings is not None:\n            background_settings[Tags.PRIORITY] = 0\n            background_settings[Tags.CONSIDER_PARTIAL_VOLUME] = False\n            super().__init__(global_settings, background_settings)\n        else:\n            super().__init__(global_settings)\n            self.priority = 0\n            self.partial_volume = True\n\n    def to_settings(self) -> dict:\n        settings_dict = super().to_settings()\n        return settings_dict",
  "def define_background_structure_settings(molecular_composition: MolecularComposition):\n    \"\"\"\n    TODO\n    \"\"\"\n    return {\n        Tags.MOLECULE_COMPOSITION: molecular_composition,\n        Tags.STRUCTURE_TYPE: Tags.BACKGROUND\n    }",
  "def get_enclosed_indices(self):\n        array = np.ones((self.volume_dimensions_voxels[0],\n                         self.volume_dimensions_voxels[1],\n                         self.volume_dimensions_voxels[2]))\n        return array == 1, 1",
  "def get_params_from_settings(self, single_structure_settings):\n        return None",
  "def __init__(self, global_settings: Settings, background_settings: Settings = None):\n\n        if background_settings is not None:\n            background_settings[Tags.PRIORITY] = 0\n            background_settings[Tags.CONSIDER_PARTIAL_VOLUME] = False\n            super().__init__(global_settings, background_settings)\n        else:\n            super().__init__(global_settings)\n            self.priority = 0\n            self.partial_volume = True",
  "def to_settings(self) -> dict:\n        settings_dict = super().to_settings()\n        return settings_dict",
  "class HorizontalLayerStructure(GeometricalStructure):\n    \"\"\"\n    Defines a Layer structure which spans the xy-plane in the SIMPA axis convention. The thickness of the layer is\n    defined along the z-axis. This layer can be deformed by the simpa.utils.deformation_manager.\n    Example usage:\n\n        # single_structure_settings initialization\n        structure = Settings()\n\n        structure[Tags.PRIORITY] = 10\n        structure[Tags.STRUCTURE_START_MM] = [0, 0, 0]\n        structure[Tags.STRUCTURE_END_MM] = [0, 0, 100]\n        structure[Tags.MOLECULE_COMPOSITION] = TISSUE_LIBRARY.epidermis()\n        structure[Tags.CONSIDER_PARTIAL_VOLUME] = True\n        structure[Tags.ADHERE_TO_DEFORMATION] = True\n        structure[Tags.STRUCTURE_TYPE] = Tags.HORIZONTAL_LAYER_STRUCTURE\n\n    \"\"\"\n\n    def get_params_from_settings(self, single_structure_settings):\n        params = (single_structure_settings[Tags.STRUCTURE_START_MM],\n                  single_structure_settings[Tags.STRUCTURE_END_MM],\n                  single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME])\n        return params\n\n    def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_END_MM] = self.params[1]\n        return settings\n\n    def get_enclosed_indices(self):\n        start_mm = np.asarray(self.params[0])\n        end_mm = np.asarray(self.params[1])\n        partial_volume = self.params[2]\n        start_voxels = start_mm / self.voxel_spacing\n        direction_mm = end_mm - start_mm\n        depth_voxels = direction_mm[2] / self.voxel_spacing\n\n        if direction_mm[0] != 0 or direction_mm[1] != 0 or direction_mm[2] == 0:\n            raise ValueError(\"Horizontal Layer structure needs a start and end vector in the form of [0, 0, n].\")\n\n        x, y, z = np.meshgrid(np.arange(self.volume_dimensions_voxels[0]),\n                              np.arange(self.volume_dimensions_voxels[1]),\n                              np.arange(self.volume_dimensions_voxels[2]),\n                              indexing='ij')\n\n        target_vector_voxels = np.subtract(np.stack([x, y, z], axis=-1), start_voxels)\n        target_vector_voxels = target_vector_voxels[:, :, :, 2]\n        if self.do_deformation:\n            # the deformation functional needs mm as inputs and returns the result in reverse indexing order...\n            deformation_values_mm = self.deformation_functional_mm(np.arange(self.volume_dimensions_voxels[0], step=1) *\n                                                                   self.voxel_spacing,\n                                                                   np.arange(self.volume_dimensions_voxels[1], step=1) *\n                                                                   self.voxel_spacing).T\n            target_vector_voxels = target_vector_voxels + (deformation_values_mm.reshape(\n                self.volume_dimensions_voxels[0],\n                self.volume_dimensions_voxels[1], 1) / self.voxel_spacing)\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n\n        if partial_volume:\n            bools_first_layer = ((target_vector_voxels >= -1) & (target_vector_voxels < 0))\n\n            volume_fractions[bools_first_layer] = 1 - np.abs(target_vector_voxels[bools_first_layer])\n\n            initial_fractions = np.max(volume_fractions, axis=2, keepdims=True)\n            floored_depth_voxels = np.floor(depth_voxels - initial_fractions)\n\n            bools_fully_filled_layers = ((target_vector_voxels >= 0) & (target_vector_voxels < floored_depth_voxels))\n\n            bools_last_layer = ((target_vector_voxels >= floored_depth_voxels) &\n                                (target_vector_voxels <= floored_depth_voxels + 1))\n\n            volume_fractions[bools_last_layer] = depth_voxels - target_vector_voxels[bools_last_layer]\n            volume_fractions[volume_fractions > depth_voxels] = depth_voxels\n            volume_fractions[volume_fractions < 0] = 0\n\n            bools_all_layers = bools_first_layer | bools_last_layer | bools_fully_filled_layers\n\n        else:\n            bools_fully_filled_layers = ((target_vector_voxels >= -0.5) & (target_vector_voxels < depth_voxels - 0.5))\n\n            bools_all_layers = bools_fully_filled_layers\n\n        volume_fractions[bools_fully_filled_layers] = 1\n\n        return bools_all_layers, volume_fractions[bools_all_layers]",
  "def define_horizontal_layer_structure_settings(molecular_composition: MolecularComposition,\n                                               z_start_mm: float = 0, thickness_mm: float = 0, priority: int = 10,\n                                               consider_partial_volume: bool = False,\n                                               adhere_to_deformation: bool = False):\n    \"\"\"\n    TODO\n    \"\"\"\n    return {\n        Tags.STRUCTURE_START_MM: [0, 0, z_start_mm],\n        Tags.STRUCTURE_END_MM: [0, 0, z_start_mm+thickness_mm],\n        Tags.PRIORITY: priority,\n        Tags.MOLECULE_COMPOSITION: molecular_composition,\n        Tags.CONSIDER_PARTIAL_VOLUME: consider_partial_volume,\n        Tags.ADHERE_TO_DEFORMATION: adhere_to_deformation,\n        Tags.STRUCTURE_TYPE: Tags.HORIZONTAL_LAYER_STRUCTURE\n    }",
  "def get_params_from_settings(self, single_structure_settings):\n        params = (single_structure_settings[Tags.STRUCTURE_START_MM],\n                  single_structure_settings[Tags.STRUCTURE_END_MM],\n                  single_structure_settings[Tags.CONSIDER_PARTIAL_VOLUME])\n        return params",
  "def to_settings(self):\n        settings = super().to_settings()\n        settings[Tags.STRUCTURE_START_MM] = self.params[0]\n        settings[Tags.STRUCTURE_END_MM] = self.params[1]\n        return settings",
  "def get_enclosed_indices(self):\n        start_mm = np.asarray(self.params[0])\n        end_mm = np.asarray(self.params[1])\n        partial_volume = self.params[2]\n        start_voxels = start_mm / self.voxel_spacing\n        direction_mm = end_mm - start_mm\n        depth_voxels = direction_mm[2] / self.voxel_spacing\n\n        if direction_mm[0] != 0 or direction_mm[1] != 0 or direction_mm[2] == 0:\n            raise ValueError(\"Horizontal Layer structure needs a start and end vector in the form of [0, 0, n].\")\n\n        x, y, z = np.meshgrid(np.arange(self.volume_dimensions_voxels[0]),\n                              np.arange(self.volume_dimensions_voxels[1]),\n                              np.arange(self.volume_dimensions_voxels[2]),\n                              indexing='ij')\n\n        target_vector_voxels = np.subtract(np.stack([x, y, z], axis=-1), start_voxels)\n        target_vector_voxels = target_vector_voxels[:, :, :, 2]\n        if self.do_deformation:\n            # the deformation functional needs mm as inputs and returns the result in reverse indexing order...\n            deformation_values_mm = self.deformation_functional_mm(np.arange(self.volume_dimensions_voxels[0], step=1) *\n                                                                   self.voxel_spacing,\n                                                                   np.arange(self.volume_dimensions_voxels[1], step=1) *\n                                                                   self.voxel_spacing).T\n            target_vector_voxels = target_vector_voxels + (deformation_values_mm.reshape(\n                self.volume_dimensions_voxels[0],\n                self.volume_dimensions_voxels[1], 1) / self.voxel_spacing)\n\n        volume_fractions = np.zeros(self.volume_dimensions_voxels)\n\n        if partial_volume:\n            bools_first_layer = ((target_vector_voxels >= -1) & (target_vector_voxels < 0))\n\n            volume_fractions[bools_first_layer] = 1 - np.abs(target_vector_voxels[bools_first_layer])\n\n            initial_fractions = np.max(volume_fractions, axis=2, keepdims=True)\n            floored_depth_voxels = np.floor(depth_voxels - initial_fractions)\n\n            bools_fully_filled_layers = ((target_vector_voxels >= 0) & (target_vector_voxels < floored_depth_voxels))\n\n            bools_last_layer = ((target_vector_voxels >= floored_depth_voxels) &\n                                (target_vector_voxels <= floored_depth_voxels + 1))\n\n            volume_fractions[bools_last_layer] = depth_voxels - target_vector_voxels[bools_last_layer]\n            volume_fractions[volume_fractions > depth_voxels] = depth_voxels\n            volume_fractions[volume_fractions < 0] = 0\n\n            bools_all_layers = bools_first_layer | bools_last_layer | bools_fully_filled_layers\n\n        else:\n            bools_fully_filled_layers = ((target_vector_voxels >= -0.5) & (target_vector_voxels < depth_voxels - 0.5))\n\n            bools_all_layers = bools_fully_filled_layers\n\n        volume_fractions[bools_fully_filled_layers] = 1\n\n        return bools_all_layers, volume_fractions[bools_all_layers]",
  "class Structures:\n    \"\"\"\n    TODO\n    \"\"\"\n\n    def __init__(self, settings: Settings, volume_creator_settings: dict):\n        \"\"\"\n        TODO\n        \"\"\"\n        self.logger = Logger()\n        self.structures = self.from_settings(settings, volume_creator_settings)\n        self.sorted_structures = sorted(self.structures, key=operator.attrgetter('priority'), reverse=True)\n\n    def from_settings(self, global_settings, volume_creator_settings):\n        structures = list()\n        if not Tags.STRUCTURES in volume_creator_settings:\n            self.logger.warning(\"Did not find any structure definitions in the settings file!\")\n            return structures\n        _structure_settings = volume_creator_settings[Tags.STRUCTURES]\n        for struc_tag_name in _structure_settings:\n            single_structure_settings = _structure_settings[struc_tag_name]\n            try:\n                structure_class = globals()[single_structure_settings[Tags.STRUCTURE_TYPE]]\n                structure = structure_class(global_settings, single_structure_settings)\n                structures.append(structure)\n            except Exception as e:\n                self.logger.critical(\"An exception has occurred while trying to parse \" +\n                                     str(single_structure_settings[Tags.STRUCTURE_TYPE]) +\n                                     \" from the dictionary.\")\n                self.logger.critical(\"The structure type was \" + str(single_structure_settings[Tags.STRUCTURE_TYPE]))\n                self.logger.critical(traceback.format_exc())\n                self.logger.critical(\"trying to continue as normal...\")\n                raise e\n\n        return structures",
  "def __init__(self, settings: Settings, volume_creator_settings: dict):\n        \"\"\"\n        TODO\n        \"\"\"\n        self.logger = Logger()\n        self.structures = self.from_settings(settings, volume_creator_settings)\n        self.sorted_structures = sorted(self.structures, key=operator.attrgetter('priority'), reverse=True)",
  "def from_settings(self, global_settings, volume_creator_settings):\n        structures = list()\n        if not Tags.STRUCTURES in volume_creator_settings:\n            self.logger.warning(\"Did not find any structure definitions in the settings file!\")\n            return structures\n        _structure_settings = volume_creator_settings[Tags.STRUCTURES]\n        for struc_tag_name in _structure_settings:\n            single_structure_settings = _structure_settings[struc_tag_name]\n            try:\n                structure_class = globals()[single_structure_settings[Tags.STRUCTURE_TYPE]]\n                structure = structure_class(global_settings, single_structure_settings)\n                structures.append(structure)\n            except Exception as e:\n                self.logger.critical(\"An exception has occurred while trying to parse \" +\n                                     str(single_structure_settings[Tags.STRUCTURE_TYPE]) +\n                                     \" from the dictionary.\")\n                self.logger.critical(\"The structure type was \" + str(single_structure_settings[Tags.STRUCTURE_TYPE]))\n                self.logger.critical(traceback.format_exc())\n                self.logger.critical(\"trying to continue as normal...\")\n                raise e\n\n        return structures",
  "def assert_equal_shapes(numpy_arrays: list):\n    \"\"\"\n    This method takes a list of n-dimensional numpy arrays and raises an AssertionError if the sizes of all arrays do\n    not match.\n\n    :param numpy_arrays: a list of np.ndarray\n    :raises AssertionError: if there is a mismatch between any of the volume dimensions.\n    \"\"\"\n\n    if len(numpy_arrays) < 2:\n        return\n\n    shapes = np.asarray([np.shape(_arr) for _arr in numpy_arrays]).astype(float)\n    mean = np.mean(shapes, axis=0)\n    for i in range(len(shapes)):\n        shapes[i, :] = shapes[i, :] - mean\n\n    if not np.sum(np.abs(shapes)) <= 1e-5:\n        raise AssertionError(\"The given volumes did not all have the same\"\n                             \" dimensions. Please double check the simulation\"\n                             f\" parameters. Called from {inspect.stack()[1].function}\")",
  "def assert_array_well_defined(array: np.ndarray, assume_non_negativity: bool = False,\n                              assume_positivity=False, array_name: str = None):\n    \"\"\"\n    This method tests if all entries of the given array are well-defined (i.e. not np.inf, np.nan, or None).\n    The method can be parametrised to be more strict.\n\n    :param array: The input np.ndarray\n    :param assume_non_negativity: bool (default: False). If true, all values must be greater than or equal to 0.\n    :param assume_positivity: bool (default: False). If true, all values must be greater than 0.\n    :param array_name: a string that gives more information in case of an error.\n    :raises AssertionError: if there are any unexpected values in the given array.\n    \"\"\"\n\n    if array_name is None:\n        array_name = \"'Not specified'\"\n    caller = inspect.stack()[1]\n    stack_string = f\" \\n\\tArray Name: {array_name} \\n\\tCaller: {caller.filename}\" \\\n                   f\" \\n\\tline: {caller.lineno} \\n\\tcode: {caller.code_context}\"\n\n    if np.isinf(array).any() or np.isneginf(array).any():\n        raise AssertionError(\"The given array contained values that were inf or -inf.\"\n                             f\" Info: {stack_string}.\")\n\n    if np.isnan(array).any():\n        raise AssertionError(\"The given array contained values that were nan.\"\n                             f\" Info: {stack_string}.\")\n\n    if assume_positivity and (array <= 0).any():\n        raise AssertionError(\"The given array contained values that were not positive.\"\n                             f\" Info: {stack_string}.\")\n\n    if assume_non_negativity and (array < 0).any():\n        raise AssertionError(\"The given array contained values that were negative.\"\n                             f\" Info: {stack_string}.\")",
  "class Logger(SerializableSIMPAClass):\n    \"\"\"\n    The SIMPA Logger.\n    The purpose of this class is to guarantee that the logging Config has been set and that logging strings are written\n    to the same file throughout the entire simulation pipeline.\n    Per default, the log file is located in the home directory as defined by Path.home().\n\n    The log levels are defined the same way they are in the python logging module:\n    DEBUG: Detailed information, typically of interest only when diagnosing problems.\n    INFO: Confirmation that things are working as expected.\n    WARNING: An indication that something unexpected happened, or indicative of some problem in the near future\n    (e.g. \u2018disk space low\u2019). The software is still working as expected.\n    ERROR: Due to a more serious problem, the software has not been able to perform some function.\n    CRITICAL: A serious error, indicating that the program itself may be unable to continue running.\n    \"\"\"\n    _instance = None\n    _simpa_logging_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n    _simpa_default_logging_path = str(Path.home())+\"/simpa.log\"\n    _logger = None\n\n    def __new__(cls, path=None, force_new_instance=False, startup_verbose=False):\n        # This pattern can be used to realise a singleton implementation in Python\n        if cls._instance is None or force_new_instance:\n            cls._instance = super(Logger, cls).__new__(cls)\n\n            if path is None:\n                path = cls._simpa_default_logging_path\n\n            cls._logger = logging.getLogger(\"SIMPA Logger\")\n            cls._logger.setLevel(logging.DEBUG)\n\n            console_handler = logging.StreamHandler(stream=sys.stdout)\n            file_handler = logging.FileHandler(path, mode=\"w\")\n\n            console_handler.setLevel(logging.DEBUG)\n            file_handler.setLevel(logging.DEBUG)\n\n            console_handler.setFormatter(cls._simpa_logging_formatter)\n            file_handler.setFormatter(cls._simpa_logging_formatter)\n\n            cls._logger.addHandler(console_handler)\n            cls._logger.addHandler(file_handler)\n\n            if startup_verbose:\n                cls._logger.debug(\"##############################\")\n                cls._logger.debug(\"NEW SIMULATION SESSION STARTED\")\n                cls._logger.debug(\"##############################\")\n\n        return cls._instance\n\n    def debug(self, msg):\n        \"\"\"\n        Logs a debug message to the logging system.\n        DEBUG: Detailed information, typically of interest only when diagnosing problems.\n\n        :param msg: the message to log\n        \"\"\"\n        self._logger.debug(msg)\n\n    def info(self, msg):\n        \"\"\"\n        Logs an info message to the logging system.\n        INFO: Confirmation that things are working as expected.\n\n        :param msg: the message to log\n        \"\"\"\n        self._logger.info(msg)\n\n    def warning(self, msg):\n        \"\"\"\n        Logs a warning message to the logging system.\n        WARNING: An indication that something unexpected happened, or indicative of some problem\n        in the near future (e.g. \u2018disk space low\u2019). The software is still working as expected.\n\n        :param msg: the message to log\n        \"\"\"\n        self._logger.warning(msg)\n\n    def error(self, msg):\n        \"\"\"\n        Logs an error message to the logging system.\n        ERROR: Due to a more serious problem, the software has not been able to perform some function.\n\n        :param msg: the message to log\n        \"\"\"\n        self._logger.error(msg)\n\n    def critical(self, msg):\n        \"\"\"\n        Logs a critical message to the logging system.\n        CRITICAL: A serious error, indicating that the program itself may be unable to continue running.\n\n        :param msg: the message to log\n        \"\"\"\n        self._logger.critical(msg)\n\n    def serialize(self) -> dict:\n        return {\"Logger\": {\"Logger\": 1}}\n\n    @staticmethod\n    def deserialize(dictionary_to_deserialize):\n        deserialized_logger = Logger()\n        return deserialized_logger",
  "def __new__(cls, path=None, force_new_instance=False, startup_verbose=False):\n        # This pattern can be used to realise a singleton implementation in Python\n        if cls._instance is None or force_new_instance:\n            cls._instance = super(Logger, cls).__new__(cls)\n\n            if path is None:\n                path = cls._simpa_default_logging_path\n\n            cls._logger = logging.getLogger(\"SIMPA Logger\")\n            cls._logger.setLevel(logging.DEBUG)\n\n            console_handler = logging.StreamHandler(stream=sys.stdout)\n            file_handler = logging.FileHandler(path, mode=\"w\")\n\n            console_handler.setLevel(logging.DEBUG)\n            file_handler.setLevel(logging.DEBUG)\n\n            console_handler.setFormatter(cls._simpa_logging_formatter)\n            file_handler.setFormatter(cls._simpa_logging_formatter)\n\n            cls._logger.addHandler(console_handler)\n            cls._logger.addHandler(file_handler)\n\n            if startup_verbose:\n                cls._logger.debug(\"##############################\")\n                cls._logger.debug(\"NEW SIMULATION SESSION STARTED\")\n                cls._logger.debug(\"##############################\")\n\n        return cls._instance",
  "def debug(self, msg):\n        \"\"\"\n        Logs a debug message to the logging system.\n        DEBUG: Detailed information, typically of interest only when diagnosing problems.\n\n        :param msg: the message to log\n        \"\"\"\n        self._logger.debug(msg)",
  "def info(self, msg):\n        \"\"\"\n        Logs an info message to the logging system.\n        INFO: Confirmation that things are working as expected.\n\n        :param msg: the message to log\n        \"\"\"\n        self._logger.info(msg)",
  "def warning(self, msg):\n        \"\"\"\n        Logs a warning message to the logging system.\n        WARNING: An indication that something unexpected happened, or indicative of some problem\n        in the near future (e.g. \u2018disk space low\u2019). The software is still working as expected.\n\n        :param msg: the message to log\n        \"\"\"\n        self._logger.warning(msg)",
  "def error(self, msg):\n        \"\"\"\n        Logs an error message to the logging system.\n        ERROR: Due to a more serious problem, the software has not been able to perform some function.\n\n        :param msg: the message to log\n        \"\"\"\n        self._logger.error(msg)",
  "def critical(self, msg):\n        \"\"\"\n        Logs a critical message to the logging system.\n        CRITICAL: A serious error, indicating that the program itself may be unable to continue running.\n\n        :param msg: the message to log\n        \"\"\"\n        self._logger.critical(msg)",
  "def serialize(self) -> dict:\n        return {\"Logger\": {\"Logger\": 1}}",
  "def deserialize(dictionary_to_deserialize):\n        deserialized_logger = Logger()\n        return deserialized_logger",
  "def save_hdf5(save_item, file_path: str, file_dictionary_path: str = \"/\", file_compression: str = None):\n    \"\"\"\n    Saves a dictionary with arbitrary content or an item of any kind to an hdf5-file with given filepath.\n\n    :param save_item: Dictionary to save.\n    :param file_path: Path of the file to save the dictionary in.\n    :param file_dictionary_path: Path in dictionary structure of existing hdf5 file to store the dictionary in.\n    :param file_compression: possible file compression for the hdf5 output file. Values are: gzip, lzf and szip.\n    :returns: :mod:`Null`\n    \"\"\"\n\n    def data_grabber(file, path, data_dictionary, compression: str = None):\n        \"\"\"\n        Helper function which recursively grabs data from dictionaries in order to store them into hdf5 groups.\n\n        :param file: hdf5 file instance to store the data in.\n        :param path: Current group path in hdf5 file group structure.\n        :param data_dictionary: Dictionary to save.\n        :param compression: possible file compression for the corresponding dataset. Values are: gzip, lzf and szip.\n        \"\"\"\n\n        for key, item in data_dictionary.items():\n            key = str(key)\n            if isinstance(item, SerializableSIMPAClass):\n                serialized_item = item.serialize()\n\n                data_grabber(file, path + key + \"/\", serialized_item, file_compression)\n            elif not isinstance(item, (list, dict, type(None))):\n\n                if isinstance(item, (bytes, int, np.int64, float, str, bool, np.bool_)):\n                    try:\n                        h5file[path + key] = item\n                    except (OSError, RuntimeError, ValueError):\n                        del h5file[path + key]\n                        h5file[path + key] = item\n                else:\n                    c = None\n                    if isinstance(item, np.ndarray):\n                        c = compression\n\n                    try:\n                        h5file.create_dataset(path + key, data=item, compression=c)\n                    except (OSError, RuntimeError, ValueError):\n                        del h5file[path + key]\n                        try:\n                            h5file.create_dataset(path + key, data=item, compression=c)\n                        except RuntimeError as e:\n                            logger.critical(\"item \" + str(item) + \" of type \" + str(type(item)) +\n                                            \" was not serializable! Full exception: \" + str(e))\n                            raise e\n                    except TypeError as e:\n                        logger.critical(\"The key \" + str(key) + \" was not of the correct typing for HDF5 handling.\"\n                                        \"Make sure this key is not a tuple. \" + str(item) + \" \" + str(type(item)))\n                        raise e\n            elif item is None:\n                try:\n                    h5file[path + key] = \"None\"\n                except (OSError, RuntimeError, ValueError):\n                    del h5file[path + key]\n                    h5file[path + key] = \"None\"\n            elif isinstance(item, list):\n                list_dict = dict()\n                for i, list_item in enumerate(item):\n                    list_dict[str(i)] = list_item\n                try:\n                    data_grabber(file, path + key + \"/list/\", list_dict, file_compression)\n                except TypeError as e:\n                    logger.critical(\"The key \" + str(key) + \" was not of the correct typing for HDF5 handling.\"\n                                    \"Make sure this key is not a tuple.\")\n                    raise e\n            else:\n                data_grabber(file, path + key + \"/\", item, file_compression)\n\n    if file_dictionary_path == \"/\":\n        writing_mode = \"w\"\n    else:\n        writing_mode = \"a\"\n\n    if isinstance(save_item, SerializableSIMPAClass):\n        save_item = save_item.serialize()\n    if isinstance(save_item, dict):\n        with h5py.File(file_path, writing_mode) as h5file:\n            data_grabber(h5file, file_dictionary_path, save_item, file_compression)\n    else:\n        save_key = file_dictionary_path.split(\"/\")[-2]\n        dictionary = {save_key: save_item}\n        file_dictionary_path = \"/\".join(file_dictionary_path.split(\"/\")[:-2]) + \"/\"\n        with h5py.File(file_path, writing_mode) as h5file:\n            data_grabber(h5file, file_dictionary_path, dictionary, file_compression)",
  "def load_hdf5(file_path, file_dictionary_path=\"/\"):\n    \"\"\"\n    Loads a dictionary from an hdf5 file.\n\n    :param file_path: Path of the file to load the dictionary from.\n    :param file_dictionary_path: Path in dictionary structure of hdf5 file to lo the dictionary in.\n    :returns: Dictionary\n    :rtype: dict\n    \"\"\"\n\n    def data_grabber(file, path):\n        \"\"\"\n        Helper function which recursively loads data from the hdf5 group structure to a dictionary.\n\n        :param file: hdf5 file instance to load the data from.\n        :param path: Current group path in hdf5 file group structure.\n        :returns: Dictionary or np.array\n        \"\"\"\n\n        if isinstance(h5file[path], h5py._hl.dataset.Dataset):\n            return h5file[path][()]\n\n        dictionary = {}\n        for key, item in h5file[path].items():\n            if isinstance(item, h5py._hl.dataset.Dataset):\n                item = item[()]\n                if item is not None:\n                    dictionary[key] = item\n                    if isinstance(dictionary[key], bytes):\n                        dictionary[key] = dictionary[key].decode(\"utf-8\")\n                    elif isinstance(dictionary[key], np.bool_):\n                        dictionary[key] = bool(dictionary[key])\n                else:\n                    dictionary[key] = None\n            elif isinstance(item, h5py._hl.group.Group):\n                if key in SERIALIZATION_MAP.keys():\n                    serialized_dict = data_grabber(file, path + key + \"/\")\n                    serialized_class = SERIALIZATION_MAP[key]\n                    deserialized_class = serialized_class.deserialize(serialized_dict)\n                    dictionary = deserialized_class\n                elif key == \"list\":\n                    dictionary_list = [None for x in item.keys()]\n                    for listkey in sorted(item.keys()):\n                        if isinstance(item[listkey], h5py._hl.dataset.Dataset):\n                            listkey_item = item[listkey][()]\n                            if listkey_item is not None:\n                                list_item = listkey_item\n                                if isinstance(list_item, bytes):\n                                    list_item = list_item.decode(\"utf-8\")\n                                elif isinstance(list_item, np.bool_):\n                                    list_item = bool(list_item)\n                            else:\n                                list_item = None\n                            dictionary_list[int(listkey)] = list_item\n                        elif isinstance(item[listkey], h5py._hl.group.Group):\n                            dictionary_list[int(listkey)] = data_grabber(file, path + key + \"/\" + listkey + \"/\")\n                    dictionary = dictionary_list\n                else:\n                    dictionary[key] = data_grabber(file, path + key + \"/\")\n        return dictionary\n\n    with h5py.File(file_path, \"r\") as h5file:\n        return data_grabber(h5file, file_dictionary_path)",
  "def load_data_field(file_path, data_field, wavelength=None):\n    path = generate_dict_path(data_field, wavelength=wavelength)\n    data = load_hdf5(file_path, path)\n    return data",
  "def save_data_field(data, file_path, data_field, wavelength=None):\n    dict_path = generate_dict_path(data_field, wavelength=wavelength)\n    save_hdf5(data, file_path, dict_path)",
  "def data_grabber(file, path, data_dictionary, compression: str = None):\n        \"\"\"\n        Helper function which recursively grabs data from dictionaries in order to store them into hdf5 groups.\n\n        :param file: hdf5 file instance to store the data in.\n        :param path: Current group path in hdf5 file group structure.\n        :param data_dictionary: Dictionary to save.\n        :param compression: possible file compression for the corresponding dataset. Values are: gzip, lzf and szip.\n        \"\"\"\n\n        for key, item in data_dictionary.items():\n            key = str(key)\n            if isinstance(item, SerializableSIMPAClass):\n                serialized_item = item.serialize()\n\n                data_grabber(file, path + key + \"/\", serialized_item, file_compression)\n            elif not isinstance(item, (list, dict, type(None))):\n\n                if isinstance(item, (bytes, int, np.int64, float, str, bool, np.bool_)):\n                    try:\n                        h5file[path + key] = item\n                    except (OSError, RuntimeError, ValueError):\n                        del h5file[path + key]\n                        h5file[path + key] = item\n                else:\n                    c = None\n                    if isinstance(item, np.ndarray):\n                        c = compression\n\n                    try:\n                        h5file.create_dataset(path + key, data=item, compression=c)\n                    except (OSError, RuntimeError, ValueError):\n                        del h5file[path + key]\n                        try:\n                            h5file.create_dataset(path + key, data=item, compression=c)\n                        except RuntimeError as e:\n                            logger.critical(\"item \" + str(item) + \" of type \" + str(type(item)) +\n                                            \" was not serializable! Full exception: \" + str(e))\n                            raise e\n                    except TypeError as e:\n                        logger.critical(\"The key \" + str(key) + \" was not of the correct typing for HDF5 handling.\"\n                                        \"Make sure this key is not a tuple. \" + str(item) + \" \" + str(type(item)))\n                        raise e\n            elif item is None:\n                try:\n                    h5file[path + key] = \"None\"\n                except (OSError, RuntimeError, ValueError):\n                    del h5file[path + key]\n                    h5file[path + key] = \"None\"\n            elif isinstance(item, list):\n                list_dict = dict()\n                for i, list_item in enumerate(item):\n                    list_dict[str(i)] = list_item\n                try:\n                    data_grabber(file, path + key + \"/list/\", list_dict, file_compression)\n                except TypeError as e:\n                    logger.critical(\"The key \" + str(key) + \" was not of the correct typing for HDF5 handling.\"\n                                    \"Make sure this key is not a tuple.\")\n                    raise e\n            else:\n                data_grabber(file, path + key + \"/\", item, file_compression)",
  "def data_grabber(file, path):\n        \"\"\"\n        Helper function which recursively loads data from the hdf5 group structure to a dictionary.\n\n        :param file: hdf5 file instance to load the data from.\n        :param path: Current group path in hdf5 file group structure.\n        :returns: Dictionary or np.array\n        \"\"\"\n\n        if isinstance(h5file[path], h5py._hl.dataset.Dataset):\n            return h5file[path][()]\n\n        dictionary = {}\n        for key, item in h5file[path].items():\n            if isinstance(item, h5py._hl.dataset.Dataset):\n                item = item[()]\n                if item is not None:\n                    dictionary[key] = item\n                    if isinstance(dictionary[key], bytes):\n                        dictionary[key] = dictionary[key].decode(\"utf-8\")\n                    elif isinstance(dictionary[key], np.bool_):\n                        dictionary[key] = bool(dictionary[key])\n                else:\n                    dictionary[key] = None\n            elif isinstance(item, h5py._hl.group.Group):\n                if key in SERIALIZATION_MAP.keys():\n                    serialized_dict = data_grabber(file, path + key + \"/\")\n                    serialized_class = SERIALIZATION_MAP[key]\n                    deserialized_class = serialized_class.deserialize(serialized_dict)\n                    dictionary = deserialized_class\n                elif key == \"list\":\n                    dictionary_list = [None for x in item.keys()]\n                    for listkey in sorted(item.keys()):\n                        if isinstance(item[listkey], h5py._hl.dataset.Dataset):\n                            listkey_item = item[listkey][()]\n                            if listkey_item is not None:\n                                list_item = listkey_item\n                                if isinstance(list_item, bytes):\n                                    list_item = list_item.decode(\"utf-8\")\n                                elif isinstance(list_item, np.bool_):\n                                    list_item = bool(list_item)\n                            else:\n                                list_item = None\n                            dictionary_list[int(listkey)] = list_item\n                        elif isinstance(item[listkey], h5py._hl.group.Group):\n                            dictionary_list[int(listkey)] = data_grabber(file, path + key + \"/\" + listkey + \"/\")\n                    dictionary = dictionary_list\n                else:\n                    dictionary[key] = data_grabber(file, path + key + \"/\")\n        return dictionary",
  "class IpascSimpaAdapter(BaseAdapter):\n    \"\"\"\n    This class contains the logic to extract the needed meta data from the SIMPA simulation files to\n    fulfill the requirements of the IPASC standard data format.\n    \"\"\"\n\n    def __init__(self, hdf5_file_path: str, device: DigitalDeviceTwinBase, settings: Settings = None):\n        self.logger = Logger()\n        raise RuntimeError(\"Please do not use this adapter currently! It is still under construction!\")\n\n        # Input validation with descriptive error messages\n        if not os.path.exists(hdf5_file_path):\n            self.logger.error(f\"The given file path ({hdf5_file_path}) does not exist.\")\n            raise AssertionError(f\"The given file path ({hdf5_file_path}) does not exist.\")\n        if not os.path.isfile(hdf5_file_path):\n            self.logger.error(f\"The given file path ({hdf5_file_path}) does not point to a file.\")\n            raise AssertionError(f\"The given file path ({hdf5_file_path}) does not point to a file.\")\n        if not hdf5_file_path.endswith(\".hdf5\"):\n            self.logger.error(f\"The given file path must point to an hdf5 file that ends with '.hdf5'\")\n            raise AssertionError(f\"The given file path must point to an hdf5 file that ends with '.hdf5'\")\n        self.simpa_hdf5_file_path = hdf5_file_path\n        self.ipasc_hdf5_file_path = hdf5_file_path.replace(\".hdf5\", \"_ipasc.hdf5\")\n\n        # checking SIMPA settings dictionary\n        if settings is None:\n            settings = load_hdf5(hdf5_file_path)\n            if Tags.SETTINGS not in settings:\n                self.logger.error(\"Unable to recover settings dictionary. Please supply a valid settings dictionary for a \"\n                                  \"successful export.\")\n            settings = settings[Tags.SETTINGS]\n        if settings is None or not isinstance(settings, Settings):\n            self.logger.error(\"No settings found at Tags.SETTINGS in the loaded HDF5 file. \"\n                              \"Please supply a valid settings dictionary for a successful export.\")\n        self.settings = settings\n\n        # checking given photoacoustic device\n        if device is None or not isinstance(device, PhotoacousticDevice):\n            self.logger.error(\"Given device was not a photoacoustic device.\")\n            raise AssertionError(\"Given device was not a photoacoustic device.\")\n        self.device = device\n\n        if Tags.WAVELENGTHS not in settings:\n            self.logger.error(\"Tags.WAVELENGTHS was not defined in the settings dictionary. Aborting IPASC file export.\")\n\n        self.wavelengths = self.settings[Tags.WAVELENGTHS]\n\n        # Load the data for the first wavelength just to get the number of elements and number of time steps\n        try:\n            num_elements, num_time_steps = np.shape(load_data_field(self.simpa_hdf5_file_path,\n                                                                    Tags.DATA_FIELD_TIME_SERIES_DATA, self.wavelengths[0]))\n        except KeyError as e:\n            self.logger.error(e)\n            raise AssertionError(e)\n\n        self.time_series_data = np.zeros(shape=(num_elements, num_time_steps, len(self.wavelengths), 1))\n\n        for wl_idx, wavelength in enumerate(self.wavelengths):\n            self.time_series_data[:, :, wl_idx, 0] = load_data_field(self.simpa_hdf5_file_path,\n                                                                     Tags.DATA_FIELD_TIME_SERIES_DATA, wavelength)\n\n        self.time_series_data = self.time_series_data.astype(np.float32)\n\n        super(IpascSimpaAdapter, self).__init__()\n\n    def generate_binary_data(self) -> np.ndarray:\n        return self.time_series_data\n\n    def generate_device_meta_data(self) -> dict:\n        device_creator = DeviceMetaDataCreator()\n        device_creator.set_general_information(uuid=self.device.generate_uuid(),\n                                               fov=self.device.field_of_view_extent_mm/1000)\n\n        positions = self.device.get_detection_geometry().get_detector_element_positions_base_mm()/1000\n        orientations = self.device.get_detection_geometry().get_detector_element_orientations()\n\n        for idx, (position, orientation) in enumerate(zip(positions, orientations)):\n            detection_element_creator = DetectionElementCreator()\n            # do not forget to convert to m\n            detection_element_creator.set_detector_position(position)\n            detection_element_creator.set_detector_orientation(orientation)\n            detection_element_creator.set_detector_geometry_type(\"CUBOID\")\n            # do not forget to convert to m\n            detection_element_creator.set_detector_geometry(\n                np.asarray([self.device.get_detection_geometry().detector_element_width_mm,\n                            self.device.get_detection_geometry().detector_element_length_mm, 0.0001]) / 1000)\n            device_creator.add_detection_element(detection_element_creator.get_dictionary())\n\n        return device_creator.finalize_device_meta_data()\n\n    def set_metadata_value(self, metadata_tag: MetaDatum) -> object:\n        if metadata_tag == MetadataAcquisitionTags.UUID:\n            return str(uuid.uuid4())\n        elif metadata_tag == MetadataAcquisitionTags.DATA_TYPE:\n            return str(type(self.time_series_data[0, 0, 0, 0].item()))\n        elif metadata_tag == MetadataAcquisitionTags.AD_SAMPLING_RATE:\n            if Tags.K_WAVE_SPECIFIC_DT in self.settings and self.settings[Tags.K_WAVE_SPECIFIC_DT]:\n                return float(1.0 / self.settings[Tags.K_WAVE_SPECIFIC_DT])\n            elif self.device.get_detection_geometry().sampling_frequency_MHz is not None:\n                return float(self.device.get_detection_geometry().sampling_frequency_MHz * 1000000)\n        elif metadata_tag == MetadataAcquisitionTags.ACQUISITION_OPTICAL_WAVELENGTHS:\n            return np.asarray(self.wavelengths)\n        elif metadata_tag == MetadataAcquisitionTags.DIMENSIONALITY:\n            return \"time\"\n        elif metadata_tag == MetadataAcquisitionTags.SCANNING_METHOD:\n            return \"full_scan\"\n        elif metadata_tag == MetadataAcquisitionTags.PHOTOACOUSTIC_IMAGING_DEVICE:\n            return str(self.device.generate_uuid())\n        elif metadata_tag == MetadataAcquisitionTags.SIZES:\n            return np.asarray(np.shape(self.time_series_data))\n        else:\n            return None",
  "def export_to_ipasc(hdf5_file_path: str, device: DigitalDeviceTwinBase, settings: Settings = None):\n    \"\"\"\n    This function exports parts of the SIMPA simulation results of the given hdf5_file_path into the IPASC\n    standard data format.\n\n\n    :param hdf5_file_path: A string with the path to an HDF5 file containing a SIMPA simulation result\n    :param device: A PhotoacousticDevice that describes the digital device twin\n    :param settings: The settings dictionary used for the simulation. if not given, it is attempted to recover the\n                     settings dictionary from the HDF5 file.\n    :return: None\n    \"\"\"\n    try:\n        ipasc_adapter = IpascSimpaAdapter(hdf5_file_path, device, settings)\n        pa_data = ipasc_adapter.generate_pa_data()\n        write_ipasc_data(ipasc_adapter.ipasc_hdf5_file_path, pa_data)\n    except Exception as e:\n        Logger().error(e)",
  "def __init__(self, hdf5_file_path: str, device: DigitalDeviceTwinBase, settings: Settings = None):\n        self.logger = Logger()\n        raise RuntimeError(\"Please do not use this adapter currently! It is still under construction!\")\n\n        # Input validation with descriptive error messages\n        if not os.path.exists(hdf5_file_path):\n            self.logger.error(f\"The given file path ({hdf5_file_path}) does not exist.\")\n            raise AssertionError(f\"The given file path ({hdf5_file_path}) does not exist.\")\n        if not os.path.isfile(hdf5_file_path):\n            self.logger.error(f\"The given file path ({hdf5_file_path}) does not point to a file.\")\n            raise AssertionError(f\"The given file path ({hdf5_file_path}) does not point to a file.\")\n        if not hdf5_file_path.endswith(\".hdf5\"):\n            self.logger.error(f\"The given file path must point to an hdf5 file that ends with '.hdf5'\")\n            raise AssertionError(f\"The given file path must point to an hdf5 file that ends with '.hdf5'\")\n        self.simpa_hdf5_file_path = hdf5_file_path\n        self.ipasc_hdf5_file_path = hdf5_file_path.replace(\".hdf5\", \"_ipasc.hdf5\")\n\n        # checking SIMPA settings dictionary\n        if settings is None:\n            settings = load_hdf5(hdf5_file_path)\n            if Tags.SETTINGS not in settings:\n                self.logger.error(\"Unable to recover settings dictionary. Please supply a valid settings dictionary for a \"\n                                  \"successful export.\")\n            settings = settings[Tags.SETTINGS]\n        if settings is None or not isinstance(settings, Settings):\n            self.logger.error(\"No settings found at Tags.SETTINGS in the loaded HDF5 file. \"\n                              \"Please supply a valid settings dictionary for a successful export.\")\n        self.settings = settings\n\n        # checking given photoacoustic device\n        if device is None or not isinstance(device, PhotoacousticDevice):\n            self.logger.error(\"Given device was not a photoacoustic device.\")\n            raise AssertionError(\"Given device was not a photoacoustic device.\")\n        self.device = device\n\n        if Tags.WAVELENGTHS not in settings:\n            self.logger.error(\"Tags.WAVELENGTHS was not defined in the settings dictionary. Aborting IPASC file export.\")\n\n        self.wavelengths = self.settings[Tags.WAVELENGTHS]\n\n        # Load the data for the first wavelength just to get the number of elements and number of time steps\n        try:\n            num_elements, num_time_steps = np.shape(load_data_field(self.simpa_hdf5_file_path,\n                                                                    Tags.DATA_FIELD_TIME_SERIES_DATA, self.wavelengths[0]))\n        except KeyError as e:\n            self.logger.error(e)\n            raise AssertionError(e)\n\n        self.time_series_data = np.zeros(shape=(num_elements, num_time_steps, len(self.wavelengths), 1))\n\n        for wl_idx, wavelength in enumerate(self.wavelengths):\n            self.time_series_data[:, :, wl_idx, 0] = load_data_field(self.simpa_hdf5_file_path,\n                                                                     Tags.DATA_FIELD_TIME_SERIES_DATA, wavelength)\n\n        self.time_series_data = self.time_series_data.astype(np.float32)\n\n        super(IpascSimpaAdapter, self).__init__()",
  "def generate_binary_data(self) -> np.ndarray:\n        return self.time_series_data",
  "def generate_device_meta_data(self) -> dict:\n        device_creator = DeviceMetaDataCreator()\n        device_creator.set_general_information(uuid=self.device.generate_uuid(),\n                                               fov=self.device.field_of_view_extent_mm/1000)\n\n        positions = self.device.get_detection_geometry().get_detector_element_positions_base_mm()/1000\n        orientations = self.device.get_detection_geometry().get_detector_element_orientations()\n\n        for idx, (position, orientation) in enumerate(zip(positions, orientations)):\n            detection_element_creator = DetectionElementCreator()\n            # do not forget to convert to m\n            detection_element_creator.set_detector_position(position)\n            detection_element_creator.set_detector_orientation(orientation)\n            detection_element_creator.set_detector_geometry_type(\"CUBOID\")\n            # do not forget to convert to m\n            detection_element_creator.set_detector_geometry(\n                np.asarray([self.device.get_detection_geometry().detector_element_width_mm,\n                            self.device.get_detection_geometry().detector_element_length_mm, 0.0001]) / 1000)\n            device_creator.add_detection_element(detection_element_creator.get_dictionary())\n\n        return device_creator.finalize_device_meta_data()",
  "def set_metadata_value(self, metadata_tag: MetaDatum) -> object:\n        if metadata_tag == MetadataAcquisitionTags.UUID:\n            return str(uuid.uuid4())\n        elif metadata_tag == MetadataAcquisitionTags.DATA_TYPE:\n            return str(type(self.time_series_data[0, 0, 0, 0].item()))\n        elif metadata_tag == MetadataAcquisitionTags.AD_SAMPLING_RATE:\n            if Tags.K_WAVE_SPECIFIC_DT in self.settings and self.settings[Tags.K_WAVE_SPECIFIC_DT]:\n                return float(1.0 / self.settings[Tags.K_WAVE_SPECIFIC_DT])\n            elif self.device.get_detection_geometry().sampling_frequency_MHz is not None:\n                return float(self.device.get_detection_geometry().sampling_frequency_MHz * 1000000)\n        elif metadata_tag == MetadataAcquisitionTags.ACQUISITION_OPTICAL_WAVELENGTHS:\n            return np.asarray(self.wavelengths)\n        elif metadata_tag == MetadataAcquisitionTags.DIMENSIONALITY:\n            return \"time\"\n        elif metadata_tag == MetadataAcquisitionTags.SCANNING_METHOD:\n            return \"full_scan\"\n        elif metadata_tag == MetadataAcquisitionTags.PHOTOACOUSTIC_IMAGING_DEVICE:\n            return str(self.device.generate_uuid())\n        elif metadata_tag == MetadataAcquisitionTags.SIZES:\n            return np.asarray(np.shape(self.time_series_data))\n        else:\n            return None",
  "def download_from_zenodo(record_id: str, save_dir: str, sandbox: bool = False):\n    \"\"\"\n    Downloads a .zip folder from zenodo.org with the specified Record ID.\n\n    :param record_id: Record ID of the specified Zenodo file.\n    :param save_dir: Output directory where the Zenodo file will be stored.\n    :param sandbox: Boolean to specify whether to download from zenodo.org or sandbox.zenodo.org.\n    \"\"\"\n\n    if sandbox:\n        url = 'https://sandbox.zenodo.org/api/records/'\n    else:\n        url = 'https://zenodo.org/api/records/'\n\n    # create directory, if necessary, then change to it\n    os.makedirs(save_dir, exist_ok=True)\n\n    record_id = record_id.strip()\n\n    r = requests.get(url + record_id)\n\n    if r.ok:\n        text = json.loads(r.text)\n        link = text[\"files\"][0][\"links\"][\"self\"]\n        wget.download(link, out=save_dir)"
]