[
  "class VersioneerConfig:\n    \"\"\"Container for Versioneer configuration parameters.\"\"\"",
  "def get_root():\n    \"\"\"Get the project root directory.\n\n    We require that all commands are run from the project root, i.e. the\n    directory that contains setup.py, setup.cfg, and versioneer.py .\n    \"\"\"\n    root = os.path.realpath(os.path.abspath(os.getcwd()))\n    setup_py = os.path.join(root, \"setup.py\")\n    versioneer_py = os.path.join(root, \"versioneer.py\")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        # allow 'python path/to/setup.py COMMAND'\n        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))\n        setup_py = os.path.join(root, \"setup.py\")\n        versioneer_py = os.path.join(root, \"versioneer.py\")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        err = (\"Versioneer was unable to run the project root directory. \"\n               \"Versioneer requires setup.py to be executed from \"\n               \"its immediate directory (like 'python setup.py COMMAND'), \"\n               \"or in a way that lets it use sys.argv[0] to find the root \"\n               \"(like 'python path/to/setup.py COMMAND').\")\n        raise VersioneerBadRootError(err)\n    try:\n        # Certain runtime workflows (setup.py install/develop in a setuptools\n        # tree) execute all dependencies in a single python process, so\n        # \"versioneer\" may be imported multiple times, and python's shared\n        # module-import table will cache the first one. So we can't use\n        # os.path.dirname(__file__), as that will find whichever\n        # versioneer.py was first imported, even in later projects.\n        my_path = os.path.realpath(os.path.abspath(__file__))\n        me_dir = os.path.normcase(os.path.splitext(my_path)[0])\n        vsr_dir = os.path.normcase(os.path.splitext(versioneer_py)[0])\n        if me_dir != vsr_dir:\n            print(\"Warning: build in %s is using versioneer.py from %s\"\n                  % (os.path.dirname(my_path), versioneer_py))\n    except NameError:\n        pass\n    return root",
  "def get_config_from_root(root):\n    \"\"\"Read the project setup.cfg file to determine Versioneer config.\"\"\"\n    # This might raise OSError (if setup.cfg is missing), or\n    # configparser.NoSectionError (if it lacks a [versioneer] section), or\n    # configparser.NoOptionError (if it lacks \"VCS=\"). See the docstring at\n    # the top of versioneer.py for instructions on writing your setup.cfg .\n    setup_cfg = os.path.join(root, \"setup.cfg\")\n    parser = configparser.ConfigParser()\n    with open(setup_cfg, \"r\") as cfg_file:\n        parser.read_file(cfg_file)\n    VCS = parser.get(\"versioneer\", \"VCS\")  # mandatory\n\n    # Dict-like interface for non-mandatory entries\n    section = parser[\"versioneer\"]\n\n    cfg = VersioneerConfig()\n    cfg.VCS = VCS\n    cfg.style = section.get(\"style\", \"\")\n    cfg.versionfile_source = section.get(\"versionfile_source\")\n    cfg.versionfile_build = section.get(\"versionfile_build\")\n    cfg.tag_prefix = section.get(\"tag_prefix\")\n    if cfg.tag_prefix in (\"''\", '\"\"'):\n        cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = section.get(\"parentdir_prefix\")\n    cfg.verbose = section.get(\"verbose\")\n    return cfg",
  "class NotThisMethod(Exception):\n    \"\"\"Exception raised if a method is not valid for the current scenario.\"\"\"",
  "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate",
  "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False,\n                env=None):\n    \"\"\"Call the given command(s).\"\"\"\n    assert isinstance(commands, list)\n    process = None\n    for command in commands:\n        try:\n            dispcmd = str([command] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            process = subprocess.Popen([command] + args, cwd=cwd, env=env,\n                                       stdout=subprocess.PIPE,\n                                       stderr=(subprocess.PIPE if hide_stderr\n                                               else None))\n            break\n        except OSError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(\"unable to find command, tried %s\" % (commands,))\n        return None, None\n    stdout = process.communicate()[0].strip().decode()\n    if process.returncode != 0:\n        if verbose:\n            print(\"unable to run %s (error)\" % dispcmd)\n            print(\"stdout was %s\" % stdout)\n        return None, process.returncode\n    return stdout, process.returncode",
  "def git_get_keywords(versionfile_abs):\n    \"\"\"Extract version information from the given file.\"\"\"\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        with open(versionfile_abs, \"r\") as fobj:\n            for line in fobj:\n                if line.strip().startswith(\"git_refnames =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"refnames\"] = mo.group(1)\n                if line.strip().startswith(\"git_full =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"full\"] = mo.group(1)\n                if line.strip().startswith(\"git_date =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"date\"] = mo.group(1)\n    except OSError:\n        pass\n    return keywords",
  "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n    \"\"\"Get version information from git keywords.\"\"\"\n    if \"refnames\" not in keywords:\n        raise NotThisMethod(\"Short version file found\")\n    date = keywords.get(\"date\")\n    if date is not None:\n        # Use only the last line.  Previous lines may contain GPG signature\n        # information.\n        date = date.splitlines()[-1]\n\n        # git-2.2.0 added \"%cI\", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer \"%ci\" (which expands to an \"ISO-8601\n        # -like\" string, which we must then edit to make compliant), because\n        # it's been around since git-1.5.3, and it's too difficult to\n        # discover which version we're using, or to work around using an\n        # older one.\n        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n    if not tags:\n        # Either we're using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like \"release\" and\n        # \"stabilization\", as well as \"HEAD\" and \"master\".\n        tags = {r for r in refs if re.search(r'\\d', r)}\n        if verbose:\n            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n    if verbose:\n        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. \"2.0\" over \"2.0rc1\"\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            # Filter out refs that exactly match prefix or that don't start\n            # with a number once the prefix is stripped (mostly a concern\n            # when prefix is '')\n            if not re.match(r'\\d', r):\n                continue\n            if verbose:\n                print(\"picking %s\" % r)\n            return {\"version\": r,\n                    \"full-revisionid\": keywords[\"full\"].strip(),\n                    \"dirty\": False, \"error\": None,\n                    \"date\": date}\n    # no suitable tags, so version is \"0+unknown\", but full hex is still there\n    if verbose:\n        print(\"no suitable tags, using unknown + full revision id\")\n    return {\"version\": \"0+unknown\",\n            \"full-revisionid\": keywords[\"full\"].strip(),\n            \"dirty\": False, \"error\": \"no suitable tags\", \"date\": None}",
  "def git_pieces_from_vcs(tag_prefix, root, verbose, runner=run_command):\n    \"\"\"Get version from 'git describe' in the root of the source tree.\n\n    This only gets called if the git-archive 'subst' keywords were *not*\n    expanded, and _version.py hasn't already been rewritten with a short\n    version string, meaning we're inside a checked out source tree.\n    \"\"\"\n    GITS = [\"git\"]\n    TAG_PREFIX_REGEX = \"*\"\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n        TAG_PREFIX_REGEX = r\"\\*\"\n\n    _, rc = runner(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root,\n                   hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(\"Directory %s not under git control\" % root)\n        raise NotThisMethod(\"'git rev-parse --git-dir' returned error\")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn't one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = runner(GITS, [\"describe\", \"--tags\", \"--dirty\",\n                                     \"--always\", \"--long\",\n                                     \"--match\",\n                                     \"%s%s\" % (tag_prefix, TAG_PREFIX_REGEX)],\n                              cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(\"'git describe' failed\")\n    describe_out = describe_out.strip()\n    full_out, rc = runner(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(\"'git rev-parse' failed\")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[\"long\"] = full_out\n    pieces[\"short\"] = full_out[:7]  # maybe improved later\n    pieces[\"error\"] = None\n\n    branch_name, rc = runner(GITS, [\"rev-parse\", \"--abbrev-ref\", \"HEAD\"],\n                             cwd=root)\n    # --abbrev-ref was added in git-1.6.3\n    if rc != 0 or branch_name is None:\n        raise NotThisMethod(\"'git rev-parse --abbrev-ref' returned error\")\n    branch_name = branch_name.strip()\n\n    if branch_name == \"HEAD\":\n        # If we aren't exactly on a branch, pick a branch which represents\n        # the current commit. If all else fails, we are on a branchless\n        # commit.\n        branches, rc = runner(GITS, [\"branch\", \"--contains\"], cwd=root)\n        # --contains was added in git-1.5.4\n        if rc != 0 or branches is None:\n            raise NotThisMethod(\"'git branch --contains' returned error\")\n        branches = branches.split(\"\\n\")\n\n        # Remove the first line if we're running detached\n        if \"(\" in branches[0]:\n            branches.pop(0)\n\n        # Strip off the leading \"* \" from the list of branches.\n        branches = [branch[2:] for branch in branches]\n        if \"master\" in branches:\n            branch_name = \"master\"\n        elif not branches:\n            branch_name = None\n        else:\n            # Pick the first branch that is returned. Good or bad.\n            branch_name = branches[0]\n\n    pieces[\"branch\"] = branch_name\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(\"-dirty\")\n    pieces[\"dirty\"] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if \"-\" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n        if not mo:\n            # unparsable. Maybe git-describe is misbehaving?\n            pieces[\"error\"] = (\"unable to parse git-describe output: '%s'\"\n                               % describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n                print(fmt % (full_tag, tag_prefix))\n            pieces[\"error\"] = (\"tag '%s' doesn't start with prefix '%s'\"\n                               % (full_tag, tag_prefix))\n            return pieces\n        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[\"distance\"] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[\"short\"] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[\"closest-tag\"] = None\n        count_out, rc = runner(GITS, [\"rev-list\", \"HEAD\", \"--count\"], cwd=root)\n        pieces[\"distance\"] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = runner(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"], cwd=root)[0].strip()\n    # Use only the last line.  Previous lines may contain GPG signature\n    # information.\n    date = date.splitlines()[-1]\n    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n\n    return pieces",
  "def do_vcs_install(manifest_in, versionfile_source, ipy):\n    \"\"\"Git-specific installation logic for Versioneer.\n\n    For Git, this means creating/changing .gitattributes to mark _version.py\n    for export-subst keyword substitution.\n    \"\"\"\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n    files = [manifest_in, versionfile_source]\n    if ipy:\n        files.append(ipy)\n    try:\n        my_path = __file__\n        if my_path.endswith(\".pyc\") or my_path.endswith(\".pyo\"):\n            my_path = os.path.splitext(my_path)[0] + \".py\"\n        versioneer_file = os.path.relpath(my_path)\n    except NameError:\n        versioneer_file = \"versioneer.py\"\n    files.append(versioneer_file)\n    present = False\n    try:\n        with open(\".gitattributes\", \"r\") as fobj:\n            for line in fobj:\n                if line.strip().startswith(versionfile_source):\n                    if \"export-subst\" in line.strip().split()[1:]:\n                        present = True\n                        break\n    except OSError:\n        pass\n    if not present:\n        with open(\".gitattributes\", \"a+\") as fobj:\n            fobj.write(f\"{versionfile_source} export-subst\\n\")\n        files.append(\".gitattributes\")\n    run_command(GITS, [\"add\", \"--\"] + files)",
  "def versions_from_parentdir(parentdir_prefix, root, verbose):\n    \"\"\"Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    \"\"\"\n    rootdirs = []\n\n    for _ in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\"version\": dirname[len(parentdir_prefix):],\n                    \"full-revisionid\": None,\n                    \"dirty\": False, \"error\": None, \"date\": None}\n        rootdirs.append(root)\n        root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(\"Tried directories %s but none started with prefix %s\" %\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(\"rootdir doesn't start with parentdir_prefix\")",
  "def versions_from_file(filename):\n    \"\"\"Try to determine the version from _version.py if present.\"\"\"\n    try:\n        with open(filename) as f:\n            contents = f.read()\n    except OSError:\n        raise NotThisMethod(\"unable to read _version.py\")\n    mo = re.search(r\"version_json = '''\\n(.*)'''  # END VERSION_JSON\",\n                   contents, re.M | re.S)\n    if not mo:\n        mo = re.search(r\"version_json = '''\\r\\n(.*)'''  # END VERSION_JSON\",\n                       contents, re.M | re.S)\n    if not mo:\n        raise NotThisMethod(\"no version_json in _version.py\")\n    return json.loads(mo.group(1))",
  "def write_to_version_file(filename, versions):\n    \"\"\"Write the given version number to the given _version.py file.\"\"\"\n    os.unlink(filename)\n    contents = json.dumps(versions, sort_keys=True,\n                          indent=1, separators=(\",\", \": \"))\n    with open(filename, \"w\") as f:\n        f.write(SHORT_VERSION_PY % contents)\n\n    print(\"set %s to '%s'\" % (filename, versions[\"version\"]))",
  "def plus_or_dot(pieces):\n    \"\"\"Return a + if we don't already have one, else return a .\"\"\"\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"",
  "def render_pep440(pieces):\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += plus_or_dot(pieces)\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\n                                          pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered",
  "def render_pep440_branch(pieces):\n    \"\"\"TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch. Note that .dev0 sorts backwards\n    (a feature branch will appear \"older\" than the master branch).\n\n    Exceptions:\n    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0\"\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+untagged.%d.g%s\" % (pieces[\"distance\"],\n                                          pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered",
  "def pep440_split_post(ver):\n    \"\"\"Split pep440 version string at the post-release segment.\n\n    Returns the release segments before the post-release and the\n    post-release version number (or -1 if no post-release segment is present).\n    \"\"\"\n    vc = str.split(ver, \".post\")\n    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None",
  "def render_pep440_pre(pieces):\n    \"\"\"TAG[.postN.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post0.devDISTANCE\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        if pieces[\"distance\"]:\n            # update the post release segment\n            tag_version, post_version = pep440_split_post(pieces[\"closest-tag\"])\n            rendered = tag_version\n            if post_version is not None:\n                rendered += \".post%d.dev%d\" % (post_version+1, pieces[\"distance\"])\n            else:\n                rendered += \".post0.dev%d\" % (pieces[\"distance\"])\n        else:\n            # no commits, use the tag as the version\n            rendered = pieces[\"closest-tag\"]\n    else:\n        # exception #1\n        rendered = \"0.post0.dev%d\" % pieces[\"distance\"]\n    return rendered",
  "def render_pep440_post(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The \".dev0\" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear \"older\" than the corresponding clean one),\n    but you shouldn't be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%s\" % pieces[\"short\"]\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n        rendered += \"+g%s\" % pieces[\"short\"]\n    return rendered",
  "def render_pep440_post_branch(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%s\" % pieces[\"short\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+g%s\" % pieces[\"short\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered",
  "def render_pep440_old(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]] .\n\n    The \".dev0\" means dirty.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n    return rendered",
  "def render_git_describe(pieces):\n    \"\"\"TAG[-DISTANCE-gHEX][-dirty].\n\n    Like 'git describe --tags --dirty --always'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered",
  "def render_git_describe_long(pieces):\n    \"\"\"TAG-DISTANCE-gHEX[-dirty].\n\n    Like 'git describe --tags --dirty --always -long'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered",
  "def render(pieces, style):\n    \"\"\"Render the given version pieces into the requested style.\"\"\"\n    if pieces[\"error\"]:\n        return {\"version\": \"unknown\",\n                \"full-revisionid\": pieces.get(\"long\"),\n                \"dirty\": None,\n                \"error\": pieces[\"error\"],\n                \"date\": None}\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-branch\":\n        rendered = render_pep440_branch(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-post-branch\":\n        rendered = render_pep440_post_branch(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n            \"dirty\": pieces[\"dirty\"], \"error\": None,\n            \"date\": pieces.get(\"date\")}",
  "class VersioneerBadRootError(Exception):\n    \"\"\"The project root directory is unknown or missing key files.\"\"\"",
  "def get_versions(verbose=False):\n    \"\"\"Get the project version from whatever source is available.\n\n    Returns dict with two keys: 'version' and 'full'.\n    \"\"\"\n    if \"versioneer\" in sys.modules:\n        # see the discussion in cmdclass.py:get_cmdclass()\n        del sys.modules[\"versioneer\"]\n\n    root = get_root()\n    cfg = get_config_from_root(root)\n\n    assert cfg.VCS is not None, \"please set [versioneer]VCS= in setup.cfg\"\n    handlers = HANDLERS.get(cfg.VCS)\n    assert handlers, \"unrecognized VCS '%s'\" % cfg.VCS\n    verbose = verbose or cfg.verbose\n    assert cfg.versionfile_source is not None, \\\n        \"please set versioneer.versionfile_source\"\n    assert cfg.tag_prefix is not None, \"please set versioneer.tag_prefix\"\n\n    versionfile_abs = os.path.join(root, cfg.versionfile_source)\n\n    # extract version from first of: _version.py, VCS command (e.g. 'git\n    # describe'), parentdir. This is meant to work for developers using a\n    # source checkout, for users of a tarball created by 'setup.py sdist',\n    # and for users of a tarball/zipball created by 'git archive' or github's\n    # download-from-tag feature or the equivalent in other VCSes.\n\n    get_keywords_f = handlers.get(\"get_keywords\")\n    from_keywords_f = handlers.get(\"keywords\")\n    if get_keywords_f and from_keywords_f:\n        try:\n            keywords = get_keywords_f(versionfile_abs)\n            ver = from_keywords_f(keywords, cfg.tag_prefix, verbose)\n            if verbose:\n                print(\"got version from expanded keyword %s\" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        ver = versions_from_file(versionfile_abs)\n        if verbose:\n            print(\"got version from file %s %s\" % (versionfile_abs, ver))\n        return ver\n    except NotThisMethod:\n        pass\n\n    from_vcs_f = handlers.get(\"pieces_from_vcs\")\n    if from_vcs_f:\n        try:\n            pieces = from_vcs_f(cfg.tag_prefix, root, verbose)\n            ver = render(pieces, cfg.style)\n            if verbose:\n                print(\"got version from VCS %s\" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        if cfg.parentdir_prefix:\n            ver = versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n            if verbose:\n                print(\"got version from parentdir %s\" % ver)\n            return ver\n    except NotThisMethod:\n        pass\n\n    if verbose:\n        print(\"unable to compute version\")\n\n    return {\"version\": \"0+unknown\", \"full-revisionid\": None,\n            \"dirty\": None, \"error\": \"unable to compute version\",\n            \"date\": None}",
  "def get_version():\n    \"\"\"Get the short version string for this project.\"\"\"\n    return get_versions()[\"version\"]",
  "def get_cmdclass(cmdclass=None):\n    \"\"\"Get the custom setuptools/distutils subclasses used by Versioneer.\n\n    If the package uses a different cmdclass (e.g. one from numpy), it\n    should be provide as an argument.\n    \"\"\"\n    if \"versioneer\" in sys.modules:\n        del sys.modules[\"versioneer\"]\n        # this fixes the \"python setup.py develop\" case (also 'install' and\n        # 'easy_install .'), in which subdependencies of the main project are\n        # built (using setup.py bdist_egg) in the same python process. Assume\n        # a main project A and a dependency B, which use different versions\n        # of Versioneer. A's setup.py imports A's Versioneer, leaving it in\n        # sys.modules by the time B's setup.py is executed, causing B to run\n        # with the wrong versioneer. Setuptools wraps the sub-dep builds in a\n        # sandbox that restores sys.modules to it's pre-build state, so the\n        # parent is protected against the child's \"import versioneer\". By\n        # removing ourselves from sys.modules here, before the child build\n        # happens, we protect the child from the parent's versioneer too.\n        # Also see https://github.com/python-versioneer/python-versioneer/issues/52\n\n    cmds = {} if cmdclass is None else cmdclass.copy()\n\n    # we add \"version\" to both distutils and setuptools\n    from distutils.core import Command\n\n    class cmd_version(Command):\n        description = \"report generated version string\"\n        user_options = []\n        boolean_options = []\n\n        def initialize_options(self):\n            pass\n\n        def finalize_options(self):\n            pass\n\n        def run(self):\n            vers = get_versions(verbose=True)\n            print(\"Version: %s\" % vers[\"version\"])\n            print(\" full-revisionid: %s\" % vers.get(\"full-revisionid\"))\n            print(\" dirty: %s\" % vers.get(\"dirty\"))\n            print(\" date: %s\" % vers.get(\"date\"))\n            if vers[\"error\"]:\n                print(\" error: %s\" % vers[\"error\"])\n    cmds[\"version\"] = cmd_version\n\n    # we override \"build_py\" in both distutils and setuptools\n    #\n    # most invocation pathways end up running build_py:\n    #  distutils/build -> build_py\n    #  distutils/install -> distutils/build ->..\n    #  setuptools/bdist_wheel -> distutils/install ->..\n    #  setuptools/bdist_egg -> distutils/install_lib -> build_py\n    #  setuptools/install -> bdist_egg ->..\n    #  setuptools/develop -> ?\n    #  pip install:\n    #   copies source tree to a tempdir before running egg_info/etc\n    #   if .git isn't copied too, 'git describe' will fail\n    #   then does setup.py bdist_wheel, or sometimes setup.py install\n    #  setup.py egg_info -> ?\n\n    # we override different \"build_py\" commands for both environments\n    if 'build_py' in cmds:\n        _build_py = cmds['build_py']\n    elif \"setuptools\" in sys.modules:\n        from setuptools.command.build_py import build_py as _build_py\n    else:\n        from distutils.command.build_py import build_py as _build_py\n\n    class cmd_build_py(_build_py):\n        def run(self):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_py.run(self)\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if cfg.versionfile_build:\n                target_versionfile = os.path.join(self.build_lib,\n                                                  cfg.versionfile_build)\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n    cmds[\"build_py\"] = cmd_build_py\n\n    if 'build_ext' in cmds:\n        _build_ext = cmds['build_ext']\n    elif \"setuptools\" in sys.modules:\n        from setuptools.command.build_ext import build_ext as _build_ext\n    else:\n        from distutils.command.build_ext import build_ext as _build_ext\n\n    class cmd_build_ext(_build_ext):\n        def run(self):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_ext.run(self)\n            if self.inplace:\n                # build_ext --inplace will only build extensions in\n                # build/lib<..> dir with no _version.py to write to.\n                # As in place builds will already have a _version.py\n                # in the module dir, we do not need to write one.\n                return\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            target_versionfile = os.path.join(self.build_lib,\n                                              cfg.versionfile_build)\n            print(\"UPDATING %s\" % target_versionfile)\n            write_to_version_file(target_versionfile, versions)\n    cmds[\"build_ext\"] = cmd_build_ext\n\n    if \"cx_Freeze\" in sys.modules:  # cx_freeze enabled?\n        from cx_Freeze.dist import build_exe as _build_exe\n        # nczeczulin reports that py2exe won't like the pep440-style string\n        # as FILEVERSION, but it can be used for PRODUCTVERSION, e.g.\n        # setup(console=[{\n        #   \"version\": versioneer.get_version().split(\"+\", 1)[0], # FILEVERSION\n        #   \"product_version\": versioneer.get_version(),\n        #   ...\n\n        class cmd_build_exe(_build_exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _build_exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, \"w\") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {\"DOLLAR\": \"$\",\n                             \"STYLE\": cfg.style,\n                             \"TAG_PREFIX\": cfg.tag_prefix,\n                             \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                             \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                             })\n        cmds[\"build_exe\"] = cmd_build_exe\n        del cmds[\"build_py\"]\n\n    if 'py2exe' in sys.modules:  # py2exe enabled?\n        from py2exe.distutils_buildexe import py2exe as _py2exe\n\n        class cmd_py2exe(_py2exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _py2exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, \"w\") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {\"DOLLAR\": \"$\",\n                             \"STYLE\": cfg.style,\n                             \"TAG_PREFIX\": cfg.tag_prefix,\n                             \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                             \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                             })\n        cmds[\"py2exe\"] = cmd_py2exe\n\n    # we override different \"sdist\" commands for both environments\n    if 'sdist' in cmds:\n        _sdist = cmds['sdist']\n    elif \"setuptools\" in sys.modules:\n        from setuptools.command.sdist import sdist as _sdist\n    else:\n        from distutils.command.sdist import sdist as _sdist\n\n    class cmd_sdist(_sdist):\n        def run(self):\n            versions = get_versions()\n            self._versioneer_generated_versions = versions\n            # unless we update this, the command will keep using the old\n            # version\n            self.distribution.metadata.version = versions[\"version\"]\n            return _sdist.run(self)\n\n        def make_release_tree(self, base_dir, files):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            _sdist.make_release_tree(self, base_dir, files)\n            # now locate _version.py in the new base_dir directory\n            # (remembering that it may be a hardlink) and replace it with an\n            # updated value\n            target_versionfile = os.path.join(base_dir, cfg.versionfile_source)\n            print(\"UPDATING %s\" % target_versionfile)\n            write_to_version_file(target_versionfile,\n                                  self._versioneer_generated_versions)\n    cmds[\"sdist\"] = cmd_sdist\n\n    return cmds",
  "def do_setup():\n    \"\"\"Do main VCS-independent setup function for installing Versioneer.\"\"\"\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)\n    except (OSError, configparser.NoSectionError,\n            configparser.NoOptionError) as e:\n        if isinstance(e, (OSError, configparser.NoSectionError)):\n            print(\"Adding sample versioneer config to setup.cfg\",\n                  file=sys.stderr)\n            with open(os.path.join(root, \"setup.cfg\"), \"a\") as f:\n                f.write(SAMPLE_CONFIG)\n        print(CONFIG_ERROR, file=sys.stderr)\n        return 1\n\n    print(\" creating %s\" % cfg.versionfile_source)\n    with open(cfg.versionfile_source, \"w\") as f:\n        LONG = LONG_VERSION_PY[cfg.VCS]\n        f.write(LONG % {\"DOLLAR\": \"$\",\n                        \"STYLE\": cfg.style,\n                        \"TAG_PREFIX\": cfg.tag_prefix,\n                        \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                        \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                        })\n\n    ipy = os.path.join(os.path.dirname(cfg.versionfile_source),\n                       \"__init__.py\")\n    if os.path.exists(ipy):\n        try:\n            with open(ipy, \"r\") as f:\n                old = f.read()\n        except OSError:\n            old = \"\"\n        module = os.path.splitext(os.path.basename(cfg.versionfile_source))[0]\n        snippet = INIT_PY_SNIPPET.format(module)\n        if OLD_SNIPPET in old:\n            print(\" replacing boilerplate in %s\" % ipy)\n            with open(ipy, \"w\") as f:\n                f.write(old.replace(OLD_SNIPPET, snippet))\n        elif snippet not in old:\n            print(\" appending to %s\" % ipy)\n            with open(ipy, \"a\") as f:\n                f.write(snippet)\n        else:\n            print(\" %s unmodified\" % ipy)\n    else:\n        print(\" %s doesn't exist, ok\" % ipy)\n        ipy = None\n\n    # Make sure both the top-level \"versioneer.py\" and versionfile_source\n    # (PKG/_version.py, used by runtime code) are in MANIFEST.in, so\n    # they'll be copied into source distributions. Pip won't be able to\n    # install the package without this.\n    manifest_in = os.path.join(root, \"MANIFEST.in\")\n    simple_includes = set()\n    try:\n        with open(manifest_in, \"r\") as f:\n            for line in f:\n                if line.startswith(\"include \"):\n                    for include in line.split()[1:]:\n                        simple_includes.add(include)\n    except OSError:\n        pass\n    # That doesn't cover everything MANIFEST.in can do\n    # (http://docs.python.org/2/distutils/sourcedist.html#commands), so\n    # it might give some false negatives. Appending redundant 'include'\n    # lines is safe, though.\n    if \"versioneer.py\" not in simple_includes:\n        print(\" appending 'versioneer.py' to MANIFEST.in\")\n        with open(manifest_in, \"a\") as f:\n            f.write(\"include versioneer.py\\n\")\n    else:\n        print(\" 'versioneer.py' already in MANIFEST.in\")\n    if cfg.versionfile_source not in simple_includes:\n        print(\" appending versionfile_source ('%s') to MANIFEST.in\" %\n              cfg.versionfile_source)\n        with open(manifest_in, \"a\") as f:\n            f.write(\"include %s\\n\" % cfg.versionfile_source)\n    else:\n        print(\" versionfile_source already in MANIFEST.in\")\n\n    # Make VCS-specific changes. For git, this means creating/changing\n    # .gitattributes to mark _version.py for export-subst keyword\n    # substitution.\n    do_vcs_install(manifest_in, cfg.versionfile_source, ipy)\n    return 0",
  "def scan_setup_py():\n    \"\"\"Validate the contents of setup.py against Versioneer's expectations.\"\"\"\n    found = set()\n    setters = False\n    errors = 0\n    with open(\"setup.py\", \"r\") as f:\n        for line in f.readlines():\n            if \"import versioneer\" in line:\n                found.add(\"import\")\n            if \"versioneer.get_cmdclass()\" in line:\n                found.add(\"cmdclass\")\n            if \"versioneer.get_version()\" in line:\n                found.add(\"get_version\")\n            if \"versioneer.VCS\" in line:\n                setters = True\n            if \"versioneer.versionfile_source\" in line:\n                setters = True\n    if len(found) != 3:\n        print(\"\")\n        print(\"Your setup.py appears to be missing some important items\")\n        print(\"(but I might be wrong). Please make sure it has something\")\n        print(\"roughly like the following:\")\n        print(\"\")\n        print(\" import versioneer\")\n        print(\" setup( version=versioneer.get_version(),\")\n        print(\"        cmdclass=versioneer.get_cmdclass(),  ...)\")\n        print(\"\")\n        errors += 1\n    if setters:\n        print(\"You should remove lines like 'versioneer.VCS = ' and\")\n        print(\"'versioneer.versionfile_source = ' . This configuration\")\n        print(\"now lives in setup.cfg, and should be removed from setup.py\")\n        print(\"\")\n        errors += 1\n    return errors",
  "def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f",
  "class cmd_version(Command):\n        description = \"report generated version string\"\n        user_options = []\n        boolean_options = []\n\n        def initialize_options(self):\n            pass\n\n        def finalize_options(self):\n            pass\n\n        def run(self):\n            vers = get_versions(verbose=True)\n            print(\"Version: %s\" % vers[\"version\"])\n            print(\" full-revisionid: %s\" % vers.get(\"full-revisionid\"))\n            print(\" dirty: %s\" % vers.get(\"dirty\"))\n            print(\" date: %s\" % vers.get(\"date\"))\n            if vers[\"error\"]:\n                print(\" error: %s\" % vers[\"error\"])",
  "class cmd_build_py(_build_py):\n        def run(self):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_py.run(self)\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if cfg.versionfile_build:\n                target_versionfile = os.path.join(self.build_lib,\n                                                  cfg.versionfile_build)\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)",
  "class cmd_build_ext(_build_ext):\n        def run(self):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_ext.run(self)\n            if self.inplace:\n                # build_ext --inplace will only build extensions in\n                # build/lib<..> dir with no _version.py to write to.\n                # As in place builds will already have a _version.py\n                # in the module dir, we do not need to write one.\n                return\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            target_versionfile = os.path.join(self.build_lib,\n                                              cfg.versionfile_build)\n            print(\"UPDATING %s\" % target_versionfile)\n            write_to_version_file(target_versionfile, versions)",
  "class cmd_sdist(_sdist):\n        def run(self):\n            versions = get_versions()\n            self._versioneer_generated_versions = versions\n            # unless we update this, the command will keep using the old\n            # version\n            self.distribution.metadata.version = versions[\"version\"]\n            return _sdist.run(self)\n\n        def make_release_tree(self, base_dir, files):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            _sdist.make_release_tree(self, base_dir, files)\n            # now locate _version.py in the new base_dir directory\n            # (remembering that it may be a hardlink) and replace it with an\n            # updated value\n            target_versionfile = os.path.join(base_dir, cfg.versionfile_source)\n            print(\"UPDATING %s\" % target_versionfile)\n            write_to_version_file(target_versionfile,\n                                  self._versioneer_generated_versions)",
  "def initialize_options(self):\n            pass",
  "def finalize_options(self):\n            pass",
  "def run(self):\n            vers = get_versions(verbose=True)\n            print(\"Version: %s\" % vers[\"version\"])\n            print(\" full-revisionid: %s\" % vers.get(\"full-revisionid\"))\n            print(\" dirty: %s\" % vers.get(\"dirty\"))\n            print(\" date: %s\" % vers.get(\"date\"))\n            if vers[\"error\"]:\n                print(\" error: %s\" % vers[\"error\"])",
  "def run(self):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_py.run(self)\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if cfg.versionfile_build:\n                target_versionfile = os.path.join(self.build_lib,\n                                                  cfg.versionfile_build)\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)",
  "def run(self):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_ext.run(self)\n            if self.inplace:\n                # build_ext --inplace will only build extensions in\n                # build/lib<..> dir with no _version.py to write to.\n                # As in place builds will already have a _version.py\n                # in the module dir, we do not need to write one.\n                return\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            target_versionfile = os.path.join(self.build_lib,\n                                              cfg.versionfile_build)\n            print(\"UPDATING %s\" % target_versionfile)\n            write_to_version_file(target_versionfile, versions)",
  "class cmd_build_exe(_build_exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _build_exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, \"w\") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {\"DOLLAR\": \"$\",\n                             \"STYLE\": cfg.style,\n                             \"TAG_PREFIX\": cfg.tag_prefix,\n                             \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                             \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                             })",
  "class cmd_py2exe(_py2exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _py2exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, \"w\") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {\"DOLLAR\": \"$\",\n                             \"STYLE\": cfg.style,\n                             \"TAG_PREFIX\": cfg.tag_prefix,\n                             \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                             \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                             })",
  "def run(self):\n            versions = get_versions()\n            self._versioneer_generated_versions = versions\n            # unless we update this, the command will keep using the old\n            # version\n            self.distribution.metadata.version = versions[\"version\"]\n            return _sdist.run(self)",
  "def make_release_tree(self, base_dir, files):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            _sdist.make_release_tree(self, base_dir, files)\n            # now locate _version.py in the new base_dir directory\n            # (remembering that it may be a hardlink) and replace it with an\n            # updated value\n            target_versionfile = os.path.join(base_dir, cfg.versionfile_source)\n            print(\"UPDATING %s\" % target_versionfile)\n            write_to_version_file(target_versionfile,\n                                  self._versioneer_generated_versions)",
  "def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _build_exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, \"w\") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {\"DOLLAR\": \"$\",\n                             \"STYLE\": cfg.style,\n                             \"TAG_PREFIX\": cfg.tag_prefix,\n                             \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                             \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                             })",
  "def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _py2exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, \"w\") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {\"DOLLAR\": \"$\",\n                             \"STYLE\": cfg.style,\n                             \"TAG_PREFIX\": cfg.tag_prefix,\n                             \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                             \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                             })",
  "def get_keywords():\n    \"\"\"Get the keywords needed to look up the version information.\"\"\"\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = \"$Format:%d$\"\n    git_full = \"$Format:%H$\"\n    git_date = \"$Format:%ci$\"\n    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n    return keywords",
  "class VersioneerConfig:\n    \"\"\"Container for Versioneer configuration parameters.\"\"\"",
  "def get_config():\n    \"\"\"Create, populate and return the VersioneerConfig() object.\"\"\"\n    # these strings are filled in when 'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"nvflare/_version.py\"\n    cfg.verbose = False\n    return cfg",
  "class NotThisMethod(Exception):\n    \"\"\"Exception raised if a method is not valid for the current scenario.\"\"\"",
  "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n\n    def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n\n    return decorate",
  "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    \"\"\"Call the given command(s).\"\"\"\n    assert isinstance(commands, list)\n    process = None\n    for command in commands:\n        try:\n            dispcmd = str([command] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            process = subprocess.Popen(\n                [command] + args,\n                cwd=cwd,\n                env=env,\n                stdout=subprocess.PIPE,\n                stderr=(subprocess.PIPE if hide_stderr else None),\n            )\n            break\n        except OSError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(\"unable to find command, tried %s\" % (commands,))\n        return None, None\n    stdout = process.communicate()[0].strip().decode()\n    if process.returncode != 0:\n        if verbose:\n            print(\"unable to run %s (error)\" % dispcmd)\n            print(\"stdout was %s\" % stdout)\n        return None, process.returncode\n    return stdout, process.returncode",
  "def versions_from_parentdir(parentdir_prefix, root, verbose):\n    \"\"\"Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    \"\"\"\n    rootdirs = []\n\n    for _ in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\n                \"version\": dirname[len(parentdir_prefix) :],\n                \"full-revisionid\": None,\n                \"dirty\": False,\n                \"error\": None,\n                \"date\": None,\n            }\n        rootdirs.append(root)\n        root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(\"Tried directories %s but none started with prefix %s\" % (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(\"rootdir doesn't start with parentdir_prefix\")",
  "def git_get_keywords(versionfile_abs):\n    \"\"\"Extract version information from the given file.\"\"\"\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        with open(versionfile_abs, \"r\") as fobj:\n            for line in fobj:\n                if line.strip().startswith(\"git_refnames =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"refnames\"] = mo.group(1)\n                if line.strip().startswith(\"git_full =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"full\"] = mo.group(1)\n                if line.strip().startswith(\"git_date =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"date\"] = mo.group(1)\n    except OSError:\n        pass\n    return keywords",
  "def git_versions_from_keywords(keywords, tag_prefix, verbose):\n    \"\"\"Get version information from git keywords.\"\"\"\n    if \"refnames\" not in keywords:\n        raise NotThisMethod(\"Short version file found\")\n    date = keywords.get(\"date\")\n    if date is not None:\n        # Use only the last line.  Previous lines may contain GPG signature\n        # information.\n        date = date.splitlines()[-1]\n\n        # git-2.2.0 added \"%cI\", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer \"%ci\" (which expands to an \"ISO-8601\n        # -like\" string, which we must then edit to make compliant), because\n        # it's been around since git-1.5.3, and it's too difficult to\n        # discover which version we're using, or to work around using an\n        # older one.\n        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = {r[len(TAG) :] for r in refs if r.startswith(TAG)}\n    if not tags:\n        # Either we're using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like \"release\" and\n        # \"stabilization\", as well as \"HEAD\" and \"master\".\n        tags = {r for r in refs if re.search(r\"\\d\", r)}\n        if verbose:\n            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n    if verbose:\n        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. \"2.0\" over \"2.0rc1\"\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix) :]\n            # Filter out refs that exactly match prefix or that don't start\n            # with a number once the prefix is stripped (mostly a concern\n            # when prefix is '')\n            if not re.match(r\"\\d\", r):\n                continue\n            if verbose:\n                print(\"picking %s\" % r)\n            return {\n                \"version\": r,\n                \"full-revisionid\": keywords[\"full\"].strip(),\n                \"dirty\": False,\n                \"error\": None,\n                \"date\": date,\n            }\n    # no suitable tags, so version is \"0+unknown\", but full hex is still there\n    if verbose:\n        print(\"no suitable tags, using unknown + full revision id\")\n    return {\n        \"version\": \"0+unknown\",\n        \"full-revisionid\": keywords[\"full\"].strip(),\n        \"dirty\": False,\n        \"error\": \"no suitable tags\",\n        \"date\": None,\n    }",
  "def git_pieces_from_vcs(tag_prefix, root, verbose, runner=run_command):\n    \"\"\"Get version from 'git describe' in the root of the source tree.\n\n    This only gets called if the git-archive 'subst' keywords were *not*\n    expanded, and _version.py hasn't already been rewritten with a short\n    version string, meaning we're inside a checked out source tree.\n    \"\"\"\n    GITS = [\"git\"]\n    TAG_PREFIX_REGEX = \"*\"\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n        TAG_PREFIX_REGEX = r\"\\*\"\n\n    _, rc = runner(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root, hide_stderr=True)\n    if rc != 0:\n        if verbose:\n            print(\"Directory %s not under git control\" % root)\n        raise NotThisMethod(\"'git rev-parse --git-dir' returned error\")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn't one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = runner(\n        GITS,\n        [\"describe\", \"--tags\", \"--dirty\", \"--always\", \"--long\", \"--match\", \"%s%s\" % (tag_prefix, TAG_PREFIX_REGEX)],\n        cwd=root,\n    )\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(\"'git describe' failed\")\n    describe_out = describe_out.strip()\n    full_out, rc = runner(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(\"'git rev-parse' failed\")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[\"long\"] = full_out\n    pieces[\"short\"] = full_out[:7]  # maybe improved later\n    pieces[\"error\"] = None\n\n    branch_name, rc = runner(GITS, [\"rev-parse\", \"--abbrev-ref\", \"HEAD\"], cwd=root)\n    # --abbrev-ref was added in git-1.6.3\n    if rc != 0 or branch_name is None:\n        raise NotThisMethod(\"'git rev-parse --abbrev-ref' returned error\")\n    branch_name = branch_name.strip()\n\n    if branch_name == \"HEAD\":\n        # If we aren't exactly on a branch, pick a branch which represents\n        # the current commit. If all else fails, we are on a branchless\n        # commit.\n        branches, rc = runner(GITS, [\"branch\", \"--contains\"], cwd=root)\n        # --contains was added in git-1.5.4\n        if rc != 0 or branches is None:\n            raise NotThisMethod(\"'git branch --contains' returned error\")\n        branches = branches.split(\"\\n\")\n\n        # Remove the first line if we're running detached\n        if \"(\" in branches[0]:\n            branches.pop(0)\n\n        # Strip off the leading \"* \" from the list of branches.\n        branches = [branch[2:] for branch in branches]\n        if \"master\" in branches:\n            branch_name = \"master\"\n        elif not branches:\n            branch_name = None\n        else:\n            # Pick the first branch that is returned. Good or bad.\n            branch_name = branches[0]\n\n    pieces[\"branch\"] = branch_name\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(\"-dirty\")\n    pieces[\"dirty\"] = dirty\n    if dirty:\n        git_describe = git_describe[: git_describe.rindex(\"-dirty\")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if \"-\" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\"^(.+)-(\\d+)-g([0-9a-f]+)$\", git_describe)\n        if not mo:\n            # unparsable. Maybe git-describe is misbehaving?\n            pieces[\"error\"] = \"unable to parse git-describe output: '%s'\" % describe_out\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n                print(fmt % (full_tag, tag_prefix))\n            pieces[\"error\"] = \"tag '%s' doesn't start with prefix '%s'\" % (full_tag, tag_prefix)\n            return pieces\n        pieces[\"closest-tag\"] = full_tag[len(tag_prefix) :]\n\n        # distance: number of commits since tag\n        pieces[\"distance\"] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[\"short\"] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[\"closest-tag\"] = None\n        count_out, rc = runner(GITS, [\"rev-list\", \"HEAD\", \"--count\"], cwd=root)\n        pieces[\"distance\"] = int(count_out)  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = runner(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"], cwd=root)[0].strip()\n    # Use only the last line.  Previous lines may contain GPG signature\n    # information.\n    date = date.splitlines()[-1]\n    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n\n    return pieces",
  "def plus_or_dot(pieces):\n    \"\"\"Return a + if we don't already have one, else return a .\"\"\"\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"",
  "def render_pep440(pieces):\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += plus_or_dot(pieces)\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered",
  "def render_pep440_branch(pieces):\n    \"\"\"TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch. Note that .dev0 sorts backwards\n    (a feature branch will appear \"older\" than the master branch).\n\n    Exceptions:\n    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0\"\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+untagged.%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered",
  "def pep440_split_post(ver):\n    \"\"\"Split pep440 version string at the post-release segment.\n\n    Returns the release segments before the post-release and the\n    post-release version number (or -1 if no post-release segment is present).\n    \"\"\"\n    vc = str.split(ver, \".post\")\n    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None",
  "def render_pep440_pre(pieces):\n    \"\"\"TAG[.postN.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post0.devDISTANCE\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        if pieces[\"distance\"]:\n            # update the post release segment\n            tag_version, post_version = pep440_split_post(pieces[\"closest-tag\"])\n            rendered = tag_version\n            if post_version is not None:\n                rendered += \".post%d.dev%d\" % (post_version + 1, pieces[\"distance\"])\n            else:\n                rendered += \".post0.dev%d\" % (pieces[\"distance\"])\n        else:\n            # no commits, use the tag as the version\n            rendered = pieces[\"closest-tag\"]\n    else:\n        # exception #1\n        rendered = \"0.post0.dev%d\" % pieces[\"distance\"]\n    return rendered",
  "def render_pep440_post(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The \".dev0\" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear \"older\" than the corresponding clean one),\n    but you shouldn't be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%s\" % pieces[\"short\"]\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n        rendered += \"+g%s\" % pieces[\"short\"]\n    return rendered",
  "def render_pep440_post_branch(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%s\" % pieces[\"short\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+g%s\" % pieces[\"short\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered",
  "def render_pep440_old(pieces):\n    \"\"\"TAG[.postDISTANCE[.dev0]] .\n\n    The \".dev0\" means dirty.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n    return rendered",
  "def render_git_describe(pieces):\n    \"\"\"TAG[-DISTANCE-gHEX][-dirty].\n\n    Like 'git describe --tags --dirty --always'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered",
  "def render_git_describe_long(pieces):\n    \"\"\"TAG-DISTANCE-gHEX[-dirty].\n\n    Like 'git describe --tags --dirty --always -long'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered",
  "def render(pieces, style):\n    \"\"\"Render the given version pieces into the requested style.\"\"\"\n    if pieces[\"error\"]:\n        return {\n            \"version\": \"unknown\",\n            \"full-revisionid\": pieces.get(\"long\"),\n            \"dirty\": None,\n            \"error\": pieces[\"error\"],\n            \"date\": None,\n        }\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-branch\":\n        rendered = render_pep440_branch(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-post-branch\":\n        rendered = render_pep440_post_branch(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\n        \"version\": rendered,\n        \"full-revisionid\": pieces[\"long\"],\n        \"dirty\": pieces[\"dirty\"],\n        \"error\": None,\n        \"date\": pieces.get(\"date\"),\n    }",
  "def get_versions():\n    \"\"\"Get version information or return default if unable to do so.\"\"\"\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix, verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for _ in cfg.versionfile_source.split(\"/\"):\n            root = os.path.dirname(root)\n    except NameError:\n        return {\n            \"version\": \"0+unknown\",\n            \"full-revisionid\": None,\n            \"dirty\": None,\n            \"error\": \"unable to find root of source tree\",\n            \"date\": None,\n        }\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {\n        \"version\": \"0+unknown\",\n        \"full-revisionid\": None,\n        \"dirty\": None,\n        \"error\": \"unable to compute version\",\n        \"date\": None,\n    }",
  "def decorate(f):\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f",
  "class DummyOverseerAgent(OverseerAgent):\n    SSID = \"ebc6125d-0a56-4688-9b08-355fe9e4d61a\"\n\n    def __init__(self, sp_end_point, heartbeat_interval=5):\n        self._base_init(sp_end_point)\n\n        self._report_and_query = threading.Thread(target=self._rnq_worker, args=())\n        self._flag = threading.Event()\n        self._asked_to_exit = False\n        self._update_callback = None\n        self._conditional_cb = False\n        self._heartbeat_interval = heartbeat_interval\n\n    def _base_init(self, sp_end_point):\n        self.sp_end_point = sp_end_point\n        name, fl_port, admin_port = self.sp_end_point.split(\":\")\n        self._psp = SP(name, fl_port, admin_port, DummyOverseerAgent.SSID, True)\n        psp_dict = {\n            \"sp_end_point\": sp_end_point,\n            \"service_seesion_id\": DummyOverseerAgent.SSID,\n            \"primary\": True,\n            \"state\": \"online\",\n        }\n        self._overseer_info = {\n            \"primary_sp\": psp_dict,\n            \"sp_list\": [psp_dict],\n            \"system\": \"ready\",\n        }\n\n    def initialize(self, fl_ctx: FLContext):\n        sp_end_point = fl_ctx.get_prop(FLContextKey.SP_END_POINT)\n        if sp_end_point:\n            self._base_init(sp_end_point)\n\n    def is_shutdown(self) -> bool:\n        \"\"\"Return whether the agent receives a shutdown request.\"\"\"\n        return False\n\n    def get_primary_sp(self) -> SP:\n        \"\"\"Return current primary service provider. The PSP is static in the dummy agent.\"\"\"\n        return self._psp\n\n    def promote_sp(self, sp_end_point, headers=None):\n        resp = Response()\n        resp.status_code = 200\n        resp.content = json.dumps({\"Error\": \"this functionality is not supported by the dummy agent\"})\n        return resp\n\n    def start(self, update_callback=None, conditional_cb=False):\n        self.conditional_cb = conditional_cb\n        self._update_callback = update_callback\n        self._report_and_query.start()\n        self._flag.set()\n\n    def pause(self):\n        self._flag.clear()\n\n    def resume(self):\n        self._flag.set()\n\n    def set_state(self, state):\n        resp = Response()\n        resp.status_code = 200\n        resp.content = json.dumps({\"Error\": \"this functionality is not supported by the dummy agent\"})\n        return resp\n\n    def end(self):\n        self._flag.set()\n        self._asked_to_exit = True\n        self._report_and_query.join()\n\n    def _do_callback(self):\n        if self._update_callback:\n            self._update_callback(self)\n\n    def _rnq_worker(self):\n        while not self._asked_to_exit:\n            self._flag.wait()\n            if not self.conditional_cb:\n                self._do_callback()\n            time.sleep(self._heartbeat_interval)",
  "def __init__(self, sp_end_point, heartbeat_interval=5):\n        self._base_init(sp_end_point)\n\n        self._report_and_query = threading.Thread(target=self._rnq_worker, args=())\n        self._flag = threading.Event()\n        self._asked_to_exit = False\n        self._update_callback = None\n        self._conditional_cb = False\n        self._heartbeat_interval = heartbeat_interval",
  "def _base_init(self, sp_end_point):\n        self.sp_end_point = sp_end_point\n        name, fl_port, admin_port = self.sp_end_point.split(\":\")\n        self._psp = SP(name, fl_port, admin_port, DummyOverseerAgent.SSID, True)\n        psp_dict = {\n            \"sp_end_point\": sp_end_point,\n            \"service_seesion_id\": DummyOverseerAgent.SSID,\n            \"primary\": True,\n            \"state\": \"online\",\n        }\n        self._overseer_info = {\n            \"primary_sp\": psp_dict,\n            \"sp_list\": [psp_dict],\n            \"system\": \"ready\",\n        }",
  "def initialize(self, fl_ctx: FLContext):\n        sp_end_point = fl_ctx.get_prop(FLContextKey.SP_END_POINT)\n        if sp_end_point:\n            self._base_init(sp_end_point)",
  "def is_shutdown(self) -> bool:\n        \"\"\"Return whether the agent receives a shutdown request.\"\"\"\n        return False",
  "def get_primary_sp(self) -> SP:\n        \"\"\"Return current primary service provider. The PSP is static in the dummy agent.\"\"\"\n        return self._psp",
  "def promote_sp(self, sp_end_point, headers=None):\n        resp = Response()\n        resp.status_code = 200\n        resp.content = json.dumps({\"Error\": \"this functionality is not supported by the dummy agent\"})\n        return resp",
  "def start(self, update_callback=None, conditional_cb=False):\n        self.conditional_cb = conditional_cb\n        self._update_callback = update_callback\n        self._report_and_query.start()\n        self._flag.set()",
  "def pause(self):\n        self._flag.clear()",
  "def resume(self):\n        self._flag.set()",
  "def set_state(self, state):\n        resp = Response()\n        resp.status_code = 200\n        resp.content = json.dumps({\"Error\": \"this functionality is not supported by the dummy agent\"})\n        return resp",
  "def end(self):\n        self._flag.set()\n        self._asked_to_exit = True\n        self._report_and_query.join()",
  "def _do_callback(self):\n        if self._update_callback:\n            self._update_callback(self)",
  "def _rnq_worker(self):\n        while not self._asked_to_exit:\n            self._flag.wait()\n            if not self.conditional_cb:\n                self._do_callback()\n            time.sleep(self._heartbeat_interval)",
  "class HttpOverseerAgent(OverseerAgent):\n    def __init__(\n        self,\n        role,\n        overseer_end_point,\n        project,\n        name: str,\n        fl_port: str = \"\",\n        admin_port: str = \"\",\n        heartbeat_interval=5,\n    ):\n        if role not in [\"server\", \"client\", \"admin\"]:\n            raise ValueError(f'Expect role in [\"server\", \"client\", \"admin\"] but got {role}')\n        self._role = role\n        self._overseer_end_point = overseer_end_point\n        self._project = project\n        self._session = None\n        self._status_lock = threading.Lock()\n        self._report_and_query = threading.Thread(target=self._rnq_worker, args=())\n        self._psp = SP()\n        self._flag = threading.Event()\n        self._ca_path = None\n        self._cert_path = None\n        self._prv_key_path = None\n        self._last_service_session_id = \"\"\n        self._asked_to_exit = False\n        self._logger = logging.getLogger(self.__class__.__name__)\n        self._retry_delay = 4\n        self._asked_to_stop_retrying = False\n        self._overseer_info = {}\n        self._update_callback = None\n        self._conditional_cb = False\n        if self._role == \"server\":\n            self._sp_end_point = \":\".join([name, fl_port, admin_port])\n        self._heartbeat_interval = heartbeat_interval\n\n    def _send(\n        self, api_point, headers: Optional[Dict[str, Any]] = None, payload: Optional[Dict[str, Any]] = None\n    ) -> Dict[str, Any]:\n        try_count = 0\n        while not self._asked_to_stop_retrying:\n            try:\n                req = Request(\"POST\", api_point, json=payload, headers=headers)\n                prepared = self._session.prepare_request(req)\n                resp = self._session.send(prepared)\n                return resp\n            except RequestException as e:\n                try_count += 1\n                # self._logger.info(f\"tried: {try_count} with exception: {e}\")\n                time.sleep(self._retry_delay)\n\n    def set_secure_context(self, ca_path: str, cert_path: str = \"\", prv_key_path: str = \"\"):\n        self._ca_path = ca_path\n        self._cert_path = cert_path\n        self._prv_key_path = prv_key_path\n\n    def start(self, update_callback=None, conditional_cb=False):\n        self._session = Session()\n        adapter = HTTPAdapter(max_retries=1)\n        self._session.mount(\"http://\", adapter)\n        self._session.mount(\"https://\", adapter)\n        if self._ca_path:\n            self._session.verify = self._ca_path\n            self._session.cert = (self._cert_path, self._prv_key_path)\n        self.conditional_cb = conditional_cb\n        if update_callback:\n            self._update_callback = update_callback\n        self._report_and_query.start()\n        self._flag.set()\n\n    def pause(self):\n        self._asked_to_stop_retrying = True\n        self._flag.clear()\n\n    def resume(self):\n        self._asked_to_stop_retrying = False\n        self._flag.set()\n\n    def end(self):\n        self._asked_to_stop_retrying = True\n        self._flag.set()\n        self._asked_to_exit = True\n        self._report_and_query.join()\n\n    def is_shutdown(self) -> bool:\n        \"\"\"Return whether the agent receives a shutdown request.\"\"\"\n        return self._overseer_info.get(\"system\") == \"shutdown\"\n\n    def get_primary_sp(self) -> SP:\n        \"\"\"Return current primary service provider.\n\n        If primary sp not available, such as not reported by SD, connection to SD not established yet\n        the name and ports will be empty strings.\n        \"\"\"\n        return self._psp\n\n    def promote_sp(self, sp_end_point, headers=None):\n        api_point = self._overseer_end_point + \"/promote\"\n        return self._send(api_point, headers=None, payload={\"sp_end_point\": sp_end_point, \"project\": self._project})\n\n    def set_state(self, state):\n        api_point = self._overseer_end_point + \"/state\"\n        return self._send(api_point, payload={\"state\": state})\n\n    def _do_callback(self):\n        if self._update_callback:\n            self._update_callback(self)\n\n    def _handle_ssid(self, ssid):\n        if not self.conditional_cb or self._last_service_session_id != ssid:\n            self._last_service_session_id = ssid\n            self._do_callback()\n\n    def _prepare_data(self):\n        data = dict(role=self._role, project=self._project)\n        return data\n\n    def _rnq_worker(self):\n        data = self._prepare_data()\n        if self._role == \"server\":\n            data[\"sp_end_point\"] = self._sp_end_point\n        api_point = self._overseer_end_point + \"/heartbeat\"\n        while not self._asked_to_exit:\n            self._flag.wait()\n            self._rnq(api_point, headers=None, data=data)\n            time.sleep(self._heartbeat_interval)\n\n    def _rnq(self, api_point, headers, data):\n        resp = self._send(api_point, headers=headers, payload=data)\n        if resp is None:\n            return\n        if resp.status_code != codes.ok:\n            return\n        self._overseer_info = resp.json()\n        psp = self._overseer_info.get(\"primary_sp\")\n        if psp:\n            name, fl_port, admin_port = psp.get(\"sp_end_point\").split(\":\")\n            service_session_id = psp.get(\"service_session_id\", \"\")\n            self._psp = SP(name, fl_port, admin_port, service_session_id, True)\n            # last_heartbeat = psp.get(\"last_heartbeat\", \"\")\n            self._handle_ssid(service_session_id)\n        else:\n            self._psp = SP()\n            service_session_id = \"\"\n            self._handle_ssid(service_session_id)",
  "def __init__(\n        self,\n        role,\n        overseer_end_point,\n        project,\n        name: str,\n        fl_port: str = \"\",\n        admin_port: str = \"\",\n        heartbeat_interval=5,\n    ):\n        if role not in [\"server\", \"client\", \"admin\"]:\n            raise ValueError(f'Expect role in [\"server\", \"client\", \"admin\"] but got {role}')\n        self._role = role\n        self._overseer_end_point = overseer_end_point\n        self._project = project\n        self._session = None\n        self._status_lock = threading.Lock()\n        self._report_and_query = threading.Thread(target=self._rnq_worker, args=())\n        self._psp = SP()\n        self._flag = threading.Event()\n        self._ca_path = None\n        self._cert_path = None\n        self._prv_key_path = None\n        self._last_service_session_id = \"\"\n        self._asked_to_exit = False\n        self._logger = logging.getLogger(self.__class__.__name__)\n        self._retry_delay = 4\n        self._asked_to_stop_retrying = False\n        self._overseer_info = {}\n        self._update_callback = None\n        self._conditional_cb = False\n        if self._role == \"server\":\n            self._sp_end_point = \":\".join([name, fl_port, admin_port])\n        self._heartbeat_interval = heartbeat_interval",
  "def _send(\n        self, api_point, headers: Optional[Dict[str, Any]] = None, payload: Optional[Dict[str, Any]] = None\n    ) -> Dict[str, Any]:\n        try_count = 0\n        while not self._asked_to_stop_retrying:\n            try:\n                req = Request(\"POST\", api_point, json=payload, headers=headers)\n                prepared = self._session.prepare_request(req)\n                resp = self._session.send(prepared)\n                return resp\n            except RequestException as e:\n                try_count += 1\n                # self._logger.info(f\"tried: {try_count} with exception: {e}\")\n                time.sleep(self._retry_delay)",
  "def set_secure_context(self, ca_path: str, cert_path: str = \"\", prv_key_path: str = \"\"):\n        self._ca_path = ca_path\n        self._cert_path = cert_path\n        self._prv_key_path = prv_key_path",
  "def start(self, update_callback=None, conditional_cb=False):\n        self._session = Session()\n        adapter = HTTPAdapter(max_retries=1)\n        self._session.mount(\"http://\", adapter)\n        self._session.mount(\"https://\", adapter)\n        if self._ca_path:\n            self._session.verify = self._ca_path\n            self._session.cert = (self._cert_path, self._prv_key_path)\n        self.conditional_cb = conditional_cb\n        if update_callback:\n            self._update_callback = update_callback\n        self._report_and_query.start()\n        self._flag.set()",
  "def pause(self):\n        self._asked_to_stop_retrying = True\n        self._flag.clear()",
  "def resume(self):\n        self._asked_to_stop_retrying = False\n        self._flag.set()",
  "def end(self):\n        self._asked_to_stop_retrying = True\n        self._flag.set()\n        self._asked_to_exit = True\n        self._report_and_query.join()",
  "def is_shutdown(self) -> bool:\n        \"\"\"Return whether the agent receives a shutdown request.\"\"\"\n        return self._overseer_info.get(\"system\") == \"shutdown\"",
  "def get_primary_sp(self) -> SP:\n        \"\"\"Return current primary service provider.\n\n        If primary sp not available, such as not reported by SD, connection to SD not established yet\n        the name and ports will be empty strings.\n        \"\"\"\n        return self._psp",
  "def promote_sp(self, sp_end_point, headers=None):\n        api_point = self._overseer_end_point + \"/promote\"\n        return self._send(api_point, headers=None, payload={\"sp_end_point\": sp_end_point, \"project\": self._project})",
  "def set_state(self, state):\n        api_point = self._overseer_end_point + \"/state\"\n        return self._send(api_point, payload={\"state\": state})",
  "def _do_callback(self):\n        if self._update_callback:\n            self._update_callback(self)",
  "def _handle_ssid(self, ssid):\n        if not self.conditional_cb or self._last_service_session_id != ssid:\n            self._last_service_session_id = ssid\n            self._do_callback()",
  "def _prepare_data(self):\n        data = dict(role=self._role, project=self._project)\n        return data",
  "def _rnq_worker(self):\n        data = self._prepare_data()\n        if self._role == \"server\":\n            data[\"sp_end_point\"] = self._sp_end_point\n        api_point = self._overseer_end_point + \"/heartbeat\"\n        while not self._asked_to_exit:\n            self._flag.wait()\n            self._rnq(api_point, headers=None, data=data)\n            time.sleep(self._heartbeat_interval)",
  "def _rnq(self, api_point, headers, data):\n        resp = self._send(api_point, headers=headers, payload=data)\n        if resp is None:\n            return\n        if resp.status_code != codes.ok:\n            return\n        self._overseer_info = resp.json()\n        psp = self._overseer_info.get(\"primary_sp\")\n        if psp:\n            name, fl_port, admin_port = psp.get(\"sp_end_point\").split(\":\")\n            service_session_id = psp.get(\"service_session_id\", \"\")\n            self._psp = SP(name, fl_port, admin_port, service_session_id, True)\n            # last_heartbeat = psp.get(\"last_heartbeat\", \"\")\n            self._handle_ssid(service_session_id)\n        else:\n            self._psp = SP()\n            service_session_id = \"\"\n            self._handle_ssid(service_session_id)",
  "def setup_basic_info():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-p\", \"--project\", type=str, default=\"example_project\", help=\"project name\")\n    parser.add_argument(\"-r\", \"--role\", type=str, help=\"role (server, client or admin)\")\n    parser.add_argument(\"-n\", \"--name\", type=str, help=\"globally unique name\")\n    parser.add_argument(\"-f\", \"--fl_port\", type=str, help=\"fl port number\")\n    parser.add_argument(\"-a\", \"--admin_port\", type=str, help=\"adm port number\")\n    parser.add_argument(\"-s\", \"--sleep\", type=float, help=\"sleep (seconds) in heartbeat\")\n    parser.add_argument(\"-c\", \"--ca_path\", type=str, help=\"root CA path\")\n    parser.add_argument(\"-o\", \"--overseer_url\", type=str, help=\"Overseer URL\")\n    parser.add_argument(\"-t\", \"--cert_path\", type=str, help=\"cert path\")\n    parser.add_argument(\"-v\", \"--prv_key_path\", type=str, help=\"priviate key path\")\n\n    args = parser.parse_args()\n\n    overseer_agent = HttpOverseerAgent(\n        overseer_end_point=args.overseer_url,\n        project=args.project,\n        role=args.role,\n        name=args.name,\n        fl_port=args.fl_port,\n        admin_port=args.admin_port,\n        heartbeat_interval=args.sleep,\n    )\n\n    if args.ca_path:\n        overseer_agent.set_secure_context(\n            ca_path=args.ca_path, cert_path=args.cert_path, prv_key_path=args.prv_key_path\n        )\n    return overseer_agent",
  "def main():\n    overseer_agent = setup_basic_info()\n    overseer_agent.start(simple_callback, conditional_cb=True)\n    while True:\n        answer = input(\"(p)ause/(r)esume/(s)witch/(d)ump/(e)nd? \")\n        normalized_answer = answer.strip().upper()\n        if normalized_answer == \"P\":\n            overseer_agent.pause()\n        elif normalized_answer == \"R\":\n            overseer_agent.resume()\n        elif normalized_answer == \"E\":\n            overseer_agent.end()\n            break\n        elif normalized_answer == \"D\":\n            pprint(overseer_agent._overseer_info)\n        elif normalized_answer == \"\":\n            continue\n        elif normalized_answer[0] == \"S\":\n            split = normalized_answer.split()\n            if len(split) == 2:\n                sp_index = int(split[1])\n            else:\n                print(\"expect sp index but got nothing.  Please provide the sp index to be promoted\")\n                continue\n            try:\n                sp = overseer_agent._overseer_info.get(\"sp_list\")[sp_index]\n            except IndexError:\n                print(\"index out of range\")\n            else:\n                resp = overseer_agent.promote_sp(sp.get(\"sp_end_point\"))\n                pprint(resp.json())",
  "def simple_callback(overseer_agent):\n    print(f\"\\nGot callback {overseer_agent.get_primary_sp()}\")",
  "class HACommandModule(CommandModule):\n    \"\"\"Command module with commands for management in relation to the high availability framework.\"\"\"\n\n    def __init__(self):\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=\"ha_mgmt\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"list_sp\",\n                    description=\"list service providers information from previous heartbeat\",\n                    usage=\"list_sp\",\n                    handler_func=self.list_sp,\n                ),\n                CommandSpec(\n                    name=\"get_active_sp\",\n                    description=\"get active service provider\",\n                    usage=\"get_active_sp\",\n                    handler_func=self.get_active_sp,\n                ),\n                CommandSpec(\n                    name=\"promote_sp\",\n                    description=\"promote active service provider to specified\",\n                    usage=\"promote_sp sp_end_point\",\n                    handler_func=self.promote_sp,\n                ),\n                CommandSpec(\n                    name=\"shutdown_system\",\n                    description=\"shut down entire system by setting the system state to shutdown through the overseer\",\n                    usage=\"shutdown_system\",\n                    handler_func=self.shutdown_system,\n                ),\n            ],\n        )\n\n    def list_sp(self, args, api):\n        \"\"\"List service provider information based on the last heartbeat from the overseer.\n\n        Details are used for displaying the response in the CLI, and data is the data in a dict that is provided in FLAdminAPI.\n\n        \"\"\"\n        return {\n            \"status\": APIStatus.SUCCESS,\n            \"details\": str(api.overseer_agent._overseer_info),\n            \"data\": api.overseer_agent._overseer_info,\n        }\n\n    def get_active_sp(self, args, api):\n        return {\"status\": APIStatus.SUCCESS, \"details\": str(api.overseer_agent.get_primary_sp())}\n\n    def promote_sp(self, args, api):\n        if len(args) != 2:\n            return {\"status\": APIStatus.ERROR_SYNTAX, \"details\": \"usage: promote_sp example1.com:8002:8003\"}\n\n        sp_end_point = args[1]\n        resp = api.overseer_agent.promote_sp(sp_end_point)\n        if json.loads(resp.text).get(\"Error\"):\n            return {\n                \"status\": APIStatus.ERROR_RUNTIME,\n                \"details\": \"Error: {}\".format(json.loads(resp.text).get(\"Error\")),\n            }\n        else:\n            return {\n                \"status\": APIStatus.SUCCESS,\n                \"details\": \"Promoted endpoint: {}. Synchronizing with overseer...\".format(sp_end_point),\n            }\n\n    def shutdown_system(self, args, api):\n        try:\n            status = api.do_command(\"check_status server\").get(\"data\")\n            if status[0].get(\"data\") != \"Engine status: stopped\":\n                return {\n                    \"status\": APIStatus.ERROR_RUNTIME,\n                    \"details\": \"Error: There are still jobs running. Please let them finish or abort_job before attempting shutdown.\",\n                }\n        except Exception as e:\n            return {\n                \"status\": APIStatus.ERROR_RUNTIME,\n                \"details\": \"Error getting server status to make sure all jobs are stopped before shutting down system: {}\".format(\n                    e\n                ),\n            }\n        print(\"Shutting down the system...\")\n        resp = api.overseer_agent.set_state(\"shutdown\")\n        if json.loads(resp.text).get(\"Error\"):\n            return {\n                \"status\": APIStatus.ERROR_RUNTIME,\n                \"details\": \"Error: {}\".format(json.loads(resp.text).get(\"Error\")),\n            }\n        else:\n            return {\"status\": APIStatus.SUCCESS, \"details\": \"Set state to shutdown in overseer.\"}",
  "def __init__(self):\n        self.logger = logging.getLogger(self.__class__.__name__)",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=\"ha_mgmt\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"list_sp\",\n                    description=\"list service providers information from previous heartbeat\",\n                    usage=\"list_sp\",\n                    handler_func=self.list_sp,\n                ),\n                CommandSpec(\n                    name=\"get_active_sp\",\n                    description=\"get active service provider\",\n                    usage=\"get_active_sp\",\n                    handler_func=self.get_active_sp,\n                ),\n                CommandSpec(\n                    name=\"promote_sp\",\n                    description=\"promote active service provider to specified\",\n                    usage=\"promote_sp sp_end_point\",\n                    handler_func=self.promote_sp,\n                ),\n                CommandSpec(\n                    name=\"shutdown_system\",\n                    description=\"shut down entire system by setting the system state to shutdown through the overseer\",\n                    usage=\"shutdown_system\",\n                    handler_func=self.shutdown_system,\n                ),\n            ],\n        )",
  "def list_sp(self, args, api):\n        \"\"\"List service provider information based on the last heartbeat from the overseer.\n\n        Details are used for displaying the response in the CLI, and data is the data in a dict that is provided in FLAdminAPI.\n\n        \"\"\"\n        return {\n            \"status\": APIStatus.SUCCESS,\n            \"details\": str(api.overseer_agent._overseer_info),\n            \"data\": api.overseer_agent._overseer_info,\n        }",
  "def get_active_sp(self, args, api):\n        return {\"status\": APIStatus.SUCCESS, \"details\": str(api.overseer_agent.get_primary_sp())}",
  "def promote_sp(self, args, api):\n        if len(args) != 2:\n            return {\"status\": APIStatus.ERROR_SYNTAX, \"details\": \"usage: promote_sp example1.com:8002:8003\"}\n\n        sp_end_point = args[1]\n        resp = api.overseer_agent.promote_sp(sp_end_point)\n        if json.loads(resp.text).get(\"Error\"):\n            return {\n                \"status\": APIStatus.ERROR_RUNTIME,\n                \"details\": \"Error: {}\".format(json.loads(resp.text).get(\"Error\")),\n            }\n        else:\n            return {\n                \"status\": APIStatus.SUCCESS,\n                \"details\": \"Promoted endpoint: {}. Synchronizing with overseer...\".format(sp_end_point),\n            }",
  "def shutdown_system(self, args, api):\n        try:\n            status = api.do_command(\"check_status server\").get(\"data\")\n            if status[0].get(\"data\") != \"Engine status: stopped\":\n                return {\n                    \"status\": APIStatus.ERROR_RUNTIME,\n                    \"details\": \"Error: There are still jobs running. Please let them finish or abort_job before attempting shutdown.\",\n                }\n        except Exception as e:\n            return {\n                \"status\": APIStatus.ERROR_RUNTIME,\n                \"details\": \"Error getting server status to make sure all jobs are stopped before shutting down system: {}\".format(\n                    e\n                ),\n            }\n        print(\"Shutting down the system...\")\n        resp = api.overseer_agent.set_state(\"shutdown\")\n        if json.loads(resp.text).get(\"Error\"):\n            return {\n                \"status\": APIStatus.ERROR_RUNTIME,\n                \"details\": \"Error: {}\".format(json.loads(resp.text).get(\"Error\")),\n            }\n        else:\n            return {\"status\": APIStatus.SUCCESS, \"details\": \"Set state to shutdown in overseer.\"}",
  "def get_system_state():\n    global system_state\n    return system_state",
  "def set_system_state(state):\n    global system_state\n    system_state = state\n    return get_system_state()",
  "def check_integrity(privilege_file):\n    data, sig = SecurityContentService.load_content(privilege_file)\n    if sig != LoadResult.OK:\n        data = None\n    return data",
  "def load_privilege():\n    privilege_file = os.environ.get(\"AUTHZ_FILE\", \"privilege.yml\")\n    file_path = pathlib.Path(privilege_file)\n    folder = file_path.parent.absolute()\n    file = file_path.name\n    SecurityContentService.initialize(folder)\n    privilege_content = check_integrity(file)\n    try:\n        privilege = load_yaml(privilege_content)\n        print(f\"privileged users: {privilege.get('super')}\")\n    except:\n        privilege = dict()\n    return privilege",
  "def update_sp_state(project, now, heartbeat_timeout=10):\n    valid_starting = now - timedelta(seconds=heartbeat_timeout)\n    # mark all late SP as offline and not primary\n    # print(f\"{now=} {valid_starting=}\")\n    for sp in get_all_sp(project):\n        if datetime.fromisoformat(sp[\"last_heartbeat\"]) < valid_starting:\n            sp[\"state\"] = \"offline\"\n            sp[\"primary\"] = False\n        else:\n            sp[\"state\"] = \"online\"\n        update_sp(sp)",
  "def simple_PSP_policy(incoming_sp, now):\n    \"\"\"Find the primary SP (PSP).\n\n    If there is no PSP or current PSP timeout, choose one without heartbeat timeout.\n    \"\"\"\n    project = incoming_sp[\"project\"]\n    sp = get_sp_by(dict(project=project, sp_end_point=incoming_sp[\"sp_end_point\"]))\n    if sp:\n        sp[\"last_heartbeat\"] = now.isoformat()\n        update_sp(sp)\n    else:\n        update_sp(\n            dict(\n                project=incoming_sp[\"project\"],\n                sp_end_point=incoming_sp[\"sp_end_point\"],\n                last_heartbeat=now.isoformat(),\n                state=\"online\",\n                primary=False,\n            )\n        )\n\n    psp = get_primary_sp(project)\n    if not psp:\n        psp = get_sp_by(dict(project=project, state=\"online\"))\n        if psp:\n            print(f\"{psp['sp_end_point']} online\")\n            psp[\"primary\"] = True\n            psp[\"service_session_id\"] = str(uuid.uuid4())\n            update_sp(psp)\n\n    return psp",
  "def promote_sp(sp):\n    psp = get_sp_by(sp)\n    project = sp[\"project\"]\n    sp_end_point = sp[\"sp_end_point\"]\n    if psp and psp[\"state\"] == \"online\":\n        current_psp = get_primary_sp(project)\n        if all(current_psp[k] == v for k, v in sp.items()):\n            return True, f\"Same sp_end_point, no need to promote {sp_end_point}.\"\n        psp[\"primary\"] = True\n        current_psp[\"primary\"] = False\n        psp[\"service_session_id\"] = str(uuid.uuid4())\n        print(f\"{psp['sp_end_point']} promoted\")\n        print(f\"{current_psp['sp_end_point']} demoted\")\n        update_sp(psp)\n        update_sp(current_psp)\n        return False, psp\n    else:\n        return True, f\"Unable to promote {sp_end_point}, either offline or not registered.\"",
  "class ClientAuthWorker(SyncWorker):\n    def handle_request(self, listener, req, client, addr):\n        cert = client.getpeercert()\n        subject = client.getpeercert().get(\"subject\")\n        commonName = next(value for ((key, value),) in subject if key == \"commonName\")\n        headers = dict(req.headers)\n        headers[\"X-USER\"] = commonName\n        req.headers = list(headers.items())\n\n        super(ClientAuthWorker, self).handle_request(listener, req, client, addr)",
  "def handle_request(self, listener, req, client, addr):\n        cert = client.getpeercert()\n        subject = client.getpeercert().get(\"subject\")\n        commonName = next(value for ((key, value),) in subject if key == \"commonName\")\n        headers = dict(req.headers)\n        headers[\"X-USER\"] = commonName\n        req.headers = list(headers.items())\n\n        super(ClientAuthWorker, self).handle_request(listener, req, client, addr)",
  "def heartbeat():\n    if request.method == \"POST\":\n        req = request.json\n        project = req.get(\"project\")\n        role = req.get(\"role\")\n        if project is None or role is None:\n            return jsonify({\"Error\": \"project and role must be provided\"})\n        now = datetime.utcnow()\n        update_sp_state(project, now, heartbeat_timeout=heartbeat_timeout)\n        if role == \"server\":\n            sp_end_point = req.get(\"sp_end_point\")\n            if sp_end_point is None:\n                return jsonify({\"Error\": \"sp_end_point is not provided\"})\n            incoming_sp = dict(sp_end_point=sp_end_point, project=project)\n            psp = simple_PSP_policy(incoming_sp, now)\n        elif role in [\"client\", \"admin\"]:\n            psp = get_primary_sp(project)\n        else:\n            psp = {}\n        return jsonify({\"primary_sp\": psp, \"sp_list\": get_all_sp(project), \"system\": get_system_state()})",
  "def promote():\n    if app.config.get(\"DEBUG\") is not True and request.headers.get(\"X-USER\") not in privilege_dict.get(\"super\", {}):\n        return jsonify({\"Error\": \"No rights\"})\n    if request.method == \"POST\":\n        req = request.json\n        sp_end_point = req.get(\"sp_end_point\", \"\")\n        project = req.get(\"project\", \"\")\n        if project and sp_end_point:\n            incoming_sp = dict(sp_end_point=sp_end_point, project=project)\n            err, result = promote_sp(incoming_sp)\n            if not err:\n                return jsonify({\"primary_sp\": result})\n            else:\n                return jsonify({\"Error\": result})\n        else:\n            return jsonify({\"Error\": \"Wrong project or sp_end_point.\"})",
  "def state():\n    if app.config.get(\"DEBUG\") is not True and request.headers.get(\"X-USER\") not in privilege_dict.get(\"super\", {}):\n        return jsonify({\"Error\": \"No rights\"})\n    req = request.json\n    state = req.get(\"state\")\n    if state not in [\"ready\", \"shutdown\"]:\n        return jsonify({\"Error\": \"Wrong state\"})\n    set_system_state(state)\n    return jsonify({\"Status\": get_system_state()})",
  "def refresh():\n    if request.headers.get(\"X-USER\") not in privilege_dict.get(\"super\", {}):\n        return jsonify({\"Error\": \"No rights\"})\n    return jsonify({\"Status\": \"Error.  API disabled.\"})",
  "def _primary_key(sp):\n    return f'{sp[\"project\"]}/{sp[\"sp_end_point\"]}'",
  "def get_all_sp(project):\n    with data_store_lock:\n        sp_list = [v for v in data_store[\"SP\"].values() if v[\"project\"] == project]\n    return sp_list",
  "def get_primary_sp(project):\n    psp = {}\n    with data_store_lock:\n        for _, sp in data_store[\"SP\"].items():\n            if sp[\"primary\"] and sp[\"project\"] == project:\n                psp = sp\n                break\n    return psp",
  "def update_sp(sp):\n    with data_store_lock:\n        key = _primary_key(sp)\n        existing_sp = data_store[\"SP\"].get(key)\n        if existing_sp:\n            existing_sp.update(sp)\n            data_store[\"SP\"][key] = existing_sp\n        else:\n            data_store[\"SP\"][key] = sp",
  "def get_sp_by(predicate: dict):\n    result = {}\n    with data_store_lock:\n        for sp in data_store[\"SP\"].values():\n            if all(sp[k] == predicate[k] for k in predicate):\n                result = sp\n                break\n    return result",
  "def generate_password():\n    s = \"abcdefghijklmnopqrstuvwxyz01234567890ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n    passlen = 16\n    p = \"\".join(random.sample(s, passlen))\n    return p",
  "def sign_all(content_folder, signing_pri_key):\n    signatures = dict()\n    for f in os.listdir(content_folder):\n        path = os.path.join(content_folder, f)\n        if os.path.isfile(path):\n            signature = signing_pri_key.sign(\n                data=open(path, \"rb\").read(),\n                padding=padding.PSS(\n                    mgf=padding.MGF1(hashes.SHA256()),\n                    salt_length=padding.PSS.MAX_LENGTH,\n                ),\n                algorithm=hashes.SHA256(),\n            )\n            signatures[f] = b64encode(signature).decode(\"utf-8\")\n    return signatures",
  "def load_yaml(file):\n    if isinstance(file, str):\n        return yaml.safe_load(open(file, \"r\"))\n    elif isinstance(file, bytes):\n        return yaml.safe_load(file)\n    else:\n        return None",
  "def sh_replace(src, mapping_dict):\n    result = src\n    for k, v in mapping_dict.items():\n        result = result.replace(\"{~~\" + k + \"~~}\", str(v))\n    return result",
  "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-p\", \"--project_file\", type=str, default=\"project.yml\", help=\"file to describe FL project\")\n    parser.add_argument(\"-w\", \"--workspace\", type=str, default=\"workspace\", help=\"directory used by provision\")\n    parser.add_argument(\"-c\", \"--custom_folder\", type=str, default=\".\", help=\"additional folder to load python codes\")\n    parser.add_argument(\n        \"-u\",\n        \"--ui_tool\",\n        action=\"store_true\",\n        help=\"Run provisioning UI tool to generate project.yml file\",\n    )\n\n    args = parser.parse_args()\n\n    file_path = pathlib.Path(__file__).parent.absolute()\n    current_path = os.getcwd()\n    custom_folder_path = os.path.join(current_path, args.custom_folder)\n    sys.path.append(custom_folder_path)\n    print(\"Path list (sys.path) for python codes loading: {}\".format(sys.path))\n\n    # main project file\n    project_file = args.project_file\n    current_project_yml = os.path.join(current_path, \"project.yml\")\n    if len(sys.argv) == 1 and not os.path.exists(current_project_yml):\n        answer = input(\n            f\"No project.yml found in current folder.  Is it OK to generate one at {current_project_yml} for you? (y/N) \"\n        )\n        if answer.strip().upper() == \"Y\":\n            shutil.copyfile(os.path.join(file_path, \"project.yml\"), current_project_yml)\n            print(f\"{current_project_yml} was created.  Please edit it to fit your FL configuration.\")\n        exit(0)\n\n    if args.ui_tool:\n        ui_helper_path = os.path.join(file_path, \"provision_helper.html\")\n        ui_helper_url = f\"file://{ui_helper_path}\"\n        webbrowser.open_new_tab(ui_helper_url)\n        print(\n            \"\\n******\\n\"\n            \"Now launching provisioning UI tool.\\n\"\n            \"After generating project.yml in the browser and saving it to your local folder,\\n\"\n            \"please re-run provision with -p option, pointing to the generated project.yml, to generate all packages.\\n******\\n\"\n        )\n        exit(0)\n\n    workspace = args.workspace\n    workspace_full_path = os.path.join(current_path, workspace)\n\n    project_full_path = os.path.join(current_path, project_file)\n    print(f\"Project yaml file: {project_full_path}.\")\n\n    project_dict = load_yaml(project_full_path)\n    api_version = project_dict.get(\"api_version\")\n    if api_version not in [3]:\n        raise ValueError(f\"API version expected 3 but found {api_version}\")\n\n    project_name = project_dict.get(\"name\")\n    project_description = project_dict.get(\"description\", \"\")\n    participants = list()\n    for p in project_dict.get(\"participants\"):\n        participants.append(Participant(**p))\n    project = Project(name=project_name, description=project_description, participants=participants)\n\n    n_servers = len(project.get_participants_by_type(\"server\", first_only=False))\n    if n_servers > 2:\n        print(\n            f\"Configuration error: Expect 2 or 1 server to be provisioned.  {project_full_path} contains {n_servers} servers.\"\n        )\n        return\n\n    builders = list()\n    for b in project_dict.get(\"builders\"):\n        path = b.get(\"path\")\n        args = b.get(\"args\")\n        builders.append(instantiate_class(path, args))\n\n    provisioner = Provisioner(workspace_full_path, builders)\n\n    provisioner.provision(project)",
  "def clone_client(num_clients: int):\n    current_path = os.getcwd()\n    poc_folder = os.path.join(current_path, \"poc\")\n    src_folder = os.path.join(poc_folder, \"client\")\n    for index in range(1, num_clients + 1):\n        dst_folder = os.path.join(poc_folder, f\"site-{index}\")\n        shutil.copytree(src_folder, dst_folder)\n        start_sh = open(os.path.join(dst_folder, \"startup\", \"start.sh\"), \"rt\")\n        content = start_sh.read()\n        start_sh.close()\n        content = content.replace(\"NNN\", f\"{index}\")\n        with open(os.path.join(dst_folder, \"startup\", \"start.sh\"), \"wt\") as f:\n            f.write(content)\n    shutil.rmtree(src_folder)",
  "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-n\", \"--num_clients\", type=int, default=1, help=\"number of client folders to create\")\n\n    args = parser.parse_args()\n\n    file_dir_path = pathlib.Path(__file__).parent.absolute()\n    poc_zip_path = file_dir_path.parent / \"poc.zip\"\n    poc_folder_path = file_dir_path.parent / \"poc\"\n    answer = input(\"This will delete poc folder in current directory and create a new one. Is it OK to proceed? (y/N) \")\n    if answer.strip().upper() == \"Y\":\n        dest_poc_folder = os.path.join(os.getcwd(), \"poc\")\n        shutil.rmtree(dest_poc_folder, ignore_errors=True)\n        try:\n            shutil.unpack_archive(poc_zip_path)\n        except shutil.ReadError:\n            print(f\"poc.zip not found at {poc_zip_path}, try to use template poc folder\")\n            try:\n                shutil.copytree(poc_folder_path, dest_poc_folder)\n            except BaseException:\n                print(f\"Unable to copy poc folder from {poc_folder_path}.  Exit\")\n                exit(1)\n        for root, dirs, files in os.walk(dest_poc_folder):\n            for file in files:\n                if file.endswith(\".sh\"):\n                    os.chmod(os.path.join(root, file), 0o755)\n        clone_client(args.num_clients)\n        print(\"Successfully creating poc folder.  Please read poc/Readme.rst for user guide.\")\n        print(\"Note POC does not have features of overseer and server switch over.\")\n        print(\"\\n\\nWARNING:\\n******* Files generated by this poc command are NOT intended for production environments.\")\n    else:\n        print(f\"Response '{answer}' received and it's not either y or Y.  Will not create new poc folder.\")",
  "class Participant(object):\n    def __init__(self, type: str, name: str, org: str, enable_byoc: bool = False, *args, **kwargs):\n        \"\"\"Class to represent a participant.\n\n        Each participant communicates to other participant.  Therefore, each participant has its\n        own name, type, organization it belongs to, rules and other information.\n\n        Args:\n            type (str): server, client, admin or other string that builders can handle\n            name (str): system-wide unique name\n            org (str): system-wide unique organization\n            enable_byoc (bool, optional): whether this participant allows byoc codes to be loaded. Defaults to False.\n\n        Raises:\n            ValueError: if name or org is not compliant with characters or format specification.\n        \"\"\"\n        err, reason = name_check(name, type)\n        if err:\n            raise ValueError(reason)\n        err, reason = name_check(org, \"org\")\n        if err:\n            raise ValueError(reason)\n        self.type = type\n        self.name = name\n        self.org = org\n        self.subject = name\n        self.enable_byoc = enable_byoc\n        self.props = kwargs",
  "class Project(object):\n    def __init__(self, name: str, description: str, participants: List[Participant]):\n        \"\"\"A container class to hold information about this FL project.\n\n        This class only holds information.  It does not drive the workflow.\n\n        Args:\n            name (str): the project name\n            description (str): brief description on this name\n            participants (List[Participant]): All the participants that will join this project\n\n        Raises:\n            ValueError: when duplicate name found in participants list\n        \"\"\"\n        self.name = name\n        all_names = list()\n        for p in participants:\n            if p.name in all_names:\n                raise ValueError(f\"Unable to add a duplicate name {p.name} into this project.\")\n            else:\n                all_names.append(p.name)\n        self.description = description\n        self.participants = participants\n\n    def get_participants_by_type(self, type, first_only=True):\n        found = list()\n        for p in self.participants:\n            if p.type == type:\n                if first_only:\n                    return p\n                else:\n                    found.append(p)\n        return found",
  "class Builder(ABC):\n    def initialize(self, ctx: dict):\n        pass\n\n    def build(self, project: Project, ctx: dict):\n        pass\n\n    def finalize(self, ctx: dict):\n        pass\n\n    def get_wip_dir(self, ctx: dict):\n        return ctx.get(\"wip_dir\")\n\n    def get_kit_dir(self, participate: Participant, ctx: dict):\n        return os.path.join(self.get_wip_dir(ctx), participate.name, \"startup\")\n\n    def get_state_dir(self, ctx: dict):\n        return ctx.get(\"state_dir\")\n\n    def get_resources_dir(self, ctx: dict):\n        return ctx.get(\"resources_dir\")",
  "class Provisioner(object):\n    def __init__(self, root_dir: str, builders: List[Builder]):\n        \"\"\"Workflow class that drive the provision process.\n\n        Provisioner's tasks:\n\n            - Maintain the provision workspace folder structure;\n            - Invoke Builders to generate the content of each startup kit\n\n        ROOT_WORKSPACE Folder Structure::\n\n            root_workspace_dir_name: this is the root of the workspace\n                project_dir_name: the root dir of the project, could be named after the project\n                    resources: stores resource files (templates, configs, etc.) of the Provisioner and Builders\n                    prod: stores the current set of startup kits (production)\n                        participate_dir: stores content files generated by builders\n                    wip: stores the set of startup kits to be created (WIP)\n                        participate_dir: stores content files generated by builders\n                    state: stores the persistent state of the Builders\n\n        Args:\n            root_dir (str): the directory path to hold all generated or intermediate folders\n            builders (List[Builder]): all builders that will be called to build the content\n        \"\"\"\n        self.root_dir = root_dir\n        self.builders = builders\n        self.ctx = None\n\n    def _make_dir(self, dirs):\n        for dir in dirs:\n            if not os.path.exists(dir):\n                os.makedirs(dir)\n\n    def _prepare_workspace(self, ctx):\n        workspace = ctx.get(\"workspace\")\n        wip_dir = os.path.join(workspace, \"wip\")\n        state_dir = os.path.join(workspace, \"state\")\n        resources_dir = os.path.join(workspace, \"resources\")\n        ctx.update(dict(wip_dir=wip_dir, state_dir=state_dir, resources_dir=resources_dir))\n        dirs = [workspace, resources_dir, wip_dir, state_dir]\n        self._make_dir(dirs)\n\n    def provision(self, project: Project):\n        # ctx = {\"workspace\": os.path.join(self.root_dir, project.name), \"project\": project}\n        workspace = os.path.join(self.root_dir, project.name)\n        ctx = {\"workspace\": workspace}  # project is more static information while ctx is dynamic\n        self._prepare_workspace(ctx)\n        try:\n            for b in self.builders:\n                b.initialize(ctx)\n\n            # call builders!\n            for b in self.builders:\n                b.build(project, ctx)\n\n            for b in self.builders[::-1]:\n                b.finalize(ctx)\n\n        except BaseException as ex:\n            prod_dir = ctx.get(\"current_prod_dir\")\n            if prod_dir:\n                shutil.rmtree(prod_dir)\n            print(\"Exception raised during provision.  Incomplete prod_n folder removed.\")\n            traceback.print_exc()\n        finally:\n            wip_dir = ctx.get(\"wip_dir\")\n            if wip_dir:\n                shutil.rmtree(wip_dir)",
  "def __init__(self, type: str, name: str, org: str, enable_byoc: bool = False, *args, **kwargs):\n        \"\"\"Class to represent a participant.\n\n        Each participant communicates to other participant.  Therefore, each participant has its\n        own name, type, organization it belongs to, rules and other information.\n\n        Args:\n            type (str): server, client, admin or other string that builders can handle\n            name (str): system-wide unique name\n            org (str): system-wide unique organization\n            enable_byoc (bool, optional): whether this participant allows byoc codes to be loaded. Defaults to False.\n\n        Raises:\n            ValueError: if name or org is not compliant with characters or format specification.\n        \"\"\"\n        err, reason = name_check(name, type)\n        if err:\n            raise ValueError(reason)\n        err, reason = name_check(org, \"org\")\n        if err:\n            raise ValueError(reason)\n        self.type = type\n        self.name = name\n        self.org = org\n        self.subject = name\n        self.enable_byoc = enable_byoc\n        self.props = kwargs",
  "def __init__(self, name: str, description: str, participants: List[Participant]):\n        \"\"\"A container class to hold information about this FL project.\n\n        This class only holds information.  It does not drive the workflow.\n\n        Args:\n            name (str): the project name\n            description (str): brief description on this name\n            participants (List[Participant]): All the participants that will join this project\n\n        Raises:\n            ValueError: when duplicate name found in participants list\n        \"\"\"\n        self.name = name\n        all_names = list()\n        for p in participants:\n            if p.name in all_names:\n                raise ValueError(f\"Unable to add a duplicate name {p.name} into this project.\")\n            else:\n                all_names.append(p.name)\n        self.description = description\n        self.participants = participants",
  "def get_participants_by_type(self, type, first_only=True):\n        found = list()\n        for p in self.participants:\n            if p.type == type:\n                if first_only:\n                    return p\n                else:\n                    found.append(p)\n        return found",
  "def initialize(self, ctx: dict):\n        pass",
  "def build(self, project: Project, ctx: dict):\n        pass",
  "def finalize(self, ctx: dict):\n        pass",
  "def get_wip_dir(self, ctx: dict):\n        return ctx.get(\"wip_dir\")",
  "def get_kit_dir(self, participate: Participant, ctx: dict):\n        return os.path.join(self.get_wip_dir(ctx), participate.name, \"startup\")",
  "def get_state_dir(self, ctx: dict):\n        return ctx.get(\"state_dir\")",
  "def get_resources_dir(self, ctx: dict):\n        return ctx.get(\"resources_dir\")",
  "def __init__(self, root_dir: str, builders: List[Builder]):\n        \"\"\"Workflow class that drive the provision process.\n\n        Provisioner's tasks:\n\n            - Maintain the provision workspace folder structure;\n            - Invoke Builders to generate the content of each startup kit\n\n        ROOT_WORKSPACE Folder Structure::\n\n            root_workspace_dir_name: this is the root of the workspace\n                project_dir_name: the root dir of the project, could be named after the project\n                    resources: stores resource files (templates, configs, etc.) of the Provisioner and Builders\n                    prod: stores the current set of startup kits (production)\n                        participate_dir: stores content files generated by builders\n                    wip: stores the set of startup kits to be created (WIP)\n                        participate_dir: stores content files generated by builders\n                    state: stores the persistent state of the Builders\n\n        Args:\n            root_dir (str): the directory path to hold all generated or intermediate folders\n            builders (List[Builder]): all builders that will be called to build the content\n        \"\"\"\n        self.root_dir = root_dir\n        self.builders = builders\n        self.ctx = None",
  "def _make_dir(self, dirs):\n        for dir in dirs:\n            if not os.path.exists(dir):\n                os.makedirs(dir)",
  "def _prepare_workspace(self, ctx):\n        workspace = ctx.get(\"workspace\")\n        wip_dir = os.path.join(workspace, \"wip\")\n        state_dir = os.path.join(workspace, \"state\")\n        resources_dir = os.path.join(workspace, \"resources\")\n        ctx.update(dict(wip_dir=wip_dir, state_dir=state_dir, resources_dir=resources_dir))\n        dirs = [workspace, resources_dir, wip_dir, state_dir]\n        self._make_dir(dirs)",
  "def provision(self, project: Project):\n        # ctx = {\"workspace\": os.path.join(self.root_dir, project.name), \"project\": project}\n        workspace = os.path.join(self.root_dir, project.name)\n        ctx = {\"workspace\": workspace}  # project is more static information while ctx is dynamic\n        self._prepare_workspace(ctx)\n        try:\n            for b in self.builders:\n                b.initialize(ctx)\n\n            # call builders!\n            for b in self.builders:\n                b.build(project, ctx)\n\n            for b in self.builders[::-1]:\n                b.finalize(ctx)\n\n        except BaseException as ex:\n            prod_dir = ctx.get(\"current_prod_dir\")\n            if prod_dir:\n                shutil.rmtree(prod_dir)\n            print(\"Exception raised during provision.  Incomplete prod_n folder removed.\")\n            traceback.print_exc()\n        finally:\n            wip_dir = ctx.get(\"wip_dir\")\n            if wip_dir:\n                shutil.rmtree(wip_dir)",
  "class HEBuilder(Builder):\n    def __init__(\n        self,\n        poly_modulus_degree=8192,\n        coeff_mod_bit_sizes=[60, 40, 40],\n        scale_bits=40,\n        scheme=\"CKKS\",\n    ):\n        \"\"\"Build Homomorphic related contents.\n\n        Generates Tenseal homomorphic encryption context for server and client and writes them to server and client\n        participant folders.\n\n        Args:\n            poly_modulus_degree: defaults to 8192.\n            coeff_mod_bit_sizes: defaults to [60, 40, 40].\n            scale_bits: defaults to 40.\n            scheme: defaults to \"CKKS\".\n        \"\"\"\n        self._context = None\n        self.scheme_type_mapping = {\n            \"CKKS\": ts.SCHEME_TYPE.CKKS,\n            \"BFV\": ts.SCHEME_TYPE.BFV,\n        }\n        self.poly_modulus_degree = poly_modulus_degree\n        self.coeff_mod_bit_sizes = coeff_mod_bit_sizes\n        self.scale_bits = scale_bits\n        _scheme = scheme\n        # Setup TenSEAL context\n        self.scheme_type = self.scheme_type_mapping[_scheme]\n        self.serialized = None\n\n    def initialize(self, ctx):\n        self._context = ts.context(\n            self.scheme_type,\n            poly_modulus_degree=self.poly_modulus_degree,\n            coeff_mod_bit_sizes=self.coeff_mod_bit_sizes,\n            encryption_type=ts.ENCRYPTION_TYPE.SYMMETRIC,\n        )\n        # dynamically call different generate keys method\n        # getattr(self._context, f'generate_{self.key_type}_keys')()\n        self._context.generate_relin_keys()\n        self._context.global_scale = 2**self.scale_bits\n\n    def build(self, project, ctx):\n        servers = project.get_participants_by_type(\"server\", first_only=False)\n        for server in servers:\n            dest_dir = self.get_kit_dir(server, ctx)\n            with open(os.path.join(dest_dir, \"server_context.tenseal\"), \"wb\") as f:\n                f.write(self.get_serialized_context())\n        for client in project.get_participants_by_type(\"client\", first_only=False):\n            dest_dir = self.get_kit_dir(client, ctx)\n            with open(os.path.join(dest_dir, \"client_context.tenseal\"), \"wb\") as f:\n                f.write(self.get_serialized_context(is_client=True))\n\n    def get_serialized_context(self, is_client=False):\n        _serialized_context = self._context.serialize(\n            save_public_key=is_client,\n            save_secret_key=is_client,\n            save_galois_keys=False,\n            save_relin_keys=True,\n        )\n        return _serialized_context",
  "def __init__(\n        self,\n        poly_modulus_degree=8192,\n        coeff_mod_bit_sizes=[60, 40, 40],\n        scale_bits=40,\n        scheme=\"CKKS\",\n    ):\n        \"\"\"Build Homomorphic related contents.\n\n        Generates Tenseal homomorphic encryption context for server and client and writes them to server and client\n        participant folders.\n\n        Args:\n            poly_modulus_degree: defaults to 8192.\n            coeff_mod_bit_sizes: defaults to [60, 40, 40].\n            scale_bits: defaults to 40.\n            scheme: defaults to \"CKKS\".\n        \"\"\"\n        self._context = None\n        self.scheme_type_mapping = {\n            \"CKKS\": ts.SCHEME_TYPE.CKKS,\n            \"BFV\": ts.SCHEME_TYPE.BFV,\n        }\n        self.poly_modulus_degree = poly_modulus_degree\n        self.coeff_mod_bit_sizes = coeff_mod_bit_sizes\n        self.scale_bits = scale_bits\n        _scheme = scheme\n        # Setup TenSEAL context\n        self.scheme_type = self.scheme_type_mapping[_scheme]\n        self.serialized = None",
  "def initialize(self, ctx):\n        self._context = ts.context(\n            self.scheme_type,\n            poly_modulus_degree=self.poly_modulus_degree,\n            coeff_mod_bit_sizes=self.coeff_mod_bit_sizes,\n            encryption_type=ts.ENCRYPTION_TYPE.SYMMETRIC,\n        )\n        # dynamically call different generate keys method\n        # getattr(self._context, f'generate_{self.key_type}_keys')()\n        self._context.generate_relin_keys()\n        self._context.global_scale = 2**self.scale_bits",
  "def build(self, project, ctx):\n        servers = project.get_participants_by_type(\"server\", first_only=False)\n        for server in servers:\n            dest_dir = self.get_kit_dir(server, ctx)\n            with open(os.path.join(dest_dir, \"server_context.tenseal\"), \"wb\") as f:\n                f.write(self.get_serialized_context())\n        for client in project.get_participants_by_type(\"client\", first_only=False):\n            dest_dir = self.get_kit_dir(client, ctx)\n            with open(os.path.join(dest_dir, \"client_context.tenseal\"), \"wb\") as f:\n                f.write(self.get_serialized_context(is_client=True))",
  "def get_serialized_context(self, is_client=False):\n        _serialized_context = self._context.serialize(\n            save_public_key=is_client,\n            save_secret_key=is_client,\n            save_galois_keys=False,\n            save_relin_keys=True,\n        )\n        return _serialized_context",
  "def serialize_pri_key(pri_key):\n    return pri_key.private_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PrivateFormat.TraditionalOpenSSL,\n        encryption_algorithm=serialization.NoEncryption(),\n    )",
  "def serialize_cert(cert):\n    return cert.public_bytes(serialization.Encoding.PEM)",
  "class CertBuilder(Builder):\n    def __init__(self):\n        \"\"\"Build certificate chain for every participant.\n\n        Handles building (creating and self-signing) the root CA certificates, creating server, client and\n        admin certificates, and having them signed by the root CA for secure communication. If the state folder has\n        information about previously generated certs, it loads them back and reuses them.\n        \"\"\"\n        self.root_cert = None\n        self.persistent_state = dict()\n\n    def initialize(self, ctx):\n        state_dir = self.get_state_dir(ctx)\n        cert_file = os.path.join(state_dir, \"cert.json\")\n        if os.path.exists(cert_file):\n            self.persistent_state = json.load(open(cert_file, \"rt\"))\n            self.serialized_cert = self.persistent_state[\"root_cert\"].encode(\"ascii\")\n            self.root_cert = x509.load_pem_x509_certificate(self.serialized_cert, default_backend())\n            self.pri_key = serialization.load_pem_private_key(\n                self.persistent_state[\"root_pri_key\"].encode(\"ascii\"), password=None, backend=default_backend()\n            )\n            self.pub_key = self.pri_key.public_key()\n            self.subject = self.root_cert.subject\n            self.issuer = self.subject.get_attributes_for_oid(NameOID.COMMON_NAME)[0].value\n\n    def _build_root(self, subject):\n        if not self.persistent_state:\n            pri_key, pub_key = self._generate_keys()\n            self.issuer = subject\n            self.root_cert = self._generate_cert(subject, self.issuer, pri_key, pub_key, ca=True)\n            self.pri_key = pri_key\n            self.pub_key = pub_key\n            self.serialized_cert = serialize_cert(self.root_cert)\n            self.persistent_state[\"root_cert\"] = self.serialized_cert.decode(\"ascii\")\n            self.persistent_state[\"root_pri_key\"] = serialize_pri_key(self.pri_key).decode(\"ascii\")\n\n    def _build_write_cert_pair(self, participant, base_name, ctx):\n        subject = participant.subject\n        if self.persistent_state and subject in self.persistent_state:\n            cert = x509.load_pem_x509_certificate(\n                self.persistent_state[subject][\"cert\"].encode(\"ascii\"), default_backend()\n            )\n            pri_key = serialization.load_pem_private_key(\n                self.persistent_state[subject][\"pri_key\"].encode(\"ascii\"), password=None, backend=default_backend()\n            )\n        else:\n            pri_key, cert = self.get_pri_key_cert(participant)\n            self.persistent_state[subject] = dict(\n                cert=serialize_cert(cert).decode(\"ascii\"), pri_key=serialize_pri_key(pri_key).decode(\"ascii\")\n            )\n        dest_dir = self.get_kit_dir(participant, ctx)\n        with open(os.path.join(dest_dir, f\"{base_name}.crt\"), \"wb\") as f:\n            f.write(serialize_cert(cert))\n        with open(os.path.join(dest_dir, f\"{base_name}.key\"), \"wb\") as f:\n            f.write(serialize_pri_key(pri_key))\n        pkcs12 = serialization.pkcs12.serialize_key_and_certificates(\n            subject.encode(\"ascii\"), pri_key, cert, None, serialization.BestAvailableEncryption(subject.encode(\"ascii\"))\n        )\n        with open(os.path.join(dest_dir, f\"{base_name}.pfx\"), \"wb\") as f:\n            f.write(pkcs12)\n        with open(os.path.join(dest_dir, \"rootCA.pem\"), \"wb\") as f:\n            f.write(self.serialized_cert)\n\n    def build(self, project, ctx):\n        self._build_root(project.name)\n        ctx[\"root_cert\"] = self.root_cert\n        ctx[\"root_pri_key\"] = self.pri_key\n        overseer = project.get_participants_by_type(\"overseer\")\n        self._build_write_cert_pair(overseer, \"overseer\", ctx)\n\n        servers = project.get_participants_by_type(\"server\", first_only=False)\n        for server in servers:\n            self._build_write_cert_pair(server, \"server\", ctx)\n\n        for client in project.get_participants_by_type(\"client\", first_only=False):\n            self._build_write_cert_pair(client, \"client\", ctx)\n\n        for admin in project.get_participants_by_type(\"admin\", first_only=False):\n            self._build_write_cert_pair(admin, \"client\", ctx)\n\n    def get_pri_key_cert(self, participant):\n        pri_key, pub_key = self._generate_keys()\n        subject = participant.subject\n        cert = self._generate_cert(subject, self.issuer, self.pri_key, pub_key)\n        return pri_key, cert\n\n    def _generate_keys(self):\n        pri_key = rsa.generate_private_key(public_exponent=65537, key_size=2048, backend=default_backend())\n        pub_key = pri_key.public_key()\n        return pri_key, pub_key\n\n    def _generate_cert(self, subject, issuer, signing_pri_key, subject_pub_key, valid_days=360, ca=False):\n        x509_subject = self._x509_name(subject)\n        x509_issuer = self._x509_name(issuer)\n        builder = (\n            x509.CertificateBuilder()\n            .subject_name(x509_subject)\n            .issuer_name(x509_issuer)\n            .public_key(subject_pub_key)\n            .serial_number(x509.random_serial_number())\n            .not_valid_before(datetime.datetime.utcnow())\n            .not_valid_after(\n                # Our certificate will be valid for 360 days\n                datetime.datetime.utcnow()\n                + datetime.timedelta(days=valid_days)\n                # Sign our certificate with our private key\n            )\n            .add_extension(x509.SubjectAlternativeName([x509.DNSName(subject)]), critical=False)\n        )\n        if ca:\n            builder = (\n                builder.add_extension(\n                    x509.SubjectKeyIdentifier.from_public_key(subject_pub_key),\n                    critical=False,\n                )\n                .add_extension(\n                    x509.AuthorityKeyIdentifier.from_issuer_public_key(subject_pub_key),\n                    critical=False,\n                )\n                .add_extension(x509.BasicConstraints(ca=True, path_length=None), critical=False)\n            )\n        return builder.sign(signing_pri_key, hashes.SHA256(), default_backend())\n\n    def _x509_name(self, cn_name, org_name=None):\n        name = [x509.NameAttribute(NameOID.COMMON_NAME, cn_name)]\n        if org_name is not None:\n            name.append(x509.NameAttribute(NameOID.ORGANIZATION_NAME, org_name))\n        return x509.Name(name)\n\n    def finalize(self, ctx):\n        state_dir = self.get_state_dir(ctx)\n        cert_file = os.path.join(state_dir, \"cert.json\")\n        json.dump(self.persistent_state, open(cert_file, \"wt\"))",
  "def __init__(self):\n        \"\"\"Build certificate chain for every participant.\n\n        Handles building (creating and self-signing) the root CA certificates, creating server, client and\n        admin certificates, and having them signed by the root CA for secure communication. If the state folder has\n        information about previously generated certs, it loads them back and reuses them.\n        \"\"\"\n        self.root_cert = None\n        self.persistent_state = dict()",
  "def initialize(self, ctx):\n        state_dir = self.get_state_dir(ctx)\n        cert_file = os.path.join(state_dir, \"cert.json\")\n        if os.path.exists(cert_file):\n            self.persistent_state = json.load(open(cert_file, \"rt\"))\n            self.serialized_cert = self.persistent_state[\"root_cert\"].encode(\"ascii\")\n            self.root_cert = x509.load_pem_x509_certificate(self.serialized_cert, default_backend())\n            self.pri_key = serialization.load_pem_private_key(\n                self.persistent_state[\"root_pri_key\"].encode(\"ascii\"), password=None, backend=default_backend()\n            )\n            self.pub_key = self.pri_key.public_key()\n            self.subject = self.root_cert.subject\n            self.issuer = self.subject.get_attributes_for_oid(NameOID.COMMON_NAME)[0].value",
  "def _build_root(self, subject):\n        if not self.persistent_state:\n            pri_key, pub_key = self._generate_keys()\n            self.issuer = subject\n            self.root_cert = self._generate_cert(subject, self.issuer, pri_key, pub_key, ca=True)\n            self.pri_key = pri_key\n            self.pub_key = pub_key\n            self.serialized_cert = serialize_cert(self.root_cert)\n            self.persistent_state[\"root_cert\"] = self.serialized_cert.decode(\"ascii\")\n            self.persistent_state[\"root_pri_key\"] = serialize_pri_key(self.pri_key).decode(\"ascii\")",
  "def _build_write_cert_pair(self, participant, base_name, ctx):\n        subject = participant.subject\n        if self.persistent_state and subject in self.persistent_state:\n            cert = x509.load_pem_x509_certificate(\n                self.persistent_state[subject][\"cert\"].encode(\"ascii\"), default_backend()\n            )\n            pri_key = serialization.load_pem_private_key(\n                self.persistent_state[subject][\"pri_key\"].encode(\"ascii\"), password=None, backend=default_backend()\n            )\n        else:\n            pri_key, cert = self.get_pri_key_cert(participant)\n            self.persistent_state[subject] = dict(\n                cert=serialize_cert(cert).decode(\"ascii\"), pri_key=serialize_pri_key(pri_key).decode(\"ascii\")\n            )\n        dest_dir = self.get_kit_dir(participant, ctx)\n        with open(os.path.join(dest_dir, f\"{base_name}.crt\"), \"wb\") as f:\n            f.write(serialize_cert(cert))\n        with open(os.path.join(dest_dir, f\"{base_name}.key\"), \"wb\") as f:\n            f.write(serialize_pri_key(pri_key))\n        pkcs12 = serialization.pkcs12.serialize_key_and_certificates(\n            subject.encode(\"ascii\"), pri_key, cert, None, serialization.BestAvailableEncryption(subject.encode(\"ascii\"))\n        )\n        with open(os.path.join(dest_dir, f\"{base_name}.pfx\"), \"wb\") as f:\n            f.write(pkcs12)\n        with open(os.path.join(dest_dir, \"rootCA.pem\"), \"wb\") as f:\n            f.write(self.serialized_cert)",
  "def build(self, project, ctx):\n        self._build_root(project.name)\n        ctx[\"root_cert\"] = self.root_cert\n        ctx[\"root_pri_key\"] = self.pri_key\n        overseer = project.get_participants_by_type(\"overseer\")\n        self._build_write_cert_pair(overseer, \"overseer\", ctx)\n\n        servers = project.get_participants_by_type(\"server\", first_only=False)\n        for server in servers:\n            self._build_write_cert_pair(server, \"server\", ctx)\n\n        for client in project.get_participants_by_type(\"client\", first_only=False):\n            self._build_write_cert_pair(client, \"client\", ctx)\n\n        for admin in project.get_participants_by_type(\"admin\", first_only=False):\n            self._build_write_cert_pair(admin, \"client\", ctx)",
  "def get_pri_key_cert(self, participant):\n        pri_key, pub_key = self._generate_keys()\n        subject = participant.subject\n        cert = self._generate_cert(subject, self.issuer, self.pri_key, pub_key)\n        return pri_key, cert",
  "def _generate_keys(self):\n        pri_key = rsa.generate_private_key(public_exponent=65537, key_size=2048, backend=default_backend())\n        pub_key = pri_key.public_key()\n        return pri_key, pub_key",
  "def _generate_cert(self, subject, issuer, signing_pri_key, subject_pub_key, valid_days=360, ca=False):\n        x509_subject = self._x509_name(subject)\n        x509_issuer = self._x509_name(issuer)\n        builder = (\n            x509.CertificateBuilder()\n            .subject_name(x509_subject)\n            .issuer_name(x509_issuer)\n            .public_key(subject_pub_key)\n            .serial_number(x509.random_serial_number())\n            .not_valid_before(datetime.datetime.utcnow())\n            .not_valid_after(\n                # Our certificate will be valid for 360 days\n                datetime.datetime.utcnow()\n                + datetime.timedelta(days=valid_days)\n                # Sign our certificate with our private key\n            )\n            .add_extension(x509.SubjectAlternativeName([x509.DNSName(subject)]), critical=False)\n        )\n        if ca:\n            builder = (\n                builder.add_extension(\n                    x509.SubjectKeyIdentifier.from_public_key(subject_pub_key),\n                    critical=False,\n                )\n                .add_extension(\n                    x509.AuthorityKeyIdentifier.from_issuer_public_key(subject_pub_key),\n                    critical=False,\n                )\n                .add_extension(x509.BasicConstraints(ca=True, path_length=None), critical=False)\n            )\n        return builder.sign(signing_pri_key, hashes.SHA256(), default_backend())",
  "def _x509_name(self, cn_name, org_name=None):\n        name = [x509.NameAttribute(NameOID.COMMON_NAME, cn_name)]\n        if org_name is not None:\n            name.append(x509.NameAttribute(NameOID.ORGANIZATION_NAME, org_name))\n        return x509.Name(name)",
  "def finalize(self, ctx):\n        state_dir = self.get_state_dir(ctx)\n        cert_file = os.path.join(state_dir, \"cert.json\")\n        json.dump(self.persistent_state, open(cert_file, \"wt\"))",
  "class WorkspaceBuilder(Builder):\n    def __init__(self, template_file):\n        \"\"\"Manages the folder structure for provisioned projects.\n\n        Sets the template_file containing scripts and configs to put into startup folders, creates directories for the\n        participants, and moves the provisioned project to the final location at the end\n        ($WORKSPACE/$PROJECT_NAME/prod_XX). WorkspaceBuilder manages and sets the number in prod_XX by incrementing from\n        the last time provision was run for this project in this workspace, starting with 00 to a max of 99.\n\n        Each time the provisioning tool runs, it requires a workspace folder in the local file system.  The workspace\n        will have the following folder structure:\n\n        .. code-block:: text\n\n          $WORKSPACE/    <--- this is assigned by -w option of provision command (default is workspace)\n            $PROJECT_NAME/  <--- this is the name value in the project.yml file\n              prod_00/   <--- a new prod_NN folder is created if provision does not have any errors.\n              prod_01/\n              ...\n              resources/ <--- this folder stores resources for other builders to load\n              state/     <--- this folder stores persistent information (such as certificates) so subsequent runs of the provision command can load the state back.\n              wip/  <--- this is only used during runtime, and will be removed when the provision command exits\n\n        Args:\n            template_file: name of template file containing scripts and configs to put into startup folders\n        \"\"\"\n        self.template_file = template_file\n\n    def _make_dir(self, dirs):\n        for dir in dirs:\n            if not os.path.exists(dir):\n                os.makedirs(dir)\n\n    def initialize(self, ctx):\n        workspace_dir = ctx[\"workspace\"]\n        prod_dirs = [_ for _ in os.listdir(workspace_dir) if _.startswith(\"prod_\")]\n        last = -1\n        for dir in prod_dirs:\n            stage = int(dir.split(\"_\")[-1])\n            if stage > last:\n                last = stage\n        ctx[\"last_prod_stage\"] = last\n        template_file_full_path = os.path.join(self.get_resources_dir(ctx), self.template_file)\n        file_path = pathlib.Path(__file__).parent.absolute()\n        shutil.copyfile(os.path.join(file_path, self.template_file), template_file_full_path)\n        ctx[\"template_file\"] = self.template_file\n\n    def build(self, project: Project, ctx: dict):\n        dirs = [self.get_kit_dir(p, ctx) for p in project.participants]\n        self._make_dir(dirs)\n\n    def finalize(self, ctx: dict):\n        if ctx[\"last_prod_stage\"] >= 99:\n            print(f\"Please clean up {ctx['workspace']} by removing prod_N folders\")\n            print(\"After clean-up, rerun the provision command.\")\n        else:\n            current_prod_stage = str(ctx[\"last_prod_stage\"] + 1).zfill(2)\n            current_prod_dir = os.path.join(ctx[\"workspace\"], f\"prod_{current_prod_stage}\")\n            shutil.move(self.get_wip_dir(ctx), current_prod_dir)\n            ctx.pop(\"wip_dir\", None)\n            print(f\"Generated results can be found under {current_prod_dir}.  Builder's wip folder removed.\")\n            ctx[\"current_prod_dir\"] = current_prod_dir",
  "class DistributionBuilder(Builder):\n    def __init__(self, zip_password=False):\n        \"\"\"Build the zip files for each folder.\n\n        Creates the zip files containing the archives for each startup kit. It will add password protection if the\n        argument (zip_password) is true.\n\n        Args:\n            zip_password: if true, will create zipped packages with passwords\n        \"\"\"\n        self.zip_password = zip_password\n\n    def build(self, project: Project, ctx: dict):\n        \"\"\"Create a zip for each individual folder.\n        Note that if zip_password is True, the zip command will be used to encrypt zip files.  Users have to to\n        install this zip utility before provisioning.  In Ubuntu system, use this command to install zip utility:\n        sudo apt-get install zip\n\n        Args:\n            project (Project): project instance\n            ctx (dict): the provision context\n        \"\"\"\n        wip_dir = self.get_wip_dir(ctx)\n        dirs = [name for name in os.listdir(wip_dir) if os.path.isdir(os.path.join(wip_dir, name))]\n        for dir in dirs:\n            dest_zip_file = os.path.join(wip_dir, f\"{dir}\")\n            if self.zip_password:\n                pw = generate_password()\n                run_args = [\"zip\", \"-rq\", \"-P\", pw, dest_zip_file + \".zip\", \".\", \"-i\", \"startup/*\"]\n                os.chdir(dest_zip_file)\n                try:\n                    subprocess.run(run_args)\n                    print(f\"Password {pw} on {dir}.zip\")\n                except FileNotFoundError as e:\n                    raise RuntimeError(\"Unable to zip folders with password.  Maybe the zip utility is not installed.\")\n                finally:\n                    os.chdir(os.path.join(dest_zip_file, \"..\"))\n            else:\n                shutil.make_archive(dest_zip_file, \"zip\", root_dir=os.path.join(wip_dir, dir), base_dir=\"startup\")",
  "def __init__(self, template_file):\n        \"\"\"Manages the folder structure for provisioned projects.\n\n        Sets the template_file containing scripts and configs to put into startup folders, creates directories for the\n        participants, and moves the provisioned project to the final location at the end\n        ($WORKSPACE/$PROJECT_NAME/prod_XX). WorkspaceBuilder manages and sets the number in prod_XX by incrementing from\n        the last time provision was run for this project in this workspace, starting with 00 to a max of 99.\n\n        Each time the provisioning tool runs, it requires a workspace folder in the local file system.  The workspace\n        will have the following folder structure:\n\n        .. code-block:: text\n\n          $WORKSPACE/    <--- this is assigned by -w option of provision command (default is workspace)\n            $PROJECT_NAME/  <--- this is the name value in the project.yml file\n              prod_00/   <--- a new prod_NN folder is created if provision does not have any errors.\n              prod_01/\n              ...\n              resources/ <--- this folder stores resources for other builders to load\n              state/     <--- this folder stores persistent information (such as certificates) so subsequent runs of the provision command can load the state back.\n              wip/  <--- this is only used during runtime, and will be removed when the provision command exits\n\n        Args:\n            template_file: name of template file containing scripts and configs to put into startup folders\n        \"\"\"\n        self.template_file = template_file",
  "def _make_dir(self, dirs):\n        for dir in dirs:\n            if not os.path.exists(dir):\n                os.makedirs(dir)",
  "def initialize(self, ctx):\n        workspace_dir = ctx[\"workspace\"]\n        prod_dirs = [_ for _ in os.listdir(workspace_dir) if _.startswith(\"prod_\")]\n        last = -1\n        for dir in prod_dirs:\n            stage = int(dir.split(\"_\")[-1])\n            if stage > last:\n                last = stage\n        ctx[\"last_prod_stage\"] = last\n        template_file_full_path = os.path.join(self.get_resources_dir(ctx), self.template_file)\n        file_path = pathlib.Path(__file__).parent.absolute()\n        shutil.copyfile(os.path.join(file_path, self.template_file), template_file_full_path)\n        ctx[\"template_file\"] = self.template_file",
  "def build(self, project: Project, ctx: dict):\n        dirs = [self.get_kit_dir(p, ctx) for p in project.participants]\n        self._make_dir(dirs)",
  "def finalize(self, ctx: dict):\n        if ctx[\"last_prod_stage\"] >= 99:\n            print(f\"Please clean up {ctx['workspace']} by removing prod_N folders\")\n            print(\"After clean-up, rerun the provision command.\")\n        else:\n            current_prod_stage = str(ctx[\"last_prod_stage\"] + 1).zfill(2)\n            current_prod_dir = os.path.join(ctx[\"workspace\"], f\"prod_{current_prod_stage}\")\n            shutil.move(self.get_wip_dir(ctx), current_prod_dir)\n            ctx.pop(\"wip_dir\", None)\n            print(f\"Generated results can be found under {current_prod_dir}.  Builder's wip folder removed.\")\n            ctx[\"current_prod_dir\"] = current_prod_dir",
  "def __init__(self, zip_password=False):\n        \"\"\"Build the zip files for each folder.\n\n        Creates the zip files containing the archives for each startup kit. It will add password protection if the\n        argument (zip_password) is true.\n\n        Args:\n            zip_password: if true, will create zipped packages with passwords\n        \"\"\"\n        self.zip_password = zip_password",
  "def build(self, project: Project, ctx: dict):\n        \"\"\"Create a zip for each individual folder.\n        Note that if zip_password is True, the zip command will be used to encrypt zip files.  Users have to to\n        install this zip utility before provisioning.  In Ubuntu system, use this command to install zip utility:\n        sudo apt-get install zip\n\n        Args:\n            project (Project): project instance\n            ctx (dict): the provision context\n        \"\"\"\n        wip_dir = self.get_wip_dir(ctx)\n        dirs = [name for name in os.listdir(wip_dir) if os.path.isdir(os.path.join(wip_dir, name))]\n        for dir in dirs:\n            dest_zip_file = os.path.join(wip_dir, f\"{dir}\")\n            if self.zip_password:\n                pw = generate_password()\n                run_args = [\"zip\", \"-rq\", \"-P\", pw, dest_zip_file + \".zip\", \".\", \"-i\", \"startup/*\"]\n                os.chdir(dest_zip_file)\n                try:\n                    subprocess.run(run_args)\n                    print(f\"Password {pw} on {dir}.zip\")\n                except FileNotFoundError as e:\n                    raise RuntimeError(\"Unable to zip folders with password.  Maybe the zip utility is not installed.\")\n                finally:\n                    os.chdir(os.path.join(dest_zip_file, \"..\"))\n            else:\n                shutil.make_archive(dest_zip_file, \"zip\", root_dir=os.path.join(wip_dir, dir), base_dir=\"startup\")",
  "class TemplateBuilder(Builder):\n    \"\"\"Load template file.\n\n    Loads the content of the template_file and the authz_def (section of template file with fixed authorization\n    definitions) into two key-value pairs in the build context.\n    \"\"\"\n\n    def initialize(self, ctx):\n        resource_dir = self.get_resources_dir(ctx)\n        template_file = ctx.get(\"template_file\")\n        template = load_yaml(os.path.join(resource_dir, template_file))\n        authz_def = json.loads(template.get(\"authz_def\"))\n        ctx[\"template\"] = template\n        ctx[\"authz_def\"] = authz_def",
  "def initialize(self, ctx):\n        resource_dir = self.get_resources_dir(ctx)\n        template_file = ctx.get(\"template_file\")\n        template = load_yaml(os.path.join(resource_dir, template_file))\n        authz_def = json.loads(template.get(\"authz_def\"))\n        ctx[\"template\"] = template\n        ctx[\"authz_def\"] = authz_def",
  "class AuthPolicyBuilder(Builder):\n    def __init__(self, orgs, roles, groups, disabled):\n        \"\"\"Build authorization.json.\n\n        Creates and writes authorization.json to the server's startup directory with the authorization policy\n        defining the groups each org is in and the admin client roles which controls the allowed rights. The\n        participant information from project.yml is included in authorization.json with what orgs, groups, and roles\n        are associated with each participant. This builder also checks for errors if the arguments are specified\n        incorrectly.\n\n        Args:\n            orgs: authorization configuration for orgs (it may be helpful to build this section with the UI)\n            roles: authorization configuration for roles (it may be helpful to build this section with the UI)\n            groups: authorization configuration for groups (it may be helpful to build this section with the UI)\n            disabled: if true, all users are super with all privileges\n        \"\"\"\n        self.orgs = orgs\n        self.roles = roles\n        self.groups = groups\n        self.disabled = disabled\n\n    def build(self, project: Project, ctx: dict):\n        authz = {\"version\": \"1.0\"}\n        authz[\"roles\"] = self.roles\n        authz[\"groups\"] = self.groups\n        users = dict()\n        for admin in project.get_participants_by_type(\"admin\", first_only=False):\n            if admin.org not in self.orgs:\n                raise ValueError(f\"Admin {admin.name}'s org {admin.org} not defined in AuthPolicy\")\n            if self.disabled:\n                users[admin.name] = {\"org\": admin.org, \"roles\": [\"super\"]}\n            else:\n                for role in admin.props.get(\"roles\", {}):\n                    if role not in self.roles:\n                        raise ValueError(f\"Admin {admin.name}'s role {role} not defined in AuthPolicy\")\n                users[admin.name] = {\"org\": admin.org, \"roles\": admin.props.get(\"roles\")}\n        authz[\"users\"] = users\n        authz[\"orgs\"] = self.orgs\n        servers = project.get_participants_by_type(\"server\", first_only=False)\n        for server in servers:\n            if server.org not in self.orgs:\n                raise ValueError(f\"Server {server.name}'s org {server.org} not defined in AuthPolicy\")\n            sites = {\"server\": server.org}\n            for client in project.get_participants_by_type(\"client\", first_only=False):\n                if client.org not in self.orgs:\n                    raise ValueError(f\"client {client.name}'s org {client.org} not defined in AuthPolicy\")\n                sites[client.name] = client.org\n            authz[\"sites\"] = sites\n            authz.update(ctx.get(\"authz_def\"))\n            dest_dir = self.get_kit_dir(server, ctx)\n            with open(os.path.join(dest_dir, \"authorization.json\"), \"wt\") as f:\n                f.write(json.dumps(authz))",
  "def __init__(self, orgs, roles, groups, disabled):\n        \"\"\"Build authorization.json.\n\n        Creates and writes authorization.json to the server's startup directory with the authorization policy\n        defining the groups each org is in and the admin client roles which controls the allowed rights. The\n        participant information from project.yml is included in authorization.json with what orgs, groups, and roles\n        are associated with each participant. This builder also checks for errors if the arguments are specified\n        incorrectly.\n\n        Args:\n            orgs: authorization configuration for orgs (it may be helpful to build this section with the UI)\n            roles: authorization configuration for roles (it may be helpful to build this section with the UI)\n            groups: authorization configuration for groups (it may be helpful to build this section with the UI)\n            disabled: if true, all users are super with all privileges\n        \"\"\"\n        self.orgs = orgs\n        self.roles = roles\n        self.groups = groups\n        self.disabled = disabled",
  "def build(self, project: Project, ctx: dict):\n        authz = {\"version\": \"1.0\"}\n        authz[\"roles\"] = self.roles\n        authz[\"groups\"] = self.groups\n        users = dict()\n        for admin in project.get_participants_by_type(\"admin\", first_only=False):\n            if admin.org not in self.orgs:\n                raise ValueError(f\"Admin {admin.name}'s org {admin.org} not defined in AuthPolicy\")\n            if self.disabled:\n                users[admin.name] = {\"org\": admin.org, \"roles\": [\"super\"]}\n            else:\n                for role in admin.props.get(\"roles\", {}):\n                    if role not in self.roles:\n                        raise ValueError(f\"Admin {admin.name}'s role {role} not defined in AuthPolicy\")\n                users[admin.name] = {\"org\": admin.org, \"roles\": admin.props.get(\"roles\")}\n        authz[\"users\"] = users\n        authz[\"orgs\"] = self.orgs\n        servers = project.get_participants_by_type(\"server\", first_only=False)\n        for server in servers:\n            if server.org not in self.orgs:\n                raise ValueError(f\"Server {server.name}'s org {server.org} not defined in AuthPolicy\")\n            sites = {\"server\": server.org}\n            for client in project.get_participants_by_type(\"client\", first_only=False):\n                if client.org not in self.orgs:\n                    raise ValueError(f\"client {client.name}'s org {client.org} not defined in AuthPolicy\")\n                sites[client.name] = client.org\n            authz[\"sites\"] = sites\n            authz.update(ctx.get(\"authz_def\"))\n            dest_dir = self.get_kit_dir(server, ctx)\n            with open(os.path.join(dest_dir, \"authorization.json\"), \"wt\") as f:\n                f.write(json.dumps(authz))",
  "class SignatureBuilder(Builder):\n    \"\"\"Sign files with rootCA's private key.\n\n    Creates signatures for all the files signed with the root CA for the startup kits so that they\n    can be cryptographically verified to ensure any tampering is detected. This builder writes the signature.pkl file.\n    \"\"\"\n\n    def _do_sign(self, root_pri_key, dest_dir):\n        signatures = sign_all(dest_dir, root_pri_key)\n        json.dump(signatures, open(os.path.join(dest_dir, \"signature.json\"), \"wt\"))\n\n    def build(self, project: Project, ctx: dict):\n        root_pri_key = ctx.get(\"root_pri_key\")\n\n        overseer = project.get_participants_by_type(\"overseer\", first_only=True)\n        dest_dir = self.get_kit_dir(overseer, ctx)\n        self._do_sign(root_pri_key, dest_dir)\n\n        servers = project.get_participants_by_type(\"server\", first_only=False)\n        for server in servers:\n            dest_dir = self.get_kit_dir(server, ctx)\n            self._do_sign(root_pri_key, dest_dir)\n\n        for p in project.get_participants_by_type(\"client\", first_only=False):\n            dest_dir = self.get_kit_dir(p, ctx)\n            self._do_sign(root_pri_key, dest_dir)",
  "def _do_sign(self, root_pri_key, dest_dir):\n        signatures = sign_all(dest_dir, root_pri_key)\n        json.dump(signatures, open(os.path.join(dest_dir, \"signature.json\"), \"wt\"))",
  "def build(self, project: Project, ctx: dict):\n        root_pri_key = ctx.get(\"root_pri_key\")\n\n        overseer = project.get_participants_by_type(\"overseer\", first_only=True)\n        dest_dir = self.get_kit_dir(overseer, ctx)\n        self._do_sign(root_pri_key, dest_dir)\n\n        servers = project.get_participants_by_type(\"server\", first_only=False)\n        for server in servers:\n            dest_dir = self.get_kit_dir(server, ctx)\n            self._do_sign(root_pri_key, dest_dir)\n\n        for p in project.get_participants_by_type(\"client\", first_only=False):\n            dest_dir = self.get_kit_dir(p, ctx)\n            self._do_sign(root_pri_key, dest_dir)",
  "class StaticFileBuilder(Builder):\n    def __init__(\n        self,\n        enable_byoc=False,\n        config_folder=\"\",\n        app_validator=\"\",\n        download_job_url=\"\",\n        docker_image=\"\",\n        snapshot_persistor=\"\",\n        overseer_agent=\"\",\n        components=\"\",\n    ):\n        \"\"\"Build all static files from template.\n\n        Uses the information from project.yml through project to go through the participants and write the contents of\n        each file with the template, and replacing with the appropriate values from project.yml.\n\n        Usually, two main categories of files are created in all FL participants, static and dynamic. Static files\n        have similar contents among different participants, with small differences.  For example, the differences in\n        sub_start.sh are client name and python module.  Those are basically static files.  This builder uses template\n        file and string replacement to generate those static files for each participant.\n\n        Args:\n            enable_byoc: for each participant, true to enable loading of code in the custom folder of applications\n            config_folder: usually \"config\"\n            app_validator: optional path to an app validator to verify that uploaded app has the expected structure\n            docker_image: when docker_image is set to a docker image name, docker.sh will be generated on server/client/admin\n        \"\"\"\n        self.enable_byoc = enable_byoc\n        self.config_folder = config_folder\n        self.docker_image = docker_image\n        self.download_job_url = download_job_url\n        self.app_validator = app_validator\n        self.overseer_agent = overseer_agent\n        self.snapshot_persistor = snapshot_persistor\n        self.components = components\n\n    def _write(self, file_full_path, content, mode, exe=False):\n        mode = mode + \"w\"\n        with open(file_full_path, mode) as f:\n            f.write(content)\n        if exe:\n            os.chmod(file_full_path, 0o755)\n\n    def _build_overseer(self, overseer, ctx):\n        dest_dir = self.get_kit_dir(overseer, ctx)\n        self._write(\n            os.path.join(dest_dir, \"start.sh\"),\n            self.template[\"start_svr_sh\"],\n            \"t\",\n            exe=True,\n        )\n        protocol = overseer.props.get(\"protocol\", \"http\")\n        api_root = overseer.props.get(\"api_root\", \"/api/v1/\")\n        default_port = \"443\" if protocol == \"https\" else \"80\"\n        port = overseer.props.get(\"port\", default_port)\n        replacement_dict = {\"port\": port, \"hostname\": overseer.name}\n        admins = self.project.get_participants_by_type(\"admin\", first_only=False)\n        privilege_dict = dict()\n        for admin in admins:\n            for role in admin.props.get(\"roles\", {}):\n                if role in privilege_dict:\n                    privilege_dict[role].append(admin.subject)\n                else:\n                    privilege_dict[role] = [admin.subject]\n        self._write(\n            os.path.join(dest_dir, \"privilege.yml\"),\n            yaml.dump(privilege_dict, Dumper=yaml.Dumper),\n            \"t\",\n            exe=False,\n        )\n\n        if self.docker_image:\n            self._write(\n                os.path.join(dest_dir, \"docker.sh\"),\n                sh_replace(self.template[\"docker_svr_sh\"], replacement_dict),\n                \"t\",\n                exe=True,\n            )\n        self._write(\n            os.path.join(dest_dir, \"gunicorn.conf.py\"),\n            sh_replace(self.template[\"gunicorn_conf_py\"], replacement_dict),\n            \"t\",\n            exe=False,\n        )\n        self._write(\n            os.path.join(dest_dir, \"start.sh\"),\n            self.template[\"start_ovsr_sh\"],\n            \"t\",\n            exe=True,\n        )\n        if port:\n            ctx[\"overseer_end_point\"] = f\"{protocol}://{overseer.name}:{port}{api_root}\"\n        else:\n            ctx[\"overseer_end_point\"] = f\"{protocol}://{overseer.name}{api_root}\"\n\n    def _build_server(self, server, ctx):\n        config = json.loads(self.template[\"fed_server\"])\n        dest_dir = self.get_kit_dir(server, ctx)\n        server_0 = config[\"servers\"][0]\n        server_0[\"name\"] = self.project_name\n        admin_port = server.props.get(\"admin_port\", 8003)\n        ctx[\"admin_port\"] = admin_port\n        fed_learn_port = server.props.get(\"fed_learn_port\", 8002)\n        ctx[\"fed_learn_port\"] = fed_learn_port\n        ctx[\"server_name\"] = server.name\n        server_0[\"service\"][\"target\"] = f\"{server.name}:{fed_learn_port}\"\n        server_0[\"admin_host\"] = server.name\n        server_0[\"admin_port\"] = admin_port\n        if self.download_job_url:\n            server_0[\"download_job_url\"] = self.download_job_url\n        config[\"enable_byoc\"] = server.enable_byoc\n        if self.app_validator:\n            config[\"app_validator\"] = {\"path\": self.app_validator}\n        if self.overseer_agent:\n            overseer_agent = copy.deepcopy(self.overseer_agent)\n            if overseer_agent.get(\"overseer_exists\", True):\n                overseer_agent[\"args\"] = {\n                    \"role\": \"server\",\n                    \"overseer_end_point\": ctx.get(\"overseer_end_point\", \"\"),\n                    \"project\": self.project_name,\n                    \"name\": server.name,\n                    \"fl_port\": str(fed_learn_port),\n                    \"admin_port\": str(admin_port),\n                }\n            overseer_agent.pop(\"overseer_exists\", None)\n            config[\"overseer_agent\"] = overseer_agent\n        if self.snapshot_persistor:\n            config[\"snapshot_persistor\"] = self.snapshot_persistor\n        components = server.props.get(\"components\", [])\n        config[\"components\"] = list()\n        for comp in components:\n            temp_dict = {\"id\": comp}\n            temp_dict.update(components[comp])\n            config[\"components\"].append(temp_dict)\n        provisioned_client_list = list()\n        for client in self.project.get_participants_by_type(\"client\", first_only=False):\n            provisioned_client_list.append(client.name)\n        config[\"provisioned_client_list\"] = provisioned_client_list\n        self._write(os.path.join(dest_dir, \"fed_server.json\"), json.dumps(config, indent=2), \"t\")\n        replacement_dict = {\n            \"admin_port\": admin_port,\n            \"fed_learn_port\": fed_learn_port,\n            \"config_folder\": self.config_folder,\n            \"docker_image\": self.docker_image,\n        }\n        if self.docker_image:\n            self._write(\n                os.path.join(dest_dir, \"docker.sh\"),\n                sh_replace(self.template[\"docker_svr_sh\"], replacement_dict),\n                \"t\",\n                exe=True,\n            )\n        self._write(\n            os.path.join(dest_dir, \"start.sh\"),\n            self.template[\"start_svr_sh\"],\n            \"t\",\n            exe=True,\n        )\n        self._write(\n            os.path.join(dest_dir, \"sub_start.sh\"),\n            sh_replace(self.template[\"sub_start_svr_sh\"], replacement_dict),\n            \"t\",\n            exe=True,\n        )\n        self._write(\n            os.path.join(dest_dir, \"log.config\"),\n            self.template[\"log_config\"],\n            \"t\",\n        )\n        self._write(\n            os.path.join(dest_dir, \"readme.txt\"),\n            self.template[\"readme_fs\"],\n            \"t\",\n        )\n        self._write(\n            os.path.join(dest_dir, \"stop_fl.sh\"),\n            self.template[\"stop_fl_sh\"],\n            \"t\",\n            exe=True,\n        )\n\n    def _build_client(self, client, ctx):\n        config = json.loads(self.template[\"fed_client\"])\n        dest_dir = self.get_kit_dir(client, ctx)\n        fed_learn_port = ctx.get(\"fed_learn_port\")\n        server_name = ctx.get(\"server_name\")\n        # config[\"servers\"][0][\"service\"][\"target\"] = f\"{server_name}:{fed_learn_port}\"\n        config[\"servers\"][0][\"name\"] = self.project_name\n        config[\"enable_byoc\"] = client.enable_byoc\n        replacement_dict = {\n            \"client_name\": f\"{client.subject}\",\n            \"config_folder\": self.config_folder,\n            \"docker_image\": self.docker_image,\n        }\n        if self.overseer_agent:\n            overseer_agent = copy.deepcopy(self.overseer_agent)\n            if overseer_agent.get(\"overseer_exists\", True):\n                overseer_agent[\"args\"] = {\n                    \"role\": \"client\",\n                    \"overseer_end_point\": ctx.get(\"overseer_end_point\", \"\"),\n                    \"project\": self.project_name,\n                    \"name\": client.subject,\n                }\n            overseer_agent.pop(\"overseer_exists\", None)\n            config[\"overseer_agent\"] = overseer_agent\n        components = client.props.get(\"components\", [])\n        config[\"components\"] = list()\n        for comp in components:\n            temp_dict = {\"id\": comp}\n            temp_dict.update(components[comp])\n            config[\"components\"].append(temp_dict)\n\n        self._write(os.path.join(dest_dir, \"fed_client.json\"), json.dumps(config, indent=2), \"t\")\n        if self.docker_image:\n            self._write(\n                os.path.join(dest_dir, \"docker.sh\"),\n                sh_replace(self.template[\"docker_cln_sh\"], replacement_dict),\n                \"t\",\n                exe=True,\n            )\n        self._write(\n            os.path.join(dest_dir, \"start.sh\"),\n            self.template[\"start_cln_sh\"],\n            \"t\",\n            exe=True,\n        )\n        self._write(\n            os.path.join(dest_dir, \"sub_start.sh\"),\n            sh_replace(self.template[\"sub_start_cln_sh\"], replacement_dict),\n            \"t\",\n            exe=True,\n        )\n        self._write(\n            os.path.join(dest_dir, \"log.config\"),\n            self.template[\"log_config\"],\n            \"t\",\n        )\n        self._write(\n            os.path.join(dest_dir, \"readme.txt\"),\n            self.template[\"readme_fc\"],\n            \"t\",\n        )\n        self._write(\n            os.path.join(dest_dir, \"stop_fl.sh\"),\n            self.template[\"stop_fl_sh\"],\n            \"t\",\n            exe=True,\n        )\n\n    def _build_admin(self, admin, ctx):\n        config = json.loads(self.template[\"fed_admin\"])\n        dest_dir = self.get_kit_dir(admin, ctx)\n        admin_port = ctx.get(\"admin_port\")\n        server_name = ctx.get(\"server_name\")\n\n        replacement_dict = {\n            \"cn\": f\"{server_name}\",\n            \"admin_port\": f\"{admin_port}\",\n            \"docker_image\": self.docker_image,\n        }\n        agent_config = dict()\n        if self.overseer_agent:\n            overseer_agent = copy.deepcopy(self.overseer_agent)\n            if overseer_agent.get(\"overseer_exists\", True):\n                overseer_agent[\"args\"] = {\n                    \"role\": \"admin\",\n                    \"overseer_end_point\": ctx.get(\"overseer_end_point\", \"\"),\n                    \"project\": self.project_name,\n                    \"name\": admin.subject,\n                }\n            overseer_agent.pop(\"overseer_exists\", None)\n            agent_config[\"overseer_agent\"] = overseer_agent\n        config[\"admin\"].update(agent_config)\n        self._write(os.path.join(dest_dir, \"fed_admin.json\"), json.dumps(config, indent=2), \"t\")\n        if self.docker_image:\n            self._write(\n                os.path.join(dest_dir, \"docker.sh\"),\n                sh_replace(self.template[\"docker_adm_sh\"], replacement_dict),\n                \"t\",\n                exe=True,\n            )\n        self._write(\n            os.path.join(dest_dir, \"fl_admin.sh\"),\n            sh_replace(self.template[\"fl_admin_sh\"], replacement_dict),\n            \"t\",\n            exe=True,\n        )\n        self._write(\n            os.path.join(dest_dir, \"readme.txt\"),\n            self.template[\"readme_am\"],\n            \"t\",\n        )\n\n    def build(self, project, ctx):\n        self.template = ctx.get(\"template\")\n        self.project_name = project.name\n        self.project = project\n        overseer = project.get_participants_by_type(\"overseer\")\n        self._build_overseer(overseer, ctx)\n        servers = project.get_participants_by_type(\"server\", first_only=False)\n        for server in servers:\n            self._build_server(server, ctx)\n\n        for client in project.get_participants_by_type(\"client\", first_only=False):\n            self._build_client(client, ctx)\n\n        for admin in project.get_participants_by_type(\"admin\", first_only=False):\n            self._build_admin(admin, ctx)",
  "def __init__(\n        self,\n        enable_byoc=False,\n        config_folder=\"\",\n        app_validator=\"\",\n        download_job_url=\"\",\n        docker_image=\"\",\n        snapshot_persistor=\"\",\n        overseer_agent=\"\",\n        components=\"\",\n    ):\n        \"\"\"Build all static files from template.\n\n        Uses the information from project.yml through project to go through the participants and write the contents of\n        each file with the template, and replacing with the appropriate values from project.yml.\n\n        Usually, two main categories of files are created in all FL participants, static and dynamic. Static files\n        have similar contents among different participants, with small differences.  For example, the differences in\n        sub_start.sh are client name and python module.  Those are basically static files.  This builder uses template\n        file and string replacement to generate those static files for each participant.\n\n        Args:\n            enable_byoc: for each participant, true to enable loading of code in the custom folder of applications\n            config_folder: usually \"config\"\n            app_validator: optional path to an app validator to verify that uploaded app has the expected structure\n            docker_image: when docker_image is set to a docker image name, docker.sh will be generated on server/client/admin\n        \"\"\"\n        self.enable_byoc = enable_byoc\n        self.config_folder = config_folder\n        self.docker_image = docker_image\n        self.download_job_url = download_job_url\n        self.app_validator = app_validator\n        self.overseer_agent = overseer_agent\n        self.snapshot_persistor = snapshot_persistor\n        self.components = components",
  "def _write(self, file_full_path, content, mode, exe=False):\n        mode = mode + \"w\"\n        with open(file_full_path, mode) as f:\n            f.write(content)\n        if exe:\n            os.chmod(file_full_path, 0o755)",
  "def _build_overseer(self, overseer, ctx):\n        dest_dir = self.get_kit_dir(overseer, ctx)\n        self._write(\n            os.path.join(dest_dir, \"start.sh\"),\n            self.template[\"start_svr_sh\"],\n            \"t\",\n            exe=True,\n        )\n        protocol = overseer.props.get(\"protocol\", \"http\")\n        api_root = overseer.props.get(\"api_root\", \"/api/v1/\")\n        default_port = \"443\" if protocol == \"https\" else \"80\"\n        port = overseer.props.get(\"port\", default_port)\n        replacement_dict = {\"port\": port, \"hostname\": overseer.name}\n        admins = self.project.get_participants_by_type(\"admin\", first_only=False)\n        privilege_dict = dict()\n        for admin in admins:\n            for role in admin.props.get(\"roles\", {}):\n                if role in privilege_dict:\n                    privilege_dict[role].append(admin.subject)\n                else:\n                    privilege_dict[role] = [admin.subject]\n        self._write(\n            os.path.join(dest_dir, \"privilege.yml\"),\n            yaml.dump(privilege_dict, Dumper=yaml.Dumper),\n            \"t\",\n            exe=False,\n        )\n\n        if self.docker_image:\n            self._write(\n                os.path.join(dest_dir, \"docker.sh\"),\n                sh_replace(self.template[\"docker_svr_sh\"], replacement_dict),\n                \"t\",\n                exe=True,\n            )\n        self._write(\n            os.path.join(dest_dir, \"gunicorn.conf.py\"),\n            sh_replace(self.template[\"gunicorn_conf_py\"], replacement_dict),\n            \"t\",\n            exe=False,\n        )\n        self._write(\n            os.path.join(dest_dir, \"start.sh\"),\n            self.template[\"start_ovsr_sh\"],\n            \"t\",\n            exe=True,\n        )\n        if port:\n            ctx[\"overseer_end_point\"] = f\"{protocol}://{overseer.name}:{port}{api_root}\"\n        else:\n            ctx[\"overseer_end_point\"] = f\"{protocol}://{overseer.name}{api_root}\"",
  "def _build_server(self, server, ctx):\n        config = json.loads(self.template[\"fed_server\"])\n        dest_dir = self.get_kit_dir(server, ctx)\n        server_0 = config[\"servers\"][0]\n        server_0[\"name\"] = self.project_name\n        admin_port = server.props.get(\"admin_port\", 8003)\n        ctx[\"admin_port\"] = admin_port\n        fed_learn_port = server.props.get(\"fed_learn_port\", 8002)\n        ctx[\"fed_learn_port\"] = fed_learn_port\n        ctx[\"server_name\"] = server.name\n        server_0[\"service\"][\"target\"] = f\"{server.name}:{fed_learn_port}\"\n        server_0[\"admin_host\"] = server.name\n        server_0[\"admin_port\"] = admin_port\n        if self.download_job_url:\n            server_0[\"download_job_url\"] = self.download_job_url\n        config[\"enable_byoc\"] = server.enable_byoc\n        if self.app_validator:\n            config[\"app_validator\"] = {\"path\": self.app_validator}\n        if self.overseer_agent:\n            overseer_agent = copy.deepcopy(self.overseer_agent)\n            if overseer_agent.get(\"overseer_exists\", True):\n                overseer_agent[\"args\"] = {\n                    \"role\": \"server\",\n                    \"overseer_end_point\": ctx.get(\"overseer_end_point\", \"\"),\n                    \"project\": self.project_name,\n                    \"name\": server.name,\n                    \"fl_port\": str(fed_learn_port),\n                    \"admin_port\": str(admin_port),\n                }\n            overseer_agent.pop(\"overseer_exists\", None)\n            config[\"overseer_agent\"] = overseer_agent\n        if self.snapshot_persistor:\n            config[\"snapshot_persistor\"] = self.snapshot_persistor\n        components = server.props.get(\"components\", [])\n        config[\"components\"] = list()\n        for comp in components:\n            temp_dict = {\"id\": comp}\n            temp_dict.update(components[comp])\n            config[\"components\"].append(temp_dict)\n        provisioned_client_list = list()\n        for client in self.project.get_participants_by_type(\"client\", first_only=False):\n            provisioned_client_list.append(client.name)\n        config[\"provisioned_client_list\"] = provisioned_client_list\n        self._write(os.path.join(dest_dir, \"fed_server.json\"), json.dumps(config, indent=2), \"t\")\n        replacement_dict = {\n            \"admin_port\": admin_port,\n            \"fed_learn_port\": fed_learn_port,\n            \"config_folder\": self.config_folder,\n            \"docker_image\": self.docker_image,\n        }\n        if self.docker_image:\n            self._write(\n                os.path.join(dest_dir, \"docker.sh\"),\n                sh_replace(self.template[\"docker_svr_sh\"], replacement_dict),\n                \"t\",\n                exe=True,\n            )\n        self._write(\n            os.path.join(dest_dir, \"start.sh\"),\n            self.template[\"start_svr_sh\"],\n            \"t\",\n            exe=True,\n        )\n        self._write(\n            os.path.join(dest_dir, \"sub_start.sh\"),\n            sh_replace(self.template[\"sub_start_svr_sh\"], replacement_dict),\n            \"t\",\n            exe=True,\n        )\n        self._write(\n            os.path.join(dest_dir, \"log.config\"),\n            self.template[\"log_config\"],\n            \"t\",\n        )\n        self._write(\n            os.path.join(dest_dir, \"readme.txt\"),\n            self.template[\"readme_fs\"],\n            \"t\",\n        )\n        self._write(\n            os.path.join(dest_dir, \"stop_fl.sh\"),\n            self.template[\"stop_fl_sh\"],\n            \"t\",\n            exe=True,\n        )",
  "def _build_client(self, client, ctx):\n        config = json.loads(self.template[\"fed_client\"])\n        dest_dir = self.get_kit_dir(client, ctx)\n        fed_learn_port = ctx.get(\"fed_learn_port\")\n        server_name = ctx.get(\"server_name\")\n        # config[\"servers\"][0][\"service\"][\"target\"] = f\"{server_name}:{fed_learn_port}\"\n        config[\"servers\"][0][\"name\"] = self.project_name\n        config[\"enable_byoc\"] = client.enable_byoc\n        replacement_dict = {\n            \"client_name\": f\"{client.subject}\",\n            \"config_folder\": self.config_folder,\n            \"docker_image\": self.docker_image,\n        }\n        if self.overseer_agent:\n            overseer_agent = copy.deepcopy(self.overseer_agent)\n            if overseer_agent.get(\"overseer_exists\", True):\n                overseer_agent[\"args\"] = {\n                    \"role\": \"client\",\n                    \"overseer_end_point\": ctx.get(\"overseer_end_point\", \"\"),\n                    \"project\": self.project_name,\n                    \"name\": client.subject,\n                }\n            overseer_agent.pop(\"overseer_exists\", None)\n            config[\"overseer_agent\"] = overseer_agent\n        components = client.props.get(\"components\", [])\n        config[\"components\"] = list()\n        for comp in components:\n            temp_dict = {\"id\": comp}\n            temp_dict.update(components[comp])\n            config[\"components\"].append(temp_dict)\n\n        self._write(os.path.join(dest_dir, \"fed_client.json\"), json.dumps(config, indent=2), \"t\")\n        if self.docker_image:\n            self._write(\n                os.path.join(dest_dir, \"docker.sh\"),\n                sh_replace(self.template[\"docker_cln_sh\"], replacement_dict),\n                \"t\",\n                exe=True,\n            )\n        self._write(\n            os.path.join(dest_dir, \"start.sh\"),\n            self.template[\"start_cln_sh\"],\n            \"t\",\n            exe=True,\n        )\n        self._write(\n            os.path.join(dest_dir, \"sub_start.sh\"),\n            sh_replace(self.template[\"sub_start_cln_sh\"], replacement_dict),\n            \"t\",\n            exe=True,\n        )\n        self._write(\n            os.path.join(dest_dir, \"log.config\"),\n            self.template[\"log_config\"],\n            \"t\",\n        )\n        self._write(\n            os.path.join(dest_dir, \"readme.txt\"),\n            self.template[\"readme_fc\"],\n            \"t\",\n        )\n        self._write(\n            os.path.join(dest_dir, \"stop_fl.sh\"),\n            self.template[\"stop_fl_sh\"],\n            \"t\",\n            exe=True,\n        )",
  "def _build_admin(self, admin, ctx):\n        config = json.loads(self.template[\"fed_admin\"])\n        dest_dir = self.get_kit_dir(admin, ctx)\n        admin_port = ctx.get(\"admin_port\")\n        server_name = ctx.get(\"server_name\")\n\n        replacement_dict = {\n            \"cn\": f\"{server_name}\",\n            \"admin_port\": f\"{admin_port}\",\n            \"docker_image\": self.docker_image,\n        }\n        agent_config = dict()\n        if self.overseer_agent:\n            overseer_agent = copy.deepcopy(self.overseer_agent)\n            if overseer_agent.get(\"overseer_exists\", True):\n                overseer_agent[\"args\"] = {\n                    \"role\": \"admin\",\n                    \"overseer_end_point\": ctx.get(\"overseer_end_point\", \"\"),\n                    \"project\": self.project_name,\n                    \"name\": admin.subject,\n                }\n            overseer_agent.pop(\"overseer_exists\", None)\n            agent_config[\"overseer_agent\"] = overseer_agent\n        config[\"admin\"].update(agent_config)\n        self._write(os.path.join(dest_dir, \"fed_admin.json\"), json.dumps(config, indent=2), \"t\")\n        if self.docker_image:\n            self._write(\n                os.path.join(dest_dir, \"docker.sh\"),\n                sh_replace(self.template[\"docker_adm_sh\"], replacement_dict),\n                \"t\",\n                exe=True,\n            )\n        self._write(\n            os.path.join(dest_dir, \"fl_admin.sh\"),\n            sh_replace(self.template[\"fl_admin_sh\"], replacement_dict),\n            \"t\",\n            exe=True,\n        )\n        self._write(\n            os.path.join(dest_dir, \"readme.txt\"),\n            self.template[\"readme_am\"],\n            \"t\",\n        )",
  "def build(self, project, ctx):\n        self.template = ctx.get(\"template\")\n        self.project_name = project.name\n        self.project = project\n        overseer = project.get_participants_by_type(\"overseer\")\n        self._build_overseer(overseer, ctx)\n        servers = project.get_participants_by_type(\"server\", first_only=False)\n        for server in servers:\n            self._build_server(server, ctx)\n\n        for client in project.get_participants_by_type(\"client\", first_only=False):\n            self._build_client(client, ctx)\n\n        for admin in project.get_participants_by_type(\"admin\", first_only=False):\n            self._build_admin(admin, ctx)",
  "class FLComponent(StatePersistable):\n    def __init__(self):\n        \"\"\"Init FLComponent.\n\n        The FLComponent is the base class of all FL Components.\n        (executors, controllers, responders, filters, aggregators, and widgets are all FLComponents)\n\n        FLComponents have the capability to handle and fire events and contain various methods for logging.\n        \"\"\"\n        self._name = self.__class__.__name__\n        self.logger = logging.getLogger(self._name)\n\n    def _fire(self, event_type: str, fl_ctx: FLContext):\n        fl_ctx.set_prop(FLContextKey.EVENT_ORIGIN, self._name, private=True, sticky=False)\n        engine = fl_ctx.get_engine()\n        if engine is None:\n            self.log_error(fl_ctx=fl_ctx, msg=\"Logic Error: no engine in fl_ctx: {}\".format(fl_ctx), fire_event=False)\n        else:\n            engine.fire_event(event_type, fl_ctx)\n\n    def fire_event(self, event_type: str, fl_ctx: FLContext):\n        \"\"\"Fires an event.\n\n        Args:\n            event_type (str): The type of event.\n            fl_ctx (FLContext): FLContext information.\n        \"\"\"\n        if not isinstance(event_type, str):\n            raise TypeError(\"expect event_type to be str, but got {}\".format(type(event_type)))\n\n        if not event_type:\n            raise ValueError(\"event_type must be specified\")\n\n        if not isinstance(fl_ctx, FLContext):\n            raise TypeError(\"expect fl_ctx to be FLContext, but got {}\".format(type(fl_ctx)))\n\n        fl_ctx.set_prop(FLContextKey.EVENT_SCOPE, value=EventScope.LOCAL, private=True, sticky=False)\n        self._fire(event_type, fl_ctx)\n\n    def fire_fed_event(self, event_type: str, event_data: Shareable, fl_ctx: FLContext, targets=None):\n        \"\"\"Fires a federation event.\n\n        A federation event means that the event will be sent to different sites.\n        For example, if fire a federation event on the server side, one can decide what clients to send via the\n        parameter `targets`.\n        If fire a federation event on the client side, the event will be sent to the server.\n\n        Args:\n            event_type (str): The type of event.\n            event_data (Shareable): The data of this fed event.\n            fl_ctx (FLContext): FLContext information.\n            targets: The targets to send to. It is only used when fire federation event from server side.\n        \"\"\"\n        if not isinstance(fl_ctx, FLContext):\n            raise TypeError(\"expect fl_ctx to be FLContext, but got {}\".format(type(fl_ctx)))\n\n        if not isinstance(event_data, Shareable):\n            raise TypeError(\"expect event_data to be Shareable, but got {}\".format(type(event_data)))\n\n        event_data.set_header(key=FedEventHeader.TARGETS, value=targets)\n        fl_ctx.set_prop(FLContextKey.EVENT_DATA, event_data, private=True, sticky=False)\n        fl_ctx.set_prop(FLContextKey.EVENT_SCOPE, value=EventScope.FEDERATION, private=True, sticky=False)\n        self._fire(event_type, fl_ctx)\n\n    def system_panic(self, reason: str, fl_ctx: FLContext):\n        \"\"\"Signals a fatal condition that could cause the RUN to end.\n\n        Args:\n            reason (str): The reason for panic.\n            fl_ctx (FLContext): FLContext information.\n        \"\"\"\n        fl_ctx.set_prop(FLContextKey.EVENT_DATA, reason, private=True, sticky=False)\n        self.fire_event(EventType.FATAL_SYSTEM_ERROR, fl_ctx)\n\n    def task_panic(self, reason: str, fl_ctx: FLContext):\n        \"\"\"Signals a fatal condition that could cause the current task (on Client) to end.\n\n        Args:\n            reason (str): The reason for panic.\n            fl_ctx (FLContext): FLContext information.\n        \"\"\"\n        fl_ctx.set_prop(FLContextKey.EVENT_DATA, reason, private=True, sticky=False)\n        self.fire_event(EventType.FATAL_TASK_ERROR, fl_ctx)\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        \"\"\"Handles events.\n\n        Args:\n            event_type (str): event type fired by workflow.\n            fl_ctx (FLContext): FLContext information.\n        \"\"\"\n        pass\n\n    def log_info(self, fl_ctx: FLContext, msg: str, fire_event=False):\n        \"\"\"Logs a message with logger.info.\n\n        These log_XXX methods are implemented because we want to have a unified way of logging messages.\n        For example, in this method, we are using generate_log_message to add the FLContext information\n        into the message. And we can decide whether to fire a log event afterwards.\n\n        Args:\n            fl_ctx (FLContext): FLContext information.\n            msg (str): The message to log.\n            fire_event (bool): Whether to fire a log event.\n        \"\"\"\n        log_msg = generate_log_message(fl_ctx, msg)\n        self.logger.info(log_msg)\n\n        if fire_event:\n            self._fire_log_event(\n                event_type=EventType.INFO_LOG_AVAILABLE, log_tag=LogMessageTag.INFO, log_msg=log_msg, fl_ctx=fl_ctx\n            )\n\n    def log_warning(self, fl_ctx: FLContext, msg: str, fire_event=True):\n        \"\"\"Logs a message with logger.warning.\n\n        Args:\n            fl_ctx (FLContext): FLContext information.\n            msg (str): The message to log.\n            fire_event (bool): Whether to fire a log event.\n        \"\"\"\n        log_msg = generate_log_message(fl_ctx, msg)\n        self.logger.warning(log_msg)\n        if fire_event:\n            self._fire_log_event(\n                event_type=EventType.WARNING_LOG_AVAILABLE,\n                log_tag=LogMessageTag.WARNING,\n                log_msg=log_msg,\n                fl_ctx=fl_ctx,\n            )\n\n    def log_error(self, fl_ctx: FLContext, msg: str, fire_event=True):\n        \"\"\"Logs a message with logger.error.\n\n        Args:\n            fl_ctx (FLContext): FLContext information.\n            msg (str): The message to log.\n            fire_event (bool): Whether to fire a log event.\n        \"\"\"\n        log_msg = generate_log_message(fl_ctx, msg)\n        self.logger.error(log_msg)\n        if fire_event:\n            self._fire_log_event(\n                event_type=EventType.ERROR_LOG_AVAILABLE, log_tag=LogMessageTag.ERROR, log_msg=log_msg, fl_ctx=fl_ctx\n            )\n\n    def log_debug(self, fl_ctx: FLContext, msg: str, fire_event=False):\n        \"\"\"Logs a message with logger.debug.\n\n        Args:\n            fl_ctx (FLContext): FLContext information.\n            msg (str): The message to log.\n            fire_event (bool): Whether to fire a log event.\n        \"\"\"\n        log_msg = generate_log_message(fl_ctx, msg)\n        self.logger.debug(log_msg)\n        if fire_event:\n            self._fire_log_event(\n                event_type=EventType.DEBUG_LOG_AVAILABLE, log_tag=LogMessageTag.DEBUG, log_msg=log_msg, fl_ctx=fl_ctx\n            )\n\n    def log_critical(self, fl_ctx: FLContext, msg: str, fire_event=True):\n        \"\"\"Logs a message with logger.critical.\n\n        Args:\n            fl_ctx (FLContext): FLContext information.\n            msg (str): The message to log.\n            fire_event (bool): Whether to fire a log event.\n        \"\"\"\n        log_msg = generate_log_message(fl_ctx, msg)\n        self.logger.critical(log_msg)\n        if fire_event:\n            self._fire_log_event(\n                event_type=EventType.CRITICAL_LOG_AVAILABLE,\n                log_tag=LogMessageTag.CRITICAL,\n                log_msg=log_msg,\n                fl_ctx=fl_ctx,\n            )\n\n    def log_exception(self, fl_ctx: FLContext, msg: str, fire_event=False):\n        \"\"\"Logs exception message with logger.error.\n\n        Args:\n            fl_ctx (FLContext): FLContext information.\n            msg (str): The message to log.\n            fire_event (bool): Whether to fire a log event. Unused.\n        \"\"\"\n        log_msg = generate_log_message(fl_ctx, msg)\n        self.logger.error(log_msg)\n        traceback.print_exc()\n\n        if fire_event:\n            ex_text = traceback.format_exc()\n            ex_msg = \"{}\\n{}\".format(log_msg, ex_text)\n            self._fire_log_event(\n                event_type=EventType.EXCEPTION_LOG_AVAILABLE,\n                log_tag=LogMessageTag.EXCEPTION,\n                log_msg=ex_msg,\n                fl_ctx=fl_ctx,\n            )\n\n    def _fire_log_event(self, event_type: str, log_tag: str, log_msg: str, fl_ctx: FLContext):\n        event_data = AnalyticsData(tag=log_tag, value=log_msg, data_type=AnalyticsDataType.TEXT, kwargs=None)\n        dxo = event_data.to_dxo()\n        fl_ctx.set_prop(key=FLContextKey.EVENT_DATA, value=dxo.to_shareable(), private=True, sticky=False)\n        self.fire_event(event_type=event_type, fl_ctx=fl_ctx)",
  "def __init__(self):\n        \"\"\"Init FLComponent.\n\n        The FLComponent is the base class of all FL Components.\n        (executors, controllers, responders, filters, aggregators, and widgets are all FLComponents)\n\n        FLComponents have the capability to handle and fire events and contain various methods for logging.\n        \"\"\"\n        self._name = self.__class__.__name__\n        self.logger = logging.getLogger(self._name)",
  "def _fire(self, event_type: str, fl_ctx: FLContext):\n        fl_ctx.set_prop(FLContextKey.EVENT_ORIGIN, self._name, private=True, sticky=False)\n        engine = fl_ctx.get_engine()\n        if engine is None:\n            self.log_error(fl_ctx=fl_ctx, msg=\"Logic Error: no engine in fl_ctx: {}\".format(fl_ctx), fire_event=False)\n        else:\n            engine.fire_event(event_type, fl_ctx)",
  "def fire_event(self, event_type: str, fl_ctx: FLContext):\n        \"\"\"Fires an event.\n\n        Args:\n            event_type (str): The type of event.\n            fl_ctx (FLContext): FLContext information.\n        \"\"\"\n        if not isinstance(event_type, str):\n            raise TypeError(\"expect event_type to be str, but got {}\".format(type(event_type)))\n\n        if not event_type:\n            raise ValueError(\"event_type must be specified\")\n\n        if not isinstance(fl_ctx, FLContext):\n            raise TypeError(\"expect fl_ctx to be FLContext, but got {}\".format(type(fl_ctx)))\n\n        fl_ctx.set_prop(FLContextKey.EVENT_SCOPE, value=EventScope.LOCAL, private=True, sticky=False)\n        self._fire(event_type, fl_ctx)",
  "def fire_fed_event(self, event_type: str, event_data: Shareable, fl_ctx: FLContext, targets=None):\n        \"\"\"Fires a federation event.\n\n        A federation event means that the event will be sent to different sites.\n        For example, if fire a federation event on the server side, one can decide what clients to send via the\n        parameter `targets`.\n        If fire a federation event on the client side, the event will be sent to the server.\n\n        Args:\n            event_type (str): The type of event.\n            event_data (Shareable): The data of this fed event.\n            fl_ctx (FLContext): FLContext information.\n            targets: The targets to send to. It is only used when fire federation event from server side.\n        \"\"\"\n        if not isinstance(fl_ctx, FLContext):\n            raise TypeError(\"expect fl_ctx to be FLContext, but got {}\".format(type(fl_ctx)))\n\n        if not isinstance(event_data, Shareable):\n            raise TypeError(\"expect event_data to be Shareable, but got {}\".format(type(event_data)))\n\n        event_data.set_header(key=FedEventHeader.TARGETS, value=targets)\n        fl_ctx.set_prop(FLContextKey.EVENT_DATA, event_data, private=True, sticky=False)\n        fl_ctx.set_prop(FLContextKey.EVENT_SCOPE, value=EventScope.FEDERATION, private=True, sticky=False)\n        self._fire(event_type, fl_ctx)",
  "def system_panic(self, reason: str, fl_ctx: FLContext):\n        \"\"\"Signals a fatal condition that could cause the RUN to end.\n\n        Args:\n            reason (str): The reason for panic.\n            fl_ctx (FLContext): FLContext information.\n        \"\"\"\n        fl_ctx.set_prop(FLContextKey.EVENT_DATA, reason, private=True, sticky=False)\n        self.fire_event(EventType.FATAL_SYSTEM_ERROR, fl_ctx)",
  "def task_panic(self, reason: str, fl_ctx: FLContext):\n        \"\"\"Signals a fatal condition that could cause the current task (on Client) to end.\n\n        Args:\n            reason (str): The reason for panic.\n            fl_ctx (FLContext): FLContext information.\n        \"\"\"\n        fl_ctx.set_prop(FLContextKey.EVENT_DATA, reason, private=True, sticky=False)\n        self.fire_event(EventType.FATAL_TASK_ERROR, fl_ctx)",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        \"\"\"Handles events.\n\n        Args:\n            event_type (str): event type fired by workflow.\n            fl_ctx (FLContext): FLContext information.\n        \"\"\"\n        pass",
  "def log_info(self, fl_ctx: FLContext, msg: str, fire_event=False):\n        \"\"\"Logs a message with logger.info.\n\n        These log_XXX methods are implemented because we want to have a unified way of logging messages.\n        For example, in this method, we are using generate_log_message to add the FLContext information\n        into the message. And we can decide whether to fire a log event afterwards.\n\n        Args:\n            fl_ctx (FLContext): FLContext information.\n            msg (str): The message to log.\n            fire_event (bool): Whether to fire a log event.\n        \"\"\"\n        log_msg = generate_log_message(fl_ctx, msg)\n        self.logger.info(log_msg)\n\n        if fire_event:\n            self._fire_log_event(\n                event_type=EventType.INFO_LOG_AVAILABLE, log_tag=LogMessageTag.INFO, log_msg=log_msg, fl_ctx=fl_ctx\n            )",
  "def log_warning(self, fl_ctx: FLContext, msg: str, fire_event=True):\n        \"\"\"Logs a message with logger.warning.\n\n        Args:\n            fl_ctx (FLContext): FLContext information.\n            msg (str): The message to log.\n            fire_event (bool): Whether to fire a log event.\n        \"\"\"\n        log_msg = generate_log_message(fl_ctx, msg)\n        self.logger.warning(log_msg)\n        if fire_event:\n            self._fire_log_event(\n                event_type=EventType.WARNING_LOG_AVAILABLE,\n                log_tag=LogMessageTag.WARNING,\n                log_msg=log_msg,\n                fl_ctx=fl_ctx,\n            )",
  "def log_error(self, fl_ctx: FLContext, msg: str, fire_event=True):\n        \"\"\"Logs a message with logger.error.\n\n        Args:\n            fl_ctx (FLContext): FLContext information.\n            msg (str): The message to log.\n            fire_event (bool): Whether to fire a log event.\n        \"\"\"\n        log_msg = generate_log_message(fl_ctx, msg)\n        self.logger.error(log_msg)\n        if fire_event:\n            self._fire_log_event(\n                event_type=EventType.ERROR_LOG_AVAILABLE, log_tag=LogMessageTag.ERROR, log_msg=log_msg, fl_ctx=fl_ctx\n            )",
  "def log_debug(self, fl_ctx: FLContext, msg: str, fire_event=False):\n        \"\"\"Logs a message with logger.debug.\n\n        Args:\n            fl_ctx (FLContext): FLContext information.\n            msg (str): The message to log.\n            fire_event (bool): Whether to fire a log event.\n        \"\"\"\n        log_msg = generate_log_message(fl_ctx, msg)\n        self.logger.debug(log_msg)\n        if fire_event:\n            self._fire_log_event(\n                event_type=EventType.DEBUG_LOG_AVAILABLE, log_tag=LogMessageTag.DEBUG, log_msg=log_msg, fl_ctx=fl_ctx\n            )",
  "def log_critical(self, fl_ctx: FLContext, msg: str, fire_event=True):\n        \"\"\"Logs a message with logger.critical.\n\n        Args:\n            fl_ctx (FLContext): FLContext information.\n            msg (str): The message to log.\n            fire_event (bool): Whether to fire a log event.\n        \"\"\"\n        log_msg = generate_log_message(fl_ctx, msg)\n        self.logger.critical(log_msg)\n        if fire_event:\n            self._fire_log_event(\n                event_type=EventType.CRITICAL_LOG_AVAILABLE,\n                log_tag=LogMessageTag.CRITICAL,\n                log_msg=log_msg,\n                fl_ctx=fl_ctx,\n            )",
  "def log_exception(self, fl_ctx: FLContext, msg: str, fire_event=False):\n        \"\"\"Logs exception message with logger.error.\n\n        Args:\n            fl_ctx (FLContext): FLContext information.\n            msg (str): The message to log.\n            fire_event (bool): Whether to fire a log event. Unused.\n        \"\"\"\n        log_msg = generate_log_message(fl_ctx, msg)\n        self.logger.error(log_msg)\n        traceback.print_exc()\n\n        if fire_event:\n            ex_text = traceback.format_exc()\n            ex_msg = \"{}\\n{}\".format(log_msg, ex_text)\n            self._fire_log_event(\n                event_type=EventType.EXCEPTION_LOG_AVAILABLE,\n                log_tag=LogMessageTag.EXCEPTION,\n                log_msg=ex_msg,\n                fl_ctx=fl_ctx,\n            )",
  "def _fire_log_event(self, event_type: str, log_tag: str, log_msg: str, fl_ctx: FLContext):\n        event_data = AnalyticsData(tag=log_tag, value=log_msg, data_type=AnalyticsDataType.TEXT, kwargs=None)\n        dxo = event_data.to_dxo()\n        fl_ctx.set_prop(key=FLContextKey.EVENT_DATA, value=dxo.to_shareable(), private=True, sticky=False)\n        self.fire_event(event_type=event_type, fl_ctx=fl_ctx)",
  "class ReturnCode(object):\n\n    OK = \"OK\"\n\n    BAD_PEER_CONTEXT = \"BAD_PEER_CONTEXT\"\n    BAD_REQUEST_DATA = \"BAD_REQUEST_DATA\"\n    BAD_TASK_DATA = \"BAD_TASK_DATA\"\n    COMMUNICATION_ERROR = \"COMMUNICATION_ERROR\"\n    ERROR = \"ERROR\"\n    EXECUTION_EXCEPTION = \"EXECUTION_EXCEPTION\"\n    EXECUTION_RESULT_ERROR = \"EXECUTION_RESULT_ERROR\"\n    HANDLER_EXCEPTION = \"HANDLER_EXCEPTION\"\n    MISSING_PEER_CONTEXT = \"MISSING_PEER_CONTEXT\"\n    RUN_MISMATCH = \"RUN_MISMATCH\"\n    TASK_ABORTED = \"TASK_ABORTED\"\n    TASK_DATA_FILTER_ERROR = \"TASK_DATA_FILTER_ERROR\"\n    TASK_RESULT_FILTER_ERROR = \"TASK_RESULT_FILTER_ERROR\"\n    TASK_UNKNOWN = \"TASK_UNKNOWN\"\n    TASK_UNSUPPORTED = \"TASK_UNSUPPORTED\"\n    TOPIC_UNKNOWN = \"TOPIC_UNKNOWN\"\n    MODEL_UNRECOGNIZED = \"MODEL_UNRECOGNIZED\"\n    VALIDATE_TYPE_UNKNOWN = \"VALIDATE_TYPE_UNKNOWN\"\n    EMPTY_RESULT = \"EMPTY_RESULT\"\n\n    SERVER_NOT_READY = \"SERVER_NOT_READY\"",
  "class MachineStatus(Enum):\n    \"\"\"Constants for machine status.\n\n    Status Lifecycle\n        STOPPED <-> STARTING -> STARTED -> STOPPING -> STOPPED\n    \"\"\"\n\n    STARTING = \"starting\"\n    STARTED = \"started\"\n    STOPPING = \"stopping\"\n    STOPPED = \"stopped\"",
  "class ReservedKey(object):\n\n    MANAGER = \"__manager__\"\n    ENGINE = \"__engine__\"\n    AUX_RUNNER = \"__aux_runner__\"\n    RUN_NUM = \"__run_num__\"\n    IDENTITY_NAME = \"__identity_name__\"  # identity of the endpoint (e.g. client name)\n    PEER_CTX = \"__peer_ctx__\"\n    RC = \"__rc__\"\n    COOKIE_JAR = \"__cookie_jar__\"\n    WORKSPACE_ROOT = \"__workspace_root__\"\n    APP_ROOT = \"__app_root__\"\n    CLIENT_NAME = \"__client_name__\"\n    TASK_NAME = \"__task_name__\"\n    TASK_DATA = \"__task_data__\"\n    TASK_RESULT = \"__task_result__\"\n    TASK_ID = \"__task_id__\"\n    EVENT_ID = \"__event_id__\"\n    IS_RESEND = \"__is_resend__\"\n    RUNNER = \"__runner__\"\n    WORKFLOW = \"__workflow__\"\n    REPLY = \"__reply__\"\n    EVENT_ORIGIN = \"__event_origin__\"\n    EVENT_ORIGIN_SITE = \"__event_origin_site__\"\n    EVENT_DATA = \"__event_data__\"\n    EVENT_SCOPE = \"__event_scope__\"\n    RUN_ABORT_SIGNAL = \"__run_abort_signal__\"\n    SHAREABLE = \"__shareable__\"\n    ARGS = \"__args__\"\n    WORKSPACE_OBJECT = \"__workspace_object__\"\n    RANK_NUMBER = \"__rank_number__\"\n    NUM_OF_PROCESSES = \"__num_of_processes__\"\n    FROM_RANK_NUMBER = \"__from_rank_number__\"\n    SECURE_MODE = \"__secure_mode__\"\n    SP_END_POINT = \"__sp_end_point__\"\n    JOB_INFO = \"__job_info__\"\n    CURRENT_JOB_ID = \"__current_job_id__\"\n    JOB_RUN_NUMBER = \"__job_run_number__\"",
  "class FLContextKey(object):\n\n    TASK_NAME = ReservedKey.TASK_NAME\n    TASK_DATA = ReservedKey.TASK_DATA\n    TASK_RESULT = ReservedKey.TASK_RESULT\n    TASK_ID = ReservedKey.TASK_ID\n    EVENT_ID = ReservedKey.EVENT_ID\n    EVENT_ORIGIN = ReservedKey.EVENT_ORIGIN\n    EVENT_ORIGIN_SITE = ReservedKey.EVENT_ORIGIN_SITE\n    EVENT_DATA = ReservedKey.EVENT_DATA\n    EVENT_SCOPE = ReservedKey.EVENT_SCOPE\n    CLIENT_NAME = ReservedKey.CLIENT_NAME\n    WORKSPACE_ROOT = ReservedKey.WORKSPACE_ROOT\n    CURRENT_RUN = ReservedKey.RUN_NUM\n    APP_ROOT = ReservedKey.APP_ROOT\n    PEER_CONTEXT = ReservedKey.PEER_CTX\n    IS_CLIENT_TASK_RESEND = ReservedKey.IS_RESEND\n    RUNNER = ReservedKey.RUNNER\n    WORKFLOW = ReservedKey.WORKFLOW\n    SHAREABLE = ReservedKey.SHAREABLE\n    RUN_ABORT_SIGNAL = ReservedKey.RUN_ABORT_SIGNAL\n    ARGS = ReservedKey.ARGS\n    REPLY = ReservedKey.REPLY\n    WORKSPACE_OBJECT = ReservedKey.WORKSPACE_OBJECT\n    RANK_NUMBER = ReservedKey.RANK_NUMBER\n    NUM_OF_PROCESSES = ReservedKey.NUM_OF_PROCESSES\n    FROM_RANK_NUMBER = ReservedKey.FROM_RANK_NUMBER\n    SECURE_MODE = ReservedKey.SECURE_MODE\n    SP_END_POINT = ReservedKey.SP_END_POINT\n    JOB_INFO = ReservedKey.JOB_INFO\n    CURRENT_JOB_ID = ReservedKey.CURRENT_JOB_ID\n    JOB_RUN_NUMBER = ReservedKey.JOB_RUN_NUMBER",
  "class ReservedTopic(object):\n\n    END_RUN = \"__end_run__\"\n    ABORT_ASK = \"__abort_task__\"\n    AUX_COMMAND = \"__aux_command__\"",
  "class AdminCommandNames(object):\n\n    SUBMIT_JOB = \"submit_job\"\n    LIST_JOBS = \"list_jobs\"\n    DOWNLOAD_JOB = \"download_job\"\n    ABORT_JOB = \"abort_job\"\n    DELETE_JOB = \"delete_job\"\n    CLONE_JOB = \"clone_job\"\n    DELETE_WORKSPACE = \"delete_workspace\"\n    DEPLOY_APP = \"deploy_app\"\n    START_APP = \"start_app\"\n    CHECK_STATUS = \"check_status\"\n    ABORT = \"abort\"\n    ABORT_TASK = \"abort_task\"\n    REMOVE_CLIENT = \"remove_client\"\n    SHUTDOWN = \"shutdown\"\n    RESTART = \"restart\"\n    SET_TIMEOUT = \"set_timeout\"\n    SHOW_STATS = \"show_stats\"\n    SHOW_ERRORS = \"show_errors\"\n    RESET_ERRORS = \"reset_errors\"\n    AUX_COMMAND = \"aux_command\"",
  "class ServerCommandNames(object):\n\n    GET_RUN_INFO = \"get_run_info\"\n    GET_TASK = \"get_task\"\n    SUBMIT_UPDATE = \"submit_update\"\n    AUX_COMMUNICATE = \"aux_communicate\"\n    HEARTBEAT = \"heartbeat\"\n    GET_CLIENTS = \"get_clients\"\n    AUX_SEND = \"aux_send\"\n    SHOW_STATS = \"show_stats\"\n    GET_ERRORS = \"get_errors\"",
  "class ServerCommandKey(object):\n\n    COMMAND = \"command\"\n    DATA = \"data\"\n    FL_CONTEXT = \"fl_context\"\n    PEER_FL_CONTEXT = \"peer_fl_ctx\"\n    SHAREABLE = \"shareable\"\n    TASK_NAME = \"task_name\"\n    TASK_ID = \"task_id\"\n    FL_CLIENT = \"fl_client\"\n    TOPIC = \"topic\"\n    AUX_REPLY = \"aux_reply\"\n    JOB_ID = \"job_id\"\n    CLIENTS = \"clients\"\n    COLLECTOR = \"collector\"",
  "class FedEventHeader(object):\n\n    TIMESTAMP = \"_timestamp\"\n    EVENT_TYPE = \"_event_type\"\n    DIRECTION = \"_direction\"\n    ORIGIN = \"_origin\"\n    TARGETS = \"_targets\"",
  "class EventScope(object):\n\n    FEDERATION = \"federation\"\n    LOCAL = \"local\"",
  "class NonSerializableKeys(object):\n\n    KEYS = [ReservedKey.ENGINE, ReservedKey.MANAGER, ReservedKey.RUNNER]",
  "class LogMessageTag(object):\n\n    DEBUG = \"log/debug\"\n    ERROR = \"log/error\"\n    EXCEPTION = \"log/exception\"\n    INFO = \"log/info\"\n    WARNING = \"log/warning\"\n    CRITICAL = \"log/critical\"\n    LOG_RECORD = \"log_record\"",
  "class SnapshotKey(object):\n\n    FL_CONTEXT = \"fl_context\"\n    SERVER_RUNNER = \"_Server_Runner\"\n    WORKSPACE = \"_workspace\"\n    JOB_INFO = \"_job_info\"\n    JOB_ID = \"_job_id\"\n    JOB_CLIENTS = \"_job_clients\"",
  "class RunProcessKey(object):\n\n    LISTEN_PORT = \"_listen_port\"\n    CONNECTION = \"_comm_conn\"\n    CHILD_PROCESS = \"_child_process\"\n    STATUS = \"_status\"\n    JOB_ID = \"_job_id\"\n    PARTICIPANTS = \"_participants\"",
  "class SystemComponents(object):\n\n    JOB_SCHEDULER = \"job_scheduler\"\n    JOB_MANAGER = \"job_manager\"\n    JOB_RUNNER = \"job_runner\"\n    SERVER_RUNNER = \"server_runner\"\n    CLIENT_RUNNER = \"client_runner\"\n    CHECK_RESOURCE_PROCESSOR = \"check_resource_processor\"\n    CANCEL_RESOURCE_PROCESSOR = \"cancel_resource_processor\"\n    RESOURCE_MANAGER = \"resource_manager\"\n    RESOURCE_CONSUMER = \"resource_consumer\"",
  "class WorkspaceConstants:\n    \"\"\"hard coded file names inside the workspace folder.\"\"\"\n\n    LOGGING_CONFIG = \"log.config\"\n    AUDIT_LOG = \"audit.log\"\n\n    # these two files is used by shell scripts to determine restart / shutdown\n    RESTART_FILE = \"restart.fl\"\n    SHUTDOWN_FILE = \"shutdown.fl\"\n\n    WORKSPACE_PREFIX = \"\"\n    APP_PREFIX = \"app_\"",
  "class StatePersistable:\n    def get_persist_state(self, fl_ctx: FLContext) -> dict:\n        \"\"\"Generate data from state to be persisted.\n\n        Args:\n            fl_ctx: FLContext\n\n        Returns:\n            A dict serializable persist data\n        \"\"\"\n        return {}\n\n    def restore(self, state_data: dict, fl_ctx: FLContext):\n        \"\"\"Restore the state from persisted data.\n\n        Args:\n            state_data: serialized persist data\n            fl_ctx: FLContext\n        \"\"\"\n        pass",
  "def get_persist_state(self, fl_ctx: FLContext) -> dict:\n        \"\"\"Generate data from state to be persisted.\n\n        Args:\n            fl_ctx: FLContext\n\n        Returns:\n            A dict serializable persist data\n        \"\"\"\n        return {}",
  "def restore(self, state_data: dict, fl_ctx: FLContext):\n        \"\"\"Restore the state from persisted data.\n\n        Args:\n            state_data: serialized persist data\n            fl_ctx: FLContext\n        \"\"\"\n        pass",
  "class ReservedHeaderKey(object):\n\n    HEADERS = \"__headers__\"\n    TOPIC = \"__topic__\"\n    RC = ReservedKey.RC\n    COOKIE_JAR = ReservedKey.COOKIE_JAR\n    PEER_PROPS = \"__peer_props__\"\n    REPLY_IS_LATE = \"__reply_is_late__\"\n    TASK_NAME = ReservedKey.TASK_NAME\n    TASK_ID = ReservedKey.TASK_ID\n    WORKFLOW = ReservedKey.WORKFLOW\n    CONTENT_TYPE = \"__content_type__\"",
  "class Shareable(dict):\n    \"\"\"The information communicated between server and client.\n\n    Shareable is just a dict that can have any keys and values, defined by developers and users.\n    It is recommended that keys are strings. Values must be serializable.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Init the Shareable.\"\"\"\n        super().__init__()\n        self[ReservedHeaderKey.HEADERS] = {}\n\n    def set_header(self, key: str, value):\n        header = self.get(ReservedHeaderKey.HEADERS, None)\n        if not header:\n            header = {}\n            self[ReservedHeaderKey.HEADERS] = header\n        header[key] = value\n\n    def get_header(self, key: str, default=None):\n        header = self.get(ReservedHeaderKey.HEADERS, None)\n        if not header:\n            return default\n        else:\n            if not isinstance(header, dict):\n                raise ValueError(\"header object must be a dict, but got {}\".format(type(header)))\n            return header.get(key, default)\n\n    # some convenience methods\n    def get_return_code(self, default=ReturnCode.OK):\n        return self.get_header(ReservedHeaderKey.RC, default)\n\n    def set_return_code(self, rc):\n        self.set_header(ReservedHeaderKey.RC, rc)\n\n    def add_cookie(self, name: str, data):\n        \"\"\"Add a cookie that is to be sent to the client and echoed back in response.\n\n        This method is intended to be called by the Server side.\n\n        Args:\n            name: the name of the cookie\n            data: the data of the cookie, which must be serializable\n\n        \"\"\"\n        cookie_jar = self.get_cookie_jar()\n        if not cookie_jar:\n            cookie_jar = {}\n            self.set_header(key=ReservedHeaderKey.COOKIE_JAR, value=cookie_jar)\n        cookie_jar[name] = data\n\n    def get_cookie_jar(self):\n        return self.get_header(key=ReservedHeaderKey.COOKIE_JAR, default=None)\n\n    def set_cookie_jar(self, jar):\n        self.set_header(key=ReservedHeaderKey.COOKIE_JAR, value=jar)\n\n    def get_cookie(self, name: str, default=None):\n        jar = self.get_cookie_jar()\n        if not jar:\n            return default\n        return jar.get(name, default)\n\n    def set_peer_props(self, props: dict):\n        self.set_header(ReservedHeaderKey.PEER_PROPS, props)\n\n    def get_peer_props(self):\n        return self.get_header(ReservedHeaderKey.PEER_PROPS, None)\n\n    def get_peer_prop(self, key: str, default):\n        props = self.get_peer_props()\n        if not isinstance(props, dict):\n            return default\n        return props.get(key, default)\n\n    def to_bytes(self) -> bytes:\n        \"\"\"Serialize the Model object into bytes.\n\n        Returns:\n            object serialized in bytes.\n\n        \"\"\"\n        return pickle.dumps(self)\n\n    @classmethod\n    def from_bytes(cls, data: bytes):\n        \"\"\"Convert the data bytes into Model object.\n\n        Args:\n            data: a bytes object\n\n        Returns:\n            an object loaded by pickle from data\n\n        \"\"\"\n        return pickle.loads(data)",
  "def make_reply(rc) -> Shareable:\n    reply = Shareable()\n    reply.set_return_code(rc)\n    return reply",
  "def __init__(self):\n        \"\"\"Init the Shareable.\"\"\"\n        super().__init__()\n        self[ReservedHeaderKey.HEADERS] = {}",
  "def set_header(self, key: str, value):\n        header = self.get(ReservedHeaderKey.HEADERS, None)\n        if not header:\n            header = {}\n            self[ReservedHeaderKey.HEADERS] = header\n        header[key] = value",
  "def get_header(self, key: str, default=None):\n        header = self.get(ReservedHeaderKey.HEADERS, None)\n        if not header:\n            return default\n        else:\n            if not isinstance(header, dict):\n                raise ValueError(\"header object must be a dict, but got {}\".format(type(header)))\n            return header.get(key, default)",
  "def get_return_code(self, default=ReturnCode.OK):\n        return self.get_header(ReservedHeaderKey.RC, default)",
  "def set_return_code(self, rc):\n        self.set_header(ReservedHeaderKey.RC, rc)",
  "def add_cookie(self, name: str, data):\n        \"\"\"Add a cookie that is to be sent to the client and echoed back in response.\n\n        This method is intended to be called by the Server side.\n\n        Args:\n            name: the name of the cookie\n            data: the data of the cookie, which must be serializable\n\n        \"\"\"\n        cookie_jar = self.get_cookie_jar()\n        if not cookie_jar:\n            cookie_jar = {}\n            self.set_header(key=ReservedHeaderKey.COOKIE_JAR, value=cookie_jar)\n        cookie_jar[name] = data",
  "def get_cookie_jar(self):\n        return self.get_header(key=ReservedHeaderKey.COOKIE_JAR, default=None)",
  "def set_cookie_jar(self, jar):\n        self.set_header(key=ReservedHeaderKey.COOKIE_JAR, value=jar)",
  "def get_cookie(self, name: str, default=None):\n        jar = self.get_cookie_jar()\n        if not jar:\n            return default\n        return jar.get(name, default)",
  "def set_peer_props(self, props: dict):\n        self.set_header(ReservedHeaderKey.PEER_PROPS, props)",
  "def get_peer_props(self):\n        return self.get_header(ReservedHeaderKey.PEER_PROPS, None)",
  "def get_peer_prop(self, key: str, default):\n        props = self.get_peer_props()\n        if not isinstance(props, dict):\n            return default\n        return props.get(key, default)",
  "def to_bytes(self) -> bytes:\n        \"\"\"Serialize the Model object into bytes.\n\n        Returns:\n            object serialized in bytes.\n\n        \"\"\"\n        return pickle.dumps(self)",
  "def from_bytes(cls, data: bytes):\n        \"\"\"Convert the data bytes into Model object.\n\n        Args:\n            data: a bytes object\n\n        Returns:\n            an object loaded by pickle from data\n\n        \"\"\"\n        return pickle.loads(data)",
  "class FLCommunicationError(Exception):\n    \"\"\"Base class for fed_learn communication exceptions.\"\"\"\n\n    def __init__(self, exception):\n        \"\"\"Init the FLCommunicationError.\n\n        Args:\n            exception: grpc.RpcError when trying to register gprc channel\n        \"\"\"\n        super().__init__()\n        # Copy all the gRPC exception properties into FLCommunicationError instance.\n        self.__dict__.update(exception.__dict__)",
  "class WorkflowError(Exception):\n    \"\"\"FL Workflow error to indicate not to continue workflow execution.\"\"\"\n\n    def __init__(self, *args: object) -> None:\n        \"\"\"Init the WorkflowError.\n\n        Args:\n            *args: variable number of arguments for Exception; usually is error message string\n        \"\"\"\n        super().__init__(*args)",
  "def __init__(self, exception):\n        \"\"\"Init the FLCommunicationError.\n\n        Args:\n            exception: grpc.RpcError when trying to register gprc channel\n        \"\"\"\n        super().__init__()\n        # Copy all the gRPC exception properties into FLCommunicationError instance.\n        self.__dict__.update(exception.__dict__)",
  "def __init__(self, *args: object) -> None:\n        \"\"\"Init the WorkflowError.\n\n        Args:\n            *args: variable number of arguments for Exception; usually is error message string\n        \"\"\"\n        super().__init__(*args)",
  "class AppValidationKey(object):\n\n    BYOC = \"byoc\"\n    CUSTOM_DATA_LIST = \"custom_datalist\"",
  "class AppValidator(ABC):\n    @abstractmethod\n    def validate(self, app_folder: str) -> Tuple[str, Dict]:\n        \"\"\"Validate and/or clean the content of specified application folder.\n\n        Args:\n            app_folder: path to the app folder to be validated\n\n        Returns:\n            A tuple of (error_msg, authorization_context)\n\n            error_msg contains error message if failed to pass; otherwise an empty string.\n            authorization_context is the context needed by authorization.\n\n            For example: the result could be (\"\", {\"byoc\": True, \"custom_datalist\": True})\n        \"\"\"\n        pass",
  "def validate(self, app_folder: str) -> Tuple[str, Dict]:\n        \"\"\"Validate and/or clean the content of specified application folder.\n\n        Args:\n            app_folder: path to the app folder to be validated\n\n        Returns:\n            A tuple of (error_msg, authorization_context)\n\n            error_msg contains error message if failed to pass; otherwise an empty string.\n            authorization_context is the context needed by authorization.\n\n            For example: the result could be (\"\", {\"byoc\": True, \"custom_datalist\": True})\n        \"\"\"\n        pass",
  "class Filter(FLComponent, ABC):\n    @abstractmethod\n    def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Filter process applied to the Shareable object.\n\n        Args:\n            shareable: shareable\n            fl_ctx: FLContext\n\n        Returns:\n            a Shareable object\n\n        \"\"\"\n        pass",
  "def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Filter process applied to the Shareable object.\n\n        Args:\n            shareable: shareable\n            fl_ctx: FLContext\n\n        Returns:\n            a Shareable object\n\n        \"\"\"\n        pass",
  "class ServerEngineSpec(ABC):\n    @abstractmethod\n    def fire_event(self, event_type: str, fl_ctx: FLContext):\n        pass\n\n    @abstractmethod\n    def get_clients(self) -> List[Client]:\n        pass\n\n    @abstractmethod\n    def sync_clients_from_main_process(self):\n        \"\"\"To fetch the participating clients from the main parent process\n\n        Returns: clients\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def validate_clients(self, client_names: List[str]) -> Tuple[List[Client], List[str]]:\n        \"\"\"Validate specified client names.\n\n        Args:\n            client_names: list of names to be validated\n\n        Returns: a list of validate clients  and a list of invalid client names\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def new_context(self) -> FLContext:\n        # the engine must use FLContextManager to create a new context!\n        pass\n\n    @abstractmethod\n    def get_workspace(self) -> Workspace:\n        pass\n\n    @abstractmethod\n    def get_component(self, component_id: str) -> object:\n        pass\n\n    @abstractmethod\n    def register_aux_message_handler(self, topic: str, message_handle_func):\n        \"\"\"Register aux message handling function with specified topics.\n\n        Exception is raised when:\n            a handler is already registered for the topic;\n            bad topic - must be a non-empty string\n            bad message_handle_func - must be callable\n\n        Implementation Note:\n            This method should simply call the ServerAuxRunner's register_aux_message_handler method.\n\n        Args:\n            topic: the topic to be handled by the func\n            message_handle_func: the func to handle the message. Must follow aux_message_handle_func_signature.\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def send_aux_request(self, targets: [], topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> dict:\n        \"\"\"Send a request to specified clients via the aux channel.\n\n        Implementation: simply calls the ServerAuxRunner's send_aux_request method.\n\n        Args:\n            targets: target clients. None or empty list means all clients\n            topic: topic of the request\n            request: request to be sent\n            timeout: number of secs to wait for replies. 0 means fire-and-forget.\n            fl_ctx: FL context\n\n        Returns: a dict of replies (client name => reply Shareable)\n\n        \"\"\"\n        pass\n\n    def fire_and_forget_aux_request(self, targets: [], topic: str, request: Shareable, fl_ctx: FLContext) -> dict:\n        return self.send_aux_request(targets, topic, request, 0.0, fl_ctx)\n\n    @abstractmethod\n    def get_widget(self, widget_id: str) -> Widget:\n        \"\"\"Get the widget with the specified ID.\n\n        Args:\n            widget_id: ID of the widget\n\n        Returns: the widget or None if not found\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def persist_components(self, fl_ctx: FLContext, completed: bool):\n        \"\"\"To persist the FL running components\n\n        Args:\n            fl_ctx: FLContext\n            completed: flag to indicate where the run is complete\n\n        Returns:\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def restore_components(self, snapshot: RunSnapshot, fl_ctx: FLContext):\n        \"\"\"To restore the FL components from the saved snapshot\n\n        Args:\n            snapshot: RunSnapshot\n            fl_ctx: FLContext\n\n        Returns:\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def start_client_job(self, job_id, client_sites):\n        \"\"\"To send the start client run commands to the clients\n\n        Args:\n            client_sites: client sites\n            job_id: job_id\n\n        Returns:\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def check_client_resources(self, resource_reqs: Dict[str, dict]) -> Dict[str, Tuple[bool, Optional[str]]]:\n        \"\"\"Sends the check_client_resources requests to the clients.\n\n        Args:\n            resource_reqs: A dict of {client_name: resource requirements dict}\n\n        Returns:\n            A dict of {client_name: client_check_result} where client_check_result\n                is a tuple of {client check OK, resource reserve token if any}\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def cancel_client_resources(\n        self, resource_check_results: Dict[str, Tuple[bool, str]], resource_reqs: Dict[str, dict]\n    ):\n        \"\"\"Cancels the request resources for the job.\n\n        Args:\n            resource_check_results: A dict of {client_name: client_check_result}\n                where client_check_result is a tuple of {client check OK, resource reserve token if any}\n            resource_reqs: A dict of {client_name: resource requirements dict}\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_client_name_from_token(self, token: str) -> str:\n        \"\"\"Gets client name from a client login token.\"\"\"\n        pass",
  "def fire_event(self, event_type: str, fl_ctx: FLContext):\n        pass",
  "def get_clients(self) -> List[Client]:\n        pass",
  "def sync_clients_from_main_process(self):\n        \"\"\"To fetch the participating clients from the main parent process\n\n        Returns: clients\n\n        \"\"\"\n        pass",
  "def validate_clients(self, client_names: List[str]) -> Tuple[List[Client], List[str]]:\n        \"\"\"Validate specified client names.\n\n        Args:\n            client_names: list of names to be validated\n\n        Returns: a list of validate clients  and a list of invalid client names\n\n        \"\"\"\n        pass",
  "def new_context(self) -> FLContext:\n        # the engine must use FLContextManager to create a new context!\n        pass",
  "def get_workspace(self) -> Workspace:\n        pass",
  "def get_component(self, component_id: str) -> object:\n        pass",
  "def register_aux_message_handler(self, topic: str, message_handle_func):\n        \"\"\"Register aux message handling function with specified topics.\n\n        Exception is raised when:\n            a handler is already registered for the topic;\n            bad topic - must be a non-empty string\n            bad message_handle_func - must be callable\n\n        Implementation Note:\n            This method should simply call the ServerAuxRunner's register_aux_message_handler method.\n\n        Args:\n            topic: the topic to be handled by the func\n            message_handle_func: the func to handle the message. Must follow aux_message_handle_func_signature.\n\n        \"\"\"\n        pass",
  "def send_aux_request(self, targets: [], topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> dict:\n        \"\"\"Send a request to specified clients via the aux channel.\n\n        Implementation: simply calls the ServerAuxRunner's send_aux_request method.\n\n        Args:\n            targets: target clients. None or empty list means all clients\n            topic: topic of the request\n            request: request to be sent\n            timeout: number of secs to wait for replies. 0 means fire-and-forget.\n            fl_ctx: FL context\n\n        Returns: a dict of replies (client name => reply Shareable)\n\n        \"\"\"\n        pass",
  "def fire_and_forget_aux_request(self, targets: [], topic: str, request: Shareable, fl_ctx: FLContext) -> dict:\n        return self.send_aux_request(targets, topic, request, 0.0, fl_ctx)",
  "def get_widget(self, widget_id: str) -> Widget:\n        \"\"\"Get the widget with the specified ID.\n\n        Args:\n            widget_id: ID of the widget\n\n        Returns: the widget or None if not found\n\n        \"\"\"\n        pass",
  "def persist_components(self, fl_ctx: FLContext, completed: bool):\n        \"\"\"To persist the FL running components\n\n        Args:\n            fl_ctx: FLContext\n            completed: flag to indicate where the run is complete\n\n        Returns:\n\n        \"\"\"\n        pass",
  "def restore_components(self, snapshot: RunSnapshot, fl_ctx: FLContext):\n        \"\"\"To restore the FL components from the saved snapshot\n\n        Args:\n            snapshot: RunSnapshot\n            fl_ctx: FLContext\n\n        Returns:\n\n        \"\"\"\n        pass",
  "def start_client_job(self, job_id, client_sites):\n        \"\"\"To send the start client run commands to the clients\n\n        Args:\n            client_sites: client sites\n            job_id: job_id\n\n        Returns:\n\n        \"\"\"\n        pass",
  "def check_client_resources(self, resource_reqs: Dict[str, dict]) -> Dict[str, Tuple[bool, Optional[str]]]:\n        \"\"\"Sends the check_client_resources requests to the clients.\n\n        Args:\n            resource_reqs: A dict of {client_name: resource requirements dict}\n\n        Returns:\n            A dict of {client_name: client_check_result} where client_check_result\n                is a tuple of {client check OK, resource reserve token if any}\n        \"\"\"\n        pass",
  "def cancel_client_resources(\n        self, resource_check_results: Dict[str, Tuple[bool, str]], resource_reqs: Dict[str, dict]\n    ):\n        \"\"\"Cancels the request resources for the job.\n\n        Args:\n            resource_check_results: A dict of {client_name: client_check_result}\n                where client_check_result is a tuple of {client check OK, resource reserve token if any}\n            resource_reqs: A dict of {client_name: resource requirements dict}\n        \"\"\"\n        pass",
  "def get_client_name_from_token(self, token: str) -> str:\n        \"\"\"Gets client name from a client login token.\"\"\"\n        pass",
  "class TaskCompletionStatus(Enum):\n\n    OK = \"ok\"\n    TIMEOUT = \"timeout\"\n    ERROR = \"error\"\n    CANCELLED = \"cancelled\"\n    ABORTED = \"aborted\"\n    IGNORED = \"ignored\"",
  "class Task(object):\n    def __init__(\n        self,\n        name: str,\n        data: Shareable,\n        props: Optional[Dict] = None,\n        timeout: int = 0,\n        before_task_sent_cb=None,\n        after_task_sent_cb=None,\n        result_received_cb=None,\n        task_done_cb=None,\n    ):\n        \"\"\"Init the Task.\n\n        A task is a piece of work that is assigned by the Controller to client workers.\n        Depending on how the task is assigned (broadcast, send, or relay), the task will be performed by one or more clients.\n\n        Args:\n            name (str): name of the task\n            data (Shareable): data of the task\n            props: Any additional properties of the task\n            timeout: How long this task will last. If == 0, the task never time out.\n            before_task_sent_cb: If provided, this callback would be called before controller sends the tasks to clients.\n                It needs to follow the before_task_sent_cb_signature.\n            after_task_sent_cb: If provided, this callback would be called after controller sends the tasks to clients.\n                It needs to follow the after_task_sent_cb_signature.\n            result_received_cb: If provided, this callback would be called when controller receives results from clients.\n                It needs to follow the result_received_cb_signature.\n            task_done_cb: If provided, this callback would be called when task is done.\n                It needs to follow the task_done_cb_signature.\n\n        \"\"\"\n        if not isinstance(name, str):\n            raise TypeError(\"name must be str, but got {}.\".format(type(name)))\n\n        if not isinstance(data, Shareable):\n            raise TypeError(\"data must be an instance of Shareable, but got {}.\".format(type(data)))\n\n        self.name = name  # name of the task\n        self.data = data  # task data to be sent to client(s)\n        self.cb_lock = threading.Lock()\n\n        if props is None:\n            self.props = {}\n        else:\n            if not isinstance(props, dict):\n                raise TypeError(\"props must be None or dict, but got {}.\".format(type(props)))\n            self.props = props\n\n        if not isinstance(timeout, int):\n            raise TypeError(\"timeout must be an int, but got {}.\".format(type(timeout)))\n\n        if timeout < 0:\n            raise ValueError(\"timeout must be >= 0, but got {}.\".format(timeout))\n\n        if before_task_sent_cb is not None and not callable(before_task_sent_cb):\n            raise TypeError(\n                \"before_task_sent must be a callable function, but got {}.\".format(type(before_task_sent_cb))\n            )\n\n        if after_task_sent_cb is not None and not callable(after_task_sent_cb):\n            raise TypeError(\n                \"after_task_sent_cb must be a callable function, but got {}.\".format(type(after_task_sent_cb))\n            )\n\n        if result_received_cb is not None and not callable(result_received_cb):\n            raise TypeError(\"result_received must be a callable function, but got {}.\".format(type(result_received_cb)))\n\n        if task_done_cb is not None and not callable(task_done_cb):\n            raise TypeError(\"task_done must be a callable function, but got {}.\".format(type(task_done_cb)))\n\n        self.timeout = timeout\n        self.before_task_sent_cb = before_task_sent_cb\n        self.after_task_sent_cb = after_task_sent_cb\n        self.result_received_cb = result_received_cb\n        self.task_done_cb = task_done_cb\n\n        self.targets = None\n        self.client_tasks = []  # list of ClientTasks sent\n        self.last_client_task_map = {}  # dict of: client name => last ClientTask of the client\n        self.completion_status = None  # task completion status\n        self.is_standing = False  # whether the task is still standing\n        self.schedule_time = None  # when the task was scheduled\n        self.create_time = time.time()\n\n    def set_prop(self, key, value):\n        if key.startswith(\"__\"):\n            raise ValueError(\"Keys start with __ is reserved. Please use other key instead of {}.\".format(key))\n        self.props[key] = value\n\n    def get_prop(self, key):\n        if key.startswith(\"__\"):\n            raise ValueError(\"Keys start with __ is reserved. Please use other key instead of {}.\".format(key))\n        return self.props.get(key)",
  "class ClientTask(object):\n    \"\"\"ClientTask records the processing information of a task for a client.\"\"\"\n\n    def __init__(self, client: Client, task: Task):\n        \"\"\"Init ClientTask.\n\n        Args:\n            client: the client\n            task: the processing information of this task will be recorded\n        \"\"\"\n        self.client = client\n        self.task = task\n        self.id = str(uuid.uuid4())\n        self.task_send_count = 0  # number of times the task is sent to the client\n        self.task_sent_time = None  # last time the task was sent to the client\n        self.result_received_time = None  # time when the result was received from the client\n        self.result = None  # result submitted by the client, or processed result\n        self.props = {}",
  "class SendOrder(Enum):\n\n    ANY = \"any\"\n    SEQUENTIAL = \"sequential\"",
  "def before_task_sent_cb_signature(client_task: ClientTask, fl_ctx: FLContext):\n    \"\"\"Signature of the before_task_sent CB.\n\n    Called before sending a task to a client.\n    Usually used to prepare the FL Context, which is created to process client's task req\n    You can also use this CB to alter the data of the task to be sent.\n\n    Args:\n        client_task: the client task that is about to be sent\n        fl_ctx: the FL context that comes with the client's task request.\n        Public properties you set to this context will be sent to the client!\n\n    \"\"\"\n    pass",
  "def after_task_sent_cb_signature(client_task: ClientTask, fl_ctx: FLContext):\n    \"\"\"Signature of the after_task_sent CB.\n\n    Called after sending a task to a client.\n    Usually used to clean up the FL Context or the Task data\n\n    Args:\n        client_task: the client task that has been sent\n        fl_ctx: the FL context that comes with the client's task request.\n\n    \"\"\"\n    pass",
  "def result_received_cb_signature(client_task: ClientTask, fl_ctx: FLContext):\n    \"\"\"Signature of result_received CB.\n\n    Called after a result is received from a client\n\n    Args:\n        client_task: the client task that the result is for\n        fl_ctx: the FL context that comes with the client's result submission\n\n    \"\"\"\n    pass",
  "def task_done_cb_signature(task: Task, fl_ctx: FLContext):\n    \"\"\"Signature of task_done CB.\n\n    Called when the task is completed.\n\n    Args:\n        task: the task that is completed\n        fl_ctx: an instance of FL Context used for this call only.\n\n    \"\"\"\n    pass",
  "class ControllerSpec(ABC):\n    @abstractmethod\n    def start_controller(self, fl_ctx: FLContext):\n        \"\"\"Starts the controller.\n\n        This method is called at the beginning of the RUN.\n\n        Args:\n            fl_ctx: the FL context. You can use this context to access services provided by the\n            framework. For example, you can get Command Register from it and register your\n            admin command modules.\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def stop_controller(self, fl_ctx: FLContext):\n        \"\"\"Stops the controller.\n\n        This method is called right before the RUN is ended.\n\n        Args:\n            fl_ctx: the FL context. You can use this context to access services provided by the\n            framework. For example, you can get Command Register from it and unregister your\n            admin command modules.\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def process_result_of_unknown_task(\n        self, client: Client, task_name: str, client_task_id: str, result: Shareable, fl_ctx: FLContext\n    ):\n        \"\"\"Process result when no task is found for it.\n\n        This is called when a result submission is received from a client, but no standing\n        task can be found for it (from the task queue)\n\n        This could happen when:\n        - the client's submission is too late - the task is already completed\n        - the Controller lost the task, e.g. the Server is restarted\n\n        Args:\n            client: the client that the result comes from\n            task_name: the name of the task\n            client_task_id: ID of the task\n            result: the result from the client\n            fl_ctx: the FL context that comes with the client's submission\n\n        \"\"\"\n        pass\n\n    def broadcast(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        min_responses: int = 0,\n        wait_time_after_min_received: int = 0,\n    ):\n        \"\"\"Schedule to broadcast the task to specified targets.\n\n        This is a non-blocking call.\n\n        The task is standing until one of the following conditions comes true:\n            - if timeout is specified (> 0), and the task has been standing for more than the specified time\n            - the controller has received the specified min_responses results for this task, and all target clients\n              are done.\n            - the controller has received the specified min_responses results for this task, and has waited\n              for wait_time_after_min_received.\n\n        While the task is standing:\n            - Before sending the task to a client, the before_task_sent CB (if specified) is called;\n            - When a result is received from a client, the result_received CB (if specified) is called;\n\n        After the task is done, the task_done CB (if specified) is called:\n            - If result_received CB is specified, the 'result' in the ClientTask of each\n              client is produced by the result_received CB;\n            - Otherwise, the 'result' contains the original result submitted by the clients;\n\n        NOTE: if the targets is None, the actual broadcast target clients will be dynamic, because the clients\n        could join/disconnect at any moment. While the task is standing, any client that joins automatically\n        becomes a target for this broadcast.\n\n        Args:\n            task: the task to be sent\n            fl_ctx: the FL context\n            targets: list of destination clients. None means all clients are determined dynamically;\n            min_responses: the min number of responses expected. If == 0, must get responses from\n              all clients that the task has been sent to;\n            wait_time_after_min_received: how long (secs) to wait after the min_responses is received.\n              If == 0, end the task immediately after the min responses are received;\n\n        \"\"\"\n        pass\n\n    def broadcast_and_wait(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        min_responses: int = 0,\n        wait_time_after_min_received: int = 0,\n        abort_signal: Signal = None,\n    ):\n        \"\"\"This is the blocking version of the 'broadcast' method.\n\n        First, the task is scheduled for broadcast (see the broadcast method);\n        It then waits until the task is completed.\n\n        Args:\n            task: the task to be sent\n            fl_ctx: the FL context\n            targets: list of destination clients. None means all clients are determined dynamically.\n            min_responses: the min number of responses expected. If == 0, must get responses from\n              all clients that the task has been sent to;\n            wait_time_after_min_received: how long (secs) to wait after the min_responses is received.\n              If == 0, end the task immediately after the min responses are received;\n            abort_signal: the abort signal. If triggered, this method stops waiting and returns to the caller.\n\n        \"\"\"\n        pass\n\n    def broadcast_forever(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n    ):\n        \"\"\"Schedule a broadcast task that never ends until timeout or explicitly cancelled.\n\n        All clients will get the task every time it asks for a new task.\n        This is a non-blocking call.\n\n        NOTE: you can change the content of the task in the before_task_sent function.\n\n        Args:\n            task: the task to be sent\n            fl_ctx: the FL context\n            targets: list of destination clients. None means all clients are determined dynamically.\n\n        \"\"\"\n        pass\n\n    def send(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order: SendOrder = SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n    ):\n        \"\"\"Schedule to send the task to a single target client.\n\n        This is a non-blocking call.\n\n        In ANY order, the target client is the first target that asks for task.\n        In SEQUENTIAL order, the controller will try its best to send the task to the first client\n        in the targets list. If can't, it will try the next target, and so on.\n\n        NOTE: if the 'targets' is None, the actual target clients will be dynamic, because the clients\n        could join/disconnect at any moment. While the task is standing, any client that joins automatically\n        becomes a target for this task.\n\n        If the send_order is SEQUENTIAL, the targets must be a non-empty list of client names.\n\n        Args:\n            task: the task to be sent\n            fl_ctx: the FL context\n            targets: list of candidate target clients.\n            send_order: how to choose the client to send the task.\n            task_assignment_timeout: in SEQUENTIAL order, this is the wait time for trying a target client, before trying next target.\n\n        \"\"\"\n        pass\n\n    def send_and_wait(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order: SendOrder = SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n        abort_signal: Signal = None,\n    ):\n        \"\"\"This is the blocking version of the 'send' method.\n\n        First, the task is scheduled for send (see the 'send' method);\n        It then waits until the task is completed and returns the task completion status and collected result.\n\n        Args:\n            task: the task to be performed by each client\n            fl_ctx: the FL context for scheduling the task\n            targets: list of clients. If None, all clients.\n            send_order: how to choose the next client\n            task_assignment_timeout: how long to wait for the expected client to get assigned\n            before assigning to next client.\n            abort_signal: the abort signal. If triggered, this method stops waiting and returns to the caller.\n\n        \"\"\"\n        pass\n\n    def relay(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order: SendOrder = SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n        task_result_timeout: int = 0,\n        dynamic_targets: bool = True,\n    ):\n        \"\"\"Schedules a task to be done sequentially by the clients in the targets list. This is a non-blocking call.\n\n        Args:\n            task: the task to be performed by each client\n            fl_ctx: the FL context for scheduling the task\n            targets: list of clients. If None, all clients.\n            send_order: how to choose the next client\n            task_assignment_timeout: how long to wait for the expected client to get assigned\n            before assigning to next client.\n            task_result_timeout: how long to wait for result from the assigned client before giving up.\n            dynamic_targets: whether to dynamically grow the target list. If True, then the target list is\n            expanded dynamically when a new client joins.\n\n        \"\"\"\n        pass\n\n    def relay_and_wait(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order=SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n        task_result_timeout: int = 0,\n        dynamic_targets: bool = True,\n        abort_signal: Signal = None,\n    ):\n        \"\"\"This is the blocking version of 'relay'.\"\"\"\n        pass\n\n    def get_num_standing_tasks(self) -> int:\n        \"\"\"Gets tasks that are currently standing.\n\n        Returns: length of the list of standing tasks\n\n        \"\"\"\n        pass\n\n    def cancel_task(\n        self,\n        task: Task,\n        completion_status: TaskCompletionStatus = TaskCompletionStatus.CANCELLED,\n        fl_ctx: Optional[FLContext] = None,\n    ):\n        \"\"\"Cancels the specified task.\n\n        If the task is standing, the task is cancelled immediately (and removed from job queue) and calls\n        the task_done CB (if specified);\n\n        If the task is not standing, this method has no effect.\n\n        Args:\n            task: the task to be cancelled\n            completion_status: the TaskCompletionStatus of the task\n            fl_ctx: the FL context\n\n        \"\"\"\n        pass\n\n    def cancel_all_tasks(self, completion_status=TaskCompletionStatus.CANCELLED, fl_ctx: Optional[FLContext] = None):\n        \"\"\"Cancels all standing tasks.\n\n        Args:\n            completion_status: the TaskCompletionStatus of the task\n            fl_ctx: the FL context\n        \"\"\"\n        pass\n\n    def abort_task(self, task: Task, fl_ctx: FLContext):\n        \"\"\"Asks all clients to abort the execution of the specified task.\n\n        Args:\n            task: the task to be aborted\n            fl_ctx: the FL context\n\n        \"\"\"\n        pass\n\n    def abort_all_tasks(self, fl_ctx: FLContext):\n        \"\"\"Asks clients to abort the execution of all tasks.\n\n        NOTE: the server should send a notification to all clients, regardless of whether the server\n        has any standing tasks.\n\n        Args:\n            fl_ctx: the FL context\n\n        \"\"\"\n        pass",
  "def __init__(\n        self,\n        name: str,\n        data: Shareable,\n        props: Optional[Dict] = None,\n        timeout: int = 0,\n        before_task_sent_cb=None,\n        after_task_sent_cb=None,\n        result_received_cb=None,\n        task_done_cb=None,\n    ):\n        \"\"\"Init the Task.\n\n        A task is a piece of work that is assigned by the Controller to client workers.\n        Depending on how the task is assigned (broadcast, send, or relay), the task will be performed by one or more clients.\n\n        Args:\n            name (str): name of the task\n            data (Shareable): data of the task\n            props: Any additional properties of the task\n            timeout: How long this task will last. If == 0, the task never time out.\n            before_task_sent_cb: If provided, this callback would be called before controller sends the tasks to clients.\n                It needs to follow the before_task_sent_cb_signature.\n            after_task_sent_cb: If provided, this callback would be called after controller sends the tasks to clients.\n                It needs to follow the after_task_sent_cb_signature.\n            result_received_cb: If provided, this callback would be called when controller receives results from clients.\n                It needs to follow the result_received_cb_signature.\n            task_done_cb: If provided, this callback would be called when task is done.\n                It needs to follow the task_done_cb_signature.\n\n        \"\"\"\n        if not isinstance(name, str):\n            raise TypeError(\"name must be str, but got {}.\".format(type(name)))\n\n        if not isinstance(data, Shareable):\n            raise TypeError(\"data must be an instance of Shareable, but got {}.\".format(type(data)))\n\n        self.name = name  # name of the task\n        self.data = data  # task data to be sent to client(s)\n        self.cb_lock = threading.Lock()\n\n        if props is None:\n            self.props = {}\n        else:\n            if not isinstance(props, dict):\n                raise TypeError(\"props must be None or dict, but got {}.\".format(type(props)))\n            self.props = props\n\n        if not isinstance(timeout, int):\n            raise TypeError(\"timeout must be an int, but got {}.\".format(type(timeout)))\n\n        if timeout < 0:\n            raise ValueError(\"timeout must be >= 0, but got {}.\".format(timeout))\n\n        if before_task_sent_cb is not None and not callable(before_task_sent_cb):\n            raise TypeError(\n                \"before_task_sent must be a callable function, but got {}.\".format(type(before_task_sent_cb))\n            )\n\n        if after_task_sent_cb is not None and not callable(after_task_sent_cb):\n            raise TypeError(\n                \"after_task_sent_cb must be a callable function, but got {}.\".format(type(after_task_sent_cb))\n            )\n\n        if result_received_cb is not None and not callable(result_received_cb):\n            raise TypeError(\"result_received must be a callable function, but got {}.\".format(type(result_received_cb)))\n\n        if task_done_cb is not None and not callable(task_done_cb):\n            raise TypeError(\"task_done must be a callable function, but got {}.\".format(type(task_done_cb)))\n\n        self.timeout = timeout\n        self.before_task_sent_cb = before_task_sent_cb\n        self.after_task_sent_cb = after_task_sent_cb\n        self.result_received_cb = result_received_cb\n        self.task_done_cb = task_done_cb\n\n        self.targets = None\n        self.client_tasks = []  # list of ClientTasks sent\n        self.last_client_task_map = {}  # dict of: client name => last ClientTask of the client\n        self.completion_status = None  # task completion status\n        self.is_standing = False  # whether the task is still standing\n        self.schedule_time = None  # when the task was scheduled\n        self.create_time = time.time()",
  "def set_prop(self, key, value):\n        if key.startswith(\"__\"):\n            raise ValueError(\"Keys start with __ is reserved. Please use other key instead of {}.\".format(key))\n        self.props[key] = value",
  "def get_prop(self, key):\n        if key.startswith(\"__\"):\n            raise ValueError(\"Keys start with __ is reserved. Please use other key instead of {}.\".format(key))\n        return self.props.get(key)",
  "def __init__(self, client: Client, task: Task):\n        \"\"\"Init ClientTask.\n\n        Args:\n            client: the client\n            task: the processing information of this task will be recorded\n        \"\"\"\n        self.client = client\n        self.task = task\n        self.id = str(uuid.uuid4())\n        self.task_send_count = 0  # number of times the task is sent to the client\n        self.task_sent_time = None  # last time the task was sent to the client\n        self.result_received_time = None  # time when the result was received from the client\n        self.result = None  # result submitted by the client, or processed result\n        self.props = {}",
  "def start_controller(self, fl_ctx: FLContext):\n        \"\"\"Starts the controller.\n\n        This method is called at the beginning of the RUN.\n\n        Args:\n            fl_ctx: the FL context. You can use this context to access services provided by the\n            framework. For example, you can get Command Register from it and register your\n            admin command modules.\n\n        \"\"\"\n        pass",
  "def stop_controller(self, fl_ctx: FLContext):\n        \"\"\"Stops the controller.\n\n        This method is called right before the RUN is ended.\n\n        Args:\n            fl_ctx: the FL context. You can use this context to access services provided by the\n            framework. For example, you can get Command Register from it and unregister your\n            admin command modules.\n\n        \"\"\"\n        pass",
  "def process_result_of_unknown_task(\n        self, client: Client, task_name: str, client_task_id: str, result: Shareable, fl_ctx: FLContext\n    ):\n        \"\"\"Process result when no task is found for it.\n\n        This is called when a result submission is received from a client, but no standing\n        task can be found for it (from the task queue)\n\n        This could happen when:\n        - the client's submission is too late - the task is already completed\n        - the Controller lost the task, e.g. the Server is restarted\n\n        Args:\n            client: the client that the result comes from\n            task_name: the name of the task\n            client_task_id: ID of the task\n            result: the result from the client\n            fl_ctx: the FL context that comes with the client's submission\n\n        \"\"\"\n        pass",
  "def broadcast(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        min_responses: int = 0,\n        wait_time_after_min_received: int = 0,\n    ):\n        \"\"\"Schedule to broadcast the task to specified targets.\n\n        This is a non-blocking call.\n\n        The task is standing until one of the following conditions comes true:\n            - if timeout is specified (> 0), and the task has been standing for more than the specified time\n            - the controller has received the specified min_responses results for this task, and all target clients\n              are done.\n            - the controller has received the specified min_responses results for this task, and has waited\n              for wait_time_after_min_received.\n\n        While the task is standing:\n            - Before sending the task to a client, the before_task_sent CB (if specified) is called;\n            - When a result is received from a client, the result_received CB (if specified) is called;\n\n        After the task is done, the task_done CB (if specified) is called:\n            - If result_received CB is specified, the 'result' in the ClientTask of each\n              client is produced by the result_received CB;\n            - Otherwise, the 'result' contains the original result submitted by the clients;\n\n        NOTE: if the targets is None, the actual broadcast target clients will be dynamic, because the clients\n        could join/disconnect at any moment. While the task is standing, any client that joins automatically\n        becomes a target for this broadcast.\n\n        Args:\n            task: the task to be sent\n            fl_ctx: the FL context\n            targets: list of destination clients. None means all clients are determined dynamically;\n            min_responses: the min number of responses expected. If == 0, must get responses from\n              all clients that the task has been sent to;\n            wait_time_after_min_received: how long (secs) to wait after the min_responses is received.\n              If == 0, end the task immediately after the min responses are received;\n\n        \"\"\"\n        pass",
  "def broadcast_and_wait(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        min_responses: int = 0,\n        wait_time_after_min_received: int = 0,\n        abort_signal: Signal = None,\n    ):\n        \"\"\"This is the blocking version of the 'broadcast' method.\n\n        First, the task is scheduled for broadcast (see the broadcast method);\n        It then waits until the task is completed.\n\n        Args:\n            task: the task to be sent\n            fl_ctx: the FL context\n            targets: list of destination clients. None means all clients are determined dynamically.\n            min_responses: the min number of responses expected. If == 0, must get responses from\n              all clients that the task has been sent to;\n            wait_time_after_min_received: how long (secs) to wait after the min_responses is received.\n              If == 0, end the task immediately after the min responses are received;\n            abort_signal: the abort signal. If triggered, this method stops waiting and returns to the caller.\n\n        \"\"\"\n        pass",
  "def broadcast_forever(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n    ):\n        \"\"\"Schedule a broadcast task that never ends until timeout or explicitly cancelled.\n\n        All clients will get the task every time it asks for a new task.\n        This is a non-blocking call.\n\n        NOTE: you can change the content of the task in the before_task_sent function.\n\n        Args:\n            task: the task to be sent\n            fl_ctx: the FL context\n            targets: list of destination clients. None means all clients are determined dynamically.\n\n        \"\"\"\n        pass",
  "def send(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order: SendOrder = SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n    ):\n        \"\"\"Schedule to send the task to a single target client.\n\n        This is a non-blocking call.\n\n        In ANY order, the target client is the first target that asks for task.\n        In SEQUENTIAL order, the controller will try its best to send the task to the first client\n        in the targets list. If can't, it will try the next target, and so on.\n\n        NOTE: if the 'targets' is None, the actual target clients will be dynamic, because the clients\n        could join/disconnect at any moment. While the task is standing, any client that joins automatically\n        becomes a target for this task.\n\n        If the send_order is SEQUENTIAL, the targets must be a non-empty list of client names.\n\n        Args:\n            task: the task to be sent\n            fl_ctx: the FL context\n            targets: list of candidate target clients.\n            send_order: how to choose the client to send the task.\n            task_assignment_timeout: in SEQUENTIAL order, this is the wait time for trying a target client, before trying next target.\n\n        \"\"\"\n        pass",
  "def send_and_wait(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order: SendOrder = SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n        abort_signal: Signal = None,\n    ):\n        \"\"\"This is the blocking version of the 'send' method.\n\n        First, the task is scheduled for send (see the 'send' method);\n        It then waits until the task is completed and returns the task completion status and collected result.\n\n        Args:\n            task: the task to be performed by each client\n            fl_ctx: the FL context for scheduling the task\n            targets: list of clients. If None, all clients.\n            send_order: how to choose the next client\n            task_assignment_timeout: how long to wait for the expected client to get assigned\n            before assigning to next client.\n            abort_signal: the abort signal. If triggered, this method stops waiting and returns to the caller.\n\n        \"\"\"\n        pass",
  "def relay(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order: SendOrder = SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n        task_result_timeout: int = 0,\n        dynamic_targets: bool = True,\n    ):\n        \"\"\"Schedules a task to be done sequentially by the clients in the targets list. This is a non-blocking call.\n\n        Args:\n            task: the task to be performed by each client\n            fl_ctx: the FL context for scheduling the task\n            targets: list of clients. If None, all clients.\n            send_order: how to choose the next client\n            task_assignment_timeout: how long to wait for the expected client to get assigned\n            before assigning to next client.\n            task_result_timeout: how long to wait for result from the assigned client before giving up.\n            dynamic_targets: whether to dynamically grow the target list. If True, then the target list is\n            expanded dynamically when a new client joins.\n\n        \"\"\"\n        pass",
  "def relay_and_wait(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order=SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n        task_result_timeout: int = 0,\n        dynamic_targets: bool = True,\n        abort_signal: Signal = None,\n    ):\n        \"\"\"This is the blocking version of 'relay'.\"\"\"\n        pass",
  "def get_num_standing_tasks(self) -> int:\n        \"\"\"Gets tasks that are currently standing.\n\n        Returns: length of the list of standing tasks\n\n        \"\"\"\n        pass",
  "def cancel_task(\n        self,\n        task: Task,\n        completion_status: TaskCompletionStatus = TaskCompletionStatus.CANCELLED,\n        fl_ctx: Optional[FLContext] = None,\n    ):\n        \"\"\"Cancels the specified task.\n\n        If the task is standing, the task is cancelled immediately (and removed from job queue) and calls\n        the task_done CB (if specified);\n\n        If the task is not standing, this method has no effect.\n\n        Args:\n            task: the task to be cancelled\n            completion_status: the TaskCompletionStatus of the task\n            fl_ctx: the FL context\n\n        \"\"\"\n        pass",
  "def cancel_all_tasks(self, completion_status=TaskCompletionStatus.CANCELLED, fl_ctx: Optional[FLContext] = None):\n        \"\"\"Cancels all standing tasks.\n\n        Args:\n            completion_status: the TaskCompletionStatus of the task\n            fl_ctx: the FL context\n        \"\"\"\n        pass",
  "def abort_task(self, task: Task, fl_ctx: FLContext):\n        \"\"\"Asks all clients to abort the execution of the specified task.\n\n        Args:\n            task: the task to be aborted\n            fl_ctx: the FL context\n\n        \"\"\"\n        pass",
  "def abort_all_tasks(self, fl_ctx: FLContext):\n        \"\"\"Asks clients to abort the execution of all tasks.\n\n        NOTE: the server should send a notification to all clients, regardless of whether the server\n        has any standing tasks.\n\n        Args:\n            fl_ctx: the FL context\n\n        \"\"\"\n        pass",
  "class Signal(object):\n    def __init__(self):\n        \"\"\"Init the Signal.\n\n        Used to signal between and within FL Components.\n        \"\"\"\n        self.value = None\n        self.trigger_time = None\n        self.triggered = False\n\n    def trigger(self, value):\n        \"\"\"Trigger the Signal.\n\n        Args:\n            value: set the value of the signal\n        \"\"\"\n        self.value = value\n        self.trigger_time = time.time()\n        self.triggered = True\n\n    def reset(self, value=None):\n        \"\"\"Reset the Signal.\n\n        Args:\n            value: reset the value of the signal\n        \"\"\"\n        self.value = value\n        self.trigger_time = None\n        self.triggered = False",
  "def __init__(self):\n        \"\"\"Init the Signal.\n\n        Used to signal between and within FL Components.\n        \"\"\"\n        self.value = None\n        self.trigger_time = None\n        self.triggered = False",
  "def trigger(self, value):\n        \"\"\"Trigger the Signal.\n\n        Args:\n            value: set the value of the signal\n        \"\"\"\n        self.value = value\n        self.trigger_time = time.time()\n        self.triggered = True",
  "def reset(self, value=None):\n        \"\"\"Reset the Signal.\n\n        Args:\n            value: reset the value of the signal\n        \"\"\"\n        self.value = value\n        self.trigger_time = None\n        self.triggered = False",
  "class RunStatus(str, Enum):\n\n    SUBMITTED = \"SUBMITTED\"\n    APPROVED = \"APPROVED\"\n    DISPATCHED = \"DISPATCHED\"\n    RUNNING = \"RUNNING\"\n    FINISHED_COMPLETED = \"FINISHED:COMPLETED\"\n    FINISHED_ABORTED = \"FINISHED:ABORTED\"\n    FINISHED_EXECUTION_EXCEPTION = \"FINISHED:EXECUTION_EXCEPTION\"\n    FAILED_TO_RUN = \"FAILED_TO_RUN\"",
  "class JobDataKey(str, Enum):\n    DATA = \"data\"\n    META = \"meta\"\n    JOB_DATA = \"job_data_\"\n    WORKSPACE_DATA = \"workspace_data_\"",
  "class JobMetaKey(str, Enum):\n    JOB_ID = \"job_id\"\n    JOB_NAME = \"name\"\n    JOB_FOLDER_NAME = \"job_folder_name\"\n    STATUS = \"status\"\n    DEPLOY_MAP = \"deploy_map\"\n    RESOURCE_SPEC = \"resource_spec\"\n    CONTENT_LOCATION = \"content_location\"\n    RESULT_LOCATION = \"result_location\"\n    APPROVALS = \"approvals\"\n    MIN_CLIENTS = \"min_clients\"\n    MANDATORY_CLIENTS = \"mandatory_clients\"\n    SUBMIT_TIME = \"submit_time\"\n    SUBMIT_TIME_ISO = \"submit_time_iso\"\n    START_TIME = \"start_time\"\n    DURATION = \"duration\"\n\n    def __repr__(self):\n        return self.value",
  "class Job:\n    def __init__(\n        self,\n        job_id: str,\n        resource_spec: Dict[str, Dict],\n        deploy_map: Dict[str, List[str]],\n        meta,\n        min_sites: int = 1,\n        required_sites: Optional[List[str]] = None,\n    ):\n        \"\"\"Job object containing the job metadata.\n\n        Args:\n            job_id: Job ID\n            resource_spec: Resource specification with information on the resources of each client\n            deploy_map: Deploy map specifying each app and the sites that it should be deployed to\n            meta: full contents of the persisted metadata for the job for persistent storage\n            min_sites (int): minimum number of sites\n            required_sites: A list of required site names\n        \"\"\"\n        self.job_id = job_id\n        self.resource_spec = resource_spec  # resource_requirements should be {site name: resource}\n        self.deploy_map = deploy_map  # should be {app name: a list of sites}\n\n        self.meta = meta\n        self.min_sites = min_sites\n        self.required_sites = required_sites\n        if not self.required_sites:\n            self.required_sites = []\n\n        self.dispatcher_id = None\n        self.dispatch_time = None\n\n        self.submit_time = None\n\n        self.run_record = None  # job id, dispatched time/UUID, finished time, completion code (normal, aborted)\n\n    def get_deployment(self) -> Dict[str, List[str]]:\n        \"\"\"Returns the deployment configuration.\n\n        ::\n\n            \"deploy_map\": {\n                \"hello-numpy-sag-server\": [\n                  \"server\"\n                ],\n                \"hello-numpy-sag-client\": [\n                  \"client1\",\n                  \"client2\"\n                ],\n                \"hello-numpy-sag-client3\": [\n                  \"client3\"\n                ]\n              },\n\n        Returns:\n            Contents of deploy_map as a dictionary of strings of app names with their corresponding sites\n        \"\"\"\n        return self.deploy_map\n\n    def get_application(self, app_name, fl_ctx: FLContext) -> bytes:\n        \"\"\"Get the application content in bytes for the specified participant.\"\"\"\n        # application_name = self.get_application_name(participant)\n        engine = fl_ctx.get_engine()\n        job_def_manager = engine.get_component(SystemComponents.JOB_MANAGER)\n        # # if not isinstance(job_def_manager, JobDefManagerSpec):\n        # #     raise TypeError(f\"job_def_manager must be JobDefManagerSpec type. Got: {type(job_def_manager)}\")\n        return job_def_manager.get_app(self, app_name, fl_ctx)\n\n    def get_application_name(self, participant):\n        \"\"\"Get the application name for the specified participant.\"\"\"\n        for app in self.deploy_map:\n            for site in self.deploy_map[app]:\n                if site == participant:\n                    return app\n        return None\n\n    def get_resource_requirements(self):\n        \"\"\"Returns app resource requirements.\n\n        Returns:\n            A dict of {site_name: resource}\n        \"\"\"\n        return self.resource_spec\n\n    def __eq__(self, other):\n        return self.job_id == other.job_id",
  "def job_from_meta(meta: dict) -> Job:\n    \"\"\"Converts information in meta into a Job object.\n\n    Args:\n        meta: dict of meta information\n\n    Returns:\n        A Job object.\n    \"\"\"\n    job = Job(\n        job_id=meta.get(JobMetaKey.JOB_ID, \"\"),\n        resource_spec=meta.get(JobMetaKey.RESOURCE_SPEC, {}),\n        deploy_map=meta.get(JobMetaKey.DEPLOY_MAP, {}),\n        meta=meta,\n        min_sites=meta.get(JobMetaKey.MIN_CLIENTS, 1),\n        required_sites=meta.get(JobMetaKey.MANDATORY_CLIENTS, []),\n    )\n    return job",
  "def __repr__(self):\n        return self.value",
  "def __init__(\n        self,\n        job_id: str,\n        resource_spec: Dict[str, Dict],\n        deploy_map: Dict[str, List[str]],\n        meta,\n        min_sites: int = 1,\n        required_sites: Optional[List[str]] = None,\n    ):\n        \"\"\"Job object containing the job metadata.\n\n        Args:\n            job_id: Job ID\n            resource_spec: Resource specification with information on the resources of each client\n            deploy_map: Deploy map specifying each app and the sites that it should be deployed to\n            meta: full contents of the persisted metadata for the job for persistent storage\n            min_sites (int): minimum number of sites\n            required_sites: A list of required site names\n        \"\"\"\n        self.job_id = job_id\n        self.resource_spec = resource_spec  # resource_requirements should be {site name: resource}\n        self.deploy_map = deploy_map  # should be {app name: a list of sites}\n\n        self.meta = meta\n        self.min_sites = min_sites\n        self.required_sites = required_sites\n        if not self.required_sites:\n            self.required_sites = []\n\n        self.dispatcher_id = None\n        self.dispatch_time = None\n\n        self.submit_time = None\n\n        self.run_record = None",
  "def get_deployment(self) -> Dict[str, List[str]]:\n        \"\"\"Returns the deployment configuration.\n\n        ::\n\n            \"deploy_map\": {\n                \"hello-numpy-sag-server\": [\n                  \"server\"\n                ],\n                \"hello-numpy-sag-client\": [\n                  \"client1\",\n                  \"client2\"\n                ],\n                \"hello-numpy-sag-client3\": [\n                  \"client3\"\n                ]\n              },\n\n        Returns:\n            Contents of deploy_map as a dictionary of strings of app names with their corresponding sites\n        \"\"\"\n        return self.deploy_map",
  "def get_application(self, app_name, fl_ctx: FLContext) -> bytes:\n        \"\"\"Get the application content in bytes for the specified participant.\"\"\"\n        # application_name = self.get_application_name(participant)\n        engine = fl_ctx.get_engine()\n        job_def_manager = engine.get_component(SystemComponents.JOB_MANAGER)\n        # # if not isinstance(job_def_manager, JobDefManagerSpec):\n        # #     raise TypeError(f\"job_def_manager must be JobDefManagerSpec type. Got: {type(job_def_manager)}\")\n        return job_def_manager.get_app(self, app_name, fl_ctx)",
  "def get_application_name(self, participant):\n        \"\"\"Get the application name for the specified participant.\"\"\"\n        for app in self.deploy_map:\n            for site in self.deploy_map[app]:\n                if site == participant:\n                    return app\n        return None",
  "def get_resource_requirements(self):\n        \"\"\"Returns app resource requirements.\n\n        Returns:\n            A dict of {site_name: resource}\n        \"\"\"\n        return self.resource_spec",
  "def __eq__(self, other):\n        return self.job_id == other.job_id",
  "class DataKind(object):\n    WEIGHTS = \"WEIGHTS\"\n    WEIGHT_DIFF = \"WEIGHT_DIFF\"\n    METRICS = \"METRICS\"\n    MODEL = \"MODEL\"\n    ANALYTIC = \"ANALYTIC\"\n    COLLECTION = \"COLLECTION\"",
  "class MetaKey(object):\n\n    NUM_STEPS_CURRENT_ROUND = \"NUM_STEPS_CURRENT_ROUND\"\n    MODEL_OWNER = \"MODEL_OWNER\"\n    PROCESSED_ALGORITHM = \"PROCESSED_ALGORITHM\"\n    PROCESSED_KEYS = \"PROCESSED_KEYS\"\n    INITIAL_METRICS = \"initial_metrics\"",
  "class DXO(object):\n    def __init__(self, data_kind: str, data: dict, meta: dict = None):\n        \"\"\"Init the DXO.\n\n        The Data Exchange Object standardizes the data passed between communicating parties.\n\n        Args:\n            data_kind: kind of data\n            data: clear-text data\n            meta: None or dict for any additional properties\n        \"\"\"\n        if data is None:\n            data = {}\n        if meta is None:\n            meta = {}\n\n        self.data_kind = data_kind\n        self.data = data\n        self.meta = meta\n\n        err = self.validate()\n        if err:\n            raise ValueError(\"invalid DXO: {}\".format(err))\n\n    def get_meta_prop(self, key: str, default=None):\n        if self.meta and isinstance(self.meta, dict):\n            return self.meta.get(key, default)\n        return default\n\n    def set_meta_prop(self, key: str, value):\n        if self.meta is None:\n            self.meta = {}\n        self.meta[key] = value\n\n    def remove_meta_props(self, keys: List[str]):\n        if self.meta and keys:\n            for k in keys:\n                self.meta.pop(k, None)\n\n    def get_meta_props(self):\n        return self.meta\n\n    def update_meta_props(self, meta):\n        self.meta.update(copy.deepcopy(meta))\n\n    def _encode(self) -> dict:\n        return {_KEY_KIND: self.data_kind, _KEY_DATA: self.data, _KEY_META: self.meta}\n\n    def update_shareable(self, s: Shareable) -> Shareable:\n        s.set_header(key=ReservedHeaderKey.CONTENT_TYPE, value=\"DXO\")\n\n        s[_KEY_DXO] = self._encode()\n        return s\n\n    def to_shareable(self) -> Shareable:\n        \"\"\"Convert the DXO object into Shareable.\n\n        Returns:\n            Shareable object.\n\n        \"\"\"\n        s = Shareable()\n        return self.update_shareable(s)\n\n    def to_bytes(self) -> bytes:\n        \"\"\"Serialize the DXO object into bytes.\n\n        Returns:\n            object serialized in bytes.\n\n        \"\"\"\n        return pickle.dumps(self)\n\n    def validate(self) -> str:\n        if self.data is None:\n            return \"missing data\"\n\n        if not isinstance(self.data, dict):\n            return \"invalid data: expect dict but got {}\".format(type(self.data))\n\n        if self.meta is not None and not isinstance(self.meta, dict):\n            return \"invalid props: expect dict but got {}\".format(type(self.meta))\n\n        return \"\"",
  "def from_shareable(s: Shareable) -> DXO:\n    \"\"\"Convert Shareable into a DXO object.\n\n    Args:\n        s: Shareable object\n\n    Returns:\n        DXO object.\n\n    \"\"\"\n    content_type = s.get_header(ReservedHeaderKey.CONTENT_TYPE)\n    if not content_type or content_type != \"DXO\":\n        raise ValueError(\"the shareable is not a valid DXO - expect content_type DXO but got {}\".format(content_type))\n\n    encoded = s.get(_KEY_DXO, None)\n    if not encoded:\n        raise ValueError(\"the shareable is not a valid DXO - missing content\")\n\n    if not isinstance(encoded, dict):\n        raise ValueError(\n            \"the shareable is not a valid DXO - should be encoded as dict but got {}\".format(type(encoded))\n        )\n\n    k = encoded.get(_KEY_KIND, None)\n    d = encoded.get(_KEY_DATA, None)\n    m = encoded.get(_KEY_META, None)\n\n    return DXO(data_kind=k, data=d, meta=m)",
  "def from_bytes(data: bytes) -> DXO:\n    \"\"\"Convert the data bytes into Model object.\n\n    Args:\n        data: a bytes object\n\n    Returns:\n        an object loaded by pickle from data\n\n    \"\"\"\n    x = pickle.loads(data)\n    if isinstance(x, DXO):\n        return x\n    else:\n        raise ValueError(\"Data bytes are from type {} and do not represent a valid DXO instance.\".format(type(x)))",
  "def __init__(self, data_kind: str, data: dict, meta: dict = None):\n        \"\"\"Init the DXO.\n\n        The Data Exchange Object standardizes the data passed between communicating parties.\n\n        Args:\n            data_kind: kind of data\n            data: clear-text data\n            meta: None or dict for any additional properties\n        \"\"\"\n        if data is None:\n            data = {}\n        if meta is None:\n            meta = {}\n\n        self.data_kind = data_kind\n        self.data = data\n        self.meta = meta\n\n        err = self.validate()\n        if err:\n            raise ValueError(\"invalid DXO: {}\".format(err))",
  "def get_meta_prop(self, key: str, default=None):\n        if self.meta and isinstance(self.meta, dict):\n            return self.meta.get(key, default)\n        return default",
  "def set_meta_prop(self, key: str, value):\n        if self.meta is None:\n            self.meta = {}\n        self.meta[key] = value",
  "def remove_meta_props(self, keys: List[str]):\n        if self.meta and keys:\n            for k in keys:\n                self.meta.pop(k, None)",
  "def get_meta_props(self):\n        return self.meta",
  "def update_meta_props(self, meta):\n        self.meta.update(copy.deepcopy(meta))",
  "def _encode(self) -> dict:\n        return {_KEY_KIND: self.data_kind, _KEY_DATA: self.data, _KEY_META: self.meta}",
  "def update_shareable(self, s: Shareable) -> Shareable:\n        s.set_header(key=ReservedHeaderKey.CONTENT_TYPE, value=\"DXO\")\n\n        s[_KEY_DXO] = self._encode()\n        return s",
  "def to_shareable(self) -> Shareable:\n        \"\"\"Convert the DXO object into Shareable.\n\n        Returns:\n            Shareable object.\n\n        \"\"\"\n        s = Shareable()\n        return self.update_shareable(s)",
  "def to_bytes(self) -> bytes:\n        \"\"\"Serialize the DXO object into bytes.\n\n        Returns:\n            object serialized in bytes.\n\n        \"\"\"\n        return pickle.dumps(self)",
  "def validate(self) -> str:\n        if self.data is None:\n            return \"missing data\"\n\n        if not isinstance(self.data, dict):\n            return \"invalid data: expect dict but got {}\".format(type(self.data))\n\n        if self.meta is not None and not isinstance(self.meta, dict):\n            return \"invalid props: expect dict but got {}\".format(type(self.meta))\n\n        return \"\"",
  "class MessageSendStatus(enum.Enum):\n\n    OK = \"ok\"  # message sent and response received\n    TIMEOUT = \"timeout\"  # message sent but no response received\n    FAILURE = \"failure\"  # failed to send message\n    REPLY_ERROR = \"reply_error\"",
  "def aux_request_handle_func_signature(topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n    \"\"\"This is the signature of the message_handle_func.\n\n    The message_handle_func is a callback function that is registered to handle an aux request of a specific topic.\n    Any implementation of a message_handle_func must follow this signature.\n\n    Example from the client runner:\n        engine.register_aux_message_handler(topic=ReservedTopic.END_RUN, message_handle_func=self._handle_end_run)\n\n    Args:\n        topic: topic of the message to be handled\n        request: the message data to be handled\n        fl_ctx: FL context\n\n    Returns: a Shareable response to the requester\n\n    \"\"\"\n    pass",
  "class RunSnapshot:\n    \"\"\"RunSnapshot keeps a snapshot of all the FLComponent states.\n\n    The format is:\n            { component_id: component_state_dict }\n    \"\"\"\n\n    def __init__(self, job_id: str):\n        super().__init__()\n        self.component_states = {}\n        self.completed = False\n        self.job_id = job_id\n\n    def get_component_snapshot(self, component_id: str) -> dict:\n        \"\"\"Get a state snapshot of a particular FL component.\n\n        Args:\n            component_id: Component ID\n\n        Returns:\n            A component state dict.\n        \"\"\"\n        return self.component_states.get(component_id)\n\n    def set_component_snapshot(self, component_id: str, component_state: dict):\n        \"\"\"Set the snapshot of a particular FL component.\n\n        Args:\n            component_id: Component ID\n            component_state: component state dict\n        \"\"\"\n        self.component_states[component_id] = component_state\n\n    def get_snapshot(self) -> dict:\n        return self.component_states",
  "class FLSnapshot:\n    \"\"\"FLSnapshot keeps a snapshot of all the current running FL application RunSnapshots.\n\n    The format is:\n            { job_id: RunSnapshot }\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.run_snapshots = {}\n\n    def add_snapshot(self, job_id: str, snapshot: RunSnapshot):\n        \"\"\"Add the RunSnapshot for job_id to the FLSnapshot.\n\n        Args:\n            job_id: the job_id\n            snapshot: snapshot of the Run\n\n        Returns:\n\n        \"\"\"\n        self.run_snapshots[job_id] = snapshot\n\n    def get_snapshot(self, job_id: str) -> RunSnapshot:\n        \"\"\"Get the RunSnapshot for job_id to the FLSnapshot.\n\n        Args:\n            job_id: the job_id\n\n        Returns: Snapshot of the Run\n\n        \"\"\"\n        return self.run_snapshots.get(job_id)\n\n    def remove_snapshot(self, job_id: str):\n        \"\"\"Remove the RunSnapshot of job_id from the FLSnapshot.\n\n        Args:\n            job_id: the job_id\n\n        Returns:\n\n        \"\"\"\n        if job_id in self.run_snapshots.keys():\n            self.run_snapshots.pop(job_id)",
  "def __init__(self, job_id: str):\n        super().__init__()\n        self.component_states = {}\n        self.completed = False\n        self.job_id = job_id",
  "def get_component_snapshot(self, component_id: str) -> dict:\n        \"\"\"Get a state snapshot of a particular FL component.\n\n        Args:\n            component_id: Component ID\n\n        Returns:\n            A component state dict.\n        \"\"\"\n        return self.component_states.get(component_id)",
  "def set_component_snapshot(self, component_id: str, component_state: dict):\n        \"\"\"Set the snapshot of a particular FL component.\n\n        Args:\n            component_id: Component ID\n            component_state: component state dict\n        \"\"\"\n        self.component_states[component_id] = component_state",
  "def get_snapshot(self) -> dict:\n        return self.component_states",
  "def __init__(self):\n        super().__init__()\n        self.run_snapshots = {}",
  "def add_snapshot(self, job_id: str, snapshot: RunSnapshot):\n        \"\"\"Add the RunSnapshot for job_id to the FLSnapshot.\n\n        Args:\n            job_id: the job_id\n            snapshot: snapshot of the Run\n\n        Returns:\n\n        \"\"\"\n        self.run_snapshots[job_id] = snapshot",
  "def get_snapshot(self, job_id: str) -> RunSnapshot:\n        \"\"\"Get the RunSnapshot for job_id to the FLSnapshot.\n\n        Args:\n            job_id: the job_id\n\n        Returns: Snapshot of the Run\n\n        \"\"\"\n        return self.run_snapshots.get(job_id)",
  "def remove_snapshot(self, job_id: str):\n        \"\"\"Remove the RunSnapshot of job_id from the FLSnapshot.\n\n        Args:\n            job_id: the job_id\n\n        Returns:\n\n        \"\"\"\n        if job_id in self.run_snapshots.keys():\n            self.run_snapshots.pop(job_id)",
  "class Workspace:\n    def __init__(self, root_dir: str, name: str, config_folder: str):\n        \"\"\"Define a workspace.\n\n        NOTE::\n\n            Workspace folder structure:\n\n                Workspace ROOT\n                    startup (optional)\n                        provisioned content\n                    run_1\n                        config (required)\n                            configurations\n                        custom (optional)\n                            custom python code\n                        other_folder (app defined)\n\n        Args:\n            root_dir: root directory of the workspace\n            name: name of the workspace\n            config_folder: where to find required config inside an app\n        \"\"\"\n        self.root_dir = root_dir\n        self.name = name\n        self.config_folder = config_folder\n\n    def get_startup_kit_dir(self) -> str:\n        return os.path.join(self.root_dir, \"startup\")\n\n    def get_root_dir(self) -> str:\n        return self.root_dir\n\n    def get_run_dir(self, job_id: str) -> str:\n        return os.path.join(self.root_dir, WorkspaceConstants.WORKSPACE_PREFIX + str(job_id))\n\n    def get_app_dir(self, job_id: str) -> str:\n        return os.path.join(self.get_run_dir(job_id), WorkspaceConstants.APP_PREFIX + self.name)\n\n    def get_app_config_dir(self, job_id: str) -> str:\n        return os.path.join(self.get_app_dir(job_id), self.config_folder)\n\n    def get_app_custom_dir(self, job_id: str) -> str:\n        return os.path.join(self.get_app_dir(job_id), \"custom\")",
  "def __init__(self, root_dir: str, name: str, config_folder: str):\n        \"\"\"Define a workspace.\n\n        NOTE::\n\n            Workspace folder structure:\n\n                Workspace ROOT\n                    startup (optional)\n                        provisioned content\n                    run_1\n                        config (required)\n                            configurations\n                        custom (optional)\n                            custom python code\n                        other_folder (app defined)\n\n        Args:\n            root_dir: root directory of the workspace\n            name: name of the workspace\n            config_folder: where to find required config inside an app\n        \"\"\"\n        self.root_dir = root_dir\n        self.name = name\n        self.config_folder = config_folder",
  "def get_startup_kit_dir(self) -> str:\n        return os.path.join(self.root_dir, \"startup\")",
  "def get_root_dir(self) -> str:\n        return self.root_dir",
  "def get_run_dir(self, job_id: str) -> str:\n        return os.path.join(self.root_dir, WorkspaceConstants.WORKSPACE_PREFIX + str(job_id))",
  "def get_app_dir(self, job_id: str) -> str:\n        return os.path.join(self.get_run_dir(job_id), WorkspaceConstants.APP_PREFIX + self.name)",
  "def get_app_config_dir(self, job_id: str) -> str:\n        return os.path.join(self.get_app_dir(job_id), self.config_folder)",
  "def get_app_custom_dir(self, job_id: str) -> str:\n        return os.path.join(self.get_app_dir(job_id), \"custom\")",
  "class Client:\n    def __init__(self, name, token) -> None:\n        \"\"\"Init Client.\n\n        Represents a client, and is managed by the client manager.\n        The token is a uuid used for authorization.\n\n        Args:\n            name: client name\n            token: client token\n        \"\"\"\n        self.name = name\n        self.token = token\n        self.last_connect_time = time.time()\n        self.props = {}\n\n    def set_token(self, token):\n        self.token = token\n\n    def get_token(self):\n        return self.token\n\n    def set_prop(self, name, value):\n        self.props[name] = value\n\n    def get_prop(self, name, default=None):\n        return self.props.get(name, default)",
  "def __init__(self, name, token) -> None:\n        \"\"\"Init Client.\n\n        Represents a client, and is managed by the client manager.\n        The token is a uuid used for authorization.\n\n        Args:\n            name: client name\n            token: client token\n        \"\"\"\n        self.name = name\n        self.token = token\n        self.last_connect_time = time.time()\n        self.props = {}",
  "def set_token(self, token):\n        self.token = token",
  "def get_token(self):\n        return self.token",
  "def set_prop(self, name, value):\n        self.props[name] = value",
  "def get_prop(self, name, default=None):\n        return self.props.get(name, default)",
  "class StorageException(Exception):\n    \"\"\"Base class for Storage exceptions.\"\"\"\n\n    pass",
  "class StorageSpec(ABC):\n    \"\"\"Functional spec of object storage.\n\n    An object is identified by a URI (unique resource identifier).\n    Each object contains:\n        - content (data)\n        - meta info that describes the control info of the object.\n\n    \"\"\"\n\n    @abstractmethod\n    def create_object(self, uri: str, data: bytes, meta: dict, overwrite_existing: bool):\n        \"\"\"Creates an object.\n\n        Examples of URI:\n\n            /state/engine/...\n            /runs/approved/covid_exam.3\n            /runs/pending/spleen_seg.1\n\n        Args:\n            uri: URI of the object\n            data: content of the object\n            meta: meta info of the object\n            overwrite_existing: whether to overwrite the object if already exists\n\n        Raises StorageException when:\n            - invalid args\n            - object already exists and overwrite_existing is False\n            - error creating the object\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_meta(self, uri: str, meta: dict, replace: bool):\n        \"\"\"Updates the meta info of the specified object.\n\n        Args:\n            uri: URI of the object\n            meta: value of new meta info\n            replace: whether to replace the current meta completely or partial update\n\n        Raises StorageException when:\n            - invalid args\n            - no such object\n            - error updating the object\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_data(self, uri: str, data: bytes):\n        \"\"\"Updates the data of the specified object.\n\n        Args:\n            uri: URI of the object\n            data: value of new data\n\n        Raises StorageException when:\n            - invalid args\n            - no such object\n            - error updating the object\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_objects(self, path: str) -> List[str]:\n        \"\"\"Lists all objects in the specified path.\n\n        Args:\n            path: the path to the objects\n\n        Returns:\n            list of URIs of objects\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_meta(self, uri: str) -> dict:\n        \"\"\"Gets user defined meta info of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            meta info of the object.\n            if object does not exist, return empty dict {}\n\n        Raises StorageException when:\n          - invalid args\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_data(self, uri: str) -> bytes:\n        \"\"\"Gets data of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            data of the object.\n            if object does not exist, return None\n\n        Raises StorageException when:\n            - invalid args\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_detail(self, uri: str) -> Tuple[dict, bytes]:\n        \"\"\"Gets both data and meta of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            meta info and data of the object.\n\n        Raises StorageException when:\n            - invalid args\n            - no such object\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_object(self, uri: str):\n        \"\"\"Deletes specified object.\n\n        Args:\n            uri: URI of the object\n\n        \"\"\"\n        pass",
  "def create_object(self, uri: str, data: bytes, meta: dict, overwrite_existing: bool):\n        \"\"\"Creates an object.\n\n        Examples of URI:\n\n            /state/engine/...\n            /runs/approved/covid_exam.3\n            /runs/pending/spleen_seg.1\n\n        Args:\n            uri: URI of the object\n            data: content of the object\n            meta: meta info of the object\n            overwrite_existing: whether to overwrite the object if already exists\n\n        Raises StorageException when:\n            - invalid args\n            - object already exists and overwrite_existing is False\n            - error creating the object\n\n        \"\"\"\n        pass",
  "def update_meta(self, uri: str, meta: dict, replace: bool):\n        \"\"\"Updates the meta info of the specified object.\n\n        Args:\n            uri: URI of the object\n            meta: value of new meta info\n            replace: whether to replace the current meta completely or partial update\n\n        Raises StorageException when:\n            - invalid args\n            - no such object\n            - error updating the object\n\n        \"\"\"\n        pass",
  "def update_data(self, uri: str, data: bytes):\n        \"\"\"Updates the data of the specified object.\n\n        Args:\n            uri: URI of the object\n            data: value of new data\n\n        Raises StorageException when:\n            - invalid args\n            - no such object\n            - error updating the object\n\n        \"\"\"\n        pass",
  "def list_objects(self, path: str) -> List[str]:\n        \"\"\"Lists all objects in the specified path.\n\n        Args:\n            path: the path to the objects\n\n        Returns:\n            list of URIs of objects\n\n        \"\"\"\n        pass",
  "def get_meta(self, uri: str) -> dict:\n        \"\"\"Gets user defined meta info of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            meta info of the object.\n            if object does not exist, return empty dict {}\n\n        Raises StorageException when:\n          - invalid args\n\n        \"\"\"\n        pass",
  "def get_data(self, uri: str) -> bytes:\n        \"\"\"Gets data of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            data of the object.\n            if object does not exist, return None\n\n        Raises StorageException when:\n            - invalid args\n\n        \"\"\"\n        pass",
  "def get_detail(self, uri: str) -> Tuple[dict, bytes]:\n        \"\"\"Gets both data and meta of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            meta info and data of the object.\n\n        Raises StorageException when:\n            - invalid args\n            - no such object\n\n        \"\"\"\n        pass",
  "def delete_object(self, uri: str):\n        \"\"\"Deletes specified object.\n\n        Args:\n            uri: URI of the object\n\n        \"\"\"\n        pass",
  "class FLContext(object):\n    MASK_STICKY = 1 << 0\n    MASK_PRIVATE = 1 << 1\n\n    @classmethod\n    def _is_sticky(cls, mask) -> bool:\n        return mask & cls.MASK_STICKY > 0\n\n    @classmethod\n    def _is_private(cls, mask) -> bool:\n        return mask & cls.MASK_PRIVATE > 0\n\n    @classmethod\n    def _matching_private(cls, mask, private) -> bool:\n        return (mask & cls.MASK_PRIVATE > 0) == private\n\n    @classmethod\n    def _to_string(cls, mask) -> str:\n        if cls._is_private(mask):\n            result = \"private:\"\n        else:\n            result = \"public:\"\n\n        if cls._is_sticky(mask):\n            return result + \"sticky\"\n        else:\n            return result + \"non-sticky\"\n\n    def __init__(self):\n        \"\"\"Init the FLContext.\n\n        The FLContext is used to passed data between FL Components.\n        It can be thought of as a dictionary that stores key/value pairs called props (properties).\n\n        Visibility: private props are only visible to local components,\n                    public props are also visible to remote components\n\n        Stickiness: sticky props become available in all future FL Contexts,\n                    non-sticky props will only be available in the current FL Context\n\n        \"\"\"\n        self.model = None\n        self.props = {}\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    def public_key_exists(self, key):\n        return key in self.props and not self._is_private(self.props[key][\"mask\"])\n\n    def get_all_public_props(self):\n        return {k: v[\"value\"] for k, v in self.props.items() if not self._is_private(v[\"mask\"])}\n\n    def set_prop(self, key: str, value, private=True, sticky=True):\n        if not isinstance(key, str):\n            raise ValueError(\"prop key must be str, but got {}\".format(type(key)))\n\n        with _update_lock:\n            mask = 0\n            if private:\n                mask += FLContext.MASK_PRIVATE\n            if sticky:\n                mask += FLContext.MASK_STICKY\n            if key not in self.props or key in self.props and self.props[key][\"mask\"] == mask:\n                self.props[key] = {\"value\": value, \"mask\": mask}\n            else:\n                existing_mask = self.props[key][\"mask\"]\n                self.logger.warning(\n                    f\"property {key} already exists with attributes \"\n                    f\"{self._to_string(existing_mask)}, cannot change to {self._to_string(mask)}\"\n                )\n                return False\n        return True\n\n    def get_prop(self, key, default=None):\n        with _update_lock:\n            if key in self.props:\n                return self.props.get(key)[\"value\"]\n            else:\n                return default\n\n    def get_prop_detail(self, key):\n        with _update_lock:\n            if key in self.props:\n                prop = self.props.get(key)\n                mask = prop[\"mask\"]\n                return {\"value\": prop[\"value\"], \"private\": self._is_private(mask), \"sticky\": self._is_sticky(mask)}\n            else:\n                return None\n\n    def remove_prop(self, key: str):\n        if not isinstance(key, str):\n            return\n\n        if key.startswith(\"__\"):\n            # do not allow removal of reserved props!\n            return\n\n        with _update_lock:\n            self.props.pop(key, None)\n\n    def __str__(self):\n        raw_list = [f'{k}: {type(v[\"value\"])}' for k, v in self.props.items()]\n        return \" \".join(raw_list)\n\n    # some convenience methods\n    def get_engine(self):\n        return self.get_prop(key=ReservedKey.ENGINE, default=None)\n\n    def get_job_id(self):\n        return self.get_prop(key=ReservedKey.RUN_NUM, default=None)\n\n    def get_identity_name(self):\n        return self.get_prop(key=ReservedKey.IDENTITY_NAME, default=\"\")\n\n    def get_run_abort_signal(self):\n        return self.get_prop(key=ReservedKey.RUN_ABORT_SIGNAL, default=None)\n\n    def set_peer_context(self, ctx):\n        self.set_prop(key=ReservedKey.PEER_CTX, value=ctx, private=True, sticky=False)\n\n    def get_peer_context(self):\n        return self.get_prop(key=ReservedKey.PEER_CTX, default=None)\n\n    def set_public_props(self, metadata: dict):\n        # remove all public props\n        self.props = {k: v for k, v in self.props.items() if self._is_private(v[\"mask\"] or self._is_sticky(v[\"mask\"]))}\n\n        for key, value in metadata.items():\n            self.set_prop(key, value, private=False, sticky=True)\n\n    def clone_sticky(self):\n        new_fl_ctx = FLContext()\n        for k, v in self.props.items():\n            if self._is_sticky(v[\"mask\"]):\n                new_fl_ctx.props[k] = {\"value\": v[\"value\"], \"mask\": v[\"mask\"]}\n        return new_fl_ctx\n\n    def sync_sticky(self):\n        ctx_manager = self.get_prop(key=ReservedKey.MANAGER, default=None)\n        if not ctx_manager:\n            raise ValueError(\"FLContextManager does not exist.\")\n\n        ctx_manager.finalize_context(self)\n\n    # implement Context Manager protocol\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        mgr = self.get_prop(key=ReservedKey.MANAGER)\n        # if not mgr:\n        #     raise ValueError(\"This FLContext is not managed. Please use FLContextManager to create FLContext\")\n        if mgr:\n            mgr.finalize_context(self)",
  "class FLContextManager(object):\n    \"\"\"FLContextManager manages the creation and updates of FLContext objects for a run.\n\n    NOTE: The engine may create a new FLContextManager object for each RUN!\n\n    \"\"\"\n\n    def __init__(self, engine, identity_name: str, job_id: str, public_stickers, private_stickers):\n        \"\"\"Init the FLContextManager.\n\n        Args:\n            engine: the engine that created this FLContextManager object\n            identity_name (str): identity name\n            job_id: the job id\n            public_stickers: public sticky properties that are copied into or copied from\n            private_stickers: private sticky properties that are copied into or copied from\n        \"\"\"\n        self.engine = engine\n        self.identity_name = identity_name\n        self.job_id = job_id\n        self._update_lock = threading.Lock()\n\n        self.public_stickers = {}\n        self.private_stickers = {}\n\n        if public_stickers and isinstance(public_stickers, dict):\n            self.public_stickers.update(public_stickers)\n\n        if private_stickers and isinstance(private_stickers, dict):\n            self.private_stickers.update(private_stickers)\n\n    def new_context(self) -> FLContext:\n        \"\"\"Create a new FLContext object.\n\n        Sticky properties are copied from the stickers into the new context.\n\n        Returns: a FLContext object\n\n        \"\"\"\n        ctx = FLContext()\n        ctx.set_prop(key=ReservedKey.MANAGER, value=self, private=True, sticky=False)\n\n        # set permanent props\n        ctx.set_prop(key=ReservedKey.ENGINE, value=self.engine, private=True)\n        ctx.set_prop(key=ReservedKey.RUN_NUM, value=self.job_id, private=False)\n\n        if self.identity_name:\n            ctx.set_prop(key=ReservedKey.IDENTITY_NAME, value=self.identity_name, private=False)\n\n        with self._update_lock:\n            for k, v in self.public_stickers.items():\n                ctx.set_prop(key=k, value=v, sticky=True, private=False)\n\n            for k, v in self.private_stickers.items():\n                ctx.set_prop(key=k, value=v, sticky=True, private=True)\n\n        return ctx\n\n    def finalize_context(self, ctx: FLContext):\n        \"\"\"Finalize the context by copying/updating sticky props into stickers.\n\n        Args:\n            ctx: the context to be finalized\n\n        \"\"\"\n        with self._update_lock:\n            for k, v in ctx.props.items():\n                if ctx._is_sticky(v[\"mask\"]):\n                    if ctx._is_private(v[\"mask\"]):\n                        self.private_stickers[k] = v[\"value\"]\n                    else:\n                        self.public_stickers[k] = v[\"value\"]",
  "def _is_sticky(cls, mask) -> bool:\n        return mask & cls.MASK_STICKY > 0",
  "def _is_private(cls, mask) -> bool:\n        return mask & cls.MASK_PRIVATE > 0",
  "def _matching_private(cls, mask, private) -> bool:\n        return (mask & cls.MASK_PRIVATE > 0) == private",
  "def _to_string(cls, mask) -> str:\n        if cls._is_private(mask):\n            result = \"private:\"\n        else:\n            result = \"public:\"\n\n        if cls._is_sticky(mask):\n            return result + \"sticky\"\n        else:\n            return result + \"non-sticky\"",
  "def __init__(self):\n        \"\"\"Init the FLContext.\n\n        The FLContext is used to passed data between FL Components.\n        It can be thought of as a dictionary that stores key/value pairs called props (properties).\n\n        Visibility: private props are only visible to local components,\n                    public props are also visible to remote components\n\n        Stickiness: sticky props become available in all future FL Contexts,\n                    non-sticky props will only be available in the current FL Context\n\n        \"\"\"\n        self.model = None\n        self.props = {}\n        self.logger = logging.getLogger(self.__class__.__name__)",
  "def public_key_exists(self, key):\n        return key in self.props and not self._is_private(self.props[key][\"mask\"])",
  "def get_all_public_props(self):\n        return {k: v[\"value\"] for k, v in self.props.items() if not self._is_private(v[\"mask\"])}",
  "def set_prop(self, key: str, value, private=True, sticky=True):\n        if not isinstance(key, str):\n            raise ValueError(\"prop key must be str, but got {}\".format(type(key)))\n\n        with _update_lock:\n            mask = 0\n            if private:\n                mask += FLContext.MASK_PRIVATE\n            if sticky:\n                mask += FLContext.MASK_STICKY\n            if key not in self.props or key in self.props and self.props[key][\"mask\"] == mask:\n                self.props[key] = {\"value\": value, \"mask\": mask}\n            else:\n                existing_mask = self.props[key][\"mask\"]\n                self.logger.warning(\n                    f\"property {key} already exists with attributes \"\n                    f\"{self._to_string(existing_mask)}, cannot change to {self._to_string(mask)}\"\n                )\n                return False\n        return True",
  "def get_prop(self, key, default=None):\n        with _update_lock:\n            if key in self.props:\n                return self.props.get(key)[\"value\"]\n            else:\n                return default",
  "def get_prop_detail(self, key):\n        with _update_lock:\n            if key in self.props:\n                prop = self.props.get(key)\n                mask = prop[\"mask\"]\n                return {\"value\": prop[\"value\"], \"private\": self._is_private(mask), \"sticky\": self._is_sticky(mask)}\n            else:\n                return None",
  "def remove_prop(self, key: str):\n        if not isinstance(key, str):\n            return\n\n        if key.startswith(\"__\"):\n            # do not allow removal of reserved props!\n            return\n\n        with _update_lock:\n            self.props.pop(key, None)",
  "def __str__(self):\n        raw_list = [f'{k}: {type(v[\"value\"])}' for k, v in self.props.items()]\n        return \" \".join(raw_list)",
  "def get_engine(self):\n        return self.get_prop(key=ReservedKey.ENGINE, default=None)",
  "def get_job_id(self):\n        return self.get_prop(key=ReservedKey.RUN_NUM, default=None)",
  "def get_identity_name(self):\n        return self.get_prop(key=ReservedKey.IDENTITY_NAME, default=\"\")",
  "def get_run_abort_signal(self):\n        return self.get_prop(key=ReservedKey.RUN_ABORT_SIGNAL, default=None)",
  "def set_peer_context(self, ctx):\n        self.set_prop(key=ReservedKey.PEER_CTX, value=ctx, private=True, sticky=False)",
  "def get_peer_context(self):\n        return self.get_prop(key=ReservedKey.PEER_CTX, default=None)",
  "def set_public_props(self, metadata: dict):\n        # remove all public props\n        self.props = {k: v for k, v in self.props.items() if self._is_private(v[\"mask\"] or self._is_sticky(v[\"mask\"]))}\n\n        for key, value in metadata.items():\n            self.set_prop(key, value, private=False, sticky=True)",
  "def clone_sticky(self):\n        new_fl_ctx = FLContext()\n        for k, v in self.props.items():\n            if self._is_sticky(v[\"mask\"]):\n                new_fl_ctx.props[k] = {\"value\": v[\"value\"], \"mask\": v[\"mask\"]}\n        return new_fl_ctx",
  "def sync_sticky(self):\n        ctx_manager = self.get_prop(key=ReservedKey.MANAGER, default=None)\n        if not ctx_manager:\n            raise ValueError(\"FLContextManager does not exist.\")\n\n        ctx_manager.finalize_context(self)",
  "def __enter__(self):\n        return self",
  "def __exit__(self, exc_type, exc_val, exc_tb):\n        mgr = self.get_prop(key=ReservedKey.MANAGER)\n        # if not mgr:\n        #     raise ValueError(\"This FLContext is not managed. Please use FLContextManager to create FLContext\")\n        if mgr:\n            mgr.finalize_context(self)",
  "def __init__(self, engine, identity_name: str, job_id: str, public_stickers, private_stickers):\n        \"\"\"Init the FLContextManager.\n\n        Args:\n            engine: the engine that created this FLContextManager object\n            identity_name (str): identity name\n            job_id: the job id\n            public_stickers: public sticky properties that are copied into or copied from\n            private_stickers: private sticky properties that are copied into or copied from\n        \"\"\"\n        self.engine = engine\n        self.identity_name = identity_name\n        self.job_id = job_id\n        self._update_lock = threading.Lock()\n\n        self.public_stickers = {}\n        self.private_stickers = {}\n\n        if public_stickers and isinstance(public_stickers, dict):\n            self.public_stickers.update(public_stickers)\n\n        if private_stickers and isinstance(private_stickers, dict):\n            self.private_stickers.update(private_stickers)",
  "def new_context(self) -> FLContext:\n        \"\"\"Create a new FLContext object.\n\n        Sticky properties are copied from the stickers into the new context.\n\n        Returns: a FLContext object\n\n        \"\"\"\n        ctx = FLContext()\n        ctx.set_prop(key=ReservedKey.MANAGER, value=self, private=True, sticky=False)\n\n        # set permanent props\n        ctx.set_prop(key=ReservedKey.ENGINE, value=self.engine, private=True)\n        ctx.set_prop(key=ReservedKey.RUN_NUM, value=self.job_id, private=False)\n\n        if self.identity_name:\n            ctx.set_prop(key=ReservedKey.IDENTITY_NAME, value=self.identity_name, private=False)\n\n        with self._update_lock:\n            for k, v in self.public_stickers.items():\n                ctx.set_prop(key=k, value=v, sticky=True, private=False)\n\n            for k, v in self.private_stickers.items():\n                ctx.set_prop(key=k, value=v, sticky=True, private=True)\n\n        return ctx",
  "def finalize_context(self, ctx: FLContext):\n        \"\"\"Finalize the context by copying/updating sticky props into stickers.\n\n        Args:\n            ctx: the context to be finalized\n\n        \"\"\"\n        with self._update_lock:\n            for k, v in ctx.props.items():\n                if ctx._is_sticky(v[\"mask\"]):\n                    if ctx._is_private(v[\"mask\"]):\n                        self.private_stickers[k] = v[\"value\"]\n                    else:\n                        self.public_stickers[k] = v[\"value\"]",
  "class AnalyticsDataType(Enum):\n    SCALARS = \"SCALARS\"\n    SCALAR = \"SCALAR\"\n    IMAGE = \"IMAGE\"\n    TEXT = \"TEXT\"\n    LOG_RECORD = \"LOG_RECORD\"",
  "class AnalyticsData:\n    def __init__(self, tag: str, value, data_type: AnalyticsDataType, kwargs: Optional[dict] = None):\n        \"\"\"This class defines AnalyticsData format.\n\n        It is a wrapper to provide to/from DXO conversion.\n\n        Args:\n            tag (str): tag name\n            value: value\n            data_type (AnalyticDataType): type of the analytic data.\n            kwargs (optional, dict): additional arguments to be passed.\n        \"\"\"\n        if not isinstance(tag, str):\n            raise TypeError(\"expect tag to be an instance of str, but got {}.\".format(type(tag)))\n        if not isinstance(data_type, AnalyticsDataType):\n            raise TypeError(\n                \"expect data_type to be an instance of AnalyticsDataType, but got {}.\".format(type(data_type))\n            )\n        if kwargs and not isinstance(kwargs, dict):\n            raise TypeError(\"expect kwargs to be an instance of dict, but got {}.\".format(type(kwargs)))\n        if data_type == AnalyticsDataType.SCALAR and not isinstance(value, float):\n            raise TypeError(\"expect value to be an instance of float, but got {}.\".format(type(value)))\n        elif data_type == AnalyticsDataType.SCALARS and not isinstance(value, dict):\n            raise TypeError(\"expect value to be an instance of dict, but got {}.\".format(type(value)))\n        elif data_type == AnalyticsDataType.TEXT and not isinstance(value, str):\n            raise TypeError(\"expect value to be an instance of str, but got {}.\".format(type(value)))\n        self.tag = tag\n        self.value = value\n        self.data_type = data_type\n        self.kwargs = kwargs\n\n    def to_dxo(self):\n        \"\"\"Converts the AnalyticsData to DXO object.\n\n        Returns:\n            DXO object\n        \"\"\"\n        dxo = DXO(data_kind=DataKind.ANALYTIC, data={self.tag: self.value})\n        dxo.set_meta_prop(_DATA_TYPE_KEY, self.data_type)\n        dxo.set_meta_prop(_KWARGS_KEY, self.kwargs)\n        return dxo\n\n    @classmethod\n    def from_dxo(cls, dxo: DXO):\n        \"\"\"Generates the AnalyticsData from DXO object.\n\n        Args:\n            dxo (DXO): The DXO object to convert.\n\n        Returns:\n            AnalyticsData object\n        \"\"\"\n        if not isinstance(dxo, DXO):\n            raise TypeError(\"expect dxo to be an instance of DXO, but got {}.\".format(type(dxo)))\n\n        if len(dxo.data) != 1:\n            raise ValueError(\n                \"dxo does not have the correct format for AnalyticsData; expected dxo.data to be length 1, but got {}\".format(\n                    len(dxo.data)\n                )\n            )\n\n        tag, value = list(dxo.data.items())[0]\n\n        data_type = dxo.get_meta_prop(_DATA_TYPE_KEY)\n        kwargs = dxo.get_meta_prop(_KWARGS_KEY)\n\n        return cls(tag, value, data_type, kwargs)",
  "def __init__(self, tag: str, value, data_type: AnalyticsDataType, kwargs: Optional[dict] = None):\n        \"\"\"This class defines AnalyticsData format.\n\n        It is a wrapper to provide to/from DXO conversion.\n\n        Args:\n            tag (str): tag name\n            value: value\n            data_type (AnalyticDataType): type of the analytic data.\n            kwargs (optional, dict): additional arguments to be passed.\n        \"\"\"\n        if not isinstance(tag, str):\n            raise TypeError(\"expect tag to be an instance of str, but got {}.\".format(type(tag)))\n        if not isinstance(data_type, AnalyticsDataType):\n            raise TypeError(\n                \"expect data_type to be an instance of AnalyticsDataType, but got {}.\".format(type(data_type))\n            )\n        if kwargs and not isinstance(kwargs, dict):\n            raise TypeError(\"expect kwargs to be an instance of dict, but got {}.\".format(type(kwargs)))\n        if data_type == AnalyticsDataType.SCALAR and not isinstance(value, float):\n            raise TypeError(\"expect value to be an instance of float, but got {}.\".format(type(value)))\n        elif data_type == AnalyticsDataType.SCALARS and not isinstance(value, dict):\n            raise TypeError(\"expect value to be an instance of dict, but got {}.\".format(type(value)))\n        elif data_type == AnalyticsDataType.TEXT and not isinstance(value, str):\n            raise TypeError(\"expect value to be an instance of str, but got {}.\".format(type(value)))\n        self.tag = tag\n        self.value = value\n        self.data_type = data_type\n        self.kwargs = kwargs",
  "def to_dxo(self):\n        \"\"\"Converts the AnalyticsData to DXO object.\n\n        Returns:\n            DXO object\n        \"\"\"\n        dxo = DXO(data_kind=DataKind.ANALYTIC, data={self.tag: self.value})\n        dxo.set_meta_prop(_DATA_TYPE_KEY, self.data_type)\n        dxo.set_meta_prop(_KWARGS_KEY, self.kwargs)\n        return dxo",
  "def from_dxo(cls, dxo: DXO):\n        \"\"\"Generates the AnalyticsData from DXO object.\n\n        Args:\n            dxo (DXO): The DXO object to convert.\n\n        Returns:\n            AnalyticsData object\n        \"\"\"\n        if not isinstance(dxo, DXO):\n            raise TypeError(\"expect dxo to be an instance of DXO, but got {}.\".format(type(dxo)))\n\n        if len(dxo.data) != 1:\n            raise ValueError(\n                \"dxo does not have the correct format for AnalyticsData; expected dxo.data to be length 1, but got {}\".format(\n                    len(dxo.data)\n                )\n            )\n\n        tag, value = list(dxo.data.items())[0]\n\n        data_type = dxo.get_meta_prop(_DATA_TYPE_KEY)\n        kwargs = dxo.get_meta_prop(_KWARGS_KEY)\n\n        return cls(tag, value, data_type, kwargs)",
  "class Executor(FLComponent, ABC):\n    @abstractmethod\n    def execute(self, task_name: str, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        pass",
  "def execute(self, task_name: str, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        pass",
  "class ResourceConsumerSpec(ABC):\n    @abstractmethod\n    def consume(self, resources: dict):\n        pass",
  "class ResourceManagerSpec(ABC):\n    @abstractmethod\n    def check_resources(self, resource_requirement: dict, fl_ctx: FLContext) -> (bool, Optional[str]):\n        \"\"\"Checks whether the specified resource requirement can be satisfied.\n\n        Args:\n            resource_requirement: a dict that specifies resource requirement\n            fl_ctx: the FLContext\n\n        Returns:\n            A tuple of (check_result, token).\n\n            check_result is a bool indicates whether there is enough resources;\n            token (optional) is for resource reservation / cancellation for this check request.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def cancel_resources(self, resource_requirement: dict, token: str, fl_ctx: FLContext):\n        \"\"\"Cancels reserved resources if any.\n\n        Args:\n            resource_requirement: a dict that specifies resource requirement\n            token: a resource reservation token returned by check_resources\n            fl_ctx: the FLContext\n\n        Note:\n            If check_resource didn't return a token, then don't need to call this method\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def allocate_resources(self, resource_requirement: dict, token: str, fl_ctx: FLContext) -> dict:\n        \"\"\"Allocates resources.\n\n        Note:\n            resource requirements and resources may be different things.\n\n        Args:\n            resource_requirement: a dict that specifies resource requirement\n            token: a resource reservation token returned by check_resources\n            fl_ctx: the FLContext\n\n        Returns:\n            A dict of allocated resources\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def free_resources(self, resources: dict, token: str, fl_ctx: FLContext):\n        \"\"\"Frees resources.\n\n        Args:\n            resources: resources to be freed\n            token: a resource reservation token returned by check_resources\n            fl_ctx: the FLContext\n        \"\"\"\n        pass",
  "def consume(self, resources: dict):\n        pass",
  "def check_resources(self, resource_requirement: dict, fl_ctx: FLContext) -> (bool, Optional[str]):\n        \"\"\"Checks whether the specified resource requirement can be satisfied.\n\n        Args:\n            resource_requirement: a dict that specifies resource requirement\n            fl_ctx: the FLContext\n\n        Returns:\n            A tuple of (check_result, token).\n\n            check_result is a bool indicates whether there is enough resources;\n            token (optional) is for resource reservation / cancellation for this check request.\n        \"\"\"\n        pass",
  "def cancel_resources(self, resource_requirement: dict, token: str, fl_ctx: FLContext):\n        \"\"\"Cancels reserved resources if any.\n\n        Args:\n            resource_requirement: a dict that specifies resource requirement\n            token: a resource reservation token returned by check_resources\n            fl_ctx: the FLContext\n\n        Note:\n            If check_resource didn't return a token, then don't need to call this method\n        \"\"\"\n        pass",
  "def allocate_resources(self, resource_requirement: dict, token: str, fl_ctx: FLContext) -> dict:\n        \"\"\"Allocates resources.\n\n        Note:\n            resource requirements and resources may be different things.\n\n        Args:\n            resource_requirement: a dict that specifies resource requirement\n            token: a resource reservation token returned by check_resources\n            fl_ctx: the FLContext\n\n        Returns:\n            A dict of allocated resources\n        \"\"\"\n        pass",
  "def free_resources(self, resources: dict, token: str, fl_ctx: FLContext):\n        \"\"\"Frees resources.\n\n        Args:\n            resources: resources to be freed\n            token: a resource reservation token returned by check_resources\n            fl_ctx: the FLContext\n        \"\"\"\n        pass",
  "class JobDefManagerSpec(FLComponent, ABC):\n    \"\"\"Job Definition Management API.\"\"\"\n\n    @abstractmethod\n    def create(self, meta: dict, uploaded_content: bytes, fl_ctx: FLContext) -> Dict[str, Any]:\n        \"\"\"Create a new job permanently.\n\n        The caller must have validated the content already and created initial meta. Receives bytes of uploaded folder,\n        uploading to permanent store, create unique Job ID (jid) and return meta.\n\n        Args:\n            meta: caller-provided meta info\n            uploaded_content: data of the job definition\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A dict containing meta info. Additional meta info are added, especially\n            a unique Job ID (jid) which has been created.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_job(self, jid: str, fl_ctx: FLContext) -> Job:\n        \"\"\"Gets the Job object through the job ID.\n\n        Args:\n            jid (str): Job ID\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A Job object\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_app(self, job: Job, app_name: str, fl_ctx: FLContext) -> bytes:\n        \"\"\"Get the contents of the specified app in bytes.\n\n        Args:\n            job: Job object\n            app_name: name of the app to get\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            Content of the specified app in bytes\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_apps(self, job: Job, fl_ctx: FLContext) -> Dict[str, bytes]:\n        \"\"\"Get the all the apps of a Job.\n\n        Args:\n            job: Job object\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A dictionary of app names with the content of the corresponding app encoded in bytes\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_content(self, jid: str, fl_ctx: FLContext) -> Optional[bytes]:\n        \"\"\"Gets the entire uploaded content for a Job.\n\n        Args:\n            jid (str): Job ID\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            Uploaded content of the job in bytes\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_job_data(self, jid: str, fl_ctx: FLContext) -> dict:\n        \"\"\"Gets the entire uploaded content and workspace for a job.\n\n        Args:\n            jid (str): Job ID\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            a dict to hold the job data and workspace.\n            Format: {\n                        JobDataKey.JOB_DATA.value: stored_data,\n                        JobDataKey.WORKSPACE_DATA: workspace_data\n                    }\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update_meta(self, jid: str, meta, fl_ctx: FLContext):\n        \"\"\"Update the meta of an existing Job.\n\n        Args:\n            jid (str): Job ID\n            meta: dictionary of metadata for the job\n            fl_ctx (FLContext): FLContext information\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def set_status(self, jid: str, status: RunStatus, fl_ctx: FLContext):\n        \"\"\"Set status of an existing Job.\n\n        Args:\n            jid (str): Job ID\n            status (RunStatus): status to set\n            fl_ctx (FLContext): FLContext information\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_jobs(self, fl_ctx: FLContext) -> List[Job]:\n        \"\"\"Gets all Jobs in the system.\n\n        Args:\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A list of all jobs\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_jobs_by_status(self, run_status: RunStatus, fl_ctx: FLContext) -> List[Job]:\n        \"\"\"Gets Jobs of a specified status.\n\n        Args:\n            run_status (RunStatus): status to filter for\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A list of Jobs of the specified status\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_jobs_waiting_for_review(self, reviewer_name: str, fl_ctx: FLContext) -> List[Job]:\n        \"\"\"Gets Jobs waiting for review for the specified user.\n\n        Args:\n            reviewer_name (str): reviewer name\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A list of Jobs waiting for review for the specified user.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def set_approval(\n        self, jid: str, reviewer_name: str, approved: bool, note: str, fl_ctx: FLContext\n    ) -> Dict[str, Any]:\n        \"\"\"Sets the approval for the specified user for a certain Job.\n\n        Args:\n            jid (str): job id\n            reviewer_name (str): reviewer name\n            approved (bool): whether job is approved\n            note (str): any note message\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A dictionary of Job metadata.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete(self, jid: str, fl_ctx: FLContext):\n        \"\"\"Deletes the specified Job.\n\n        Args:\n            jid (str): Job ID\n            fl_ctx (FLContext): FLContext information\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def save_workspace(self, jid: str, data: bytes, fl_ctx: FLContext):\n        \"\"\"Save the job workspace to the job storage.\n\n        Args:\n            jid (str): Job ID\n            data: Job workspace data\n            fl_ctx (FLContext): FLContext information\n\n        \"\"\"\n        pass",
  "def create(self, meta: dict, uploaded_content: bytes, fl_ctx: FLContext) -> Dict[str, Any]:\n        \"\"\"Create a new job permanently.\n\n        The caller must have validated the content already and created initial meta. Receives bytes of uploaded folder,\n        uploading to permanent store, create unique Job ID (jid) and return meta.\n\n        Args:\n            meta: caller-provided meta info\n            uploaded_content: data of the job definition\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A dict containing meta info. Additional meta info are added, especially\n            a unique Job ID (jid) which has been created.\n        \"\"\"\n        pass",
  "def get_job(self, jid: str, fl_ctx: FLContext) -> Job:\n        \"\"\"Gets the Job object through the job ID.\n\n        Args:\n            jid (str): Job ID\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A Job object\n        \"\"\"\n        pass",
  "def get_app(self, job: Job, app_name: str, fl_ctx: FLContext) -> bytes:\n        \"\"\"Get the contents of the specified app in bytes.\n\n        Args:\n            job: Job object\n            app_name: name of the app to get\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            Content of the specified app in bytes\n        \"\"\"\n        pass",
  "def get_apps(self, job: Job, fl_ctx: FLContext) -> Dict[str, bytes]:\n        \"\"\"Get the all the apps of a Job.\n\n        Args:\n            job: Job object\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A dictionary of app names with the content of the corresponding app encoded in bytes\n        \"\"\"\n        pass",
  "def get_content(self, jid: str, fl_ctx: FLContext) -> Optional[bytes]:\n        \"\"\"Gets the entire uploaded content for a Job.\n\n        Args:\n            jid (str): Job ID\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            Uploaded content of the job in bytes\n        \"\"\"\n        pass",
  "def get_job_data(self, jid: str, fl_ctx: FLContext) -> dict:\n        \"\"\"Gets the entire uploaded content and workspace for a job.\n\n        Args:\n            jid (str): Job ID\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            a dict to hold the job data and workspace.\n            Format: {\n                        JobDataKey.JOB_DATA.value: stored_data,\n                        JobDataKey.WORKSPACE_DATA: workspace_data\n                    }\n        \"\"\"\n        pass",
  "def update_meta(self, jid: str, meta, fl_ctx: FLContext):\n        \"\"\"Update the meta of an existing Job.\n\n        Args:\n            jid (str): Job ID\n            meta: dictionary of metadata for the job\n            fl_ctx (FLContext): FLContext information\n\n        \"\"\"\n        pass",
  "def set_status(self, jid: str, status: RunStatus, fl_ctx: FLContext):\n        \"\"\"Set status of an existing Job.\n\n        Args:\n            jid (str): Job ID\n            status (RunStatus): status to set\n            fl_ctx (FLContext): FLContext information\n\n        \"\"\"\n        pass",
  "def get_all_jobs(self, fl_ctx: FLContext) -> List[Job]:\n        \"\"\"Gets all Jobs in the system.\n\n        Args:\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A list of all jobs\n        \"\"\"\n        pass",
  "def get_jobs_by_status(self, run_status: RunStatus, fl_ctx: FLContext) -> List[Job]:\n        \"\"\"Gets Jobs of a specified status.\n\n        Args:\n            run_status (RunStatus): status to filter for\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A list of Jobs of the specified status\n        \"\"\"\n        pass",
  "def get_jobs_waiting_for_review(self, reviewer_name: str, fl_ctx: FLContext) -> List[Job]:\n        \"\"\"Gets Jobs waiting for review for the specified user.\n\n        Args:\n            reviewer_name (str): reviewer name\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A list of Jobs waiting for review for the specified user.\n        \"\"\"\n        pass",
  "def set_approval(\n        self, jid: str, reviewer_name: str, approved: bool, note: str, fl_ctx: FLContext\n    ) -> Dict[str, Any]:\n        \"\"\"Sets the approval for the specified user for a certain Job.\n\n        Args:\n            jid (str): job id\n            reviewer_name (str): reviewer name\n            approved (bool): whether job is approved\n            note (str): any note message\n            fl_ctx (FLContext): FLContext information\n\n        Returns:\n            A dictionary of Job metadata.\n        \"\"\"\n        pass",
  "def delete(self, jid: str, fl_ctx: FLContext):\n        \"\"\"Deletes the specified Job.\n\n        Args:\n            jid (str): Job ID\n            fl_ctx (FLContext): FLContext information\n\n        \"\"\"\n        pass",
  "def save_workspace(self, jid: str, data: bytes, fl_ctx: FLContext):\n        \"\"\"Save the job workspace to the job storage.\n\n        Args:\n            jid (str): Job ID\n            data: Job workspace data\n            fl_ctx (FLContext): FLContext information\n\n        \"\"\"\n        pass",
  "class EventType(object):\n    \"\"\"Built-in system events.\"\"\"\n\n    SYSTEM_START = \"_system_start\"\n    SYSTEM_END = \"_system_end\"\n    ABOUT_TO_START_RUN = \"_about_to_start_run\"\n    START_RUN = \"_start_run\"\n    ABOUT_TO_END_RUN = \"_about_to_end_run\"\n    END_RUN = \"_end_run\"\n    START_WORKFLOW = \"_start_workflow\"\n    END_WORKFLOW = \"_end_workflow\"\n    ABORT_TASK = \"_abort_task\"\n    FATAL_SYSTEM_ERROR = \"_fatal_system_error\"\n    FATAL_TASK_ERROR = \"_fatal_task_error\"\n    JOB_DEPLOYED = \"_job_deployed\"\n    JOB_STARTED = \"_job_started\"\n    JOB_COMPLETED = \"_job_completed\"\n    JOB_ABORTED = \"_job_aborted\"\n    JOB_CANCELLED = \"_job_cancelled\"\n\n    BEFORE_PULL_TASK = \"_before_pull_task\"\n    AFTER_PULL_TASK = \"_after_pull_task\"\n    BEFORE_PROCESS_SUBMISSION = \"_before_process_submission\"\n    AFTER_PROCESS_SUBMISSION = \"_after_process_submission\"\n\n    BEFORE_TASK_DATA_FILTER = \"_before_task_data_filter\"\n    AFTER_TASK_DATA_FILTER = \"_after_task_data_filter\"\n    BEFORE_TASK_RESULT_FILTER = \"_before_task_result_filter\"\n    AFTER_TASK_RESULT_FILTER = \"_after_task_result_filter\"\n    BEFORE_TASK_EXECUTION = \"_before_task_execution\"\n    AFTER_TASK_EXECUTION = \"_after_task_execution\"\n    BEFORE_SEND_TASK_RESULT = \"_before_send_task_result\"\n    AFTER_SEND_TASK_RESULT = \"_after_send_task_result\"\n\n    CRITICAL_LOG_AVAILABLE = \"_critical_log_available\"\n    ERROR_LOG_AVAILABLE = \"_error_log_available\"\n    EXCEPTION_LOG_AVAILABLE = \"_exception_log_available\"\n    WARNING_LOG_AVAILABLE = \"_warning_log_available\"\n    INFO_LOG_AVAILABLE = \"_info_log_available\"\n    DEBUG_LOG_AVAILABLE = \"_debug_log_available\"",
  "class StatePersistor(ABC):\n    @abstractmethod\n    def save(self, snapshot: RunSnapshot) -> str:\n        \"\"\"Saves the snapshot of the FL state to storage.\n\n        Args:\n            snapshot: RunSnapshot object\n\n        Returns:\n            Storage location.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def retrieve(self) -> FLSnapshot:\n        \"\"\"Loads the persisted FL components snapshot from the persisted location.\n\n        Returns:\n            An FLSnapshot\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def retrieve_run(self, job_id: str) -> RunSnapshot:\n        \"\"\"Loads the persisted RunSnapshot of a job_id from the persisted location.\n\n        Args:\n            job_id: job_id\n\n        Returns:\n            A RunSnapshot of the job_id\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete(self):\n        \"\"\"Deletes the FL component snapshot.\"\"\"\n        pass\n\n    @abstractmethod\n    def delete_run(self, job_id: str):\n        \"\"\"Deletes the RunSnapshot of a job_id\"\"\"\n        pass",
  "def save(self, snapshot: RunSnapshot) -> str:\n        \"\"\"Saves the snapshot of the FL state to storage.\n\n        Args:\n            snapshot: RunSnapshot object\n\n        Returns:\n            Storage location.\n        \"\"\"\n        pass",
  "def retrieve(self) -> FLSnapshot:\n        \"\"\"Loads the persisted FL components snapshot from the persisted location.\n\n        Returns:\n            An FLSnapshot\n        \"\"\"\n        pass",
  "def retrieve_run(self, job_id: str) -> RunSnapshot:\n        \"\"\"Loads the persisted RunSnapshot of a job_id from the persisted location.\n\n        Args:\n            job_id: job_id\n\n        Returns:\n            A RunSnapshot of the job_id\n        \"\"\"\n        pass",
  "def delete(self):\n        \"\"\"Deletes the FL component snapshot.\"\"\"\n        pass",
  "def delete_run(self, job_id: str):\n        \"\"\"Deletes the RunSnapshot of a job_id\"\"\"\n        pass",
  "class Responder(FLComponent, ABC):\n    def __init__(self):\n        \"\"\"Init the Responder.\n\n        Base class for responding to clients. Controller is a subclass of Responder.\n        \"\"\"\n        FLComponent.__init__(self)\n\n    @abstractmethod\n    def process_task_request(self, client: Client, fl_ctx: FLContext) -> Tuple[str, str, Shareable]:\n        \"\"\"Called by the Engine when a task request is received from a client.\n\n        Args:\n            client: the Client that the task request is from\n            fl_ctx: the FLContext\n\n        Returns: task name, task id, and task data\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def handle_exception(self, task_id: str, fl_ctx: FLContext):\n        \"\"\"Called after process_task_request returns, but exception occurs before task is sent out.\"\"\"\n        pass\n\n    @abstractmethod\n    def process_submission(self, client: Client, task_name: str, task_id: str, result: Shareable, fl_ctx: FLContext):\n        \"\"\"Called by the Engine to process the submitted result from a client.\n\n        Args:\n            client: the Client that the submitted result is from\n            task_name: the name of the task\n            task_id: the id of the task\n            result: the Shareable result from the Client\n            fl_ctx: the FLContext\n\n        \"\"\"\n        pass\n\n    def initialize_run(self, fl_ctx: FLContext):\n        \"\"\"Called when a new RUN is about to start.\n\n        Args:\n            fl_ctx: FL context. It must contain 'job_id' that is to be initialized\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def control_flow(self, abort_signal: Signal, fl_ctx: FLContext):\n        \"\"\"This is the control logic for the RUN.\n\n        NOTE: this is running in a separate thread, and its life is the duration of the RUN.\n\n        Args:\n            fl_ctx: the FL context\n            abort_signal: the abort signal. If triggered, this method stops waiting and returns to the caller.\n\n        \"\"\"\n        pass\n\n    def finalize_run(self, fl_ctx: FLContext):\n        \"\"\"Called when a new RUN is finished.\n\n        Args:\n            fl_ctx: the FL context\n\n        \"\"\"\n        pass",
  "def __init__(self):\n        \"\"\"Init the Responder.\n\n        Base class for responding to clients. Controller is a subclass of Responder.\n        \"\"\"\n        FLComponent.__init__(self)",
  "def process_task_request(self, client: Client, fl_ctx: FLContext) -> Tuple[str, str, Shareable]:\n        \"\"\"Called by the Engine when a task request is received from a client.\n\n        Args:\n            client: the Client that the task request is from\n            fl_ctx: the FLContext\n\n        Returns: task name, task id, and task data\n\n        \"\"\"\n        pass",
  "def handle_exception(self, task_id: str, fl_ctx: FLContext):\n        \"\"\"Called after process_task_request returns, but exception occurs before task is sent out.\"\"\"\n        pass",
  "def process_submission(self, client: Client, task_name: str, task_id: str, result: Shareable, fl_ctx: FLContext):\n        \"\"\"Called by the Engine to process the submitted result from a client.\n\n        Args:\n            client: the Client that the submitted result is from\n            task_name: the name of the task\n            task_id: the id of the task\n            result: the Shareable result from the Client\n            fl_ctx: the FLContext\n\n        \"\"\"\n        pass",
  "def initialize_run(self, fl_ctx: FLContext):\n        \"\"\"Called when a new RUN is about to start.\n\n        Args:\n            fl_ctx: FL context. It must contain 'job_id' that is to be initialized\n\n        \"\"\"\n        pass",
  "def control_flow(self, abort_signal: Signal, fl_ctx: FLContext):\n        \"\"\"This is the control logic for the RUN.\n\n        NOTE: this is running in a separate thread, and its life is the duration of the RUN.\n\n        Args:\n            fl_ctx: the FL context\n            abort_signal: the abort signal. If triggered, this method stops waiting and returns to the caller.\n\n        \"\"\"\n        pass",
  "def finalize_run(self, fl_ctx: FLContext):\n        \"\"\"Called when a new RUN is finished.\n\n        Args:\n            fl_ctx: the FL context\n\n        \"\"\"\n        pass",
  "class TaskAssignment(object):\n    def __init__(self, name: str, task_id: str, data: Shareable):\n        \"\"\"Init TaskAssignment.\n\n        Keeps track of information about the assignment of a task, including the time\n        that it was created after being fetched by the Client Run Manager.\n\n        Args:\n            name: task name\n            task_id: task id\n            data: the Shareable data for the task assignment\n        \"\"\"\n        self.name = name\n        self.task_id = task_id\n        self.data = data\n        self.receive_time = time.time()",
  "class ClientEngineSpec(ABC):\n    @abstractmethod\n    def fire_event(self, event_type: str, fl_ctx: FLContext):\n        pass\n\n    @abstractmethod\n    def get_task_assignment(self, fl_ctx: FLContext) -> TaskAssignment:\n        pass\n\n    @abstractmethod\n    def new_context(self) -> FLContext:\n        # the engine must use FLContextManager to create a new context!\n        pass\n\n    @abstractmethod\n    def send_task_result(self, result: Shareable, fl_ctx: FLContext) -> bool:\n        pass\n\n    @abstractmethod\n    def get_workspace(self) -> Workspace:\n        pass\n\n    @abstractmethod\n    def get_component(self, component_id: str) -> object:\n        pass\n\n    @abstractmethod\n    def get_all_components(self) -> dict:\n        pass\n\n    def get_widget(self, widget_id: str) -> Widget:\n        pass",
  "def __init__(self, name: str, task_id: str, data: Shareable):\n        \"\"\"Init TaskAssignment.\n\n        Keeps track of information about the assignment of a task, including the time\n        that it was created after being fetched by the Client Run Manager.\n\n        Args:\n            name: task name\n            task_id: task id\n            data: the Shareable data for the task assignment\n        \"\"\"\n        self.name = name\n        self.task_id = task_id\n        self.data = data\n        self.receive_time = time.time()",
  "def fire_event(self, event_type: str, fl_ctx: FLContext):\n        pass",
  "def get_task_assignment(self, fl_ctx: FLContext) -> TaskAssignment:\n        pass",
  "def new_context(self) -> FLContext:\n        # the engine must use FLContextManager to create a new context!\n        pass",
  "def send_task_result(self, result: Shareable, fl_ctx: FLContext) -> bool:\n        pass",
  "def get_workspace(self) -> Workspace:\n        pass",
  "def get_component(self, component_id: str) -> object:\n        pass",
  "def get_all_components(self) -> dict:\n        pass",
  "def get_widget(self, widget_id: str) -> Widget:\n        pass",
  "class DispatchInfo:\n    \"\"\"Information needed for dispatch\"\"\"\n\n    def __init__(self, app_name: str, resource_requirements: dict, token: Optional[str]):\n        self.app_name = app_name\n        self.resource_requirements = resource_requirements\n        self.token = token\n\n    def __eq__(self, other):\n        return (\n            self.app_name == other.app_name\n            and self.resource_requirements == other.resource_requirements\n            and self.token == other.token\n        )\n\n    def __repr__(self):\n        return f\"{self.__class__.__name__}: app_name: {self.app_name}, resource_requirements: {self.resource_requirements}, token: {self.token}\"",
  "class JobSchedulerSpec(ABC):\n    @abstractmethod\n    def schedule_job(\n        self, job_candidates: List[Job], fl_ctx: FLContext\n    ) -> (Optional[Job], Optional[Dict[str, DispatchInfo]]):\n        \"\"\"Try to schedule a Job.\n\n        Args:\n            job_candidates: The candidate to choose from.\n            fl_ctx: FLContext.\n\n        Returns:\n            A tuple of (job, sites_dispatch_info), if there is a Job that satisfy the criteria of the scheduler.\n            sites_dispatch_info is a dict of {site name: DispatchInfo}.\n            Otherwise, return (None, None).\n        \"\"\"\n        pass",
  "def __init__(self, app_name: str, resource_requirements: dict, token: Optional[str]):\n        self.app_name = app_name\n        self.resource_requirements = resource_requirements\n        self.token = token",
  "def __eq__(self, other):\n        return (\n            self.app_name == other.app_name\n            and self.resource_requirements == other.resource_requirements\n            and self.token == other.token\n        )",
  "def __repr__(self):\n        return f\"{self.__class__.__name__}: app_name: {self.app_name}, resource_requirements: {self.resource_requirements}, token: {self.token}\"",
  "def schedule_job(\n        self, job_candidates: List[Job], fl_ctx: FLContext\n    ) -> (Optional[Job], Optional[Dict[str, DispatchInfo]]):\n        \"\"\"Try to schedule a Job.\n\n        Args:\n            job_candidates: The candidate to choose from.\n            fl_ctx: FLContext.\n\n        Returns:\n            A tuple of (job, sites_dispatch_info), if there is a Job that satisfy the criteria of the scheduler.\n            sites_dispatch_info is a dict of {site name: DispatchInfo}.\n            Otherwise, return (None, None).\n        \"\"\"\n        pass",
  "class SP:\n    name: str = \"\"\n    fl_port: str = \"\"\n    admin_port: str = \"\"\n    service_session_id: str = \"\"\n    primary: bool = False\n    props: dict = field(default_factory=dict)",
  "class OverseerAgent(ABC):\n    def initialize(self, fl_ctx: FLContext):\n        pass\n\n    def set_secure_context(self, ca_path: str, cert_path: str = \"\", prv_key_path: str = \"\"):\n        pass\n\n    def start(self, update_callback=None, conditional_cb=False):\n        pass\n\n    def pause(self):\n        pass\n\n    def resume(self):\n        pass\n\n    def end(self):\n        pass\n\n    def get_primary_sp(self) -> SP:\n        \"\"\"Return current primary service provider.\n\n        If primary sp not available, such as not reported by SD, connection to SD not established yet\n        the name and ports will be empty strings.\n        \"\"\"\n        pass\n\n    def promote_sp(self, sp_end_point, headers=None):\n        pass\n\n    def add_payload(self, payload: Dict[str, Any]):\n        pass\n\n    def get_overseer_status(self) -> Dict[str, Any]:\n        \"\"\"\n\n        Returns:\n            Dict[str, Any]: [description]\n        \"\"\"\n        pass",
  "def initialize(self, fl_ctx: FLContext):\n        pass",
  "def set_secure_context(self, ca_path: str, cert_path: str = \"\", prv_key_path: str = \"\"):\n        pass",
  "def start(self, update_callback=None, conditional_cb=False):\n        pass",
  "def pause(self):\n        pass",
  "def resume(self):\n        pass",
  "def end(self):\n        pass",
  "def get_primary_sp(self) -> SP:\n        \"\"\"Return current primary service provider.\n\n        If primary sp not available, such as not reported by SD, connection to SD not established yet\n        the name and ports will be empty strings.\n        \"\"\"\n        pass",
  "def promote_sp(self, sp_end_point, headers=None):\n        pass",
  "def add_payload(self, payload: Dict[str, Any]):\n        pass",
  "def get_overseer_status(self) -> Dict[str, Any]:\n        \"\"\"\n\n        Returns:\n            Dict[str, Any]: [description]\n        \"\"\"\n        pass",
  "def name_check(name: str, entity_type: str):\n    regex_pattern = type_pattern_mapping.get(entity_type)\n    if regex_pattern is None:\n        return True, \"entity_type={} not defined, unable to check name={}.\".format(entity_type, name)\n    if re.match(regex_pattern, name):\n        return False, \"name={} passed on regex_pattern={} check\".format(name, regex_pattern)\n    else:\n        return True, \"name={} is ill-formatted based on regex_pattern={}\".format(name, regex_pattern)",
  "def validate_class_methods_args(cls):\n    for name, method in inspect.getmembers(cls, inspect.isfunction):\n        if name != \"__init_subclass__\":\n            setattr(cls, name, validate_args(method))\n    return cls",
  "def validate_args(method):\n    signature = inspect.signature(method)\n\n    @wraps(method)\n    def wrapper(*args, **kwargs):\n        bound_arguments = signature.bind(*args, **kwargs)\n        for name, value in bound_arguments.arguments.items():\n            annotation = signature.parameters[name].annotation\n            if not (annotation is inspect.Signature.empty or isinstance(value, annotation)):\n                raise TypeError(\n                    \"argument '{}' of {} must be {} but got {}\".format(name, method, annotation, type(value))\n                )\n        return method(*args, **kwargs)\n\n    return wrapper",
  "def wrapper(*args, **kwargs):\n        bound_arguments = signature.bind(*args, **kwargs)\n        for name, value in bound_arguments.arguments.items():\n            annotation = signature.parameters[name].annotation\n            if not (annotation is inspect.Signature.empty or isinstance(value, annotation)):\n                raise TypeError(\n                    \"argument '{}' of {} must be {} but got {}\".format(name, method, annotation, type(value))\n                )\n        return method(*args, **kwargs)",
  "def get_serializable_data(fl_ctx: FLContext):\n    logger = logging.getLogger(\"fl_context_utils\")\n    new_fl_ctx = FLContext()\n    for k, v in fl_ctx.props.items():\n        if k not in NonSerializableKeys.KEYS:\n            try:\n                pickle.dumps(v)\n                new_fl_ctx.props[k] = v\n            except:\n                logger.warning(generate_log_message(fl_ctx, f\"Object is not serializable (discarded): {k} - {v}\"))\n    return new_fl_ctx",
  "def generate_log_message(fl_ctx: FLContext, msg: str):\n    _my_run = \"run\"\n    _peer_run = \"peer_run\"\n    _peer_name = \"peer\"\n    _task_name = \"task_name\"\n    _task_id = \"task_id\"\n    _rc = \"peer_rc\"\n    _wf = \"wf\"\n\n    all_kvs = {}\n    my_run = fl_ctx.get_job_id()\n    if not my_run:\n        my_run = \"?\"\n    all_kvs[_my_run] = my_run\n\n    task_name = fl_ctx.get_prop(FLContextKey.TASK_NAME, None)\n    task_id = fl_ctx.get_prop(FLContextKey.TASK_ID, None)\n\n    if task_name:\n        all_kvs[_task_name] = task_name\n\n    if task_id:\n        all_kvs[_task_id] = task_id\n\n    wf_id = fl_ctx.get_prop(FLContextKey.WORKFLOW, None)\n    if wf_id is not None:\n        all_kvs[_wf] = wf_id\n\n    peer_ctx = fl_ctx.get_peer_context()\n    if peer_ctx:\n        if not isinstance(peer_ctx, FLContext):\n            raise TypeError(\"peer_ctx must be an instance of FLContext, but got {}\".format(type(peer_ctx)))\n        peer_run = peer_ctx.get_job_id()\n        if not peer_run:\n            peer_run = \"?\"\n        all_kvs[_peer_run] = peer_run\n\n        peer_name = peer_ctx.get_identity_name()\n        if not peer_name:\n            peer_name = \"?\"\n        all_kvs[_peer_name] = peer_name\n\n    reply = fl_ctx.get_prop(FLContextKey.REPLY, None)\n    if isinstance(reply, Shareable):\n        rc = reply.get_return_code(\"OK\")\n        all_kvs[_rc] = rc\n\n    item_order = [_my_run, _wf, _peer_name, _peer_run, _rc, _task_name, _task_id]\n    ctx_items = []\n    for item in item_order:\n        if item in all_kvs:\n            ctx_items.append(item + \"=\" + str(all_kvs[item]))\n\n    return \"[\" + \", \".join(ctx_items) + \"]: \" + msg",
  "def get_open_ports(number):\n    \"\"\"Get the number of open ports from the system.\n\n    Args:\n        number: number of ports\n    Returns: list of open_ports\n    \"\"\"\n    ports = []\n    for i in range(number):\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.bind((\"\", 0))\n        s.listen(1)\n        port = s.getsockname()[1]\n        s.close()\n        if port > 0:\n            ports.append(port)\n    if len(ports) != number:\n        raise RuntimeError(\n            \"Could not get enough open ports from the system. Needed {} but got {}.\".format(number, len(ports))\n        )\n    return ports",
  "def get_size(obj, seen=None):\n    \"\"\"Recursively finds size of objects\"\"\"\n    size = sys.getsizeof(obj)\n    if seen is None:\n        seen = set()\n    obj_id = id(obj)\n    if obj_id in seen:\n        return 0\n    # Important mark as seen *before* entering recursion to gracefully handle\n    # self-referential objects\n    seen.add(obj_id)\n    if isinstance(obj, dict):\n        size += sum([get_size(v, seen) for v in obj.values()])\n        size += sum([get_size(k, seen) for k in obj.keys()])\n    elif hasattr(obj, \"__dict__\"):\n        size += get_size(obj.__dict__, seen)\n    elif hasattr(obj, \"__iter__\") and not isinstance(obj, (str, bytes, bytearray)):\n        size += sum([get_size(i, seen) for i in obj])\n    return size",
  "class BcastTaskManager(TaskManager):\n    def __init__(self, task: Task, min_responses: int = 0, wait_time_after_min_received: int = 0):\n        \"\"\"Task manager for broadcast controller.\n\n        Args:\n            task (Task): an instance of Task\n            min_responses (int, optional): the minimum number of responses so this task is considered finished. Defaults to 0.\n            wait_time_after_min_received (int, optional): additional wait time for late clients to contribute their results. Defaults to 0.\n        \"\"\"\n        TaskManager.__init__(self)\n        task.props[_KEY_MIN_RESPS] = min_responses\n        task.props[_KEY_WAIT_TIME_AFTER_MIN_RESPS] = wait_time_after_min_received\n        task.props[_KEY_MIN_RESPS_RCV_TIME] = None\n\n    def check_task_exit(self, task: Task) -> Tuple[bool, TaskCompletionStatus]:\n        \"\"\"Determine if the task should exit.\n\n        Args:\n            task (Task): an instance of Task\n\n        Tuple[bool, TaskCompletionStatus]:\n            first entry in the tuple means whether to exit the task or not.  If it's True, the task should exit.\n            second entry in the tuple indicates the TaskCompletionStatus.\n        \"\"\"\n        if len(task.client_tasks) == 0:\n            # nothing has been sent - continue to wait\n            return False, TaskCompletionStatus.IGNORED\n\n        clients_responded = 0\n        clients_not_responded = 0\n        for s in task.client_tasks:\n            if s.result_received_time is None:\n                clients_not_responded += 1\n            else:\n                clients_responded += 1\n\n        # if min_responses is 0, need to have all client tasks responded\n        if task.props[_KEY_MIN_RESPS] == 0 and clients_not_responded:\n            return False, TaskCompletionStatus.IGNORED\n\n        # check if minimum responses are received\n        if clients_responded == 0 or clients_responded < task.props[_KEY_MIN_RESPS]:\n            # continue to wait\n            return False, TaskCompletionStatus.IGNORED\n\n        # minimum responses received\n        min_resps_received_time = task.props[_KEY_MIN_RESPS_RCV_TIME]\n        if min_resps_received_time is None:\n            min_resps_received_time = time.time()\n            task.props[_KEY_MIN_RESPS_RCV_TIME] = min_resps_received_time\n\n        # see whether we have waited for long enough\n        if time.time() - min_resps_received_time >= task.props[_KEY_WAIT_TIME_AFTER_MIN_RESPS]:\n            # yes - exit the task\n            return True, TaskCompletionStatus.OK\n        else:\n            # no - continue to wait\n            return False, TaskCompletionStatus.IGNORED",
  "class BcastForeverTaskManager(TaskManager):\n    def __init__(self):\n        \"\"\"Task manager for broadcast controller with forever waiting time.\"\"\"\n        TaskManager.__init__(self)\n\n    def check_task_send(self, client_task: ClientTask, fl_ctx: FLContext) -> TaskCheckStatus:\n        \"\"\"Determine whether the task should be sent to the client.\n\n        Args:\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n\n\n        Returns:\n            TaskCheckStatus: NO_BLOCK for not sending the task, SEND for OK to send\n        \"\"\"\n        # Note: even if the client may have done the task, we may still send it!\n        client_name = client_task.client.name\n        if client_task.task.targets is None or client_name in client_task.task.targets:\n            return TaskCheckStatus.SEND\n        else:\n            return TaskCheckStatus.NO_BLOCK\n\n    def check_task_exit(self, task: Task) -> Tuple[bool, TaskCompletionStatus]:\n        \"\"\"Determine whether the task should exit.\n\n        Args:\n            task (Task): an instance of Task\n\n        Tuple[bool, TaskCompletionStatus]:\n            first entry in the tuple means whether to exit the task or not.  If it's True, the task should exit.\n            second entry in the tuple indicates the TaskCompletionStatus.\n        \"\"\"\n        # never exit\n        return False, TaskCompletionStatus.IGNORED",
  "def __init__(self, task: Task, min_responses: int = 0, wait_time_after_min_received: int = 0):\n        \"\"\"Task manager for broadcast controller.\n\n        Args:\n            task (Task): an instance of Task\n            min_responses (int, optional): the minimum number of responses so this task is considered finished. Defaults to 0.\n            wait_time_after_min_received (int, optional): additional wait time for late clients to contribute their results. Defaults to 0.\n        \"\"\"\n        TaskManager.__init__(self)\n        task.props[_KEY_MIN_RESPS] = min_responses\n        task.props[_KEY_WAIT_TIME_AFTER_MIN_RESPS] = wait_time_after_min_received\n        task.props[_KEY_MIN_RESPS_RCV_TIME] = None",
  "def check_task_exit(self, task: Task) -> Tuple[bool, TaskCompletionStatus]:\n        \"\"\"Determine if the task should exit.\n\n        Args:\n            task (Task): an instance of Task\n\n        Tuple[bool, TaskCompletionStatus]:\n            first entry in the tuple means whether to exit the task or not.  If it's True, the task should exit.\n            second entry in the tuple indicates the TaskCompletionStatus.\n        \"\"\"\n        if len(task.client_tasks) == 0:\n            # nothing has been sent - continue to wait\n            return False, TaskCompletionStatus.IGNORED\n\n        clients_responded = 0\n        clients_not_responded = 0\n        for s in task.client_tasks:\n            if s.result_received_time is None:\n                clients_not_responded += 1\n            else:\n                clients_responded += 1\n\n        # if min_responses is 0, need to have all client tasks responded\n        if task.props[_KEY_MIN_RESPS] == 0 and clients_not_responded:\n            return False, TaskCompletionStatus.IGNORED\n\n        # check if minimum responses are received\n        if clients_responded == 0 or clients_responded < task.props[_KEY_MIN_RESPS]:\n            # continue to wait\n            return False, TaskCompletionStatus.IGNORED\n\n        # minimum responses received\n        min_resps_received_time = task.props[_KEY_MIN_RESPS_RCV_TIME]\n        if min_resps_received_time is None:\n            min_resps_received_time = time.time()\n            task.props[_KEY_MIN_RESPS_RCV_TIME] = min_resps_received_time\n\n        # see whether we have waited for long enough\n        if time.time() - min_resps_received_time >= task.props[_KEY_WAIT_TIME_AFTER_MIN_RESPS]:\n            # yes - exit the task\n            return True, TaskCompletionStatus.OK\n        else:\n            # no - continue to wait\n            return False, TaskCompletionStatus.IGNORED",
  "def __init__(self):\n        \"\"\"Task manager for broadcast controller with forever waiting time.\"\"\"\n        TaskManager.__init__(self)",
  "def check_task_send(self, client_task: ClientTask, fl_ctx: FLContext) -> TaskCheckStatus:\n        \"\"\"Determine whether the task should be sent to the client.\n\n        Args:\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n\n\n        Returns:\n            TaskCheckStatus: NO_BLOCK for not sending the task, SEND for OK to send\n        \"\"\"\n        # Note: even if the client may have done the task, we may still send it!\n        client_name = client_task.client.name\n        if client_task.task.targets is None or client_name in client_task.task.targets:\n            return TaskCheckStatus.SEND\n        else:\n            return TaskCheckStatus.NO_BLOCK",
  "def check_task_exit(self, task: Task) -> Tuple[bool, TaskCompletionStatus]:\n        \"\"\"Determine whether the task should exit.\n\n        Args:\n            task (Task): an instance of Task\n\n        Tuple[bool, TaskCompletionStatus]:\n            first entry in the tuple means whether to exit the task or not.  If it's True, the task should exit.\n            second entry in the tuple indicates the TaskCompletionStatus.\n        \"\"\"\n        # never exit\n        return False, TaskCompletionStatus.IGNORED",
  "class _JobFilter(ABC):\n    @abstractmethod\n    def filter_job(self, meta: dict) -> bool:\n        pass",
  "class _StatusFilter(_JobFilter):\n    def __init__(self, status_to_check):\n        self.result = []\n        self.status_to_check = status_to_check\n\n    def filter_job(self, meta: dict):\n        if meta[JobMetaKey.STATUS] == self.status_to_check:\n            self.result.append(job_from_meta(meta))\n        return True",
  "class _AllJobsFilter(_JobFilter):\n    def __init__(self):\n        self.result = []\n\n    def filter_job(self, meta: dict):\n        self.result.append(job_from_meta(meta))\n        return True",
  "class _ReviewerFilter(_JobFilter):\n    def __init__(self, reviewer_name, fl_ctx: FLContext):\n        \"\"\"Not used yet, for use in future implementations.\"\"\"\n        self.result = []\n        self.reviewer_name = reviewer_name\n\n    def filter_job(self, meta: dict):\n        approvals = meta.get(JobMetaKey.APPROVALS)\n        if not approvals or self.reviewer_name not in approvals:\n            self.result.append(job_from_meta(meta))\n        return True",
  "class SimpleJobDefManager(JobDefManagerSpec):\n    def __init__(self, uri_root: str = \"jobs\", job_store_id: str = \"job_store\"):\n        super().__init__()\n        self.uri_root = uri_root\n        os.makedirs(uri_root, exist_ok=True)\n        self.job_store_id = job_store_id\n\n    def _get_job_store(self, fl_ctx):\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ServerEngineSpec):\n            raise TypeError(f\"engine should be of type ServerEngineSpec, but got {type(engine)}\")\n        store = engine.get_component(self.job_store_id)\n        if not isinstance(store, StorageSpec):\n            raise TypeError(f\"engine should have a job store component of type StorageSpec, but got {type(store)}\")\n        return store\n\n    def job_uri(self, jid: str):\n        return os.path.join(self.uri_root, jid)\n\n    def create(self, meta: dict, uploaded_content: bytes, fl_ctx: FLContext) -> Dict[str, Any]:\n        # validate meta to make sure it has:\n\n        jid = str(uuid.uuid4())\n        meta[JobMetaKey.JOB_ID.value] = jid\n        meta[JobMetaKey.SUBMIT_TIME.value] = time.time()\n        meta[JobMetaKey.SUBMIT_TIME_ISO.value] = (\n            datetime.datetime.fromtimestamp(meta[JobMetaKey.SUBMIT_TIME]).astimezone().isoformat()\n        )\n        meta[JobMetaKey.START_TIME.value] = \"\"\n        meta[JobMetaKey.DURATION.value] = \"N/A\"\n        meta[JobMetaKey.STATUS.value] = RunStatus.SUBMITTED.value\n\n        # write it to the store\n        stored_data = {JobDataKey.JOB_DATA.value: uploaded_content, JobDataKey.WORKSPACE_DATA.value: None}\n        store = self._get_job_store(fl_ctx)\n        store.create_object(self.job_uri(jid), pickle.dumps(stored_data), meta, overwrite_existing=True)\n        return meta\n\n    def delete(self, jid: str, fl_ctx: FLContext):\n        store = self._get_job_store(fl_ctx)\n        store.delete_object(self.job_uri(jid))\n\n    def _validate_meta(self, meta):\n        \"\"\"Validate meta\n\n        Args:\n            meta: meta to validate\n\n        Returns:\n\n        \"\"\"\n        pass\n\n    def _validate_uploaded_content(self, uploaded_content) -> bool:\n        \"\"\"Validate uploaded content for creating a run config. (THIS NEEDS TO HAPPEN BEFORE CONTENT IS PROVIDED NOW)\n\n        Internally used by create and update.\n\n        1. check all sites in deployment are in resources\n        2. each site in deployment need to have resources (each site in resource need to be in deployment ???)\n        \"\"\"\n        pass\n\n    def get_job(self, jid: str, fl_ctx: FLContext) -> Optional[Job]:\n        store = self._get_job_store(fl_ctx)\n        try:\n            job_meta = store.get_meta(self.job_uri(jid))\n            return job_from_meta(job_meta)\n        except StorageException:\n            return None\n\n    def set_results_uri(self, jid: str, result_uri: str, fl_ctx: FLContext):\n        store = self._get_job_store(fl_ctx)\n        updated_meta = {JobMetaKey.RESULT_LOCATION.value: result_uri}\n        store.update_meta(self.job_uri(jid), updated_meta, replace=False)\n        return self.get_job(jid, fl_ctx)\n\n    def get_app(self, job: Job, app_name: str, fl_ctx: FLContext) -> bytes:\n        temp_dir = tempfile.mkdtemp()\n        job_id_dir = self._load_job_data_from_store(job.job_id, temp_dir, fl_ctx)\n        job_folder = os.path.join(job_id_dir, job.meta[JobMetaKey.JOB_FOLDER_NAME.value])\n        fullpath_src = os.path.join(job_folder, app_name)\n        result = zip_directory_to_bytes(fullpath_src, \"\")\n        shutil.rmtree(temp_dir)\n        return result\n\n    def get_apps(self, job: Job, fl_ctx: FLContext) -> Dict[str, bytes]:\n        temp_dir = tempfile.mkdtemp()\n        job_id_dir = self._load_job_data_from_store(job.job_id, temp_dir, fl_ctx)\n        job_folder = os.path.join(job_id_dir, job.meta[JobMetaKey.JOB_FOLDER_NAME.value])\n        result_dict = {}\n        for app in job.get_deployment():\n            fullpath_src = os.path.join(job_folder, app)\n            result_dict[app] = zip_directory_to_bytes(fullpath_src, \"\")\n        shutil.rmtree(temp_dir)\n        return result_dict\n\n    def _load_job_data_from_store(self, jid: str, temp_dir: str, fl_ctx: FLContext):\n        data_bytes = self.get_content(jid, fl_ctx)\n        job_id_dir = os.path.join(temp_dir, jid)\n        if os.path.exists(job_id_dir):\n            shutil.rmtree(job_id_dir)\n        os.mkdir(job_id_dir)\n        unzip_all_from_bytes(data_bytes, job_id_dir)\n        return job_id_dir\n\n    def get_content(self, jid: str, fl_ctx: FLContext) -> Optional[bytes]:\n        store = self._get_job_store(fl_ctx)\n        try:\n            stored_data = store.get_data(self.job_uri(jid))\n        except StorageException:\n            return None\n        return pickle.loads(stored_data).get(JobDataKey.JOB_DATA.value)\n\n    def get_job_data(self, jid: str, fl_ctx: FLContext) -> dict:\n        store = self._get_job_store(fl_ctx)\n        stored_data = store.get_data(self.job_uri(jid))\n        return pickle.loads(stored_data)\n\n    def set_status(self, jid: str, status: RunStatus, fl_ctx: FLContext):\n        meta = {JobMetaKey.STATUS.value: status.value}\n        store = self._get_job_store(fl_ctx)\n        if status == RunStatus.RUNNING.value:\n            meta[JobMetaKey.START_TIME.value] = str(datetime.datetime.now())\n        elif status in [\n            RunStatus.FINISHED_ABORTED.value,\n            RunStatus.FINISHED_COMPLETED.value,\n            RunStatus.FINISHED_EXECUTION_EXCEPTION.value,\n        ]:\n            job_meta = store.get_meta(self.job_uri(jid))\n            if job_meta[JobMetaKey.START_TIME.value]:\n                start_time = datetime.datetime.strptime(job_meta.get(JobMetaKey.START_TIME), \"%Y-%m-%d %H:%M:%S.%f\")\n                meta[JobMetaKey.DURATION.value] = str(datetime.datetime.now() - start_time)\n        store.update_meta(uri=self.job_uri(jid), meta=meta, replace=False)\n\n    def update_meta(self, jid: str, meta, fl_ctx: FLContext):\n        store = self._get_job_store(fl_ctx)\n        store.update_meta(uri=self.job_uri(jid), meta=meta, replace=False)\n\n    def get_all_jobs(self, fl_ctx: FLContext) -> List[Job]:\n        job_filter = _AllJobsFilter()\n        self._scan(job_filter, fl_ctx)\n        return job_filter.result\n\n    def _scan(self, job_filter: _JobFilter, fl_ctx: FLContext):\n        store = self._get_job_store(fl_ctx)\n        jid_paths = store.list_objects(self.uri_root)\n        if not jid_paths:\n            return\n\n        for jid_path in jid_paths:\n            jid = pathlib.PurePath(jid_path).name\n            meta = store.get_meta(self.job_uri(jid))\n            if meta:\n                ok = job_filter.filter_job(meta)\n                if not ok:\n                    break\n\n    def get_jobs_by_status(self, status, fl_ctx: FLContext) -> List[Job]:\n        job_filter = _StatusFilter(status)\n        self._scan(job_filter, fl_ctx)\n        return job_filter.result\n\n    def get_jobs_waiting_for_review(self, reviewer_name: str, fl_ctx: FLContext) -> List[Job]:\n        job_filter = _ReviewerFilter(reviewer_name, fl_ctx)\n        self._scan(job_filter, fl_ctx)\n        return job_filter.result\n\n    def set_approval(\n        self, jid: str, reviewer_name: str, approved: bool, note: str, fl_ctx: FLContext\n    ) -> Dict[str, Any]:\n        meta = self.get_job(jid, fl_ctx).meta\n        if meta:\n            approvals = meta.get(JobMetaKey.APPROVALS)\n            if not approvals:\n                approvals = {}\n                meta[JobMetaKey.APPROVALS.value] = approvals\n            approvals[reviewer_name] = (approved, note)\n            updated_meta = {JobMetaKey.APPROVALS.value: approvals}\n            store = self._get_job_store(fl_ctx)\n            store.update_meta(self.job_uri(jid), updated_meta, replace=False)\n        return meta\n\n    def save_workspace(self, jid: str, data: bytes, fl_ctx: FLContext):\n        store = self._get_job_store(fl_ctx)\n        stored_data = store.get_data(self.job_uri(jid))\n        job_data = pickle.loads(stored_data)\n        job_data[JobDataKey.WORKSPACE_DATA.value] = data\n        store.update_data(self.job_uri(jid), pickle.dumps(job_data))",
  "def filter_job(self, meta: dict) -> bool:\n        pass",
  "def __init__(self, status_to_check):\n        self.result = []\n        self.status_to_check = status_to_check",
  "def filter_job(self, meta: dict):\n        if meta[JobMetaKey.STATUS] == self.status_to_check:\n            self.result.append(job_from_meta(meta))\n        return True",
  "def __init__(self):\n        self.result = []",
  "def filter_job(self, meta: dict):\n        self.result.append(job_from_meta(meta))\n        return True",
  "def __init__(self, reviewer_name, fl_ctx: FLContext):\n        \"\"\"Not used yet, for use in future implementations.\"\"\"\n        self.result = []\n        self.reviewer_name = reviewer_name",
  "def filter_job(self, meta: dict):\n        approvals = meta.get(JobMetaKey.APPROVALS)\n        if not approvals or self.reviewer_name not in approvals:\n            self.result.append(job_from_meta(meta))\n        return True",
  "def __init__(self, uri_root: str = \"jobs\", job_store_id: str = \"job_store\"):\n        super().__init__()\n        self.uri_root = uri_root\n        os.makedirs(uri_root, exist_ok=True)\n        self.job_store_id = job_store_id",
  "def _get_job_store(self, fl_ctx):\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ServerEngineSpec):\n            raise TypeError(f\"engine should be of type ServerEngineSpec, but got {type(engine)}\")\n        store = engine.get_component(self.job_store_id)\n        if not isinstance(store, StorageSpec):\n            raise TypeError(f\"engine should have a job store component of type StorageSpec, but got {type(store)}\")\n        return store",
  "def job_uri(self, jid: str):\n        return os.path.join(self.uri_root, jid)",
  "def create(self, meta: dict, uploaded_content: bytes, fl_ctx: FLContext) -> Dict[str, Any]:\n        # validate meta to make sure it has:\n\n        jid = str(uuid.uuid4())\n        meta[JobMetaKey.JOB_ID.value] = jid\n        meta[JobMetaKey.SUBMIT_TIME.value] = time.time()\n        meta[JobMetaKey.SUBMIT_TIME_ISO.value] = (\n            datetime.datetime.fromtimestamp(meta[JobMetaKey.SUBMIT_TIME]).astimezone().isoformat()\n        )\n        meta[JobMetaKey.START_TIME.value] = \"\"\n        meta[JobMetaKey.DURATION.value] = \"N/A\"\n        meta[JobMetaKey.STATUS.value] = RunStatus.SUBMITTED.value\n\n        # write it to the store\n        stored_data = {JobDataKey.JOB_DATA.value: uploaded_content, JobDataKey.WORKSPACE_DATA.value: None}\n        store = self._get_job_store(fl_ctx)\n        store.create_object(self.job_uri(jid), pickle.dumps(stored_data), meta, overwrite_existing=True)\n        return meta",
  "def delete(self, jid: str, fl_ctx: FLContext):\n        store = self._get_job_store(fl_ctx)\n        store.delete_object(self.job_uri(jid))",
  "def _validate_meta(self, meta):\n        \"\"\"Validate meta\n\n        Args:\n            meta: meta to validate\n\n        Returns:\n\n        \"\"\"\n        pass",
  "def _validate_uploaded_content(self, uploaded_content) -> bool:\n        \"\"\"Validate uploaded content for creating a run config. (THIS NEEDS TO HAPPEN BEFORE CONTENT IS PROVIDED NOW)\n\n        Internally used by create and update.\n\n        1. check all sites in deployment are in resources\n        2. each site in deployment need to have resources (each site in resource need to be in deployment ???)\n        \"\"\"\n        pass",
  "def get_job(self, jid: str, fl_ctx: FLContext) -> Optional[Job]:\n        store = self._get_job_store(fl_ctx)\n        try:\n            job_meta = store.get_meta(self.job_uri(jid))\n            return job_from_meta(job_meta)\n        except StorageException:\n            return None",
  "def set_results_uri(self, jid: str, result_uri: str, fl_ctx: FLContext):\n        store = self._get_job_store(fl_ctx)\n        updated_meta = {JobMetaKey.RESULT_LOCATION.value: result_uri}\n        store.update_meta(self.job_uri(jid), updated_meta, replace=False)\n        return self.get_job(jid, fl_ctx)",
  "def get_app(self, job: Job, app_name: str, fl_ctx: FLContext) -> bytes:\n        temp_dir = tempfile.mkdtemp()\n        job_id_dir = self._load_job_data_from_store(job.job_id, temp_dir, fl_ctx)\n        job_folder = os.path.join(job_id_dir, job.meta[JobMetaKey.JOB_FOLDER_NAME.value])\n        fullpath_src = os.path.join(job_folder, app_name)\n        result = zip_directory_to_bytes(fullpath_src, \"\")\n        shutil.rmtree(temp_dir)\n        return result",
  "def get_apps(self, job: Job, fl_ctx: FLContext) -> Dict[str, bytes]:\n        temp_dir = tempfile.mkdtemp()\n        job_id_dir = self._load_job_data_from_store(job.job_id, temp_dir, fl_ctx)\n        job_folder = os.path.join(job_id_dir, job.meta[JobMetaKey.JOB_FOLDER_NAME.value])\n        result_dict = {}\n        for app in job.get_deployment():\n            fullpath_src = os.path.join(job_folder, app)\n            result_dict[app] = zip_directory_to_bytes(fullpath_src, \"\")\n        shutil.rmtree(temp_dir)\n        return result_dict",
  "def _load_job_data_from_store(self, jid: str, temp_dir: str, fl_ctx: FLContext):\n        data_bytes = self.get_content(jid, fl_ctx)\n        job_id_dir = os.path.join(temp_dir, jid)\n        if os.path.exists(job_id_dir):\n            shutil.rmtree(job_id_dir)\n        os.mkdir(job_id_dir)\n        unzip_all_from_bytes(data_bytes, job_id_dir)\n        return job_id_dir",
  "def get_content(self, jid: str, fl_ctx: FLContext) -> Optional[bytes]:\n        store = self._get_job_store(fl_ctx)\n        try:\n            stored_data = store.get_data(self.job_uri(jid))\n        except StorageException:\n            return None\n        return pickle.loads(stored_data).get(JobDataKey.JOB_DATA.value)",
  "def get_job_data(self, jid: str, fl_ctx: FLContext) -> dict:\n        store = self._get_job_store(fl_ctx)\n        stored_data = store.get_data(self.job_uri(jid))\n        return pickle.loads(stored_data)",
  "def set_status(self, jid: str, status: RunStatus, fl_ctx: FLContext):\n        meta = {JobMetaKey.STATUS.value: status.value}\n        store = self._get_job_store(fl_ctx)\n        if status == RunStatus.RUNNING.value:\n            meta[JobMetaKey.START_TIME.value] = str(datetime.datetime.now())\n        elif status in [\n            RunStatus.FINISHED_ABORTED.value,\n            RunStatus.FINISHED_COMPLETED.value,\n            RunStatus.FINISHED_EXECUTION_EXCEPTION.value,\n        ]:\n            job_meta = store.get_meta(self.job_uri(jid))\n            if job_meta[JobMetaKey.START_TIME.value]:\n                start_time = datetime.datetime.strptime(job_meta.get(JobMetaKey.START_TIME), \"%Y-%m-%d %H:%M:%S.%f\")\n                meta[JobMetaKey.DURATION.value] = str(datetime.datetime.now() - start_time)\n        store.update_meta(uri=self.job_uri(jid), meta=meta, replace=False)",
  "def update_meta(self, jid: str, meta, fl_ctx: FLContext):\n        store = self._get_job_store(fl_ctx)\n        store.update_meta(uri=self.job_uri(jid), meta=meta, replace=False)",
  "def get_all_jobs(self, fl_ctx: FLContext) -> List[Job]:\n        job_filter = _AllJobsFilter()\n        self._scan(job_filter, fl_ctx)\n        return job_filter.result",
  "def _scan(self, job_filter: _JobFilter, fl_ctx: FLContext):\n        store = self._get_job_store(fl_ctx)\n        jid_paths = store.list_objects(self.uri_root)\n        if not jid_paths:\n            return\n\n        for jid_path in jid_paths:\n            jid = pathlib.PurePath(jid_path).name\n            meta = store.get_meta(self.job_uri(jid))\n            if meta:\n                ok = job_filter.filter_job(meta)\n                if not ok:\n                    break",
  "def get_jobs_by_status(self, status, fl_ctx: FLContext) -> List[Job]:\n        job_filter = _StatusFilter(status)\n        self._scan(job_filter, fl_ctx)\n        return job_filter.result",
  "def get_jobs_waiting_for_review(self, reviewer_name: str, fl_ctx: FLContext) -> List[Job]:\n        job_filter = _ReviewerFilter(reviewer_name, fl_ctx)\n        self._scan(job_filter, fl_ctx)\n        return job_filter.result",
  "def set_approval(\n        self, jid: str, reviewer_name: str, approved: bool, note: str, fl_ctx: FLContext\n    ) -> Dict[str, Any]:\n        meta = self.get_job(jid, fl_ctx).meta\n        if meta:\n            approvals = meta.get(JobMetaKey.APPROVALS)\n            if not approvals:\n                approvals = {}\n                meta[JobMetaKey.APPROVALS.value] = approvals\n            approvals[reviewer_name] = (approved, note)\n            updated_meta = {JobMetaKey.APPROVALS.value: approvals}\n            store = self._get_job_store(fl_ctx)\n            store.update_meta(self.job_uri(jid), updated_meta, replace=False)\n        return meta",
  "def save_workspace(self, jid: str, data: bytes, fl_ctx: FLContext):\n        store = self._get_job_store(fl_ctx)\n        stored_data = store.get_data(self.job_uri(jid))\n        job_data = pickle.loads(stored_data)\n        job_data[JobDataKey.WORKSPACE_DATA.value] = data\n        store.update_data(self.job_uri(jid), pickle.dumps(job_data))",
  "class SendTaskManager(TaskManager):\n    def __init__(self, task: Task, send_order: SendOrder, task_assignment_timeout):\n        \"\"\"Task manager for send controller.\n\n        Args:\n            task (Task): an instance of Task\n            send_order (SendOrder): the order of clients to receive task\n            task_assignment_timeout (int): timeout value on a client requesting its task\n        \"\"\"\n        TaskManager.__init__(self)\n        if task_assignment_timeout is None or task_assignment_timeout <= 0:\n            task_assignment_timeout = 0\n        task.props[_KEY_ORDER] = send_order\n        task.props[_KEY_TASK_ASSIGN_TIMEOUT] = task_assignment_timeout\n\n    def check_task_send(self, client_task: ClientTask, fl_ctx: FLContext) -> TaskCheckStatus:\n        \"\"\"Determine whether the task should be sent to the client.\n\n        Args:\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n\n        Returns:\n            TaskCheckStatus: NO_BLOCK for not sending the task, BLOCK for waiting, SEND for OK to send\n        \"\"\"\n        task = client_task.task\n        if len(task.client_tasks) > 0:  # already sent to one client\n            if client_task.task_sent_time is not None:  # the task was sent to this client!\n                if client_task.result_received_time is not None:\n                    # the task result was already received\n                    # this task is actually done - waiting to end by the monitor\n                    return TaskCheckStatus.NO_BLOCK\n                else:\n                    return TaskCheckStatus.SEND\n            else:  # the task was sent to someone else\n                return TaskCheckStatus.NO_BLOCK\n\n        # in SEQUENTIAL mode - targets must be explicitly specified\n        # is this client eligible?\n        try:\n            client_idx = task.targets.index(client_task.client.name)\n        except ValueError:\n            client_idx = -1\n\n        if client_idx < 0:\n            # this client is not a target\n            return TaskCheckStatus.NO_BLOCK\n\n        if task.props[_KEY_ORDER] == SendOrder.ANY:\n            return TaskCheckStatus.SEND\n\n        task_assignment_timeout = task.props[_KEY_TASK_ASSIGN_TIMEOUT]\n        if task_assignment_timeout == 0:\n            # no client timeout - can only send to the first target\n            eligible_client_idx = 0\n        else:\n            elapsed = time.time() - task.create_time\n            eligible_client_idx = int(elapsed / task_assignment_timeout)\n\n        if client_idx <= eligible_client_idx:\n            return TaskCheckStatus.SEND\n        else:\n            # this client is currently not eligible but could be later\n            # since this client is involved in the task, we need to wait until this task is resolved!\n            return TaskCheckStatus.BLOCK\n\n    def check_task_exit(self, task: Task) -> Tuple[bool, TaskCompletionStatus]:\n        \"\"\"Determine whether the task should exit.\n\n        Args:\n            task (Task): an instance of Task\n\n        Tuple[bool, TaskCompletionStatus]:\n            first entry in the tuple means whether to exit the task or not.  If it's True, the task should exit.\n            second entry in the tuple indicates the TaskCompletionStatus.\n        \"\"\"\n        if len(task.client_tasks) > 0:\n            # there should be only a single item in the task's client status list\n            # because only a single client is sent the task!\n            for s in task.client_tasks:\n                if s.result_received_time is not None:\n                    # this task is done!\n                    return True, TaskCompletionStatus.OK\n\n        # no one is working on this task yet or the task is not done\n        return False, TaskCompletionStatus.IGNORED",
  "def __init__(self, task: Task, send_order: SendOrder, task_assignment_timeout):\n        \"\"\"Task manager for send controller.\n\n        Args:\n            task (Task): an instance of Task\n            send_order (SendOrder): the order of clients to receive task\n            task_assignment_timeout (int): timeout value on a client requesting its task\n        \"\"\"\n        TaskManager.__init__(self)\n        if task_assignment_timeout is None or task_assignment_timeout <= 0:\n            task_assignment_timeout = 0\n        task.props[_KEY_ORDER] = send_order\n        task.props[_KEY_TASK_ASSIGN_TIMEOUT] = task_assignment_timeout",
  "def check_task_send(self, client_task: ClientTask, fl_ctx: FLContext) -> TaskCheckStatus:\n        \"\"\"Determine whether the task should be sent to the client.\n\n        Args:\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n\n        Returns:\n            TaskCheckStatus: NO_BLOCK for not sending the task, BLOCK for waiting, SEND for OK to send\n        \"\"\"\n        task = client_task.task\n        if len(task.client_tasks) > 0:  # already sent to one client\n            if client_task.task_sent_time is not None:  # the task was sent to this client!\n                if client_task.result_received_time is not None:\n                    # the task result was already received\n                    # this task is actually done - waiting to end by the monitor\n                    return TaskCheckStatus.NO_BLOCK\n                else:\n                    return TaskCheckStatus.SEND\n            else:  # the task was sent to someone else\n                return TaskCheckStatus.NO_BLOCK\n\n        # in SEQUENTIAL mode - targets must be explicitly specified\n        # is this client eligible?\n        try:\n            client_idx = task.targets.index(client_task.client.name)\n        except ValueError:\n            client_idx = -1\n\n        if client_idx < 0:\n            # this client is not a target\n            return TaskCheckStatus.NO_BLOCK\n\n        if task.props[_KEY_ORDER] == SendOrder.ANY:\n            return TaskCheckStatus.SEND\n\n        task_assignment_timeout = task.props[_KEY_TASK_ASSIGN_TIMEOUT]\n        if task_assignment_timeout == 0:\n            # no client timeout - can only send to the first target\n            eligible_client_idx = 0\n        else:\n            elapsed = time.time() - task.create_time\n            eligible_client_idx = int(elapsed / task_assignment_timeout)\n\n        if client_idx <= eligible_client_idx:\n            return TaskCheckStatus.SEND\n        else:\n            # this client is currently not eligible but could be later\n            # since this client is involved in the task, we need to wait until this task is resolved!\n            return TaskCheckStatus.BLOCK",
  "def check_task_exit(self, task: Task) -> Tuple[bool, TaskCompletionStatus]:\n        \"\"\"Determine whether the task should exit.\n\n        Args:\n            task (Task): an instance of Task\n\n        Tuple[bool, TaskCompletionStatus]:\n            first entry in the tuple means whether to exit the task or not.  If it's True, the task should exit.\n            second entry in the tuple indicates the TaskCompletionStatus.\n        \"\"\"\n        if len(task.client_tasks) > 0:\n            # there should be only a single item in the task's client status list\n            # because only a single client is sent the task!\n            for s in task.client_tasks:\n                if s.result_received_time is not None:\n                    # this task is done!\n                    return True, TaskCompletionStatus.OK\n\n        # no one is working on this task yet or the task is not done\n        return False, TaskCompletionStatus.IGNORED",
  "class SequentialRelayTaskManager(TaskManager):\n    def __init__(self, task: Task, task_assignment_timeout, task_result_timeout, dynamic_targets: bool):\n        \"\"\"Task manager for relay controller on SendOrder.SEQUENTIAL.\n\n        Args:\n            task (Task): an instance of Task\n            task_assignment_timeout (int): timeout value on a client requesting its task\n            task_result_timeout (int): timeout value on reply of one client\n            dynamic_targets (bool): allow clients to join after this task starts\n        \"\"\"\n        TaskManager.__init__(self)\n        if task_assignment_timeout is None:\n            task_assignment_timeout = 0\n\n        if task_result_timeout is None:\n            task_result_timeout = 0\n\n        task.props[_KEY_DYNAMIC_TARGETS] = dynamic_targets\n        task.props[_KEY_TASK_ASSIGN_TIMEOUT] = task_assignment_timeout\n        task.props[_KEY_TASK_RESULT_TIMEOUT] = task_result_timeout\n        task.props[_KEY_LAST_SEND_IDX] = -1  # client index of last send\n        task.props[_PENDING_CLIENT_TASK] = None\n\n    def check_task_send(self, client_task: ClientTask, fl_ctx: FLContext) -> TaskCheckStatus:\n        \"\"\"Determine whether the task should be sent to the client.\n\n        Args:\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n\n        Returns:\n            TaskCheckStatus: NO_BLOCK for not sending the task, BLOCK for waiting, SEND for OK to send\n        \"\"\"\n        client_name = client_task.client.name\n        task = client_task.task\n        if task.props[_KEY_DYNAMIC_TARGETS]:\n            if task.targets is None:\n                task.targets = []\n            if client_name not in task.targets:\n                self.logger.debug(\"client_name: {} added to task.targets\".format(client_name))\n                task.targets.append(client_name)\n\n        # is this client eligible?\n        if client_name not in task.targets:\n            # this client is not a target\n            return TaskCheckStatus.NO_BLOCK\n\n        # adjust client window\n        win_start_idx, win_end_idx = self._determine_window(task)\n        self.logger.debug(\"win_start_idx={}, win_end_idx={}\".format(win_start_idx, win_end_idx))\n        if win_start_idx < 0:\n            # wait for this task to end by the monitor\n            return TaskCheckStatus.BLOCK\n\n        # see whether this client is in the window\n        for i in range(win_start_idx, win_end_idx):\n            if client_name == task.targets[i]:\n                # this client is in the window!\n                self.logger.debug(\"last_send_idx={}\".format(i))\n                task.props[_KEY_LAST_SEND_IDX] = i\n                return TaskCheckStatus.SEND\n\n        # this client is not in the window\n        return TaskCheckStatus.NO_BLOCK\n\n    def _determine_window(self, task: Task) -> Tuple[int, int]:\n        \"\"\"Returns two indexes (starting/ending) of a window of client candidates.\n\n        When starting is negative and ending is 0, the window is closed and the task should exit\n        When both starting and ending are negative, there is no client candidate as current client task has not returned\n\n        Args:\n            task (Task): an instance of Task\n\n        Returns:\n            Tuple[int, int]: starting and ending indices of a window of client candidates.\n\n        \"\"\"\n        # adjust client window\n        last_send_idx = task.props[_KEY_LAST_SEND_IDX]\n        task_result_timeout = task.props[_KEY_TASK_RESULT_TIMEOUT]\n        if last_send_idx >= 0:\n            # see whether the result has been received\n            last_task = task.last_client_task_map[task.targets[last_send_idx]]\n            self.logger.debug(\"last_task={}\".format(last_task))\n\n            if last_task.result_received_time is None:\n                # result has not been received\n                # should this client timeout?\n                if task_result_timeout and time.time() - last_task.task_sent_time > task_result_timeout:\n                    # timeout!\n                    # we give up on this client and move to the next target\n                    win_start_idx = last_send_idx + 1\n                    win_start_time = last_task.task_sent_time + task_result_timeout\n                    self.logger.debug(\n                        \"client task result timed out. win_start_idx={}, win_start_time={}\".format(\n                            win_start_idx, win_start_time\n                        )\n                    )\n                else:\n                    # continue to wait\n                    self.logger.debug(\"keep waiting on task={}\".format(task))\n                    return -1, -1\n            else:\n                # result has been received!\n                win_start_idx = last_send_idx + 1\n                win_start_time = last_task.result_received_time\n                self.logger.debug(\n                    \"result received. win_start_idx={}, win_start_time={}\".format(win_start_idx, win_start_time)\n                )\n        else:\n            # nothing has been sent\n            win_start_idx = 0\n            win_start_time = task.schedule_time\n            self.logger.debug(\n                \"nothing has been sent. win_start_idx={}, win_start_time={}\".format(win_start_idx, win_start_time)\n            )\n\n        num_targets = 0 if task.targets is None else len(task.targets)\n        if num_targets and win_start_idx >= num_targets:\n            # we reached the end of targets\n            # so task should exit\n            return -1, 0\n\n        task_assignment_timeout = task.props[_KEY_TASK_ASSIGN_TIMEOUT]\n        if task_assignment_timeout:\n            win_size = int((time.time() - win_start_time) / task_assignment_timeout) + 1\n        else:\n            win_size = 1\n\n        self.logger.debug(\"win_size={}\".format(win_size))\n        win_end_idx = win_start_idx + win_size\n\n        # Should exit if win extends past the entire target list + 1\n        if task_assignment_timeout and win_end_idx > num_targets + 1:\n            return -1, 0\n        if win_end_idx > num_targets:\n            win_end_idx = num_targets\n\n        self.logger.debug(\"win_end_idx={}\".format(win_end_idx))\n        return win_start_idx, win_end_idx\n\n    def check_task_exit(self, task: Task) -> Tuple[bool, TaskCompletionStatus]:\n        \"\"\"Determine whether the task should exit.\n\n        Args:\n            task (Task): an instance of Task\n\n        Returns:\n            Tuple[bool, TaskCompletionStatus]:\n                first entry in the tuple means whether to exit the task or not.  If it's True, the task should exit.\n                second entry in the tuple indicates the TaskCompletionStatus.\n        \"\"\"\n        # are we waiting for any client?\n        win_start_idx, win_end_idx = self._determine_window(task)\n        last_send_idx = task.props[_KEY_LAST_SEND_IDX]\n        last_client_task = None\n        if last_send_idx >= 0:\n            # see whether the result has been received\n            last_client_task = task.last_client_task_map[task.targets[last_send_idx]]\n\n        self.logger.debug(\"check_task_exit: win_start_idx={}, win_end_idx={}\".format(win_start_idx, win_end_idx))\n        if win_start_idx < 0 and win_end_idx == 0:\n            if last_client_task and last_client_task.result_received_time is not None:\n                return True, TaskCompletionStatus.OK\n            return True, TaskCompletionStatus.TIMEOUT\n        else:\n            return False, TaskCompletionStatus.IGNORED\n\n    def check_task_result(self, result: Shareable, client_task: ClientTask, fl_ctx: FLContext):\n        \"\"\"Check the result received from the client.\n\n        See whether the client_task is the last one in the task's list\n        If not, then it is a late response and ReservedHeaderKey.REPLY_IS_LATE is\n        set to True in result's header.\n\n        Args:\n            result (Shareable): an instance of Shareable\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n        \"\"\"\n        # see whether the client_task is the last one in the task's list\n        # If not, then it is a late response\n        task = client_task.task\n        if client_task != task.client_tasks[-1]:\n            result.set_header(key=ReservedHeaderKey.REPLY_IS_LATE, value=True)",
  "def __init__(self, task: Task, task_assignment_timeout, task_result_timeout, dynamic_targets: bool):\n        \"\"\"Task manager for relay controller on SendOrder.SEQUENTIAL.\n\n        Args:\n            task (Task): an instance of Task\n            task_assignment_timeout (int): timeout value on a client requesting its task\n            task_result_timeout (int): timeout value on reply of one client\n            dynamic_targets (bool): allow clients to join after this task starts\n        \"\"\"\n        TaskManager.__init__(self)\n        if task_assignment_timeout is None:\n            task_assignment_timeout = 0\n\n        if task_result_timeout is None:\n            task_result_timeout = 0\n\n        task.props[_KEY_DYNAMIC_TARGETS] = dynamic_targets\n        task.props[_KEY_TASK_ASSIGN_TIMEOUT] = task_assignment_timeout\n        task.props[_KEY_TASK_RESULT_TIMEOUT] = task_result_timeout\n        task.props[_KEY_LAST_SEND_IDX] = -1  # client index of last send\n        task.props[_PENDING_CLIENT_TASK] = None",
  "def check_task_send(self, client_task: ClientTask, fl_ctx: FLContext) -> TaskCheckStatus:\n        \"\"\"Determine whether the task should be sent to the client.\n\n        Args:\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n\n        Returns:\n            TaskCheckStatus: NO_BLOCK for not sending the task, BLOCK for waiting, SEND for OK to send\n        \"\"\"\n        client_name = client_task.client.name\n        task = client_task.task\n        if task.props[_KEY_DYNAMIC_TARGETS]:\n            if task.targets is None:\n                task.targets = []\n            if client_name not in task.targets:\n                self.logger.debug(\"client_name: {} added to task.targets\".format(client_name))\n                task.targets.append(client_name)\n\n        # is this client eligible?\n        if client_name not in task.targets:\n            # this client is not a target\n            return TaskCheckStatus.NO_BLOCK\n\n        # adjust client window\n        win_start_idx, win_end_idx = self._determine_window(task)\n        self.logger.debug(\"win_start_idx={}, win_end_idx={}\".format(win_start_idx, win_end_idx))\n        if win_start_idx < 0:\n            # wait for this task to end by the monitor\n            return TaskCheckStatus.BLOCK\n\n        # see whether this client is in the window\n        for i in range(win_start_idx, win_end_idx):\n            if client_name == task.targets[i]:\n                # this client is in the window!\n                self.logger.debug(\"last_send_idx={}\".format(i))\n                task.props[_KEY_LAST_SEND_IDX] = i\n                return TaskCheckStatus.SEND\n\n        # this client is not in the window\n        return TaskCheckStatus.NO_BLOCK",
  "def _determine_window(self, task: Task) -> Tuple[int, int]:\n        \"\"\"Returns two indexes (starting/ending) of a window of client candidates.\n\n        When starting is negative and ending is 0, the window is closed and the task should exit\n        When both starting and ending are negative, there is no client candidate as current client task has not returned\n\n        Args:\n            task (Task): an instance of Task\n\n        Returns:\n            Tuple[int, int]: starting and ending indices of a window of client candidates.\n\n        \"\"\"\n        # adjust client window\n        last_send_idx = task.props[_KEY_LAST_SEND_IDX]\n        task_result_timeout = task.props[_KEY_TASK_RESULT_TIMEOUT]\n        if last_send_idx >= 0:\n            # see whether the result has been received\n            last_task = task.last_client_task_map[task.targets[last_send_idx]]\n            self.logger.debug(\"last_task={}\".format(last_task))\n\n            if last_task.result_received_time is None:\n                # result has not been received\n                # should this client timeout?\n                if task_result_timeout and time.time() - last_task.task_sent_time > task_result_timeout:\n                    # timeout!\n                    # we give up on this client and move to the next target\n                    win_start_idx = last_send_idx + 1\n                    win_start_time = last_task.task_sent_time + task_result_timeout\n                    self.logger.debug(\n                        \"client task result timed out. win_start_idx={}, win_start_time={}\".format(\n                            win_start_idx, win_start_time\n                        )\n                    )\n                else:\n                    # continue to wait\n                    self.logger.debug(\"keep waiting on task={}\".format(task))\n                    return -1, -1\n            else:\n                # result has been received!\n                win_start_idx = last_send_idx + 1\n                win_start_time = last_task.result_received_time\n                self.logger.debug(\n                    \"result received. win_start_idx={}, win_start_time={}\".format(win_start_idx, win_start_time)\n                )\n        else:\n            # nothing has been sent\n            win_start_idx = 0\n            win_start_time = task.schedule_time\n            self.logger.debug(\n                \"nothing has been sent. win_start_idx={}, win_start_time={}\".format(win_start_idx, win_start_time)\n            )\n\n        num_targets = 0 if task.targets is None else len(task.targets)\n        if num_targets and win_start_idx >= num_targets:\n            # we reached the end of targets\n            # so task should exit\n            return -1, 0\n\n        task_assignment_timeout = task.props[_KEY_TASK_ASSIGN_TIMEOUT]\n        if task_assignment_timeout:\n            win_size = int((time.time() - win_start_time) / task_assignment_timeout) + 1\n        else:\n            win_size = 1\n\n        self.logger.debug(\"win_size={}\".format(win_size))\n        win_end_idx = win_start_idx + win_size\n\n        # Should exit if win extends past the entire target list + 1\n        if task_assignment_timeout and win_end_idx > num_targets + 1:\n            return -1, 0\n        if win_end_idx > num_targets:\n            win_end_idx = num_targets\n\n        self.logger.debug(\"win_end_idx={}\".format(win_end_idx))\n        return win_start_idx, win_end_idx",
  "def check_task_exit(self, task: Task) -> Tuple[bool, TaskCompletionStatus]:\n        \"\"\"Determine whether the task should exit.\n\n        Args:\n            task (Task): an instance of Task\n\n        Returns:\n            Tuple[bool, TaskCompletionStatus]:\n                first entry in the tuple means whether to exit the task or not.  If it's True, the task should exit.\n                second entry in the tuple indicates the TaskCompletionStatus.\n        \"\"\"\n        # are we waiting for any client?\n        win_start_idx, win_end_idx = self._determine_window(task)\n        last_send_idx = task.props[_KEY_LAST_SEND_IDX]\n        last_client_task = None\n        if last_send_idx >= 0:\n            # see whether the result has been received\n            last_client_task = task.last_client_task_map[task.targets[last_send_idx]]\n\n        self.logger.debug(\"check_task_exit: win_start_idx={}, win_end_idx={}\".format(win_start_idx, win_end_idx))\n        if win_start_idx < 0 and win_end_idx == 0:\n            if last_client_task and last_client_task.result_received_time is not None:\n                return True, TaskCompletionStatus.OK\n            return True, TaskCompletionStatus.TIMEOUT\n        else:\n            return False, TaskCompletionStatus.IGNORED",
  "def check_task_result(self, result: Shareable, client_task: ClientTask, fl_ctx: FLContext):\n        \"\"\"Check the result received from the client.\n\n        See whether the client_task is the last one in the task's list\n        If not, then it is a late response and ReservedHeaderKey.REPLY_IS_LATE is\n        set to True in result's header.\n\n        Args:\n            result (Shareable): an instance of Shareable\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n        \"\"\"\n        # see whether the client_task is the last one in the task's list\n        # If not, then it is a late response\n        task = client_task.task\n        if client_task != task.client_tasks[-1]:\n            result.set_header(key=ReservedHeaderKey.REPLY_IS_LATE, value=True)",
  "class AnyRelayTaskManager(TaskManager):\n    def __init__(self, task: Task, task_result_timeout, dynamic_targets):\n        \"\"\"Task manager for relay controller on SendOrder.ANY.\n\n        Args:\n            task (Task): an instance of Task\n            task_result_timeout (int): timeout value on reply of one client\n            dynamic_targets (bool): allow clients to join after this task starts\n        \"\"\"\n        TaskManager.__init__(self)\n\n        if task_result_timeout is None:\n            task_result_timeout = 0\n\n        task.props[_KEY_DYNAMIC_TARGETS] = dynamic_targets\n        task.props[_KEY_TASK_RESULT_TIMEOUT] = task_result_timeout\n        task.props[_KEY_FINISHED_TARGETS] = {}  # target name => times sent\n        task.props[_KEY_PENDING_CLIENT] = None\n\n    def check_task_send(self, client_task: ClientTask, fl_ctx: FLContext) -> TaskCheckStatus:\n        \"\"\"Determine whether the task should be sent to the client.\n\n        Args:\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n\n        Raises:\n            RuntimeError: when a client asking for a task while the same client_task has already been dispatched to it\n\n        Returns:\n            TaskCheckStatus: NO_BLOCK for not sending the task, BLOCK for waiting, SEND for OK to send\n        \"\"\"\n        client_name = client_task.client.name\n        task = client_task.task\n        if task.props[_KEY_DYNAMIC_TARGETS]:\n            if task.targets is None:\n                task.targets = []\n            if client_name not in task.targets:\n                task.targets.append(client_name)\n\n        # is this client eligible?\n        if client_name not in task.targets:\n            # this client is not a target\n            return TaskCheckStatus.NO_BLOCK\n\n        client_occurrences = task.targets.count(client_name)\n        finished_targets = task.props[_KEY_FINISHED_TARGETS]\n        send_count = finished_targets.get(client_name, 0)\n        if send_count >= client_occurrences:\n            # already sent enough times to this client\n            return TaskCheckStatus.NO_BLOCK\n\n        # only allow one pending task. Is there a client pending result?\n        pending_client_name = task.props[_KEY_PENDING_CLIENT]\n        task_result_timeout = task.props[_KEY_TASK_RESULT_TIMEOUT]\n        if pending_client_name is not None:\n            # see whether the result has been received\n            pending_task = task.last_client_task_map[pending_client_name]\n            if pending_task.result_received_time is None:\n                # result has not been received\n                # Note: in this case, the pending client and the asking client must not be the\n                # same, because this would be a resend case already taken care of by the controller.\n                if pending_client_name == client_name:\n                    raise RuntimeError(\"Logic Error: must not be here for client {}\".format(client_name))\n\n                # should this client timeout?\n                if task_result_timeout and time.time() - pending_task.task_sent_time > task_result_timeout:\n                    # timeout!\n                    # give up on the pending task and move to the next target\n                    finished_targets[pending_client_name] -= 1\n                    pass\n                else:\n                    # continue to wait\n                    return TaskCheckStatus.BLOCK\n\n        # can send\n        task.props[_KEY_PENDING_CLIENT] = client_name\n        finished_targets[client_name] = send_count + 1\n        return TaskCheckStatus.SEND\n\n    def check_task_exit(self, task: Task) -> Tuple[bool, TaskCompletionStatus]:\n        \"\"\"Determine whether the task should exit.\n\n        Args:\n            task (Task): an instance of Task\n\n        Returns:\n            Tuple[bool, TaskCompletionStatus]:\n                first entry in the tuple means whether to exit the task or not.  If it's True, the task should exit.\n                second entry in the tuple indicates the TaskCompletionStatus.\n        \"\"\"\n        # are we waiting for any client?\n        num_targets = 0 if task.targets is None else len(task.targets)\n        if num_targets == 0:\n            # nothing has been sent\n            return False, TaskCompletionStatus.IGNORED\n\n        # see whether all targets are done\n        finished_targets = task.props[_KEY_FINISHED_TARGETS]\n\n        total_sent = 0\n        for v in finished_targets.values():\n            total_sent += v\n\n        if total_sent < num_targets:\n            return False, TaskCompletionStatus.IGNORED\n\n        for c_t in task.client_tasks:\n            if c_t.result_received_time is None:\n                return False, TaskCompletionStatus.IGNORED\n\n        return True, TaskCompletionStatus.OK\n\n    def check_task_result(self, result: Shareable, client_task: ClientTask, fl_ctx: FLContext):\n        \"\"\"Check the result received from the client.\n\n        See whether the client_task is the last one in the task's list\n        If not, then it is a late response and ReservedHeaderKey.REPLY_IS_LATE is\n        set to True in result's header.\n\n        Args:\n            result (Shareable): an instance of Shareable\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n        \"\"\"\n        task = client_task.task\n        if client_task != task.client_tasks[-1]:\n            result.set_header(key=ReservedHeaderKey.REPLY_IS_LATE, value=True)",
  "def __init__(self, task: Task, task_result_timeout, dynamic_targets):\n        \"\"\"Task manager for relay controller on SendOrder.ANY.\n\n        Args:\n            task (Task): an instance of Task\n            task_result_timeout (int): timeout value on reply of one client\n            dynamic_targets (bool): allow clients to join after this task starts\n        \"\"\"\n        TaskManager.__init__(self)\n\n        if task_result_timeout is None:\n            task_result_timeout = 0\n\n        task.props[_KEY_DYNAMIC_TARGETS] = dynamic_targets\n        task.props[_KEY_TASK_RESULT_TIMEOUT] = task_result_timeout\n        task.props[_KEY_FINISHED_TARGETS] = {}  # target name => times sent\n        task.props[_KEY_PENDING_CLIENT] = None",
  "def check_task_send(self, client_task: ClientTask, fl_ctx: FLContext) -> TaskCheckStatus:\n        \"\"\"Determine whether the task should be sent to the client.\n\n        Args:\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n\n        Raises:\n            RuntimeError: when a client asking for a task while the same client_task has already been dispatched to it\n\n        Returns:\n            TaskCheckStatus: NO_BLOCK for not sending the task, BLOCK for waiting, SEND for OK to send\n        \"\"\"\n        client_name = client_task.client.name\n        task = client_task.task\n        if task.props[_KEY_DYNAMIC_TARGETS]:\n            if task.targets is None:\n                task.targets = []\n            if client_name not in task.targets:\n                task.targets.append(client_name)\n\n        # is this client eligible?\n        if client_name not in task.targets:\n            # this client is not a target\n            return TaskCheckStatus.NO_BLOCK\n\n        client_occurrences = task.targets.count(client_name)\n        finished_targets = task.props[_KEY_FINISHED_TARGETS]\n        send_count = finished_targets.get(client_name, 0)\n        if send_count >= client_occurrences:\n            # already sent enough times to this client\n            return TaskCheckStatus.NO_BLOCK\n\n        # only allow one pending task. Is there a client pending result?\n        pending_client_name = task.props[_KEY_PENDING_CLIENT]\n        task_result_timeout = task.props[_KEY_TASK_RESULT_TIMEOUT]\n        if pending_client_name is not None:\n            # see whether the result has been received\n            pending_task = task.last_client_task_map[pending_client_name]\n            if pending_task.result_received_time is None:\n                # result has not been received\n                # Note: in this case, the pending client and the asking client must not be the\n                # same, because this would be a resend case already taken care of by the controller.\n                if pending_client_name == client_name:\n                    raise RuntimeError(\"Logic Error: must not be here for client {}\".format(client_name))\n\n                # should this client timeout?\n                if task_result_timeout and time.time() - pending_task.task_sent_time > task_result_timeout:\n                    # timeout!\n                    # give up on the pending task and move to the next target\n                    finished_targets[pending_client_name] -= 1\n                    pass\n                else:\n                    # continue to wait\n                    return TaskCheckStatus.BLOCK\n\n        # can send\n        task.props[_KEY_PENDING_CLIENT] = client_name\n        finished_targets[client_name] = send_count + 1\n        return TaskCheckStatus.SEND",
  "def check_task_exit(self, task: Task) -> Tuple[bool, TaskCompletionStatus]:\n        \"\"\"Determine whether the task should exit.\n\n        Args:\n            task (Task): an instance of Task\n\n        Returns:\n            Tuple[bool, TaskCompletionStatus]:\n                first entry in the tuple means whether to exit the task or not.  If it's True, the task should exit.\n                second entry in the tuple indicates the TaskCompletionStatus.\n        \"\"\"\n        # are we waiting for any client?\n        num_targets = 0 if task.targets is None else len(task.targets)\n        if num_targets == 0:\n            # nothing has been sent\n            return False, TaskCompletionStatus.IGNORED\n\n        # see whether all targets are done\n        finished_targets = task.props[_KEY_FINISHED_TARGETS]\n\n        total_sent = 0\n        for v in finished_targets.values():\n            total_sent += v\n\n        if total_sent < num_targets:\n            return False, TaskCompletionStatus.IGNORED\n\n        for c_t in task.client_tasks:\n            if c_t.result_received_time is None:\n                return False, TaskCompletionStatus.IGNORED\n\n        return True, TaskCompletionStatus.OK",
  "def check_task_result(self, result: Shareable, client_task: ClientTask, fl_ctx: FLContext):\n        \"\"\"Check the result received from the client.\n\n        See whether the client_task is the last one in the task's list\n        If not, then it is a late response and ReservedHeaderKey.REPLY_IS_LATE is\n        set to True in result's header.\n\n        Args:\n            result (Shareable): an instance of Shareable\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n        \"\"\"\n        task = client_task.task\n        if client_task != task.client_tasks[-1]:\n            result.set_header(key=ReservedHeaderKey.REPLY_IS_LATE, value=True)",
  "def _check_positive_int(name, value):\n    if not isinstance(value, int):\n        raise TypeError(\"{} must be an instance of int, but got {}.\".format(name, type(name)))\n    if value < 0:\n        raise ValueError(\"{} must >= 0.\".format(name))",
  "def _check_inputs(task: Task, fl_ctx: FLContext, targets: Union[List[Client], List[str], None]):\n    if not isinstance(task, Task):\n        raise TypeError(\"task must be an instance of Task, but got {}\".format(type(task)))\n\n    if not isinstance(fl_ctx, FLContext):\n        raise TypeError(\"fl_ctx must be an instance of FLContext, but got {}\".format(type(fl_ctx)))\n\n    if targets is not None:\n        if not isinstance(targets, list):\n            raise TypeError(\"targets must be a list of Client or string, but got {}\".format(type(targets)))\n\n        for t in targets:\n            if not isinstance(t, (Client, str)):\n                raise TypeError(\n                    \"targets must be a list of Client or string, but got element of type {}\".format(type(t))\n                )",
  "class Controller(Responder, ControllerSpec, ABC):\n    def __init__(self, task_check_period=0.5):\n        \"\"\"Manage life cycles of tasks and their destinations.\n\n        Args:\n            task_check_period (float, optional): interval for checking status of tasks. Defaults to 0.5.\n        \"\"\"\n        Responder.__init__(self)\n        self._engine = None\n        self._tasks = []  # list of standing tasks\n        self._client_task_map = {}  # client_task_id => client_task\n        self._all_done = False\n        self._task_lock = Lock()\n        self._task_monitor = threading.Thread(target=self._monitor_tasks, args=())\n        self._task_check_period = task_check_period\n\n    def initialize_run(self, fl_ctx: FLContext):\n        \"\"\"Called by runners to initialize controller with information in fl_ctx.\n\n        Note: Controller subclasses must not overwrite this method.\n\n        Args:\n            fl_ctx (FLContext): FLContext information\n        \"\"\"\n        self._engine = fl_ctx.get_engine()\n        self.start_controller(fl_ctx)\n        self._task_monitor.start()\n\n    def _try_again(self) -> Tuple[str, str, Shareable]:\n        # TODO: how to tell client no shareable available now?\n        return \"\", \"\", None\n\n    def _set_stats(self, fl_ctx: FLContext):\n        \"\"\"Called to set stats into InfoCollector.\n\n        Args:\n            fl_ctx (FLContext): info collector is retrieved from fl_ctx with InfoCollector.CTX_KEY_STATS_COLLECTOR key\n        \"\"\"\n        collector = fl_ctx.get_prop(InfoCollector.CTX_KEY_STATS_COLLECTOR, None)\n        if collector:\n            if not isinstance(collector, GroupInfoCollector):\n                raise TypeError(\n                    \"collector must be an instance of GroupInfoCollector, but got {}\".format(type(collector))\n                )\n            collector.set_info(\n                group_name=self._name,\n                info={\n                    \"tasks\": {t.name: [ct.client.name for ct in t.client_tasks] for t in self._tasks},\n                },\n            )\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        \"\"\"Called when events are fired.\n\n        Args:\n            event_type (str): all event types, including AppEventType and EventType\n            fl_ctx (FLContext): FLContext information with current event type\n        \"\"\"\n        if event_type == InfoCollector.EVENT_TYPE_GET_STATS:\n            self._set_stats(fl_ctx)\n\n    def process_task_request(self, client: Client, fl_ctx: FLContext) -> Tuple[str, str, Shareable]:\n        \"\"\"Called by runner when a client asks for a task.\n\n        Note: this is called in a separate thread.\n\n        Args:\n            client (Client): The record of one client requesting tasks\n            fl_ctx (FLContext): The FLContext associated with this request\n\n        Raises:\n            TypeError: when client is not an instance of Client\n            TypeError: when fl_ctx is not an instance of FLContext\n            TypeError: when any standing task containing an invalid client_task\n\n        Returns:\n            Tuple[str, str, Shareable]: task_name, an id for the client_task, and the data for this requst\n        \"\"\"\n        if not isinstance(client, Client):\n            raise TypeError(\"client must be an instance of Client, but got {}\".format(type(client)))\n        if not isinstance(fl_ctx, FLContext):\n            raise TypeError(\"fl_ctx must be an instance of FLContext, but got {}\".format(type(fl_ctx)))\n\n        client_task_to_send = None\n        with self._task_lock:\n            self.logger.debug(\"self._tasks: {}\".format(self._tasks))\n            for task in self._tasks:\n                if task.completion_status is not None:\n                    # this task is finished (and waiting for the monitor to exit it)\n                    continue\n\n                # do we need to send this task to this client?\n                # note: the task could be sent to a client multiple times (e.g. in relay)\n                # we only check the last ClientTask sent to the client\n                client_task_to_check = task.last_client_task_map.get(client.name, None)\n                self.logger.debug(\"client_task_to_check: {}\".format(client_task_to_check))\n                resend_task = False\n\n                if client_task_to_check is not None:\n                    # this client has been sent the task already\n                    if not isinstance(client_task_to_check, ClientTask):\n                        raise TypeError(\n                            \"client_task_to_check must be an instance of ClientTask, but got {}\".format(\n                                type(client_task_to_check)\n                            )\n                        )\n                    if client_task_to_check.result_received_time is None:\n                        # controller has not received result from client\n                        # something wrong happens when client working on this task, so resend the task\n                        resend_task = True\n                        client_task_to_send = client_task_to_check\n                        fl_ctx.set_prop(FLContextKey.IS_CLIENT_TASK_RESEND, True, sticky=False)\n\n                if not resend_task:\n                    # check with the task manager whether to send\n                    manager = task.props[_TASK_KEY_MANAGER]\n                    if client_task_to_check is None:\n                        client_task_to_check = ClientTask(task=task, client=client)\n                    check_status = manager.check_task_send(client_task_to_check, fl_ctx)\n                    self.logger.debug(\n                        \"Checking client task: {}, task.client.name: {}\".format(\n                            client_task_to_check, client_task_to_check.client.name\n                        )\n                    )\n                    self.logger.debug(\"Check task send get check_status: {}\".format(check_status))\n                    if check_status == TaskCheckStatus.BLOCK:\n                        # do not send this task, and do not check other tasks\n                        return self._try_again()\n                    elif check_status == TaskCheckStatus.NO_BLOCK:\n                        # do not send this task, but continue to check next task\n                        continue\n                    else:\n                        # send the task and remember the client_task\n                        client_task_to_send = ClientTask(client, task)\n                        task.last_client_task_map[client.name] = client_task_to_send\n                        task.client_tasks.append(client_task_to_send)\n                        self._client_task_map[client_task_to_send.id] = client_task_to_send\n                        break\n\n        # NOTE: move task sending process outside the lock\n        # This is to minimize the locking time and to avoid potential deadlock:\n        # the CB could schedule another task, which requires lock\n        self.logger.debug(\"Determining based on client_task_to_send: {}\".format(client_task_to_send))\n        if client_task_to_send is None:\n            # no task available for this client\n            return self._try_again()\n\n        # try to send the task\n        can_send_task = True\n        task = client_task_to_send.task\n        with task.cb_lock:\n            # Note: must guarantee the after_task_sent_cb is always called\n            # regardless whether the task is sent successfully.\n            # This is so that the app could clear up things in after_task_sent_cb.\n            if task.before_task_sent_cb is not None:\n                try:\n                    task.before_task_sent_cb(client_task=client_task_to_send, fl_ctx=fl_ctx)\n                except WorkflowError as ex:\n                    self._engine.ask_to_stop()\n                    self.log_exception(\n                        fl_ctx,\n                        \"processing error in before_task_sent_cb on task {} ({}): {}\".format(\n                            client_task_to_send.task.name, client_task_to_send.id, ex\n                        ),\n                    )\n                    task.completion_status = TaskCompletionStatus.ERROR\n                    task.exception = ex\n                except BaseException as ex:\n                    self.log_exception(\n                        fl_ctx,\n                        \"processing error in before_task_sent_cb on task {} ({}): {}\".format(\n                            client_task_to_send.task.name, client_task_to_send.id, ex\n                        ),\n                    )\n                    # this task cannot proceed anymore\n                    task.completion_status = TaskCompletionStatus.ERROR\n                    task.exception = ex\n\n            self.logger.debug(\"before_task_sent_cb done on client_task_to_send: {}\".format(client_task_to_send))\n            self.logger.debug(f\"task completion status is {task.completion_status}\")\n\n            if task.completion_status is not None:\n                can_send_task = False\n\n            # remember the task name and data to be sent to the client\n            # since task.data could be reset by the after_task_sent_cb\n            task_name = task.name\n            task_data = task.data\n\n            if task.after_task_sent_cb is not None:\n                try:\n                    task.after_task_sent_cb(client_task=client_task_to_send, fl_ctx=fl_ctx)\n                except WorkflowError as ex:\n                    self._engine.ask_to_stop()\n                    self.log_exception(\n                        fl_ctx,\n                        \"processing error in after_task_sent_cb on task {} ({}): {}\".format(\n                            client_task_to_send.task.name, client_task_to_send.id, ex\n                        ),\n                    )\n                    task.completion_status = TaskCompletionStatus.ERROR\n                    task.exception = ex\n                except BaseException as ex:\n                    self.log_exception(\n                        fl_ctx,\n                        \"processing error in after_task_sent_cb on task {} ({}): {}\".format(\n                            client_task_to_send.task.name, client_task_to_send.id, ex\n                        ),\n                    )\n                    task.completion_status = TaskCompletionStatus.ERROR\n                    task.exception = ex\n\n            if task.completion_status is not None:\n                # NOTE: the CB could cancel the task\n                can_send_task = False\n\n            if not can_send_task:\n                return self._try_again()\n\n            self.logger.debug(\"after_task_sent_cb done on client_task_to_send: {}\".format(client_task_to_send))\n\n            client_task_to_send.task_sent_time = time.time()\n            client_task_to_send.task_send_count += 1\n            return task_name, client_task_to_send.id, task_data\n\n    def handle_exception(self, task_id: str, fl_ctx: FLContext) -> None:\n        \"\"\"Called to cancel one task as its client_task is causing exception at upper level.\n\n        Args:\n            task_id (str): an id to the failing client_task\n            fl_ctx (FLContext): FLContext associated with this client_task\n        \"\"\"\n        with self._task_lock:\n            # task_id is the uuid associated with the client_task\n            client_task = self._client_task_map.get(task_id, None)\n            self.logger.debug(\"Handle exception on client_task {} with id {}\".format(client_task, task_id))\n\n        if client_task is None:\n            # cannot find a standing task on the exception\n            return\n\n        task = client_task.task\n        self.cancel_task(task=task, fl_ctx=fl_ctx)\n        self.log_error(fl_ctx, \"task {} is cancelled due to exception\".format(task.name))\n\n    def process_submission(self, client: Client, task_name: str, task_id: str, result: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process a submission from one client.\n\n        Note: this method is called by a separate thread.\n\n        Args:\n            client (Client): the client that submitted this task\n            task_name (str): the task name associated this submission\n            task_id (str): the id associated with the client_task\n            result (Shareable): the actual submitted data from the client\n            fl_ctx (FLContext): the FLContext associated with this submission\n\n        Raises:\n            TypeError: when client is not an instance of Client\n            TypeError: when fl_ctx is not an instance of FLContext\n            TypeError: when result is not an instance of Shareable\n            ValueError: task_name is not found in the client_task\n        \"\"\"\n        if not isinstance(client, Client):\n            raise TypeError(\"client must be an instance of Client, but got {}\".format(type(client)))\n        if not isinstance(fl_ctx, FLContext):\n            raise TypeError(\"fl_ctx must be an instance of FLContext, but got {}\".format(type(fl_ctx)))\n        if not isinstance(result, Shareable):\n            raise TypeError(\"result must be an instance of Shareable, but got {}\".format(type(result)))\n\n        with self._task_lock:\n            # task_id is the uuid associated with the client_task\n            client_task = self._client_task_map.get(task_id, None)\n            self.logger.debug(\"Get submission={} from client task={} id={}\".format(result, client_task, task_id))\n\n        if client_task is None:\n            # cannot find a standing task for the submission\n            self.log_info(fl_ctx, \"no standing task found for {}:{}\".format(task_name, task_id))\n            self.process_result_of_unknown_task(client, task_name, task_id, result, fl_ctx)\n            return\n\n        task = client_task.task\n        with task.cb_lock:\n            if task.name != task_name:\n                raise ValueError(\"client specified task name {} doesn't match {}\".format(task_name, task.name))\n\n            if task.completion_status is not None:\n                # the task is already finished - drop the result\n                self.log_info(fl_ctx, \"task is already finished - submission dropped\")\n                return\n\n            # do client task CB processing outside the lock\n            # this is because the CB could schedule another task, which requires the lock\n            client_task.result = result\n            client_task.result_received_time = time.time()\n\n            manager = task.props[_TASK_KEY_MANAGER]\n            manager.check_task_result(result, client_task, fl_ctx)\n\n            if task.result_received_cb is not None:\n                try:\n                    self.log_info(fl_ctx, \"invoking result_received_cb ...\")\n                    task.result_received_cb(client_task=client_task, fl_ctx=fl_ctx)\n                except WorkflowError as ex:\n                    self._engine.ask_to_stop()\n                    self.log_exception(\n                        fl_ctx,\n                        \"processing error in result_received_cb on task {}({}): {}\".format(task_name, task_id, ex),\n                    )\n                    task.completion_status = TaskCompletionStatus.ERROR\n                    task.exception = ex\n                    return\n                except BaseException as ex:\n                    # this task cannot proceed anymore\n                    self.log_exception(\n                        fl_ctx,\n                        \"processing error in result_received_cb on task {}({}): {}\".format(task_name, task_id, ex),\n                    )\n                    task.completion_status = TaskCompletionStatus.ERROR\n                    task.exception = ex\n                    return\n            else:\n                self.log_info(fl_ctx, \"no result_received_cb\")\n\n    def _schedule_task(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        manager: TaskManager,\n        targets: Union[List[Client], List[str], None],\n        allow_dup_targets: bool = False,\n    ):\n        if task.schedule_time is not None:\n            # this task was scheduled before\n            # we do not allow a task object to be reused\n            self.logger.debug(\"task.schedule_time: {}\".format(task.schedule_time))\n            raise ValueError(\"Task was already used. Please create a new task object.\")\n\n        task.targets = targets\n        if targets is not None:\n            target_names = list()\n            if not isinstance(targets, list):\n                raise ValueError(\"task targets must be a list, but got {}\".format(type(targets)))\n            for t in targets:\n                if isinstance(t, str):\n                    name = t\n                elif isinstance(t, Client):\n                    name = t.name\n                else:\n                    raise ValueError(\"element in targets must be string or Client type, but got {}\".format(type(t)))\n\n                if allow_dup_targets or (name not in target_names):\n                    target_names.append(name)\n            task.targets = target_names\n\n        task.props[_TASK_KEY_MANAGER] = manager\n        task.props[_TASK_KEY_ENGINE] = fl_ctx.get_engine()\n        task.is_standing = True\n        task.schedule_time = time.time()\n\n        with self._task_lock:\n            self._tasks.append(task)\n            self.log_info(fl_ctx, \"scheduled task {}\".format(task.name))\n\n    def broadcast(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        min_responses: int = 1,\n        wait_time_after_min_received: int = 0,\n    ):\n        \"\"\"Schedule a broadcast task.  This is a non-blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n            min_responses (int, optional): the condition to mark this task as completed because enough clients respond with submission. Defaults to 1.\n            wait_time_after_min_received (int, optional): a grace period for late clients to contribute their submission.  0 means no grace period.\n              Submission of late clients in the grace period are still collected as valid submission. Defaults to 0.\n\n        Raises:\n            ValueError: min_responses is greater than the length of targets since this condition will make the task, if allowed to be scheduled, never exit.\n        \"\"\"\n        _check_inputs(task=task, fl_ctx=fl_ctx, targets=targets)\n        _check_positive_int(\"min_responses\", min_responses)\n        _check_positive_int(\"wait_time_after_min_received\", wait_time_after_min_received)\n        if targets and min_responses > len(targets):\n            raise ValueError(\n                \"min_responses ({}) must be less than length of targets ({}).\".format(min_responses, len(targets))\n            )\n\n        manager = BcastTaskManager(\n            task=task, min_responses=min_responses, wait_time_after_min_received=wait_time_after_min_received\n        )\n        self._schedule_task(task=task, fl_ctx=fl_ctx, manager=manager, targets=targets)\n\n    def broadcast_and_wait(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        min_responses: int = 1,\n        wait_time_after_min_received: int = 0,\n        abort_signal: Optional[Signal] = None,\n    ):\n        \"\"\"Schedule a broadcast task.  This is a blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n            min_responses (int, optional): the condition to mark this task as completed because enough clients respond with submission. Defaults to 1.\n            wait_time_after_min_received (int, optional): a grace period for late clients to contribute their submission.  0 means no grace period.\n            Submission of late clients in the grace period are still collected as valid submission. Defaults to 0.\n            abort_signal (Optional[Signal], optional): as this is a blocking call, this abort_signal informs this method to return. Defaults to None.\n        \"\"\"\n        self.broadcast(\n            task=task,\n            fl_ctx=fl_ctx,\n            targets=targets,\n            min_responses=min_responses,\n            wait_time_after_min_received=wait_time_after_min_received,\n        )\n        self._wait_for_task(task, abort_signal)\n\n    def broadcast_forever(self, task: Task, fl_ctx: FLContext, targets: Union[List[Client], List[str], None] = None):\n        \"\"\"Schedule a broadcast task.  This is a non-blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients.\n        This broadcast will not end.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n        \"\"\"\n        _check_inputs(task=task, fl_ctx=fl_ctx, targets=targets)\n        manager = BcastForeverTaskManager()\n        self._schedule_task(task=task, fl_ctx=fl_ctx, manager=manager, targets=targets)\n\n    def send(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order: SendOrder = SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n    ):\n        \"\"\"Schedule a single task to targets.  This is a non-blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients based on the send_order.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n            send_order (SendOrder, optional): the order for clients to become eligible.  SEQUENTIAL means the order in targets is enforced.  ANY means\n            clients in targets and haven't received task are eligible for task. Defaults to SendOrder.SEQUENTIAL.\n            task_assignment_timeout (int, optional): how long to wait for one client to pick the task. Defaults to 0.\n\n        Raises:\n            ValueError: when task_assignment_timeout is greater than task's timeout.\n            TypeError: send_order is not defined in SendOrder\n            ValueError: targets is None or an empty list\n        \"\"\"\n        _check_inputs(\n            task=task,\n            fl_ctx=fl_ctx,\n            targets=targets,\n        )\n        _check_positive_int(\"task_assignment_timeout\", task_assignment_timeout)\n        if task.timeout and task_assignment_timeout and task_assignment_timeout > task.timeout:\n            raise ValueError(\n                \"task_assignment_timeout ({}) needs to be less than or equal to task.timeout ({}).\".format(\n                    task_assignment_timeout, task.timeout\n                )\n            )\n        if not isinstance(send_order, SendOrder):\n            raise TypeError(\"send_order must be in Enum SendOrder, but got {}\".format(type(send_order)))\n\n        # targets must be provided\n        if targets is None or len(targets) == 0:\n            raise ValueError(\"Targets must be provided for send.\")\n\n        manager = SendTaskManager(task, send_order, task_assignment_timeout)\n        self._schedule_task(\n            task=task,\n            fl_ctx=fl_ctx,\n            manager=manager,\n            targets=targets,\n        )\n\n    def send_and_wait(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order: SendOrder = SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n        abort_signal: Signal = None,\n    ):\n        \"\"\"Schedule a single task to targets.  This is a blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients based on the send_order.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n            send_order (SendOrder, optional): the order for clients to become eligible.  SEQUENTIAL means the order in targets is enforced.  ANY means\n            clients in targets and haven't received task are eligible for task. Defaults to SendOrder.SEQUENTIAL.\n            task_assignment_timeout (int, optional): how long to wait for one client to pick the task. Defaults to 0.\n            abort_signal (Optional[Signal], optional): as this is a blocking call, this abort_signal informs this method to return. Defaults to None.\n\n        \"\"\"\n        self.send(\n            task=task,\n            fl_ctx=fl_ctx,\n            targets=targets,\n            send_order=send_order,\n            task_assignment_timeout=task_assignment_timeout,\n        )\n        self._wait_for_task(task, abort_signal)\n\n    def get_num_standing_tasks(self) -> int:\n        \"\"\"Get the number of tasks that are currently standing.\n\n        Returns:\n            int: length of the list of standing tasks\n        \"\"\"\n        return len(self._tasks)\n\n    def cancel_task(\n        self, task: Task, completion_status=TaskCompletionStatus.CANCELLED, fl_ctx: Optional[FLContext] = None\n    ):\n        \"\"\"Cancel the specified task.\n\n        Change the task completion_status, which will inform task monitor to clean up this task\n        NOTE: we only mark the task as completed and leave it to the task monitor to clean up\n        This is to avoid potential dead lock of task_lock\n\n        Args:\n            task (Task): the task to be cancelled\n            completion_status (str, optional): the completion status for this cancellation. Defaults to TaskCompletionStatus.CANCELLED.\n            fl_ctx (Optional[FLContext], optional): FLContext associated with this cancellation. Defaults to None.\n        \"\"\"\n        task.completion_status = completion_status\n\n    def cancel_all_tasks(self, completion_status=TaskCompletionStatus.CANCELLED, fl_ctx: Optional[FLContext] = None):\n        \"\"\"Cancel all standing tasks in this controller.\n\n        Args:\n            completion_status (str, optional): the completion status for this cancellation. Defaults to TaskCompletionStatus.CANCELLED.\n            fl_ctx (Optional[FLContext], optional): FLContext associated with this cancellation. Defaults to None.\n        \"\"\"\n        with self._task_lock:\n            for t in self._tasks:\n                t.completion_status = completion_status\n\n    def abort_task(self, task, fl_ctx: FLContext):\n        \"\"\"Ask all clients to abort the execution of the specified task.\n\n        Args:\n            task (str): the task to be aborted\n            fl_ctx (FLContext): FLContext associated with this action\n        \"\"\"\n        self.log_info(fl_ctx, \"asked all clients to abort task {}\".format(task.name))\n        self._end_task([task.name], fl_ctx)\n\n    def _end_task(self, task_names, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ServerEngineSpec):\n            raise TypeError(\"engine should be an instance of ServerEngineSpec, but got {}\".format(type(engine)))\n        request = Shareable()\n        request[\"task_names\"] = task_names\n        engine.send_aux_request(targets=None, topic=ReservedTopic.ABORT_ASK, request=request, timeout=0, fl_ctx=fl_ctx)\n\n    def abort_all_tasks(self, fl_ctx: FLContext):\n        \"\"\"Ask clients to abort the execution of all tasks.\n\n        NOTE: the server should send a notification to all clients, regardless of whether the server\n        has any standing tasks.\n\n        Args:\n            fl_ctx (FLContext): FLContext associated with this action\n        \"\"\"\n        self._end_task([], fl_ctx)\n\n    def finalize_run(self, fl_ctx: FLContext):\n        \"\"\"Do cleanup of the coordinator implementation.\n\n        NOTE: subclass controllers should not overwrite finalize_run.\n\n        Args:\n            fl_ctx (FLContext): FLContext associated with this action\n        \"\"\"\n        self.cancel_all_tasks()  # unconditionally cancel all tasks\n        self._all_done = True\n        try:\n            if self._task_monitor.is_alive():\n                self._task_monitor.join()\n        except RuntimeError:\n            self.log_debug(fl_ctx, \"unable to join monitor thread (not started?)\")\n        self.stop_controller(fl_ctx)\n\n    def relay(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order: SendOrder = SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n        task_result_timeout: int = 0,\n        dynamic_targets: bool = True,\n    ):\n        \"\"\"Schedule a single task to targets in one-after-another style.  This is a non-blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients based on the send_order.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n            send_order (SendOrder, optional): the order for clients to become eligible.\n              SEQUENTIAL means the order in targets is enforced.\n              ANY means any clients that are inside the targets and haven't received the task are eligible. Defaults to SendOrder.SEQUENTIAL.\n            task_assignment_timeout (int, optional): how long to wait for one client to pick the task. Defaults to 0.\n            task_result_timeout (int, optional): how long to wait for current working client to reply its result. Defaults to 0.\n            dynamic_targets (bool, optional): allow clients not in targets to join at the end of targets list. Defaults to True.\n\n        Raises:\n            ValueError: when task_assignment_timeout is greater than task's timeout\n            ValueError: when task_result_timeout is greater than task's timeout\n            TypeError: send_order is not defined in SendOrder\n            TypeError: when dynamic_targets is not a boolean variable\n            ValueError: targets is None or an empty list but dynamic_targets is False\n        \"\"\"\n        _check_inputs(\n            task=task,\n            fl_ctx=fl_ctx,\n            targets=targets,\n        )\n        _check_positive_int(\"task_assignment_timeout\", task_assignment_timeout)\n        _check_positive_int(\"task_result_timeout\", task_result_timeout)\n        if task.timeout and task_assignment_timeout and task_assignment_timeout > task.timeout:\n            raise ValueError(\n                \"task_assignment_timeout ({}) needs to be less than or equal to task.timeout ({}).\".format(\n                    task_assignment_timeout, task.timeout\n                )\n            )\n        if task.timeout and task_result_timeout and task_result_timeout > task.timeout:\n            raise ValueError(\n                \"task_result_timeout ({}) needs to be less than or equal to task.timeout ({}).\".format(\n                    task_result_timeout, task.timeout\n                )\n            )\n        if not isinstance(send_order, SendOrder):\n            raise TypeError(\"send_order must be in Enum SendOrder, but got {}\".format(type(send_order)))\n        if not isinstance(dynamic_targets, bool):\n            raise TypeError(\"dynamic_targets must be an instance of bool, but got {}\".format(type(dynamic_targets)))\n        if targets is None and dynamic_targets is False:\n            raise ValueError(\"Need to provide targets when dynamic_targets is set to False.\")\n\n        if send_order == SendOrder.SEQUENTIAL:\n            manager = SequentialRelayTaskManager(\n                task=task,\n                task_assignment_timeout=task_assignment_timeout,\n                task_result_timeout=task_result_timeout,\n                dynamic_targets=dynamic_targets,\n            )\n        else:\n            manager = AnyRelayTaskManager(\n                task=task, task_result_timeout=task_result_timeout, dynamic_targets=dynamic_targets\n            )\n\n        self._schedule_task(\n            task=task,\n            fl_ctx=fl_ctx,\n            manager=manager,\n            targets=targets,\n            allow_dup_targets=True,\n        )\n\n    def relay_and_wait(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order=SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n        task_result_timeout: int = 0,\n        dynamic_targets: bool = True,\n        abort_signal: Optional[Signal] = None,\n    ):\n        \"\"\"Schedule a single task to targets in one-after-another style.  This is a blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients based on the send_order.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n            send_order (SendOrder, optional): the order for clients to become eligible.  SEQUENTIAL means the order in targets is enforced.  ANY means\n            clients in targets and haven't received task are eligible for task. Defaults to SendOrder.SEQUENTIAL.\n            task_assignment_timeout (int, optional): how long to wait for one client to pick the task. Defaults to 0.\n            task_result_timeout (int, optional): how long to wait for current working client to reply its result. Defaults to 0.\n            dynamic_targets (bool, optional): allow clients not in targets to join at the end of targets list. Defaults to True.\n            abort_signal (Optional[Signal], optional): as this is a blocking call, this abort_signal informs this method to return. Defaults to None.\n        \"\"\"\n        self.relay(\n            task=task,\n            fl_ctx=fl_ctx,\n            targets=targets,\n            send_order=send_order,\n            task_assignment_timeout=task_assignment_timeout,\n            task_result_timeout=task_result_timeout,\n            dynamic_targets=dynamic_targets,\n        )\n        self._wait_for_task(task, abort_signal)\n\n    def _monitor_tasks(self):\n        while not self._all_done:\n            self._check_tasks()\n            time.sleep(self._task_check_period)\n\n    def _check_tasks(self):\n        exit_tasks = []\n        with self._task_lock:\n            for task in self._tasks:\n                if task.completion_status is not None:\n                    exit_tasks.append(task)\n                    continue\n\n                # check the task-specific exit condition\n                manager = task.props[_TASK_KEY_MANAGER]\n                if manager is not None:\n                    if not isinstance(manager, TaskManager):\n                        raise TypeError(\n                            \"manager in task must be an instance of TaskManager, but got {}\".format(manager)\n                        )\n                    should_exit, exit_status = manager.check_task_exit(task)\n                    self.logger.debug(\"should_exit: {}, exit_status: {}\".format(should_exit, exit_status))\n                    if should_exit:\n                        task.completion_status = exit_status\n                        exit_tasks.append(task)\n                        continue\n\n                # check if task timeout\n                if task.timeout and time.time() - task.schedule_time >= task.timeout:\n                    task.completion_status = TaskCompletionStatus.TIMEOUT\n                    exit_tasks.append(task)\n                    continue\n\n            for exit_task in exit_tasks:\n                exit_task.is_standing = False\n                self.logger.debug(\n                    \"Removing task={}, completion_status={}\".format(exit_task, exit_task.completion_status)\n                )\n                self._tasks.remove(exit_task)\n                for client_task in exit_task.client_tasks:\n                    self.logger.debug(\"Removing client_task with id={}\".format(client_task.id))\n                    self._client_task_map.pop(client_task.id)\n\n        # do the task exit processing outside the lock to minimize the locking time\n        # and to avoid potential deadlock since the CB could schedule another task\n        if len(exit_tasks) <= 0:\n            return\n\n        with self._engine.new_context() as fl_ctx:\n            for exit_task in exit_tasks:\n                with exit_task.cb_lock:\n                    self.log_info(\n                        fl_ctx, \"task {} exit with status {}\".format(exit_task.name, exit_task.completion_status)\n                    )\n\n                    if exit_task.task_done_cb is not None:\n                        try:\n                            exit_task.task_done_cb(task=exit_task, fl_ctx=fl_ctx)\n                        except WorkflowError as ex:\n                            self._engine.ask_to_stop()\n                            self.log_exception(\n                                fl_ctx,\n                                \"processing error in task_done_cb error on task {}: {}\".format(exit_task.name, ex),\n                            )\n                            task.completion_status = TaskCompletionStatus.ERROR\n                            task.exception = ex\n                        except BaseException as ex:\n                            self.log_exception(\n                                fl_ctx,\n                                \"processing error in task_done_cb error on task {}: {}\".format(exit_task.name, ex),\n                            )\n                            exit_task.completion_status = TaskCompletionStatus.ERROR\n                            exit_task.exception = ex\n\n    @staticmethod\n    def _process_finished_task(task, func):\n        def wrap(*args, **kwargs):\n            if func:\n                func(*args, **kwargs)\n            task.props[_TASK_KEY_DONE] = True\n\n        return wrap\n\n    def _wait_for_task(self, task: Task, abort_signal: Signal):\n        task.props[_TASK_KEY_DONE] = False\n        task.task_done_cb = self._process_finished_task(task=task, func=task.task_done_cb)\n        while True:\n            if task.completion_status is not None:\n                break\n\n            if abort_signal and abort_signal.triggered:\n                self.cancel_task(task, fl_ctx=None, completion_status=TaskCompletionStatus.ABORTED)\n                break\n\n            task_done = task.props[_TASK_KEY_DONE]\n            if task_done:\n                break\n            time.sleep(self._task_check_period)",
  "def __init__(self, task_check_period=0.5):\n        \"\"\"Manage life cycles of tasks and their destinations.\n\n        Args:\n            task_check_period (float, optional): interval for checking status of tasks. Defaults to 0.5.\n        \"\"\"\n        Responder.__init__(self)\n        self._engine = None\n        self._tasks = []  # list of standing tasks\n        self._client_task_map = {}  # client_task_id => client_task\n        self._all_done = False\n        self._task_lock = Lock()\n        self._task_monitor = threading.Thread(target=self._monitor_tasks, args=())\n        self._task_check_period = task_check_period",
  "def initialize_run(self, fl_ctx: FLContext):\n        \"\"\"Called by runners to initialize controller with information in fl_ctx.\n\n        Note: Controller subclasses must not overwrite this method.\n\n        Args:\n            fl_ctx (FLContext): FLContext information\n        \"\"\"\n        self._engine = fl_ctx.get_engine()\n        self.start_controller(fl_ctx)\n        self._task_monitor.start()",
  "def _try_again(self) -> Tuple[str, str, Shareable]:\n        # TODO: how to tell client no shareable available now?\n        return \"\", \"\", None",
  "def _set_stats(self, fl_ctx: FLContext):\n        \"\"\"Called to set stats into InfoCollector.\n\n        Args:\n            fl_ctx (FLContext): info collector is retrieved from fl_ctx with InfoCollector.CTX_KEY_STATS_COLLECTOR key\n        \"\"\"\n        collector = fl_ctx.get_prop(InfoCollector.CTX_KEY_STATS_COLLECTOR, None)\n        if collector:\n            if not isinstance(collector, GroupInfoCollector):\n                raise TypeError(\n                    \"collector must be an instance of GroupInfoCollector, but got {}\".format(type(collector))\n                )\n            collector.set_info(\n                group_name=self._name,\n                info={\n                    \"tasks\": {t.name: [ct.client.name for ct in t.client_tasks] for t in self._tasks},\n                },\n            )",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        \"\"\"Called when events are fired.\n\n        Args:\n            event_type (str): all event types, including AppEventType and EventType\n            fl_ctx (FLContext): FLContext information with current event type\n        \"\"\"\n        if event_type == InfoCollector.EVENT_TYPE_GET_STATS:\n            self._set_stats(fl_ctx)",
  "def process_task_request(self, client: Client, fl_ctx: FLContext) -> Tuple[str, str, Shareable]:\n        \"\"\"Called by runner when a client asks for a task.\n\n        Note: this is called in a separate thread.\n\n        Args:\n            client (Client): The record of one client requesting tasks\n            fl_ctx (FLContext): The FLContext associated with this request\n\n        Raises:\n            TypeError: when client is not an instance of Client\n            TypeError: when fl_ctx is not an instance of FLContext\n            TypeError: when any standing task containing an invalid client_task\n\n        Returns:\n            Tuple[str, str, Shareable]: task_name, an id for the client_task, and the data for this requst\n        \"\"\"\n        if not isinstance(client, Client):\n            raise TypeError(\"client must be an instance of Client, but got {}\".format(type(client)))\n        if not isinstance(fl_ctx, FLContext):\n            raise TypeError(\"fl_ctx must be an instance of FLContext, but got {}\".format(type(fl_ctx)))\n\n        client_task_to_send = None\n        with self._task_lock:\n            self.logger.debug(\"self._tasks: {}\".format(self._tasks))\n            for task in self._tasks:\n                if task.completion_status is not None:\n                    # this task is finished (and waiting for the monitor to exit it)\n                    continue\n\n                # do we need to send this task to this client?\n                # note: the task could be sent to a client multiple times (e.g. in relay)\n                # we only check the last ClientTask sent to the client\n                client_task_to_check = task.last_client_task_map.get(client.name, None)\n                self.logger.debug(\"client_task_to_check: {}\".format(client_task_to_check))\n                resend_task = False\n\n                if client_task_to_check is not None:\n                    # this client has been sent the task already\n                    if not isinstance(client_task_to_check, ClientTask):\n                        raise TypeError(\n                            \"client_task_to_check must be an instance of ClientTask, but got {}\".format(\n                                type(client_task_to_check)\n                            )\n                        )\n                    if client_task_to_check.result_received_time is None:\n                        # controller has not received result from client\n                        # something wrong happens when client working on this task, so resend the task\n                        resend_task = True\n                        client_task_to_send = client_task_to_check\n                        fl_ctx.set_prop(FLContextKey.IS_CLIENT_TASK_RESEND, True, sticky=False)\n\n                if not resend_task:\n                    # check with the task manager whether to send\n                    manager = task.props[_TASK_KEY_MANAGER]\n                    if client_task_to_check is None:\n                        client_task_to_check = ClientTask(task=task, client=client)\n                    check_status = manager.check_task_send(client_task_to_check, fl_ctx)\n                    self.logger.debug(\n                        \"Checking client task: {}, task.client.name: {}\".format(\n                            client_task_to_check, client_task_to_check.client.name\n                        )\n                    )\n                    self.logger.debug(\"Check task send get check_status: {}\".format(check_status))\n                    if check_status == TaskCheckStatus.BLOCK:\n                        # do not send this task, and do not check other tasks\n                        return self._try_again()\n                    elif check_status == TaskCheckStatus.NO_BLOCK:\n                        # do not send this task, but continue to check next task\n                        continue\n                    else:\n                        # send the task and remember the client_task\n                        client_task_to_send = ClientTask(client, task)\n                        task.last_client_task_map[client.name] = client_task_to_send\n                        task.client_tasks.append(client_task_to_send)\n                        self._client_task_map[client_task_to_send.id] = client_task_to_send\n                        break\n\n        # NOTE: move task sending process outside the lock\n        # This is to minimize the locking time and to avoid potential deadlock:\n        # the CB could schedule another task, which requires lock\n        self.logger.debug(\"Determining based on client_task_to_send: {}\".format(client_task_to_send))\n        if client_task_to_send is None:\n            # no task available for this client\n            return self._try_again()\n\n        # try to send the task\n        can_send_task = True\n        task = client_task_to_send.task\n        with task.cb_lock:\n            # Note: must guarantee the after_task_sent_cb is always called\n            # regardless whether the task is sent successfully.\n            # This is so that the app could clear up things in after_task_sent_cb.\n            if task.before_task_sent_cb is not None:\n                try:\n                    task.before_task_sent_cb(client_task=client_task_to_send, fl_ctx=fl_ctx)\n                except WorkflowError as ex:\n                    self._engine.ask_to_stop()\n                    self.log_exception(\n                        fl_ctx,\n                        \"processing error in before_task_sent_cb on task {} ({}): {}\".format(\n                            client_task_to_send.task.name, client_task_to_send.id, ex\n                        ),\n                    )\n                    task.completion_status = TaskCompletionStatus.ERROR\n                    task.exception = ex\n                except BaseException as ex:\n                    self.log_exception(\n                        fl_ctx,\n                        \"processing error in before_task_sent_cb on task {} ({}): {}\".format(\n                            client_task_to_send.task.name, client_task_to_send.id, ex\n                        ),\n                    )\n                    # this task cannot proceed anymore\n                    task.completion_status = TaskCompletionStatus.ERROR\n                    task.exception = ex\n\n            self.logger.debug(\"before_task_sent_cb done on client_task_to_send: {}\".format(client_task_to_send))\n            self.logger.debug(f\"task completion status is {task.completion_status}\")\n\n            if task.completion_status is not None:\n                can_send_task = False\n\n            # remember the task name and data to be sent to the client\n            # since task.data could be reset by the after_task_sent_cb\n            task_name = task.name\n            task_data = task.data\n\n            if task.after_task_sent_cb is not None:\n                try:\n                    task.after_task_sent_cb(client_task=client_task_to_send, fl_ctx=fl_ctx)\n                except WorkflowError as ex:\n                    self._engine.ask_to_stop()\n                    self.log_exception(\n                        fl_ctx,\n                        \"processing error in after_task_sent_cb on task {} ({}): {}\".format(\n                            client_task_to_send.task.name, client_task_to_send.id, ex\n                        ),\n                    )\n                    task.completion_status = TaskCompletionStatus.ERROR\n                    task.exception = ex\n                except BaseException as ex:\n                    self.log_exception(\n                        fl_ctx,\n                        \"processing error in after_task_sent_cb on task {} ({}): {}\".format(\n                            client_task_to_send.task.name, client_task_to_send.id, ex\n                        ),\n                    )\n                    task.completion_status = TaskCompletionStatus.ERROR\n                    task.exception = ex\n\n            if task.completion_status is not None:\n                # NOTE: the CB could cancel the task\n                can_send_task = False\n\n            if not can_send_task:\n                return self._try_again()\n\n            self.logger.debug(\"after_task_sent_cb done on client_task_to_send: {}\".format(client_task_to_send))\n\n            client_task_to_send.task_sent_time = time.time()\n            client_task_to_send.task_send_count += 1\n            return task_name, client_task_to_send.id, task_data",
  "def handle_exception(self, task_id: str, fl_ctx: FLContext) -> None:\n        \"\"\"Called to cancel one task as its client_task is causing exception at upper level.\n\n        Args:\n            task_id (str): an id to the failing client_task\n            fl_ctx (FLContext): FLContext associated with this client_task\n        \"\"\"\n        with self._task_lock:\n            # task_id is the uuid associated with the client_task\n            client_task = self._client_task_map.get(task_id, None)\n            self.logger.debug(\"Handle exception on client_task {} with id {}\".format(client_task, task_id))\n\n        if client_task is None:\n            # cannot find a standing task on the exception\n            return\n\n        task = client_task.task\n        self.cancel_task(task=task, fl_ctx=fl_ctx)\n        self.log_error(fl_ctx, \"task {} is cancelled due to exception\".format(task.name))",
  "def process_submission(self, client: Client, task_name: str, task_id: str, result: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process a submission from one client.\n\n        Note: this method is called by a separate thread.\n\n        Args:\n            client (Client): the client that submitted this task\n            task_name (str): the task name associated this submission\n            task_id (str): the id associated with the client_task\n            result (Shareable): the actual submitted data from the client\n            fl_ctx (FLContext): the FLContext associated with this submission\n\n        Raises:\n            TypeError: when client is not an instance of Client\n            TypeError: when fl_ctx is not an instance of FLContext\n            TypeError: when result is not an instance of Shareable\n            ValueError: task_name is not found in the client_task\n        \"\"\"\n        if not isinstance(client, Client):\n            raise TypeError(\"client must be an instance of Client, but got {}\".format(type(client)))\n        if not isinstance(fl_ctx, FLContext):\n            raise TypeError(\"fl_ctx must be an instance of FLContext, but got {}\".format(type(fl_ctx)))\n        if not isinstance(result, Shareable):\n            raise TypeError(\"result must be an instance of Shareable, but got {}\".format(type(result)))\n\n        with self._task_lock:\n            # task_id is the uuid associated with the client_task\n            client_task = self._client_task_map.get(task_id, None)\n            self.logger.debug(\"Get submission={} from client task={} id={}\".format(result, client_task, task_id))\n\n        if client_task is None:\n            # cannot find a standing task for the submission\n            self.log_info(fl_ctx, \"no standing task found for {}:{}\".format(task_name, task_id))\n            self.process_result_of_unknown_task(client, task_name, task_id, result, fl_ctx)\n            return\n\n        task = client_task.task\n        with task.cb_lock:\n            if task.name != task_name:\n                raise ValueError(\"client specified task name {} doesn't match {}\".format(task_name, task.name))\n\n            if task.completion_status is not None:\n                # the task is already finished - drop the result\n                self.log_info(fl_ctx, \"task is already finished - submission dropped\")\n                return\n\n            # do client task CB processing outside the lock\n            # this is because the CB could schedule another task, which requires the lock\n            client_task.result = result\n            client_task.result_received_time = time.time()\n\n            manager = task.props[_TASK_KEY_MANAGER]\n            manager.check_task_result(result, client_task, fl_ctx)\n\n            if task.result_received_cb is not None:\n                try:\n                    self.log_info(fl_ctx, \"invoking result_received_cb ...\")\n                    task.result_received_cb(client_task=client_task, fl_ctx=fl_ctx)\n                except WorkflowError as ex:\n                    self._engine.ask_to_stop()\n                    self.log_exception(\n                        fl_ctx,\n                        \"processing error in result_received_cb on task {}({}): {}\".format(task_name, task_id, ex),\n                    )\n                    task.completion_status = TaskCompletionStatus.ERROR\n                    task.exception = ex\n                    return\n                except BaseException as ex:\n                    # this task cannot proceed anymore\n                    self.log_exception(\n                        fl_ctx,\n                        \"processing error in result_received_cb on task {}({}): {}\".format(task_name, task_id, ex),\n                    )\n                    task.completion_status = TaskCompletionStatus.ERROR\n                    task.exception = ex\n                    return\n            else:\n                self.log_info(fl_ctx, \"no result_received_cb\")",
  "def _schedule_task(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        manager: TaskManager,\n        targets: Union[List[Client], List[str], None],\n        allow_dup_targets: bool = False,\n    ):\n        if task.schedule_time is not None:\n            # this task was scheduled before\n            # we do not allow a task object to be reused\n            self.logger.debug(\"task.schedule_time: {}\".format(task.schedule_time))\n            raise ValueError(\"Task was already used. Please create a new task object.\")\n\n        task.targets = targets\n        if targets is not None:\n            target_names = list()\n            if not isinstance(targets, list):\n                raise ValueError(\"task targets must be a list, but got {}\".format(type(targets)))\n            for t in targets:\n                if isinstance(t, str):\n                    name = t\n                elif isinstance(t, Client):\n                    name = t.name\n                else:\n                    raise ValueError(\"element in targets must be string or Client type, but got {}\".format(type(t)))\n\n                if allow_dup_targets or (name not in target_names):\n                    target_names.append(name)\n            task.targets = target_names\n\n        task.props[_TASK_KEY_MANAGER] = manager\n        task.props[_TASK_KEY_ENGINE] = fl_ctx.get_engine()\n        task.is_standing = True\n        task.schedule_time = time.time()\n\n        with self._task_lock:\n            self._tasks.append(task)\n            self.log_info(fl_ctx, \"scheduled task {}\".format(task.name))",
  "def broadcast(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        min_responses: int = 1,\n        wait_time_after_min_received: int = 0,\n    ):\n        \"\"\"Schedule a broadcast task.  This is a non-blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n            min_responses (int, optional): the condition to mark this task as completed because enough clients respond with submission. Defaults to 1.\n            wait_time_after_min_received (int, optional): a grace period for late clients to contribute their submission.  0 means no grace period.\n              Submission of late clients in the grace period are still collected as valid submission. Defaults to 0.\n\n        Raises:\n            ValueError: min_responses is greater than the length of targets since this condition will make the task, if allowed to be scheduled, never exit.\n        \"\"\"\n        _check_inputs(task=task, fl_ctx=fl_ctx, targets=targets)\n        _check_positive_int(\"min_responses\", min_responses)\n        _check_positive_int(\"wait_time_after_min_received\", wait_time_after_min_received)\n        if targets and min_responses > len(targets):\n            raise ValueError(\n                \"min_responses ({}) must be less than length of targets ({}).\".format(min_responses, len(targets))\n            )\n\n        manager = BcastTaskManager(\n            task=task, min_responses=min_responses, wait_time_after_min_received=wait_time_after_min_received\n        )\n        self._schedule_task(task=task, fl_ctx=fl_ctx, manager=manager, targets=targets)",
  "def broadcast_and_wait(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        min_responses: int = 1,\n        wait_time_after_min_received: int = 0,\n        abort_signal: Optional[Signal] = None,\n    ):\n        \"\"\"Schedule a broadcast task.  This is a blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n            min_responses (int, optional): the condition to mark this task as completed because enough clients respond with submission. Defaults to 1.\n            wait_time_after_min_received (int, optional): a grace period for late clients to contribute their submission.  0 means no grace period.\n            Submission of late clients in the grace period are still collected as valid submission. Defaults to 0.\n            abort_signal (Optional[Signal], optional): as this is a blocking call, this abort_signal informs this method to return. Defaults to None.\n        \"\"\"\n        self.broadcast(\n            task=task,\n            fl_ctx=fl_ctx,\n            targets=targets,\n            min_responses=min_responses,\n            wait_time_after_min_received=wait_time_after_min_received,\n        )\n        self._wait_for_task(task, abort_signal)",
  "def broadcast_forever(self, task: Task, fl_ctx: FLContext, targets: Union[List[Client], List[str], None] = None):\n        \"\"\"Schedule a broadcast task.  This is a non-blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients.\n        This broadcast will not end.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n        \"\"\"\n        _check_inputs(task=task, fl_ctx=fl_ctx, targets=targets)\n        manager = BcastForeverTaskManager()\n        self._schedule_task(task=task, fl_ctx=fl_ctx, manager=manager, targets=targets)",
  "def send(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order: SendOrder = SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n    ):\n        \"\"\"Schedule a single task to targets.  This is a non-blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients based on the send_order.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n            send_order (SendOrder, optional): the order for clients to become eligible.  SEQUENTIAL means the order in targets is enforced.  ANY means\n            clients in targets and haven't received task are eligible for task. Defaults to SendOrder.SEQUENTIAL.\n            task_assignment_timeout (int, optional): how long to wait for one client to pick the task. Defaults to 0.\n\n        Raises:\n            ValueError: when task_assignment_timeout is greater than task's timeout.\n            TypeError: send_order is not defined in SendOrder\n            ValueError: targets is None or an empty list\n        \"\"\"\n        _check_inputs(\n            task=task,\n            fl_ctx=fl_ctx,\n            targets=targets,\n        )\n        _check_positive_int(\"task_assignment_timeout\", task_assignment_timeout)\n        if task.timeout and task_assignment_timeout and task_assignment_timeout > task.timeout:\n            raise ValueError(\n                \"task_assignment_timeout ({}) needs to be less than or equal to task.timeout ({}).\".format(\n                    task_assignment_timeout, task.timeout\n                )\n            )\n        if not isinstance(send_order, SendOrder):\n            raise TypeError(\"send_order must be in Enum SendOrder, but got {}\".format(type(send_order)))\n\n        # targets must be provided\n        if targets is None or len(targets) == 0:\n            raise ValueError(\"Targets must be provided for send.\")\n\n        manager = SendTaskManager(task, send_order, task_assignment_timeout)\n        self._schedule_task(\n            task=task,\n            fl_ctx=fl_ctx,\n            manager=manager,\n            targets=targets,\n        )",
  "def send_and_wait(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order: SendOrder = SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n        abort_signal: Signal = None,\n    ):\n        \"\"\"Schedule a single task to targets.  This is a blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients based on the send_order.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n            send_order (SendOrder, optional): the order for clients to become eligible.  SEQUENTIAL means the order in targets is enforced.  ANY means\n            clients in targets and haven't received task are eligible for task. Defaults to SendOrder.SEQUENTIAL.\n            task_assignment_timeout (int, optional): how long to wait for one client to pick the task. Defaults to 0.\n            abort_signal (Optional[Signal], optional): as this is a blocking call, this abort_signal informs this method to return. Defaults to None.\n\n        \"\"\"\n        self.send(\n            task=task,\n            fl_ctx=fl_ctx,\n            targets=targets,\n            send_order=send_order,\n            task_assignment_timeout=task_assignment_timeout,\n        )\n        self._wait_for_task(task, abort_signal)",
  "def get_num_standing_tasks(self) -> int:\n        \"\"\"Get the number of tasks that are currently standing.\n\n        Returns:\n            int: length of the list of standing tasks\n        \"\"\"\n        return len(self._tasks)",
  "def cancel_task(\n        self, task: Task, completion_status=TaskCompletionStatus.CANCELLED, fl_ctx: Optional[FLContext] = None\n    ):\n        \"\"\"Cancel the specified task.\n\n        Change the task completion_status, which will inform task monitor to clean up this task\n        NOTE: we only mark the task as completed and leave it to the task monitor to clean up\n        This is to avoid potential dead lock of task_lock\n\n        Args:\n            task (Task): the task to be cancelled\n            completion_status (str, optional): the completion status for this cancellation. Defaults to TaskCompletionStatus.CANCELLED.\n            fl_ctx (Optional[FLContext], optional): FLContext associated with this cancellation. Defaults to None.\n        \"\"\"\n        task.completion_status = completion_status",
  "def cancel_all_tasks(self, completion_status=TaskCompletionStatus.CANCELLED, fl_ctx: Optional[FLContext] = None):\n        \"\"\"Cancel all standing tasks in this controller.\n\n        Args:\n            completion_status (str, optional): the completion status for this cancellation. Defaults to TaskCompletionStatus.CANCELLED.\n            fl_ctx (Optional[FLContext], optional): FLContext associated with this cancellation. Defaults to None.\n        \"\"\"\n        with self._task_lock:\n            for t in self._tasks:\n                t.completion_status = completion_status",
  "def abort_task(self, task, fl_ctx: FLContext):\n        \"\"\"Ask all clients to abort the execution of the specified task.\n\n        Args:\n            task (str): the task to be aborted\n            fl_ctx (FLContext): FLContext associated with this action\n        \"\"\"\n        self.log_info(fl_ctx, \"asked all clients to abort task {}\".format(task.name))\n        self._end_task([task.name], fl_ctx)",
  "def _end_task(self, task_names, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ServerEngineSpec):\n            raise TypeError(\"engine should be an instance of ServerEngineSpec, but got {}\".format(type(engine)))\n        request = Shareable()\n        request[\"task_names\"] = task_names\n        engine.send_aux_request(targets=None, topic=ReservedTopic.ABORT_ASK, request=request, timeout=0, fl_ctx=fl_ctx)",
  "def abort_all_tasks(self, fl_ctx: FLContext):\n        \"\"\"Ask clients to abort the execution of all tasks.\n\n        NOTE: the server should send a notification to all clients, regardless of whether the server\n        has any standing tasks.\n\n        Args:\n            fl_ctx (FLContext): FLContext associated with this action\n        \"\"\"\n        self._end_task([], fl_ctx)",
  "def finalize_run(self, fl_ctx: FLContext):\n        \"\"\"Do cleanup of the coordinator implementation.\n\n        NOTE: subclass controllers should not overwrite finalize_run.\n\n        Args:\n            fl_ctx (FLContext): FLContext associated with this action\n        \"\"\"\n        self.cancel_all_tasks()  # unconditionally cancel all tasks\n        self._all_done = True\n        try:\n            if self._task_monitor.is_alive():\n                self._task_monitor.join()\n        except RuntimeError:\n            self.log_debug(fl_ctx, \"unable to join monitor thread (not started?)\")\n        self.stop_controller(fl_ctx)",
  "def relay(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order: SendOrder = SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n        task_result_timeout: int = 0,\n        dynamic_targets: bool = True,\n    ):\n        \"\"\"Schedule a single task to targets in one-after-another style.  This is a non-blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients based on the send_order.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n            send_order (SendOrder, optional): the order for clients to become eligible.\n              SEQUENTIAL means the order in targets is enforced.\n              ANY means any clients that are inside the targets and haven't received the task are eligible. Defaults to SendOrder.SEQUENTIAL.\n            task_assignment_timeout (int, optional): how long to wait for one client to pick the task. Defaults to 0.\n            task_result_timeout (int, optional): how long to wait for current working client to reply its result. Defaults to 0.\n            dynamic_targets (bool, optional): allow clients not in targets to join at the end of targets list. Defaults to True.\n\n        Raises:\n            ValueError: when task_assignment_timeout is greater than task's timeout\n            ValueError: when task_result_timeout is greater than task's timeout\n            TypeError: send_order is not defined in SendOrder\n            TypeError: when dynamic_targets is not a boolean variable\n            ValueError: targets is None or an empty list but dynamic_targets is False\n        \"\"\"\n        _check_inputs(\n            task=task,\n            fl_ctx=fl_ctx,\n            targets=targets,\n        )\n        _check_positive_int(\"task_assignment_timeout\", task_assignment_timeout)\n        _check_positive_int(\"task_result_timeout\", task_result_timeout)\n        if task.timeout and task_assignment_timeout and task_assignment_timeout > task.timeout:\n            raise ValueError(\n                \"task_assignment_timeout ({}) needs to be less than or equal to task.timeout ({}).\".format(\n                    task_assignment_timeout, task.timeout\n                )\n            )\n        if task.timeout and task_result_timeout and task_result_timeout > task.timeout:\n            raise ValueError(\n                \"task_result_timeout ({}) needs to be less than or equal to task.timeout ({}).\".format(\n                    task_result_timeout, task.timeout\n                )\n            )\n        if not isinstance(send_order, SendOrder):\n            raise TypeError(\"send_order must be in Enum SendOrder, but got {}\".format(type(send_order)))\n        if not isinstance(dynamic_targets, bool):\n            raise TypeError(\"dynamic_targets must be an instance of bool, but got {}\".format(type(dynamic_targets)))\n        if targets is None and dynamic_targets is False:\n            raise ValueError(\"Need to provide targets when dynamic_targets is set to False.\")\n\n        if send_order == SendOrder.SEQUENTIAL:\n            manager = SequentialRelayTaskManager(\n                task=task,\n                task_assignment_timeout=task_assignment_timeout,\n                task_result_timeout=task_result_timeout,\n                dynamic_targets=dynamic_targets,\n            )\n        else:\n            manager = AnyRelayTaskManager(\n                task=task, task_result_timeout=task_result_timeout, dynamic_targets=dynamic_targets\n            )\n\n        self._schedule_task(\n            task=task,\n            fl_ctx=fl_ctx,\n            manager=manager,\n            targets=targets,\n            allow_dup_targets=True,\n        )",
  "def relay_and_wait(\n        self,\n        task: Task,\n        fl_ctx: FLContext,\n        targets: Union[List[Client], List[str], None] = None,\n        send_order=SendOrder.SEQUENTIAL,\n        task_assignment_timeout: int = 0,\n        task_result_timeout: int = 0,\n        dynamic_targets: bool = True,\n        abort_signal: Optional[Signal] = None,\n    ):\n        \"\"\"Schedule a single task to targets in one-after-another style.  This is a blocking call.\n\n        The task is scheduled into a task list.  Clients can request tasks and controller will dispatch the task to eligible clients based on the send_order.\n\n        Args:\n            task (Task): the task to be scheduled\n            fl_ctx (FLContext): FLContext associated with this task\n            targets (Union[List[Client], List[str], None], optional): the list of eligible clients or client names or None (all clients). Defaults to None.\n            send_order (SendOrder, optional): the order for clients to become eligible.  SEQUENTIAL means the order in targets is enforced.  ANY means\n            clients in targets and haven't received task are eligible for task. Defaults to SendOrder.SEQUENTIAL.\n            task_assignment_timeout (int, optional): how long to wait for one client to pick the task. Defaults to 0.\n            task_result_timeout (int, optional): how long to wait for current working client to reply its result. Defaults to 0.\n            dynamic_targets (bool, optional): allow clients not in targets to join at the end of targets list. Defaults to True.\n            abort_signal (Optional[Signal], optional): as this is a blocking call, this abort_signal informs this method to return. Defaults to None.\n        \"\"\"\n        self.relay(\n            task=task,\n            fl_ctx=fl_ctx,\n            targets=targets,\n            send_order=send_order,\n            task_assignment_timeout=task_assignment_timeout,\n            task_result_timeout=task_result_timeout,\n            dynamic_targets=dynamic_targets,\n        )\n        self._wait_for_task(task, abort_signal)",
  "def _monitor_tasks(self):\n        while not self._all_done:\n            self._check_tasks()\n            time.sleep(self._task_check_period)",
  "def _check_tasks(self):\n        exit_tasks = []\n        with self._task_lock:\n            for task in self._tasks:\n                if task.completion_status is not None:\n                    exit_tasks.append(task)\n                    continue\n\n                # check the task-specific exit condition\n                manager = task.props[_TASK_KEY_MANAGER]\n                if manager is not None:\n                    if not isinstance(manager, TaskManager):\n                        raise TypeError(\n                            \"manager in task must be an instance of TaskManager, but got {}\".format(manager)\n                        )\n                    should_exit, exit_status = manager.check_task_exit(task)\n                    self.logger.debug(\"should_exit: {}, exit_status: {}\".format(should_exit, exit_status))\n                    if should_exit:\n                        task.completion_status = exit_status\n                        exit_tasks.append(task)\n                        continue\n\n                # check if task timeout\n                if task.timeout and time.time() - task.schedule_time >= task.timeout:\n                    task.completion_status = TaskCompletionStatus.TIMEOUT\n                    exit_tasks.append(task)\n                    continue\n\n            for exit_task in exit_tasks:\n                exit_task.is_standing = False\n                self.logger.debug(\n                    \"Removing task={}, completion_status={}\".format(exit_task, exit_task.completion_status)\n                )\n                self._tasks.remove(exit_task)\n                for client_task in exit_task.client_tasks:\n                    self.logger.debug(\"Removing client_task with id={}\".format(client_task.id))\n                    self._client_task_map.pop(client_task.id)\n\n        # do the task exit processing outside the lock to minimize the locking time\n        # and to avoid potential deadlock since the CB could schedule another task\n        if len(exit_tasks) <= 0:\n            return\n\n        with self._engine.new_context() as fl_ctx:\n            for exit_task in exit_tasks:\n                with exit_task.cb_lock:\n                    self.log_info(\n                        fl_ctx, \"task {} exit with status {}\".format(exit_task.name, exit_task.completion_status)\n                    )\n\n                    if exit_task.task_done_cb is not None:\n                        try:\n                            exit_task.task_done_cb(task=exit_task, fl_ctx=fl_ctx)\n                        except WorkflowError as ex:\n                            self._engine.ask_to_stop()\n                            self.log_exception(\n                                fl_ctx,\n                                \"processing error in task_done_cb error on task {}: {}\".format(exit_task.name, ex),\n                            )\n                            task.completion_status = TaskCompletionStatus.ERROR\n                            task.exception = ex\n                        except BaseException as ex:\n                            self.log_exception(\n                                fl_ctx,\n                                \"processing error in task_done_cb error on task {}: {}\".format(exit_task.name, ex),\n                            )\n                            exit_task.completion_status = TaskCompletionStatus.ERROR\n                            exit_task.exception = ex",
  "def _process_finished_task(task, func):\n        def wrap(*args, **kwargs):\n            if func:\n                func(*args, **kwargs)\n            task.props[_TASK_KEY_DONE] = True\n\n        return wrap",
  "def _wait_for_task(self, task: Task, abort_signal: Signal):\n        task.props[_TASK_KEY_DONE] = False\n        task.task_done_cb = self._process_finished_task(task=task, func=task.task_done_cb)\n        while True:\n            if task.completion_status is not None:\n                break\n\n            if abort_signal and abort_signal.triggered:\n                self.cancel_task(task, fl_ctx=None, completion_status=TaskCompletionStatus.ABORTED)\n                break\n\n            task_done = task.props[_TASK_KEY_DONE]\n            if task_done:\n                break\n            time.sleep(self._task_check_period)",
  "def wrap(*args, **kwargs):\n            if func:\n                func(*args, **kwargs)\n            task.props[_TASK_KEY_DONE] = True",
  "class TaskCheckStatus(Enum):\n\n    SEND = 1  # send the task to the client\n    BLOCK = 2  # do not send the task, and block other tasks\n    NO_BLOCK = 3",
  "class TaskManager(object):\n    def __init__(self):\n        \"\"\"Manages tasks for clients.\n\n        Programming Conventions:\n        A TaskManager should be implemented as a state-free object.\n        All task processing state info should be stored in the Task's props dict.\n        Name the keys in the props dict with prefix \"__\" to avoid potential conflict with\n        app-defined props.\n        \"\"\"\n        self._name = self.__class__.__name__\n        self.logger = logging.getLogger(self._name)\n\n    def check_task_send(self, client_task: ClientTask, fl_ctx: FLContext) -> TaskCheckStatus:\n        \"\"\"Determine whether the task should be sent to the client.\n\n        Default logic:\n        If the client already did the task, don't send again (BLOCK).\n        If the client is in the task's target list or the task's target\n        list is None (meaning all clients), then send the task (SEND). Otherwise, do not block the\n        task checking (NO_BLOCK), so next task will be checked.\n\n        Args:\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n\n\n        Returns:\n            TaskCheckStatus: NO_BLOCK for not sending the task, BLOCK for waiting, SEND for OK to send\n        \"\"\"\n        if client_task.result_received_time:\n            # the task was already sent to the client AND result was already received\n            # do not send again\n            return TaskCheckStatus.NO_BLOCK\n\n        client_name = client_task.client.name\n        if client_task.task.targets is None or client_name in client_task.task.targets:\n            return TaskCheckStatus.SEND\n        else:\n            return TaskCheckStatus.NO_BLOCK\n\n    def check_task_exit(self, task: Task) -> Tuple[bool, TaskCompletionStatus]:\n        \"\"\"Determine whether the task should exit.\n\n        Args:\n            task (Task): an instance of Task\n\n        Returns:\n            Tuple[bool, TaskCompletionStatus]:\n                first entry in the tuple means whether to exit the task or not.  If it's True, the task should exit.\n                second entry in the tuple indicates the TaskCompletionStatus.\n        \"\"\"\n        pass\n\n    def check_task_result(self, result: Shareable, client_task: ClientTask, fl_ctx: FLContext):\n        \"\"\"Check the result received from the client.\n\n        The manager can set appropriate headers into the result to indicate certain conditions (e.g.\n        late response).\n\n        Args:\n            result (Shareable): the result to be checked\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n        \"\"\"\n        pass",
  "def __init__(self):\n        \"\"\"Manages tasks for clients.\n\n        Programming Conventions:\n        A TaskManager should be implemented as a state-free object.\n        All task processing state info should be stored in the Task's props dict.\n        Name the keys in the props dict with prefix \"__\" to avoid potential conflict with\n        app-defined props.\n        \"\"\"\n        self._name = self.__class__.__name__\n        self.logger = logging.getLogger(self._name)",
  "def check_task_send(self, client_task: ClientTask, fl_ctx: FLContext) -> TaskCheckStatus:\n        \"\"\"Determine whether the task should be sent to the client.\n\n        Default logic:\n        If the client already did the task, don't send again (BLOCK).\n        If the client is in the task's target list or the task's target\n        list is None (meaning all clients), then send the task (SEND). Otherwise, do not block the\n        task checking (NO_BLOCK), so next task will be checked.\n\n        Args:\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n\n\n        Returns:\n            TaskCheckStatus: NO_BLOCK for not sending the task, BLOCK for waiting, SEND for OK to send\n        \"\"\"\n        if client_task.result_received_time:\n            # the task was already sent to the client AND result was already received\n            # do not send again\n            return TaskCheckStatus.NO_BLOCK\n\n        client_name = client_task.client.name\n        if client_task.task.targets is None or client_name in client_task.task.targets:\n            return TaskCheckStatus.SEND\n        else:\n            return TaskCheckStatus.NO_BLOCK",
  "def check_task_exit(self, task: Task) -> Tuple[bool, TaskCompletionStatus]:\n        \"\"\"Determine whether the task should exit.\n\n        Args:\n            task (Task): an instance of Task\n\n        Returns:\n            Tuple[bool, TaskCompletionStatus]:\n                first entry in the tuple means whether to exit the task or not.  If it's True, the task should exit.\n                second entry in the tuple indicates the TaskCompletionStatus.\n        \"\"\"\n        pass",
  "def check_task_result(self, result: Shareable, client_task: ClientTask, fl_ctx: FLContext):\n        \"\"\"Check the result received from the client.\n\n        The manager can set appropriate headers into the result to indicate certain conditions (e.g.\n        late response).\n\n        Args:\n            result (Shareable): the result to be checked\n            client_task (ClientTask): the task processing state of the client\n            fl_ctx (FLContext): fl context that comes with the task request\n        \"\"\"\n        pass",
  "class FedEventRunner(Widget):\n    def __init__(self, topic=FED_EVENT_TOPIC):\n        \"\"\"Init FedEventRunner.\n\n        The FedEventRunner handles posting and receiving of fed events.\n        The system will do its best to fire off all events in the queue before shutdown\n        using the ABOUT_TO_END_RUN event and a grace period during END_RUN.\n\n        Args:\n            topic: the fed event topic to be handled. Defaults to 'fed.event'\n        \"\"\"\n        Widget.__init__(self)\n        self.topic = topic\n        self.abort_signal = None\n        self.asked_to_stop = False\n        self.asked_to_flush = False\n        self.regular_interval = 0.001\n        self.grace_period = 2\n        self.flush_wait = 2\n        self.engine = None\n        self.last_timestamps = {}  # client name => last_timestamp\n        self.in_events = []\n        self.in_lock = threading.Lock()\n        self.poster = threading.Thread(target=self._post, args=())\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.engine = fl_ctx.get_engine()\n            self.engine.register_aux_message_handler(topic=self.topic, message_handle_func=self._receive)\n            self.abort_signal = fl_ctx.get_run_abort_signal()\n            self.asked_to_stop = False\n            self.asked_to_flush = False\n            self.poster.start()\n        elif event_type == EventType.ABOUT_TO_END_RUN:\n            self.asked_to_flush = True\n            # delay self.flush_wait seconds so\n            # _post can empty the queue before\n            # END_RUN is fired\n            time.sleep(self.flush_wait)\n        elif event_type == EventType.END_RUN:\n            self.asked_to_stop = True\n            if self.poster.is_alive():\n                self.poster.join()\n        else:\n            # handle outgoing fed events\n            event_scope = fl_ctx.get_prop(key=FLContextKey.EVENT_SCOPE, default=EventScope.LOCAL)\n            if event_scope != EventScope.FEDERATION:\n                return\n\n            event_data = fl_ctx.get_prop(FLContextKey.EVENT_DATA, None)\n            if not isinstance(event_data, Shareable):\n                self.log_error(fl_ctx, \"bad fed event: expect data to be Shareable but got {}\".format(type(event_data)))\n                return\n\n            direction = event_data.get_header(FedEventHeader.DIRECTION, \"out\")\n            if direction != \"out\":\n                # ignore incoming events\n                return\n\n            event_data.set_header(FedEventHeader.EVENT_TYPE, event_type)\n            event_data.set_header(FedEventHeader.ORIGIN, fl_ctx.get_identity_name())\n            event_data.set_header(FedEventHeader.TIMESTAMP, time.time())\n\n            targets = event_data.get_header(FedEventHeader.TARGETS, None)\n            self.fire_and_forget_request(request=event_data, fl_ctx=fl_ctx, targets=targets)\n\n    def fire_and_forget_request(self, request: Shareable, fl_ctx: FLContext, targets=None):\n        pass\n\n    def _receive(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        peer_name = request.get_peer_prop(ReservedKey.IDENTITY_NAME, None)\n        if not peer_name:\n            self.log_error(fl_ctx, \"missing identity name of the data sender\")\n            return make_reply(ReturnCode.MISSING_PEER_CONTEXT)\n\n        timestamp = request.get_header(FedEventHeader.TIMESTAMP, None)\n        if timestamp is None:\n            self.log_error(fl_ctx, \"missing timestamp in incoming fed event\")\n            return make_reply(ReturnCode.BAD_REQUEST_DATA)\n\n        event_type = request.get_header(FedEventHeader.EVENT_TYPE, None)\n        if event_type is None:\n            self.log_error(fl_ctx, \"missing event_type in incoming fed event\")\n            return make_reply(ReturnCode.BAD_REQUEST_DATA)\n\n        with self.in_lock:\n            last_timestamp = self.last_timestamps.get(peer_name, None)\n            if last_timestamp is None or timestamp > last_timestamp:\n                # we only keep new items, in case the peer somehow sent old items\n                request.set_header(FedEventHeader.DIRECTION, \"in\")\n                self.in_events.append(request)\n                self.last_timestamps[peer_name] = timestamp\n\n        # NOTE: we do not fire event here since event process could take time.\n        # Instead, we simply add the package to the queue and return quickly.\n        # The posting of events will be handled in the poster thread\n        return make_reply(ReturnCode.OK)\n\n    def _post(self):\n        \"\"\"Post an event.\n\n        During ABOUT_TO_END_RUN, sleep_time is 0 and system will flush\n         in_events by firing events without delay.\n\n        During END_RUN, system will wait for self.grace_period, even the queue is empty,\n        so any new item can be processed.\n\n        However, since the system does not guarantee the receiving side of _post is still\n        alive, we catch the exception and show warning messages to users if events can not\n        be handled by receiving side.\n        \"\"\"\n        sleep_time = self.regular_interval\n        countdown = self.grace_period\n        while True:\n            time.sleep(sleep_time)\n            if self.abort_signal.triggered:\n                break\n            n = len(self.in_events)\n            if n > 0:\n                if self.asked_to_flush:\n                    sleep_time = 0\n                else:\n                    sleep_time = self.regular_interval\n                with self.in_lock:\n                    event_to_post = self.in_events.pop(0)\n            elif self.asked_to_stop:\n                # the queue is empty, and we are asked to stop.\n                # wait self.grace_period seconds , then exit.\n                if countdown < 0:\n                    break\n                else:\n                    countdown = countdown - 1\n                    time.sleep(1)\n                    continue\n            else:\n                sleep_time = min(sleep_time * 2, 1)\n                continue\n\n            with self.engine.new_context() as fl_ctx:\n                if self.asked_to_stop:\n                    self.log_warning(fl_ctx, f\"{n} items remained in in_events.  Will stop when it reaches 0.\")\n                fl_ctx.set_prop(key=FLContextKey.EVENT_DATA, value=event_to_post, private=True, sticky=False)\n                fl_ctx.set_prop(key=FLContextKey.EVENT_SCOPE, value=EventScope.FEDERATION, private=True, sticky=False)\n\n                event_type = event_to_post.get_header(FedEventHeader.EVENT_TYPE)\n                try:\n                    self.engine.fire_event(event_type=event_type, fl_ctx=fl_ctx)\n                except BaseException as e:\n                    if self.asked_to_stop:\n                        self.log_warning(fl_ctx, f\"event {event_to_post} fired unsuccessfully during END_RUN\")\n                    else:\n                        raise e",
  "class ServerFedEventRunner(FedEventRunner):\n    def __init__(self, topic=FED_EVENT_TOPIC):\n        \"\"\"Init ServerFedEventRunner.\"\"\"\n        FedEventRunner.__init__(self, topic)\n\n    def fire_and_forget_request(self, request: Shareable, fl_ctx: FLContext, targets=None):\n        if not isinstance(self.engine, ServerEngineSpec):\n            raise TypeError(\"self.engine must be ServerEngineSpec but got {}\".format(type(self.engine)))\n        self.engine.fire_and_forget_aux_request(\n            topic=self.topic,\n            targets=targets,\n            request=request,\n            fl_ctx=fl_ctx,\n        )",
  "class ClientFedEventRunner(FedEventRunner):\n    def __init__(self, topic=FED_EVENT_TOPIC):\n        \"\"\"Init ClientFedEventRunner.\"\"\"\n        FedEventRunner.__init__(self, topic)\n        self.ready = False\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        super().handle_event(event_type, fl_ctx)\n\n        if event_type == EventType.START_RUN:\n            self.ready = True\n\n    def fire_and_forget_request(self, request: Shareable, fl_ctx: FLContext, targets=None):\n        if not self.ready:\n            self.log_warning(fl_ctx, \"Engine in not ready, skip the fed event firing.\")\n            return\n\n        if not isinstance(self.engine, ClientEngineSpec):\n            raise TypeError(\"self.engine must be ClientEngineSpec but got {}\".format(type(self.engine)))\n        self.engine.fire_and_forget_aux_request(topic=self.topic, request=request, fl_ctx=fl_ctx)",
  "def __init__(self, topic=FED_EVENT_TOPIC):\n        \"\"\"Init FedEventRunner.\n\n        The FedEventRunner handles posting and receiving of fed events.\n        The system will do its best to fire off all events in the queue before shutdown\n        using the ABOUT_TO_END_RUN event and a grace period during END_RUN.\n\n        Args:\n            topic: the fed event topic to be handled. Defaults to 'fed.event'\n        \"\"\"\n        Widget.__init__(self)\n        self.topic = topic\n        self.abort_signal = None\n        self.asked_to_stop = False\n        self.asked_to_flush = False\n        self.regular_interval = 0.001\n        self.grace_period = 2\n        self.flush_wait = 2\n        self.engine = None\n        self.last_timestamps = {}  # client name => last_timestamp\n        self.in_events = []\n        self.in_lock = threading.Lock()\n        self.poster = threading.Thread(target=self._post, args=())",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.engine = fl_ctx.get_engine()\n            self.engine.register_aux_message_handler(topic=self.topic, message_handle_func=self._receive)\n            self.abort_signal = fl_ctx.get_run_abort_signal()\n            self.asked_to_stop = False\n            self.asked_to_flush = False\n            self.poster.start()\n        elif event_type == EventType.ABOUT_TO_END_RUN:\n            self.asked_to_flush = True\n            # delay self.flush_wait seconds so\n            # _post can empty the queue before\n            # END_RUN is fired\n            time.sleep(self.flush_wait)\n        elif event_type == EventType.END_RUN:\n            self.asked_to_stop = True\n            if self.poster.is_alive():\n                self.poster.join()\n        else:\n            # handle outgoing fed events\n            event_scope = fl_ctx.get_prop(key=FLContextKey.EVENT_SCOPE, default=EventScope.LOCAL)\n            if event_scope != EventScope.FEDERATION:\n                return\n\n            event_data = fl_ctx.get_prop(FLContextKey.EVENT_DATA, None)\n            if not isinstance(event_data, Shareable):\n                self.log_error(fl_ctx, \"bad fed event: expect data to be Shareable but got {}\".format(type(event_data)))\n                return\n\n            direction = event_data.get_header(FedEventHeader.DIRECTION, \"out\")\n            if direction != \"out\":\n                # ignore incoming events\n                return\n\n            event_data.set_header(FedEventHeader.EVENT_TYPE, event_type)\n            event_data.set_header(FedEventHeader.ORIGIN, fl_ctx.get_identity_name())\n            event_data.set_header(FedEventHeader.TIMESTAMP, time.time())\n\n            targets = event_data.get_header(FedEventHeader.TARGETS, None)\n            self.fire_and_forget_request(request=event_data, fl_ctx=fl_ctx, targets=targets)",
  "def fire_and_forget_request(self, request: Shareable, fl_ctx: FLContext, targets=None):\n        pass",
  "def _receive(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        peer_name = request.get_peer_prop(ReservedKey.IDENTITY_NAME, None)\n        if not peer_name:\n            self.log_error(fl_ctx, \"missing identity name of the data sender\")\n            return make_reply(ReturnCode.MISSING_PEER_CONTEXT)\n\n        timestamp = request.get_header(FedEventHeader.TIMESTAMP, None)\n        if timestamp is None:\n            self.log_error(fl_ctx, \"missing timestamp in incoming fed event\")\n            return make_reply(ReturnCode.BAD_REQUEST_DATA)\n\n        event_type = request.get_header(FedEventHeader.EVENT_TYPE, None)\n        if event_type is None:\n            self.log_error(fl_ctx, \"missing event_type in incoming fed event\")\n            return make_reply(ReturnCode.BAD_REQUEST_DATA)\n\n        with self.in_lock:\n            last_timestamp = self.last_timestamps.get(peer_name, None)\n            if last_timestamp is None or timestamp > last_timestamp:\n                # we only keep new items, in case the peer somehow sent old items\n                request.set_header(FedEventHeader.DIRECTION, \"in\")\n                self.in_events.append(request)\n                self.last_timestamps[peer_name] = timestamp\n\n        # NOTE: we do not fire event here since event process could take time.\n        # Instead, we simply add the package to the queue and return quickly.\n        # The posting of events will be handled in the poster thread\n        return make_reply(ReturnCode.OK)",
  "def _post(self):\n        \"\"\"Post an event.\n\n        During ABOUT_TO_END_RUN, sleep_time is 0 and system will flush\n         in_events by firing events without delay.\n\n        During END_RUN, system will wait for self.grace_period, even the queue is empty,\n        so any new item can be processed.\n\n        However, since the system does not guarantee the receiving side of _post is still\n        alive, we catch the exception and show warning messages to users if events can not\n        be handled by receiving side.\n        \"\"\"\n        sleep_time = self.regular_interval\n        countdown = self.grace_period\n        while True:\n            time.sleep(sleep_time)\n            if self.abort_signal.triggered:\n                break\n            n = len(self.in_events)\n            if n > 0:\n                if self.asked_to_flush:\n                    sleep_time = 0\n                else:\n                    sleep_time = self.regular_interval\n                with self.in_lock:\n                    event_to_post = self.in_events.pop(0)\n            elif self.asked_to_stop:\n                # the queue is empty, and we are asked to stop.\n                # wait self.grace_period seconds , then exit.\n                if countdown < 0:\n                    break\n                else:\n                    countdown = countdown - 1\n                    time.sleep(1)\n                    continue\n            else:\n                sleep_time = min(sleep_time * 2, 1)\n                continue\n\n            with self.engine.new_context() as fl_ctx:\n                if self.asked_to_stop:\n                    self.log_warning(fl_ctx, f\"{n} items remained in in_events.  Will stop when it reaches 0.\")\n                fl_ctx.set_prop(key=FLContextKey.EVENT_DATA, value=event_to_post, private=True, sticky=False)\n                fl_ctx.set_prop(key=FLContextKey.EVENT_SCOPE, value=EventScope.FEDERATION, private=True, sticky=False)\n\n                event_type = event_to_post.get_header(FedEventHeader.EVENT_TYPE)\n                try:\n                    self.engine.fire_event(event_type=event_type, fl_ctx=fl_ctx)\n                except BaseException as e:\n                    if self.asked_to_stop:\n                        self.log_warning(fl_ctx, f\"event {event_to_post} fired unsuccessfully during END_RUN\")\n                    else:\n                        raise e",
  "def __init__(self, topic=FED_EVENT_TOPIC):\n        \"\"\"Init ServerFedEventRunner.\"\"\"\n        FedEventRunner.__init__(self, topic)",
  "def fire_and_forget_request(self, request: Shareable, fl_ctx: FLContext, targets=None):\n        if not isinstance(self.engine, ServerEngineSpec):\n            raise TypeError(\"self.engine must be ServerEngineSpec but got {}\".format(type(self.engine)))\n        self.engine.fire_and_forget_aux_request(\n            topic=self.topic,\n            targets=targets,\n            request=request,\n            fl_ctx=fl_ctx,\n        )",
  "def __init__(self, topic=FED_EVENT_TOPIC):\n        \"\"\"Init ClientFedEventRunner.\"\"\"\n        FedEventRunner.__init__(self, topic)\n        self.ready = False",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        super().handle_event(event_type, fl_ctx)\n\n        if event_type == EventType.START_RUN:\n            self.ready = True",
  "def fire_and_forget_request(self, request: Shareable, fl_ctx: FLContext, targets=None):\n        if not self.ready:\n            self.log_warning(fl_ctx, \"Engine in not ready, skip the fed event firing.\")\n            return\n\n        if not isinstance(self.engine, ClientEngineSpec):\n            raise TypeError(\"self.engine must be ClientEngineSpec but got {}\".format(type(self.engine)))\n        self.engine.fire_and_forget_aux_request(topic=self.topic, request=request, fl_ctx=fl_ctx)",
  "class Widget(FLComponent):\n    \"\"\"Pre-defined components that address specific needs.\n\n    Some examples of such needs:\n        - report current status\n        - dynamically change its tunable parameters\n        - record processing errors\n        - stats recording\n\n    Each widget is a singleton object that is registered with the Engine with a\n    unique ID.\n\n    All built-in widget IDs are documented in the WidgetID class.\n\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Init the Widget.\"\"\"\n        FLComponent.__init__(self)",
  "class WidgetID(str, Enum):\n\n    INFO_COLLECTOR = \"info_collector\"\n    COMPONENT_CALLER = \"component_caller\"\n    FED_EVENT_RUNNER = \"fed_event_runner\"",
  "def __init__(self):\n        \"\"\"Init the Widget.\"\"\"\n        FLComponent.__init__(self)",
  "class CallInfo(object):\n    def __init__(self, target: str, action: str, params: dict):\n        \"\"\"Required information to call a component.\n\n        Args:\n            target (str): target component(s) that the call is applied to\n            action (str): action of the call\n            params (dict): params of the call\n        \"\"\"\n        self.target = target\n        self.action = action\n        self.params = params\n        self.results = {}  # results of components that tried to apply the params\n\n    def record_result(self, target: str, result: str = \"OK\"):\n        \"\"\"Records the result.\n\n        Args:\n            target (str): the target component(s) that is called\n            result (str): the result generated by calling the target component(s)\n        \"\"\"\n        self.results[target] = result",
  "class ComponentCaller(Widget):\n\n    EVENT_TYPE_CALL_COMPONENT = \"comp_caller.call\"\n    CTX_KEY_CALL_INFO = \"comp_caller.call_info\"\n\n    def __init__(self):\n        \"\"\"A widget enables calling component(s).\"\"\"\n        super().__init__()\n        self.engine = None\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.engine = fl_ctx.get_engine()\n        elif event_type == EventType.END_RUN:\n            self.engine = None\n\n    def call_components(self, target: str, action: str, params: dict):\n        \"\"\"Makes a call to component(s).\n\n        Args:\n            target (str): the target spec of the component(s) to be called.\n            action (str): action of the call\n            params (dict): parameters for the call\n\n        Returns:\n            None or a dict of result: comp name => result string\n\n        NOTE:\n            each component that wants to participate the call mechanism must:\n                - Listen to the event EVENT_TYPE_CALL_COMPONENT\n\n                - In the event handler, decide whether the call is applicable to it by comparing itself to\n                  the 'target'. The target could be a specific component ID, or a type of components\n\n                - decide further whether the call is applicable to it by looking at the 'action'.\n                  Conceptually, the action is like a function to be called on the component.\n                  If the component doesn't support the action, simply ignore the call.\n\n                - if the call is applicable, always report the execution status to the call.\n        \"\"\"\n        # NOTE: it's important to assign self.engine to a new var!\n        # This is because another thread may fire the END_RUN event, which will cause\n        # self.engine to be set to None, just after checking it being None and before using it!\n        engine = self.engine\n        if not engine:\n            return None\n\n        # NOTE: we need a new context here to make sure all sticky props are copied!\n        with engine.new_context() as fl_ctx:\n            info = CallInfo(target=target, action=action, params=params)\n            fl_ctx.set_prop(key=self.CTX_KEY_CALL_INFO, value=info, sticky=False, private=True)\n\n            engine.fire_event(event_type=self.EVENT_TYPE_CALL_COMPONENT, fl_ctx=fl_ctx)\n\n            return info.results",
  "def __init__(self, target: str, action: str, params: dict):\n        \"\"\"Required information to call a component.\n\n        Args:\n            target (str): target component(s) that the call is applied to\n            action (str): action of the call\n            params (dict): params of the call\n        \"\"\"\n        self.target = target\n        self.action = action\n        self.params = params\n        self.results = {}",
  "def record_result(self, target: str, result: str = \"OK\"):\n        \"\"\"Records the result.\n\n        Args:\n            target (str): the target component(s) that is called\n            result (str): the result generated by calling the target component(s)\n        \"\"\"\n        self.results[target] = result",
  "def __init__(self):\n        \"\"\"A widget enables calling component(s).\"\"\"\n        super().__init__()\n        self.engine = None",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.engine = fl_ctx.get_engine()\n        elif event_type == EventType.END_RUN:\n            self.engine = None",
  "def call_components(self, target: str, action: str, params: dict):\n        \"\"\"Makes a call to component(s).\n\n        Args:\n            target (str): the target spec of the component(s) to be called.\n            action (str): action of the call\n            params (dict): parameters for the call\n\n        Returns:\n            None or a dict of result: comp name => result string\n\n        NOTE:\n            each component that wants to participate the call mechanism must:\n                - Listen to the event EVENT_TYPE_CALL_COMPONENT\n\n                - In the event handler, decide whether the call is applicable to it by comparing itself to\n                  the 'target'. The target could be a specific component ID, or a type of components\n\n                - decide further whether the call is applicable to it by looking at the 'action'.\n                  Conceptually, the action is like a function to be called on the component.\n                  If the component doesn't support the action, simply ignore the call.\n\n                - if the call is applicable, always report the execution status to the call.\n        \"\"\"\n        # NOTE: it's important to assign self.engine to a new var!\n        # This is because another thread may fire the END_RUN event, which will cause\n        # self.engine to be set to None, just after checking it being None and before using it!\n        engine = self.engine\n        if not engine:\n            return None\n\n        # NOTE: we need a new context here to make sure all sticky props are copied!\n        with engine.new_context() as fl_ctx:\n            info = CallInfo(target=target, action=action, params=params)\n            fl_ctx.set_prop(key=self.CTX_KEY_CALL_INFO, value=info, sticky=False, private=True)\n\n            engine.fire_event(event_type=self.EVENT_TYPE_CALL_COMPONENT, fl_ctx=fl_ctx)\n\n            return info.results",
  "class GroupInfoCollector(object):\n    def __init__(self):\n        \"\"\"Records the information using a dict of dict.\n\n        Note:\n           Key is group name and value is the information dictionary.\n        \"\"\"\n        self.info = {}\n\n    def set_info(self, group_name: str, info: dict):\n        self.info[group_name] = info\n\n    def add_info(self, group_name: str, info: dict):\n        if group_name not in self.info:\n            self.info[group_name] = info\n        else:\n            self.info[group_name].update(info)",
  "class InfoCollector(Widget):\n    CATEGORY_STATS = \"stats\"\n    CATEGORY_ERROR = \"error\"\n\n    EVENT_TYPE_GET_STATS = \"info_collector.get_stats\"\n    CTX_KEY_STATS_COLLECTOR = \"info_collector.stats_collector\"\n\n    def __init__(self):\n        \"\"\"A widget for information collection.\n\n        Note:\n           self.categories structure:\n                category (dict)\n                    group (dict)\n                        key/value (dict)\n        \"\"\"\n        super().__init__()\n        self.categories = {}\n        self.engine = None\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.reset_all()\n            self.engine = fl_ctx.get_engine()\n        elif event_type == EventType.END_RUN:\n            self.engine = None\n        elif event_type in (\n            EventType.CRITICAL_LOG_AVAILABLE,\n            EventType.ERROR_LOG_AVAILABLE,\n            EventType.WARNING_LOG_AVAILABLE,\n            EventType.EXCEPTION_LOG_AVAILABLE,\n        ):\n            origin = fl_ctx.get_prop(FLContextKey.EVENT_ORIGIN, None)\n            if origin:\n                group_name = str(origin)\n            else:\n                group_name = \"general\"\n\n            data = fl_ctx.get_prop(FLContextKey.EVENT_DATA, None)\n            if not isinstance(data, Shareable):\n                # not a valid error report\n                self.log_error(\n                    fl_ctx=fl_ctx,\n                    msg=\"wrong event data type for event {}: expect Shareable but got {}\".format(\n                        event_type, type(data)\n                    ),\n                    fire_event=False,\n                )\n                return\n\n            try:\n                dxo = from_shareable(data)\n            except:\n                self.log_exception(\n                    fl_ctx=fl_ctx, msg=\"invalid event data type for event {}\".format(event_type), fire_event=False\n                )\n                return\n\n            analytic_data = AnalyticsData.from_dxo(dxo)\n\n            if event_type == EventType.CRITICAL_LOG_AVAILABLE:\n                key = \"critical\"\n            elif event_type == EventType.ERROR_LOG_AVAILABLE:\n                key = \"error\"\n            elif event_type == EventType.WARNING_LOG_AVAILABLE:\n                key = \"warning\"\n            else:\n                key = \"exception\"\n\n            self.add_error(group_name=group_name, key=key, err=analytic_data.value)\n\n    def get_run_stats(self):\n        \"\"\"Gets status for this current run.\n\n        Returns:\n            A dictionary that contains the status for this run.\n        \"\"\"\n        # NOTE: it's important to assign self.engine to a new var!\n        # This is because another thread may fire the END_RUN event, which will cause\n        # self.engine to be set to None, just after checking it being None and before using it!\n        engine = self.engine\n        if not engine:\n            return None\n\n        # NOTE: we need a new context here to make sure all sticky props are copied!\n        # We create a new StatusCollector to hold status info.\n        # Do not use the InfoCollector itself for thread safety - multiple calls to\n        # this method (from parallel admin commands) are possible at the same time!\n        with self.engine.new_context() as fl_ctx:\n            coll = GroupInfoCollector()\n            fl_ctx.set_prop(key=self.CTX_KEY_STATS_COLLECTOR, value=coll, sticky=False, private=True)\n\n            engine.fire_event(event_type=self.EVENT_TYPE_GET_STATS, fl_ctx=fl_ctx)\n            # Get the StatusCollector from the fl_ctx, it could have been updated by other component.\n            coll = fl_ctx.get_prop(InfoCollector.CTX_KEY_STATS_COLLECTOR)\n            return coll.info\n\n    def add_info(self, category_name: str, group_name: str, key: str, value):\n        \"\"\"Adds information to the specified category / group.\n\n        Args:\n            category_name (str): The top level distinction is called category.\n            group_name (str): One level down category is called group\n            key (str): The key to be recorded inside the dict.\n            value (str): The value to be recorded inside the dict.\n        \"\"\"\n        category = self.categories.get(category_name, None)\n        if not category:\n            category = dict()\n            self.categories[category_name] = category\n        group = category.get(group_name, None)\n        if not group:\n            group = dict()\n            category[group_name] = group\n        group[key] = value\n\n    def set_info(self, category_name: str, group_name: str, info: dict):\n        \"\"\"Sets information to the specified category / group.\n\n        Args:\n            category_name (str): The top level distinction is called category.\n            group_name (str): One level down category is called group\n            info (dict): The dict to be recorded.\n\n        Note:\n            This sets the entire dictionary vs add_info only add a key-value pair.\n        \"\"\"\n        category = self.categories.get(category_name, None)\n        if not category:\n            category = dict()\n            self.categories[category_name] = category\n        category[group_name] = info\n\n    def get_category(self, category_name: str):\n        \"\"\"Gets the category dict.\n\n        Args:\n            category_name (str): The name of the category.\n\n        Returns:\n            A dictionary of specified category.\n        \"\"\"\n        return self.categories.get(category_name, None)\n\n    def get_group(self, category_name: str, group_name: str):\n        \"\"\"Gets the group dict.\n\n        Args:\n            category_name (str): The name of the category.\n            group_name (str): The name of the group_name.\n\n        Returns:\n            A dictionary of specified category/group.\n        \"\"\"\n        cat = self.categories.get(category_name, None)\n        if not cat:\n            return None\n        return cat.get(group_name, None)\n\n    def reset_all(self):\n        \"\"\"Resets all information collected.\"\"\"\n        self.categories = {}\n\n    def reset_category(self, category_name: str):\n        \"\"\"Resets the specified category information collected.\n\n        Args:\n            category_name (str): The name of the category.\n        \"\"\"\n        self.categories[category_name] = {}\n\n    def reset_group(self, category_name: str, group_name: str):\n        \"\"\"Resets the specified category/group information collected.\n\n        Args:\n            category_name (str): The name of the category.\n            group_name (str): The name of the group_name.\n        \"\"\"\n        cat = self.categories.get(category_name, None)\n        if not cat:\n            return\n        cat.get[group_name] = {}\n\n    def add_error(self, group_name: str, key: str, err: str):\n        \"\"\"Adds error information to error category.\n\n        Args:\n            group_name (str): One level down category is called group\n            key (str): The key to be recorded inside the dict.\n            err (str): The error value to be put in.\n        \"\"\"\n        now = datetime.datetime.now()\n        value = \"{}: {}\".format(now.strftime(\"%Y-%m-%d %H:%M:%S\"), err)\n\n        self.add_info(category_name=self.CATEGORY_ERROR, group_name=group_name, key=key, value=value)\n\n    def get_errors(self):\n        \"\"\"Gets the error category information.\"\"\"\n        return self.get_category(self.CATEGORY_ERROR)\n\n    def reset_errors(self, job_id):\n        \"\"\"Resets the error category information.\"\"\"\n        self.reset_category(self.CATEGORY_ERROR)",
  "def __init__(self):\n        \"\"\"Records the information using a dict of dict.\n\n        Note:\n           Key is group name and value is the information dictionary.\n        \"\"\"\n        self.info = {}",
  "def set_info(self, group_name: str, info: dict):\n        self.info[group_name] = info",
  "def add_info(self, group_name: str, info: dict):\n        if group_name not in self.info:\n            self.info[group_name] = info\n        else:\n            self.info[group_name].update(info)",
  "def __init__(self):\n        \"\"\"A widget for information collection.\n\n        Note:\n           self.categories structure:\n                category (dict)\n                    group (dict)\n                        key/value (dict)\n        \"\"\"\n        super().__init__()\n        self.categories = {}\n        self.engine = None",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.reset_all()\n            self.engine = fl_ctx.get_engine()\n        elif event_type == EventType.END_RUN:\n            self.engine = None\n        elif event_type in (\n            EventType.CRITICAL_LOG_AVAILABLE,\n            EventType.ERROR_LOG_AVAILABLE,\n            EventType.WARNING_LOG_AVAILABLE,\n            EventType.EXCEPTION_LOG_AVAILABLE,\n        ):\n            origin = fl_ctx.get_prop(FLContextKey.EVENT_ORIGIN, None)\n            if origin:\n                group_name = str(origin)\n            else:\n                group_name = \"general\"\n\n            data = fl_ctx.get_prop(FLContextKey.EVENT_DATA, None)\n            if not isinstance(data, Shareable):\n                # not a valid error report\n                self.log_error(\n                    fl_ctx=fl_ctx,\n                    msg=\"wrong event data type for event {}: expect Shareable but got {}\".format(\n                        event_type, type(data)\n                    ),\n                    fire_event=False,\n                )\n                return\n\n            try:\n                dxo = from_shareable(data)\n            except:\n                self.log_exception(\n                    fl_ctx=fl_ctx, msg=\"invalid event data type for event {}\".format(event_type), fire_event=False\n                )\n                return\n\n            analytic_data = AnalyticsData.from_dxo(dxo)\n\n            if event_type == EventType.CRITICAL_LOG_AVAILABLE:\n                key = \"critical\"\n            elif event_type == EventType.ERROR_LOG_AVAILABLE:\n                key = \"error\"\n            elif event_type == EventType.WARNING_LOG_AVAILABLE:\n                key = \"warning\"\n            else:\n                key = \"exception\"\n\n            self.add_error(group_name=group_name, key=key, err=analytic_data.value)",
  "def get_run_stats(self):\n        \"\"\"Gets status for this current run.\n\n        Returns:\n            A dictionary that contains the status for this run.\n        \"\"\"\n        # NOTE: it's important to assign self.engine to a new var!\n        # This is because another thread may fire the END_RUN event, which will cause\n        # self.engine to be set to None, just after checking it being None and before using it!\n        engine = self.engine\n        if not engine:\n            return None\n\n        # NOTE: we need a new context here to make sure all sticky props are copied!\n        # We create a new StatusCollector to hold status info.\n        # Do not use the InfoCollector itself for thread safety - multiple calls to\n        # this method (from parallel admin commands) are possible at the same time!\n        with self.engine.new_context() as fl_ctx:\n            coll = GroupInfoCollector()\n            fl_ctx.set_prop(key=self.CTX_KEY_STATS_COLLECTOR, value=coll, sticky=False, private=True)\n\n            engine.fire_event(event_type=self.EVENT_TYPE_GET_STATS, fl_ctx=fl_ctx)\n            # Get the StatusCollector from the fl_ctx, it could have been updated by other component.\n            coll = fl_ctx.get_prop(InfoCollector.CTX_KEY_STATS_COLLECTOR)\n            return coll.info",
  "def add_info(self, category_name: str, group_name: str, key: str, value):\n        \"\"\"Adds information to the specified category / group.\n\n        Args:\n            category_name (str): The top level distinction is called category.\n            group_name (str): One level down category is called group\n            key (str): The key to be recorded inside the dict.\n            value (str): The value to be recorded inside the dict.\n        \"\"\"\n        category = self.categories.get(category_name, None)\n        if not category:\n            category = dict()\n            self.categories[category_name] = category\n        group = category.get(group_name, None)\n        if not group:\n            group = dict()\n            category[group_name] = group\n        group[key] = value",
  "def set_info(self, category_name: str, group_name: str, info: dict):\n        \"\"\"Sets information to the specified category / group.\n\n        Args:\n            category_name (str): The top level distinction is called category.\n            group_name (str): One level down category is called group\n            info (dict): The dict to be recorded.\n\n        Note:\n            This sets the entire dictionary vs add_info only add a key-value pair.\n        \"\"\"\n        category = self.categories.get(category_name, None)\n        if not category:\n            category = dict()\n            self.categories[category_name] = category\n        category[group_name] = info",
  "def get_category(self, category_name: str):\n        \"\"\"Gets the category dict.\n\n        Args:\n            category_name (str): The name of the category.\n\n        Returns:\n            A dictionary of specified category.\n        \"\"\"\n        return self.categories.get(category_name, None)",
  "def get_group(self, category_name: str, group_name: str):\n        \"\"\"Gets the group dict.\n\n        Args:\n            category_name (str): The name of the category.\n            group_name (str): The name of the group_name.\n\n        Returns:\n            A dictionary of specified category/group.\n        \"\"\"\n        cat = self.categories.get(category_name, None)\n        if not cat:\n            return None\n        return cat.get(group_name, None)",
  "def reset_all(self):\n        \"\"\"Resets all information collected.\"\"\"\n        self.categories = {}",
  "def reset_category(self, category_name: str):\n        \"\"\"Resets the specified category information collected.\n\n        Args:\n            category_name (str): The name of the category.\n        \"\"\"\n        self.categories[category_name] = {}",
  "def reset_group(self, category_name: str, group_name: str):\n        \"\"\"Resets the specified category/group information collected.\n\n        Args:\n            category_name (str): The name of the category.\n            group_name (str): The name of the group_name.\n        \"\"\"\n        cat = self.categories.get(category_name, None)\n        if not cat:\n            return\n        cat.get[group_name] = {}",
  "def add_error(self, group_name: str, key: str, err: str):\n        \"\"\"Adds error information to error category.\n\n        Args:\n            group_name (str): One level down category is called group\n            key (str): The key to be recorded inside the dict.\n            err (str): The error value to be put in.\n        \"\"\"\n        now = datetime.datetime.now()\n        value = \"{}: {}\".format(now.strftime(\"%Y-%m-%d %H:%M:%S\"), err)\n\n        self.add_info(category_name=self.CATEGORY_ERROR, group_name=group_name, key=key, value=value)",
  "def get_errors(self):\n        \"\"\"Gets the error category information.\"\"\"\n        return self.get_category(self.CATEGORY_ERROR)",
  "def reset_errors(self, job_id):\n        \"\"\"Resets the error category information.\"\"\"\n        self.reset_category(self.CATEGORY_ERROR)",
  "class FilterChain(object):\n    def __init__(self):\n        \"\"\"To init the FilterChain.\"\"\"\n        self.tasks = []\n        self.filters = []",
  "class FedJsonConfigurator(JsonConfigurator):\n    def __init__(self, config_file_name: str, base_pkgs: [str], module_names: [str], exclude_libs=True):\n        \"\"\"To init the FedJsonConfigurator.\n\n        Args:\n            config_file_name: config filename\n            base_pkgs: base packages need to be scanned\n            module_names: module names need to be scanned\n            exclude_libs: True/False to exclude the libs folder\n        \"\"\"\n        JsonConfigurator.__init__(\n            self,\n            config_file_name=config_file_name,\n            base_pkgs=base_pkgs,\n            module_names=module_names,\n            exclude_libs=exclude_libs,\n        )\n\n        self.format_version = None\n        self.handlers = []\n        self.components = {}  # id => component\n        self.task_data_filter_chains = []\n        self.task_result_filter_chains = []\n        self.current_filter_chain = None\n        self.data_filter_table = None\n        self.result_filter_table = None\n\n    def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        element = node.element\n        path = node.path()\n\n        if path == \"format_version\":\n            self.format_version = element\n            return\n\n        # if re.search(r\"^handlers\\.#[0-9]+$\", path):\n        #     h = self.build_component(element)\n        #     if not isinstance(h, FLComponent):\n        #         raise ConfigError(\"handler must be a FLComponent object, but got {}\".format(type(h)))\n        #     # Ensure only add one instance of the handlers for the same component\n        #     if type(h).__name__ not in [type(t).__name__ for t in self.handlers]:\n        #         self.handlers.append(h)\n        #     return\n\n        if re.search(r\"^components\\.#[0-9]+$\", path):\n            c = self.build_component(element)\n            cid = element.get(\"id\", None)\n            if not cid:\n                raise ConfigError(\"missing component id\")\n\n            if not isinstance(cid, str):\n                raise ConfigError('\"id\" must be str but got {}'.format(type(cid)))\n\n            if cid in self.components:\n                raise ConfigError('duplicate component id \"{}\"'.format(cid))\n\n            self.components[cid] = c\n            return\n\n        # result filters\n        if re.search(r\"^task_result_filters\\.#[0-9]+$\", path):\n            self.current_filter_chain = FilterChain()\n            node.props[\"data\"] = self.current_filter_chain\n            node.exit_cb = self._process_result_filter_chain\n            return\n\n        if re.search(r\"^task_result_filters\\.#[0-9]+\\.tasks$\", path):\n            self.current_filter_chain.tasks = element\n            return\n\n        if re.search(r\"^task_result_filters.#[0-9]+\\.filters\\.#[0-9]+$\", path):\n            f = self.build_component(element)\n            self.current_filter_chain.filters.append(f)\n            return\n\n        # data filters\n        if re.search(r\"^task_data_filters\\.#[0-9]+$\", path):\n            self.current_filter_chain = FilterChain()\n            node.props[\"data\"] = self.current_filter_chain\n            node.exit_cb = self._process_data_filter_chain\n            return\n\n        if re.search(r\"^task_data_filters\\.#[0-9]+\\.tasks$\", path):\n            self.current_filter_chain.tasks = element\n            return\n\n        if re.search(r\"^task_data_filters.#[0-9]+\\.filters\\.#[0-9]+$\", path):\n            f = self.build_component(element)\n            self.current_filter_chain.filters.append(f)\n            return\n\n    def validate_tasks(self, tasks):\n        if not isinstance(tasks, list):\n            raise ConfigError('\"tasks\" must be specified as list of task names but got {}'.format(type(tasks)))\n\n        if len(tasks) <= 0:\n            raise ConfigError('\"tasks\" must not be empty')\n\n        for n in tasks:\n            if not isinstance(n, str):\n                raise ConfigError(\"task names must be string but got {}\".format(type(n)))\n\n    def validate_filter_chain(self, chain: FilterChain):\n        self.validate_tasks(chain.tasks)\n\n        if not isinstance(chain.filters, list):\n            raise ConfigError('\"filters\" must be specified as list of filters but got {}'.format(type(chain.filters)))\n\n        if len(chain.filters) <= 0:\n            raise ConfigError('\"filters\" must not be empty')\n\n        for f in chain.filters:\n            if not isinstance(f, Filter):\n                raise ConfigError('\"filters\" must contain Filter object but got {}'.format(type(f)))\n\n    def _process_result_filter_chain(self, node: Node):\n        filter_chain = node.props[\"data\"]\n        self.validate_filter_chain(filter_chain)\n        self.task_result_filter_chains.append(filter_chain)\n\n    def _process_data_filter_chain(self, node: Node):\n        filter_chain = node.props[\"data\"]\n        self.validate_filter_chain(filter_chain)\n        self.task_data_filter_chains.append(filter_chain)\n\n    def finalize_config(self, config_ctx: ConfigContext):\n        if self.format_version is None:\n            raise ConfigError(\"missing format_version\")\n\n        if not isinstance(self.format_version, int):\n            raise ConfigError('\"format_version\" must be int, but got {}'.format(type(self.format_version)))\n\n        if self.format_version != 2:\n            raise ConfigError('wrong \"format_version\" {}: must be 2'.format(self.format_version))\n\n        data_filter_table = {}\n        for c in self.task_data_filter_chains:\n            if not isinstance(c, FilterChain):\n                raise TypeError(\"chain must be FilterChain but got {}\".format(type(c)))\n            for t in c.tasks:\n                if t in data_filter_table:\n                    raise ConfigError(\"multiple data filter chains defined for task {}\".format(t))\n                data_filter_table[t] = c.filters\n        self.data_filter_table = data_filter_table\n\n        result_filter_table = {}\n        for c in self.task_result_filter_chains:\n            if not isinstance(c, FilterChain):\n                raise TypeError(\"chain must be FilterChain but got {}\".format(type(c)))\n            for t in c.tasks:\n                if t in result_filter_table:\n                    raise ConfigError(\"multiple data filter chains defined for task {}\".format(t))\n                result_filter_table[t] = c.filters\n\n        self.result_filter_table = result_filter_table",
  "def __init__(self):\n        \"\"\"To init the FilterChain.\"\"\"\n        self.tasks = []\n        self.filters = []",
  "def __init__(self, config_file_name: str, base_pkgs: [str], module_names: [str], exclude_libs=True):\n        \"\"\"To init the FedJsonConfigurator.\n\n        Args:\n            config_file_name: config filename\n            base_pkgs: base packages need to be scanned\n            module_names: module names need to be scanned\n            exclude_libs: True/False to exclude the libs folder\n        \"\"\"\n        JsonConfigurator.__init__(\n            self,\n            config_file_name=config_file_name,\n            base_pkgs=base_pkgs,\n            module_names=module_names,\n            exclude_libs=exclude_libs,\n        )\n\n        self.format_version = None\n        self.handlers = []\n        self.components = {}  # id => component\n        self.task_data_filter_chains = []\n        self.task_result_filter_chains = []\n        self.current_filter_chain = None\n        self.data_filter_table = None\n        self.result_filter_table = None",
  "def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        element = node.element\n        path = node.path()\n\n        if path == \"format_version\":\n            self.format_version = element\n            return\n\n        # if re.search(r\"^handlers\\.#[0-9]+$\", path):\n        #     h = self.build_component(element)\n        #     if not isinstance(h, FLComponent):\n        #         raise ConfigError(\"handler must be a FLComponent object, but got {}\".format(type(h)))\n        #     # Ensure only add one instance of the handlers for the same component\n        #     if type(h).__name__ not in [type(t).__name__ for t in self.handlers]:\n        #         self.handlers.append(h)\n        #     return\n\n        if re.search(r\"^components\\.#[0-9]+$\", path):\n            c = self.build_component(element)\n            cid = element.get(\"id\", None)\n            if not cid:\n                raise ConfigError(\"missing component id\")\n\n            if not isinstance(cid, str):\n                raise ConfigError('\"id\" must be str but got {}'.format(type(cid)))\n\n            if cid in self.components:\n                raise ConfigError('duplicate component id \"{}\"'.format(cid))\n\n            self.components[cid] = c\n            return\n\n        # result filters\n        if re.search(r\"^task_result_filters\\.#[0-9]+$\", path):\n            self.current_filter_chain = FilterChain()\n            node.props[\"data\"] = self.current_filter_chain\n            node.exit_cb = self._process_result_filter_chain\n            return\n\n        if re.search(r\"^task_result_filters\\.#[0-9]+\\.tasks$\", path):\n            self.current_filter_chain.tasks = element\n            return\n\n        if re.search(r\"^task_result_filters.#[0-9]+\\.filters\\.#[0-9]+$\", path):\n            f = self.build_component(element)\n            self.current_filter_chain.filters.append(f)\n            return\n\n        # data filters\n        if re.search(r\"^task_data_filters\\.#[0-9]+$\", path):\n            self.current_filter_chain = FilterChain()\n            node.props[\"data\"] = self.current_filter_chain\n            node.exit_cb = self._process_data_filter_chain\n            return\n\n        if re.search(r\"^task_data_filters\\.#[0-9]+\\.tasks$\", path):\n            self.current_filter_chain.tasks = element\n            return\n\n        if re.search(r\"^task_data_filters.#[0-9]+\\.filters\\.#[0-9]+$\", path):\n            f = self.build_component(element)\n            self.current_filter_chain.filters.append(f)\n            return",
  "def validate_tasks(self, tasks):\n        if not isinstance(tasks, list):\n            raise ConfigError('\"tasks\" must be specified as list of task names but got {}'.format(type(tasks)))\n\n        if len(tasks) <= 0:\n            raise ConfigError('\"tasks\" must not be empty')\n\n        for n in tasks:\n            if not isinstance(n, str):\n                raise ConfigError(\"task names must be string but got {}\".format(type(n)))",
  "def validate_filter_chain(self, chain: FilterChain):\n        self.validate_tasks(chain.tasks)\n\n        if not isinstance(chain.filters, list):\n            raise ConfigError('\"filters\" must be specified as list of filters but got {}'.format(type(chain.filters)))\n\n        if len(chain.filters) <= 0:\n            raise ConfigError('\"filters\" must not be empty')\n\n        for f in chain.filters:\n            if not isinstance(f, Filter):\n                raise ConfigError('\"filters\" must contain Filter object but got {}'.format(type(f)))",
  "def _process_result_filter_chain(self, node: Node):\n        filter_chain = node.props[\"data\"]\n        self.validate_filter_chain(filter_chain)\n        self.task_result_filter_chains.append(filter_chain)",
  "def _process_data_filter_chain(self, node: Node):\n        filter_chain = node.props[\"data\"]\n        self.validate_filter_chain(filter_chain)\n        self.task_data_filter_chains.append(filter_chain)",
  "def finalize_config(self, config_ctx: ConfigContext):\n        if self.format_version is None:\n            raise ConfigError(\"missing format_version\")\n\n        if not isinstance(self.format_version, int):\n            raise ConfigError('\"format_version\" must be int, but got {}'.format(type(self.format_version)))\n\n        if self.format_version != 2:\n            raise ConfigError('wrong \"format_version\" {}: must be 2'.format(self.format_version))\n\n        data_filter_table = {}\n        for c in self.task_data_filter_chains:\n            if not isinstance(c, FilterChain):\n                raise TypeError(\"chain must be FilterChain but got {}\".format(type(c)))\n            for t in c.tasks:\n                if t in data_filter_table:\n                    raise ConfigError(\"multiple data filter chains defined for task {}\".format(t))\n                data_filter_table[t] = c.filters\n        self.data_filter_table = data_filter_table\n\n        result_filter_table = {}\n        for c in self.task_result_filter_chains:\n            if not isinstance(c, FilterChain):\n                raise TypeError(\"chain must be FilterChain but got {}\".format(type(c)))\n            for t in c.tasks:\n                if t in result_filter_table:\n                    raise ConfigError(\"multiple data filter chains defined for task {}\".format(t))\n                result_filter_table[t] = c.filters\n\n        self.result_filter_table = result_filter_table",
  "class MsgHeader(object):\n\n    REF_MSG_ID = \"_refMsgId\"\n    RETURN_CODE = \"_rtnCode\"",
  "class ReturnCode(object):\n\n    OK = \"_ok\"\n    ERROR = \"_error\"",
  "class Message(object):\n    def __init__(self, topic: str, body):\n        \"\"\"To init a Message.\n\n        Args:\n            topic: message topic\n            body: message body.\n        \"\"\"\n        self.id = str(uuid.uuid4())\n        self.topic = topic\n        self.body = body\n        self.headers = {}\n\n    def set_header(self, key, value):\n        self.headers[key] = value\n\n    def set_headers(self, headers: dict):\n        if not headers:\n            return\n        if not isinstance(headers, dict):\n            raise TypeError(\"headers must be dict but got {}\".format(type(headers)))\n        if len(headers) > 0:\n            self.headers.update(headers)\n\n    def get_header(self, key, default=None):\n        return self.headers.get(key, default)\n\n    def get_ref_id(self, default=None):\n        return self.get_header(MsgHeader.REF_MSG_ID, default)\n\n    def set_ref_id(self, msg_id):\n        self.set_header(MsgHeader.REF_MSG_ID, msg_id)",
  "def error_reply(err: str) -> Message:\n    msg = Message(topic=\"reply\", body=err)\n    msg.set_header(MsgHeader.RETURN_CODE, ReturnCode.ERROR)\n    return msg",
  "def ok_reply(data=None) -> Message:\n    if data is None:\n        data = \"ok\"\n\n    msg = Message(topic=\"reply\", body=data)\n    msg.set_header(MsgHeader.RETURN_CODE, ReturnCode.OK)\n    return msg",
  "def __init__(self, topic: str, body):\n        \"\"\"To init a Message.\n\n        Args:\n            topic: message topic\n            body: message body.\n        \"\"\"\n        self.id = str(uuid.uuid4())\n        self.topic = topic\n        self.body = body\n        self.headers = {}",
  "def set_header(self, key, value):\n        self.headers[key] = value",
  "def set_headers(self, headers: dict):\n        if not headers:\n            return\n        if not isinstance(headers, dict):\n            raise TypeError(\"headers must be dict but got {}\".format(type(headers)))\n        if len(headers) > 0:\n            self.headers.update(headers)",
  "def get_header(self, key, default=None):\n        return self.headers.get(key, default)",
  "def get_ref_id(self, default=None):\n        return self.get_header(MsgHeader.REF_MSG_ID, default)",
  "def set_ref_id(self, msg_id):\n        self.set_header(MsgHeader.REF_MSG_ID, msg_id)",
  "class SpecialTaskName(object):\n\n    TRY_AGAIN = \"__try_again__\"\n    END_RUN = \"__end_run__\"",
  "class TaskConstant(object):\n    WAIT_TIME = \"__wait_time__\"",
  "class EngineConstant(object):\n\n    FEDERATE_CLIENT = \"federate_client\"\n    FL_TOKEN = \"fl_token\"\n    CLIENT_TOKEN_FILE = \"client_token.txt\"\n    ENGINE_TASK_NAME = \"engine_task_name\"",
  "class InfoCollectorTopic(object):\n\n    SHOW_STATS = \"info.show_stats\"\n    SHOW_ERRORS = \"info.show_errors\"\n    RESET_ERRORS = \"info.reset_errors\"",
  "class ComponentCallerTopic(object):\n\n    CALL_COMPONENT = \"comp_caller.call\"",
  "class TrainingTopic(object):\n\n    START = \"train.start\"\n    ABORT = \"train.abort\"\n    ABORT_TASK = \"train.abort_task\"\n    DELETE_RUN = \"train.delete_run\"\n    DEPLOY = \"train.deploy\"\n    SHUTDOWN = \"train.shutdown\"\n    RESTART = \"train.restart\"\n    CHECK_STATUS = \"train.check_status\"\n    SET_JOB_ID = \"train.set_job_id\"\n    CHECK_RESOURCE = \"scheduler.check_resource\"\n    ALLOCATE_RESOURCE = \"scheduler.allocate_resource\"\n    CANCEL_RESOURCE = \"scheduler.cancel_resource\"\n    START_JOB = \"train.start_job\"",
  "class RequestHeader(object):\n\n    JOB_ID = \"job_id\"\n    APP_NAME = \"app_name\"\n    CONTROL_COMMAND = \"control_command\"\n    CALL_NAME = \"call_name\"\n    COMPONENT_TARGET = \"component_target\"",
  "class SysCommandTopic(object):\n\n    SYS_INFO = \"sys.info\"\n    SHELL = \"sys.shell\"",
  "class ControlCommandTopic(object):\n\n    DO_COMMAND = \"control.do_command\"",
  "class ControlCommandName(object):\n\n    ABORT_TASK = \"abort_task\"\n    END_RUN = \"end_run\"",
  "class ClientStatusKey(object):\n\n    JOB_ID = \"job_id\"\n    CURRENT_TASK = \"current_task\"\n    STATUS = \"status\"\n    APP_NAME = \"app_name\"\n    CLIENT_NAME = \"client_name\"\n    RUNNING_JOBS = \"running_jobs\"",
  "class AppFolderConstants:\n    \"\"\"hard coded file names inside the app folder.\"\"\"\n\n    CONFIG_TRAIN = \"config_train.json\"\n    CONFIG_ENV = \"environment.json\"\n    CONFIG_FED_SERVER = \"config_fed_server.json\"\n    CONFIG_FED_CLIENT = \"config_fed_client.json\"",
  "class SSLConstants:\n    \"\"\"hard coded names related to SSL.\"\"\"\n\n    CERT = \"ssl_cert\"\n    PRIVATE_KEY = \"ssl_private_key\"\n    ROOT_CERT = \"ssl_root_cert\"",
  "class AuxRunner(FLComponent):\n\n    DATA_KEY_BULK = \"bulk_data\"\n    TOPIC_BULK = \"__runner.bulk__\"\n\n    def __init__(self):\n        \"\"\"To init the AuxRunner.\"\"\"\n        FLComponent.__init__(self)\n        self.job_id = None\n        self.topic_table = {\n            self.TOPIC_BULK: self._process_bulk_requests,\n        }  # topic => handler\n        self.reg_lock = Lock()\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.job_id = fl_ctx.get_job_id()\n\n    def register_aux_message_handler(self, topic: str, message_handle_func):\n        \"\"\"Register aux message handling function with specified topics.\n\n        This method should be called by ServerEngine's register_aux_message_handler method.\n\n        Args:\n            topic: the topic to be handled by the func\n            message_handle_func: the func to handle the message. Must follow aux_message_handle_func_signature.\n\n        Returns: N/A\n\n        Exception is raised when:\n            a handler is already registered for the topic;\n            bad topic - must be a non-empty string\n            bad message_handle_func - must be callable\n        \"\"\"\n        if not isinstance(topic, str):\n            raise TypeError(\"topic must be str, but got {}\".format(type(topic)))\n\n        if topic == self.TOPIC_BULK:\n            raise ValueError('topic value \"{}\" is reserved'.format(topic))\n\n        if len(topic) <= 0:\n            raise ValueError(\"topic must not be empty\")\n\n        if message_handle_func is None:\n            raise ValueError(\"message handler function is not specified\")\n\n        if not callable(message_handle_func):\n            raise TypeError(\"specified message_handle_func {} is not callable\".format(message_handle_func))\n\n        with self.reg_lock:\n            if topic in self.topic_table:\n                raise ValueError(\"handler already registered for topic {}\".format(topic))\n\n            self.topic_table[topic] = message_handle_func\n\n    def _process_request(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Call to process the request.\n\n        NOTE: peer_ctx props must have been set into the PEER_PROPS header of the request by Engine.\n\n        Args:\n            topic: topic of the message\n            request: message to be handled\n            fl_ctx: fl context\n\n        Returns: reply message\n\n        \"\"\"\n        handler_f = self.topic_table.get(topic, None)\n        if handler_f is None:\n            self.log_error(fl_ctx, \"received unknown aux message topic {}\".format(topic))\n            return make_reply(ReturnCode.TOPIC_UNKNOWN)\n\n        if not isinstance(request, Shareable):\n            self.log_error(fl_ctx, \"received invalid aux request: expects a Shareable but got {}\".format(type(request)))\n            return make_reply(ReturnCode.BAD_REQUEST_DATA)\n\n        peer_props = request.get_peer_props()\n        if not peer_props:\n            self.log_error(fl_ctx, \"missing peer_ctx from client\")\n            return make_reply(ReturnCode.MISSING_PEER_CONTEXT)\n\n        if not isinstance(peer_props, dict):\n            self.log_error(\n                fl_ctx,\n                \"bad peer_props from client: expects dict but got {}\".format(type(peer_props)),\n            )\n            return make_reply(ReturnCode.BAD_PEER_CONTEXT)\n\n        peer_job_id = peer_props.get(ReservedKey.RUN_NUM)\n        if peer_job_id != self.job_id:\n            self.log_error(fl_ctx, \"invalid aux msg: not for the same job_id\")\n            return make_reply(ReturnCode.RUN_MISMATCH)\n\n        try:\n            reply = handler_f(topic=topic, request=request, fl_ctx=fl_ctx)\n        except BaseException:\n            self.log_exception(fl_ctx, \"processing error in message handling\")\n            return make_reply(ReturnCode.HANDLER_EXCEPTION)\n\n        return reply\n\n    def dispatch(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"This method is to be called by the Engine when an aux message is received from peer.\n\n        NOTE: peer_ctx props must have been set into the PEER_PROPS header of the request by Engine.\n\n        Args:\n            topic: message topic\n            request: request message\n            fl_ctx: FLContext\n\n        Returns: reply message\n\n        \"\"\"\n        valid_reply = self._process_request(topic, request, fl_ctx)\n        if isinstance(request, Shareable):\n            cookie_jar = request.get_cookie_jar()\n            if cookie_jar:\n                valid_reply.set_cookie_jar(cookie_jar)\n\n        valid_reply.set_peer_props(fl_ctx.get_all_public_props())\n        return valid_reply\n\n    def _process_bulk_requests(self, topic: str, request: Shareable, fl_ctx: FLContext):\n        reqs = request.get(self.DATA_KEY_BULK, None)\n        if not isinstance(reqs, list):\n            self.log_error(fl_ctx, \"invalid bulk request - missing list of requests, got {} instead\".format(type(reqs)))\n            return make_reply(ReturnCode.BAD_REQUEST_DATA)\n\n        abort_signal = fl_ctx.get_run_abort_signal()\n        for req in reqs:\n            if isinstance(abort_signal, Signal) and abort_signal.triggered:\n                break\n\n            if not isinstance(req, Shareable):\n                self.log_error(fl_ctx, \"invalid request in bulk: expect Shareable but got {}\".format(type(req)))\n                continue\n            req_topic = req.get_header(ReservedHeaderKey.TOPIC, \"\")\n            if not req_topic:\n                self.log_error(fl_ctx, \"invalid request in bulk: no topic in header\")\n                continue\n\n            self._process_request(req_topic, req, fl_ctx)\n        return make_reply(ReturnCode.OK)",
  "def __init__(self):\n        \"\"\"To init the AuxRunner.\"\"\"\n        FLComponent.__init__(self)\n        self.job_id = None\n        self.topic_table = {\n            self.TOPIC_BULK: self._process_bulk_requests,\n        }  # topic => handler\n        self.reg_lock = Lock()",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.job_id = fl_ctx.get_job_id()",
  "def register_aux_message_handler(self, topic: str, message_handle_func):\n        \"\"\"Register aux message handling function with specified topics.\n\n        This method should be called by ServerEngine's register_aux_message_handler method.\n\n        Args:\n            topic: the topic to be handled by the func\n            message_handle_func: the func to handle the message. Must follow aux_message_handle_func_signature.\n\n        Returns: N/A\n\n        Exception is raised when:\n            a handler is already registered for the topic;\n            bad topic - must be a non-empty string\n            bad message_handle_func - must be callable\n        \"\"\"\n        if not isinstance(topic, str):\n            raise TypeError(\"topic must be str, but got {}\".format(type(topic)))\n\n        if topic == self.TOPIC_BULK:\n            raise ValueError('topic value \"{}\" is reserved'.format(topic))\n\n        if len(topic) <= 0:\n            raise ValueError(\"topic must not be empty\")\n\n        if message_handle_func is None:\n            raise ValueError(\"message handler function is not specified\")\n\n        if not callable(message_handle_func):\n            raise TypeError(\"specified message_handle_func {} is not callable\".format(message_handle_func))\n\n        with self.reg_lock:\n            if topic in self.topic_table:\n                raise ValueError(\"handler already registered for topic {}\".format(topic))\n\n            self.topic_table[topic] = message_handle_func",
  "def _process_request(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Call to process the request.\n\n        NOTE: peer_ctx props must have been set into the PEER_PROPS header of the request by Engine.\n\n        Args:\n            topic: topic of the message\n            request: message to be handled\n            fl_ctx: fl context\n\n        Returns: reply message\n\n        \"\"\"\n        handler_f = self.topic_table.get(topic, None)\n        if handler_f is None:\n            self.log_error(fl_ctx, \"received unknown aux message topic {}\".format(topic))\n            return make_reply(ReturnCode.TOPIC_UNKNOWN)\n\n        if not isinstance(request, Shareable):\n            self.log_error(fl_ctx, \"received invalid aux request: expects a Shareable but got {}\".format(type(request)))\n            return make_reply(ReturnCode.BAD_REQUEST_DATA)\n\n        peer_props = request.get_peer_props()\n        if not peer_props:\n            self.log_error(fl_ctx, \"missing peer_ctx from client\")\n            return make_reply(ReturnCode.MISSING_PEER_CONTEXT)\n\n        if not isinstance(peer_props, dict):\n            self.log_error(\n                fl_ctx,\n                \"bad peer_props from client: expects dict but got {}\".format(type(peer_props)),\n            )\n            return make_reply(ReturnCode.BAD_PEER_CONTEXT)\n\n        peer_job_id = peer_props.get(ReservedKey.RUN_NUM)\n        if peer_job_id != self.job_id:\n            self.log_error(fl_ctx, \"invalid aux msg: not for the same job_id\")\n            return make_reply(ReturnCode.RUN_MISMATCH)\n\n        try:\n            reply = handler_f(topic=topic, request=request, fl_ctx=fl_ctx)\n        except BaseException:\n            self.log_exception(fl_ctx, \"processing error in message handling\")\n            return make_reply(ReturnCode.HANDLER_EXCEPTION)\n\n        return reply",
  "def dispatch(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"This method is to be called by the Engine when an aux message is received from peer.\n\n        NOTE: peer_ctx props must have been set into the PEER_PROPS header of the request by Engine.\n\n        Args:\n            topic: message topic\n            request: request message\n            fl_ctx: FLContext\n\n        Returns: reply message\n\n        \"\"\"\n        valid_reply = self._process_request(topic, request, fl_ctx)\n        if isinstance(request, Shareable):\n            cookie_jar = request.get_cookie_jar()\n            if cookie_jar:\n                valid_reply.set_cookie_jar(cookie_jar)\n\n        valid_reply.set_peer_props(fl_ctx.get_all_public_props())\n        return valid_reply",
  "def _process_bulk_requests(self, topic: str, request: Shareable, fl_ctx: FLContext):\n        reqs = request.get(self.DATA_KEY_BULK, None)\n        if not isinstance(reqs, list):\n            self.log_error(fl_ctx, \"invalid bulk request - missing list of requests, got {} instead\".format(type(reqs)))\n            return make_reply(ReturnCode.BAD_REQUEST_DATA)\n\n        abort_signal = fl_ctx.get_run_abort_signal()\n        for req in reqs:\n            if isinstance(abort_signal, Signal) and abort_signal.triggered:\n                break\n\n            if not isinstance(req, Shareable):\n                self.log_error(fl_ctx, \"invalid request in bulk: expect Shareable but got {}\".format(type(req)))\n                continue\n            req_topic = req.get_header(ReservedHeaderKey.TOPIC, \"\")\n            if not req_topic:\n                self.log_error(fl_ctx, \"invalid request in bulk: no topic in header\")\n                continue\n\n            self._process_request(req_topic, req, fl_ctx)\n        return make_reply(ReturnCode.OK)",
  "def fire_event(event: str, handlers: list, ctx: FLContext):\n    \"\"\"Fires the specified event and invokes the list of handlers.\n\n    Args:\n        event: the event to be fired\n        handlers: handlers to be invoked\n        ctx: context for cross-component data sharing\n\n    Returns: N/A\n\n    \"\"\"\n    event_id = str(uuid.uuid4())\n    event_data = ctx.get_prop(FLContextKey.EVENT_DATA, None)\n    event_origin = ctx.get_prop(FLContextKey.EVENT_ORIGIN, None)\n    event_scope = ctx.get_prop(FLContextKey.EVENT_SCOPE, EventScope.LOCAL)\n\n    depth = ctx.get_prop(_KEY_EVENT_DEPTH, 0)\n    if depth > _MAX_EVENT_DEPTH:\n        # too many recursive event calls\n        raise RuntimeError(\"Recursive event calls too deep (>{})\".format(_MAX_EVENT_DEPTH))\n\n    ctx.set_prop(key=_KEY_EVENT_DEPTH, value=depth + 1, private=True, sticky=False)\n\n    if handlers:\n        for h in handlers:\n            if not isinstance(h, FLComponent):\n                raise TypeError(\"handler must be FLComponent but got {}\".format(type(h)))\n            try:\n                # since events could be recursive (a handler fires another event) on the same fl_ctx,\n                # we need to reset these key values into the fl_ctx\n                ctx.set_prop(key=FLContextKey.EVENT_ID, value=event_id, private=True, sticky=False)\n                ctx.set_prop(key=FLContextKey.EVENT_DATA, value=event_data, private=True, sticky=False)\n                ctx.set_prop(key=FLContextKey.EVENT_ORIGIN, value=event_origin, private=True, sticky=False)\n                ctx.set_prop(key=FLContextKey.EVENT_SCOPE, value=event_scope, private=True, sticky=False)\n                h.handle_event(event, ctx)\n            except Exception as e:\n                h.log_exception(ctx, 'Exception when handling event \"{}\": {}'.format(event, e), fire_event=False)\n\n    ctx.set_prop(key=_KEY_EVENT_DEPTH, value=depth, private=True, sticky=False)",
  "class ShareableHeader:\n    CHECK_RESOURCE_RESULT = \"_check_resource_result\"\n    RESOURCE_RESERVE_TOKEN = \"_resource_reserve_token\"",
  "class ConfigContext(object):\n    def __init__(self):\n        \"\"\"To init thee ConfigContext.\"\"\"\n        self.config_json = None\n        self.pass_num = 0",
  "class JsonConfigurator(JsonObjectProcessor, ComponentBuilder):\n    def __init__(\n        self,\n        config_file_name: str,\n        base_pkgs: [str],\n        module_names: [str],\n        exclude_libs=True,\n        num_passes=1,\n    ):\n        \"\"\"To init the JsonConfigurator.\n\n        Args:\n            config_file_name: config filename\n            base_pkgs: base packages need to be scanned\n            module_names: module names need to be scanned\n            exclude_libs: True/False to exclude the libs folder\n            num_passes: number of passes to parsing the config\n        \"\"\"\n        JsonObjectProcessor.__init__(self)\n\n        if not isinstance(num_passes, int):\n            raise TypeError(\"num_passes must be int but got {}\".format(type(num_passes)))\n        if not num_passes > 0:\n            raise ValueError(\"num_passes must > 0 but got {}\".format(num_passes))\n        if not isinstance(config_file_name, str):\n            raise TypeError(\"config_file_name must be str but got {}\".format(type(config_file_name)))\n        if not os.path.isfile(config_file_name):\n            raise FileNotFoundError(\"config_file_name {} is not a valid file\".format(config_file_name))\n        if not os.path.exists(config_file_name):\n            raise FileNotFoundError(\"config_file_name {} does not exist\".format(config_file_name))\n\n        self.config_file_name = config_file_name\n        self.num_passes = num_passes\n        self.module_scanner = ModuleScanner(base_pkgs, module_names, exclude_libs)\n        self.config_ctx = None\n\n        with open(config_file_name) as file:\n            self.config_data = json.load(file)\n\n        self.json_scanner = JsonScanner(self.config_data, config_file_name)\n\n    def get_module_scanner(self):\n        return self.module_scanner\n\n    def _do_configure(self):\n        config_ctx = ConfigContext()\n        config_ctx.config_json = self.config_data\n        self.config_ctx = config_ctx\n\n        all_vars = extract_first_level_primitive(self.config_data)\n        self.json_scanner.scan(_EnvUpdater(all_vars))\n\n        self.start_config(self.config_ctx)\n\n        # scan the config to create components\n        for i in range(self.num_passes):\n            self.config_ctx.pass_num = i + 1\n            self.json_scanner.scan(self)\n\n        # finalize configuration\n        self.finalize_config(self.config_ctx)\n\n    def configure(self):\n        try:\n            self._do_configure()\n        except ConfigError as ex:\n            raise ConfigError(\"Config error in {}: {}\".format(self.config_file_name, ex))\n        except Exception as ex:\n            print(\"Error processing config {}: {}\".format(self.config_file_name, ex))\n            raise ex\n\n    def process_element(self, node: Node):\n        self.process_config_element(self.config_ctx, node)\n\n    def is_configured_subclass(self, config_dict, base_class):\n        return issubclass(get_class(self.get_class_path(config_dict)), base_class)\n\n    def start_config(self, config_ctx: ConfigContext):\n        pass\n\n    def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        pass\n\n    def finalize_config(self, config_ctx: ConfigContext):\n        pass",
  "def get_component_refs(component):\n    if \"name\" in component:\n        name = component[\"name\"]\n        key = \"name\"\n    elif \"path\" in component:\n        name = component[\"path\"]\n        key = \"path\"\n    else:\n        raise ConfigError('component has no \"name\" or \"path')\n\n    parts = name.split(\"#\")\n    component[key] = parts[0]\n    return parts",
  "def __init__(self):\n        \"\"\"To init thee ConfigContext.\"\"\"\n        self.config_json = None\n        self.pass_num = 0",
  "def __init__(\n        self,\n        config_file_name: str,\n        base_pkgs: [str],\n        module_names: [str],\n        exclude_libs=True,\n        num_passes=1,\n    ):\n        \"\"\"To init the JsonConfigurator.\n\n        Args:\n            config_file_name: config filename\n            base_pkgs: base packages need to be scanned\n            module_names: module names need to be scanned\n            exclude_libs: True/False to exclude the libs folder\n            num_passes: number of passes to parsing the config\n        \"\"\"\n        JsonObjectProcessor.__init__(self)\n\n        if not isinstance(num_passes, int):\n            raise TypeError(\"num_passes must be int but got {}\".format(type(num_passes)))\n        if not num_passes > 0:\n            raise ValueError(\"num_passes must > 0 but got {}\".format(num_passes))\n        if not isinstance(config_file_name, str):\n            raise TypeError(\"config_file_name must be str but got {}\".format(type(config_file_name)))\n        if not os.path.isfile(config_file_name):\n            raise FileNotFoundError(\"config_file_name {} is not a valid file\".format(config_file_name))\n        if not os.path.exists(config_file_name):\n            raise FileNotFoundError(\"config_file_name {} does not exist\".format(config_file_name))\n\n        self.config_file_name = config_file_name\n        self.num_passes = num_passes\n        self.module_scanner = ModuleScanner(base_pkgs, module_names, exclude_libs)\n        self.config_ctx = None\n\n        with open(config_file_name) as file:\n            self.config_data = json.load(file)\n\n        self.json_scanner = JsonScanner(self.config_data, config_file_name)",
  "def get_module_scanner(self):\n        return self.module_scanner",
  "def _do_configure(self):\n        config_ctx = ConfigContext()\n        config_ctx.config_json = self.config_data\n        self.config_ctx = config_ctx\n\n        all_vars = extract_first_level_primitive(self.config_data)\n        self.json_scanner.scan(_EnvUpdater(all_vars))\n\n        self.start_config(self.config_ctx)\n\n        # scan the config to create components\n        for i in range(self.num_passes):\n            self.config_ctx.pass_num = i + 1\n            self.json_scanner.scan(self)\n\n        # finalize configuration\n        self.finalize_config(self.config_ctx)",
  "def configure(self):\n        try:\n            self._do_configure()\n        except ConfigError as ex:\n            raise ConfigError(\"Config error in {}: {}\".format(self.config_file_name, ex))\n        except Exception as ex:\n            print(\"Error processing config {}: {}\".format(self.config_file_name, ex))\n            raise ex",
  "def process_element(self, node: Node):\n        self.process_config_element(self.config_ctx, node)",
  "def is_configured_subclass(self, config_dict, base_class):\n        return issubclass(get_class(self.get_class_path(config_dict)), base_class)",
  "def start_config(self, config_ctx: ConfigContext):\n        pass",
  "def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        pass",
  "def finalize_config(self, config_ctx: ConfigContext):\n        pass",
  "class FederatedTrainingStub(object):\n    \"\"\"The global federated model interfaces\n    \"\"\"\n\n    def __init__(self, channel):\n        \"\"\"Constructor.\n\n        Args:\n            channel: A grpc.Channel.\n        \"\"\"\n        self.Register = channel.unary_unary(\n                '/fedlearn.FederatedTraining/Register',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientLogin.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n                )\n        self.Quit = channel.unary_unary(\n                '/fedlearn.FederatedTraining/Quit',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientState.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n                )\n        self.GetTask = channel.unary_unary(\n                '/fedlearn.FederatedTraining/GetTask',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientState.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.CurrentTask.FromString,\n                )\n        self.SubmitUpdate = channel.unary_unary(\n                '/fedlearn.FederatedTraining/SubmitUpdate',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.Contribution.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n                )\n        self.Heartbeat = channel.unary_unary(\n                '/fedlearn.FederatedTraining/Heartbeat',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.Token.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n                )\n        self.AuxCommunicate = channel.unary_unary(\n                '/fedlearn.FederatedTraining/AuxCommunicate',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.AuxMessage.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.AuxReply.FromString,\n                )",
  "class FederatedTrainingServicer(object):\n    \"\"\"The global federated model interfaces\n    \"\"\"\n\n    def Register(self, request, context):\n        \"\"\"client registration, so that it will contribute to the training\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')\n\n    def Quit(self, request, context):\n        \"\"\"client quiting the federated training\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')\n\n    def GetTask(self, request, context):\n        \"\"\"server to client model sharing\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')\n\n    def SubmitUpdate(self, request, context):\n        \"\"\"client to server contribution submission\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')\n\n    def Heartbeat(self, request, context):\n        \"\"\"client to server heartbeat keep live\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')\n\n    def AuxCommunicate(self, request, context):\n        \"\"\"client to server aux channel communication\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')",
  "def add_FederatedTrainingServicer_to_server(servicer, server):\n    rpc_method_handlers = {\n            'Register': grpc.unary_unary_rpc_method_handler(\n                    servicer.Register,\n                    request_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientLogin.FromString,\n                    response_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.SerializeToString,\n            ),\n            'Quit': grpc.unary_unary_rpc_method_handler(\n                    servicer.Quit,\n                    request_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientState.FromString,\n                    response_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.SerializeToString,\n            ),\n            'GetTask': grpc.unary_unary_rpc_method_handler(\n                    servicer.GetTask,\n                    request_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientState.FromString,\n                    response_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.CurrentTask.SerializeToString,\n            ),\n            'SubmitUpdate': grpc.unary_unary_rpc_method_handler(\n                    servicer.SubmitUpdate,\n                    request_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.Contribution.FromString,\n                    response_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.SerializeToString,\n            ),\n            'Heartbeat': grpc.unary_unary_rpc_method_handler(\n                    servicer.Heartbeat,\n                    request_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.Token.FromString,\n                    response_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.SerializeToString,\n            ),\n            'AuxCommunicate': grpc.unary_unary_rpc_method_handler(\n                    servicer.AuxCommunicate,\n                    request_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.AuxMessage.FromString,\n                    response_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.AuxReply.SerializeToString,\n            ),\n    }\n    generic_handler = grpc.method_handlers_generic_handler(\n            'fedlearn.FederatedTraining', rpc_method_handlers)\n    server.add_generic_rpc_handlers((generic_handler,))",
  "class FederatedTraining(object):\n    \"\"\"The global federated model interfaces\n    \"\"\"\n\n    @staticmethod\n    def Register(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/fedlearn.FederatedTraining/Register',\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientLogin.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)\n\n    @staticmethod\n    def Quit(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/fedlearn.FederatedTraining/Quit',\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientState.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)\n\n    @staticmethod\n    def GetTask(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/fedlearn.FederatedTraining/GetTask',\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientState.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.CurrentTask.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)\n\n    @staticmethod\n    def SubmitUpdate(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/fedlearn.FederatedTraining/SubmitUpdate',\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.Contribution.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)\n\n    @staticmethod\n    def Heartbeat(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/fedlearn.FederatedTraining/Heartbeat',\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.Token.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)\n\n    @staticmethod\n    def AuxCommunicate(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/fedlearn.FederatedTraining/AuxCommunicate',\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.AuxMessage.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.AuxReply.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)",
  "def __init__(self, channel):\n        \"\"\"Constructor.\n\n        Args:\n            channel: A grpc.Channel.\n        \"\"\"\n        self.Register = channel.unary_unary(\n                '/fedlearn.FederatedTraining/Register',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientLogin.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n                )\n        self.Quit = channel.unary_unary(\n                '/fedlearn.FederatedTraining/Quit',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientState.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n                )\n        self.GetTask = channel.unary_unary(\n                '/fedlearn.FederatedTraining/GetTask',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientState.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.CurrentTask.FromString,\n                )\n        self.SubmitUpdate = channel.unary_unary(\n                '/fedlearn.FederatedTraining/SubmitUpdate',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.Contribution.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n                )\n        self.Heartbeat = channel.unary_unary(\n                '/fedlearn.FederatedTraining/Heartbeat',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.Token.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n                )\n        self.AuxCommunicate = channel.unary_unary(\n                '/fedlearn.FederatedTraining/AuxCommunicate',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.AuxMessage.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.AuxReply.FromString,\n                )",
  "def Register(self, request, context):\n        \"\"\"client registration, so that it will contribute to the training\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')",
  "def Quit(self, request, context):\n        \"\"\"client quiting the federated training\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')",
  "def GetTask(self, request, context):\n        \"\"\"server to client model sharing\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')",
  "def SubmitUpdate(self, request, context):\n        \"\"\"client to server contribution submission\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')",
  "def Heartbeat(self, request, context):\n        \"\"\"client to server heartbeat keep live\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')",
  "def AuxCommunicate(self, request, context):\n        \"\"\"client to server aux channel communication\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')",
  "def Register(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/fedlearn.FederatedTraining/Register',\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientLogin.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)",
  "def Quit(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/fedlearn.FederatedTraining/Quit',\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientState.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)",
  "def GetTask(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/fedlearn.FederatedTraining/GetTask',\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.ClientState.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.CurrentTask.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)",
  "def SubmitUpdate(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/fedlearn.FederatedTraining/SubmitUpdate',\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.Contribution.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)",
  "def Heartbeat(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/fedlearn.FederatedTraining/Heartbeat',\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.Token.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.FederatedSummary.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)",
  "def AuxCommunicate(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/fedlearn.FederatedTraining/AuxCommunicate',\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.AuxMessage.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_federated__pb2.AuxReply.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)",
  "class AdminCommunicatingStub(object):\n    \"\"\"import \"google/protobuf/timestamp.proto\";\n    import \"google/protobuf/struct.proto\";\n\n    The admin communication interfaces\n    \"\"\"\n\n    def __init__(self, channel):\n        \"\"\"Constructor.\n\n        Args:\n            channel: A grpc.Channel.\n        \"\"\"\n        self.Retrieve = channel.unary_unary(\n                '/admin.AdminCommunicating/Retrieve',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Client.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Messages.FromString,\n                )\n        self.SendReply = channel.unary_unary(\n                '/admin.AdminCommunicating/SendReply',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Reply.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Empty.FromString,\n                )\n        self.SendResult = channel.unary_unary(\n                '/admin.AdminCommunicating/SendResult',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Reply.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Empty.FromString,\n                )",
  "class AdminCommunicatingServicer(object):\n    \"\"\"import \"google/protobuf/timestamp.proto\";\n    import \"google/protobuf/struct.proto\";\n\n    The admin communication interfaces\n    \"\"\"\n\n    def Retrieve(self, request, context):\n        \"\"\"client retrieve requests.\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')\n\n    def SendReply(self, request, context):\n        \"\"\"client send reply to server\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')\n\n    def SendResult(self, request, context):\n        \"\"\"client send process results to server\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')",
  "def add_AdminCommunicatingServicer_to_server(servicer, server):\n    rpc_method_handlers = {\n            'Retrieve': grpc.unary_unary_rpc_method_handler(\n                    servicer.Retrieve,\n                    request_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Client.FromString,\n                    response_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Messages.SerializeToString,\n            ),\n            'SendReply': grpc.unary_unary_rpc_method_handler(\n                    servicer.SendReply,\n                    request_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Reply.FromString,\n                    response_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Empty.SerializeToString,\n            ),\n            'SendResult': grpc.unary_unary_rpc_method_handler(\n                    servicer.SendResult,\n                    request_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Reply.FromString,\n                    response_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Empty.SerializeToString,\n            ),\n    }\n    generic_handler = grpc.method_handlers_generic_handler(\n            'admin.AdminCommunicating', rpc_method_handlers)\n    server.add_generic_rpc_handlers((generic_handler,))",
  "class AdminCommunicating(object):\n    \"\"\"import \"google/protobuf/timestamp.proto\";\n    import \"google/protobuf/struct.proto\";\n\n    The admin communication interfaces\n    \"\"\"\n\n    @staticmethod\n    def Retrieve(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/admin.AdminCommunicating/Retrieve',\n            nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Client.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Messages.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)\n\n    @staticmethod\n    def SendReply(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/admin.AdminCommunicating/SendReply',\n            nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Reply.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Empty.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)\n\n    @staticmethod\n    def SendResult(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/admin.AdminCommunicating/SendResult',\n            nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Reply.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Empty.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)",
  "def __init__(self, channel):\n        \"\"\"Constructor.\n\n        Args:\n            channel: A grpc.Channel.\n        \"\"\"\n        self.Retrieve = channel.unary_unary(\n                '/admin.AdminCommunicating/Retrieve',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Client.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Messages.FromString,\n                )\n        self.SendReply = channel.unary_unary(\n                '/admin.AdminCommunicating/SendReply',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Reply.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Empty.FromString,\n                )\n        self.SendResult = channel.unary_unary(\n                '/admin.AdminCommunicating/SendResult',\n                request_serializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Reply.SerializeToString,\n                response_deserializer=nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Empty.FromString,\n                )",
  "def Retrieve(self, request, context):\n        \"\"\"client retrieve requests.\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')",
  "def SendReply(self, request, context):\n        \"\"\"client send reply to server\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')",
  "def SendResult(self, request, context):\n        \"\"\"client send process results to server\n        \"\"\"\n        context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n        context.set_details('Method not implemented!')\n        raise NotImplementedError('Method not implemented!')",
  "def Retrieve(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/admin.AdminCommunicating/Retrieve',\n            nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Client.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Messages.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)",
  "def SendReply(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/admin.AdminCommunicating/SendReply',\n            nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Reply.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Empty.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)",
  "def SendResult(request,\n            target,\n            options=(),\n            channel_credentials=None,\n            call_credentials=None,\n            insecure=False,\n            compression=None,\n            wait_for_ready=None,\n            timeout=None,\n            metadata=None):\n        return grpc.experimental.unary_unary(request, target, '/admin.AdminCommunicating/SendResult',\n            nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Reply.SerializeToString,\n            nvflare_dot_private_dot_fed_dot_protos_dot_admin__pb2.Empty.FromString,\n            options, channel_credentials,\n            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)",
  "class DefaultAppValidator(AppValidator):\n    def validate(self, app_folder: str) -> Tuple[str, Dict]:\n        result = dict()\n        app_root = os.path.abspath(app_folder)\n        if not os.path.exists(os.path.join(app_root, \"config\")):\n            return \"Missing config folder inside app folder.\", {}\n        if not os.path.exists(os.path.join(app_root, \"config\", \"config_fed_server.json\")):\n            return \"Missing config_fed_server.json inside app/config folder.\", {}\n        if not os.path.exists(os.path.join(app_root, \"config\", \"config_fed_client.json\")):\n            return \"Missing config_fed_client.json inside app/config folder.\", {}\n        if os.path.exists(os.path.join(app_root, \"custom\")):\n            result[AppValidationKey.BYOC] = True\n        return \"\", result",
  "def validate(self, app_folder: str) -> Tuple[str, Dict]:\n        result = dict()\n        app_root = os.path.abspath(app_folder)\n        if not os.path.exists(os.path.join(app_root, \"config\")):\n            return \"Missing config folder inside app folder.\", {}\n        if not os.path.exists(os.path.join(app_root, \"config\", \"config_fed_server.json\")):\n            return \"Missing config_fed_server.json inside app/config folder.\", {}\n        if not os.path.exists(os.path.join(app_root, \"config\", \"config_fed_client.json\")):\n            return \"Missing config_fed_client.json inside app/config folder.\", {}\n        if os.path.exists(os.path.join(app_root, \"custom\")):\n            result[AppValidationKey.BYOC] = True\n        return \"\", result",
  "class FLAppValidator(AppValidator):\n    def __init__(self, custom_validators: Optional[List[AppValidator]] = None):\n        super().__init__()\n        self.validators = [DefaultAppValidator()]\n        if custom_validators:\n            if not isinstance(custom_validators, list):\n                raise TypeError(\"custom_validators must be list, but got {}\".format(type(custom_validators)))\n            for validator in custom_validators:\n                if not isinstance(validator, AppValidator):\n                    raise TypeError(\"validator must be AppValidator, but got {}\".format(type(validator)))\n                self.validators.append(validator)\n\n    def validate(self, app_folder: str) -> Tuple[str, Dict]:\n        final_result = {}\n        for v in self.validators:\n            err, result = v.validate(app_folder)\n            if err:\n                return err, result\n            if result:\n                final_result.update(result)\n        return \"\", final_result",
  "def __init__(self, custom_validators: Optional[List[AppValidator]] = None):\n        super().__init__()\n        self.validators = [DefaultAppValidator()]\n        if custom_validators:\n            if not isinstance(custom_validators, list):\n                raise TypeError(\"custom_validators must be list, but got {}\".format(type(custom_validators)))\n            for validator in custom_validators:\n                if not isinstance(validator, AppValidator):\n                    raise TypeError(\"validator must be AppValidator, but got {}\".format(type(validator)))\n                self.validators.append(validator)",
  "def validate(self, app_folder: str) -> Tuple[str, Dict]:\n        final_result = {}\n        for v in self.validators:\n            err, result = v.validate(app_folder)\n            if err:\n                return err, result\n            if result:\n                final_result.update(result)\n        return \"\", final_result",
  "class FLServerStarterConfiger(JsonConfigurator):\n    \"\"\"FL Server startup configer.\"\"\"\n\n    def __init__(\n        self,\n        app_root: str,\n        server_config_file_name=None,\n        log_config_file_name=None,\n        kv_list=None,\n        logging_config=True,\n    ):\n        \"\"\"Init the FLServerStarterConfiger.\n\n        Args:\n            app_root: application root\n            server_config_file_name: server config filename\n            log_config_file_name: log config filename\n            kv_list: key value pair list\n            logging_config: True/False\n        \"\"\"\n        base_pkgs = FL_PACKAGES\n        module_names = FL_MODULES\n\n        if kv_list:\n            assert isinstance(kv_list, list), \"cmd_vars must be list, but got {}\".format(type(kv_list))\n            self.cmd_vars = parse_vars(kv_list)\n        else:\n            self.cmd_vars = {}\n\n        if logging_config:\n            log_config_file_path = os.path.join(app_root, log_config_file_name)\n            assert os.path.isfile(log_config_file_path), \"missing log config file {}\".format(log_config_file_path)\n            logging.config.fileConfig(fname=log_config_file_path, disable_existing_loggers=False)\n\n        server_config_file_name = os.path.join(app_root, server_config_file_name)\n\n        JsonConfigurator.__init__(\n            self,\n            config_file_name=server_config_file_name,\n            base_pkgs=base_pkgs,\n            module_names=module_names,\n            exclude_libs=True,\n        )\n\n        self.components = {}  # id => component\n        self.handlers = []\n\n        self.app_root = app_root\n        self.server_config_file_name = server_config_file_name\n\n        self.deployer = None\n        self.app_validator = None\n        self.enable_byoc = False\n        self.snapshot_persistor = None\n        self.overseer_agent = None\n\n    def start_config(self, config_ctx: ConfigContext):\n        \"\"\"Start the config process.\n\n        Args:\n            config_ctx: config context\n\n        \"\"\"\n        super().start_config(config_ctx)\n\n        # loading server specifications\n        try:\n            for server in self.config_data[\"servers\"]:\n                if server.get(SSLConstants.PRIVATE_KEY):\n                    server[SSLConstants.PRIVATE_KEY] = os.path.join(self.app_root, server[SSLConstants.PRIVATE_KEY])\n                if server.get(SSLConstants.CERT):\n                    server[SSLConstants.CERT] = os.path.join(self.app_root, server[SSLConstants.CERT])\n                if server.get(SSLConstants.ROOT_CERT):\n                    server[SSLConstants.ROOT_CERT] = os.path.join(self.app_root, server[SSLConstants.ROOT_CERT])\n        except Exception:\n            raise ValueError(\"Server config error: '{}'\".format(self.server_config_file_name))\n\n    def build_component(self, config_dict):\n        t = super().build_component(config_dict)\n        if isinstance(t, FLComponent):\n            if type(t).__name__ not in [type(h).__name__ for h in self.handlers]:\n                self.handlers.append(t)\n        return t\n\n    def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        \"\"\"Process the config element.\n\n        Args:\n            config_ctx: config context\n            node: element node\n\n        \"\"\"\n        # JsonConfigurator.process_config_element(self, config_ctx, node)\n\n        element = node.element\n        path = node.path()\n\n        if path == \"enable_byoc\":\n            self.enable_byoc = element\n            return\n\n        if path == \"app_validator\" and isinstance(element, dict):\n            self.app_validator = self.build_component(element)\n            return\n\n        if path == \"snapshot_persistor\":\n            self.snapshot_persistor = self.build_component(element)\n            return\n\n        if path == \"overseer_agent\":\n            self.overseer_agent = self.build_component(element)\n            return\n\n        if re.search(r\"^components\\.#[0-9]+$\", path):\n            c = self.build_component(element)\n            cid = element.get(\"id\", None)\n            if not cid:\n                raise ConfigError(\"missing component id\")\n\n            if not isinstance(cid, str):\n                raise ConfigError('\"id\" must be str but got {}'.format(type(cid)))\n\n            if cid in self.components:\n                raise ConfigError('duplicate component id \"{}\"'.format(cid))\n\n            self.components[cid] = c\n            return\n\n    def finalize_config(self, config_ctx: ConfigContext):\n        \"\"\"Finalize the config process.\n\n        Args:\n            config_ctx: config context\n\n        \"\"\"\n        secure_train = False\n        if self.cmd_vars.get(\"secure_train\"):\n            secure_train = self.cmd_vars[\"secure_train\"]\n        if not secure_train:\n            self.enable_byoc = True\n\n        custom_validators = [self.app_validator] if self.app_validator else []\n        self.app_validator = FLAppValidator(custom_validators=custom_validators)\n\n        build_ctx = {\n            \"secure_train\": secure_train,\n            \"app_validator\": self.app_validator,\n            \"server_config\": self.config_data[\"servers\"],\n            \"server_host\": self.cmd_vars.get(\"host\", None),\n            \"enable_byoc\": self.enable_byoc,\n            \"snapshot_persistor\": self.snapshot_persistor,\n            \"overseer_agent\": self.overseer_agent,\n            \"server_components\": self.components,\n            \"server_handlers\": self.handlers,\n        }\n\n        deployer = ServerDeployer()\n        deployer.build(build_ctx)\n        self.deployer = deployer",
  "class FLClientStarterConfiger(JsonConfigurator):\n    \"\"\"FL Client startup configer.\"\"\"\n\n    def __init__(\n        self,\n        app_root: str,\n        client_config_file_name=None,\n        log_config_file_name=None,\n        kv_list=None,\n        logging_config=True,\n    ):\n        \"\"\"Init the FLClientStarterConfiger.\n\n        Args:\n            app_root: application root\n            client_config_file_name: client config filename\n            log_config_file_name: log config filename\n            kv_list: key value pair list\n            logging_config: True/False\n        \"\"\"\n        base_pkgs = FL_PACKAGES\n        module_names = FL_MODULES\n\n        if kv_list:\n            assert isinstance(kv_list, list), \"cmd_vars must be list, but got {}\".format(type(kv_list))\n            self.cmd_vars = parse_vars(kv_list)\n        else:\n            self.cmd_vars = {}\n\n        if logging_config:\n            log_config_file_path = os.path.join(app_root, log_config_file_name)\n            assert os.path.isfile(log_config_file_path), \"missing log config file {}\".format(log_config_file_path)\n            logging.config.fileConfig(fname=log_config_file_path, disable_existing_loggers=False)\n\n        client_config_file_name = os.path.join(app_root, client_config_file_name)\n\n        JsonConfigurator.__init__(\n            self,\n            config_file_name=client_config_file_name,\n            base_pkgs=base_pkgs,\n            module_names=module_names,\n            exclude_libs=True,\n        )\n\n        self.components = {}  # id => component\n        self.handlers = []\n\n        self.app_root = app_root\n        self.client_config_file_name = client_config_file_name\n        self.enable_byoc = False\n        self.base_deployer = None\n        self.overseer_agent = None\n\n    def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        \"\"\"Process config element.\n\n        Args:\n            config_ctx: config context\n            node: element node\n        \"\"\"\n        element = node.element\n        path = node.path()\n\n        if path == \"enable_byoc\":\n            self.enable_byoc = element\n            return\n\n        if path == \"overseer_agent\":\n            self.overseer_agent = self.build_component(element)\n            return\n\n        if re.search(r\"^components\\.#[0-9]+$\", path):\n            c = self.build_component(element)\n            cid = element.get(\"id\", None)\n            if not cid:\n                raise ConfigError(\"missing component id\")\n\n            if not isinstance(cid, str):\n                raise ConfigError('\"id\" must be str but got {}'.format(type(cid)))\n\n            if cid in self.components:\n                raise ConfigError('duplicate component id \"{}\"'.format(cid))\n\n            self.components[cid] = c\n            return\n\n    def build_component(self, config_dict):\n        t = super().build_component(config_dict)\n        if isinstance(t, FLComponent):\n            if type(t).__name__ not in [type(h).__name__ for h in self.handlers]:\n                self.handlers.append(t)\n        return t\n\n    def start_config(self, config_ctx: ConfigContext):\n        \"\"\"Start the config process.\n\n        Args:\n            config_ctx: config context\n        \"\"\"\n        super().start_config(config_ctx)\n\n        try:\n            client = self.config_data[\"client\"]\n            if client.get(SSLConstants.PRIVATE_KEY):\n                client[SSLConstants.PRIVATE_KEY] = os.path.join(self.app_root, client[SSLConstants.PRIVATE_KEY])\n            if client.get(SSLConstants.CERT):\n                client[SSLConstants.CERT] = os.path.join(self.app_root, client[SSLConstants.CERT])\n            if client.get(SSLConstants.ROOT_CERT):\n                client[SSLConstants.ROOT_CERT] = os.path.join(self.app_root, client[SSLConstants.ROOT_CERT])\n        except Exception:\n            raise ValueError(\"Client config error: '{}'\".format(self.client_config_file_name))\n\n    def finalize_config(self, config_ctx: ConfigContext):\n        \"\"\"Finalize the config process.\n\n        Args:\n            config_ctx: config context\n        \"\"\"\n        secure_train = False\n        if self.cmd_vars.get(\"secure_train\"):\n            secure_train = self.cmd_vars[\"secure_train\"]\n        if not secure_train:\n            self.enable_byoc = True\n\n        build_ctx = {\n            \"client_name\": self.cmd_vars.get(\"uid\", \"\"),\n            \"server_config\": self.config_data.get(\"servers\", []),\n            \"client_config\": self.config_data[\"client\"],\n            \"secure_train\": secure_train,\n            \"server_host\": self.cmd_vars.get(\"host\", None),\n            \"enable_byoc\": self.enable_byoc,\n            \"overseer_agent\": self.overseer_agent,\n            \"client_components\": self.components,\n            \"client_handlers\": self.handlers,\n        }\n\n        self.base_deployer = BaseClientDeployer()\n        self.base_deployer.build(build_ctx)",
  "class FLAdminClientStarterConfigurator(JsonConfigurator):\n    \"\"\"FL Admin Client startup configurator.\"\"\"\n\n    def __init__(self, app_root: str, admin_config_file_name=None):\n        \"\"\"Uses the json configuration to start the FL admin client.\n\n        Args:\n            app_root: application root\n            admin_config_file_name: admin config filename\n        \"\"\"\n        base_pkgs = FL_PACKAGES\n        module_names = FL_MODULES\n\n        admin_config_file_name = os.path.join(app_root, admin_config_file_name)\n\n        JsonConfigurator.__init__(\n            self,\n            config_file_name=admin_config_file_name,\n            base_pkgs=base_pkgs,\n            module_names=module_names,\n            exclude_libs=True,\n        )\n\n        self.app_root = app_root\n        self.admin_config_file_name = admin_config_file_name\n        self.base_deployer = None\n        self.overseer_agent = None\n\n    def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        \"\"\"Process config element.\n\n        Args:\n            config_ctx: config context\n            node: element node\n        \"\"\"\n        element = node.element\n        path = node.path()\n\n        if path == \"admin.overseer_agent\":\n            self.overseer_agent = self.build_component(element)\n            return\n\n    def start_config(self, config_ctx: ConfigContext):\n        \"\"\"Start the config process.\n\n        Args:\n            config_ctx: config context\n        \"\"\"\n        super().start_config(config_ctx)\n\n        try:\n            admin = self.config_data[\"admin\"]\n            if admin.get(\"client_key\"):\n                admin[\"client_key\"] = os.path.join(self.app_root, admin[\"client_key\"])\n            if admin.get(\"client_cert\"):\n                admin[\"client_cert\"] = os.path.join(self.app_root, admin[\"client_cert\"])\n            if admin.get(\"ca_cert\"):\n                admin[\"ca_cert\"] = os.path.join(self.app_root, admin[\"ca_cert\"])\n            if admin.get(\"upload_dir\"):\n                admin[\"upload_dir\"] = os.path.join(os.path.dirname(self.app_root), admin[\"upload_dir\"])\n            if admin.get(\"download_dir\"):\n                admin[\"download_dir\"] = os.path.join(os.path.dirname(self.app_root), admin[\"download_dir\"])\n        except Exception:\n            raise ValueError(\"Client config error: '{}'\".format(self.admin_config_file_name))",
  "def __init__(\n        self,\n        app_root: str,\n        server_config_file_name=None,\n        log_config_file_name=None,\n        kv_list=None,\n        logging_config=True,\n    ):\n        \"\"\"Init the FLServerStarterConfiger.\n\n        Args:\n            app_root: application root\n            server_config_file_name: server config filename\n            log_config_file_name: log config filename\n            kv_list: key value pair list\n            logging_config: True/False\n        \"\"\"\n        base_pkgs = FL_PACKAGES\n        module_names = FL_MODULES\n\n        if kv_list:\n            assert isinstance(kv_list, list), \"cmd_vars must be list, but got {}\".format(type(kv_list))\n            self.cmd_vars = parse_vars(kv_list)\n        else:\n            self.cmd_vars = {}\n\n        if logging_config:\n            log_config_file_path = os.path.join(app_root, log_config_file_name)\n            assert os.path.isfile(log_config_file_path), \"missing log config file {}\".format(log_config_file_path)\n            logging.config.fileConfig(fname=log_config_file_path, disable_existing_loggers=False)\n\n        server_config_file_name = os.path.join(app_root, server_config_file_name)\n\n        JsonConfigurator.__init__(\n            self,\n            config_file_name=server_config_file_name,\n            base_pkgs=base_pkgs,\n            module_names=module_names,\n            exclude_libs=True,\n        )\n\n        self.components = {}  # id => component\n        self.handlers = []\n\n        self.app_root = app_root\n        self.server_config_file_name = server_config_file_name\n\n        self.deployer = None\n        self.app_validator = None\n        self.enable_byoc = False\n        self.snapshot_persistor = None\n        self.overseer_agent = None",
  "def start_config(self, config_ctx: ConfigContext):\n        \"\"\"Start the config process.\n\n        Args:\n            config_ctx: config context\n\n        \"\"\"\n        super().start_config(config_ctx)\n\n        # loading server specifications\n        try:\n            for server in self.config_data[\"servers\"]:\n                if server.get(SSLConstants.PRIVATE_KEY):\n                    server[SSLConstants.PRIVATE_KEY] = os.path.join(self.app_root, server[SSLConstants.PRIVATE_KEY])\n                if server.get(SSLConstants.CERT):\n                    server[SSLConstants.CERT] = os.path.join(self.app_root, server[SSLConstants.CERT])\n                if server.get(SSLConstants.ROOT_CERT):\n                    server[SSLConstants.ROOT_CERT] = os.path.join(self.app_root, server[SSLConstants.ROOT_CERT])\n        except Exception:\n            raise ValueError(\"Server config error: '{}'\".format(self.server_config_file_name))",
  "def build_component(self, config_dict):\n        t = super().build_component(config_dict)\n        if isinstance(t, FLComponent):\n            if type(t).__name__ not in [type(h).__name__ for h in self.handlers]:\n                self.handlers.append(t)\n        return t",
  "def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        \"\"\"Process the config element.\n\n        Args:\n            config_ctx: config context\n            node: element node\n\n        \"\"\"\n        # JsonConfigurator.process_config_element(self, config_ctx, node)\n\n        element = node.element\n        path = node.path()\n\n        if path == \"enable_byoc\":\n            self.enable_byoc = element\n            return\n\n        if path == \"app_validator\" and isinstance(element, dict):\n            self.app_validator = self.build_component(element)\n            return\n\n        if path == \"snapshot_persistor\":\n            self.snapshot_persistor = self.build_component(element)\n            return\n\n        if path == \"overseer_agent\":\n            self.overseer_agent = self.build_component(element)\n            return\n\n        if re.search(r\"^components\\.#[0-9]+$\", path):\n            c = self.build_component(element)\n            cid = element.get(\"id\", None)\n            if not cid:\n                raise ConfigError(\"missing component id\")\n\n            if not isinstance(cid, str):\n                raise ConfigError('\"id\" must be str but got {}'.format(type(cid)))\n\n            if cid in self.components:\n                raise ConfigError('duplicate component id \"{}\"'.format(cid))\n\n            self.components[cid] = c\n            return",
  "def finalize_config(self, config_ctx: ConfigContext):\n        \"\"\"Finalize the config process.\n\n        Args:\n            config_ctx: config context\n\n        \"\"\"\n        secure_train = False\n        if self.cmd_vars.get(\"secure_train\"):\n            secure_train = self.cmd_vars[\"secure_train\"]\n        if not secure_train:\n            self.enable_byoc = True\n\n        custom_validators = [self.app_validator] if self.app_validator else []\n        self.app_validator = FLAppValidator(custom_validators=custom_validators)\n\n        build_ctx = {\n            \"secure_train\": secure_train,\n            \"app_validator\": self.app_validator,\n            \"server_config\": self.config_data[\"servers\"],\n            \"server_host\": self.cmd_vars.get(\"host\", None),\n            \"enable_byoc\": self.enable_byoc,\n            \"snapshot_persistor\": self.snapshot_persistor,\n            \"overseer_agent\": self.overseer_agent,\n            \"server_components\": self.components,\n            \"server_handlers\": self.handlers,\n        }\n\n        deployer = ServerDeployer()\n        deployer.build(build_ctx)\n        self.deployer = deployer",
  "def __init__(\n        self,\n        app_root: str,\n        client_config_file_name=None,\n        log_config_file_name=None,\n        kv_list=None,\n        logging_config=True,\n    ):\n        \"\"\"Init the FLClientStarterConfiger.\n\n        Args:\n            app_root: application root\n            client_config_file_name: client config filename\n            log_config_file_name: log config filename\n            kv_list: key value pair list\n            logging_config: True/False\n        \"\"\"\n        base_pkgs = FL_PACKAGES\n        module_names = FL_MODULES\n\n        if kv_list:\n            assert isinstance(kv_list, list), \"cmd_vars must be list, but got {}\".format(type(kv_list))\n            self.cmd_vars = parse_vars(kv_list)\n        else:\n            self.cmd_vars = {}\n\n        if logging_config:\n            log_config_file_path = os.path.join(app_root, log_config_file_name)\n            assert os.path.isfile(log_config_file_path), \"missing log config file {}\".format(log_config_file_path)\n            logging.config.fileConfig(fname=log_config_file_path, disable_existing_loggers=False)\n\n        client_config_file_name = os.path.join(app_root, client_config_file_name)\n\n        JsonConfigurator.__init__(\n            self,\n            config_file_name=client_config_file_name,\n            base_pkgs=base_pkgs,\n            module_names=module_names,\n            exclude_libs=True,\n        )\n\n        self.components = {}  # id => component\n        self.handlers = []\n\n        self.app_root = app_root\n        self.client_config_file_name = client_config_file_name\n        self.enable_byoc = False\n        self.base_deployer = None\n        self.overseer_agent = None",
  "def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        \"\"\"Process config element.\n\n        Args:\n            config_ctx: config context\n            node: element node\n        \"\"\"\n        element = node.element\n        path = node.path()\n\n        if path == \"enable_byoc\":\n            self.enable_byoc = element\n            return\n\n        if path == \"overseer_agent\":\n            self.overseer_agent = self.build_component(element)\n            return\n\n        if re.search(r\"^components\\.#[0-9]+$\", path):\n            c = self.build_component(element)\n            cid = element.get(\"id\", None)\n            if not cid:\n                raise ConfigError(\"missing component id\")\n\n            if not isinstance(cid, str):\n                raise ConfigError('\"id\" must be str but got {}'.format(type(cid)))\n\n            if cid in self.components:\n                raise ConfigError('duplicate component id \"{}\"'.format(cid))\n\n            self.components[cid] = c\n            return",
  "def build_component(self, config_dict):\n        t = super().build_component(config_dict)\n        if isinstance(t, FLComponent):\n            if type(t).__name__ not in [type(h).__name__ for h in self.handlers]:\n                self.handlers.append(t)\n        return t",
  "def start_config(self, config_ctx: ConfigContext):\n        \"\"\"Start the config process.\n\n        Args:\n            config_ctx: config context\n        \"\"\"\n        super().start_config(config_ctx)\n\n        try:\n            client = self.config_data[\"client\"]\n            if client.get(SSLConstants.PRIVATE_KEY):\n                client[SSLConstants.PRIVATE_KEY] = os.path.join(self.app_root, client[SSLConstants.PRIVATE_KEY])\n            if client.get(SSLConstants.CERT):\n                client[SSLConstants.CERT] = os.path.join(self.app_root, client[SSLConstants.CERT])\n            if client.get(SSLConstants.ROOT_CERT):\n                client[SSLConstants.ROOT_CERT] = os.path.join(self.app_root, client[SSLConstants.ROOT_CERT])\n        except Exception:\n            raise ValueError(\"Client config error: '{}'\".format(self.client_config_file_name))",
  "def finalize_config(self, config_ctx: ConfigContext):\n        \"\"\"Finalize the config process.\n\n        Args:\n            config_ctx: config context\n        \"\"\"\n        secure_train = False\n        if self.cmd_vars.get(\"secure_train\"):\n            secure_train = self.cmd_vars[\"secure_train\"]\n        if not secure_train:\n            self.enable_byoc = True\n\n        build_ctx = {\n            \"client_name\": self.cmd_vars.get(\"uid\", \"\"),\n            \"server_config\": self.config_data.get(\"servers\", []),\n            \"client_config\": self.config_data[\"client\"],\n            \"secure_train\": secure_train,\n            \"server_host\": self.cmd_vars.get(\"host\", None),\n            \"enable_byoc\": self.enable_byoc,\n            \"overseer_agent\": self.overseer_agent,\n            \"client_components\": self.components,\n            \"client_handlers\": self.handlers,\n        }\n\n        self.base_deployer = BaseClientDeployer()\n        self.base_deployer.build(build_ctx)",
  "def __init__(self, app_root: str, admin_config_file_name=None):\n        \"\"\"Uses the json configuration to start the FL admin client.\n\n        Args:\n            app_root: application root\n            admin_config_file_name: admin config filename\n        \"\"\"\n        base_pkgs = FL_PACKAGES\n        module_names = FL_MODULES\n\n        admin_config_file_name = os.path.join(app_root, admin_config_file_name)\n\n        JsonConfigurator.__init__(\n            self,\n            config_file_name=admin_config_file_name,\n            base_pkgs=base_pkgs,\n            module_names=module_names,\n            exclude_libs=True,\n        )\n\n        self.app_root = app_root\n        self.admin_config_file_name = admin_config_file_name\n        self.base_deployer = None\n        self.overseer_agent = None",
  "def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        \"\"\"Process config element.\n\n        Args:\n            config_ctx: config context\n            node: element node\n        \"\"\"\n        element = node.element\n        path = node.path()\n\n        if path == \"admin.overseer_agent\":\n            self.overseer_agent = self.build_component(element)\n            return",
  "def start_config(self, config_ctx: ConfigContext):\n        \"\"\"Start the config process.\n\n        Args:\n            config_ctx: config context\n        \"\"\"\n        super().start_config(config_ctx)\n\n        try:\n            admin = self.config_data[\"admin\"]\n            if admin.get(\"client_key\"):\n                admin[\"client_key\"] = os.path.join(self.app_root, admin[\"client_key\"])\n            if admin.get(\"client_cert\"):\n                admin[\"client_cert\"] = os.path.join(self.app_root, admin[\"client_cert\"])\n            if admin.get(\"ca_cert\"):\n                admin[\"ca_cert\"] = os.path.join(self.app_root, admin[\"ca_cert\"])\n            if admin.get(\"upload_dir\"):\n                admin[\"upload_dir\"] = os.path.join(os.path.dirname(self.app_root), admin[\"upload_dir\"])\n            if admin.get(\"download_dir\"):\n                admin[\"download_dir\"] = os.path.join(os.path.dirname(self.app_root), admin[\"download_dir\"])\n        except Exception:\n            raise ValueError(\"Client config error: '{}'\".format(self.admin_config_file_name))",
  "class ServerDeployer:\n    \"\"\"FL Server deployer.\"\"\"\n\n    def __init__(self):\n        \"\"\"Init the ServerDeployer.\"\"\"\n        self.services = None\n        self.cmd_modules = ServerCommandModules.cmd_modules\n        self.server_config = None\n        self.secure_train = None\n        self.app_validator = None\n        self.host = None\n        self.enable_byoc = None\n        self.snapshot_persistor = None\n        self.overseer_agent = None\n        self.components = None\n        self.handlers = None\n\n    def build(self, build_ctx):\n        \"\"\"To build the ServerDeployer.\n\n        Args:\n            build_ctx: build context\n\n        \"\"\"\n        self.server_config = build_ctx[\"server_config\"]\n        self.secure_train = build_ctx[\"secure_train\"]\n        self.app_validator = build_ctx[\"app_validator\"]\n        self.host = build_ctx[\"server_host\"]\n        self.enable_byoc = build_ctx[\"enable_byoc\"]\n        self.snapshot_persistor = build_ctx[\"snapshot_persistor\"]\n        self.overseer_agent = build_ctx[\"overseer_agent\"]\n        self.components = build_ctx[\"server_components\"]\n        self.handlers = build_ctx[\"server_handlers\"]\n\n    def create_fl_server(self, args, secure_train=False):\n        \"\"\"To create the FL Server.\n\n        Args:\n            args: command args\n            secure_train: True/False\n\n        Returns: FL Server\n\n        \"\"\"\n        # We only deploy the first server right now .....\n        first_server = sorted(self.server_config)[0]\n        wait_after_min_clients = first_server.get(\"wait_after_min_clients\", 10)\n        heart_beat_timeout = 600\n        if first_server[\"heart_beat_timeout\"]:\n            heart_beat_timeout = first_server[\"heart_beat_timeout\"]\n\n        if self.host:\n            target = first_server[\"service\"].get(\"target\", None)\n            first_server[\"service\"][\"target\"] = self.host + \":\" + target.split(\":\")[1]\n\n        services = FederatedServer(\n            project_name=first_server.get(\"name\", \"\"),\n            min_num_clients=first_server.get(\"min_num_clients\", 1),\n            max_num_clients=first_server.get(\"max_num_clients\", 100),\n            wait_after_min_clients=wait_after_min_clients,\n            cmd_modules=self.cmd_modules,\n            heart_beat_timeout=heart_beat_timeout,\n            args=args,\n            secure_train=secure_train,\n            enable_byoc=self.enable_byoc,\n            snapshot_persistor=self.snapshot_persistor,\n            overseer_agent=self.overseer_agent,\n        )\n        return first_server, services\n\n    def deploy(self, args):\n        \"\"\"To deploy the FL server services.\n\n        Args:\n            args: command args.\n\n        Returns: FL Server\n\n        \"\"\"\n        first_server, services = self.create_fl_server(args, secure_train=self.secure_train)\n        services.deploy(args, grpc_args=first_server, secure_train=self.secure_train)\n\n        job_runner = JobRunner(workspace_root=args.workspace)\n        workspace = Workspace(args.workspace, \"server\", args.config_folder)\n        run_manager = RunManager(\n            server_name=services.project_name,\n            engine=services.engine,\n            job_id=\"\",\n            workspace=workspace,\n            components=self.components,\n            handlers=self.handlers,\n        )\n        job_manager = self.components.get(SystemComponents.JOB_MANAGER)\n        services.engine.set_run_manager(run_manager)\n        services.engine.set_job_runner(job_runner, job_manager)\n\n        run_manager.add_handler(job_runner)\n        run_manager.add_component(SystemComponents.JOB_RUNNER, job_runner)\n        fl_ctx = services.engine.new_context()\n\n        threading.Thread(target=self._start_job_runner, args=[job_runner, fl_ctx]).start()\n\n        services.engine.fire_event(EventType.SYSTEM_START, services.engine.new_context())\n        print(\"deployed FL server trainer.\")\n        return services\n\n    def _start_job_runner(self, job_runner, fl_ctx):\n        job_runner.run(fl_ctx)\n\n    def close(self):\n        \"\"\"To close the services.\"\"\"\n        if self.services:\n            self.services.close()",
  "def __init__(self):\n        \"\"\"Init the ServerDeployer.\"\"\"\n        self.services = None\n        self.cmd_modules = ServerCommandModules.cmd_modules\n        self.server_config = None\n        self.secure_train = None\n        self.app_validator = None\n        self.host = None\n        self.enable_byoc = None\n        self.snapshot_persistor = None\n        self.overseer_agent = None\n        self.components = None\n        self.handlers = None",
  "def build(self, build_ctx):\n        \"\"\"To build the ServerDeployer.\n\n        Args:\n            build_ctx: build context\n\n        \"\"\"\n        self.server_config = build_ctx[\"server_config\"]\n        self.secure_train = build_ctx[\"secure_train\"]\n        self.app_validator = build_ctx[\"app_validator\"]\n        self.host = build_ctx[\"server_host\"]\n        self.enable_byoc = build_ctx[\"enable_byoc\"]\n        self.snapshot_persistor = build_ctx[\"snapshot_persistor\"]\n        self.overseer_agent = build_ctx[\"overseer_agent\"]\n        self.components = build_ctx[\"server_components\"]\n        self.handlers = build_ctx[\"server_handlers\"]",
  "def create_fl_server(self, args, secure_train=False):\n        \"\"\"To create the FL Server.\n\n        Args:\n            args: command args\n            secure_train: True/False\n\n        Returns: FL Server\n\n        \"\"\"\n        # We only deploy the first server right now .....\n        first_server = sorted(self.server_config)[0]\n        wait_after_min_clients = first_server.get(\"wait_after_min_clients\", 10)\n        heart_beat_timeout = 600\n        if first_server[\"heart_beat_timeout\"]:\n            heart_beat_timeout = first_server[\"heart_beat_timeout\"]\n\n        if self.host:\n            target = first_server[\"service\"].get(\"target\", None)\n            first_server[\"service\"][\"target\"] = self.host + \":\" + target.split(\":\")[1]\n\n        services = FederatedServer(\n            project_name=first_server.get(\"name\", \"\"),\n            min_num_clients=first_server.get(\"min_num_clients\", 1),\n            max_num_clients=first_server.get(\"max_num_clients\", 100),\n            wait_after_min_clients=wait_after_min_clients,\n            cmd_modules=self.cmd_modules,\n            heart_beat_timeout=heart_beat_timeout,\n            args=args,\n            secure_train=secure_train,\n            enable_byoc=self.enable_byoc,\n            snapshot_persistor=self.snapshot_persistor,\n            overseer_agent=self.overseer_agent,\n        )\n        return first_server, services",
  "def deploy(self, args):\n        \"\"\"To deploy the FL server services.\n\n        Args:\n            args: command args.\n\n        Returns: FL Server\n\n        \"\"\"\n        first_server, services = self.create_fl_server(args, secure_train=self.secure_train)\n        services.deploy(args, grpc_args=first_server, secure_train=self.secure_train)\n\n        job_runner = JobRunner(workspace_root=args.workspace)\n        workspace = Workspace(args.workspace, \"server\", args.config_folder)\n        run_manager = RunManager(\n            server_name=services.project_name,\n            engine=services.engine,\n            job_id=\"\",\n            workspace=workspace,\n            components=self.components,\n            handlers=self.handlers,\n        )\n        job_manager = self.components.get(SystemComponents.JOB_MANAGER)\n        services.engine.set_run_manager(run_manager)\n        services.engine.set_job_runner(job_runner, job_manager)\n\n        run_manager.add_handler(job_runner)\n        run_manager.add_component(SystemComponents.JOB_RUNNER, job_runner)\n        fl_ctx = services.engine.new_context()\n\n        threading.Thread(target=self._start_job_runner, args=[job_runner, fl_ctx]).start()\n\n        services.engine.fire_event(EventType.SYSTEM_START, services.engine.new_context())\n        print(\"deployed FL server trainer.\")\n        return services",
  "def _start_job_runner(self, job_runner, fl_ctx):\n        job_runner.run(fl_ctx)",
  "def close(self):\n        \"\"\"To close the services.\"\"\"\n        if self.services:\n            self.services.close()",
  "class BaseClientDeployer:\n    def __init__(self):\n        \"\"\"To init the BaseClientDeployer.\"\"\"\n        self.multi_gpu = False\n        self.outbound_filters = None\n        self.inbound_filters = None\n        self.federated_client = None\n        self.model_validator = None\n        self.cross_val_participating = False\n        self.model_registry_path = None\n        self.cross_val_timeout = None\n        self.executors = None\n\n        self.req_processors = ClientRequestProcessors.request_processors\n\n    def build(self, build_ctx):\n        self.server_config = build_ctx[\"server_config\"]\n        self.client_config = build_ctx[\"client_config\"]\n        self.secure_train = build_ctx[\"secure_train\"]\n        self.client_name = build_ctx[\"client_name\"]\n        self.host = build_ctx[\"server_host\"]\n        self.enable_byoc = build_ctx[\"enable_byoc\"]\n        self.overseer_agent = build_ctx[\"overseer_agent\"]\n        self.components = build_ctx[\"client_components\"]\n        self.handlers = build_ctx[\"client_handlers\"]\n\n    def set_model_manager(self, model_manager):\n        self.model_manager = model_manager\n\n    def create_fed_client(self, args, sp_target=None):\n        if sp_target:\n            for item in self.server_config:\n                service = item[\"service\"]\n                service[\"target\"] = sp_target\n        servers = [{t[\"name\"]: t[\"service\"]} for t in self.server_config]\n        retry_timeout = 30\n        if \"retry_timeout\" in self.client_config:\n            retry_timeout = self.client_config[\"retry_timeout\"]\n\n        compression = grpc.Compression.NoCompression\n        if \"Deflate\" == self.client_config.get(\"compression\"):\n            compression = grpc.Compression.Deflate\n        elif \"Gzip\" == self.client_config.get(\"compression\"):\n            compression = grpc.Compression.Gzip\n\n        for _, processor in self.components.items():\n            if isinstance(processor, RequestProcessor):\n                self.req_processors.append(processor)\n\n        self.federated_client = FederatedClient(\n            client_name=str(self.client_name),\n            # We only deploy the first server right now .....\n            server_args=sorted(servers)[0],\n            client_args=self.client_config,\n            secure_train=self.secure_train,\n            retry_timeout=retry_timeout,\n            executors=self.executors,\n            compression=compression,\n            enable_byoc=self.enable_byoc,\n            overseer_agent=self.overseer_agent,\n            args=args,\n            components=self.components,\n            handlers=self.handlers,\n        )\n        return self.federated_client\n\n    def finalize(self, fl_ctx: FLContext):\n        self.close()\n\n    def close(self):\n        # if self.federated_client:\n        #     self.federated_client.model_manager.close()\n        pass",
  "def __init__(self):\n        \"\"\"To init the BaseClientDeployer.\"\"\"\n        self.multi_gpu = False\n        self.outbound_filters = None\n        self.inbound_filters = None\n        self.federated_client = None\n        self.model_validator = None\n        self.cross_val_participating = False\n        self.model_registry_path = None\n        self.cross_val_timeout = None\n        self.executors = None\n\n        self.req_processors = ClientRequestProcessors.request_processors",
  "def build(self, build_ctx):\n        self.server_config = build_ctx[\"server_config\"]\n        self.client_config = build_ctx[\"client_config\"]\n        self.secure_train = build_ctx[\"secure_train\"]\n        self.client_name = build_ctx[\"client_name\"]\n        self.host = build_ctx[\"server_host\"]\n        self.enable_byoc = build_ctx[\"enable_byoc\"]\n        self.overseer_agent = build_ctx[\"overseer_agent\"]\n        self.components = build_ctx[\"client_components\"]\n        self.handlers = build_ctx[\"client_handlers\"]",
  "def set_model_manager(self, model_manager):\n        self.model_manager = model_manager",
  "def create_fed_client(self, args, sp_target=None):\n        if sp_target:\n            for item in self.server_config:\n                service = item[\"service\"]\n                service[\"target\"] = sp_target\n        servers = [{t[\"name\"]: t[\"service\"]} for t in self.server_config]\n        retry_timeout = 30\n        if \"retry_timeout\" in self.client_config:\n            retry_timeout = self.client_config[\"retry_timeout\"]\n\n        compression = grpc.Compression.NoCompression\n        if \"Deflate\" == self.client_config.get(\"compression\"):\n            compression = grpc.Compression.Deflate\n        elif \"Gzip\" == self.client_config.get(\"compression\"):\n            compression = grpc.Compression.Gzip\n\n        for _, processor in self.components.items():\n            if isinstance(processor, RequestProcessor):\n                self.req_processors.append(processor)\n\n        self.federated_client = FederatedClient(\n            client_name=str(self.client_name),\n            # We only deploy the first server right now .....\n            server_args=sorted(servers)[0],\n            client_args=self.client_config,\n            secure_train=self.secure_train,\n            retry_timeout=retry_timeout,\n            executors=self.executors,\n            compression=compression,\n            enable_byoc=self.enable_byoc,\n            overseer_agent=self.overseer_agent,\n            args=args,\n            components=self.components,\n            handlers=self.handlers,\n        )\n        return self.federated_client",
  "def finalize(self, fl_ctx: FLContext):\n        self.close()",
  "def close(self):\n        # if self.federated_client:\n        #     self.federated_client.model_manager.close()\n        pass",
  "def main():\n    if sys.version_info >= (3, 9):\n        raise RuntimeError(\"Python versions 3.9 and above are not yet supported. Please use Python 3.8 or 3.7.\")\n    if sys.version_info < (3, 7):\n        raise RuntimeError(\"Python versions 3.6 and below are not supported. Please use Python 3.8 or 3.7.\")\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--workspace\", \"-m\", type=str, help=\"WORKSPACE folder\", required=True)\n    parser.add_argument(\n        \"--fed_server\", \"-s\", type=str, help=\"an aggregation server specification json file\", required=True\n    )\n    parser.add_argument(\"--set\", metavar=\"KEY=VALUE\", nargs=\"*\")\n\n    args = parser.parse_args()\n    kv_list = parse_vars(args.set)\n\n    config_folder = kv_list.get(\"config_folder\", \"\")\n    if config_folder == \"\":\n        args.server_config = AppFolderConstants.CONFIG_FED_SERVER\n    else:\n        args.server_config = os.path.join(config_folder, AppFolderConstants.CONFIG_FED_SERVER)\n\n    # TODO:: remove env and train config since they are not core\n    args.env = os.path.join(\"config\", AppFolderConstants.CONFIG_ENV)\n    args.train_config = os.path.join(\"config\", AppFolderConstants.CONFIG_TRAIN)\n    args.config_folder = config_folder\n    logger = logging.getLogger()\n    args.log_config = None\n\n    for name in [WorkspaceConstants.RESTART_FILE, WorkspaceConstants.SHUTDOWN_FILE]:\n        try:\n            f = os.path.join(args.workspace, name)\n            if os.path.exists(f):\n                os.remove(f)\n        except BaseException:\n            print(\"Could not remove the {} file.  Please check your system before starting FL.\".format(name))\n            sys.exit(-1)\n\n    try:\n        os.chdir(args.workspace)\n\n        startup = os.path.join(args.workspace, \"startup\")\n        conf = FLServerStarterConfiger(\n            app_root=startup,\n            server_config_file_name=args.fed_server,\n            log_config_file_name=WorkspaceConstants.LOGGING_CONFIG,\n            kv_list=args.set,\n        )\n        log_level = os.environ.get(\"FL_LOG_LEVEL\", \"\")\n        numeric_level = getattr(logging, log_level.upper(), None)\n        if isinstance(numeric_level, int):\n            logging.getLogger().setLevel(numeric_level)\n            logger.debug(\"loglevel debug enabled\")\n            logger.info(\"loglevel info enabled\")\n            logger.warning(\"loglevel warn enabled\")\n            logger.error(\"loglevel error enabled\")\n            logger.critical(\"loglevel critical enabled\")\n        conf.configure()\n\n        log_file = os.path.join(args.workspace, \"log.txt\")\n        add_logfile_handler(log_file)\n\n        deployer = conf.deployer\n        secure_train = conf.cmd_vars.get(\"secure_train\", False)\n\n        security_check(secure_train=secure_train, content_folder=startup, fed_server_config=args.fed_server)\n\n        try:\n            # Deploy the FL server\n            services = deployer.deploy(args)\n\n            first_server = sorted(conf.config_data[\"servers\"])[0]\n            # allow command to overwrite the admin_host\n            if conf.cmd_vars.get(\"host\", None):\n                first_server[\"admin_host\"] = conf.cmd_vars[\"host\"]\n            admin_server = create_admin_server(\n                services,\n                server_conf=first_server,\n                args=args,\n                secure_train=secure_train,\n                app_validator=deployer.app_validator,\n            )\n            admin_server.start()\n\n            services.platform = \"PT\"\n\n            services.set_admin_server(admin_server)\n        finally:\n            deployer.close()\n\n        logger.info(\"Server started\")\n\n    except ConfigError as ex:\n        print(\"ConfigError:\", str(ex))\n    finally:\n        pass",
  "def security_check(secure_train: bool, content_folder: str, fed_server_config: str):\n    \"\"\"To check the security content if running in security mode.\n\n    Args:\n        secure_train (bool): if run in secure mode or not.\n        content_folder (str): the folder to check.\n        fed_server_config (str): fed_server.json\n    \"\"\"\n    # initialize the SecurityContentService.\n    # must do this before initializing other services since it may be needed by them!\n    SecurityContentService.initialize(content_folder=content_folder)\n\n    if secure_train:\n        insecure_list = secure_content_check(fed_server_config, site_type=\"server\")\n        if len(insecure_list):\n            print(\"The following files are not secure content.\")\n            for item in insecure_list:\n                print(item)\n            sys.exit(1)\n\n    # initialize the AuditService, which is used by command processing.\n    # The Audit Service can be used in other places as well.\n    AuditService.initialize(audit_file_name=WorkspaceConstants.AUDIT_LOG)\n\n    # Initialize the AuthorizationService. It is used by command authorization\n    # We use FLAuthorizer for policy processing.\n    # AuthorizationService depends on SecurityContentService to read authorization policy file.\n    if secure_train:\n        _, err = AuthorizationService.initialize(FLAuthorizer())\n    else:\n        _, err = AuthorizationService.initialize(EmptyAuthorizer())\n\n    if err:\n        print(\"AuthorizationService error: {}\".format(err))\n        sys.exit(1)",
  "def create_admin_server(\n    fl_server: FederatedServer, server_conf=None, args=None, secure_train=False, app_validator=None\n):\n    \"\"\"To create the admin server.\n\n    Args:\n        fl_server: fl_server\n        server_conf: server config\n        args: command args\n        secure_train: True/False\n        app_validator: application validator\n\n    Returns:\n        A FedAdminServer.\n    \"\"\"\n    users = {}\n    # Create a default user admin:admin for the POC insecure use case.\n    if not secure_train:\n        users = {\"admin\": hash_password(\"admin\")}\n\n    root_cert = server_conf[SSLConstants.ROOT_CERT] if secure_train else None\n    server_cert = server_conf[SSLConstants.CERT] if secure_train else None\n    server_key = server_conf[SSLConstants.PRIVATE_KEY] if secure_train else None\n    admin_server = FedAdminServer(\n        fed_admin_interface=fl_server.engine,\n        users=users,\n        cmd_modules=fl_server.cmd_modules,\n        file_upload_dir=os.path.join(args.workspace, server_conf.get(\"admin_storage\", \"tmp\")),\n        file_download_dir=os.path.join(args.workspace, server_conf.get(\"admin_storage\", \"tmp\")),\n        allowed_shell_cmds=None,\n        host=server_conf.get(\"admin_host\", \"localhost\"),\n        port=server_conf.get(\"admin_port\", 5005),\n        ca_cert_file_name=root_cert,\n        server_cert_file_name=server_cert,\n        server_key_file_name=server_key,\n        accepted_client_cns=None,\n        app_validator=app_validator,\n        download_job_url=server_conf.get(\"download_job_url\", \"http://\"),\n    )\n    return admin_server",
  "def main():\n    \"\"\"FL Server program starting point.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--workspace\", \"-m\", type=str, help=\"WORKSPACE folder\", required=True)\n    parser.add_argument(\n        \"--fed_server\", \"-s\", type=str, help=\"an aggregation server specification json file\", required=True\n    )\n    parser.add_argument(\"--app_root\", \"-r\", type=str, help=\"App Root\", required=True)\n    parser.add_argument(\"--job_id\", \"-n\", type=str, help=\"job id\", required=True)\n    parser.add_argument(\"--port\", \"-p\", type=str, help=\"listen port\", required=True)\n    parser.add_argument(\"--conn\", \"-c\", type=str, help=\"connection port\", required=True)\n\n    parser.add_argument(\"--set\", metavar=\"KEY=VALUE\", nargs=\"*\")\n\n    args = parser.parse_args()\n    kv_list = parse_vars(args.set)\n\n    config_folder = kv_list.get(\"config_folder\", \"\")\n    if config_folder == \"\":\n        args.server_config = AppFolderConstants.CONFIG_FED_SERVER\n    else:\n        args.server_config = os.path.join(config_folder, AppFolderConstants.CONFIG_FED_SERVER)\n\n    # TODO:: remove env and train config since they are not core\n    args.env = os.path.join(\"config\", AppFolderConstants.CONFIG_ENV)\n    args.config_folder = config_folder\n    logger = logging.getLogger()\n    args.log_config = None\n    args.snapshot = kv_list.get(\"restore_snapshot\")\n\n    startup = os.path.join(args.workspace, \"startup\")\n    logging_setup(startup)\n\n    log_file = os.path.join(args.workspace, args.job_id, \"log.txt\")\n    add_logfile_handler(log_file)\n    logger = logging.getLogger(\"runner_process\")\n    logger.info(\"Runner_process started.\")\n\n    command_agent = None\n    try:\n        os.chdir(args.workspace)\n\n        SecurityContentService.initialize(content_folder=startup)\n\n        conf = FLServerStarterConfiger(\n            app_root=startup,\n            server_config_file_name=args.fed_server,\n            log_config_file_name=WorkspaceConstants.LOGGING_CONFIG,\n            kv_list=args.set,\n            logging_config=False,\n        )\n        log_level = os.environ.get(\"FL_LOG_LEVEL\", \"\")\n        numeric_level = getattr(logging, log_level.upper(), None)\n        if isinstance(numeric_level, int):\n            logging.getLogger().setLevel(numeric_level)\n            logger.debug(\"loglevel debug enabled\")\n            logger.info(\"loglevel info enabled\")\n            logger.warning(\"loglevel warn enabled\")\n            logger.error(\"loglevel error enabled\")\n            logger.critical(\"loglevel critical enabled\")\n        conf.configure()\n\n        deployer = conf.deployer\n        secure_train = conf.cmd_vars.get(\"secure_train\", False)\n\n        try:\n            # create the FL server\n            _, server = deployer.create_fl_server(args, secure_train=secure_train)\n\n            command_agent = ServerCommandAgent(int(args.port))\n            command_agent.start(server.engine)\n\n            snapshot = None\n            if args.snapshot:\n                snapshot = server.snapshot_persistor.retrieve_run(args.job_id)\n\n            start_server_app(server, args, args.app_root, args.job_id, snapshot, logger)\n        finally:\n            if command_agent:\n                command_agent.shutdown()\n            if deployer:\n                deployer.close()\n\n    except ConfigError as ex:\n        logger.exception(f\"ConfigError: {ex}\", exc_info=True)\n        raise ex",
  "def logging_setup(startup):\n    log_config_file_path = os.path.join(startup, WorkspaceConstants.LOGGING_CONFIG)\n    logging.config.fileConfig(fname=log_config_file_path, disable_existing_loggers=False)",
  "def start_server_app(server, args, app_root, job_id, snapshot, logger):\n\n    try:\n        server_config_file_name = os.path.join(app_root, args.server_config)\n\n        conf = ServerJsonConfigurator(\n            config_file_name=server_config_file_name,\n        )\n        conf.configure()\n\n        set_up_run_config(server, conf)\n\n        if not isinstance(server.engine, ServerEngine):\n            raise TypeError(f\"server.engine must be ServerEngine. Got type:{type(server.engine).__name__}\")\n        server.engine.create_parent_connection(int(args.conn))\n        server.engine.sync_clients_from_main_process()\n\n        server.start_run(job_id, app_root, conf, args, snapshot)\n    except BaseException as e:\n        logger.exception(f\"FL server execution exception: {e}\", exc_info=True)\n        raise e\n    finally:\n        server.status = ServerStatus.STOPPED\n        server.engine.engine_info.status = MachineStatus.STOPPED\n        server.stop_training()",
  "def set_up_run_config(server, conf):\n    server.heart_beat_timeout = conf.heartbeat_timeout\n    server.runner_config = conf.runner_config\n    server.handlers = conf.handlers",
  "def main():\n    if sys.version_info >= (3, 9):\n        raise RuntimeError(\"Python versions 3.9 and above are not yet supported. Please use Python 3.8 or 3.7.\")\n    if sys.version_info < (3, 7):\n        raise RuntimeError(\"Python versions 3.6 and below are not supported. Please use Python 3.8 or 3.7.\")\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--workspace\", \"-m\", type=str, help=\"WORKSPACE folder\", required=True)\n    parser.add_argument(\n        \"--fed_client\", \"-s\", type=str, help=\"an aggregation server specification json file\", required=True\n    )\n    parser.add_argument(\"--set\", metavar=\"KEY=VALUE\", nargs=\"*\")\n    parser.add_argument(\"--local_rank\", type=int, default=0)\n\n    args = parser.parse_args()\n    kv_list = parse_vars(args.set)\n\n    config_folder = kv_list.get(\"config_folder\", \"\")\n    if config_folder == \"\":\n        args.client_config = AppFolderConstants.CONFIG_FED_CLIENT\n    else:\n        args.client_config = os.path.join(config_folder, AppFolderConstants.CONFIG_FED_CLIENT)\n    # TODO:: remove env and train config since they are not core\n    args.env = os.path.join(\"config\", AppFolderConstants.CONFIG_ENV)\n    args.train_config = os.path.join(\"config\", AppFolderConstants.CONFIG_TRAIN)\n    args.log_config = None\n\n    for name in [WorkspaceConstants.RESTART_FILE, WorkspaceConstants.SHUTDOWN_FILE]:\n        try:\n            f = os.path.join(args.workspace, name)\n            if os.path.exists(f):\n                os.remove(f)\n        except BaseException:\n            print(\"Could not remove the {} file.  Please check your system before starting FL.\".format(name))\n            sys.exit(-1)\n\n    rank = args.local_rank\n\n    try:\n        os.chdir(args.workspace)\n        AuditService.initialize(audit_file_name=WorkspaceConstants.AUDIT_LOG)\n\n        startup = os.path.join(args.workspace, \"startup\")\n        conf = FLClientStarterConfiger(\n            app_root=startup,\n            client_config_file_name=args.fed_client,\n            log_config_file_name=WorkspaceConstants.LOGGING_CONFIG,\n            kv_list=args.set,\n        )\n        conf.configure()\n\n        log_file = os.path.join(args.workspace, \"log.txt\")\n        add_logfile_handler(log_file)\n\n        deployer = conf.base_deployer\n\n        security_check(secure_train=deployer.secure_train, content_folder=startup, fed_client_config=args.fed_client)\n\n        federated_client = deployer.create_fed_client(args)\n\n        while not federated_client.sp_established:\n            print(\"Waiting for SP....\")\n            time.sleep(1.0)\n\n        federated_client.use_gpu = False\n        federated_client.config_folder = config_folder\n\n        if rank == 0:\n            federated_client.register()\n\n        if not federated_client.token:\n            print(\"The client could not register to server. \")\n            raise RuntimeError(\"Login failed.\")\n\n        federated_client.start_heartbeat()\n\n        servers = [{t[\"name\"]: t[\"service\"]} for t in deployer.server_config]\n        admin_agent = create_admin_agent(\n            deployer.client_config,\n            deployer.client_name,\n            deployer.req_processors,\n            deployer.secure_train,\n            sorted(servers)[0],\n            federated_client,\n            args,\n            deployer.multi_gpu,\n            rank,\n        )\n        admin_agent.start()\n\n        deployer.close()\n\n    except ConfigError as ex:\n        print(\"ConfigError:\", str(ex))\n    finally:\n        pass\n\n    sys.exit(0)",
  "def security_check(secure_train: bool, content_folder: str, fed_client_config: str):\n    \"\"\"To check the security content if running in security mode.\n\n    Args:\n       secure_train (bool): if run in secure mode or not.\n       content_folder (str): the folder to check.\n       fed_client_config (str): fed_client.json\n    \"\"\"\n    # initialize the SecurityContentService.\n    # must do this before initializing other services since it may be needed by them!\n    SecurityContentService.initialize(content_folder=content_folder)\n\n    if secure_train:\n        insecure_list = secure_content_check(fed_client_config, site_type=\"client\")\n        if len(insecure_list):\n            print(\"The following files are not secure content.\")\n            for item in insecure_list:\n                print(item)\n            sys.exit(1)\n    # initialize the AuditService, which is used by command processing.\n    # The Audit Service can be used in other places as well.\n    AuditService.initialize(audit_file_name=WorkspaceConstants.AUDIT_LOG)",
  "def create_admin_agent(\n    client_args,\n    client_id,\n    req_processors,\n    secure_train,\n    server_args,\n    federated_client: FederatedClient,\n    args,\n    is_multi_gpu,\n    rank,\n):\n    \"\"\"Creates an admin agent.\n\n    Args:\n        client_args: start client command args\n        client_id: client name\n        req_processors: request processors\n        secure_train: True/False\n        server_args: FL server args\n        federated_client: FL client object\n        args: command args\n        is_multi_gpu: True/False\n        rank: client rank process number\n\n    Returns:\n        A FedAdminAgent.\n    \"\"\"\n    sender = AdminMessageSender(\n        client_name=federated_client.token,\n        root_cert=client_args[SSLConstants.ROOT_CERT],\n        ssl_cert=client_args[SSLConstants.CERT],\n        private_key=client_args[SSLConstants.PRIVATE_KEY],\n        server_args=server_args,\n        secure=secure_train,\n        is_multi_gpu=is_multi_gpu,\n        rank=rank,\n    )\n    client_engine = ClientEngine(federated_client, federated_client.token, sender, args, rank)\n    admin_agent = FedAdminAgent(\n        client_name=\"admin_agent\",\n        sender=sender,\n        app_ctx=client_engine,\n    )\n    admin_agent.app_ctx.set_agent(admin_agent)\n    federated_client.set_client_engine(client_engine)\n    for processor in req_processors:\n        admin_agent.register_processor(processor)\n\n    client_engine.fire_event(EventType.SYSTEM_START, client_engine.new_context())\n\n    return admin_agent",
  "def check_parent_alive(parent_pid, stop_event: threading.Event):\n    while True:\n        if stop_event.is_set():\n            break\n        if not psutil.pid_exists(parent_pid):\n            # if parent is not alive, kill its worker process\n            os.killpg(os.getpgid(os.getpid()), 9)\n            break\n        time.sleep(1)",
  "def main():\n    \"\"\"Worker process start program.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--workspace\", \"-m\", type=str, help=\"WORKSPACE folder\", required=True)\n    parser.add_argument(\"--startup\", \"-w\", type=str, help=\"startup folder\", required=True)\n    parser.add_argument(\"--token\", \"-t\", type=str, help=\"token\", required=True)\n    parser.add_argument(\"--ssid\", \"-d\", type=str, help=\"ssid\", required=True)\n    parser.add_argument(\"--job_id\", \"-n\", type=str, help=\"job_id\", required=True)\n    parser.add_argument(\"--client_name\", \"-c\", type=str, help=\"client name\", required=True)\n    parser.add_argument(\"--listen_port\", \"-p\", type=str, help=\"listen port\", required=True)\n    parser.add_argument(\"--sp_target\", \"-g\", type=str, help=\"Sp target\", required=True)\n\n    parser.add_argument(\n        \"--fed_client\", \"-s\", type=str, help=\"an aggregation server specification json file\", required=True\n    )\n\n    parser.add_argument(\"--set\", metavar=\"KEY=VALUE\", nargs=\"*\")\n\n    parser.add_argument(\"--local_rank\", type=int, default=0)\n\n    args = parser.parse_args()\n    kv_list = parse_vars(args.set)\n\n    # get parent process id\n    parent_pid = os.getppid()\n\n    args.train_config = os.path.join(\"config\", \"config_train.json\")\n    config_folder = kv_list.get(\"config_folder\", \"\")\n    secure_train = kv_list.get(\"secure_train\", True)\n    if config_folder == \"\":\n        args.client_config = \"config_fed_client.json\"\n    else:\n        args.client_config = os.path.join(config_folder, \"config_fed_client.json\")\n    args.config_folder = config_folder\n    args.env = os.path.join(\"config\", \"environment.json\")\n\n    try:\n        remove_restart_file(args)\n    except BaseException:\n        print(\"Could not remove the restart.fl / shutdown.fl file.  Please check your system before starting FL.\")\n        sys.exit(-1)\n\n    restart_file = os.path.join(args.workspace, \"restart.fl\")\n    if os.path.exists(restart_file):\n        os.remove(restart_file)\n\n    print(\"starting the client .....\")\n\n    startup = os.path.join(args.workspace, \"startup\")\n    SecurityContentService.initialize(content_folder=startup)\n\n    thread = None\n    stop_event = threading.Event()\n    deployer = None\n    command_agent = None\n    federated_client = None\n\n    startup = args.startup\n    app_root = os.path.join(\n        args.workspace,\n        WorkspaceConstants.WORKSPACE_PREFIX + str(args.job_id),\n        WorkspaceConstants.APP_PREFIX + args.client_name,\n    )\n\n    logging_setup(app_root, args, config_folder, startup)\n\n    log_file = os.path.join(args.workspace, args.job_id, \"log.txt\")\n    add_logfile_handler(log_file)\n    logger = logging.getLogger(\"worker_process\")\n    logger.info(\"Worker_process started.\")\n\n    try:\n        # start parent process checking thread\n        thread = threading.Thread(target=check_parent_alive, args=(parent_pid, stop_event))\n        thread.start()\n\n        conf = FLClientStarterConfiger(\n            app_root=startup,\n            client_config_file_name=args.fed_client,\n            log_config_file_name=args.log_config,\n            kv_list=args.set,\n            logging_config=False,\n        )\n        conf.configure()\n\n        deployer = conf.base_deployer\n        federated_client = deployer.create_fed_client(args, args.sp_target)\n        federated_client.status = ClientStatus.STARTING\n\n        federated_client.token = args.token\n        federated_client.ssid = args.ssid\n        federated_client.client_name = args.client_name\n        federated_client.fl_ctx.set_prop(FLContextKey.CLIENT_NAME, args.client_name, private=False)\n        federated_client.fl_ctx.set_prop(EngineConstant.FL_TOKEN, args.token, private=False)\n        federated_client.fl_ctx.set_prop(FLContextKey.WORKSPACE_ROOT, args.workspace, private=True)\n\n        client_config_file_name = os.path.join(app_root, args.client_config)\n        conf = ClientJsonConfigurator(\n            config_file_name=client_config_file_name,\n        )\n        conf.configure()\n\n        workspace = Workspace(args.workspace, args.client_name, config_folder)\n        run_manager = ClientRunManager(\n            client_name=args.client_name,\n            job_id=args.job_id,\n            workspace=workspace,\n            client=federated_client,\n            components=conf.runner_config.components,\n            handlers=conf.runner_config.handlers,\n            conf=conf,\n        )\n        federated_client.run_manager = run_manager\n\n        with run_manager.new_context() as fl_ctx:\n            fl_ctx.set_prop(FLContextKey.CLIENT_NAME, args.client_name, private=False)\n            fl_ctx.set_prop(EngineConstant.FL_TOKEN, args.token, private=False)\n            fl_ctx.set_prop(FLContextKey.WORKSPACE_ROOT, args.workspace, private=True)\n            fl_ctx.set_prop(FLContextKey.ARGS, args, sticky=True)\n            fl_ctx.set_prop(FLContextKey.APP_ROOT, app_root, private=True, sticky=True)\n            fl_ctx.set_prop(FLContextKey.WORKSPACE_OBJECT, workspace, private=True)\n            fl_ctx.set_prop(FLContextKey.SECURE_MODE, secure_train, private=True, sticky=True)\n\n            client_runner = ClientRunner(config=conf.runner_config, job_id=args.job_id, engine=run_manager)\n            run_manager.add_handler(client_runner)\n            fl_ctx.set_prop(FLContextKey.RUNNER, client_runner, private=True)\n\n            # Start the command agent\n            command_agent = CommandAgent(federated_client, int(args.listen_port), client_runner)\n            command_agent.start(fl_ctx)\n\n        federated_client.status = ClientStatus.STARTED\n        client_runner.run(app_root, args)\n\n    except BaseException as e:\n        logger.error(f\"FL client execution exception: {e}\", exc_info=True)\n        raise e\n    finally:\n        stop_event.set()\n        if command_agent:\n            command_agent.shutdown()\n        if deployer:\n            deployer.close()\n        if federated_client:\n            federated_client.close()\n        if thread and thread.is_alive():\n            thread.join()",
  "def logging_setup(app_root, args, config_folder, startup):\n    app_log_config = os.path.join(app_root, config_folder, \"log.config\")\n    if os.path.exists(app_log_config):\n        args.log_config = app_log_config\n    else:\n        args.log_config = os.path.join(startup, \"log.config\")\n    log_config_file_path = os.path.join(app_root, args.log_config)\n    logging.config.fileConfig(fname=log_config_file_path, disable_existing_loggers=False)",
  "def remove_restart_file(args):\n    \"\"\"To remove the restart.fl file.\n\n    Args:\n        args: command args\n\n    \"\"\"\n    restart_file = os.path.join(args.workspace, \"restart.fl\")\n    if os.path.exists(restart_file):\n        os.remove(restart_file)\n    restart_file = os.path.join(args.workspace, \"shutdown.fl\")\n    if os.path.exists(restart_file):\n        os.remove(restart_file)",
  "class EventRelayer(FLComponent):\n    \"\"\"To relay the event from the worker_process.\"\"\"\n\n    def __init__(self, conn, local_rank):\n        \"\"\"To init the EventRelayer.\n\n        Args:\n            conn: worker_process connection.\n            local_rank: process local rank\n        \"\"\"\n        super().__init__()\n        self.conn = conn\n        self.local_rank = local_rank\n\n        self.event_lock = threading.Lock()\n\n    def relay_event(self, run_manager, data):\n        \"\"\"To relay the event.\n\n        Args:\n            run_manager: Client_Run_Manager\n            data: event data\n\n        \"\"\"\n        with run_manager.new_context() as fl_ctx:\n            event_type = data[CommunicationMetaData.EVENT_TYPE]\n            fl_ctx.props.update(data[CommunicationMetaData.FL_CTX].props)\n\n            fl_ctx.set_prop(\n                FLContextKey.EVENT_ORIGIN_SITE, CommunicateData.MULTI_PROCESS_EXECUTOR, private=True, sticky=False\n            )\n            self.fire_event(event_type=event_type, fl_ctx=fl_ctx)\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        \"\"\"To handle the event.\n\n        Args:\n            event_type: event_type\n            fl_ctx: FLContext\n\n        \"\"\"\n        event_site = fl_ctx.get_prop(FLContextKey.EVENT_ORIGIN_SITE)\n\n        new_fl_ctx = FLContext()\n        new_fl_ctx.props.update(copy.deepcopy(get_serializable_data(fl_ctx).props))\n        if event_site != CommunicateData.MULTI_PROCESS_EXECUTOR:\n            with self.event_lock:\n                try:\n                    data = {\n                        CommunicationMetaData.EVENT_TYPE: event_type,\n                        CommunicationMetaData.RANK_NUMBER: self.local_rank,\n                        CommunicationMetaData.FL_CTX: new_fl_ctx,\n                    }\n                    self.conn.send(data)\n\n                    return_data = self.conn.recv()\n                    # update the fl_ctx from the child process return data.\n                    fl_ctx.props.update(return_data[CommunicationMetaData.FL_CTX].props)\n                except BaseException:\n                    self.log_warning(\n                        fl_ctx, f\"Failed to relay the event to parent process. Event: {event_type}\", fire_event=False\n                    )",
  "def main():\n    \"\"\"Sub_worker process program.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--workspace\", \"-m\", type=str, help=\"WORKSPACE folder\", required=True)\n    # parser.add_argument(\"--parent_port\", type=str, help=\"Parent listen port\", required=True)\n    parser.add_argument(\"--ports\", type=str, help=\"Listen ports\", required=True)\n    # parser.add_argument(\"--local_rank\", type=int, default=0)\n    args = parser.parse_args()\n    listen_ports = list(map(int, args.ports.split(\"-\")))\n    # parent_port = args.parent_port\n\n    startup = os.path.join(args.workspace, \"startup\")\n    SecurityContentService.initialize(content_folder=startup)\n\n    # local_rank = args.local_rank\n    local_rank = int(os.environ[\"LOCAL_RANK\"])\n    listen_port = listen_ports[local_rank * 3]\n    exe_conn = _create_connection(listen_port)\n\n    listen_port = listen_ports[local_rank * 3 + 1]\n    handle_conn = _create_connection(listen_port)\n\n    listen_port = listen_ports[local_rank * 3 + 2]\n\n    event_conn = None\n    while not event_conn:\n        try:\n            address = (\"localhost\", listen_port)\n            event_conn = Client(address, authkey=CommunicationMetaData.PARENT_PASSWORD.encode())\n        except Exception as e:\n            time.sleep(1.0)\n            pass\n\n    data = exe_conn.recv()\n\n    client_name = data[CommunicationMetaData.FL_CTX].get_prop(FLContextKey.CLIENT_NAME)\n    job_id = data[CommunicationMetaData.FL_CTX].get_prop(FLContextKey.CURRENT_RUN)\n    workspace = data[CommunicationMetaData.FL_CTX].get_prop(FLContextKey.WORKSPACE_OBJECT)\n    run_manager = ClientRunManager(\n        client_name=client_name,\n        job_id=job_id,\n        workspace=workspace,\n        client=None,\n        components=data[CommunicationMetaData.COMPONENTS],\n        handlers=data[CommunicationMetaData.HANDLERS],\n        conf=None,\n    )\n\n    log_config_file_path = os.path.join(startup, \"log.config\")\n    logging.config.fileConfig(fname=log_config_file_path, disable_existing_loggers=False)\n\n    log_file = os.path.join(args.workspace, job_id, \"log.txt\")\n    add_logfile_handler(log_file)\n\n    relayer = EventRelayer(event_conn, local_rank)\n    run_manager.add_handler(relayer)\n    run_manager.components[CommunicationMetaData.RELAYER] = relayer\n\n    executor = data[CommunicationMetaData.LOCAL_EXECUTOR]\n    exe_conn.send({CommunicationMetaData.RANK_PROCESS_STARTED: True})\n\n    exe_thread = threading.Thread(target=execute, args=(run_manager, local_rank, exe_conn, executor))\n    exe_thread.start()\n\n    event_thread = threading.Thread(target=handle_event, args=(run_manager, local_rank, handle_conn))\n    event_thread.start()\n\n    with run_manager.new_context() as fl_ctx:\n        fl_ctx.set_prop(FLContextKey.RANK_NUMBER, local_rank, private=True, sticky=True)\n        num_of_processes = int(len(listen_ports) / 3)\n        fl_ctx.set_prop(FLContextKey.NUM_OF_PROCESSES, num_of_processes, private=True, sticky=True)\n\n    exe_thread.join()\n    event_thread.join()",
  "def _create_connection(listen_port):\n    address = (\"localhost\", int(listen_port))\n    listener = Listener(address, authkey=CommunicationMetaData.CHILD_PASSWORD.encode())\n    conn = listener.accept()\n    return conn",
  "def execute(run_manager, local_rank, exe_conn, executor):\n    \"\"\"To execute the event task and pass to worker_process.\n\n    Args:\n        run_manager: Client_Run_Manager\n        local_rank: provcess local rank\n        exe_conn: execution connection\n        executor: local executor\n\n    \"\"\"\n    try:\n        abort_signal = None\n        while True:\n            data = exe_conn.recv()\n\n            command = data[CommunicationMetaData.COMMAND]\n            if command == CommunicateData.EXECUTE:\n                with run_manager.new_context() as fl_ctx:\n                    abort_signal = Signal()\n\n                    task_name = data[CommunicationMetaData.TASK_NAME]\n                    shareable = data[CommunicationMetaData.SHAREABLE]\n                    fl_ctx.props.update(data[CommunicationMetaData.FL_CTX].props)\n\n                    shareable = executor.execute(\n                        task_name=task_name, shareable=shareable, fl_ctx=fl_ctx, abort_signal=abort_signal\n                    )\n                    if local_rank == 0:\n                        return_data = {\n                            CommunicationMetaData.SHAREABLE: shareable,\n                            CommunicationMetaData.FL_CTX: get_serializable_data(fl_ctx),\n                        }\n                        exe_conn.send(return_data)\n\n            elif command == CommunicateData.CLOSE:\n                if abort_signal:\n                    abort_signal.trigger(True)\n                break\n    except Exception:\n        traceback.print_exc()\n        print(\"If you abort client you can ignore this exception.\")",
  "def handle_event(run_manager, local_rank, exe_conn):\n    \"\"\"To handle the event.\n\n    Args:\n        run_manager: Client_run_manager\n        local_rank: process local rank\n        exe_conn: execute connection\n\n    \"\"\"\n    try:\n        while True:\n            data = exe_conn.recv()\n\n            command = data[CommunicationMetaData.COMMAND]\n            if command == CommunicateData.HANDLE_EVENT:\n                event_relayer = run_manager.get_component(CommunicationMetaData.RELAYER)\n                event_relayer.relay_event(run_manager, data)\n\n                fl_ctx = data[CommunicationMetaData.FL_CTX]\n                if local_rank == 0:\n                    return_data = {CommunicationMetaData.FL_CTX: get_serializable_data(fl_ctx)}\n                    exe_conn.send(return_data)\n            elif command == CommunicateData.CLOSE:\n                break\n    except Exception:\n        traceback.print_exc()\n        print(\"If you abort client you can ignore this exception.\")",
  "def __init__(self, conn, local_rank):\n        \"\"\"To init the EventRelayer.\n\n        Args:\n            conn: worker_process connection.\n            local_rank: process local rank\n        \"\"\"\n        super().__init__()\n        self.conn = conn\n        self.local_rank = local_rank\n\n        self.event_lock = threading.Lock()",
  "def relay_event(self, run_manager, data):\n        \"\"\"To relay the event.\n\n        Args:\n            run_manager: Client_Run_Manager\n            data: event data\n\n        \"\"\"\n        with run_manager.new_context() as fl_ctx:\n            event_type = data[CommunicationMetaData.EVENT_TYPE]\n            fl_ctx.props.update(data[CommunicationMetaData.FL_CTX].props)\n\n            fl_ctx.set_prop(\n                FLContextKey.EVENT_ORIGIN_SITE, CommunicateData.MULTI_PROCESS_EXECUTOR, private=True, sticky=False\n            )\n            self.fire_event(event_type=event_type, fl_ctx=fl_ctx)",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        \"\"\"To handle the event.\n\n        Args:\n            event_type: event_type\n            fl_ctx: FLContext\n\n        \"\"\"\n        event_site = fl_ctx.get_prop(FLContextKey.EVENT_ORIGIN_SITE)\n\n        new_fl_ctx = FLContext()\n        new_fl_ctx.props.update(copy.deepcopy(get_serializable_data(fl_ctx).props))\n        if event_site != CommunicateData.MULTI_PROCESS_EXECUTOR:\n            with self.event_lock:\n                try:\n                    data = {\n                        CommunicationMetaData.EVENT_TYPE: event_type,\n                        CommunicationMetaData.RANK_NUMBER: self.local_rank,\n                        CommunicationMetaData.FL_CTX: new_fl_ctx,\n                    }\n                    self.conn.send(data)\n\n                    return_data = self.conn.recv()\n                    # update the fl_ctx from the child process return data.\n                    fl_ctx.props.update(return_data[CommunicationMetaData.FL_CTX].props)\n                except BaseException:\n                    self.log_warning(\n                        fl_ctx, f\"Failed to relay the event to parent process. Event: {event_type}\", fire_event=False\n                    )",
  "class CommandUtil(object):\n\n    TARGET_CLIENTS = \"target_clients\"\n    TARGET_CLIENT_TOKENS = \"target_client_tokens\"\n    TARGET_CLIENT_NAMES = \"target_client_names\"\n    TARGET_TYPE = \"target_type\"\n\n    TARGET_TYPE_CLIENT = \"client\"\n    TARGET_TYPE_SERVER = \"server\"\n    TARGET_TYPE_ALL = \"all\"\n\n    SITE_SERVER = \"server\"\n    ALL_SITES = \"@ALL\"\n    JOB_ID = \"job_id\"\n\n    def validate_command_targets(self, conn: Connection, args: List[str]) -> str:\n        \"\"\"Validate specified args and determine and set target type and target names in the Connection.\n\n        The args must be like this:\n\n            target_type client_names ...\n\n        where target_type is one of 'all', 'client', 'server'\n\n        Args:\n            conn: A Connection object.\n            args: Specified arguments.\n\n        Returns:\n            An error message. It is empty \"\" if no error found.\n        \"\"\"\n        # return target type and a list of target names\n        if len(args) < 1:\n            return \"missing target type (server or client)\"\n\n        target_type = args[0]\n        conn.set_prop(self.TARGET_TYPE, target_type)\n\n        if target_type == self.TARGET_TYPE_SERVER:\n            return \"\"\n\n        if target_type == self.TARGET_TYPE_CLIENT:\n            client_names = args[1:]\n        elif target_type == self.TARGET_TYPE_ALL:\n            client_names = []\n        else:\n            return \"unknown target type {}\".format(target_type)\n\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineSpec):\n            raise TypeError(\"engine must be ServerEngineSpec but got {}\".format(type(engine)))\n        if len(client_names) == 0:\n            # get all clients\n            clients = engine.get_clients()\n        else:\n            clients, invalid_inputs = engine.validate_clients(client_names)\n            if invalid_inputs:\n                return \"invalid client(s): {}\".format(\" \".join(invalid_inputs))\n\n        if target_type == self.TARGET_TYPE_CLIENT and not clients:\n            return \"no clients available\"\n\n        valid_tokens = []\n        client_names = []\n        all_clients = {}\n        for c in clients:\n            valid_tokens.append(c.token)\n            client_names.append(c.name)\n            all_clients[c.token] = c.name\n        conn.set_prop(self.TARGET_CLIENT_TOKENS, valid_tokens)\n        # if clients:\n        #     client_names = [c.name for c in clients]\n        # else:\n        #     client_names = []\n        conn.set_prop(self.TARGET_CLIENT_NAMES, client_names)\n        conn.set_prop(self.TARGET_CLIENTS, all_clients)\n        return \"\"\n\n    def _authorize_actions(self, conn: Connection, args: List[str], actions):\n        err = self.validate_command_targets(conn, args)\n        if err:\n            conn.append_error(err)\n            return False, None\n\n        target_type = conn.get_prop(self.TARGET_TYPE)\n        authorize_server = False\n        authorize_clients = False\n\n        if target_type == self.TARGET_TYPE_SERVER:\n            authorize_server = True\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            authorize_clients = True\n        else:\n            # all\n            authorize_server = True\n            authorize_clients = True\n\n        sites = []\n        if authorize_clients:\n            client_names = conn.get_prop(self.TARGET_CLIENT_NAMES)\n\n            if client_names:\n                sites.extend(client_names)\n\n        if authorize_server:\n            sites.append(self.SITE_SERVER)\n\n        authz_ctx = FLAuthzContext.new_authz_context(site_names=sites, actions=actions)\n        return True, authz_ctx\n\n    def authorize_view(self, conn: Connection, args: List[str]):\n        return self._authorize_actions(conn, args[1:], [Action.VIEW])\n\n    def authorize_train(self, conn: Connection, args: List[str]):\n        if len(args) != 3:\n            conn.append_error(\"syntax error: missing job_id and target\")\n            return False, None\n\n        job_id = args[1].lower()\n\n        destination = job_id[len(WorkspaceConstants.WORKSPACE_PREFIX) :]\n        conn.set_prop(self.JOB_ID, destination)\n\n        return self._authorize_actions(conn, args[2:], [Action.TRAIN])\n\n    def authorize_job_meta(self, conn: Connection, meta: dict, actions: List[str]):\n\n        deploy_map = meta.get(\"deploy_map\")\n        if not deploy_map:\n            conn.append_error(f\"deploy_map missing for job {self.get_job_name(meta)}\")\n            return False, None\n\n        sites = set()\n        for app, site_list in deploy_map.items():\n            sites.update(site_list)\n\n        # Run-time might be a better spot for this\n        if self.ALL_SITES.casefold() in (site.casefold() for site in sites):\n            sites.add(self.SITE_SERVER)\n            engine = conn.app_ctx\n            clients = engine.get_clients()\n            sites.update([client.name for client in clients])\n\n        authz_ctx = FLAuthzContext.new_authz_context(site_names=list(sites), actions=actions)\n        return True, authz_ctx\n\n    def authorize_operate(self, conn: Connection, args: List[str]):\n        return self._authorize_actions(conn, args[1:], [Action.OPERATE])\n\n    def send_request_to_clients(self, conn, message, process_client_replies=None):\n        client_tokens = conn.get_prop(self.TARGET_CLIENT_TOKENS)\n\n        # for client in clients:\n        #     requests.update({client.strip(): message})\n\n        # client_names = conn.get_prop(self.TARGET_CLIENT_NAMES, None)\n        if not client_tokens:\n            return None\n\n        requests = {}\n        for token in client_tokens:\n            requests.update({token: message})\n\n        admin_server = conn.server\n        replies = admin_server.send_requests(requests, timeout_secs=admin_server.timeout)\n\n        if process_client_replies:\n            return process_client_replies(replies)\n        else:\n            return replies\n\n    @staticmethod\n    def get_job_name(meta: dict) -> str:\n        \"\"\"Get job name from meta.json\"\"\"\n\n        name = meta.get(JobMetaKey.JOB_NAME)\n        if not name:\n            name = meta.get(JobMetaKey.JOB_FOLDER_NAME, \"No name\")\n\n        return name\n\n    def process_replies_to_table(self, conn: Connection, replies):\n        \"\"\"Process the clients' replies and put in a table format.\n\n        Args:\n            conn: A Connection object.\n            replies: replies from clients\n        \"\"\"\n        if not replies:\n            conn.append_string(\"no responses from clients\")\n\n        engine = conn.app_ctx\n        table = conn.append_table([\"Client\", \"Response\"])\n        for r in replies:\n            if r.reply:\n                resp = r.reply.body\n            else:\n                resp = \"\"\n            client_name = engine.get_client_name_from_token(r.client_token)\n            if not client_name:\n                clients = conn.get_prop(self.TARGET_CLIENTS)\n                client_name = clients.get(r.client_token, \"\")\n\n            table.add_row([client_name, resp])\n\n    def _process_replies_to_string(self, conn: Connection, replies) -> str:\n        \"\"\"Process the clients replies and put in a string format.\n\n        Args:\n            conn: A Connection object.\n            replies: replies from clients\n\n        Returns:\n            A string response.\n        \"\"\"\n        engine = conn.app_ctx\n        response = \"no responses from clients\"\n        if replies:\n            response = \"\"\n            for r in replies:\n                client_name = engine.get_client_name_from_token(r.client_token)\n                response += \"client:\" + client_name\n                if r.reply:\n                    response += \" : \" + r.reply.body + \"\\n\"\n                else:\n                    response += \" : No replies\\n\"\n        return response",
  "def validate_command_targets(self, conn: Connection, args: List[str]) -> str:\n        \"\"\"Validate specified args and determine and set target type and target names in the Connection.\n\n        The args must be like this:\n\n            target_type client_names ...\n\n        where target_type is one of 'all', 'client', 'server'\n\n        Args:\n            conn: A Connection object.\n            args: Specified arguments.\n\n        Returns:\n            An error message. It is empty \"\" if no error found.\n        \"\"\"\n        # return target type and a list of target names\n        if len(args) < 1:\n            return \"missing target type (server or client)\"\n\n        target_type = args[0]\n        conn.set_prop(self.TARGET_TYPE, target_type)\n\n        if target_type == self.TARGET_TYPE_SERVER:\n            return \"\"\n\n        if target_type == self.TARGET_TYPE_CLIENT:\n            client_names = args[1:]\n        elif target_type == self.TARGET_TYPE_ALL:\n            client_names = []\n        else:\n            return \"unknown target type {}\".format(target_type)\n\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineSpec):\n            raise TypeError(\"engine must be ServerEngineSpec but got {}\".format(type(engine)))\n        if len(client_names) == 0:\n            # get all clients\n            clients = engine.get_clients()\n        else:\n            clients, invalid_inputs = engine.validate_clients(client_names)\n            if invalid_inputs:\n                return \"invalid client(s): {}\".format(\" \".join(invalid_inputs))\n\n        if target_type == self.TARGET_TYPE_CLIENT and not clients:\n            return \"no clients available\"\n\n        valid_tokens = []\n        client_names = []\n        all_clients = {}\n        for c in clients:\n            valid_tokens.append(c.token)\n            client_names.append(c.name)\n            all_clients[c.token] = c.name\n        conn.set_prop(self.TARGET_CLIENT_TOKENS, valid_tokens)\n        # if clients:\n        #     client_names = [c.name for c in clients]\n        # else:\n        #     client_names = []\n        conn.set_prop(self.TARGET_CLIENT_NAMES, client_names)\n        conn.set_prop(self.TARGET_CLIENTS, all_clients)\n        return \"\"",
  "def _authorize_actions(self, conn: Connection, args: List[str], actions):\n        err = self.validate_command_targets(conn, args)\n        if err:\n            conn.append_error(err)\n            return False, None\n\n        target_type = conn.get_prop(self.TARGET_TYPE)\n        authorize_server = False\n        authorize_clients = False\n\n        if target_type == self.TARGET_TYPE_SERVER:\n            authorize_server = True\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            authorize_clients = True\n        else:\n            # all\n            authorize_server = True\n            authorize_clients = True\n\n        sites = []\n        if authorize_clients:\n            client_names = conn.get_prop(self.TARGET_CLIENT_NAMES)\n\n            if client_names:\n                sites.extend(client_names)\n\n        if authorize_server:\n            sites.append(self.SITE_SERVER)\n\n        authz_ctx = FLAuthzContext.new_authz_context(site_names=sites, actions=actions)\n        return True, authz_ctx",
  "def authorize_view(self, conn: Connection, args: List[str]):\n        return self._authorize_actions(conn, args[1:], [Action.VIEW])",
  "def authorize_train(self, conn: Connection, args: List[str]):\n        if len(args) != 3:\n            conn.append_error(\"syntax error: missing job_id and target\")\n            return False, None\n\n        job_id = args[1].lower()\n\n        destination = job_id[len(WorkspaceConstants.WORKSPACE_PREFIX) :]\n        conn.set_prop(self.JOB_ID, destination)\n\n        return self._authorize_actions(conn, args[2:], [Action.TRAIN])",
  "def authorize_job_meta(self, conn: Connection, meta: dict, actions: List[str]):\n\n        deploy_map = meta.get(\"deploy_map\")\n        if not deploy_map:\n            conn.append_error(f\"deploy_map missing for job {self.get_job_name(meta)}\")\n            return False, None\n\n        sites = set()\n        for app, site_list in deploy_map.items():\n            sites.update(site_list)\n\n        # Run-time might be a better spot for this\n        if self.ALL_SITES.casefold() in (site.casefold() for site in sites):\n            sites.add(self.SITE_SERVER)\n            engine = conn.app_ctx\n            clients = engine.get_clients()\n            sites.update([client.name for client in clients])\n\n        authz_ctx = FLAuthzContext.new_authz_context(site_names=list(sites), actions=actions)\n        return True, authz_ctx",
  "def authorize_operate(self, conn: Connection, args: List[str]):\n        return self._authorize_actions(conn, args[1:], [Action.OPERATE])",
  "def send_request_to_clients(self, conn, message, process_client_replies=None):\n        client_tokens = conn.get_prop(self.TARGET_CLIENT_TOKENS)\n\n        # for client in clients:\n        #     requests.update({client.strip(): message})\n\n        # client_names = conn.get_prop(self.TARGET_CLIENT_NAMES, None)\n        if not client_tokens:\n            return None\n\n        requests = {}\n        for token in client_tokens:\n            requests.update({token: message})\n\n        admin_server = conn.server\n        replies = admin_server.send_requests(requests, timeout_secs=admin_server.timeout)\n\n        if process_client_replies:\n            return process_client_replies(replies)\n        else:\n            return replies",
  "def get_job_name(meta: dict) -> str:\n        \"\"\"Get job name from meta.json\"\"\"\n\n        name = meta.get(JobMetaKey.JOB_NAME)\n        if not name:\n            name = meta.get(JobMetaKey.JOB_FOLDER_NAME, \"No name\")\n\n        return name",
  "def process_replies_to_table(self, conn: Connection, replies):\n        \"\"\"Process the clients' replies and put in a table format.\n\n        Args:\n            conn: A Connection object.\n            replies: replies from clients\n        \"\"\"\n        if not replies:\n            conn.append_string(\"no responses from clients\")\n\n        engine = conn.app_ctx\n        table = conn.append_table([\"Client\", \"Response\"])\n        for r in replies:\n            if r.reply:\n                resp = r.reply.body\n            else:\n                resp = \"\"\n            client_name = engine.get_client_name_from_token(r.client_token)\n            if not client_name:\n                clients = conn.get_prop(self.TARGET_CLIENTS)\n                client_name = clients.get(r.client_token, \"\")\n\n            table.add_row([client_name, resp])",
  "def _process_replies_to_string(self, conn: Connection, replies) -> str:\n        \"\"\"Process the clients replies and put in a string format.\n\n        Args:\n            conn: A Connection object.\n            replies: replies from clients\n\n        Returns:\n            A string response.\n        \"\"\"\n        engine = conn.app_ctx\n        response = \"no responses from clients\"\n        if replies:\n            response = \"\"\n            for r in replies:\n                client_name = engine.get_client_name_from_token(r.client_token)\n                response += \"client:\" + client_name\n                if r.reply:\n                    response += \" : \" + r.reply.body + \"\\n\"\n                else:\n                    response += \" : No replies\\n\"\n        return response",
  "def new_message(conn: Connection, topic, body) -> Message:\n    msg = Message(topic=topic, body=body)\n    event_id = conn.get_prop(ConnProps.EVENT_ID, default=None)\n    if event_id:\n        msg.set_header(ConnProps.EVENT_ID, event_id)\n\n    user_name = conn.get_prop(ConnProps.USER_NAME, default=None)\n    if user_name:\n        msg.set_header(ConnProps.USER_NAME, user_name)\n\n    return msg",
  "class _Waiter(object):\n    def __init__(self, req: Message):\n        self.req = req\n        self.reply = None\n        self.reply_time = None",
  "class _Client(object):\n    def __init__(self, token):\n        self.token = token\n        self.last_heard_time = None\n        self.outgoing_reqs = []\n        self.fnf_reqs = []  # fire-and-forget requests\n        self.waiters = {}  # ref => waiter\n        self.req_lock = threading.Lock()\n        self.waiter_lock = threading.Lock()\n\n    def send(self, req: Message):\n        waiter = _Waiter(req)\n        with self.req_lock:\n            self.outgoing_reqs.append(req)\n\n        with self.waiter_lock:\n            self.waiters[req.id] = waiter\n\n        return waiter\n\n    def fire_and_forget(self, reqs: [Message]):\n        with self.req_lock:\n            for r in reqs:\n                self.fnf_reqs.append(r)\n\n    def get_outgoing_requests(self, max_num_reqs=0) -> [Message]:\n        result = []\n        with self.req_lock:\n            # reqs in outgoing_reqs have higher priority\n            q = self.outgoing_reqs\n            if len(self.outgoing_reqs) <= 0:\n                # no regular reqs - take fire-and-forget reqs\n                q = self.fnf_reqs\n\n            if max_num_reqs <= 0:\n                num_reqs = len(q)\n            else:\n                num_reqs = min(max_num_reqs, len(q))\n\n            for i in range(num_reqs):\n                result.append(q.pop(0))\n\n        return result\n\n    def accept_reply(self, reply: Message):\n        self.last_heard_time = time.time()\n        ref_id = reply.get_ref_id()\n        with self.waiter_lock:\n            w = self.waiters.pop(ref_id, None)\n\n        if w:\n            w.reply = reply\n            w.reply_time = time.time()\n\n    def cancel_waiter(self, waiter: _Waiter):\n        req = waiter.req\n        with self.waiter_lock:\n            waiter = self.waiters.pop(req.id, None)\n\n        if waiter:\n            with self.req_lock:\n                if req in self.outgoing_reqs:\n                    self.outgoing_reqs.remove(req)",
  "class ClientReply(object):\n    def __init__(self, client_token: str, req: Message, reply: Message):\n        \"\"\"Client reply.\n\n        Args:\n            client_token (str): client token\n            req (Message): request\n            reply (Message): reply\n        \"\"\"\n        self.client_token = client_token\n        self.request = req\n        self.reply = reply",
  "class _ClientReq(object):\n    def __init__(self, client, req: Message):\n        self.client = client\n        self.req = req\n        self.waiter = None",
  "def check_client_replies(replies: List[ClientReply], client_sites: List[str], command: str):\n    display_sites = \", \".join(client_sites)\n    if not replies:\n        raise RuntimeError(f\"Failed to {command} to the clients {display_sites}: no replies.\")\n    if len(replies) != len(client_sites):\n        raise RuntimeError(f\"Failed to {command} to the clients {display_sites}: not enough replies.\")\n\n    error_msg = \"\"\n    for r, client_name in zip(replies, client_sites):\n        if r.reply and ERROR_MSG_PREFIX in r.reply.body:\n            error_msg += f\"\\t{client_name}: {r.reply.body}\\n\"\n    if error_msg != \"\":\n        raise RuntimeError(f\"Failed to {command} to the following clients: \\n{error_msg}\")",
  "class FedAdminServer(AdminServer):\n    def __init__(\n        self,\n        fed_admin_interface,\n        users,\n        cmd_modules,\n        file_upload_dir,\n        file_download_dir,\n        allowed_shell_cmds,\n        host,\n        port,\n        ca_cert_file_name,\n        server_cert_file_name,\n        server_key_file_name,\n        accepted_client_cns=None,\n        app_validator=None,\n        download_job_url=None,\n    ):\n        \"\"\"The FedAdminServer is the framework for developing admin commands.\n\n        Args:\n            fed_admin_interface: the server's federated admin interface\n            users: a dict of {username: pwd hash}\n            cmd_modules: a list of CommandModules\n            file_upload_dir: the directory for uploaded files\n            file_download_dir: the directory for files to be downloaded\n            allowed_shell_cmds: list of shell commands allowed. If not specified, all allowed.\n            host: the IP address of the admin server\n            port: port number of admin server\n            ca_cert_file_name: the root CA's cert file name\n            server_cert_file_name: server's cert, signed by the CA\n            server_key_file_name: server's private key file\n            accepted_client_cns: list of accepted Common Names from client, if specified\n            app_validator: Application folder validator.\n        \"\"\"\n        cmd_reg = new_command_register_with_builtin_module(app_ctx=fed_admin_interface)\n        self.sai = fed_admin_interface\n        self.allowed_shell_cmds = allowed_shell_cmds\n\n        authenticator = SimpleAuthenticator(users)\n        sess_mgr = SessionManager()\n        login_module = LoginModule(authenticator, sess_mgr)\n        cmd_reg.register_module(login_module)\n\n        # register filters - order is important!\n        # login_module is also a filter that determines if user is authenticated\n        cmd_reg.add_filter(login_module)\n\n        # next is the authorization filter and command module\n        authorizer = AuthorizationService.get_authorizer()\n        authz_filter = AuthzFilter(authorizer=authorizer)\n        cmd_reg.add_filter(authz_filter)\n        authz_cmd_module = AuthzCommandModule(authorizer=authorizer)\n        cmd_reg.register_module(authz_cmd_module)\n\n        # audit filter records commands to audit trail\n        auditor = AuditService.get_auditor()\n        # TODO:: clean this up\n        if not isinstance(auditor, Auditor):\n            raise TypeError(\"auditor must be Auditor but got {}\".format(type(auditor)))\n        audit_filter = CommandAudit(auditor)\n        cmd_reg.add_filter(audit_filter)\n\n        self.file_upload_dir = file_upload_dir\n        self.file_download_dir = file_download_dir\n\n        AppAuthzService.initialize(app_validator)\n        cmd_reg.register_module(\n            FileTransferModule(\n                upload_dir=file_upload_dir,\n                download_dir=file_download_dir,\n                upload_folder_authz_func=AppAuthzService.authorize_upload,\n                download_job_url=download_job_url,\n            )\n        )\n\n        cmd_reg.register_module(sess_mgr)\n\n        if cmd_modules:\n            if not isinstance(cmd_modules, list):\n                raise TypeError(\"cmd_modules must be list but got {}\".format(type(cmd_modules)))\n\n            for m in cmd_modules:\n                if not isinstance(m, CommandModule):\n                    raise TypeError(\"cmd_modules must contain CommandModule but got element of type {}\".format(type(m)))\n                cmd_reg.register_module(m)\n\n        AdminServer.__init__(\n            self,\n            cmd_reg=cmd_reg,\n            host=host,\n            port=port,\n            ca_cert=ca_cert_file_name,\n            server_cert=server_cert_file_name,\n            server_key=server_key_file_name,\n            accepted_client_cns=accepted_client_cns,\n        )\n\n        self.clients = {}  # token => _Client\n        self.client_lock = threading.Lock()\n        self.timeout = 10.0\n\n    def client_heartbeat(self, token):\n        \"\"\"Receive client heartbeat.\n\n        Args:\n            token: the session token of the client\n\n        Returns:\n            Client.\n        \"\"\"\n        with self.client_lock:\n            client = self.clients.get(token)\n            if not client:\n                client = _Client(token)\n                self.clients[token] = client\n            client.last_heard_time = time.time()\n            return client\n\n    def client_dead(self, token):\n        \"\"\"Remove dead client.\n\n        Args:\n            token: the session token of the client\n        \"\"\"\n        with self.client_lock:\n            self.clients.pop(token, None)\n\n    def get_client_tokens(self) -> []:\n        \"\"\"Get tokens of existing clients.\"\"\"\n        result = []\n        with self.client_lock:\n            for token in self.clients.keys():\n                result.append(token)\n        return result\n\n    def send_request_to_client(self, req: Message, client_token: str, timeout_secs=2.0) -> ClientReply:\n        if not isinstance(req, Message):\n            raise TypeError(\"request must be Message but got {}\".format(type(req)))\n        reqs = {client_token: req}\n        replies = self.send_requests(reqs, timeout_secs)\n        if replies is None or len(replies) <= 0:\n            return None\n        else:\n            return replies[0]\n\n    def send_request_to_clients(self, req: Message, client_tokens: [str], timeout_secs=2.0) -> [ClientReply]:\n        if not isinstance(req, Message):\n            raise TypeError(\"request must be Message but got {}\".format(type(req)))\n        reqs = {}\n        for token in client_tokens:\n            reqs[token] = req\n\n        return self.send_requests(reqs, timeout_secs)\n\n    def send_requests(self, requests: dict, timeout_secs=2.0) -> [ClientReply]:\n        \"\"\"Send requests to clients.\n\n        NOTE::\n\n            This method is to be used by a Command Handler to send requests to Clients.\n            Hence, it is run in the Command Handler's handling thread.\n            This is a blocking call - returned only after all responses are received or timeout.\n\n        Args:\n            requests: A dict of requests: {client token: request or list of requests}\n            timeout_secs: how long to wait for reply before timeout\n\n        Returns:\n            A list of ClientReply\n        \"\"\"\n\n        if not isinstance(requests, dict):\n            raise TypeError(\"requests must be a dict but got {}\".format(type(requests)))\n\n        if len(requests) <= 0:\n            return []\n\n        if timeout_secs <= 0.0:\n            # this is fire-and-forget!\n            for token, r in requests.items():\n                client = self.clients.get(token)\n                if not client:\n                    continue\n\n                if isinstance(r, list):\n                    reqs = r\n                else:\n                    reqs = [r]\n\n                client.fire_and_forget(reqs)\n            # No replies\n            return []\n\n        # Regular requests\n        client_reqs = []\n        with self.client_lock:\n            for token, r in requests.items():\n                client = self.clients.get(token)\n                if not client:\n                    continue\n\n                if isinstance(r, list):\n                    reqs = r\n                else:\n                    reqs = [r]\n\n                for req in reqs:\n                    if not isinstance(req, Message):\n                        raise TypeError(\"request must be a Message but got {}\".format(type(req)))\n                    client_reqs.append(_ClientReq(client, req))\n\n        return self._send_client_reqs(client_reqs, timeout_secs)\n\n    def _send_client_reqs(self, client_reqs, timeout_secs) -> [ClientReply]:\n        result = []\n        if len(client_reqs) <= 0:\n            return result\n\n        for cr in client_reqs:\n            cr.waiter = cr.client.send(cr.req)\n\n        start_time = time.time()\n        while True:\n            all_received = True\n            for cr in client_reqs:\n                if cr.waiter.reply_time is None:\n                    all_received = False\n                    break\n\n            if all_received:\n                break\n\n            if time.time() - start_time > timeout_secs:\n                # timeout\n                break\n\n            time.sleep(0.1)\n\n        for cr in client_reqs:\n            result.append(ClientReply(client_token=cr.client.token, req=cr.waiter.req, reply=cr.waiter.reply))\n\n            if cr.waiter.reply_time is None:\n                # this client timed out\n                cr.client.cancel_waiter(cr.waiter)\n\n        return result\n\n    def accept_reply(self, client_token, reply: Message):\n        \"\"\"Accept client reply.\n\n        NOTE::\n            This method is to be called by the FL Engine after a client's reply is received.\n            Hence, it is called from the FL Engine's message processing thread.\n\n        Args:\n            client_token: session token of the client\n            reply: the reply message\n        \"\"\"\n        client = self.client_heartbeat(client_token)\n\n        ref_id = reply.get_ref_id()\n        assert ref_id is not None, \"protocol error: missing ref_id in reply from client {}\".format(client_token)\n\n        client.accept_reply(reply)\n\n    def get_outgoing_requests(self, client_token, max_reqs=0):\n        \"\"\"Get outgoing request from a client.\n\n        NOTE::\n            This method is called by FL Engine to get outgoing messages to the client, so it\n            can send them to the client.\n\n        Args:\n            client_token: session token of the client\n            max_reqs: max number of requests. 0 means unlimited.\n\n        Returns:\n            outgoing requests. A list of Message.\n        \"\"\"\n        with self.client_lock:\n            client = self.clients.get(client_token)\n\n        if client:\n            return client.get_outgoing_requests(max_reqs)\n        else:\n            return []\n\n    def stop(self):\n        super().stop()\n        self.sai.close()",
  "def __init__(self, req: Message):\n        self.req = req\n        self.reply = None\n        self.reply_time = None",
  "def __init__(self, token):\n        self.token = token\n        self.last_heard_time = None\n        self.outgoing_reqs = []\n        self.fnf_reqs = []  # fire-and-forget requests\n        self.waiters = {}  # ref => waiter\n        self.req_lock = threading.Lock()\n        self.waiter_lock = threading.Lock()",
  "def send(self, req: Message):\n        waiter = _Waiter(req)\n        with self.req_lock:\n            self.outgoing_reqs.append(req)\n\n        with self.waiter_lock:\n            self.waiters[req.id] = waiter\n\n        return waiter",
  "def fire_and_forget(self, reqs: [Message]):\n        with self.req_lock:\n            for r in reqs:\n                self.fnf_reqs.append(r)",
  "def get_outgoing_requests(self, max_num_reqs=0) -> [Message]:\n        result = []\n        with self.req_lock:\n            # reqs in outgoing_reqs have higher priority\n            q = self.outgoing_reqs\n            if len(self.outgoing_reqs) <= 0:\n                # no regular reqs - take fire-and-forget reqs\n                q = self.fnf_reqs\n\n            if max_num_reqs <= 0:\n                num_reqs = len(q)\n            else:\n                num_reqs = min(max_num_reqs, len(q))\n\n            for i in range(num_reqs):\n                result.append(q.pop(0))\n\n        return result",
  "def accept_reply(self, reply: Message):\n        self.last_heard_time = time.time()\n        ref_id = reply.get_ref_id()\n        with self.waiter_lock:\n            w = self.waiters.pop(ref_id, None)\n\n        if w:\n            w.reply = reply\n            w.reply_time = time.time()",
  "def cancel_waiter(self, waiter: _Waiter):\n        req = waiter.req\n        with self.waiter_lock:\n            waiter = self.waiters.pop(req.id, None)\n\n        if waiter:\n            with self.req_lock:\n                if req in self.outgoing_reqs:\n                    self.outgoing_reqs.remove(req)",
  "def __init__(self, client_token: str, req: Message, reply: Message):\n        \"\"\"Client reply.\n\n        Args:\n            client_token (str): client token\n            req (Message): request\n            reply (Message): reply\n        \"\"\"\n        self.client_token = client_token\n        self.request = req\n        self.reply = reply",
  "def __init__(self, client, req: Message):\n        self.client = client\n        self.req = req\n        self.waiter = None",
  "def __init__(\n        self,\n        fed_admin_interface,\n        users,\n        cmd_modules,\n        file_upload_dir,\n        file_download_dir,\n        allowed_shell_cmds,\n        host,\n        port,\n        ca_cert_file_name,\n        server_cert_file_name,\n        server_key_file_name,\n        accepted_client_cns=None,\n        app_validator=None,\n        download_job_url=None,\n    ):\n        \"\"\"The FedAdminServer is the framework for developing admin commands.\n\n        Args:\n            fed_admin_interface: the server's federated admin interface\n            users: a dict of {username: pwd hash}\n            cmd_modules: a list of CommandModules\n            file_upload_dir: the directory for uploaded files\n            file_download_dir: the directory for files to be downloaded\n            allowed_shell_cmds: list of shell commands allowed. If not specified, all allowed.\n            host: the IP address of the admin server\n            port: port number of admin server\n            ca_cert_file_name: the root CA's cert file name\n            server_cert_file_name: server's cert, signed by the CA\n            server_key_file_name: server's private key file\n            accepted_client_cns: list of accepted Common Names from client, if specified\n            app_validator: Application folder validator.\n        \"\"\"\n        cmd_reg = new_command_register_with_builtin_module(app_ctx=fed_admin_interface)\n        self.sai = fed_admin_interface\n        self.allowed_shell_cmds = allowed_shell_cmds\n\n        authenticator = SimpleAuthenticator(users)\n        sess_mgr = SessionManager()\n        login_module = LoginModule(authenticator, sess_mgr)\n        cmd_reg.register_module(login_module)\n\n        # register filters - order is important!\n        # login_module is also a filter that determines if user is authenticated\n        cmd_reg.add_filter(login_module)\n\n        # next is the authorization filter and command module\n        authorizer = AuthorizationService.get_authorizer()\n        authz_filter = AuthzFilter(authorizer=authorizer)\n        cmd_reg.add_filter(authz_filter)\n        authz_cmd_module = AuthzCommandModule(authorizer=authorizer)\n        cmd_reg.register_module(authz_cmd_module)\n\n        # audit filter records commands to audit trail\n        auditor = AuditService.get_auditor()\n        # TODO:: clean this up\n        if not isinstance(auditor, Auditor):\n            raise TypeError(\"auditor must be Auditor but got {}\".format(type(auditor)))\n        audit_filter = CommandAudit(auditor)\n        cmd_reg.add_filter(audit_filter)\n\n        self.file_upload_dir = file_upload_dir\n        self.file_download_dir = file_download_dir\n\n        AppAuthzService.initialize(app_validator)\n        cmd_reg.register_module(\n            FileTransferModule(\n                upload_dir=file_upload_dir,\n                download_dir=file_download_dir,\n                upload_folder_authz_func=AppAuthzService.authorize_upload,\n                download_job_url=download_job_url,\n            )\n        )\n\n        cmd_reg.register_module(sess_mgr)\n\n        if cmd_modules:\n            if not isinstance(cmd_modules, list):\n                raise TypeError(\"cmd_modules must be list but got {}\".format(type(cmd_modules)))\n\n            for m in cmd_modules:\n                if not isinstance(m, CommandModule):\n                    raise TypeError(\"cmd_modules must contain CommandModule but got element of type {}\".format(type(m)))\n                cmd_reg.register_module(m)\n\n        AdminServer.__init__(\n            self,\n            cmd_reg=cmd_reg,\n            host=host,\n            port=port,\n            ca_cert=ca_cert_file_name,\n            server_cert=server_cert_file_name,\n            server_key=server_key_file_name,\n            accepted_client_cns=accepted_client_cns,\n        )\n\n        self.clients = {}  # token => _Client\n        self.client_lock = threading.Lock()\n        self.timeout = 10.0",
  "def client_heartbeat(self, token):\n        \"\"\"Receive client heartbeat.\n\n        Args:\n            token: the session token of the client\n\n        Returns:\n            Client.\n        \"\"\"\n        with self.client_lock:\n            client = self.clients.get(token)\n            if not client:\n                client = _Client(token)\n                self.clients[token] = client\n            client.last_heard_time = time.time()\n            return client",
  "def client_dead(self, token):\n        \"\"\"Remove dead client.\n\n        Args:\n            token: the session token of the client\n        \"\"\"\n        with self.client_lock:\n            self.clients.pop(token, None)",
  "def get_client_tokens(self) -> []:\n        \"\"\"Get tokens of existing clients.\"\"\"\n        result = []\n        with self.client_lock:\n            for token in self.clients.keys():\n                result.append(token)\n        return result",
  "def send_request_to_client(self, req: Message, client_token: str, timeout_secs=2.0) -> ClientReply:\n        if not isinstance(req, Message):\n            raise TypeError(\"request must be Message but got {}\".format(type(req)))\n        reqs = {client_token: req}\n        replies = self.send_requests(reqs, timeout_secs)\n        if replies is None or len(replies) <= 0:\n            return None\n        else:\n            return replies[0]",
  "def send_request_to_clients(self, req: Message, client_tokens: [str], timeout_secs=2.0) -> [ClientReply]:\n        if not isinstance(req, Message):\n            raise TypeError(\"request must be Message but got {}\".format(type(req)))\n        reqs = {}\n        for token in client_tokens:\n            reqs[token] = req\n\n        return self.send_requests(reqs, timeout_secs)",
  "def send_requests(self, requests: dict, timeout_secs=2.0) -> [ClientReply]:\n        \"\"\"Send requests to clients.\n\n        NOTE::\n\n            This method is to be used by a Command Handler to send requests to Clients.\n            Hence, it is run in the Command Handler's handling thread.\n            This is a blocking call - returned only after all responses are received or timeout.\n\n        Args:\n            requests: A dict of requests: {client token: request or list of requests}\n            timeout_secs: how long to wait for reply before timeout\n\n        Returns:\n            A list of ClientReply\n        \"\"\"\n\n        if not isinstance(requests, dict):\n            raise TypeError(\"requests must be a dict but got {}\".format(type(requests)))\n\n        if len(requests) <= 0:\n            return []\n\n        if timeout_secs <= 0.0:\n            # this is fire-and-forget!\n            for token, r in requests.items():\n                client = self.clients.get(token)\n                if not client:\n                    continue\n\n                if isinstance(r, list):\n                    reqs = r\n                else:\n                    reqs = [r]\n\n                client.fire_and_forget(reqs)\n            # No replies\n            return []\n\n        # Regular requests\n        client_reqs = []\n        with self.client_lock:\n            for token, r in requests.items():\n                client = self.clients.get(token)\n                if not client:\n                    continue\n\n                if isinstance(r, list):\n                    reqs = r\n                else:\n                    reqs = [r]\n\n                for req in reqs:\n                    if not isinstance(req, Message):\n                        raise TypeError(\"request must be a Message but got {}\".format(type(req)))\n                    client_reqs.append(_ClientReq(client, req))\n\n        return self._send_client_reqs(client_reqs, timeout_secs)",
  "def _send_client_reqs(self, client_reqs, timeout_secs) -> [ClientReply]:\n        result = []\n        if len(client_reqs) <= 0:\n            return result\n\n        for cr in client_reqs:\n            cr.waiter = cr.client.send(cr.req)\n\n        start_time = time.time()\n        while True:\n            all_received = True\n            for cr in client_reqs:\n                if cr.waiter.reply_time is None:\n                    all_received = False\n                    break\n\n            if all_received:\n                break\n\n            if time.time() - start_time > timeout_secs:\n                # timeout\n                break\n\n            time.sleep(0.1)\n\n        for cr in client_reqs:\n            result.append(ClientReply(client_token=cr.client.token, req=cr.waiter.req, reply=cr.waiter.reply))\n\n            if cr.waiter.reply_time is None:\n                # this client timed out\n                cr.client.cancel_waiter(cr.waiter)\n\n        return result",
  "def accept_reply(self, client_token, reply: Message):\n        \"\"\"Accept client reply.\n\n        NOTE::\n            This method is to be called by the FL Engine after a client's reply is received.\n            Hence, it is called from the FL Engine's message processing thread.\n\n        Args:\n            client_token: session token of the client\n            reply: the reply message\n        \"\"\"\n        client = self.client_heartbeat(client_token)\n\n        ref_id = reply.get_ref_id()\n        assert ref_id is not None, \"protocol error: missing ref_id in reply from client {}\".format(client_token)\n\n        client.accept_reply(reply)",
  "def get_outgoing_requests(self, client_token, max_reqs=0):\n        \"\"\"Get outgoing request from a client.\n\n        NOTE::\n            This method is called by FL Engine to get outgoing messages to the client, so it\n            can send them to the client.\n\n        Args:\n            client_token: session token of the client\n            max_reqs: max number of requests. 0 means unlimited.\n\n        Returns:\n            outgoing requests. A list of Message.\n        \"\"\"\n        with self.client_lock:\n            client = self.clients.get(client_token)\n\n        if client:\n            return client.get_outgoing_requests(max_reqs)\n        else:\n            return []",
  "def stop(self):\n        super().stop()\n        self.sai.close()",
  "class JobMetaValidator:\n    \"\"\"Job validator\"\"\"\n\n    def validate(self, job_name: str, job_data: bytes) -> Tuple[bool, str, dict]:\n        \"\"\"Validate job\n\n        Args:\n            job_name (str): Job name\n            job_data (bytes): Job ZIP data\n\n        Returns:\n            Tuple[bool, str, dict]: (is_valid, error_message, meta)\n        \"\"\"\n\n        meta = {}\n        try:\n            with ZipFile(BytesIO(job_data), \"r\") as zf:\n                meta = self._validate_meta(job_name, zf)\n                site_list = self._validate_deploy_map(job_name, meta)\n                self._validate_app(job_name, meta, zf)\n                clients = self._get_all_clients(site_list)\n                self._validate_min_clients(job_name, meta, clients)\n                self._validate_resource(job_name, meta)\n                self._validate_mandatory_clients(job_name, meta, clients)\n\n        except ValueError as e:\n            return False, str(e), meta\n\n        return True, \"\", meta\n\n    @staticmethod\n    def _validate_meta(job_name: str, zf: ZipFile) -> Optional[dict]:\n        meta_file = f\"{job_name}/{META}\"\n        logger.debug(f\"validate file {meta_file} exists for job {job_name}\")\n        meta = None\n\n        if meta_file in zf.namelist():\n            meta_data = zf.read(meta_file)\n            meta = json.loads(meta_data)\n        return meta\n\n    @staticmethod\n    def _validate_deploy_map(job_name: str, meta: dict) -> list:\n\n        if not meta:\n            raise ValueError(f\"meta.json is empty for job {job_name}\")\n\n        deploy_map = meta.get(JobMetaKey.DEPLOY_MAP.value)\n        if not deploy_map:\n            raise ValueError(f\"deploy_map is empty for job {job_name}\")\n\n        site_list = [site for deployments in deploy_map.values() for site in deployments]\n        if not site_list:\n            raise ValueError(f\"No site is specified in deploy_map for job {job_name}\")\n\n        if ALL_SITES.casefold() in (site.casefold() for site in site_list):\n            # if ALL_SITES is specified, no other site can be in the list\n            if len(site_list) > 1:\n                raise ValueError(f\"No other site can be specified if {ALL_SITES} is used for job {job_name}\")\n            else:\n                site_list = [ALL_SITES]\n        else:\n            duplicates = [site for site, count in collections.Counter(site_list).items() if count > 1]\n            if duplicates:\n                raise ValueError(f\"Multiple apps to be deployed to following sites {duplicates} for job {job_name}\")\n\n        return site_list\n\n    def _validate_app(self, job_name: str, meta: dict, zip_file: ZipFile) -> None:\n\n        deploy_map = meta.get(JobMetaKey.DEPLOY_MAP.value)\n\n        for app, deployments in deploy_map.items():\n\n            zip_folder = job_name + \"/\" + app + \"/config/\"\n            if not self._entry_exists(zip_file, zip_folder):\n                logger.debug(f\"zip folder {zip_folder} missing. Files in the zip:\")\n                for x in zip_file.namelist():\n                    logger.debug(f\"    {x}\")\n                raise ValueError(f\"App {app} in deploy_map doesn't exist for job {job_name}\")\n\n            all_sites = ALL_SITES.casefold() in (site.casefold() for site in deployments)\n\n            if (all_sites or \"server\" in deployments) and not self._entry_exists(zip_file, zip_folder + SERVER_CONFIG):\n                raise ValueError(f\"App {app} is will be deployed to server but server config is missing\")\n\n            if (all_sites or [client for client in deployments if client != \"server\"]) and not self._entry_exists(\n                zip_file, zip_folder + CLIENT_CONFIG\n            ):\n                raise ValueError(f\"App {app} will be deployed to client but client config is missing\")\n\n    @staticmethod\n    def _convert_value_to_int(v) -> int:\n        if isinstance(v, int):\n            return v\n        else:\n            try:\n                v = int(v)\n                return v\n            except ValueError as e:\n                raise ValueError(f\"invalid data type for {v},can't not convert to Int\", e)\n            except TypeError as e:\n                raise ValueError(f\"invalid data type for {v},can't not convert to Int\", e)\n\n    def _validate_min_clients(self, job_name: str, meta: dict, clients: set) -> None:\n        logger.debug(f\"validate min_clients for job {job_name}\")\n\n        value = meta.get(JobMetaKey.MIN_CLIENTS)\n        if value is not None:\n            min_clients = self._convert_value_to_int(value)\n            if min_clients <= 0:\n                raise ValueError(f\"min_clients {min_clients} must be positive for job {job_name}\")\n            elif min_clients > MAX_CLIENTS:\n                raise ValueError(f\"min_clients {min_clients} must be less than {MAX_CLIENTS}  for job {job_name}\")\n\n            if next(iter(clients)) != ALL_SITES and len(clients) < min_clients:\n                raise ValueError(f\"min {min_clients} clients required for job {job_name}, found {len(clients)}.\")\n\n    @staticmethod\n    def _validate_mandatory_clients(job_name: str, meta: dict, clients: set) -> None:\n        logger.debug(f\" validate mandatory_clients for job {job_name}\")\n\n        if next(iter(clients)) != ALL_SITES:\n            # Validating mandatory clients are deployed\n            mandatory_clients = meta.get(JobMetaKey.MANDATORY_CLIENTS)\n            if mandatory_clients:\n                mandatory_set = set(mandatory_clients)\n                if not mandatory_set.issubset(clients):\n                    diff = mandatory_set - clients\n                    raise ValueError(f\"Mandatory clients {diff} are not in the deploy_map for job {job_name}\")\n\n    @staticmethod\n    def _validate_resource(job_name: str, meta: dict) -> None:\n        logger.debug(f\"validate resource for job {job_name}\")\n\n        resource_spec = meta.get(JobMetaKey.RESOURCE_SPEC.value)\n        if resource_spec and not isinstance(resource_spec, dict):\n            raise ValueError(f\"Invalid resource_spec for job {job_name}\")\n\n        if not resource_spec:\n            logger.debug(\"empty resource spec provided\")\n\n        if resource_spec:\n            for k in resource_spec:\n                if resource_spec[k] and not isinstance(resource_spec[k], dict):\n                    raise ValueError(f\"value for key {k} in resource spec is expecting a dictionary\")\n\n    @staticmethod\n    def _get_all_clients(site_list: Optional[list]) -> Set[str]:\n\n        if site_list[0] == ALL_SITES:\n            return {ALL_SITES}\n\n        return set([site for site in site_list if site != \"server\"])\n\n    @staticmethod\n    def _entry_exists(zip_file: ZipFile, path: str) -> bool:\n        try:\n            zip_file.getinfo(path)\n            return True\n        except KeyError:\n            return False",
  "def validate(self, job_name: str, job_data: bytes) -> Tuple[bool, str, dict]:\n        \"\"\"Validate job\n\n        Args:\n            job_name (str): Job name\n            job_data (bytes): Job ZIP data\n\n        Returns:\n            Tuple[bool, str, dict]: (is_valid, error_message, meta)\n        \"\"\"\n\n        meta = {}\n        try:\n            with ZipFile(BytesIO(job_data), \"r\") as zf:\n                meta = self._validate_meta(job_name, zf)\n                site_list = self._validate_deploy_map(job_name, meta)\n                self._validate_app(job_name, meta, zf)\n                clients = self._get_all_clients(site_list)\n                self._validate_min_clients(job_name, meta, clients)\n                self._validate_resource(job_name, meta)\n                self._validate_mandatory_clients(job_name, meta, clients)\n\n        except ValueError as e:\n            return False, str(e), meta\n\n        return True, \"\", meta",
  "def _validate_meta(job_name: str, zf: ZipFile) -> Optional[dict]:\n        meta_file = f\"{job_name}/{META}\"\n        logger.debug(f\"validate file {meta_file} exists for job {job_name}\")\n        meta = None\n\n        if meta_file in zf.namelist():\n            meta_data = zf.read(meta_file)\n            meta = json.loads(meta_data)\n        return meta",
  "def _validate_deploy_map(job_name: str, meta: dict) -> list:\n\n        if not meta:\n            raise ValueError(f\"meta.json is empty for job {job_name}\")\n\n        deploy_map = meta.get(JobMetaKey.DEPLOY_MAP.value)\n        if not deploy_map:\n            raise ValueError(f\"deploy_map is empty for job {job_name}\")\n\n        site_list = [site for deployments in deploy_map.values() for site in deployments]\n        if not site_list:\n            raise ValueError(f\"No site is specified in deploy_map for job {job_name}\")\n\n        if ALL_SITES.casefold() in (site.casefold() for site in site_list):\n            # if ALL_SITES is specified, no other site can be in the list\n            if len(site_list) > 1:\n                raise ValueError(f\"No other site can be specified if {ALL_SITES} is used for job {job_name}\")\n            else:\n                site_list = [ALL_SITES]\n        else:\n            duplicates = [site for site, count in collections.Counter(site_list).items() if count > 1]\n            if duplicates:\n                raise ValueError(f\"Multiple apps to be deployed to following sites {duplicates} for job {job_name}\")\n\n        return site_list",
  "def _validate_app(self, job_name: str, meta: dict, zip_file: ZipFile) -> None:\n\n        deploy_map = meta.get(JobMetaKey.DEPLOY_MAP.value)\n\n        for app, deployments in deploy_map.items():\n\n            zip_folder = job_name + \"/\" + app + \"/config/\"\n            if not self._entry_exists(zip_file, zip_folder):\n                logger.debug(f\"zip folder {zip_folder} missing. Files in the zip:\")\n                for x in zip_file.namelist():\n                    logger.debug(f\"    {x}\")\n                raise ValueError(f\"App {app} in deploy_map doesn't exist for job {job_name}\")\n\n            all_sites = ALL_SITES.casefold() in (site.casefold() for site in deployments)\n\n            if (all_sites or \"server\" in deployments) and not self._entry_exists(zip_file, zip_folder + SERVER_CONFIG):\n                raise ValueError(f\"App {app} is will be deployed to server but server config is missing\")\n\n            if (all_sites or [client for client in deployments if client != \"server\"]) and not self._entry_exists(\n                zip_file, zip_folder + CLIENT_CONFIG\n            ):\n                raise ValueError(f\"App {app} will be deployed to client but client config is missing\")",
  "def _convert_value_to_int(v) -> int:\n        if isinstance(v, int):\n            return v\n        else:\n            try:\n                v = int(v)\n                return v\n            except ValueError as e:\n                raise ValueError(f\"invalid data type for {v},can't not convert to Int\", e)\n            except TypeError as e:\n                raise ValueError(f\"invalid data type for {v},can't not convert to Int\", e)",
  "def _validate_min_clients(self, job_name: str, meta: dict, clients: set) -> None:\n        logger.debug(f\"validate min_clients for job {job_name}\")\n\n        value = meta.get(JobMetaKey.MIN_CLIENTS)\n        if value is not None:\n            min_clients = self._convert_value_to_int(value)\n            if min_clients <= 0:\n                raise ValueError(f\"min_clients {min_clients} must be positive for job {job_name}\")\n            elif min_clients > MAX_CLIENTS:\n                raise ValueError(f\"min_clients {min_clients} must be less than {MAX_CLIENTS}  for job {job_name}\")\n\n            if next(iter(clients)) != ALL_SITES and len(clients) < min_clients:\n                raise ValueError(f\"min {min_clients} clients required for job {job_name}, found {len(clients)}.\")",
  "def _validate_mandatory_clients(job_name: str, meta: dict, clients: set) -> None:\n        logger.debug(f\" validate mandatory_clients for job {job_name}\")\n\n        if next(iter(clients)) != ALL_SITES:\n            # Validating mandatory clients are deployed\n            mandatory_clients = meta.get(JobMetaKey.MANDATORY_CLIENTS)\n            if mandatory_clients:\n                mandatory_set = set(mandatory_clients)\n                if not mandatory_set.issubset(clients):\n                    diff = mandatory_set - clients\n                    raise ValueError(f\"Mandatory clients {diff} are not in the deploy_map for job {job_name}\")",
  "def _validate_resource(job_name: str, meta: dict) -> None:\n        logger.debug(f\"validate resource for job {job_name}\")\n\n        resource_spec = meta.get(JobMetaKey.RESOURCE_SPEC.value)\n        if resource_spec and not isinstance(resource_spec, dict):\n            raise ValueError(f\"Invalid resource_spec for job {job_name}\")\n\n        if not resource_spec:\n            logger.debug(\"empty resource spec provided\")\n\n        if resource_spec:\n            for k in resource_spec:\n                if resource_spec[k] and not isinstance(resource_spec[k], dict):\n                    raise ValueError(f\"value for key {k} in resource spec is expecting a dictionary\")",
  "def _get_all_clients(site_list: Optional[list]) -> Set[str]:\n\n        if site_list[0] == ALL_SITES:\n            return {ALL_SITES}\n\n        return set([site for site in site_list if site != \"server\"])",
  "def _entry_exists(zip_file: ZipFile, path: str) -> bool:\n        try:\n            zip_file.getinfo(path)\n            return True\n        except KeyError:\n            return False",
  "class ServerCommandAgent(object):\n    def __init__(self, listen_port) -> None:\n        \"\"\"To init the CommandAgent.\n\n        Args:\n            listen_port: port to listen the command\n        \"\"\"\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.listen_port = int(listen_port)\n        self.thread = None\n        self.asked_to_stop = False\n\n        self.commands = ServerCommands.commands\n\n    def start(self, engine):\n        self.thread = threading.Thread(\n            target=listen_command, args=[self.listen_port, engine, self.execute_command, self.logger]\n        )\n        self.thread.start()\n        self.logger.info(f\"ServerCommandAgent listening on port: {self.listen_port}\")\n\n    def execute_command(self, conn, engine):\n        while not self.asked_to_stop:\n            try:\n                if conn.poll(1.0):\n                    msg = conn.recv()\n                    msg = pickle.loads(msg)\n                    command_name = msg.get(ServerCommandKey.COMMAND)\n                    data = msg.get(ServerCommandKey.DATA)\n                    command = ServerCommands.get_command(command_name)\n                    if command:\n                        with engine.new_context() as new_fl_ctx:\n                            reply = command.process(data=data, fl_ctx=new_fl_ctx)\n                            if reply:\n                                conn.send(reply)\n            except EOFError:\n                self.logger.info(\"listener communication terminated.\")\n                break\n            except Exception as e:\n                self.logger.error(f\"IPC Communication error on the port: {self.listen_port}: {e}.\", exc_info=False)\n\n    def shutdown(self):\n        self.asked_to_stop = True\n\n        if self.thread and self.thread.is_alive():\n            self.thread.join()",
  "def __init__(self, listen_port) -> None:\n        \"\"\"To init the CommandAgent.\n\n        Args:\n            listen_port: port to listen the command\n        \"\"\"\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.listen_port = int(listen_port)\n        self.thread = None\n        self.asked_to_stop = False\n\n        self.commands = ServerCommands.commands",
  "def start(self, engine):\n        self.thread = threading.Thread(\n            target=listen_command, args=[self.listen_port, engine, self.execute_command, self.logger]\n        )\n        self.thread.start()\n        self.logger.info(f\"ServerCommandAgent listening on port: {self.listen_port}\")",
  "def execute_command(self, conn, engine):\n        while not self.asked_to_stop:\n            try:\n                if conn.poll(1.0):\n                    msg = conn.recv()\n                    msg = pickle.loads(msg)\n                    command_name = msg.get(ServerCommandKey.COMMAND)\n                    data = msg.get(ServerCommandKey.DATA)\n                    command = ServerCommands.get_command(command_name)\n                    if command:\n                        with engine.new_context() as new_fl_ctx:\n                            reply = command.process(data=data, fl_ctx=new_fl_ctx)\n                            if reply:\n                                conn.send(reply)\n            except EOFError:\n                self.logger.info(\"listener communication terminated.\")\n                break\n            except Exception as e:\n                self.logger.error(f\"IPC Communication error on the port: {self.listen_port}: {e}.\", exc_info=False)",
  "def shutdown(self):\n        self.asked_to_stop = True\n\n        if self.thread and self.thread.is_alive():\n            self.thread.join()",
  "class EngineInfo(object):\n    def __init__(self):\n        \"\"\"Engine information.\"\"\"\n        self.start_time = time.time()\n        self.status = MachineStatus.STOPPED\n\n        self.app_names = {}",
  "class ServerEngineInternalSpec(ServerEngineSpec, ABC):\n    def get_engine_info(self) -> EngineInfo:\n        \"\"\"Get general info of the engine.\"\"\"\n        pass\n\n    def get_run_info(self) -> RunInfo:\n        pass\n\n    @abstractmethod\n    def get_staging_path_of_app(self, app_name: str) -> str:\n        \"\"\"Get the staging path of the app waiting to be deployed.\n\n        Args:\n            app_name (str): application name\n\n        Returns:\n            The app's folder path or empty string if the app doesn't exist\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def deploy_app_to_server(self, job_id: str, app_name: str, app_staging_path: str) -> str:\n        \"\"\"Deploy the specified app to the server.\n\n        Copy the app folder tree from staging area to the server's RUN area\n\n        Args:\n            job_id: job id of the app to be deployed\n            app_name: name of the app to be deployed\n            app_staging_path: the full path to the app folder in staging area\n\n        Returns:\n            An error message. An empty string if successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_app_data(self, app_name: str) -> (str, object):\n        \"\"\"Get data for deploying the app.\n\n        Args:\n            app_name: name of the app\n\n        Returns:\n            An error message. An empty string if successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_app_run_info(self, job_id) -> RunInfo:\n        \"\"\"Get the app RunInfo from the child process.\n\n        Returns:\n            App RunInfo\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_job_id(self, job_id: str) -> str:\n        \"\"\"Delete specified RUN.\n\n        The Engine must do status check before the run can be deleted.\n        Args:\n            job_id: job id\n\n        Returns:\n            An error message. An empty string if successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def start_app_on_server(self, job_idber: str, job_id: str = None, job_clients=None, snapshot=None) -> str:\n        \"\"\"Start the FL app on Server.\n\n        Returns:\n            An error message. An empty string if successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def check_app_start_readiness(self, job_id: str) -> str:\n        \"\"\"Check whether the app is ready to start.\n\n        Returns:\n            An error message. An empty string if successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def abort_app_on_clients(self, clients: [str]):\n        \"\"\"Abort the application on the specified clients.\"\"\"\n        pass\n\n    @abstractmethod\n    def abort_app_on_server(self, job_id: str):\n        \"\"\"Abort the application on the server.\"\"\"\n        pass\n\n    @abstractmethod\n    def shutdown_server(self) -> str:\n        \"\"\"Shutdown the server.\n\n        The engine should not exit right away.\n        It should set its status to STOPPING, and set up a timer (in a different thread),\n        and return from this call right away (if other restart conditions are met).\n        When the timer fires, it exits.\n        This would give the caller to process the feedback or clean up (e.g. admin cmd response).\n\n        Returns:\n            An error message. An empty string if successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def remove_clients(self, clients: [str]) -> str:\n        \"\"\"Remove specified clients.\n\n        Args:\n            clients: clients to be removed\n\n        Returns:\n             An error message. An empty string if successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def restart_server(self) -> str:\n        \"\"\"Restart the server.\n\n        The engine should not exit right away.\n        See shutdown_server.\n\n        Returns:\n             An error message. An empty string if successful.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def set_run_manager(self, run_manager: RunManager):\n        \"\"\"Set the RunManager for server.\n\n        Args:\n            run_manager: A RunManager object\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def set_job_runner(self, job_runner: JobRunner, job_manager: JobDefManagerSpec):\n        \"\"\"Set the JobRunner for server.\n\n        Args:\n            job_runner: A JobRunner object\n            job_manager: A JobDefManagerSpec object\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def set_configurator(self, conf: ServerJsonConfigurator):\n        \"\"\"Set the configurator for server.\n\n        Args:\n            conf: A ServerJsonConfigurator object\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def build_component(self, config_dict):\n        \"\"\"Build a component from the config_dict.\n\n        Args:\n            config_dict: configuration.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_client_name_from_token(self, token: str) -> str:\n        \"\"\"Get the registered client name from communication token.\n\n        Args:\n            token: communication token\n\n        Returns:\n            Client name\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_client_from_name(self, client_name: str) -> Client:\n        \"\"\"Get the registered client token from client_name.\n\n        Args:\n            client_name: client name\n\n        Returns: registered client\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_job_clients(self, client_sites) -> {}:\n        \"\"\"To get the participating clients for the job\n\n        Args:\n            client_sites: clients with the dispatching info\n\n        Returns:\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def ask_to_stop(self):\n        \"\"\"Ask the engine to stop the current run.\"\"\"\n        pass\n\n    @abstractmethod\n    def aux_send(self, targets: [], topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> dict:\n        \"\"\"Send a request to client(s) via the auxiliary channel.\n\n        Args:\n            targets: list of Client or client names\n            topic: topic of the request\n            request: request to be sent\n            timeout: number of secs to wait for replies\n            fl_ctx: FL context\n\n        Returns:\n             A dict of replies: client_name => Shareable\n\n        NOTE: when a reply is received, the peer_ctx props must be set into the PEER_PROPS header\n        of the reply Shareable.\n\n        If a reply is not received from a client, do not put it into the reply dict.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def show_stats(self, job_id):\n        \"\"\"Show_stats of the server.\n\n        Args:\n            job_id: current job_id\n\n        Returns:\n            Component stats of the server\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_errors(self, job_id):\n        \"\"\"Get the errors of the server components.\n\n        Args:\n            job_id: current job_id\n\n        Returns:\n            Server components errors.\n\n        \"\"\"\n        pass",
  "def __init__(self):\n        \"\"\"Engine information.\"\"\"\n        self.start_time = time.time()\n        self.status = MachineStatus.STOPPED\n\n        self.app_names = {}",
  "def get_engine_info(self) -> EngineInfo:\n        \"\"\"Get general info of the engine.\"\"\"\n        pass",
  "def get_run_info(self) -> RunInfo:\n        pass",
  "def get_staging_path_of_app(self, app_name: str) -> str:\n        \"\"\"Get the staging path of the app waiting to be deployed.\n\n        Args:\n            app_name (str): application name\n\n        Returns:\n            The app's folder path or empty string if the app doesn't exist\n        \"\"\"\n        pass",
  "def deploy_app_to_server(self, job_id: str, app_name: str, app_staging_path: str) -> str:\n        \"\"\"Deploy the specified app to the server.\n\n        Copy the app folder tree from staging area to the server's RUN area\n\n        Args:\n            job_id: job id of the app to be deployed\n            app_name: name of the app to be deployed\n            app_staging_path: the full path to the app folder in staging area\n\n        Returns:\n            An error message. An empty string if successful.\n        \"\"\"\n        pass",
  "def get_app_data(self, app_name: str) -> (str, object):\n        \"\"\"Get data for deploying the app.\n\n        Args:\n            app_name: name of the app\n\n        Returns:\n            An error message. An empty string if successful.\n        \"\"\"\n        pass",
  "def get_app_run_info(self, job_id) -> RunInfo:\n        \"\"\"Get the app RunInfo from the child process.\n\n        Returns:\n            App RunInfo\n\n        \"\"\"\n        pass",
  "def delete_job_id(self, job_id: str) -> str:\n        \"\"\"Delete specified RUN.\n\n        The Engine must do status check before the run can be deleted.\n        Args:\n            job_id: job id\n\n        Returns:\n            An error message. An empty string if successful.\n        \"\"\"\n        pass",
  "def start_app_on_server(self, job_idber: str, job_id: str = None, job_clients=None, snapshot=None) -> str:\n        \"\"\"Start the FL app on Server.\n\n        Returns:\n            An error message. An empty string if successful.\n        \"\"\"\n        pass",
  "def check_app_start_readiness(self, job_id: str) -> str:\n        \"\"\"Check whether the app is ready to start.\n\n        Returns:\n            An error message. An empty string if successful.\n        \"\"\"\n        pass",
  "def abort_app_on_clients(self, clients: [str]):\n        \"\"\"Abort the application on the specified clients.\"\"\"\n        pass",
  "def abort_app_on_server(self, job_id: str):\n        \"\"\"Abort the application on the server.\"\"\"\n        pass",
  "def shutdown_server(self) -> str:\n        \"\"\"Shutdown the server.\n\n        The engine should not exit right away.\n        It should set its status to STOPPING, and set up a timer (in a different thread),\n        and return from this call right away (if other restart conditions are met).\n        When the timer fires, it exits.\n        This would give the caller to process the feedback or clean up (e.g. admin cmd response).\n\n        Returns:\n            An error message. An empty string if successful.\n        \"\"\"\n        pass",
  "def remove_clients(self, clients: [str]) -> str:\n        \"\"\"Remove specified clients.\n\n        Args:\n            clients: clients to be removed\n\n        Returns:\n             An error message. An empty string if successful.\n        \"\"\"\n        pass",
  "def restart_server(self) -> str:\n        \"\"\"Restart the server.\n\n        The engine should not exit right away.\n        See shutdown_server.\n\n        Returns:\n             An error message. An empty string if successful.\n        \"\"\"\n        pass",
  "def set_run_manager(self, run_manager: RunManager):\n        \"\"\"Set the RunManager for server.\n\n        Args:\n            run_manager: A RunManager object\n        \"\"\"\n        pass",
  "def set_job_runner(self, job_runner: JobRunner, job_manager: JobDefManagerSpec):\n        \"\"\"Set the JobRunner for server.\n\n        Args:\n            job_runner: A JobRunner object\n            job_manager: A JobDefManagerSpec object\n        \"\"\"\n        pass",
  "def set_configurator(self, conf: ServerJsonConfigurator):\n        \"\"\"Set the configurator for server.\n\n        Args:\n            conf: A ServerJsonConfigurator object\n        \"\"\"\n        pass",
  "def build_component(self, config_dict):\n        \"\"\"Build a component from the config_dict.\n\n        Args:\n            config_dict: configuration.\n        \"\"\"\n        pass",
  "def get_client_name_from_token(self, token: str) -> str:\n        \"\"\"Get the registered client name from communication token.\n\n        Args:\n            token: communication token\n\n        Returns:\n            Client name\n        \"\"\"\n        pass",
  "def get_client_from_name(self, client_name: str) -> Client:\n        \"\"\"Get the registered client token from client_name.\n\n        Args:\n            client_name: client name\n\n        Returns: registered client\n\n        \"\"\"\n        pass",
  "def get_job_clients(self, client_sites) -> {}:\n        \"\"\"To get the participating clients for the job\n\n        Args:\n            client_sites: clients with the dispatching info\n\n        Returns:\n\n        \"\"\"\n        pass",
  "def ask_to_stop(self):\n        \"\"\"Ask the engine to stop the current run.\"\"\"\n        pass",
  "def aux_send(self, targets: [], topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> dict:\n        \"\"\"Send a request to client(s) via the auxiliary channel.\n\n        Args:\n            targets: list of Client or client names\n            topic: topic of the request\n            request: request to be sent\n            timeout: number of secs to wait for replies\n            fl_ctx: FL context\n\n        Returns:\n             A dict of replies: client_name => Shareable\n\n        NOTE: when a reply is received, the peer_ctx props must be set into the PEER_PROPS header\n        of the reply Shareable.\n\n        If a reply is not received from a client, do not put it into the reply dict.\n        \"\"\"\n        pass",
  "def show_stats(self, job_id):\n        \"\"\"Show_stats of the server.\n\n        Args:\n            job_id: current job_id\n\n        Returns:\n            Component stats of the server\n\n        \"\"\"\n        pass",
  "def get_errors(self, job_id):\n        \"\"\"Get the errors of the server components.\n\n        Args:\n            job_id: current job_id\n\n        Returns:\n            Server components errors.\n\n        \"\"\"\n        pass",
  "class ServerRunnerConfig(object):\n    def __init__(\n        self,\n        heartbeat_timeout: int,\n        task_request_interval: int,\n        workflows: [],\n        task_data_filters: dict,\n        task_result_filters: dict,\n        handlers=None,\n        components=None,\n    ):\n        \"\"\"Configuration for ServerRunner.\n\n        Args:\n            heartbeat_timeout (int): Client heartbeat timeout in seconds\n            task_request_interval (int): Task request interval in seconds\n            workflows (list): A list of workflow\n            task_data_filters (dict):  A dict of  {task_name: list of filters apply to data (pre-process)}\n            task_result_filters (dict): A dict of {task_name: list of filters apply to result (post-process)}\n            handlers (list, optional):  A list of event handlers\n            components (dict, optional):  A dict of extra python objects {id: object}\n        \"\"\"\n        self.heartbeat_timeout = heartbeat_timeout\n        self.task_request_interval = task_request_interval\n        self.workflows = workflows\n        self.task_data_filters = task_data_filters\n        self.task_result_filters = task_result_filters\n        self.handlers = handlers\n        self.components = components",
  "class ServerRunner(FLComponent):\n    def __init__(self, config: ServerRunnerConfig, job_id: str, engine: ServerEngineSpec):\n        \"\"\"Server runner class.\n\n        Args:\n            config (ServerRunnerConfig): configuration of server runner\n            job_id (str): The number to distinguish each experiment\n            engine (ServerEngineSpec): server engine\n        \"\"\"\n        FLComponent.__init__(self)\n        self.job_id = job_id\n        self.config = config\n        self.engine = engine\n        self.abort_signal = Signal()\n        self.wf_lock = threading.Lock()\n        self.current_wf = None\n        self.current_wf_index = 0\n        self.status = \"init\"\n\n    def _execute_run(self):\n        while self.current_wf_index < len(self.config.workflows):\n            wf = self.config.workflows[self.current_wf_index]\n            try:\n                with self.engine.new_context() as fl_ctx:\n                    self.log_info(fl_ctx, \"starting workflow {} ({}) ...\".format(wf.id, type(wf.responder)))\n\n                    wf.responder.initialize_run(fl_ctx)\n\n                    self.log_info(fl_ctx, \"Workflow {} ({}) started\".format(wf.id, type(wf.responder)))\n                    fl_ctx.set_prop(FLContextKey.WORKFLOW, wf.id, sticky=True)\n                    self.log_debug(fl_ctx, \"firing event EventType.START_WORKFLOW\")\n                    self.fire_event(EventType.START_WORKFLOW, fl_ctx)\n\n                    # use the wf_lock to ensure state integrity between workflow change and message processing\n                    with self.wf_lock:\n                        # we only set self.current_wf to open for business after successful initialize_run!\n                        self.current_wf = wf\n\n                with self.engine.new_context() as fl_ctx:\n                    wf.responder.control_flow(self.abort_signal, fl_ctx)\n            except WorkflowError as e:\n                with self.engine.new_context() as fl_ctx:\n                    self.log_exception(fl_ctx, f\"Fatal error occurred in workflow {wf.id}: {e}. Aborting the RUN\")\n                self.abort_signal.trigger(True)\n            except BaseException as e:\n                with self.engine.new_context() as fl_ctx:\n                    self.log_exception(fl_ctx, \"Exception in workflow {}: {}\".format(wf.id, e))\n            finally:\n                with self.engine.new_context() as fl_ctx:\n                    # do not execute finalize_run() until the wf_lock is acquired\n                    with self.wf_lock:\n                        # unset current_wf to prevent message processing\n                        # then we can release the lock - no need to delay message processing\n                        # during finalization!\n                        # Note: WF finalization may take time since it needs to wait for\n                        # the job monitor to join.\n                        self.current_wf = None\n\n                    self.log_info(fl_ctx, f\"Workflow: {wf.id} finalizing ...\")\n                    try:\n                        wf.responder.finalize_run(fl_ctx)\n                    except BaseException as e:\n                        self.log_exception(fl_ctx, \"Error finalizing workflow {}: {}\".format(wf.id, e))\n\n                    self.log_debug(fl_ctx, \"firing event EventType.END_WORKFLOW\")\n                    self.fire_event(EventType.END_WORKFLOW, fl_ctx)\n\n                # Stopped the server runner from the current responder, not continue the following responders.\n                if self.abort_signal.triggered:\n                    break\n            self.current_wf_index += 1\n\n    def run(self):\n        with self.engine.new_context() as fl_ctx:\n            self.log_info(fl_ctx, \"Server runner starting ...\")\n\n            self.log_debug(fl_ctx, \"firing event EventType.START_RUN\")\n            fl_ctx.set_prop(ReservedKey.RUN_ABORT_SIGNAL, self.abort_signal, private=True, sticky=True)\n            self.fire_event(EventType.START_RUN, fl_ctx)\n            self.engine.persist_components(fl_ctx, completed=False)\n\n        self.status = \"started\"\n        try:\n            self._execute_run()\n        except BaseException as ex:\n            with self.engine.new_context() as fl_ctx:\n                self.log_exception(fl_ctx, f\"Error executing RUN: {ex}\")\n        finally:\n            # use wf_lock to ensure state of current_wf!\n            self.status = \"done\"\n            with self.wf_lock:\n                with self.engine.new_context() as fl_ctx:\n                    self.fire_event(EventType.ABOUT_TO_END_RUN, fl_ctx)\n                    self.log_info(fl_ctx, \"ABOUT_TO_END_RUN fired\")\n                    self.fire_event(EventType.END_RUN, fl_ctx)\n                    self.log_info(fl_ctx, \"END_RUN fired\")\n                    self.engine.persist_components(fl_ctx, completed=True)\n\n            # ask all clients to end run!\n            self.engine.send_aux_request(\n                targets=None, topic=ReservedTopic.END_RUN, request=Shareable(), timeout=0.0, fl_ctx=fl_ctx\n            )\n\n            self.log_info(fl_ctx, \"Server runner finished.\")\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == InfoCollector.EVENT_TYPE_GET_STATS:\n            collector = fl_ctx.get_prop(InfoCollector.CTX_KEY_STATS_COLLECTOR)\n            if collector:\n                if not isinstance(collector, GroupInfoCollector):\n                    raise TypeError(\"collector must be GroupInfoCollect but got {}\".format(type(collector)))\n\n                with self.wf_lock:\n                    if self.current_wf:\n                        collector.set_info(\n                            group_name=\"ServerRunner\",\n                            info={\"job_id\": self.job_id, \"status\": self.status, \"workflow\": self.current_wf.id},\n                        )\n        elif event_type == EventType.FATAL_SYSTEM_ERROR:\n            reason = fl_ctx.get_prop(key=FLContextKey.EVENT_DATA, default=\"\")\n            self.log_error(fl_ctx, \"Aborting current RUN due to FATAL_SYSTEM_ERROR received: {}\".format(reason))\n            self.abort(fl_ctx)\n\n    def _task_try_again(self) -> (str, str, Shareable):\n        task = Shareable()\n        task[TaskConstant.WAIT_TIME] = self.config.task_request_interval\n        return SpecialTaskName.TRY_AGAIN, \"\", task\n\n    def process_task_request(self, client: Client, fl_ctx: FLContext) -> (str, str, Shareable):\n        \"\"\"Process task request from a client.\n\n        NOTE: the Engine will create a new fl_ctx and call this method:\n\n            with engine.new_context() as fl_ctx:\n                name, id, data = runner.process_task_request(client, fl_ctx)\n                ...\n\n        Args:\n            client (Client): client object\n            fl_ctx (FLContext): FL context\n\n        Returns:\n            A tuple of (task name, task id, and task data)\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ServerEngineSpec):\n            raise TypeError(\"engine must be ServerEngineSpec but got {}\".format(type(engine)))\n\n        self.log_debug(fl_ctx, \"process task request from client\")\n\n        if self.status == \"init\":\n            self.log_debug(fl_ctx, \"server runner still initializing - asked client to try again later\")\n            return self._task_try_again()\n\n        if self.status == \"done\":\n            self.log_info(fl_ctx, \"server runner is finalizing - asked client to end the run\")\n            return SpecialTaskName.END_RUN, \"\", None\n\n        peer_ctx = fl_ctx.get_peer_context()\n        if not isinstance(peer_ctx, FLContext):\n            self.log_debug(fl_ctx, \"invalid task request: no peer context - asked client to try again later\")\n            return self._task_try_again()\n\n        peer_job_id = peer_ctx.get_job_id()\n        if not peer_job_id or peer_job_id != self.job_id:\n            # the client is in a different RUN\n            self.log_info(fl_ctx, \"invalid task request: not the same job_id - asked client to end the run\")\n            return SpecialTaskName.END_RUN, \"\", None\n\n        try:\n            with self.wf_lock:\n                if self.current_wf is None:\n                    self.log_info(fl_ctx, \"no current workflow - asked client to try again later\")\n                    return self._task_try_again()\n\n                task_name, task_id, task_data = self.current_wf.responder.process_task_request(client, fl_ctx)\n\n                if not task_name or task_name == SpecialTaskName.TRY_AGAIN:\n                    self.log_debug(fl_ctx, \"no task currently for client - asked client to try again later\")\n                    return self._task_try_again()\n\n                if task_data:\n                    if not isinstance(task_data, Shareable):\n                        self.log_error(\n                            fl_ctx,\n                            \"bad task data generated by workflow {}: must be Shareable but got {}\".format(\n                                self.current_wf.id, type(task_data)\n                            ),\n                        )\n                        return self._task_try_again()\n                else:\n                    task_data = Shareable()\n\n                task_data.set_header(ReservedHeaderKey.TASK_ID, task_id)\n                task_data.set_header(ReservedHeaderKey.TASK_NAME, task_name)\n                task_data.add_cookie(ReservedHeaderKey.WORKFLOW, self.current_wf.id)\n\n            self.log_info(fl_ctx, \"assigned task to client: name={}, id={}\".format(task_name, task_id))\n\n            # filter task data\n            fl_ctx.set_prop(FLContextKey.TASK_NAME, value=task_name, private=True, sticky=False)\n            fl_ctx.set_prop(FLContextKey.TASK_DATA, value=task_data, private=True, sticky=False)\n            fl_ctx.set_prop(FLContextKey.TASK_ID, value=task_id, private=True, sticky=False)\n\n            self.log_debug(fl_ctx, \"firing event EventType.BEFORE_TASK_DATA_FILTER\")\n            self.fire_event(EventType.BEFORE_TASK_DATA_FILTER, fl_ctx)\n            filter_list = self.config.task_data_filters.get(task_name)\n            if filter_list:\n                for f in filter_list:\n                    try:\n                        task_data = f.process(task_data, fl_ctx)\n                    except BaseException as ex:\n                        self.log_exception(\n                            fl_ctx,\n                            \"processing error in task data filter {}: {}; \"\n                            \"asked client to try again later\".format(type(f), ex),\n                        )\n\n                        with self.wf_lock:\n                            if self.current_wf:\n                                self.current_wf.responder.handle_exception(task_id, fl_ctx)\n                        return self._task_try_again()\n\n            self.log_debug(fl_ctx, \"firing event EventType.AFTER_TASK_DATA_FILTER\")\n            self.fire_event(EventType.AFTER_TASK_DATA_FILTER, fl_ctx)\n            self.log_info(fl_ctx, \"sent task assignment to client\")\n            return task_name, task_id, task_data\n        except BaseException as e:\n            self.log_exception(fl_ctx, f\"Error processing client task request: {e}; asked client to try again later\")\n            return self._task_try_again()\n\n    def process_submission(self, client: Client, task_name: str, task_id: str, result: Shareable, fl_ctx: FLContext):\n        \"\"\"Process task result submitted from a client.\n\n        NOTE: the Engine will create a new fl_ctx and call this method:\n\n            with engine.new_context() as fl_ctx:\n                name, id, data = runner.process_submission(client, fl_ctx)\n\n        Args:\n            client: Client object\n            task_name: task name\n            task_id: task id\n            result: task result\n            fl_ctx: FLContext\n        \"\"\"\n        self.log_info(fl_ctx, \"got result from client for task: name={}, id={}\".format(task_name, task_id))\n\n        if not isinstance(result, Shareable):\n            self.log_error(fl_ctx, \"invalid result submission: must be Shareable but got {}\".format(type(result)))\n            return\n\n        # set the reply prop so log msg context could include RC from it\n        fl_ctx.set_prop(FLContextKey.REPLY, result, private=True, sticky=False)\n\n        fl_ctx.set_prop(FLContextKey.TASK_NAME, value=task_name, private=True, sticky=False)\n        fl_ctx.set_prop(FLContextKey.TASK_RESULT, value=result, private=True, sticky=False)\n        fl_ctx.set_prop(FLContextKey.TASK_ID, value=task_id, private=True, sticky=False)\n\n        if self.status != \"started\":\n            self.log_info(fl_ctx, \"ignored result submission since server runner's status is {}\".format(self.status))\n            return\n\n        peer_ctx = fl_ctx.get_peer_context()\n        if not isinstance(peer_ctx, FLContext):\n            self.log_info(fl_ctx, \"invalid result submission: no peer context - dropped\")\n            return\n\n        peer_job_id = peer_ctx.get_job_id()\n        if not peer_job_id or peer_job_id != self.job_id:\n            # the client is on a different RUN\n            self.log_info(fl_ctx, \"invalid result submission: not the same job id - dropped\")\n            return\n\n        result.set_header(ReservedHeaderKey.TASK_NAME, task_name)\n        result.set_header(ReservedHeaderKey.TASK_ID, task_id)\n        result.set_peer_props(peer_ctx.get_all_public_props())\n\n        # filter task result\n        self.log_debug(fl_ctx, \"firing event EventType.BEFORE_TASK_RESULT_FILTER\")\n        self.fire_event(EventType.BEFORE_TASK_RESULT_FILTER, fl_ctx)\n        filter_list = self.config.task_result_filters.get(task_name)\n        if filter_list:\n            for f in filter_list:\n                try:\n                    result = f.process(result, fl_ctx)\n                except BaseException as e:\n                    self.log_exception(fl_ctx, \"Error processing in task result filter {}: {}\".format(type(f), e))\n                    return\n\n        self.log_debug(fl_ctx, \"firing event EventType.AFTER_TASK_RESULT_FILTER\")\n        self.fire_event(EventType.AFTER_TASK_RESULT_FILTER, fl_ctx)\n\n        with self.wf_lock:\n            try:\n                if self.current_wf is None:\n                    self.log_info(fl_ctx, \"no current workflow - dropped submission.\")\n                    return\n\n                wf_id = result.get_cookie(ReservedHeaderKey.WORKFLOW, None)\n                if wf_id is not None and wf_id != self.current_wf.id:\n                    self.log_info(\n                        fl_ctx,\n                        \"Got result for workflow {}, but we are running {} - dropped submission.\".format(\n                            wf_id, self.current_wf.id\n                        ),\n                    )\n                    return\n\n                self.log_debug(fl_ctx, \"firing event EventType.BEFORE_PROCESS_SUBMISSION\")\n                self.fire_event(EventType.BEFORE_PROCESS_SUBMISSION, fl_ctx)\n\n                self.current_wf.responder.process_submission(\n                    client=client, task_name=task_name, task_id=task_id, result=result, fl_ctx=fl_ctx\n                )\n                self.log_info(fl_ctx, \"finished processing client result by {}\".format(self.current_wf.id))\n\n                self.log_debug(fl_ctx, \"firing event EventType.AFTER_PROCESS_SUBMISSION\")\n                self.fire_event(EventType.AFTER_PROCESS_SUBMISSION, fl_ctx)\n            except BaseException as e:\n                self.log_exception(fl_ctx, \"Error processing client result by {}: {}\".format(self.current_wf.id, e))\n\n    def abort(self, fl_ctx: FLContext):\n        self.status = \"done\"\n        self.abort_signal.trigger(value=True)\n        self.log_info(fl_ctx, \"asked to abort - triggered abort_signal to stop the RUN\")\n\n    def get_persist_state(self, fl_ctx: FLContext) -> dict:\n        return {\"job_id\": str(self.job_id), \"current_wf_index\": self.current_wf_index}\n\n    def restore(self, state_data: dict, fl_ctx: FLContext):\n        self.job_id = state_data.get(\"job_id\")\n        self.current_wf_index = int(state_data.get(\"current_wf_index\", 0))",
  "def __init__(\n        self,\n        heartbeat_timeout: int,\n        task_request_interval: int,\n        workflows: [],\n        task_data_filters: dict,\n        task_result_filters: dict,\n        handlers=None,\n        components=None,\n    ):\n        \"\"\"Configuration for ServerRunner.\n\n        Args:\n            heartbeat_timeout (int): Client heartbeat timeout in seconds\n            task_request_interval (int): Task request interval in seconds\n            workflows (list): A list of workflow\n            task_data_filters (dict):  A dict of  {task_name: list of filters apply to data (pre-process)}\n            task_result_filters (dict): A dict of {task_name: list of filters apply to result (post-process)}\n            handlers (list, optional):  A list of event handlers\n            components (dict, optional):  A dict of extra python objects {id: object}\n        \"\"\"\n        self.heartbeat_timeout = heartbeat_timeout\n        self.task_request_interval = task_request_interval\n        self.workflows = workflows\n        self.task_data_filters = task_data_filters\n        self.task_result_filters = task_result_filters\n        self.handlers = handlers\n        self.components = components",
  "def __init__(self, config: ServerRunnerConfig, job_id: str, engine: ServerEngineSpec):\n        \"\"\"Server runner class.\n\n        Args:\n            config (ServerRunnerConfig): configuration of server runner\n            job_id (str): The number to distinguish each experiment\n            engine (ServerEngineSpec): server engine\n        \"\"\"\n        FLComponent.__init__(self)\n        self.job_id = job_id\n        self.config = config\n        self.engine = engine\n        self.abort_signal = Signal()\n        self.wf_lock = threading.Lock()\n        self.current_wf = None\n        self.current_wf_index = 0\n        self.status = \"init\"",
  "def _execute_run(self):\n        while self.current_wf_index < len(self.config.workflows):\n            wf = self.config.workflows[self.current_wf_index]\n            try:\n                with self.engine.new_context() as fl_ctx:\n                    self.log_info(fl_ctx, \"starting workflow {} ({}) ...\".format(wf.id, type(wf.responder)))\n\n                    wf.responder.initialize_run(fl_ctx)\n\n                    self.log_info(fl_ctx, \"Workflow {} ({}) started\".format(wf.id, type(wf.responder)))\n                    fl_ctx.set_prop(FLContextKey.WORKFLOW, wf.id, sticky=True)\n                    self.log_debug(fl_ctx, \"firing event EventType.START_WORKFLOW\")\n                    self.fire_event(EventType.START_WORKFLOW, fl_ctx)\n\n                    # use the wf_lock to ensure state integrity between workflow change and message processing\n                    with self.wf_lock:\n                        # we only set self.current_wf to open for business after successful initialize_run!\n                        self.current_wf = wf\n\n                with self.engine.new_context() as fl_ctx:\n                    wf.responder.control_flow(self.abort_signal, fl_ctx)\n            except WorkflowError as e:\n                with self.engine.new_context() as fl_ctx:\n                    self.log_exception(fl_ctx, f\"Fatal error occurred in workflow {wf.id}: {e}. Aborting the RUN\")\n                self.abort_signal.trigger(True)\n            except BaseException as e:\n                with self.engine.new_context() as fl_ctx:\n                    self.log_exception(fl_ctx, \"Exception in workflow {}: {}\".format(wf.id, e))\n            finally:\n                with self.engine.new_context() as fl_ctx:\n                    # do not execute finalize_run() until the wf_lock is acquired\n                    with self.wf_lock:\n                        # unset current_wf to prevent message processing\n                        # then we can release the lock - no need to delay message processing\n                        # during finalization!\n                        # Note: WF finalization may take time since it needs to wait for\n                        # the job monitor to join.\n                        self.current_wf = None\n\n                    self.log_info(fl_ctx, f\"Workflow: {wf.id} finalizing ...\")\n                    try:\n                        wf.responder.finalize_run(fl_ctx)\n                    except BaseException as e:\n                        self.log_exception(fl_ctx, \"Error finalizing workflow {}: {}\".format(wf.id, e))\n\n                    self.log_debug(fl_ctx, \"firing event EventType.END_WORKFLOW\")\n                    self.fire_event(EventType.END_WORKFLOW, fl_ctx)\n\n                # Stopped the server runner from the current responder, not continue the following responders.\n                if self.abort_signal.triggered:\n                    break\n            self.current_wf_index += 1",
  "def run(self):\n        with self.engine.new_context() as fl_ctx:\n            self.log_info(fl_ctx, \"Server runner starting ...\")\n\n            self.log_debug(fl_ctx, \"firing event EventType.START_RUN\")\n            fl_ctx.set_prop(ReservedKey.RUN_ABORT_SIGNAL, self.abort_signal, private=True, sticky=True)\n            self.fire_event(EventType.START_RUN, fl_ctx)\n            self.engine.persist_components(fl_ctx, completed=False)\n\n        self.status = \"started\"\n        try:\n            self._execute_run()\n        except BaseException as ex:\n            with self.engine.new_context() as fl_ctx:\n                self.log_exception(fl_ctx, f\"Error executing RUN: {ex}\")\n        finally:\n            # use wf_lock to ensure state of current_wf!\n            self.status = \"done\"\n            with self.wf_lock:\n                with self.engine.new_context() as fl_ctx:\n                    self.fire_event(EventType.ABOUT_TO_END_RUN, fl_ctx)\n                    self.log_info(fl_ctx, \"ABOUT_TO_END_RUN fired\")\n                    self.fire_event(EventType.END_RUN, fl_ctx)\n                    self.log_info(fl_ctx, \"END_RUN fired\")\n                    self.engine.persist_components(fl_ctx, completed=True)\n\n            # ask all clients to end run!\n            self.engine.send_aux_request(\n                targets=None, topic=ReservedTopic.END_RUN, request=Shareable(), timeout=0.0, fl_ctx=fl_ctx\n            )\n\n            self.log_info(fl_ctx, \"Server runner finished.\")",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == InfoCollector.EVENT_TYPE_GET_STATS:\n            collector = fl_ctx.get_prop(InfoCollector.CTX_KEY_STATS_COLLECTOR)\n            if collector:\n                if not isinstance(collector, GroupInfoCollector):\n                    raise TypeError(\"collector must be GroupInfoCollect but got {}\".format(type(collector)))\n\n                with self.wf_lock:\n                    if self.current_wf:\n                        collector.set_info(\n                            group_name=\"ServerRunner\",\n                            info={\"job_id\": self.job_id, \"status\": self.status, \"workflow\": self.current_wf.id},\n                        )\n        elif event_type == EventType.FATAL_SYSTEM_ERROR:\n            reason = fl_ctx.get_prop(key=FLContextKey.EVENT_DATA, default=\"\")\n            self.log_error(fl_ctx, \"Aborting current RUN due to FATAL_SYSTEM_ERROR received: {}\".format(reason))\n            self.abort(fl_ctx)",
  "def _task_try_again(self) -> (str, str, Shareable):\n        task = Shareable()\n        task[TaskConstant.WAIT_TIME] = self.config.task_request_interval\n        return SpecialTaskName.TRY_AGAIN, \"\", task",
  "def process_task_request(self, client: Client, fl_ctx: FLContext) -> (str, str, Shareable):\n        \"\"\"Process task request from a client.\n\n        NOTE: the Engine will create a new fl_ctx and call this method:\n\n            with engine.new_context() as fl_ctx:\n                name, id, data = runner.process_task_request(client, fl_ctx)\n                ...\n\n        Args:\n            client (Client): client object\n            fl_ctx (FLContext): FL context\n\n        Returns:\n            A tuple of (task name, task id, and task data)\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ServerEngineSpec):\n            raise TypeError(\"engine must be ServerEngineSpec but got {}\".format(type(engine)))\n\n        self.log_debug(fl_ctx, \"process task request from client\")\n\n        if self.status == \"init\":\n            self.log_debug(fl_ctx, \"server runner still initializing - asked client to try again later\")\n            return self._task_try_again()\n\n        if self.status == \"done\":\n            self.log_info(fl_ctx, \"server runner is finalizing - asked client to end the run\")\n            return SpecialTaskName.END_RUN, \"\", None\n\n        peer_ctx = fl_ctx.get_peer_context()\n        if not isinstance(peer_ctx, FLContext):\n            self.log_debug(fl_ctx, \"invalid task request: no peer context - asked client to try again later\")\n            return self._task_try_again()\n\n        peer_job_id = peer_ctx.get_job_id()\n        if not peer_job_id or peer_job_id != self.job_id:\n            # the client is in a different RUN\n            self.log_info(fl_ctx, \"invalid task request: not the same job_id - asked client to end the run\")\n            return SpecialTaskName.END_RUN, \"\", None\n\n        try:\n            with self.wf_lock:\n                if self.current_wf is None:\n                    self.log_info(fl_ctx, \"no current workflow - asked client to try again later\")\n                    return self._task_try_again()\n\n                task_name, task_id, task_data = self.current_wf.responder.process_task_request(client, fl_ctx)\n\n                if not task_name or task_name == SpecialTaskName.TRY_AGAIN:\n                    self.log_debug(fl_ctx, \"no task currently for client - asked client to try again later\")\n                    return self._task_try_again()\n\n                if task_data:\n                    if not isinstance(task_data, Shareable):\n                        self.log_error(\n                            fl_ctx,\n                            \"bad task data generated by workflow {}: must be Shareable but got {}\".format(\n                                self.current_wf.id, type(task_data)\n                            ),\n                        )\n                        return self._task_try_again()\n                else:\n                    task_data = Shareable()\n\n                task_data.set_header(ReservedHeaderKey.TASK_ID, task_id)\n                task_data.set_header(ReservedHeaderKey.TASK_NAME, task_name)\n                task_data.add_cookie(ReservedHeaderKey.WORKFLOW, self.current_wf.id)\n\n            self.log_info(fl_ctx, \"assigned task to client: name={}, id={}\".format(task_name, task_id))\n\n            # filter task data\n            fl_ctx.set_prop(FLContextKey.TASK_NAME, value=task_name, private=True, sticky=False)\n            fl_ctx.set_prop(FLContextKey.TASK_DATA, value=task_data, private=True, sticky=False)\n            fl_ctx.set_prop(FLContextKey.TASK_ID, value=task_id, private=True, sticky=False)\n\n            self.log_debug(fl_ctx, \"firing event EventType.BEFORE_TASK_DATA_FILTER\")\n            self.fire_event(EventType.BEFORE_TASK_DATA_FILTER, fl_ctx)\n            filter_list = self.config.task_data_filters.get(task_name)\n            if filter_list:\n                for f in filter_list:\n                    try:\n                        task_data = f.process(task_data, fl_ctx)\n                    except BaseException as ex:\n                        self.log_exception(\n                            fl_ctx,\n                            \"processing error in task data filter {}: {}; \"\n                            \"asked client to try again later\".format(type(f), ex),\n                        )\n\n                        with self.wf_lock:\n                            if self.current_wf:\n                                self.current_wf.responder.handle_exception(task_id, fl_ctx)\n                        return self._task_try_again()\n\n            self.log_debug(fl_ctx, \"firing event EventType.AFTER_TASK_DATA_FILTER\")\n            self.fire_event(EventType.AFTER_TASK_DATA_FILTER, fl_ctx)\n            self.log_info(fl_ctx, \"sent task assignment to client\")\n            return task_name, task_id, task_data\n        except BaseException as e:\n            self.log_exception(fl_ctx, f\"Error processing client task request: {e}; asked client to try again later\")\n            return self._task_try_again()",
  "def process_submission(self, client: Client, task_name: str, task_id: str, result: Shareable, fl_ctx: FLContext):\n        \"\"\"Process task result submitted from a client.\n\n        NOTE: the Engine will create a new fl_ctx and call this method:\n\n            with engine.new_context() as fl_ctx:\n                name, id, data = runner.process_submission(client, fl_ctx)\n\n        Args:\n            client: Client object\n            task_name: task name\n            task_id: task id\n            result: task result\n            fl_ctx: FLContext\n        \"\"\"\n        self.log_info(fl_ctx, \"got result from client for task: name={}, id={}\".format(task_name, task_id))\n\n        if not isinstance(result, Shareable):\n            self.log_error(fl_ctx, \"invalid result submission: must be Shareable but got {}\".format(type(result)))\n            return\n\n        # set the reply prop so log msg context could include RC from it\n        fl_ctx.set_prop(FLContextKey.REPLY, result, private=True, sticky=False)\n\n        fl_ctx.set_prop(FLContextKey.TASK_NAME, value=task_name, private=True, sticky=False)\n        fl_ctx.set_prop(FLContextKey.TASK_RESULT, value=result, private=True, sticky=False)\n        fl_ctx.set_prop(FLContextKey.TASK_ID, value=task_id, private=True, sticky=False)\n\n        if self.status != \"started\":\n            self.log_info(fl_ctx, \"ignored result submission since server runner's status is {}\".format(self.status))\n            return\n\n        peer_ctx = fl_ctx.get_peer_context()\n        if not isinstance(peer_ctx, FLContext):\n            self.log_info(fl_ctx, \"invalid result submission: no peer context - dropped\")\n            return\n\n        peer_job_id = peer_ctx.get_job_id()\n        if not peer_job_id or peer_job_id != self.job_id:\n            # the client is on a different RUN\n            self.log_info(fl_ctx, \"invalid result submission: not the same job id - dropped\")\n            return\n\n        result.set_header(ReservedHeaderKey.TASK_NAME, task_name)\n        result.set_header(ReservedHeaderKey.TASK_ID, task_id)\n        result.set_peer_props(peer_ctx.get_all_public_props())\n\n        # filter task result\n        self.log_debug(fl_ctx, \"firing event EventType.BEFORE_TASK_RESULT_FILTER\")\n        self.fire_event(EventType.BEFORE_TASK_RESULT_FILTER, fl_ctx)\n        filter_list = self.config.task_result_filters.get(task_name)\n        if filter_list:\n            for f in filter_list:\n                try:\n                    result = f.process(result, fl_ctx)\n                except BaseException as e:\n                    self.log_exception(fl_ctx, \"Error processing in task result filter {}: {}\".format(type(f), e))\n                    return\n\n        self.log_debug(fl_ctx, \"firing event EventType.AFTER_TASK_RESULT_FILTER\")\n        self.fire_event(EventType.AFTER_TASK_RESULT_FILTER, fl_ctx)\n\n        with self.wf_lock:\n            try:\n                if self.current_wf is None:\n                    self.log_info(fl_ctx, \"no current workflow - dropped submission.\")\n                    return\n\n                wf_id = result.get_cookie(ReservedHeaderKey.WORKFLOW, None)\n                if wf_id is not None and wf_id != self.current_wf.id:\n                    self.log_info(\n                        fl_ctx,\n                        \"Got result for workflow {}, but we are running {} - dropped submission.\".format(\n                            wf_id, self.current_wf.id\n                        ),\n                    )\n                    return\n\n                self.log_debug(fl_ctx, \"firing event EventType.BEFORE_PROCESS_SUBMISSION\")\n                self.fire_event(EventType.BEFORE_PROCESS_SUBMISSION, fl_ctx)\n\n                self.current_wf.responder.process_submission(\n                    client=client, task_name=task_name, task_id=task_id, result=result, fl_ctx=fl_ctx\n                )\n                self.log_info(fl_ctx, \"finished processing client result by {}\".format(self.current_wf.id))\n\n                self.log_debug(fl_ctx, \"firing event EventType.AFTER_PROCESS_SUBMISSION\")\n                self.fire_event(EventType.AFTER_PROCESS_SUBMISSION, fl_ctx)\n            except BaseException as e:\n                self.log_exception(fl_ctx, \"Error processing client result by {}: {}\".format(self.current_wf.id, e))",
  "def abort(self, fl_ctx: FLContext):\n        self.status = \"done\"\n        self.abort_signal.trigger(value=True)\n        self.log_info(fl_ctx, \"asked to abort - triggered abort_signal to stop the RUN\")",
  "def get_persist_state(self, fl_ctx: FLContext) -> dict:\n        return {\"job_id\": str(self.job_id), \"current_wf_index\": self.current_wf_index}",
  "def restore(self, state_data: dict, fl_ctx: FLContext):\n        self.job_id = state_data.get(\"job_id\")\n        self.current_wf_index = int(state_data.get(\"current_wf_index\", 0))",
  "class TrainingCommandModule(CommandModule, CommandUtil):\n\n    APP_STAGING_PATH = \"app_staging_path\"\n\n    def __init__(self):\n        \"\"\"A class for training commands.\"\"\"\n        super().__init__()\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=\"training\",\n            cmd_specs=[\n                CommandSpec(\n                    name=AdminCommandNames.DELETE_WORKSPACE,\n                    description=\"delete the workspace of a job\",\n                    usage=\"delete_workspace job_id\",\n                    handler_func=self.delete_job_id,\n                    authz_func=self.authorize_set_job_id,\n                    visible=False,\n                    confirm=\"auth\",\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.DEPLOY_APP,\n                    description=\"deploy FL app to client/server\",\n                    usage=\"deploy_app job_id app server|client <client-name>|all\",\n                    handler_func=self.deploy_app,\n                    authz_func=self.authorize_deploy_app,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.START_APP,\n                    description=\"start the FL app\",\n                    usage=\"start_app job_id server|client|all\",\n                    handler_func=self.start_app,\n                    authz_func=self.authorize_train,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.CHECK_STATUS,\n                    description=\"check status of the FL server/client\",\n                    usage=\"check_status server|client\",\n                    handler_func=self.check_status,\n                    authz_func=self.authorize_view,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.ABORT,\n                    description=\"abort the FL app\",\n                    usage=\"abort job_id server|client|all\",\n                    handler_func=self.abort_app,\n                    authz_func=self.authorize_train,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.ABORT_TASK,\n                    description=\"abort the client current task execution\",\n                    usage=\"abort_task job_id <client-name>\",\n                    handler_func=self.abort_task,\n                    authz_func=self.authorize_abort_client,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.REMOVE_CLIENT,\n                    description=\"remove a FL client\",\n                    usage=\"remove_client <client-name>\",\n                    handler_func=self.remove_client,\n                    authz_func=self.authorize_remove_client,\n                    visible=True,\n                    confirm=\"auth\",\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.SHUTDOWN,\n                    description=\"shutdown the FL server/client\",\n                    usage=\"shutdown server|client|all\",\n                    handler_func=self.shutdown,\n                    authz_func=self.authorize_operate,\n                    visible=True,\n                    confirm=\"auth\",\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.RESTART,\n                    description=\"restart the FL server/client\",\n                    usage=\"restart server|client|all\",\n                    handler_func=self.restart,\n                    authz_func=self.authorize_operate,\n                    visible=True,\n                    confirm=\"auth\",\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.SET_TIMEOUT,\n                    description=\"set the admin commands timeout\",\n                    usage=\"set_timeout seconds \",\n                    handler_func=self.set_timeout,\n                    authz_func=self.authorize_set_timeout,\n                    visible=True,\n                ),\n            ],\n        )\n\n    def authorize_set_job_id(self, conn: Connection, args: List[str]):\n        if len(args) < 2:\n            conn.append_error(\"syntax error: missing job id\")\n            return False, None\n\n        return True, FLAuthzContext.new_authz_context(site_names=[self.SITE_SERVER], actions=[Action.TRAIN])\n\n    def _set_job_id_clients(self, conn: Connection, job_id) -> bool:\n        engine = conn.app_ctx\n        clients = engine.get_clients()\n        if clients:\n            valid_tokens = []\n            for c in clients:\n                valid_tokens.append(c.token)\n            conn.set_prop(self.TARGET_CLIENT_TOKENS, valid_tokens)\n\n            message = new_message(conn, topic=TrainingTopic.SET_JOB_ID, body=\"\")\n            message.set_header(RequestHeader.JOB_ID, str(job_id))\n            replies = self.send_request_to_clients(conn, message)\n            self.process_replies_to_table(conn, replies)\n            return True\n\n    def delete_job_id(self, conn: Connection, args: List[str]):\n        job_id = args[1]\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngine):\n            raise TypeError(\"engine must be ServerEngine but got {}\".format(type(engine)))\n\n        if job_id in engine.run_processes.keys():\n            conn.append_error(f\"Current running run_{job_id} can not be deleted.\")\n            return\n\n        err = engine.delete_job_id(job_id)\n        if err:\n            conn.append_error(err)\n            return\n\n        # ask clients to delete this RUN\n        message = new_message(conn, topic=TrainingTopic.DELETE_RUN, body=\"\")\n        message.set_header(RequestHeader.JOB_ID, str(job_id))\n        clients = engine.get_clients()\n        if clients:\n            conn.set_prop(self.TARGET_CLIENT_TOKENS, [x.token for x in clients])\n            replies = self.send_request_to_clients(conn, message)\n            self.process_replies_to_table(conn, replies)\n\n        conn.append_success(\"\")\n\n    # Deploy\n    def authorize_deploy_app(self, conn: Connection, args: List[str]):\n        if len(args) < 4:\n            conn.append_error(\"syntax error: missing job_id and target\")\n            return False, None\n\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        err = self.validate_command_targets(conn, args[3:])\n        if err:\n            conn.append_error(err)\n            return False, None\n\n        run_destination = args[1].lower()\n        if not run_destination.startswith(WorkspaceConstants.WORKSPACE_PREFIX):\n            conn.append_error(\"syntax error: run_destination must be run_XXX\")\n            return False, None\n        destination = run_destination[len(WorkspaceConstants.WORKSPACE_PREFIX) :]\n        conn.set_prop(self.JOB_ID, destination)\n\n        app_name = args[2]\n        app_staging_path = engine.get_staging_path_of_app(app_name)\n        if not app_staging_path:\n            conn.append_error(\"App {} does not exist. Please upload it first\".format(app_name))\n            return False, None\n\n        conn.set_prop(self.APP_STAGING_PATH, app_staging_path)\n        target_type = args[3]\n\n        if target_type == self.TARGET_TYPE_SERVER:\n            sites = [self.SITE_SERVER]\n        else:\n            sites = []\n            client_names = conn.get_prop(self.TARGET_CLIENT_NAMES)\n            if client_names:\n                sites.extend(client_names)\n\n            if target_type == self.TARGET_TYPE_ALL:\n                sites.append(self.SITE_SERVER)\n\n        err, authz_ctx = AppAuthzService.authorize_deploy(app_staging_path, sites)\n        if err:\n            conn.append_error(err)\n            return False, None\n        else:\n\n            return True, authz_ctx\n\n    def _deploy_to_clients(self, conn: Connection, app_name, job_id) -> bool:\n        # return True if successful\n        engine = conn.app_ctx\n        err, app_data = engine.get_app_data(app_name)\n        if err:\n            conn.append_error(err)\n            return False\n\n        message = new_message(conn, topic=TrainingTopic.DEPLOY, body=app_data)\n        message.set_header(RequestHeader.JOB_ID, str(job_id))\n        message.set_header(RequestHeader.APP_NAME, app_name)\n        replies = self.send_request_to_clients(conn, message)\n        self.process_replies_to_table(conn, replies)\n        return True\n\n    def _deploy_to_server(self, conn, job_id, app_name, app_staging_path) -> bool:\n        # return True if successful\n        engine = conn.app_ctx\n        err = engine.deploy_app_to_server(job_id, app_name, app_staging_path)\n        if not err:\n            conn.append_string('deployed app \"{}\" to Server'.format(app_name))\n            return True\n        else:\n            conn.append_error(err)\n            return False\n\n    def deploy_app(self, conn: Connection, args: List[str]):\n        app_name = args[2]\n\n        job_id = conn.get_prop(self.JOB_ID)\n        target_type = conn.get_prop(self.TARGET_TYPE)\n        app_staging_path = conn.get_prop(self.APP_STAGING_PATH)\n        if target_type == self.TARGET_TYPE_SERVER:\n            if not self._deploy_to_server(conn, job_id, app_name, app_staging_path):\n                return\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            if not self._deploy_to_clients(conn, app_name, job_id):\n                return\n        else:\n            # all\n            success = self._deploy_to_server(conn, job_id, app_name, app_staging_path)\n            if success:\n                client_names = conn.get_prop(self.TARGET_CLIENT_NAMES, None)\n                if client_names:\n                    if not self._deploy_to_clients(conn, app_name, job_id):\n                        return\n            else:\n                return\n        conn.append_success(\"\")\n\n    # Start App\n    def _start_app_on_server(self, conn: Connection, job_id: str) -> bool:\n        engine = conn.app_ctx\n        err = engine.start_app_on_server(job_id)\n        if err:\n            conn.append_error(err)\n            return False\n        else:\n            conn.append_string(\"Server app is starting....\")\n            return True\n\n    def _start_app_on_clients(self, conn: Connection, job_id: str) -> bool:\n        engine = conn.app_ctx\n        err = engine.check_app_start_readiness(job_id)\n        if err:\n            conn.append_error(err)\n            return False\n\n        # run_info = engine.get_run_info()\n        message = new_message(conn, topic=TrainingTopic.START, body=\"\")\n        # message.set_header(RequestHeader.JOB_ID, str(run_info.job_id))\n        message.set_header(RequestHeader.JOB_ID, job_id)\n        replies = self.send_request_to_clients(conn, message)\n        self.process_replies_to_table(conn, replies)\n        return True\n\n    def start_app(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        job_id = conn.get_prop(self.JOB_ID)\n        target_type = args[2]\n        if target_type == self.TARGET_TYPE_SERVER:\n            if not self._start_app_on_server(conn, job_id):\n                return\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            if not self._start_app_on_clients(conn, job_id):\n                return\n        else:\n            # all\n            success = self._start_app_on_server(conn, job_id)\n\n            if success:\n                client_names = conn.get_prop(self.TARGET_CLIENT_NAMES, None)\n                if client_names:\n                    if not self._start_app_on_clients(conn, job_id):\n                        return\n        conn.append_success(\"\")\n\n    # Abort App\n    def _abort_clients(self, conn, clients: List[str], job_id) -> bool:\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        err = engine.abort_app_on_clients(clients)\n        if err:\n            conn.append_error(err)\n            return False\n\n        # run_info = engine.get_app_run_info(job_id)\n        message = new_message(conn, topic=TrainingTopic.ABORT, body=\"\")\n        # if run_info:\n        message.set_header(RequestHeader.JOB_ID, str(job_id))\n\n        # conn.set_prop(self.TARGET_CLIENT_NAMES, client_names)\n        replies = self.send_request_to_clients(conn, message)\n        self.process_replies_to_table(conn, replies)\n        return True\n\n    def abort_app(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        job_id = conn.get_prop(self.JOB_ID)\n        target_type = args[2]\n        if target_type == self.TARGET_TYPE_SERVER or target_type == self.TARGET_TYPE_ALL:\n            conn.append_string(\"Trying to abort all clients before abort server ...\")\n            clients = engine.get_clients()\n            if clients:\n                tokens = [c.token for c in clients]\n                conn.set_prop(\n                    self.TARGET_CLIENT_TOKENS, tokens\n                )  # need this because not set in validate_command_targets when target_type == self.TARGET_TYPE_SERVER\n                if not self._abort_clients(conn, clients=[c.token for c in clients], job_id=job_id):\n                    return\n            err = engine.abort_app_on_server(job_id)\n            if err:\n                conn.append_error(err)\n                return\n            conn.append_string(\"Abort signal has been sent to the server app.\")\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            clients = conn.get_prop(self.TARGET_CLIENT_TOKENS)\n            if not clients:\n                conn.append_string(\"No clients to abort\")\n                return\n            if not self._abort_clients(conn, clients, job_id):\n                return\n        conn.append_success(\"\")\n\n    def abort_task(self, conn, clients: List[str]) -> str:\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        job_id = conn.get_prop(self.JOB_ID)\n        # run_info = engine.get_app_run_info()\n        message = new_message(conn, topic=TrainingTopic.ABORT_TASK, body=\"\")\n        # if run_info:\n        message.set_header(RequestHeader.JOB_ID, str(job_id))\n\n        # conn.set_prop(self.TARGET_CLIENT_NAMES, client_names)\n        replies = self.send_request_to_clients(conn, message)\n        return self.process_replies_to_table(conn, replies)\n\n    # Shutdown\n    def _shutdown_app_on_server(self, conn: Connection) -> bool:\n        engine = conn.app_ctx\n        err = engine.shutdown_server()\n        if err:\n            conn.append_error(err)\n            return False\n        else:\n            conn.append_string(\"FL app has been shutdown.\")\n            conn.append_shutdown(\"Bye bye\")\n            return True\n\n    def _shutdown_app_on_clients(self, conn: Connection) -> bool:\n        engine = conn.app_ctx\n        message = new_message(conn, topic=TrainingTopic.SHUTDOWN, body=\"\")\n        clients = conn.get_prop(self.TARGET_CLIENT_TOKENS, None)\n        if not clients:\n            conn.append_error(\"no clients to shutdown\")\n            return False\n\n        replies = self.send_request_to_clients(conn, message)\n        self.process_replies_to_table(conn, replies)\n\n        err = engine.remove_clients(clients)\n        if err:\n            conn.append_error(err)\n            return False\n        return True\n\n    def shutdown(self, conn: Connection, args: List[str]):\n        target_type = args[1]\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngine):\n            raise TypeError(\"engine must be ServerEngine but got {}\".format(type(engine)))\n\n        if engine.job_runner.running_jobs:\n            conn.append_error(\"There are still jobs running. Please let them finish or abort_job before shutdown.\")\n            return\n\n        if target_type == self.TARGET_TYPE_SERVER:\n            if engine.get_clients():\n                conn.append_error(\"There are still active clients. Shutdown all clients first.\")\n                return\n            if not self._shutdown_app_on_server(conn):\n                return\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            if not self._shutdown_app_on_clients(conn):\n                return\n        else:\n            # all\n            if engine.get_clients():\n                conn.append_string(\"Trying to shutdown clients before server...\")\n                success = self._shutdown_app_on_clients(conn)\n                if success:\n                    if not self._shutdown_app_on_server(conn):\n                        return\n            else:\n                if not self._shutdown_app_on_server(conn):\n                    return\n        conn.append_success(\"\")\n\n    # Remove Clients\n    def authorize_remove_client(self, conn: Connection, args: List[str]):\n        if len(args) < 2:\n            conn.append_error(\"syntax error: missing site names\")\n            return False, None\n\n        auth_args = [args[0], self.TARGET_TYPE_CLIENT]\n        auth_args.extend(args[1:])\n        return self.authorize_operate(conn, auth_args)\n\n    def authorize_abort_client(self, conn: Connection, args: List[str]):\n        if len(args) < 3:\n            conn.append_error(\"syntax error: missing job_id and target\")\n            return False, None\n\n        run_destination = args[1].lower()\n        if not run_destination.startswith(WorkspaceConstants.WORKSPACE_PREFIX):\n            conn.append_error(\"syntax error: run_destination must be run_XXX\")\n            return False, None\n        job_id = run_destination[len(WorkspaceConstants.WORKSPACE_PREFIX) :]\n        conn.set_prop(self.JOB_ID, job_id)\n\n        auth_args = [args[0], self.TARGET_TYPE_CLIENT]\n        auth_args.extend(args[2:])\n        return self.authorize_operate(conn, auth_args)\n\n    def remove_client(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n        clients = conn.get_prop(self.TARGET_CLIENT_TOKENS)\n        err = engine.remove_clients(clients)\n        if err:\n            conn.append_error(err)\n            return\n        conn.append_success(\"\")\n\n    # Restart\n    def _restart_clients(self, conn, clients) -> str:\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n        engine.remove_clients(clients)\n        message = new_message(conn, topic=TrainingTopic.RESTART, body=\"\")\n        replies = self.send_request_to_clients(conn, message)\n        return self._process_replies_to_string(conn, replies)\n\n    def restart(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngine):\n            raise TypeError(\"engine must be ServerEngine but got {}\".format(type(engine)))\n\n        if engine.job_runner.running_jobs:\n            conn.append_error(\"There are still jobs running. Please let them finish or abort_job before restart.\")\n            return\n\n        target_type = args[1]\n        if target_type == self.TARGET_TYPE_SERVER or target_type == self.TARGET_TYPE_ALL:\n\n            clients = engine.get_clients()\n            if clients:\n                conn.append_string(\"Trying to restart all clients before restarting server...\")\n                tokens = [c.token for c in clients]\n                conn.set_prop(\n                    self.TARGET_CLIENT_TOKENS, tokens\n                )  # need this because not set in validate_command_targets when target_type == self.TARGET_TYPE_SERVER\n                response = self._restart_clients(conn, tokens)\n                conn.append_string(response)\n                # check with Isaac - no need to wait!\n                # time.sleep(5)\n\n            err = engine.restart_server()\n            if err:\n                conn.append_error(err)\n            else:\n                conn.append_string(\"Server scheduled for restart\")\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            clients = conn.get_prop(self.TARGET_CLIENT_TOKENS)\n            if not clients:\n                conn.append_error(\"no clients available\")\n                return\n            else:\n                response = self._restart_clients(conn, clients)\n                conn.append_string(response)\n        conn.append_success(\"\")\n\n    # Set Timeout\n    def authorize_set_timeout(self, conn: Connection, args: List[str]):\n        if len(args) != 2:\n            conn.append_error(\"syntax error: missing timeout\")\n            return False, None\n\n        try:\n            num = float(args[1])\n        except ValueError:\n            conn.append_error(\"must provide the timeout value in seconds\")\n            return False, None\n\n        if num <= 0:\n            conn.append_error(\"timeout must be > 0\")\n            return False, None\n\n        return True, FLAuthzContext.new_authz_context(site_names=[self.SITE_SERVER], actions=[Action.TRAIN])\n\n    def set_timeout(self, conn: Connection, args: List[str]):\n        timeout = float(args[1])\n        server = conn.server\n        server.timeout = timeout\n        conn.append_string(\"admin command timeout has been set to: {}\".format(timeout))\n        conn.append_success(\"\")\n\n    # Check status\n    def check_status(self, conn: Connection, args: List[str]):\n        # TODO:: Need more discussion on what status to be shown\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n        dst = args[1]\n        if dst == self.TARGET_TYPE_SERVER:\n            engine_info = engine.get_engine_info()\n            conn.append_string(f\"Engine status: {engine_info.status.value}\")\n            table = conn.append_table([\"Job_id\", \"App Name\"])\n            for job_id, app_name in engine_info.app_names.items():\n                table.add_row([job_id, app_name])\n\n            clients = engine.get_clients()\n            conn.append_string(\"Registered clients: {} \".format(len(clients)))\n\n            if clients:\n                table = conn.append_table([\"Client\", \"Token\", \"Last Connect Time\"])\n                for c in clients:\n                    if not isinstance(c, Client):\n                        raise TypeError(\"c must be Client but got {}\".format(type(c)))\n                    table.add_row([c.name, str(c.token), time.asctime(time.localtime(c.last_connect_time))])\n        elif dst == self.TARGET_TYPE_CLIENT:\n            message = new_message(conn, topic=TrainingTopic.CHECK_STATUS, body=\"\")\n            replies = self.send_request_to_clients(conn, message)\n            self._process_status_replies(conn, replies)\n        else:\n            conn.append_error(\"invalid target type {}. Usage: check_status server|client ...\".format(dst))\n\n    def _process_status_replies(self, conn, replies):\n        if not replies:\n            conn.append_error(\"no responses from clients\")\n            return\n\n        engine = conn.app_ctx\n        table = conn.append_table([\"client\", \"app_name\", \"job_id\", \"status\"])\n        for r in replies:\n            job_id = \"?\"\n            app_name = \"?\"\n            client_name = engine.get_client_name_from_token(r.client_token)\n\n            if r.reply:\n                try:\n                    body = json.loads(r.reply.body)\n                    if r.reply and isinstance(body, dict):\n                        running_jobs = body.get(ClientStatusKey.RUNNING_JOBS)\n                        if running_jobs:\n                            for job in running_jobs:\n                                app_name = job.get(ClientStatusKey.APP_NAME, \"?\")\n                                job_id = job.get(ClientStatusKey.JOB_ID, \"?\")\n                                status = job.get(ClientStatusKey.STATUS, \"?\")\n                                table.add_row([client_name, app_name, job_id, status])\n                        else:\n                            table.add_row([client_name, app_name, job_id, \"No Jobs\"])\n                except BaseException as ex:\n                    self.logger.error(f\"Bad reply from client: {ex}\")\n            else:\n                table.add_row([client_name, app_name, job_id, \"No Reply\"])",
  "def __init__(self):\n        \"\"\"A class for training commands.\"\"\"\n        super().__init__()\n        self.logger = logging.getLogger(self.__class__.__name__)",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=\"training\",\n            cmd_specs=[\n                CommandSpec(\n                    name=AdminCommandNames.DELETE_WORKSPACE,\n                    description=\"delete the workspace of a job\",\n                    usage=\"delete_workspace job_id\",\n                    handler_func=self.delete_job_id,\n                    authz_func=self.authorize_set_job_id,\n                    visible=False,\n                    confirm=\"auth\",\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.DEPLOY_APP,\n                    description=\"deploy FL app to client/server\",\n                    usage=\"deploy_app job_id app server|client <client-name>|all\",\n                    handler_func=self.deploy_app,\n                    authz_func=self.authorize_deploy_app,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.START_APP,\n                    description=\"start the FL app\",\n                    usage=\"start_app job_id server|client|all\",\n                    handler_func=self.start_app,\n                    authz_func=self.authorize_train,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.CHECK_STATUS,\n                    description=\"check status of the FL server/client\",\n                    usage=\"check_status server|client\",\n                    handler_func=self.check_status,\n                    authz_func=self.authorize_view,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.ABORT,\n                    description=\"abort the FL app\",\n                    usage=\"abort job_id server|client|all\",\n                    handler_func=self.abort_app,\n                    authz_func=self.authorize_train,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.ABORT_TASK,\n                    description=\"abort the client current task execution\",\n                    usage=\"abort_task job_id <client-name>\",\n                    handler_func=self.abort_task,\n                    authz_func=self.authorize_abort_client,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.REMOVE_CLIENT,\n                    description=\"remove a FL client\",\n                    usage=\"remove_client <client-name>\",\n                    handler_func=self.remove_client,\n                    authz_func=self.authorize_remove_client,\n                    visible=True,\n                    confirm=\"auth\",\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.SHUTDOWN,\n                    description=\"shutdown the FL server/client\",\n                    usage=\"shutdown server|client|all\",\n                    handler_func=self.shutdown,\n                    authz_func=self.authorize_operate,\n                    visible=True,\n                    confirm=\"auth\",\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.RESTART,\n                    description=\"restart the FL server/client\",\n                    usage=\"restart server|client|all\",\n                    handler_func=self.restart,\n                    authz_func=self.authorize_operate,\n                    visible=True,\n                    confirm=\"auth\",\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.SET_TIMEOUT,\n                    description=\"set the admin commands timeout\",\n                    usage=\"set_timeout seconds \",\n                    handler_func=self.set_timeout,\n                    authz_func=self.authorize_set_timeout,\n                    visible=True,\n                ),\n            ],\n        )",
  "def authorize_set_job_id(self, conn: Connection, args: List[str]):\n        if len(args) < 2:\n            conn.append_error(\"syntax error: missing job id\")\n            return False, None\n\n        return True, FLAuthzContext.new_authz_context(site_names=[self.SITE_SERVER], actions=[Action.TRAIN])",
  "def _set_job_id_clients(self, conn: Connection, job_id) -> bool:\n        engine = conn.app_ctx\n        clients = engine.get_clients()\n        if clients:\n            valid_tokens = []\n            for c in clients:\n                valid_tokens.append(c.token)\n            conn.set_prop(self.TARGET_CLIENT_TOKENS, valid_tokens)\n\n            message = new_message(conn, topic=TrainingTopic.SET_JOB_ID, body=\"\")\n            message.set_header(RequestHeader.JOB_ID, str(job_id))\n            replies = self.send_request_to_clients(conn, message)\n            self.process_replies_to_table(conn, replies)\n            return True",
  "def delete_job_id(self, conn: Connection, args: List[str]):\n        job_id = args[1]\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngine):\n            raise TypeError(\"engine must be ServerEngine but got {}\".format(type(engine)))\n\n        if job_id in engine.run_processes.keys():\n            conn.append_error(f\"Current running run_{job_id} can not be deleted.\")\n            return\n\n        err = engine.delete_job_id(job_id)\n        if err:\n            conn.append_error(err)\n            return\n\n        # ask clients to delete this RUN\n        message = new_message(conn, topic=TrainingTopic.DELETE_RUN, body=\"\")\n        message.set_header(RequestHeader.JOB_ID, str(job_id))\n        clients = engine.get_clients()\n        if clients:\n            conn.set_prop(self.TARGET_CLIENT_TOKENS, [x.token for x in clients])\n            replies = self.send_request_to_clients(conn, message)\n            self.process_replies_to_table(conn, replies)\n\n        conn.append_success(\"\")",
  "def authorize_deploy_app(self, conn: Connection, args: List[str]):\n        if len(args) < 4:\n            conn.append_error(\"syntax error: missing job_id and target\")\n            return False, None\n\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        err = self.validate_command_targets(conn, args[3:])\n        if err:\n            conn.append_error(err)\n            return False, None\n\n        run_destination = args[1].lower()\n        if not run_destination.startswith(WorkspaceConstants.WORKSPACE_PREFIX):\n            conn.append_error(\"syntax error: run_destination must be run_XXX\")\n            return False, None\n        destination = run_destination[len(WorkspaceConstants.WORKSPACE_PREFIX) :]\n        conn.set_prop(self.JOB_ID, destination)\n\n        app_name = args[2]\n        app_staging_path = engine.get_staging_path_of_app(app_name)\n        if not app_staging_path:\n            conn.append_error(\"App {} does not exist. Please upload it first\".format(app_name))\n            return False, None\n\n        conn.set_prop(self.APP_STAGING_PATH, app_staging_path)\n        target_type = args[3]\n\n        if target_type == self.TARGET_TYPE_SERVER:\n            sites = [self.SITE_SERVER]\n        else:\n            sites = []\n            client_names = conn.get_prop(self.TARGET_CLIENT_NAMES)\n            if client_names:\n                sites.extend(client_names)\n\n            if target_type == self.TARGET_TYPE_ALL:\n                sites.append(self.SITE_SERVER)\n\n        err, authz_ctx = AppAuthzService.authorize_deploy(app_staging_path, sites)\n        if err:\n            conn.append_error(err)\n            return False, None\n        else:\n\n            return True, authz_ctx",
  "def _deploy_to_clients(self, conn: Connection, app_name, job_id) -> bool:\n        # return True if successful\n        engine = conn.app_ctx\n        err, app_data = engine.get_app_data(app_name)\n        if err:\n            conn.append_error(err)\n            return False\n\n        message = new_message(conn, topic=TrainingTopic.DEPLOY, body=app_data)\n        message.set_header(RequestHeader.JOB_ID, str(job_id))\n        message.set_header(RequestHeader.APP_NAME, app_name)\n        replies = self.send_request_to_clients(conn, message)\n        self.process_replies_to_table(conn, replies)\n        return True",
  "def _deploy_to_server(self, conn, job_id, app_name, app_staging_path) -> bool:\n        # return True if successful\n        engine = conn.app_ctx\n        err = engine.deploy_app_to_server(job_id, app_name, app_staging_path)\n        if not err:\n            conn.append_string('deployed app \"{}\" to Server'.format(app_name))\n            return True\n        else:\n            conn.append_error(err)\n            return False",
  "def deploy_app(self, conn: Connection, args: List[str]):\n        app_name = args[2]\n\n        job_id = conn.get_prop(self.JOB_ID)\n        target_type = conn.get_prop(self.TARGET_TYPE)\n        app_staging_path = conn.get_prop(self.APP_STAGING_PATH)\n        if target_type == self.TARGET_TYPE_SERVER:\n            if not self._deploy_to_server(conn, job_id, app_name, app_staging_path):\n                return\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            if not self._deploy_to_clients(conn, app_name, job_id):\n                return\n        else:\n            # all\n            success = self._deploy_to_server(conn, job_id, app_name, app_staging_path)\n            if success:\n                client_names = conn.get_prop(self.TARGET_CLIENT_NAMES, None)\n                if client_names:\n                    if not self._deploy_to_clients(conn, app_name, job_id):\n                        return\n            else:\n                return\n        conn.append_success(\"\")",
  "def _start_app_on_server(self, conn: Connection, job_id: str) -> bool:\n        engine = conn.app_ctx\n        err = engine.start_app_on_server(job_id)\n        if err:\n            conn.append_error(err)\n            return False\n        else:\n            conn.append_string(\"Server app is starting....\")\n            return True",
  "def _start_app_on_clients(self, conn: Connection, job_id: str) -> bool:\n        engine = conn.app_ctx\n        err = engine.check_app_start_readiness(job_id)\n        if err:\n            conn.append_error(err)\n            return False\n\n        # run_info = engine.get_run_info()\n        message = new_message(conn, topic=TrainingTopic.START, body=\"\")\n        # message.set_header(RequestHeader.JOB_ID, str(run_info.job_id))\n        message.set_header(RequestHeader.JOB_ID, job_id)\n        replies = self.send_request_to_clients(conn, message)\n        self.process_replies_to_table(conn, replies)\n        return True",
  "def start_app(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        job_id = conn.get_prop(self.JOB_ID)\n        target_type = args[2]\n        if target_type == self.TARGET_TYPE_SERVER:\n            if not self._start_app_on_server(conn, job_id):\n                return\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            if not self._start_app_on_clients(conn, job_id):\n                return\n        else:\n            # all\n            success = self._start_app_on_server(conn, job_id)\n\n            if success:\n                client_names = conn.get_prop(self.TARGET_CLIENT_NAMES, None)\n                if client_names:\n                    if not self._start_app_on_clients(conn, job_id):\n                        return\n        conn.append_success(\"\")",
  "def _abort_clients(self, conn, clients: List[str], job_id) -> bool:\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        err = engine.abort_app_on_clients(clients)\n        if err:\n            conn.append_error(err)\n            return False\n\n        # run_info = engine.get_app_run_info(job_id)\n        message = new_message(conn, topic=TrainingTopic.ABORT, body=\"\")\n        # if run_info:\n        message.set_header(RequestHeader.JOB_ID, str(job_id))\n\n        # conn.set_prop(self.TARGET_CLIENT_NAMES, client_names)\n        replies = self.send_request_to_clients(conn, message)\n        self.process_replies_to_table(conn, replies)\n        return True",
  "def abort_app(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        job_id = conn.get_prop(self.JOB_ID)\n        target_type = args[2]\n        if target_type == self.TARGET_TYPE_SERVER or target_type == self.TARGET_TYPE_ALL:\n            conn.append_string(\"Trying to abort all clients before abort server ...\")\n            clients = engine.get_clients()\n            if clients:\n                tokens = [c.token for c in clients]\n                conn.set_prop(\n                    self.TARGET_CLIENT_TOKENS, tokens\n                )  # need this because not set in validate_command_targets when target_type == self.TARGET_TYPE_SERVER\n                if not self._abort_clients(conn, clients=[c.token for c in clients], job_id=job_id):\n                    return\n            err = engine.abort_app_on_server(job_id)\n            if err:\n                conn.append_error(err)\n                return\n            conn.append_string(\"Abort signal has been sent to the server app.\")\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            clients = conn.get_prop(self.TARGET_CLIENT_TOKENS)\n            if not clients:\n                conn.append_string(\"No clients to abort\")\n                return\n            if not self._abort_clients(conn, clients, job_id):\n                return\n        conn.append_success(\"\")",
  "def abort_task(self, conn, clients: List[str]) -> str:\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        job_id = conn.get_prop(self.JOB_ID)\n        # run_info = engine.get_app_run_info()\n        message = new_message(conn, topic=TrainingTopic.ABORT_TASK, body=\"\")\n        # if run_info:\n        message.set_header(RequestHeader.JOB_ID, str(job_id))\n\n        # conn.set_prop(self.TARGET_CLIENT_NAMES, client_names)\n        replies = self.send_request_to_clients(conn, message)\n        return self.process_replies_to_table(conn, replies)",
  "def _shutdown_app_on_server(self, conn: Connection) -> bool:\n        engine = conn.app_ctx\n        err = engine.shutdown_server()\n        if err:\n            conn.append_error(err)\n            return False\n        else:\n            conn.append_string(\"FL app has been shutdown.\")\n            conn.append_shutdown(\"Bye bye\")\n            return True",
  "def _shutdown_app_on_clients(self, conn: Connection) -> bool:\n        engine = conn.app_ctx\n        message = new_message(conn, topic=TrainingTopic.SHUTDOWN, body=\"\")\n        clients = conn.get_prop(self.TARGET_CLIENT_TOKENS, None)\n        if not clients:\n            conn.append_error(\"no clients to shutdown\")\n            return False\n\n        replies = self.send_request_to_clients(conn, message)\n        self.process_replies_to_table(conn, replies)\n\n        err = engine.remove_clients(clients)\n        if err:\n            conn.append_error(err)\n            return False\n        return True",
  "def shutdown(self, conn: Connection, args: List[str]):\n        target_type = args[1]\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngine):\n            raise TypeError(\"engine must be ServerEngine but got {}\".format(type(engine)))\n\n        if engine.job_runner.running_jobs:\n            conn.append_error(\"There are still jobs running. Please let them finish or abort_job before shutdown.\")\n            return\n\n        if target_type == self.TARGET_TYPE_SERVER:\n            if engine.get_clients():\n                conn.append_error(\"There are still active clients. Shutdown all clients first.\")\n                return\n            if not self._shutdown_app_on_server(conn):\n                return\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            if not self._shutdown_app_on_clients(conn):\n                return\n        else:\n            # all\n            if engine.get_clients():\n                conn.append_string(\"Trying to shutdown clients before server...\")\n                success = self._shutdown_app_on_clients(conn)\n                if success:\n                    if not self._shutdown_app_on_server(conn):\n                        return\n            else:\n                if not self._shutdown_app_on_server(conn):\n                    return\n        conn.append_success(\"\")",
  "def authorize_remove_client(self, conn: Connection, args: List[str]):\n        if len(args) < 2:\n            conn.append_error(\"syntax error: missing site names\")\n            return False, None\n\n        auth_args = [args[0], self.TARGET_TYPE_CLIENT]\n        auth_args.extend(args[1:])\n        return self.authorize_operate(conn, auth_args)",
  "def authorize_abort_client(self, conn: Connection, args: List[str]):\n        if len(args) < 3:\n            conn.append_error(\"syntax error: missing job_id and target\")\n            return False, None\n\n        run_destination = args[1].lower()\n        if not run_destination.startswith(WorkspaceConstants.WORKSPACE_PREFIX):\n            conn.append_error(\"syntax error: run_destination must be run_XXX\")\n            return False, None\n        job_id = run_destination[len(WorkspaceConstants.WORKSPACE_PREFIX) :]\n        conn.set_prop(self.JOB_ID, job_id)\n\n        auth_args = [args[0], self.TARGET_TYPE_CLIENT]\n        auth_args.extend(args[2:])\n        return self.authorize_operate(conn, auth_args)",
  "def remove_client(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n        clients = conn.get_prop(self.TARGET_CLIENT_TOKENS)\n        err = engine.remove_clients(clients)\n        if err:\n            conn.append_error(err)\n            return\n        conn.append_success(\"\")",
  "def _restart_clients(self, conn, clients) -> str:\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n        engine.remove_clients(clients)\n        message = new_message(conn, topic=TrainingTopic.RESTART, body=\"\")\n        replies = self.send_request_to_clients(conn, message)\n        return self._process_replies_to_string(conn, replies)",
  "def restart(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngine):\n            raise TypeError(\"engine must be ServerEngine but got {}\".format(type(engine)))\n\n        if engine.job_runner.running_jobs:\n            conn.append_error(\"There are still jobs running. Please let them finish or abort_job before restart.\")\n            return\n\n        target_type = args[1]\n        if target_type == self.TARGET_TYPE_SERVER or target_type == self.TARGET_TYPE_ALL:\n\n            clients = engine.get_clients()\n            if clients:\n                conn.append_string(\"Trying to restart all clients before restarting server...\")\n                tokens = [c.token for c in clients]\n                conn.set_prop(\n                    self.TARGET_CLIENT_TOKENS, tokens\n                )  # need this because not set in validate_command_targets when target_type == self.TARGET_TYPE_SERVER\n                response = self._restart_clients(conn, tokens)\n                conn.append_string(response)\n                # check with Isaac - no need to wait!\n                # time.sleep(5)\n\n            err = engine.restart_server()\n            if err:\n                conn.append_error(err)\n            else:\n                conn.append_string(\"Server scheduled for restart\")\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            clients = conn.get_prop(self.TARGET_CLIENT_TOKENS)\n            if not clients:\n                conn.append_error(\"no clients available\")\n                return\n            else:\n                response = self._restart_clients(conn, clients)\n                conn.append_string(response)\n        conn.append_success(\"\")",
  "def authorize_set_timeout(self, conn: Connection, args: List[str]):\n        if len(args) != 2:\n            conn.append_error(\"syntax error: missing timeout\")\n            return False, None\n\n        try:\n            num = float(args[1])\n        except ValueError:\n            conn.append_error(\"must provide the timeout value in seconds\")\n            return False, None\n\n        if num <= 0:\n            conn.append_error(\"timeout must be > 0\")\n            return False, None\n\n        return True, FLAuthzContext.new_authz_context(site_names=[self.SITE_SERVER], actions=[Action.TRAIN])",
  "def set_timeout(self, conn: Connection, args: List[str]):\n        timeout = float(args[1])\n        server = conn.server\n        server.timeout = timeout\n        conn.append_string(\"admin command timeout has been set to: {}\".format(timeout))\n        conn.append_success(\"\")",
  "def check_status(self, conn: Connection, args: List[str]):\n        # TODO:: Need more discussion on what status to be shown\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n        dst = args[1]\n        if dst == self.TARGET_TYPE_SERVER:\n            engine_info = engine.get_engine_info()\n            conn.append_string(f\"Engine status: {engine_info.status.value}\")\n            table = conn.append_table([\"Job_id\", \"App Name\"])\n            for job_id, app_name in engine_info.app_names.items():\n                table.add_row([job_id, app_name])\n\n            clients = engine.get_clients()\n            conn.append_string(\"Registered clients: {} \".format(len(clients)))\n\n            if clients:\n                table = conn.append_table([\"Client\", \"Token\", \"Last Connect Time\"])\n                for c in clients:\n                    if not isinstance(c, Client):\n                        raise TypeError(\"c must be Client but got {}\".format(type(c)))\n                    table.add_row([c.name, str(c.token), time.asctime(time.localtime(c.last_connect_time))])\n        elif dst == self.TARGET_TYPE_CLIENT:\n            message = new_message(conn, topic=TrainingTopic.CHECK_STATUS, body=\"\")\n            replies = self.send_request_to_clients(conn, message)\n            self._process_status_replies(conn, replies)\n        else:\n            conn.append_error(\"invalid target type {}. Usage: check_status server|client ...\".format(dst))",
  "def _process_status_replies(self, conn, replies):\n        if not replies:\n            conn.append_error(\"no responses from clients\")\n            return\n\n        engine = conn.app_ctx\n        table = conn.append_table([\"client\", \"app_name\", \"job_id\", \"status\"])\n        for r in replies:\n            job_id = \"?\"\n            app_name = \"?\"\n            client_name = engine.get_client_name_from_token(r.client_token)\n\n            if r.reply:\n                try:\n                    body = json.loads(r.reply.body)\n                    if r.reply and isinstance(body, dict):\n                        running_jobs = body.get(ClientStatusKey.RUNNING_JOBS)\n                        if running_jobs:\n                            for job in running_jobs:\n                                app_name = job.get(ClientStatusKey.APP_NAME, \"?\")\n                                job_id = job.get(ClientStatusKey.JOB_ID, \"?\")\n                                status = job.get(ClientStatusKey.STATUS, \"?\")\n                                table.add_row([client_name, app_name, job_id, status])\n                        else:\n                            table.add_row([client_name, app_name, job_id, \"No Jobs\"])\n                except BaseException as ex:\n                    self.logger.error(f\"Bad reply from client: {ex}\")\n            else:\n                table.add_row([client_name, app_name, job_id, \"No Reply\"])",
  "class JobCommandModule(TrainingCommandModule, CommandUtil):\n    \"\"\"Command module with commands for job management.\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=\"job_mgmt\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"list_jobs\",\n                    description=\"list submitted jobs\",\n                    usage=\"list_jobs [-n name_prefix] [-d] [job_id_prefix]\",\n                    handler_func=self.list_jobs,\n                ),\n                CommandSpec(\n                    name=\"delete_job\",\n                    description=\"delete a job and persisted workspace\",\n                    usage=\"delete_job job_id\",\n                    handler_func=self.delete_job,\n                    authz_func=self.authorize_job,\n                ),\n                CommandSpec(\n                    name=\"abort_job\",\n                    description=\"abort a job if it is running or dispatched\",\n                    usage=\"abort_job job_id\",\n                    handler_func=self.abort_job,  # see if running, if running, send abort command\n                    authz_func=self.authorize_job,\n                ),\n                CommandSpec(\n                    name=\"clone_job\",\n                    description=\"clone a job with a new job_id\",\n                    usage=\"clone_job job_id\",\n                    handler_func=self.clone_job,\n                    authz_func=self.authorize_job,\n                ),\n            ],\n        )\n\n    def authorize_job(self, conn: Connection, args: List[str]):\n        if len(args) != 2:\n            conn.append_error(\"syntax error: missing job_id\")\n            return False, None\n\n        job_id = args[1].lower()\n        conn.set_prop(self.JOB_ID, job_id)\n        engine = conn.app_ctx\n        job_def_manager = engine.job_def_manager\n\n        with engine.new_context() as fl_ctx:\n            job = job_def_manager.get_job(job_id, fl_ctx)\n\n        if not job:\n            conn.append_error(f\"Job with ID {job_id} doesn't exist\")\n            return False, None\n\n        return self.authorize_job_meta(conn, job.meta, [Action.TRAIN])\n\n    def list_jobs(self, conn: Connection, args: List[str]):\n\n        try:\n            parser = SafeArgumentParser(prog=\"list_jobs\")\n            parser.add_argument(\"job_id\", nargs=\"?\", help=\"Job ID prefix\")\n            parser.add_argument(\"-d\", action=\"store_true\", help=\"Show detailed list\")\n            parser.add_argument(\"-n\", help=\"Filter by job name prefix\")\n            parsed_args = parser.parse_args(args[1:])\n\n            engine = conn.app_ctx\n            job_def_manager = engine.job_def_manager\n            if not isinstance(job_def_manager, JobDefManagerSpec):\n                raise TypeError(\n                    f\"job_def_manager in engine is not of type JobDefManagerSpec, but got {type(job_def_manager)}\"\n                )\n\n            with engine.new_context() as fl_ctx:\n                jobs = job_def_manager.get_all_jobs(fl_ctx)\n            if jobs:\n                id_prefix = parsed_args.job_id\n                name_prefix = parsed_args.n\n\n                filtered_jobs = [job for job in jobs if self._job_match(job.meta, id_prefix, name_prefix)]\n                if not filtered_jobs:\n                    conn.append_error(\"No jobs matching the searching criteria\")\n                    return\n\n                # Can't use authz_func so do authorization one by one\n                authorized_jobs = [job for job in filtered_jobs if self._job_authorized(conn, job)]\n\n                authorized_jobs.sort(key=lambda job: job.meta.get(JobMetaKey.SUBMIT_TIME, 0.0))\n\n                if parsed_args.d:\n                    self._send_detail_list(conn, authorized_jobs)\n                else:\n                    self._send_summary_list(conn, authorized_jobs)\n\n                diff = set([job.job_id for job in filtered_jobs]) - set([job.job_id for job in authorized_jobs])\n                if diff:\n                    self.logger.debug(f\"Following jobs are not authorized for listing: {diff}\")\n                    conn.append_string(\"Some jobs are not listed due to permission restrictions\")\n            else:\n                conn.append_string(\"No jobs.\")\n        except Exception as e:\n            conn.append_error(str(e))\n            return\n\n        conn.append_success(\"\")\n\n    def delete_job(self, conn: Connection, args: List[str]):\n        job_id = conn.get_prop(self.JOB_ID)\n        engine = conn.app_ctx\n        try:\n            if not isinstance(engine, ServerEngine):\n                raise TypeError(f\"engine is not of type ServerEngine, but got {type(engine)}\")\n            job_def_manager = engine.job_def_manager\n            if not isinstance(job_def_manager, JobDefManagerSpec):\n                raise TypeError(\n                    f\"job_def_manager in engine is not of type JobDefManagerSpec, but got {type(job_def_manager)}\"\n                )\n            with engine.new_context() as fl_ctx:\n                job = job_def_manager.get_job(job_id, fl_ctx)\n                if not job:\n                    conn.append_error(f\"job: {job_id} does not exist\")\n                    return\n                if job.meta.get(JobMetaKey.STATUS, \"\") in [RunStatus.DISPATCHED.value, RunStatus.RUNNING.value]:\n                    conn.append_error(f\"job: {job_id} is running, could not be deleted at this time.\")\n                    return\n\n                job_def_manager.delete(job_id, fl_ctx)\n            conn.append_string(\"Job {} deleted.\".format(job_id))\n        except Exception as e:\n            conn.append_error(\"exception occurred: \" + str(e))\n            return\n        conn.append_success(\"\")\n\n    def abort_job(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        job_runner = engine.job_runner\n\n        try:\n            job_id = conn.get_prop(self.JOB_ID)\n            job_runner.stop_run(job_id, engine.new_context())\n            conn.append_string(\"Abort signal has been sent to the server app.\")\n            conn.append_success(\"\")\n        except Exception as e:\n            conn.append_error(\"Exception occurred trying to abort job: \" + str(e))\n            return\n\n    def clone_job(self, conn: Connection, args: List[str]):\n        job_id = conn.get_prop(self.JOB_ID)\n        engine = conn.app_ctx\n        try:\n            if not isinstance(engine, ServerEngine):\n                raise TypeError(f\"engine is not of type ServerEngine, but got {type(engine)}\")\n            job_def_manager = engine.job_def_manager\n            if not isinstance(job_def_manager, JobDefManagerSpec):\n                raise TypeError(\n                    f\"job_def_manager in engine is not of type JobDefManagerSpec, but got {type(job_def_manager)}\"\n                )\n            with engine.new_context() as fl_ctx:\n                job = job_def_manager.get_job(job_id, fl_ctx)\n                data_bytes = job_def_manager.get_content(job_id, fl_ctx)\n                meta = job_def_manager.create(job.meta, data_bytes, fl_ctx)\n                conn.append_string(\"Cloned job {} as: {}\".format(job_id, meta.get(JobMetaKey.JOB_ID)))\n        except Exception as e:\n            conn.append_error(\"Exception occurred trying to clone job: \" + str(e))\n            return\n        conn.append_success(\"\")\n\n    @staticmethod\n    def _job_match(job_meta: Dict, id_prefix: str, name_prefix: str) -> bool:\n        return ((not id_prefix) or job_meta.get(\"job_id\").lower().startswith(id_prefix.lower())) and (\n            (not name_prefix) or job_meta.get(\"name\").lower().startswith(name_prefix.lower())\n        )\n\n    @staticmethod\n    def _send_detail_list(conn: Connection, jobs: List[Job]):\n        for job in jobs:\n            JobCommandModule._set_duration(job)\n            conn.append_string(json.dumps(job.meta, indent=4))\n\n    @staticmethod\n    def _send_summary_list(conn: Connection, jobs: List[Job]):\n\n        table = Table([\"Job ID\", \"Name\", \"Status\", \"Submit Time\", \"Run Duration\"])\n        for job in jobs:\n            JobCommandModule._set_duration(job)\n            table.add_row(\n                [\n                    job.meta.get(JobMetaKey.JOB_ID, \"\"),\n                    CommandUtil.get_job_name(job.meta),\n                    job.meta.get(JobMetaKey.STATUS, \"\"),\n                    job.meta.get(JobMetaKey.SUBMIT_TIME_ISO, \"\"),\n                    str(job.meta.get(JobMetaKey.DURATION, \"N/A\")),\n                ]\n            )\n\n        writer = io.StringIO()\n        table.write(writer)\n        conn.append_string(writer.getvalue())\n\n    @staticmethod\n    def _set_duration(job):\n        if job.meta.get(JobMetaKey.STATUS) == RunStatus.RUNNING.value:\n            start_time = datetime.datetime.strptime(job.meta.get(JobMetaKey.START_TIME), \"%Y-%m-%d %H:%M:%S.%f\")\n            duration = datetime.datetime.now() - start_time\n            job.meta[JobMetaKey.DURATION] = str(duration)\n\n    def _job_authorized(self, conn: Connection, job: Job) -> bool:\n\n        valid, authz_ctx = self.authorize_job_meta(conn, job.meta, [Action.VIEW])\n        if not valid:\n            return False\n\n        authz_ctx.user_name = conn.get_prop(ConnProps.USER_NAME, \"\")\n        conn.set_prop(ConnProps.AUTHZ_CTX, authz_ctx)\n        authorizer = AuthorizationService.get_authorizer()\n        authorized, err = authorizer.authorize(ctx=authz_ctx)\n        if err:\n            self.logger.debug(\"Authorization Error to view job {}: {}\".format(job.job_id, err))\n            return False\n\n        if not authorized:\n            self.logger.debug(f\"View action for job {job.job_id} is not authorized\")\n            return False\n\n        return True",
  "def __init__(self):\n        super().__init__()\n        self.logger = logging.getLogger(self.__class__.__name__)",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=\"job_mgmt\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"list_jobs\",\n                    description=\"list submitted jobs\",\n                    usage=\"list_jobs [-n name_prefix] [-d] [job_id_prefix]\",\n                    handler_func=self.list_jobs,\n                ),\n                CommandSpec(\n                    name=\"delete_job\",\n                    description=\"delete a job and persisted workspace\",\n                    usage=\"delete_job job_id\",\n                    handler_func=self.delete_job,\n                    authz_func=self.authorize_job,\n                ),\n                CommandSpec(\n                    name=\"abort_job\",\n                    description=\"abort a job if it is running or dispatched\",\n                    usage=\"abort_job job_id\",\n                    handler_func=self.abort_job,  # see if running, if running, send abort command\n                    authz_func=self.authorize_job,\n                ),\n                CommandSpec(\n                    name=\"clone_job\",\n                    description=\"clone a job with a new job_id\",\n                    usage=\"clone_job job_id\",\n                    handler_func=self.clone_job,\n                    authz_func=self.authorize_job,\n                ),\n            ],\n        )",
  "def authorize_job(self, conn: Connection, args: List[str]):\n        if len(args) != 2:\n            conn.append_error(\"syntax error: missing job_id\")\n            return False, None\n\n        job_id = args[1].lower()\n        conn.set_prop(self.JOB_ID, job_id)\n        engine = conn.app_ctx\n        job_def_manager = engine.job_def_manager\n\n        with engine.new_context() as fl_ctx:\n            job = job_def_manager.get_job(job_id, fl_ctx)\n\n        if not job:\n            conn.append_error(f\"Job with ID {job_id} doesn't exist\")\n            return False, None\n\n        return self.authorize_job_meta(conn, job.meta, [Action.TRAIN])",
  "def list_jobs(self, conn: Connection, args: List[str]):\n\n        try:\n            parser = SafeArgumentParser(prog=\"list_jobs\")\n            parser.add_argument(\"job_id\", nargs=\"?\", help=\"Job ID prefix\")\n            parser.add_argument(\"-d\", action=\"store_true\", help=\"Show detailed list\")\n            parser.add_argument(\"-n\", help=\"Filter by job name prefix\")\n            parsed_args = parser.parse_args(args[1:])\n\n            engine = conn.app_ctx\n            job_def_manager = engine.job_def_manager\n            if not isinstance(job_def_manager, JobDefManagerSpec):\n                raise TypeError(\n                    f\"job_def_manager in engine is not of type JobDefManagerSpec, but got {type(job_def_manager)}\"\n                )\n\n            with engine.new_context() as fl_ctx:\n                jobs = job_def_manager.get_all_jobs(fl_ctx)\n            if jobs:\n                id_prefix = parsed_args.job_id\n                name_prefix = parsed_args.n\n\n                filtered_jobs = [job for job in jobs if self._job_match(job.meta, id_prefix, name_prefix)]\n                if not filtered_jobs:\n                    conn.append_error(\"No jobs matching the searching criteria\")\n                    return\n\n                # Can't use authz_func so do authorization one by one\n                authorized_jobs = [job for job in filtered_jobs if self._job_authorized(conn, job)]\n\n                authorized_jobs.sort(key=lambda job: job.meta.get(JobMetaKey.SUBMIT_TIME, 0.0))\n\n                if parsed_args.d:\n                    self._send_detail_list(conn, authorized_jobs)\n                else:\n                    self._send_summary_list(conn, authorized_jobs)\n\n                diff = set([job.job_id for job in filtered_jobs]) - set([job.job_id for job in authorized_jobs])\n                if diff:\n                    self.logger.debug(f\"Following jobs are not authorized for listing: {diff}\")\n                    conn.append_string(\"Some jobs are not listed due to permission restrictions\")\n            else:\n                conn.append_string(\"No jobs.\")\n        except Exception as e:\n            conn.append_error(str(e))\n            return\n\n        conn.append_success(\"\")",
  "def delete_job(self, conn: Connection, args: List[str]):\n        job_id = conn.get_prop(self.JOB_ID)\n        engine = conn.app_ctx\n        try:\n            if not isinstance(engine, ServerEngine):\n                raise TypeError(f\"engine is not of type ServerEngine, but got {type(engine)}\")\n            job_def_manager = engine.job_def_manager\n            if not isinstance(job_def_manager, JobDefManagerSpec):\n                raise TypeError(\n                    f\"job_def_manager in engine is not of type JobDefManagerSpec, but got {type(job_def_manager)}\"\n                )\n            with engine.new_context() as fl_ctx:\n                job = job_def_manager.get_job(job_id, fl_ctx)\n                if not job:\n                    conn.append_error(f\"job: {job_id} does not exist\")\n                    return\n                if job.meta.get(JobMetaKey.STATUS, \"\") in [RunStatus.DISPATCHED.value, RunStatus.RUNNING.value]:\n                    conn.append_error(f\"job: {job_id} is running, could not be deleted at this time.\")\n                    return\n\n                job_def_manager.delete(job_id, fl_ctx)\n            conn.append_string(\"Job {} deleted.\".format(job_id))\n        except Exception as e:\n            conn.append_error(\"exception occurred: \" + str(e))\n            return\n        conn.append_success(\"\")",
  "def abort_job(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        job_runner = engine.job_runner\n\n        try:\n            job_id = conn.get_prop(self.JOB_ID)\n            job_runner.stop_run(job_id, engine.new_context())\n            conn.append_string(\"Abort signal has been sent to the server app.\")\n            conn.append_success(\"\")\n        except Exception as e:\n            conn.append_error(\"Exception occurred trying to abort job: \" + str(e))\n            return",
  "def clone_job(self, conn: Connection, args: List[str]):\n        job_id = conn.get_prop(self.JOB_ID)\n        engine = conn.app_ctx\n        try:\n            if not isinstance(engine, ServerEngine):\n                raise TypeError(f\"engine is not of type ServerEngine, but got {type(engine)}\")\n            job_def_manager = engine.job_def_manager\n            if not isinstance(job_def_manager, JobDefManagerSpec):\n                raise TypeError(\n                    f\"job_def_manager in engine is not of type JobDefManagerSpec, but got {type(job_def_manager)}\"\n                )\n            with engine.new_context() as fl_ctx:\n                job = job_def_manager.get_job(job_id, fl_ctx)\n                data_bytes = job_def_manager.get_content(job_id, fl_ctx)\n                meta = job_def_manager.create(job.meta, data_bytes, fl_ctx)\n                conn.append_string(\"Cloned job {} as: {}\".format(job_id, meta.get(JobMetaKey.JOB_ID)))\n        except Exception as e:\n            conn.append_error(\"Exception occurred trying to clone job: \" + str(e))\n            return\n        conn.append_success(\"\")",
  "def _job_match(job_meta: Dict, id_prefix: str, name_prefix: str) -> bool:\n        return ((not id_prefix) or job_meta.get(\"job_id\").lower().startswith(id_prefix.lower())) and (\n            (not name_prefix) or job_meta.get(\"name\").lower().startswith(name_prefix.lower())\n        )",
  "def _send_detail_list(conn: Connection, jobs: List[Job]):\n        for job in jobs:\n            JobCommandModule._set_duration(job)\n            conn.append_string(json.dumps(job.meta, indent=4))",
  "def _send_summary_list(conn: Connection, jobs: List[Job]):\n\n        table = Table([\"Job ID\", \"Name\", \"Status\", \"Submit Time\", \"Run Duration\"])\n        for job in jobs:\n            JobCommandModule._set_duration(job)\n            table.add_row(\n                [\n                    job.meta.get(JobMetaKey.JOB_ID, \"\"),\n                    CommandUtil.get_job_name(job.meta),\n                    job.meta.get(JobMetaKey.STATUS, \"\"),\n                    job.meta.get(JobMetaKey.SUBMIT_TIME_ISO, \"\"),\n                    str(job.meta.get(JobMetaKey.DURATION, \"N/A\")),\n                ]\n            )\n\n        writer = io.StringIO()\n        table.write(writer)\n        conn.append_string(writer.getvalue())",
  "def _set_duration(job):\n        if job.meta.get(JobMetaKey.STATUS) == RunStatus.RUNNING.value:\n            start_time = datetime.datetime.strptime(job.meta.get(JobMetaKey.START_TIME), \"%Y-%m-%d %H:%M:%S.%f\")\n            duration = datetime.datetime.now() - start_time\n            job.meta[JobMetaKey.DURATION] = str(duration)",
  "def _job_authorized(self, conn: Connection, job: Job) -> bool:\n\n        valid, authz_ctx = self.authorize_job_meta(conn, job.meta, [Action.VIEW])\n        if not valid:\n            return False\n\n        authz_ctx.user_name = conn.get_prop(ConnProps.USER_NAME, \"\")\n        conn.set_prop(ConnProps.AUTHZ_CTX, authz_ctx)\n        authorizer = AuthorizationService.get_authorizer()\n        authorized, err = authorizer.authorize(ctx=authz_ctx)\n        if err:\n            self.logger.debug(\"Authorization Error to view job {}: {}\".format(job.job_id, err))\n            return False\n\n        if not authorized:\n            self.logger.debug(f\"View action for job {job.job_id} is not authorized\")\n            return False\n\n        return True",
  "class SystemCommandModule(CommandModule, CommandUtil):\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=\"sys\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"sys_info\",\n                    description=\"get the system info\",\n                    usage=\"sys_info server|client <client-name> ...\",\n                    handler_func=self.sys_info,\n                    authz_func=self.authorize_operate,\n                    visible=True,\n                ),\n            ],\n        )\n\n    def sys_info(self, conn: Connection, args: [str]):\n        if len(args) < 2:\n            conn.append_error(\"syntax error: missing site names\")\n            return\n\n        target_type = args[1]\n        if target_type == self.TARGET_TYPE_SERVER:\n            infos = dict(psutil.virtual_memory()._asdict())\n\n            table = conn.append_table([\"Metrics\", \"Value\"])\n\n            for k, v in infos.items():\n                table.add_row([str(k), str(v)])\n            table.add_row(\n                [\n                    \"available_percent\",\n                    \"%.1f\" % (psutil.virtual_memory().available * 100 / psutil.virtual_memory().total),\n                ]\n            )\n            return\n\n        if target_type == self.TARGET_TYPE_CLIENT:\n            message = new_message(conn, topic=SysCommandTopic.SYS_INFO, body=\"\")\n            replies = self.send_request_to_clients(conn, message)\n            self._process_replies(conn, replies)\n            return\n\n        conn.append_string(\"invalid target type {}. Usage: sys_info server|client <client-name>\".format(target_type))\n\n    def _process_replies(self, conn, replies):\n        if not replies:\n            conn.append_error(\"no responses from clients\")\n            return\n\n        engine = conn.app_ctx\n        for r in replies:\n            client_name = engine.get_client_name_from_token(r.client_token)\n            conn.append_string(\"Client: \" + client_name)\n\n            if r.reply:\n                try:\n                    infos = json.loads(r.reply.body)\n                    table = conn.append_table([\"Metrics\", \"Value\"])\n\n                    for k, v in infos.items():\n                        table.add_row([str(k), str(v)])\n                    table.add_row(\n                        [\n                            \"available_percent\",\n                            \"%.1f\" % (psutil.virtual_memory().available * 100 / psutil.virtual_memory().total),\n                        ]\n                    )\n                except BaseException:\n                    conn.append_string(\": Bad replies\")\n            else:\n                conn.append_string(\": No replies\")",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=\"sys\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"sys_info\",\n                    description=\"get the system info\",\n                    usage=\"sys_info server|client <client-name> ...\",\n                    handler_func=self.sys_info,\n                    authz_func=self.authorize_operate,\n                    visible=True,\n                ),\n            ],\n        )",
  "def sys_info(self, conn: Connection, args: [str]):\n        if len(args) < 2:\n            conn.append_error(\"syntax error: missing site names\")\n            return\n\n        target_type = args[1]\n        if target_type == self.TARGET_TYPE_SERVER:\n            infos = dict(psutil.virtual_memory()._asdict())\n\n            table = conn.append_table([\"Metrics\", \"Value\"])\n\n            for k, v in infos.items():\n                table.add_row([str(k), str(v)])\n            table.add_row(\n                [\n                    \"available_percent\",\n                    \"%.1f\" % (psutil.virtual_memory().available * 100 / psutil.virtual_memory().total),\n                ]\n            )\n            return\n\n        if target_type == self.TARGET_TYPE_CLIENT:\n            message = new_message(conn, topic=SysCommandTopic.SYS_INFO, body=\"\")\n            replies = self.send_request_to_clients(conn, message)\n            self._process_replies(conn, replies)\n            return\n\n        conn.append_string(\"invalid target type {}. Usage: sys_info server|client <client-name>\".format(target_type))",
  "def _process_replies(self, conn, replies):\n        if not replies:\n            conn.append_error(\"no responses from clients\")\n            return\n\n        engine = conn.app_ctx\n        for r in replies:\n            client_name = engine.get_client_name_from_token(r.client_token)\n            conn.append_string(\"Client: \" + client_name)\n\n            if r.reply:\n                try:\n                    infos = json.loads(r.reply.body)\n                    table = conn.append_table([\"Metrics\", \"Value\"])\n\n                    for k, v in infos.items():\n                        table.add_row([str(k), str(v)])\n                    table.add_row(\n                        [\n                            \"available_percent\",\n                            \"%.1f\" % (psutil.virtual_memory().available * 100 / psutil.virtual_memory().total),\n                        ]\n                    )\n                except BaseException:\n                    conn.append_string(\": Bad replies\")\n            else:\n                conn.append_string(\": No replies\")",
  "class ServerCommandModules:\n    cmd_modules = [\n        ShellCommandModule(),\n        SystemCommandModule(),\n        TrainingCommandModule(),\n        JobCommandModule(),\n        InfoCollectorCommandModule(),\n    ]\n\n    @staticmethod\n    def register_cmd_module(cmd_module: CommandModule):\n        ServerCommandModules.cmd_modules.append(cmd_module)",
  "def register_cmd_module(cmd_module: CommandModule):\n        ServerCommandModules.cmd_modules.append(cmd_module)",
  "class AppAuthzService(object):\n\n    app_validator = None\n\n    @staticmethod\n    def initialize(app_validator):\n        if app_validator and not isinstance(app_validator, AppValidator):\n            raise TypeError(f\"app_validator must be an instance of AppValidator, but get {type(app_validator)}.\")\n        AppAuthzService.app_validator = app_validator\n\n    @staticmethod\n    def _authorize_actions(app_path: str, sites: [str], actions) -> (str, AuthzContext):\n        if AppAuthzService.app_validator:\n            err, info = AppAuthzService.app_validator.validate(app_path)\n            if err:\n                return err, None\n\n            byoc = info.get(AppValidationKey.BYOC, False)\n            custom_datalist = info.get(AppValidationKey.CUSTOM_DATA_LIST, False)\n            if byoc:\n                actions.append(Action.BYOC)\n            if custom_datalist:\n                actions.append(Action.CUSTOM_DATALIST)\n\n        return \"\", FLAuthzContext.new_authz_context(site_names=sites, actions=actions)\n\n    @staticmethod\n    def authorize_upload(app_path: str) -> (str, AuthzContext):\n        return AppAuthzService._authorize_actions(app_path, [\"server\"], [Action.UPLOAD])\n\n    @staticmethod\n    def authorize_deploy(app_path: str, sites: [str]) -> (str, AuthzContext):\n        return AppAuthzService._authorize_actions(app_path, sites, [Action.DEPLOY])",
  "def initialize(app_validator):\n        if app_validator and not isinstance(app_validator, AppValidator):\n            raise TypeError(f\"app_validator must be an instance of AppValidator, but get {type(app_validator)}.\")\n        AppAuthzService.app_validator = app_validator",
  "def _authorize_actions(app_path: str, sites: [str], actions) -> (str, AuthzContext):\n        if AppAuthzService.app_validator:\n            err, info = AppAuthzService.app_validator.validate(app_path)\n            if err:\n                return err, None\n\n            byoc = info.get(AppValidationKey.BYOC, False)\n            custom_datalist = info.get(AppValidationKey.CUSTOM_DATA_LIST, False)\n            if byoc:\n                actions.append(Action.BYOC)\n            if custom_datalist:\n                actions.append(Action.CUSTOM_DATALIST)\n\n        return \"\", FLAuthzContext.new_authz_context(site_names=sites, actions=actions)",
  "def authorize_upload(app_path: str) -> (str, AuthzContext):\n        return AppAuthzService._authorize_actions(app_path, [\"server\"], [Action.UPLOAD])",
  "def authorize_deploy(app_path: str, sites: [str]) -> (str, AuthzContext):\n        return AppAuthzService._authorize_actions(app_path, sites, [Action.DEPLOY])",
  "class CommandProcessor(object):\n    \"\"\"The CommandProcessor is responsible for processing a command from parent process.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"Get command name that this processor will handle.\n\n        Returns: name of the command\n\n        \"\"\"\n        pass\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the specified command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Return: reply message\n\n        \"\"\"\n        pass",
  "class AbortCommand(CommandProcessor):\n    \"\"\"To implement the abort command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.ABORT\n\n        \"\"\"\n        return AdminCommandNames.ABORT\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: abort command message\n\n        \"\"\"\n        server_runner = fl_ctx.get_prop(FLContextKey.RUNNER)\n        server_runner.abort(fl_ctx)\n        # wait for the runner process gracefully abort the run.\n        time.sleep(3.0)\n        return \"Aborted the run\"",
  "class GetRunInfoCommand(CommandProcessor):\n    \"\"\"To implement the abort command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: ServerCommandNames.GET_RUN_INFO\n\n        \"\"\"\n        return ServerCommandNames.GET_RUN_INFO\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: Engine run_info\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        return engine.get_run_info()",
  "class GetTaskCommand(CommandProcessor):\n    \"\"\"To implement the server GetTask command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: ServerCommandNames.GET_TASK\n\n        \"\"\"\n        return ServerCommandNames.GET_TASK\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: task data\n\n        \"\"\"\n\n        shared_fl_ctx = data.get_header(ServerCommandKey.PEER_FL_CONTEXT)\n        client = data.get_header(ServerCommandKey.FL_CLIENT)\n        fl_ctx.set_peer_context(shared_fl_ctx)\n        server_runner = fl_ctx.get_prop(FLContextKey.RUNNER)\n        taskname, task_id, shareable = server_runner.process_task_request(client, fl_ctx)\n        data = {\n            ServerCommandKey.TASK_NAME: taskname,\n            ServerCommandKey.TASK_ID: task_id,\n            ServerCommandKey.SHAREABLE: shareable,\n            ServerCommandKey.FL_CONTEXT: copy.deepcopy(get_serializable_data(fl_ctx).props),\n        }\n        return pickle.dumps(data)",
  "class SubmitUpdateCommand(CommandProcessor):\n    \"\"\"To implement the server GetTask command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: ServerCommandNames.SUBMIT_UPDATE\n\n        \"\"\"\n        return ServerCommandNames.SUBMIT_UPDATE\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns:\n\n        \"\"\"\n\n        shared_fl_ctx = data.get_header(ServerCommandKey.PEER_FL_CONTEXT)\n        client = data.get_header(ServerCommandKey.FL_CLIENT)\n        fl_ctx.set_peer_context(shared_fl_ctx)\n        contribution_task_name = data.get_header(ServerCommandKey.TASK_NAME)\n        task_id = data.get_cookie(FLContextKey.TASK_ID)\n        server_runner = fl_ctx.get_prop(FLContextKey.RUNNER)\n        server_runner.process_submission(client, contribution_task_name, task_id, data, fl_ctx)\n\n        return \"\"",
  "class AuxCommunicateCommand(CommandProcessor):\n    \"\"\"To implement the server GetTask command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: ServerCommandNames.AUX_COMMUNICATE\n\n        \"\"\"\n        return ServerCommandNames.AUX_COMMUNICATE\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: task data\n\n        \"\"\"\n\n        shared_fl_ctx = data.get_header(ServerCommandKey.PEER_FL_CONTEXT)\n        topic = data.get_header(ServerCommandKey.TOPIC)\n        shareable = data.get_header(ServerCommandKey.SHAREABLE)\n        fl_ctx.set_peer_context(shared_fl_ctx)\n\n        engine = fl_ctx.get_engine()\n        reply = engine.dispatch(topic=topic, request=shareable, fl_ctx=fl_ctx)\n\n        data = {\n            ServerCommandKey.AUX_REPLY: reply,\n            ServerCommandKey.FL_CONTEXT: copy.deepcopy(get_serializable_data(fl_ctx).props),\n        }\n        return data",
  "class ShowStatsCommand(CommandProcessor):\n    \"\"\"To implement the show_stats command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: ServerCommandNames.SHOW_STATS\n\n        \"\"\"\n        return ServerCommandNames.SHOW_STATS\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: Engine run_info\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        collector = engine.get_widget(WidgetID.INFO_COLLECTOR)\n        return collector.get_run_stats()",
  "class GetErrorsCommand(CommandProcessor):\n    \"\"\"To implement the show_errors command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: ServerCommandNames.GET_ERRORS\n\n        \"\"\"\n        return ServerCommandNames.GET_ERRORS\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: Engine run_info\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        collector = engine.get_widget(WidgetID.INFO_COLLECTOR)\n        errors = collector.get_errors()\n        if not errors:\n            errors = \"No Error\"\n        return errors",
  "class ByeCommand(CommandProcessor):\n    \"\"\"To implement the ShutdownCommand.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.SHUTDOWN\n\n        \"\"\"\n        return AdminCommandNames.SHUTDOWN\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the Shutdown command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: Shutdown command message\n\n        \"\"\"\n        return None",
  "class ServerCommands(object):\n    \"\"\"AdminCommands contains all the commands for processing the commands from the parent process.\"\"\"\n\n    commands = [\n        AbortCommand(),\n        ByeCommand(),\n        GetRunInfoCommand(),\n        GetTaskCommand(),\n        SubmitUpdateCommand(),\n        AuxCommunicateCommand(),\n        ShowStatsCommand(),\n        GetErrorsCommand(),\n    ]\n\n    @staticmethod\n    def get_command(command_name):\n        \"\"\"Call to return the AdminCommand object.\n\n        Args:\n            command_name: AdminCommand name\n\n        Returns: AdminCommand object\n\n        \"\"\"\n        for command in ServerCommands.commands:\n            if command_name == command.get_command_name():\n                return command\n        return None\n\n    @staticmethod\n    def register_command(command_processor: CommandProcessor):\n        \"\"\"Call to register the AdminCommand processor.\n\n        Args:\n            command_processor: AdminCommand processor\n\n        \"\"\"\n        if not isinstance(command_processor, CommandProcessor):\n            raise TypeError(\n                \"command_processor must be an instance of CommandProcessor, but got {}\".format(type(command_processor))\n            )\n\n        ServerCommands.commands.append(command_processor)",
  "def get_command_name(self) -> str:\n        \"\"\"Get command name that this processor will handle.\n\n        Returns: name of the command\n\n        \"\"\"\n        pass",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the specified command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Return: reply message\n\n        \"\"\"\n        pass",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.ABORT\n\n        \"\"\"\n        return AdminCommandNames.ABORT",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: abort command message\n\n        \"\"\"\n        server_runner = fl_ctx.get_prop(FLContextKey.RUNNER)\n        server_runner.abort(fl_ctx)\n        # wait for the runner process gracefully abort the run.\n        time.sleep(3.0)\n        return \"Aborted the run\"",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: ServerCommandNames.GET_RUN_INFO\n\n        \"\"\"\n        return ServerCommandNames.GET_RUN_INFO",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: Engine run_info\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        return engine.get_run_info()",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: ServerCommandNames.GET_TASK\n\n        \"\"\"\n        return ServerCommandNames.GET_TASK",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: task data\n\n        \"\"\"\n\n        shared_fl_ctx = data.get_header(ServerCommandKey.PEER_FL_CONTEXT)\n        client = data.get_header(ServerCommandKey.FL_CLIENT)\n        fl_ctx.set_peer_context(shared_fl_ctx)\n        server_runner = fl_ctx.get_prop(FLContextKey.RUNNER)\n        taskname, task_id, shareable = server_runner.process_task_request(client, fl_ctx)\n        data = {\n            ServerCommandKey.TASK_NAME: taskname,\n            ServerCommandKey.TASK_ID: task_id,\n            ServerCommandKey.SHAREABLE: shareable,\n            ServerCommandKey.FL_CONTEXT: copy.deepcopy(get_serializable_data(fl_ctx).props),\n        }\n        return pickle.dumps(data)",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: ServerCommandNames.SUBMIT_UPDATE\n\n        \"\"\"\n        return ServerCommandNames.SUBMIT_UPDATE",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns:\n\n        \"\"\"\n\n        shared_fl_ctx = data.get_header(ServerCommandKey.PEER_FL_CONTEXT)\n        client = data.get_header(ServerCommandKey.FL_CLIENT)\n        fl_ctx.set_peer_context(shared_fl_ctx)\n        contribution_task_name = data.get_header(ServerCommandKey.TASK_NAME)\n        task_id = data.get_cookie(FLContextKey.TASK_ID)\n        server_runner = fl_ctx.get_prop(FLContextKey.RUNNER)\n        server_runner.process_submission(client, contribution_task_name, task_id, data, fl_ctx)\n\n        return \"\"",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: ServerCommandNames.AUX_COMMUNICATE\n\n        \"\"\"\n        return ServerCommandNames.AUX_COMMUNICATE",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: task data\n\n        \"\"\"\n\n        shared_fl_ctx = data.get_header(ServerCommandKey.PEER_FL_CONTEXT)\n        topic = data.get_header(ServerCommandKey.TOPIC)\n        shareable = data.get_header(ServerCommandKey.SHAREABLE)\n        fl_ctx.set_peer_context(shared_fl_ctx)\n\n        engine = fl_ctx.get_engine()\n        reply = engine.dispatch(topic=topic, request=shareable, fl_ctx=fl_ctx)\n\n        data = {\n            ServerCommandKey.AUX_REPLY: reply,\n            ServerCommandKey.FL_CONTEXT: copy.deepcopy(get_serializable_data(fl_ctx).props),\n        }\n        return data",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: ServerCommandNames.SHOW_STATS\n\n        \"\"\"\n        return ServerCommandNames.SHOW_STATS",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: Engine run_info\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        collector = engine.get_widget(WidgetID.INFO_COLLECTOR)\n        return collector.get_run_stats()",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: ServerCommandNames.GET_ERRORS\n\n        \"\"\"\n        return ServerCommandNames.GET_ERRORS",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: Engine run_info\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        collector = engine.get_widget(WidgetID.INFO_COLLECTOR)\n        errors = collector.get_errors()\n        if not errors:\n            errors = \"No Error\"\n        return errors",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.SHUTDOWN\n\n        \"\"\"\n        return AdminCommandNames.SHUTDOWN",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the Shutdown command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: Shutdown command message\n\n        \"\"\"\n        return None",
  "def get_command(command_name):\n        \"\"\"Call to return the AdminCommand object.\n\n        Args:\n            command_name: AdminCommand name\n\n        Returns: AdminCommand object\n\n        \"\"\"\n        for command in ServerCommands.commands:\n            if command_name == command.get_command_name():\n                return command\n        return None",
  "def register_command(command_processor: CommandProcessor):\n        \"\"\"Call to register the AdminCommand processor.\n\n        Args:\n            command_processor: AdminCommand processor\n\n        \"\"\"\n        if not isinstance(command_processor, CommandProcessor):\n            raise TypeError(\n                \"command_processor must be an instance of CommandProcessor, but got {}\".format(type(command_processor))\n            )\n\n        ServerCommands.commands.append(command_processor)",
  "class BaseServer(ABC):\n    def __init__(\n        self,\n        project_name=None,\n        min_num_clients=2,\n        max_num_clients=10,\n        heart_beat_timeout=600,\n        handlers: Optional[List[FLComponent]] = None,\n    ):\n        \"\"\"Base server that provides the clients management and server deployment.\"\"\"\n        self.project_name = project_name\n        self.min_num_clients = max(min_num_clients, 1)\n        self.max_num_clients = max(max_num_clients, 1)\n\n        self.heart_beat_timeout = heart_beat_timeout\n        self.handlers = handlers\n        # self.cmd_modules = cmd_modules\n\n        self.client_manager = ClientManager(\n            project_name=self.project_name, min_num_clients=self.min_num_clients, max_num_clients=self.max_num_clients\n        )\n\n        self.grpc_server = None\n        self.admin_server = None\n        self.lock = Lock()\n        self.snapshot_lock = Lock()\n        self.fl_ctx = FLContext()\n        self.platform = None\n\n        self.shutdown = False\n        self.status = ServerStatus.NOT_STARTED\n\n        self.abort_signal = None\n        self.executor = None\n\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    def get_all_clients(self):\n        return self.client_manager.get_clients()\n\n    @abstractmethod\n    def remove_client_data(self, token):\n        pass\n\n    def close(self):\n        \"\"\"Shutdown the server.\"\"\"\n        try:\n            if self.lock:\n                self.lock.release()\n        except RuntimeError:\n            self.logger.info(\"canceling sync locks\")\n        try:\n            if self.grpc_server:\n                self.grpc_server.stop(0)\n        finally:\n            self.logger.info(\"server off\")\n            return 0\n\n    def deploy(self, args, grpc_args=None, secure_train=False):\n        \"\"\"Start a grpc server and listening the designated port.\"\"\"\n        num_server_workers = grpc_args.get(\"num_server_workers\", 1)\n        num_server_workers = max(self.client_manager.get_min_clients(), num_server_workers)\n        target = grpc_args[\"service\"].get(\"target\", \"0.0.0.0:6007\")\n        grpc_options = grpc_args[\"service\"].get(\"options\", GRPC_DEFAULT_OPTIONS)\n\n        compression = grpc.Compression.NoCompression\n        if \"Deflate\" == grpc_args.get(\"compression\"):\n            compression = grpc.Compression.Deflate\n        elif \"Gzip\" == grpc_args.get(\"compression\"):\n            compression = grpc.Compression.Gzip\n\n        if not self.grpc_server:\n            self.executor = futures.ThreadPoolExecutor(max_workers=num_server_workers)\n            self.grpc_server = grpc.server(\n                self.executor,\n                options=grpc_options,\n                compression=compression,\n            )\n            fed_service.add_FederatedTrainingServicer_to_server(self, self.grpc_server)\n            admin_service.add_AdminCommunicatingServicer_to_server(self, self.grpc_server)\n\n        if secure_train:\n            with open(grpc_args[\"ssl_private_key\"], \"rb\") as f:\n                private_key = f.read()\n            with open(grpc_args[\"ssl_cert\"], \"rb\") as f:\n                certificate_chain = f.read()\n            with open(grpc_args[\"ssl_root_cert\"], \"rb\") as f:\n                root_ca = f.read()\n\n            server_credentials = grpc.ssl_server_credentials(\n                (\n                    (\n                        private_key,\n                        certificate_chain,\n                    ),\n                ),\n                root_certificates=root_ca,\n                require_client_auth=True,\n            )\n            self.grpc_server.add_secure_port(target, server_credentials)\n            self.logger.info(\"starting secure server at %s\", target)\n        else:\n            self.grpc_server.add_insecure_port(target)\n            self.logger.info(\"starting insecure server at %s\", target)\n        self.grpc_server.start()\n\n        # return self.start()\n        cleanup_thread = threading.Thread(target=self.client_cleanup)\n        # heartbeat_thread.daemon = True\n        cleanup_thread.start()\n\n    def client_cleanup(self):\n        while not self.shutdown:\n            self.remove_dead_clients()\n            time.sleep(15)\n\n    def set_admin_server(self, admin_server):\n        self.admin_server = admin_server\n\n    def remove_dead_clients(self):\n        # Clean and remove the dead client without heartbeat.\n        self.logger.debug(\"trying to remove dead clients .......\")\n        delete = []\n        for token, client in self.client_manager.get_clients().items():\n            if client.last_connect_time < time.time() - self.heart_beat_timeout:\n                delete.append(token)\n        for token in delete:\n            client = self.client_manager.remove_client(token)\n            self.remove_client_data(token)\n            if self.admin_server:\n                self.admin_server.client_dead(token)\n            self.logger.info(\n                \"Remove the dead Client. Name: {}\\t Token: {}.  Total clients: {}\".format(\n                    client.name, token, len(self.client_manager.get_clients())\n                )\n            )\n\n    def fl_shutdown(self):\n        self.shutdown = True\n        self.close()\n        if self.executor:\n            self.executor.shutdown()",
  "class FederatedServer(BaseServer, fed_service.FederatedTrainingServicer, admin_service.AdminCommunicatingServicer):\n    def __init__(\n        self,\n        project_name=None,\n        min_num_clients=2,\n        max_num_clients=10,\n        wait_after_min_clients=10,\n        cmd_modules=None,\n        heart_beat_timeout=600,\n        handlers: Optional[List[FLComponent]] = None,\n        args=None,\n        secure_train=False,\n        enable_byoc=False,\n        snapshot_persistor=None,\n        overseer_agent=None,\n    ):\n        \"\"\"Federated server services.\n\n        Args:\n            project_name: server project name.\n            min_num_clients: minimum number of contributors at each round.\n            max_num_clients: maximum number of contributors at each round.\n            wait_after_min_clients: wait time after minimum clients responded.\n            cmd_modules: command modules.\n            heart_beat_timeout: heartbeat timeout\n            handlers: A list of handler\n            args: arguments\n            secure_train: whether to use secure communication\n            enable_byoc: whether to enable custom components\n        \"\"\"\n        self.logger = logging.getLogger(\"FederatedServer\")\n\n        BaseServer.__init__(\n            self,\n            project_name=project_name,\n            min_num_clients=min_num_clients,\n            max_num_clients=max_num_clients,\n            heart_beat_timeout=heart_beat_timeout,\n            handlers=handlers,\n        )\n\n        self.contributed_clients = {}\n        self.tokens = None\n        self.round_started = Timestamp()\n\n        with self.lock:\n            self.reset_tokens()\n\n        self.wait_after_min_clients = wait_after_min_clients\n\n        self.cmd_modules = cmd_modules\n\n        self.builder = None\n\n        # Additional fields for CurrentTask meta_data in GetModel API.\n        self.current_model_meta_data = {}\n\n        self.engine = ServerEngine(\n            server=self, args=args, client_manager=self.client_manager, snapshot_persistor=snapshot_persistor\n        )\n        self.run_manager = None\n        self.server_runner = None\n\n        self.processors = {}\n        self.runner_config = None\n        self.secure_train = secure_train\n        self.enable_byoc = enable_byoc\n\n        self.workspace = args.workspace\n        self.snapshot_location = None\n        self.overseer_agent = overseer_agent\n        self.server_state: ServerState = ColdState()\n        self.snapshot_persistor = snapshot_persistor\n\n    def get_current_model_meta_data(self):\n        \"\"\"Get the model metadata, which usually contains additional fields.\"\"\"\n        s = Struct()\n        for k, v in self.current_model_meta_data.items():\n            s.update({k: v})\n        return s\n\n    @property\n    def task_meta_info(self):\n        \"\"\"Task meta information.\n\n        The model_meta_info uniquely defines the current model,\n        it is used to reject outdated client's update.\n        \"\"\"\n        meta_info = fed_msg.MetaData()\n        meta_info.created.CopyFrom(self.round_started)\n        meta_info.project.name = self.project_name\n        return meta_info\n\n    def remove_client_data(self, token):\n        self.tokens.pop(token, None)\n\n    def reset_tokens(self):\n        \"\"\"Reset the token set.\n\n        After resetting, each client can take a token\n        and start fetching the current global model.\n        This function is not thread-safe.\n        \"\"\"\n        self.tokens = dict()\n        for client in self.get_all_clients().keys():\n            self.tokens[client] = self.task_meta_info\n\n    def Register(self, request, context):\n        \"\"\"Register new clients on the fly.\n\n        Each client must get registered before getting the global model.\n        The server will expect updates from the registered clients\n        for multiple federated rounds.\n\n        This function does not change min_num_clients and max_num_clients.\n        \"\"\"\n\n        with self.engine.new_context() as fl_ctx:\n            state_check = self.server_state.register(fl_ctx)\n            self._handle_state_check(context, state_check)\n\n            token = self.client_manager.authenticate(request, context)\n            if token:\n                self.tokens[token] = self.task_meta_info\n                if self.admin_server:\n                    self.admin_server.client_heartbeat(token)\n\n                return fed_msg.FederatedSummary(\n                    comment=\"New client registered\", token=token, ssid=self.server_state.ssid\n                )\n\n    def _handle_state_check(self, context, state_check):\n        if state_check.get(ACTION) == NIS:\n            context.abort(\n                grpc.StatusCode.FAILED_PRECONDITION,\n                state_check.get(MESSAGE),\n            )\n        elif state_check.get(ACTION) == ABORT_RUN:\n            context.abort(\n                grpc.StatusCode.ABORTED,\n                state_check.get(MESSAGE),\n            )\n\n    def _ssid_check(self, client_state, context):\n        if client_state.ssid != self.server_state.ssid:\n            context.abort(grpc.StatusCode.UNAUTHENTICATED, \"Invalid Service session ID\")\n\n    def Quit(self, request, context):\n        \"\"\"Existing client quits the federated training process.\n\n        Server will stop sharing the global model with the client,\n        further contribution will be rejected.\n\n        This function does not change min_num_clients and max_num_clients.\n        \"\"\"\n        # fire_event(EventType.CLIENT_QUIT, self.handlers, self.fl_ctx)\n\n        client = self.client_manager.validate_client(request, context)\n        if client:\n            token = client.get_token()\n\n            _ = self.client_manager.remove_client(token)\n            self.tokens.pop(token, None)\n            if self.admin_server:\n                self.admin_server.client_dead(token)\n\n        return fed_msg.FederatedSummary(comment=\"Removed client\")\n\n    def GetTask(self, request, context):\n        \"\"\"Process client's get task request.\"\"\"\n\n        with self.engine.new_context() as fl_ctx:\n            state_check = self.server_state.get_task(fl_ctx)\n            self._handle_state_check(context, state_check)\n            self._ssid_check(request, context)\n\n            client = self.client_manager.validate_client(request, context)\n            if client is None:\n                context.abort(grpc.StatusCode.FAILED_PRECONDITION, \"Client not valid.\")\n\n            self.logger.debug(f\"Fetch task requested from client: {client.name} ({client.get_token()})\")\n            token = client.get_token()\n\n            # engine = fl_ctx.get_engine()\n            shared_fl_ctx = pickle.loads(proto_to_bytes(request.context[\"fl_context\"]))\n            job_id = str(shared_fl_ctx.get_prop(FLContextKey.CURRENT_RUN))\n            # fl_ctx.set_peer_context(shared_fl_ctx)\n\n            with self.lock:\n                # if self.server_runner is None or engine is None or self.engine.run_manager is None:\n                if job_id not in self.engine.run_processes.keys():\n                    self.logger.info(\"server has no current run - asked client to end the run\")\n                    task_name = SpecialTaskName.END_RUN\n                    task_id = \"\"\n                    shareable = None\n                else:\n                    shareable, task_id, task_name = self._process_task_request(client, fl_ctx, shared_fl_ctx)\n\n                    # task_name, task_id, shareable = self.server_runner.process_task_request(client, fl_ctx)\n\n                if shareable is None:\n                    shareable = Shareable()\n\n                task = fed_msg.CurrentTask(task_name=task_name)\n                task.meta.CopyFrom(self.task_meta_info)\n                meta_data = self.get_current_model_meta_data()\n\n                # we need TASK_ID back as a cookie\n                shareable.add_cookie(name=FLContextKey.TASK_ID, data=task_id)\n\n                # we also need to make TASK_ID available to the client\n                shareable.set_header(key=FLContextKey.TASK_ID, value=task_id)\n\n                task.meta_data.CopyFrom(meta_data)\n\n                current_model = shareable_to_modeldata(shareable, fl_ctx)\n                task.data.CopyFrom(current_model)\n                if task_name == SpecialTaskName.TRY_AGAIN:\n                    self.logger.debug(f\"GetTask: Return task: {task_name} to client: {client.name} ({token}) \")\n                else:\n                    self.logger.info(f\"GetTask: Return task: {task_name} to client: {client.name} ({token}) \")\n\n                return task\n\n    def _process_task_request(self, client, fl_ctx, shared_fl_ctx):\n        task_name = SpecialTaskName.END_RUN\n        task_id = \"\"\n        shareable = None\n        try:\n            with self.engine.lock:\n                job_id = shared_fl_ctx.get_prop(FLContextKey.CURRENT_RUN)\n                command_conn = self.engine.get_command_conn(str(job_id))\n                if command_conn:\n                    command_shareable = Shareable()\n                    command_shareable.set_header(ServerCommandKey.PEER_FL_CONTEXT, shared_fl_ctx)\n                    command_shareable.set_header(ServerCommandKey.FL_CLIENT, client)\n\n                    data = {\n                        ServerCommandKey.COMMAND: ServerCommandNames.GET_TASK,\n                        ServerCommandKey.DATA: command_shareable,\n                    }\n                    command_conn.send(data)\n\n                    return_data = pickle.loads(command_conn.recv())\n                    task_name = return_data.get(ServerCommandKey.TASK_NAME)\n                    task_id = return_data.get(ServerCommandKey.TASK_ID)\n                    shareable = return_data.get(ServerCommandKey.SHAREABLE)\n                    child_fl_ctx = return_data.get(ServerCommandKey.FL_CONTEXT)\n\n                    fl_ctx.props.update(child_fl_ctx)\n        except BaseException as e:\n            self.logger.info(f\"Could not connect to server runner process: {e} - asked client to end the run\")\n        return shareable, task_id, task_name\n\n    def SubmitUpdate(self, request, context):\n        \"\"\"Handle client's submission of the federated updates.\"\"\"\n        # if self.server_runner is None or self.engine.run_manager is None:\n\n        with self.engine.new_context() as fl_ctx:\n            state_check = self.server_state.submit_result(fl_ctx)\n            self._handle_state_check(context, state_check)\n            self._ssid_check(request.client, context)\n\n            contribution = request\n\n            client = self.client_manager.validate_client(contribution.client, context)\n            if client is None:\n                response_comment = \"Ignored the submit from invalid client. \"\n                self.logger.info(response_comment)\n            else:\n                with self.lock:\n                    shareable = Shareable.from_bytes(proto_to_bytes(request.data.params[\"data\"]))\n                    shared_fl_context = pickle.loads(proto_to_bytes(request.data.params[\"fl_context\"]))\n\n                    job_id = str(shared_fl_context.get_prop(FLContextKey.CURRENT_RUN))\n                    if job_id not in self.engine.run_processes.keys():\n                        self.logger.info(\"ignored result submission since Server Engine isn't ready\")\n                        context.abort(grpc.StatusCode.OUT_OF_RANGE, \"Server has stopped\")\n\n                    shared_fl_context.set_prop(FLContextKey.SHAREABLE, shareable, private=False)\n\n                    contribution_meta = contribution.client.meta\n                    client_contrib_id = \"{}_{}_{}\".format(\n                        contribution_meta.project.name, client.name, contribution_meta.current_round\n                    )\n                    contribution_task_name = contribution.task_name\n\n                    timenow = Timestamp()\n                    timenow.GetCurrentTime()\n                    time_seconds = timenow.seconds - self.round_started.seconds\n                    self.logger.info(\n                        \"received update from %s (%s Bytes, %s seconds)\",\n                        client_contrib_id,\n                        contribution.ByteSize(),\n                        time_seconds or \"less than 1\",\n                    )\n\n                    task_id = shareable.get_cookie(FLContextKey.TASK_ID)\n                    shareable.set_header(ServerCommandKey.PEER_FL_CONTEXT, shared_fl_context)\n                    shareable.set_header(ServerCommandKey.FL_CLIENT, client)\n                    shareable.set_header(ServerCommandKey.TASK_NAME, contribution_task_name)\n\n                    self._submit_update(shareable, shared_fl_context)\n\n                    # self.server_runner.process_submission(client, contribution_task_name, task_id, shareable, fl_ctx)\n\n            response_comment = \"Received from {} ({} Bytes, {} seconds)\".format(\n                contribution.client.client_name,\n                contribution.ByteSize(),\n                time_seconds or \"less than 1\",\n            )\n            summary_info = fed_msg.FederatedSummary(comment=response_comment)\n            summary_info.meta.CopyFrom(self.task_meta_info)\n\n            return summary_info\n\n    def _submit_update(self, shareable, shared_fl_context):\n        try:\n            with self.engine.lock:\n                job_id = shared_fl_context.get_prop(FLContextKey.CURRENT_RUN)\n                command_conn = self.engine.get_command_conn(str(job_id))\n                if command_conn:\n                    data = {\n                        ServerCommandKey.COMMAND: ServerCommandNames.SUBMIT_UPDATE,\n                        ServerCommandKey.DATA: shareable,\n                    }\n                    command_conn.send(data)\n        except BaseException:\n            self.logger.info(\"Could not connect to server runner process - asked client to end the run\")\n\n    def AuxCommunicate(self, request, context):\n        \"\"\"Handle auxiliary channel communication.\"\"\"\n        with self.engine.new_context() as fl_ctx:\n            state_check = self.server_state.aux_communicate(fl_ctx)\n            self._handle_state_check(context, state_check)\n            self._ssid_check(request.client, context)\n\n            contribution = request\n\n            client = self.client_manager.validate_client(contribution.client, context)\n            if client is None:\n                response_comment = \"Ignored the submit from invalid client. \"\n                self.logger.info(response_comment)\n\n            shareable = Shareable()\n            shareable = shareable.from_bytes(proto_to_bytes(request.data[\"data\"]))\n            shared_fl_context = pickle.loads(proto_to_bytes(request.data[\"fl_context\"]))\n\n            job_id = str(shared_fl_context.get_prop(FLContextKey.CURRENT_RUN))\n            if job_id not in self.engine.run_processes.keys():\n                self.logger.info(\"ignored AuxCommunicate request since Server Engine isn't ready\")\n                reply = make_reply(ReturnCode.SERVER_NOT_READY)\n                aux_reply = fed_msg.AuxReply()\n                aux_reply.data.CopyFrom(shareable_to_modeldata(reply, fl_ctx))\n\n                return aux_reply\n\n            fl_ctx.set_peer_context(shared_fl_context)\n            shareable.set_peer_props(shared_fl_context.get_all_public_props())\n\n            shared_fl_context.set_prop(FLContextKey.SHAREABLE, shareable, private=False)\n\n            topic = shareable.get_header(ReservedHeaderKey.TOPIC)\n\n            reply = self._aux_communicate(fl_ctx, shareable, shared_fl_context, topic)\n\n            # reply = self.engine.dispatch(topic=topic, request=shareable, fl_ctx=fl_ctx)\n\n            aux_reply = fed_msg.AuxReply()\n            aux_reply.data.CopyFrom(shareable_to_modeldata(reply, fl_ctx))\n\n            return aux_reply\n\n    def _aux_communicate(self, fl_ctx, shareable, shared_fl_context, topic):\n        try:\n            with self.engine.lock:\n                job_id = shared_fl_context.get_prop(FLContextKey.CURRENT_RUN)\n                command_conn = self.engine.get_command_conn(str(job_id))\n                if command_conn:\n                    command_shareable = Shareable()\n                    command_shareable.set_header(ServerCommandKey.PEER_FL_CONTEXT, shared_fl_context)\n                    command_shareable.set_header(ServerCommandKey.TOPIC, topic)\n                    command_shareable.set_header(ServerCommandKey.SHAREABLE, shareable)\n\n                    data = {\n                        ServerCommandKey.COMMAND: ServerCommandNames.AUX_COMMUNICATE,\n                        ServerCommandKey.DATA: command_shareable,\n                    }\n                    command_conn.send(data)\n\n                    return_data = command_conn.recv()\n                    reply = return_data.get(ServerCommandKey.AUX_REPLY)\n                    child_fl_ctx = return_data.get(ServerCommandKey.FL_CONTEXT)\n\n                    fl_ctx.props.update(child_fl_ctx)\n                else:\n                    reply = make_reply(ReturnCode.ERROR)\n        except BaseException:\n            self.logger.info(\"Could not connect to server runner process - asked client to end the run\")\n            reply = make_reply(ReturnCode.COMMUNICATION_ERROR)\n\n        return reply\n\n    def Heartbeat(self, request, context):\n\n        with self.engine.new_context() as fl_ctx:\n            state_check = self.server_state.heartbeat(fl_ctx)\n            self._handle_state_check(context, state_check)\n\n            token = request.token\n            cn_names = context.auth_context().get(\"x509_common_name\")\n            if cn_names:\n                client_name = cn_names[0].decode(\"utf-8\")\n            else:\n                client_name = request.client_name\n\n            if self.client_manager.heartbeat(token, client_name, context):\n                self.tokens[token] = self.task_meta_info\n            if self.admin_server:\n                self.admin_server.client_heartbeat(token)\n\n            abort_runs = self._sync_client_jobs(request)\n            summary_info = fed_msg.FederatedSummary()\n            if abort_runs:\n                del summary_info.abort_jobs[:]\n                summary_info.abort_jobs.extend(abort_runs)\n                display_runs = \",\".join(abort_runs)\n                self.logger.info(\n                    f\"These jobs: {display_runs} are not running on the server. \"\n                    f\"Ask client: {client_name} to abort these runs.\"\n                )\n            return summary_info\n\n    def _sync_client_jobs(self, request):\n        client_jobs = request.jobs\n        server_jobs = self.engine.run_processes.keys()\n        jobs_need_abort = list(set(client_jobs).difference(server_jobs))\n        return jobs_need_abort\n\n    def Retrieve(self, request, context):\n        client_name = request.client_name\n        messages = self.admin_server.get_outgoing_requests(client_token=client_name) if self.admin_server else []\n\n        response = admin_msg.Messages()\n        for m in messages:\n            response.message.append(message_to_proto(m))\n        return response\n\n    def SendReply(self, request, context):\n        client_name = request.client_name\n        message = proto_to_message(request.message)\n        if self.admin_server:\n            self.admin_server.accept_reply(client_token=client_name, reply=message)\n\n        response = admin_msg.Empty()\n        return response\n\n    def SendResult(self, request, context):\n        client_name = request.client_name\n        message = proto_to_message(request.message)\n\n        processor = self.processors.get(message.topic)\n        processor.process(client_name, message)\n\n        response = admin_msg.Empty()\n        return response\n\n    def start_run(self, job_id, run_root, conf, args, snapshot):\n        # Create the FL Engine\n        workspace = Workspace(args.workspace, \"server\", args.config_folder)\n        self.run_manager = RunManager(\n            server_name=self.project_name,\n            engine=self.engine,\n            job_id=job_id,\n            workspace=workspace,\n            components=self.runner_config.components,\n            client_manager=self.client_manager,\n            handlers=self.runner_config.handlers,\n        )\n        self.engine.set_run_manager(self.run_manager)\n        self.engine.set_configurator(conf)\n        self.engine.asked_to_stop = False\n\n        fed_event_runner = ServerFedEventRunner()\n        self.run_manager.add_handler(fed_event_runner)\n\n        try:\n            self.server_runner = ServerRunner(config=self.runner_config, job_id=job_id, engine=self.engine)\n            self.run_manager.add_handler(self.server_runner)\n            self.run_manager.add_component(\"_Server_Runner\", self.server_runner)\n\n            with self.engine.new_context() as fl_ctx:\n\n                if snapshot:\n                    self.engine.restore_components(snapshot=snapshot, fl_ctx=FLContext())\n\n                fl_ctx.set_prop(FLContextKey.APP_ROOT, run_root, sticky=True)\n                fl_ctx.set_prop(FLContextKey.CURRENT_RUN, job_id, private=False, sticky=True)\n                fl_ctx.set_prop(FLContextKey.WORKSPACE_ROOT, args.workspace, private=True, sticky=True)\n                fl_ctx.set_prop(FLContextKey.ARGS, args, private=True, sticky=True)\n                fl_ctx.set_prop(FLContextKey.WORKSPACE_OBJECT, workspace, private=True)\n                fl_ctx.set_prop(FLContextKey.SECURE_MODE, self.secure_train, private=True, sticky=True)\n                fl_ctx.set_prop(FLContextKey.RUNNER, self.server_runner, private=True, sticky=True)\n\n            engine_thread = threading.Thread(target=self.run_engine)\n            engine_thread.start()\n\n            self.engine.engine_info.status = MachineStatus.STARTED\n            while self.engine.engine_info.status != MachineStatus.STOPPED:\n                if self.engine.asked_to_stop:\n                    self.engine.engine_info.status = MachineStatus.STOPPED\n\n                time.sleep(3)\n\n            if engine_thread.is_alive():\n                engine_thread.join()\n\n        finally:\n            self.engine.engine_info.status = MachineStatus.STOPPED\n            self.engine.run_manager = None\n            self.run_manager = None\n\n    def abort_run(self):\n        with self.engine.new_context() as fl_ctx:\n            if self.server_runner:\n                self.server_runner.abort(fl_ctx)\n\n    def run_engine(self):\n        self.engine.engine_info.status = MachineStatus.STARTED\n        self.server_runner.run()\n        self.engine.engine_info.status = MachineStatus.STOPPED\n\n    def deploy(self, args, grpc_args=None, secure_train=False):\n        super().deploy(args, grpc_args, secure_train)\n\n        target = grpc_args[\"service\"].get(\"target\", \"0.0.0.0:6007\")\n        self.server_state.host = target.split(\":\")[0]\n        self.server_state.service_port = target.split(\":\")[1]\n\n        self.overseer_agent = self._init_agent(args)\n\n        if secure_train:\n            if self.overseer_agent:\n                self.overseer_agent.set_secure_context(\n                    ca_path=grpc_args[\"ssl_root_cert\"],\n                    cert_path=grpc_args[\"ssl_cert\"],\n                    prv_key_path=grpc_args[\"ssl_private_key\"],\n                )\n\n        self.overseer_agent.start(self.overseer_callback)\n\n    def _init_agent(self, args=None):\n        kv_list = parse_vars(args.set)\n        sp = kv_list.get(\"sp\")\n\n        if sp:\n            with self.engine.new_context() as fl_ctx:\n                fl_ctx.set_prop(FLContextKey.SP_END_POINT, sp)\n                self.overseer_agent.initialize(fl_ctx)\n\n        return self.overseer_agent\n\n    def overseer_callback(self, overseer_agent):\n        if overseer_agent.is_shutdown():\n            self.engine.shutdown_server()\n            return\n\n        sp = overseer_agent.get_primary_sp()\n        # print(sp)\n        with self.engine.new_context() as fl_ctx:\n            self.server_state = self.server_state.handle_sd_callback(sp, fl_ctx)\n\n        if isinstance(self.server_state, Cold2HotState):\n            server_thread = threading.Thread(target=self._turn_to_hot)\n            server_thread.start()\n\n        if isinstance(self.server_state, Hot2ColdState):\n            server_thread = threading.Thread(target=self._turn_to_cold)\n            server_thread.start()\n\n    def _turn_to_hot(self):\n        # Restore Snapshot\n        with self.snapshot_lock:\n            fl_snapshot = self.snapshot_persistor.retrieve()\n            if fl_snapshot:\n                for run_number, snapshot in fl_snapshot.run_snapshots.items():\n                    if snapshot and not snapshot.completed:\n                        # Restore the workspace\n                        workspace_data = snapshot.get_component_snapshot(SnapshotKey.WORKSPACE).get(\"content\")\n                        dst = os.path.join(self.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(run_number))\n                        if os.path.exists(dst):\n                            shutil.rmtree(dst, ignore_errors=True)\n\n                        os.makedirs(dst, exist_ok=True)\n                        unzip_all_from_bytes(workspace_data, dst)\n\n                        job_id = snapshot.get_component_snapshot(SnapshotKey.JOB_INFO).get(SnapshotKey.JOB_ID)\n                        job_clients = snapshot.get_component_snapshot(SnapshotKey.JOB_INFO).get(SnapshotKey.JOB_CLIENTS)\n                        self.logger.info(f\"Restore the previous snapshot. Run_number: {run_number}\")\n                        with self.engine.new_context() as fl_ctx:\n                            job_runner = self.engine.job_runner\n                            job_runner.restore_running_job(\n                                run_number=run_number,\n                                job_id=job_id,\n                                job_clients=job_clients,\n                                snapshot=snapshot,\n                                fl_ctx=fl_ctx,\n                            )\n\n            self.server_state = HotState(\n                host=self.server_state.host, port=self.server_state.service_port, ssid=self.server_state.ssid\n            )\n\n    def _turn_to_cold(self):\n        # Wrap-up server operations\n        self.server_state = ColdState(host=self.server_state.host, port=self.server_state.service_port)\n\n    def stop_training(self):\n        self.status = ServerStatus.STOPPED\n        self.logger.info(\"Server app stopped.\\n\\n\")\n\n    def fl_shutdown(self):\n        self.engine.stop_all_jobs()\n        self.engine.fire_event(EventType.SYSTEM_END, self.engine.new_context())\n\n        super().fl_shutdown()\n\n    def close(self):\n        \"\"\"Shutdown the server.\"\"\"\n        self.logger.info(\"shutting down server\")\n        self.overseer_agent.end()\n        return super().close()",
  "def __init__(\n        self,\n        project_name=None,\n        min_num_clients=2,\n        max_num_clients=10,\n        heart_beat_timeout=600,\n        handlers: Optional[List[FLComponent]] = None,\n    ):\n        \"\"\"Base server that provides the clients management and server deployment.\"\"\"\n        self.project_name = project_name\n        self.min_num_clients = max(min_num_clients, 1)\n        self.max_num_clients = max(max_num_clients, 1)\n\n        self.heart_beat_timeout = heart_beat_timeout\n        self.handlers = handlers\n        # self.cmd_modules = cmd_modules\n\n        self.client_manager = ClientManager(\n            project_name=self.project_name, min_num_clients=self.min_num_clients, max_num_clients=self.max_num_clients\n        )\n\n        self.grpc_server = None\n        self.admin_server = None\n        self.lock = Lock()\n        self.snapshot_lock = Lock()\n        self.fl_ctx = FLContext()\n        self.platform = None\n\n        self.shutdown = False\n        self.status = ServerStatus.NOT_STARTED\n\n        self.abort_signal = None\n        self.executor = None\n\n        self.logger = logging.getLogger(self.__class__.__name__)",
  "def get_all_clients(self):\n        return self.client_manager.get_clients()",
  "def remove_client_data(self, token):\n        pass",
  "def close(self):\n        \"\"\"Shutdown the server.\"\"\"\n        try:\n            if self.lock:\n                self.lock.release()\n        except RuntimeError:\n            self.logger.info(\"canceling sync locks\")\n        try:\n            if self.grpc_server:\n                self.grpc_server.stop(0)\n        finally:\n            self.logger.info(\"server off\")\n            return 0",
  "def deploy(self, args, grpc_args=None, secure_train=False):\n        \"\"\"Start a grpc server and listening the designated port.\"\"\"\n        num_server_workers = grpc_args.get(\"num_server_workers\", 1)\n        num_server_workers = max(self.client_manager.get_min_clients(), num_server_workers)\n        target = grpc_args[\"service\"].get(\"target\", \"0.0.0.0:6007\")\n        grpc_options = grpc_args[\"service\"].get(\"options\", GRPC_DEFAULT_OPTIONS)\n\n        compression = grpc.Compression.NoCompression\n        if \"Deflate\" == grpc_args.get(\"compression\"):\n            compression = grpc.Compression.Deflate\n        elif \"Gzip\" == grpc_args.get(\"compression\"):\n            compression = grpc.Compression.Gzip\n\n        if not self.grpc_server:\n            self.executor = futures.ThreadPoolExecutor(max_workers=num_server_workers)\n            self.grpc_server = grpc.server(\n                self.executor,\n                options=grpc_options,\n                compression=compression,\n            )\n            fed_service.add_FederatedTrainingServicer_to_server(self, self.grpc_server)\n            admin_service.add_AdminCommunicatingServicer_to_server(self, self.grpc_server)\n\n        if secure_train:\n            with open(grpc_args[\"ssl_private_key\"], \"rb\") as f:\n                private_key = f.read()\n            with open(grpc_args[\"ssl_cert\"], \"rb\") as f:\n                certificate_chain = f.read()\n            with open(grpc_args[\"ssl_root_cert\"], \"rb\") as f:\n                root_ca = f.read()\n\n            server_credentials = grpc.ssl_server_credentials(\n                (\n                    (\n                        private_key,\n                        certificate_chain,\n                    ),\n                ),\n                root_certificates=root_ca,\n                require_client_auth=True,\n            )\n            self.grpc_server.add_secure_port(target, server_credentials)\n            self.logger.info(\"starting secure server at %s\", target)\n        else:\n            self.grpc_server.add_insecure_port(target)\n            self.logger.info(\"starting insecure server at %s\", target)\n        self.grpc_server.start()\n\n        # return self.start()\n        cleanup_thread = threading.Thread(target=self.client_cleanup)\n        # heartbeat_thread.daemon = True\n        cleanup_thread.start()",
  "def client_cleanup(self):\n        while not self.shutdown:\n            self.remove_dead_clients()\n            time.sleep(15)",
  "def set_admin_server(self, admin_server):\n        self.admin_server = admin_server",
  "def remove_dead_clients(self):\n        # Clean and remove the dead client without heartbeat.\n        self.logger.debug(\"trying to remove dead clients .......\")\n        delete = []\n        for token, client in self.client_manager.get_clients().items():\n            if client.last_connect_time < time.time() - self.heart_beat_timeout:\n                delete.append(token)\n        for token in delete:\n            client = self.client_manager.remove_client(token)\n            self.remove_client_data(token)\n            if self.admin_server:\n                self.admin_server.client_dead(token)\n            self.logger.info(\n                \"Remove the dead Client. Name: {}\\t Token: {}.  Total clients: {}\".format(\n                    client.name, token, len(self.client_manager.get_clients())\n                )\n            )",
  "def fl_shutdown(self):\n        self.shutdown = True\n        self.close()\n        if self.executor:\n            self.executor.shutdown()",
  "def __init__(\n        self,\n        project_name=None,\n        min_num_clients=2,\n        max_num_clients=10,\n        wait_after_min_clients=10,\n        cmd_modules=None,\n        heart_beat_timeout=600,\n        handlers: Optional[List[FLComponent]] = None,\n        args=None,\n        secure_train=False,\n        enable_byoc=False,\n        snapshot_persistor=None,\n        overseer_agent=None,\n    ):\n        \"\"\"Federated server services.\n\n        Args:\n            project_name: server project name.\n            min_num_clients: minimum number of contributors at each round.\n            max_num_clients: maximum number of contributors at each round.\n            wait_after_min_clients: wait time after minimum clients responded.\n            cmd_modules: command modules.\n            heart_beat_timeout: heartbeat timeout\n            handlers: A list of handler\n            args: arguments\n            secure_train: whether to use secure communication\n            enable_byoc: whether to enable custom components\n        \"\"\"\n        self.logger = logging.getLogger(\"FederatedServer\")\n\n        BaseServer.__init__(\n            self,\n            project_name=project_name,\n            min_num_clients=min_num_clients,\n            max_num_clients=max_num_clients,\n            heart_beat_timeout=heart_beat_timeout,\n            handlers=handlers,\n        )\n\n        self.contributed_clients = {}\n        self.tokens = None\n        self.round_started = Timestamp()\n\n        with self.lock:\n            self.reset_tokens()\n\n        self.wait_after_min_clients = wait_after_min_clients\n\n        self.cmd_modules = cmd_modules\n\n        self.builder = None\n\n        # Additional fields for CurrentTask meta_data in GetModel API.\n        self.current_model_meta_data = {}\n\n        self.engine = ServerEngine(\n            server=self, args=args, client_manager=self.client_manager, snapshot_persistor=snapshot_persistor\n        )\n        self.run_manager = None\n        self.server_runner = None\n\n        self.processors = {}\n        self.runner_config = None\n        self.secure_train = secure_train\n        self.enable_byoc = enable_byoc\n\n        self.workspace = args.workspace\n        self.snapshot_location = None\n        self.overseer_agent = overseer_agent\n        self.server_state: ServerState = ColdState()\n        self.snapshot_persistor = snapshot_persistor",
  "def get_current_model_meta_data(self):\n        \"\"\"Get the model metadata, which usually contains additional fields.\"\"\"\n        s = Struct()\n        for k, v in self.current_model_meta_data.items():\n            s.update({k: v})\n        return s",
  "def task_meta_info(self):\n        \"\"\"Task meta information.\n\n        The model_meta_info uniquely defines the current model,\n        it is used to reject outdated client's update.\n        \"\"\"\n        meta_info = fed_msg.MetaData()\n        meta_info.created.CopyFrom(self.round_started)\n        meta_info.project.name = self.project_name\n        return meta_info",
  "def remove_client_data(self, token):\n        self.tokens.pop(token, None)",
  "def reset_tokens(self):\n        \"\"\"Reset the token set.\n\n        After resetting, each client can take a token\n        and start fetching the current global model.\n        This function is not thread-safe.\n        \"\"\"\n        self.tokens = dict()\n        for client in self.get_all_clients().keys():\n            self.tokens[client] = self.task_meta_info",
  "def Register(self, request, context):\n        \"\"\"Register new clients on the fly.\n\n        Each client must get registered before getting the global model.\n        The server will expect updates from the registered clients\n        for multiple federated rounds.\n\n        This function does not change min_num_clients and max_num_clients.\n        \"\"\"\n\n        with self.engine.new_context() as fl_ctx:\n            state_check = self.server_state.register(fl_ctx)\n            self._handle_state_check(context, state_check)\n\n            token = self.client_manager.authenticate(request, context)\n            if token:\n                self.tokens[token] = self.task_meta_info\n                if self.admin_server:\n                    self.admin_server.client_heartbeat(token)\n\n                return fed_msg.FederatedSummary(\n                    comment=\"New client registered\", token=token, ssid=self.server_state.ssid\n                )",
  "def _handle_state_check(self, context, state_check):\n        if state_check.get(ACTION) == NIS:\n            context.abort(\n                grpc.StatusCode.FAILED_PRECONDITION,\n                state_check.get(MESSAGE),\n            )\n        elif state_check.get(ACTION) == ABORT_RUN:\n            context.abort(\n                grpc.StatusCode.ABORTED,\n                state_check.get(MESSAGE),\n            )",
  "def _ssid_check(self, client_state, context):\n        if client_state.ssid != self.server_state.ssid:\n            context.abort(grpc.StatusCode.UNAUTHENTICATED, \"Invalid Service session ID\")",
  "def Quit(self, request, context):\n        \"\"\"Existing client quits the federated training process.\n\n        Server will stop sharing the global model with the client,\n        further contribution will be rejected.\n\n        This function does not change min_num_clients and max_num_clients.\n        \"\"\"\n        # fire_event(EventType.CLIENT_QUIT, self.handlers, self.fl_ctx)\n\n        client = self.client_manager.validate_client(request, context)\n        if client:\n            token = client.get_token()\n\n            _ = self.client_manager.remove_client(token)\n            self.tokens.pop(token, None)\n            if self.admin_server:\n                self.admin_server.client_dead(token)\n\n        return fed_msg.FederatedSummary(comment=\"Removed client\")",
  "def GetTask(self, request, context):\n        \"\"\"Process client's get task request.\"\"\"\n\n        with self.engine.new_context() as fl_ctx:\n            state_check = self.server_state.get_task(fl_ctx)\n            self._handle_state_check(context, state_check)\n            self._ssid_check(request, context)\n\n            client = self.client_manager.validate_client(request, context)\n            if client is None:\n                context.abort(grpc.StatusCode.FAILED_PRECONDITION, \"Client not valid.\")\n\n            self.logger.debug(f\"Fetch task requested from client: {client.name} ({client.get_token()})\")\n            token = client.get_token()\n\n            # engine = fl_ctx.get_engine()\n            shared_fl_ctx = pickle.loads(proto_to_bytes(request.context[\"fl_context\"]))\n            job_id = str(shared_fl_ctx.get_prop(FLContextKey.CURRENT_RUN))\n            # fl_ctx.set_peer_context(shared_fl_ctx)\n\n            with self.lock:\n                # if self.server_runner is None or engine is None or self.engine.run_manager is None:\n                if job_id not in self.engine.run_processes.keys():\n                    self.logger.info(\"server has no current run - asked client to end the run\")\n                    task_name = SpecialTaskName.END_RUN\n                    task_id = \"\"\n                    shareable = None\n                else:\n                    shareable, task_id, task_name = self._process_task_request(client, fl_ctx, shared_fl_ctx)\n\n                    # task_name, task_id, shareable = self.server_runner.process_task_request(client, fl_ctx)\n\n                if shareable is None:\n                    shareable = Shareable()\n\n                task = fed_msg.CurrentTask(task_name=task_name)\n                task.meta.CopyFrom(self.task_meta_info)\n                meta_data = self.get_current_model_meta_data()\n\n                # we need TASK_ID back as a cookie\n                shareable.add_cookie(name=FLContextKey.TASK_ID, data=task_id)\n\n                # we also need to make TASK_ID available to the client\n                shareable.set_header(key=FLContextKey.TASK_ID, value=task_id)\n\n                task.meta_data.CopyFrom(meta_data)\n\n                current_model = shareable_to_modeldata(shareable, fl_ctx)\n                task.data.CopyFrom(current_model)\n                if task_name == SpecialTaskName.TRY_AGAIN:\n                    self.logger.debug(f\"GetTask: Return task: {task_name} to client: {client.name} ({token}) \")\n                else:\n                    self.logger.info(f\"GetTask: Return task: {task_name} to client: {client.name} ({token}) \")\n\n                return task",
  "def _process_task_request(self, client, fl_ctx, shared_fl_ctx):\n        task_name = SpecialTaskName.END_RUN\n        task_id = \"\"\n        shareable = None\n        try:\n            with self.engine.lock:\n                job_id = shared_fl_ctx.get_prop(FLContextKey.CURRENT_RUN)\n                command_conn = self.engine.get_command_conn(str(job_id))\n                if command_conn:\n                    command_shareable = Shareable()\n                    command_shareable.set_header(ServerCommandKey.PEER_FL_CONTEXT, shared_fl_ctx)\n                    command_shareable.set_header(ServerCommandKey.FL_CLIENT, client)\n\n                    data = {\n                        ServerCommandKey.COMMAND: ServerCommandNames.GET_TASK,\n                        ServerCommandKey.DATA: command_shareable,\n                    }\n                    command_conn.send(data)\n\n                    return_data = pickle.loads(command_conn.recv())\n                    task_name = return_data.get(ServerCommandKey.TASK_NAME)\n                    task_id = return_data.get(ServerCommandKey.TASK_ID)\n                    shareable = return_data.get(ServerCommandKey.SHAREABLE)\n                    child_fl_ctx = return_data.get(ServerCommandKey.FL_CONTEXT)\n\n                    fl_ctx.props.update(child_fl_ctx)\n        except BaseException as e:\n            self.logger.info(f\"Could not connect to server runner process: {e} - asked client to end the run\")\n        return shareable, task_id, task_name",
  "def SubmitUpdate(self, request, context):\n        \"\"\"Handle client's submission of the federated updates.\"\"\"\n        # if self.server_runner is None or self.engine.run_manager is None:\n\n        with self.engine.new_context() as fl_ctx:\n            state_check = self.server_state.submit_result(fl_ctx)\n            self._handle_state_check(context, state_check)\n            self._ssid_check(request.client, context)\n\n            contribution = request\n\n            client = self.client_manager.validate_client(contribution.client, context)\n            if client is None:\n                response_comment = \"Ignored the submit from invalid client. \"\n                self.logger.info(response_comment)\n            else:\n                with self.lock:\n                    shareable = Shareable.from_bytes(proto_to_bytes(request.data.params[\"data\"]))\n                    shared_fl_context = pickle.loads(proto_to_bytes(request.data.params[\"fl_context\"]))\n\n                    job_id = str(shared_fl_context.get_prop(FLContextKey.CURRENT_RUN))\n                    if job_id not in self.engine.run_processes.keys():\n                        self.logger.info(\"ignored result submission since Server Engine isn't ready\")\n                        context.abort(grpc.StatusCode.OUT_OF_RANGE, \"Server has stopped\")\n\n                    shared_fl_context.set_prop(FLContextKey.SHAREABLE, shareable, private=False)\n\n                    contribution_meta = contribution.client.meta\n                    client_contrib_id = \"{}_{}_{}\".format(\n                        contribution_meta.project.name, client.name, contribution_meta.current_round\n                    )\n                    contribution_task_name = contribution.task_name\n\n                    timenow = Timestamp()\n                    timenow.GetCurrentTime()\n                    time_seconds = timenow.seconds - self.round_started.seconds\n                    self.logger.info(\n                        \"received update from %s (%s Bytes, %s seconds)\",\n                        client_contrib_id,\n                        contribution.ByteSize(),\n                        time_seconds or \"less than 1\",\n                    )\n\n                    task_id = shareable.get_cookie(FLContextKey.TASK_ID)\n                    shareable.set_header(ServerCommandKey.PEER_FL_CONTEXT, shared_fl_context)\n                    shareable.set_header(ServerCommandKey.FL_CLIENT, client)\n                    shareable.set_header(ServerCommandKey.TASK_NAME, contribution_task_name)\n\n                    self._submit_update(shareable, shared_fl_context)\n\n                    # self.server_runner.process_submission(client, contribution_task_name, task_id, shareable, fl_ctx)\n\n            response_comment = \"Received from {} ({} Bytes, {} seconds)\".format(\n                contribution.client.client_name,\n                contribution.ByteSize(),\n                time_seconds or \"less than 1\",\n            )\n            summary_info = fed_msg.FederatedSummary(comment=response_comment)\n            summary_info.meta.CopyFrom(self.task_meta_info)\n\n            return summary_info",
  "def _submit_update(self, shareable, shared_fl_context):\n        try:\n            with self.engine.lock:\n                job_id = shared_fl_context.get_prop(FLContextKey.CURRENT_RUN)\n                command_conn = self.engine.get_command_conn(str(job_id))\n                if command_conn:\n                    data = {\n                        ServerCommandKey.COMMAND: ServerCommandNames.SUBMIT_UPDATE,\n                        ServerCommandKey.DATA: shareable,\n                    }\n                    command_conn.send(data)\n        except BaseException:\n            self.logger.info(\"Could not connect to server runner process - asked client to end the run\")",
  "def AuxCommunicate(self, request, context):\n        \"\"\"Handle auxiliary channel communication.\"\"\"\n        with self.engine.new_context() as fl_ctx:\n            state_check = self.server_state.aux_communicate(fl_ctx)\n            self._handle_state_check(context, state_check)\n            self._ssid_check(request.client, context)\n\n            contribution = request\n\n            client = self.client_manager.validate_client(contribution.client, context)\n            if client is None:\n                response_comment = \"Ignored the submit from invalid client. \"\n                self.logger.info(response_comment)\n\n            shareable = Shareable()\n            shareable = shareable.from_bytes(proto_to_bytes(request.data[\"data\"]))\n            shared_fl_context = pickle.loads(proto_to_bytes(request.data[\"fl_context\"]))\n\n            job_id = str(shared_fl_context.get_prop(FLContextKey.CURRENT_RUN))\n            if job_id not in self.engine.run_processes.keys():\n                self.logger.info(\"ignored AuxCommunicate request since Server Engine isn't ready\")\n                reply = make_reply(ReturnCode.SERVER_NOT_READY)\n                aux_reply = fed_msg.AuxReply()\n                aux_reply.data.CopyFrom(shareable_to_modeldata(reply, fl_ctx))\n\n                return aux_reply\n\n            fl_ctx.set_peer_context(shared_fl_context)\n            shareable.set_peer_props(shared_fl_context.get_all_public_props())\n\n            shared_fl_context.set_prop(FLContextKey.SHAREABLE, shareable, private=False)\n\n            topic = shareable.get_header(ReservedHeaderKey.TOPIC)\n\n            reply = self._aux_communicate(fl_ctx, shareable, shared_fl_context, topic)\n\n            # reply = self.engine.dispatch(topic=topic, request=shareable, fl_ctx=fl_ctx)\n\n            aux_reply = fed_msg.AuxReply()\n            aux_reply.data.CopyFrom(shareable_to_modeldata(reply, fl_ctx))\n\n            return aux_reply",
  "def _aux_communicate(self, fl_ctx, shareable, shared_fl_context, topic):\n        try:\n            with self.engine.lock:\n                job_id = shared_fl_context.get_prop(FLContextKey.CURRENT_RUN)\n                command_conn = self.engine.get_command_conn(str(job_id))\n                if command_conn:\n                    command_shareable = Shareable()\n                    command_shareable.set_header(ServerCommandKey.PEER_FL_CONTEXT, shared_fl_context)\n                    command_shareable.set_header(ServerCommandKey.TOPIC, topic)\n                    command_shareable.set_header(ServerCommandKey.SHAREABLE, shareable)\n\n                    data = {\n                        ServerCommandKey.COMMAND: ServerCommandNames.AUX_COMMUNICATE,\n                        ServerCommandKey.DATA: command_shareable,\n                    }\n                    command_conn.send(data)\n\n                    return_data = command_conn.recv()\n                    reply = return_data.get(ServerCommandKey.AUX_REPLY)\n                    child_fl_ctx = return_data.get(ServerCommandKey.FL_CONTEXT)\n\n                    fl_ctx.props.update(child_fl_ctx)\n                else:\n                    reply = make_reply(ReturnCode.ERROR)\n        except BaseException:\n            self.logger.info(\"Could not connect to server runner process - asked client to end the run\")\n            reply = make_reply(ReturnCode.COMMUNICATION_ERROR)\n\n        return reply",
  "def Heartbeat(self, request, context):\n\n        with self.engine.new_context() as fl_ctx:\n            state_check = self.server_state.heartbeat(fl_ctx)\n            self._handle_state_check(context, state_check)\n\n            token = request.token\n            cn_names = context.auth_context().get(\"x509_common_name\")\n            if cn_names:\n                client_name = cn_names[0].decode(\"utf-8\")\n            else:\n                client_name = request.client_name\n\n            if self.client_manager.heartbeat(token, client_name, context):\n                self.tokens[token] = self.task_meta_info\n            if self.admin_server:\n                self.admin_server.client_heartbeat(token)\n\n            abort_runs = self._sync_client_jobs(request)\n            summary_info = fed_msg.FederatedSummary()\n            if abort_runs:\n                del summary_info.abort_jobs[:]\n                summary_info.abort_jobs.extend(abort_runs)\n                display_runs = \",\".join(abort_runs)\n                self.logger.info(\n                    f\"These jobs: {display_runs} are not running on the server. \"\n                    f\"Ask client: {client_name} to abort these runs.\"\n                )\n            return summary_info",
  "def _sync_client_jobs(self, request):\n        client_jobs = request.jobs\n        server_jobs = self.engine.run_processes.keys()\n        jobs_need_abort = list(set(client_jobs).difference(server_jobs))\n        return jobs_need_abort",
  "def Retrieve(self, request, context):\n        client_name = request.client_name\n        messages = self.admin_server.get_outgoing_requests(client_token=client_name) if self.admin_server else []\n\n        response = admin_msg.Messages()\n        for m in messages:\n            response.message.append(message_to_proto(m))\n        return response",
  "def SendReply(self, request, context):\n        client_name = request.client_name\n        message = proto_to_message(request.message)\n        if self.admin_server:\n            self.admin_server.accept_reply(client_token=client_name, reply=message)\n\n        response = admin_msg.Empty()\n        return response",
  "def SendResult(self, request, context):\n        client_name = request.client_name\n        message = proto_to_message(request.message)\n\n        processor = self.processors.get(message.topic)\n        processor.process(client_name, message)\n\n        response = admin_msg.Empty()\n        return response",
  "def start_run(self, job_id, run_root, conf, args, snapshot):\n        # Create the FL Engine\n        workspace = Workspace(args.workspace, \"server\", args.config_folder)\n        self.run_manager = RunManager(\n            server_name=self.project_name,\n            engine=self.engine,\n            job_id=job_id,\n            workspace=workspace,\n            components=self.runner_config.components,\n            client_manager=self.client_manager,\n            handlers=self.runner_config.handlers,\n        )\n        self.engine.set_run_manager(self.run_manager)\n        self.engine.set_configurator(conf)\n        self.engine.asked_to_stop = False\n\n        fed_event_runner = ServerFedEventRunner()\n        self.run_manager.add_handler(fed_event_runner)\n\n        try:\n            self.server_runner = ServerRunner(config=self.runner_config, job_id=job_id, engine=self.engine)\n            self.run_manager.add_handler(self.server_runner)\n            self.run_manager.add_component(\"_Server_Runner\", self.server_runner)\n\n            with self.engine.new_context() as fl_ctx:\n\n                if snapshot:\n                    self.engine.restore_components(snapshot=snapshot, fl_ctx=FLContext())\n\n                fl_ctx.set_prop(FLContextKey.APP_ROOT, run_root, sticky=True)\n                fl_ctx.set_prop(FLContextKey.CURRENT_RUN, job_id, private=False, sticky=True)\n                fl_ctx.set_prop(FLContextKey.WORKSPACE_ROOT, args.workspace, private=True, sticky=True)\n                fl_ctx.set_prop(FLContextKey.ARGS, args, private=True, sticky=True)\n                fl_ctx.set_prop(FLContextKey.WORKSPACE_OBJECT, workspace, private=True)\n                fl_ctx.set_prop(FLContextKey.SECURE_MODE, self.secure_train, private=True, sticky=True)\n                fl_ctx.set_prop(FLContextKey.RUNNER, self.server_runner, private=True, sticky=True)\n\n            engine_thread = threading.Thread(target=self.run_engine)\n            engine_thread.start()\n\n            self.engine.engine_info.status = MachineStatus.STARTED\n            while self.engine.engine_info.status != MachineStatus.STOPPED:\n                if self.engine.asked_to_stop:\n                    self.engine.engine_info.status = MachineStatus.STOPPED\n\n                time.sleep(3)\n\n            if engine_thread.is_alive():\n                engine_thread.join()\n\n        finally:\n            self.engine.engine_info.status = MachineStatus.STOPPED\n            self.engine.run_manager = None\n            self.run_manager = None",
  "def abort_run(self):\n        with self.engine.new_context() as fl_ctx:\n            if self.server_runner:\n                self.server_runner.abort(fl_ctx)",
  "def run_engine(self):\n        self.engine.engine_info.status = MachineStatus.STARTED\n        self.server_runner.run()\n        self.engine.engine_info.status = MachineStatus.STOPPED",
  "def deploy(self, args, grpc_args=None, secure_train=False):\n        super().deploy(args, grpc_args, secure_train)\n\n        target = grpc_args[\"service\"].get(\"target\", \"0.0.0.0:6007\")\n        self.server_state.host = target.split(\":\")[0]\n        self.server_state.service_port = target.split(\":\")[1]\n\n        self.overseer_agent = self._init_agent(args)\n\n        if secure_train:\n            if self.overseer_agent:\n                self.overseer_agent.set_secure_context(\n                    ca_path=grpc_args[\"ssl_root_cert\"],\n                    cert_path=grpc_args[\"ssl_cert\"],\n                    prv_key_path=grpc_args[\"ssl_private_key\"],\n                )\n\n        self.overseer_agent.start(self.overseer_callback)",
  "def _init_agent(self, args=None):\n        kv_list = parse_vars(args.set)\n        sp = kv_list.get(\"sp\")\n\n        if sp:\n            with self.engine.new_context() as fl_ctx:\n                fl_ctx.set_prop(FLContextKey.SP_END_POINT, sp)\n                self.overseer_agent.initialize(fl_ctx)\n\n        return self.overseer_agent",
  "def overseer_callback(self, overseer_agent):\n        if overseer_agent.is_shutdown():\n            self.engine.shutdown_server()\n            return\n\n        sp = overseer_agent.get_primary_sp()\n        # print(sp)\n        with self.engine.new_context() as fl_ctx:\n            self.server_state = self.server_state.handle_sd_callback(sp, fl_ctx)\n\n        if isinstance(self.server_state, Cold2HotState):\n            server_thread = threading.Thread(target=self._turn_to_hot)\n            server_thread.start()\n\n        if isinstance(self.server_state, Hot2ColdState):\n            server_thread = threading.Thread(target=self._turn_to_cold)\n            server_thread.start()",
  "def _turn_to_hot(self):\n        # Restore Snapshot\n        with self.snapshot_lock:\n            fl_snapshot = self.snapshot_persistor.retrieve()\n            if fl_snapshot:\n                for run_number, snapshot in fl_snapshot.run_snapshots.items():\n                    if snapshot and not snapshot.completed:\n                        # Restore the workspace\n                        workspace_data = snapshot.get_component_snapshot(SnapshotKey.WORKSPACE).get(\"content\")\n                        dst = os.path.join(self.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(run_number))\n                        if os.path.exists(dst):\n                            shutil.rmtree(dst, ignore_errors=True)\n\n                        os.makedirs(dst, exist_ok=True)\n                        unzip_all_from_bytes(workspace_data, dst)\n\n                        job_id = snapshot.get_component_snapshot(SnapshotKey.JOB_INFO).get(SnapshotKey.JOB_ID)\n                        job_clients = snapshot.get_component_snapshot(SnapshotKey.JOB_INFO).get(SnapshotKey.JOB_CLIENTS)\n                        self.logger.info(f\"Restore the previous snapshot. Run_number: {run_number}\")\n                        with self.engine.new_context() as fl_ctx:\n                            job_runner = self.engine.job_runner\n                            job_runner.restore_running_job(\n                                run_number=run_number,\n                                job_id=job_id,\n                                job_clients=job_clients,\n                                snapshot=snapshot,\n                                fl_ctx=fl_ctx,\n                            )\n\n            self.server_state = HotState(\n                host=self.server_state.host, port=self.server_state.service_port, ssid=self.server_state.ssid\n            )",
  "def _turn_to_cold(self):\n        # Wrap-up server operations\n        self.server_state = ColdState(host=self.server_state.host, port=self.server_state.service_port)",
  "def stop_training(self):\n        self.status = ServerStatus.STOPPED\n        self.logger.info(\"Server app stopped.\\n\\n\")",
  "def fl_shutdown(self):\n        self.engine.stop_all_jobs()\n        self.engine.fire_event(EventType.SYSTEM_END, self.engine.new_context())\n\n        super().fl_shutdown()",
  "def close(self):\n        \"\"\"Shutdown the server.\"\"\"\n        self.logger.info(\"shutting down server\")\n        self.overseer_agent.end()\n        return super().close()",
  "class ServerStatus(object):\n    NOT_STARTED = 0\n    STARTING = 1\n    STARTED = 2\n    STOPPED = 3\n    SHUTDOWN = 4\n\n    status_messages = {\n        NOT_STARTED: \"app server not started\",\n        STARTING: \"app server starting\",\n        STARTED: \"app server started\",\n        STOPPED: \"app server stopped\",\n        SHUTDOWN: \"FL server shutdown\",\n    }",
  "def get_status_message(status):\n    return ServerStatus.status_messages.get(status)",
  "class ComponentCallerCommandModule(CommandModule, CommandUtil):\n\n    _CONN_KEY_CALLER = \"caller\"\n    _CONN_KEY_TARGET = \"comp_target\"\n    _CONN_KEY_ACTION = \"action\"\n    _CONN_KEY_PARAMS = \"params\"\n\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=\"admin\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"call\",\n                    description=\"issue a call to components\",\n                    usage=\"call comp_target action params\",\n                    handler_func=self.call_component,\n                    authz_func=self.authorize_call_component,\n                    visible=True,\n                )\n            ],\n        )\n\n    def authorize_call_component(self, conn: Connection, args: [str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        caller = engine.get_widget(WidgetID.COMPONENT_CALLER)\n        if not caller:\n            conn.append_error(\"component caller not available\")\n            return False, None\n\n        if not isinstance(caller, ComponentCaller):\n            conn.append_error(\"system error: component caller not right object\")\n            return False, None\n\n        conn.set_prop(self._CONN_KEY_CALLER, caller)\n\n        run_info = engine.get_app_run_info()\n        if not run_info or run_info.job_id < 0:\n            conn.append_string(\"App is not running\")\n            return False, None\n\n        # validate the command\n        if len(args) < 3:\n            conn.append_error(\"Syntax error. Usage: {} comp_target action [params...]\".format(args[0]))\n            return False, None\n\n        comp_target = args[1]\n        action = args[2]\n        param_args = args[3:]\n\n        # parse params\n        params_dict = {}\n        if param_args:\n            for a in param_args:\n                parts = a.split()\n                if len(parts) <= 0:\n                    conn.append_error(\"missing params\")\n                    return False, None\n\n                # each param part must be: key=value\n                for p in parts:\n                    kvs = p.split(\"=\")\n                    if len(kvs) != 2:\n                        conn.append_error(\"Syntax error: params must be key/value pairs separated by =\")\n                        return False, None\n                    params_dict[kvs[0]] = kvs[1]\n\n        conn.set_prop(self._CONN_KEY_ACTION, action)\n        conn.set_prop(self._CONN_KEY_TARGET, comp_target)\n        conn.set_prop(self._CONN_KEY_PARAMS, params_dict)\n\n        return True, FLAuthzContext.new_authz_context(site_names=[\"server\"], actions=[Action.TRAIN])\n\n    def call_component(self, conn: Connection, args: [str]):\n        # only support server side for now\n        caller = conn.get_prop(self._CONN_KEY_CALLER)\n        if not isinstance(caller, ComponentCaller):\n            raise TypeError(\"caller must be ComponentCaller but got {}\".format(type(caller)))\n        action = conn.get_prop(self._CONN_KEY_ACTION)\n        comp_target = conn.get_prop(self._CONN_KEY_TARGET)\n        call_params = conn.get_prop(self._CONN_KEY_PARAMS)\n\n        result = caller.call_components(target=comp_target, action=action, params=call_params)\n\n        if not result:\n            conn.append_string(\"No result: no component responded to the call\")\n            return\n\n        # the result is a dict of: target => response\n        table = conn.append_table([\"Component\", \"Response\"])\n        for comp_name, resp in result.items():\n            table.add_row([comp_name, resp])",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=\"admin\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"call\",\n                    description=\"issue a call to components\",\n                    usage=\"call comp_target action params\",\n                    handler_func=self.call_component,\n                    authz_func=self.authorize_call_component,\n                    visible=True,\n                )\n            ],\n        )",
  "def authorize_call_component(self, conn: Connection, args: [str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        caller = engine.get_widget(WidgetID.COMPONENT_CALLER)\n        if not caller:\n            conn.append_error(\"component caller not available\")\n            return False, None\n\n        if not isinstance(caller, ComponentCaller):\n            conn.append_error(\"system error: component caller not right object\")\n            return False, None\n\n        conn.set_prop(self._CONN_KEY_CALLER, caller)\n\n        run_info = engine.get_app_run_info()\n        if not run_info or run_info.job_id < 0:\n            conn.append_string(\"App is not running\")\n            return False, None\n\n        # validate the command\n        if len(args) < 3:\n            conn.append_error(\"Syntax error. Usage: {} comp_target action [params...]\".format(args[0]))\n            return False, None\n\n        comp_target = args[1]\n        action = args[2]\n        param_args = args[3:]\n\n        # parse params\n        params_dict = {}\n        if param_args:\n            for a in param_args:\n                parts = a.split()\n                if len(parts) <= 0:\n                    conn.append_error(\"missing params\")\n                    return False, None\n\n                # each param part must be: key=value\n                for p in parts:\n                    kvs = p.split(\"=\")\n                    if len(kvs) != 2:\n                        conn.append_error(\"Syntax error: params must be key/value pairs separated by =\")\n                        return False, None\n                    params_dict[kvs[0]] = kvs[1]\n\n        conn.set_prop(self._CONN_KEY_ACTION, action)\n        conn.set_prop(self._CONN_KEY_TARGET, comp_target)\n        conn.set_prop(self._CONN_KEY_PARAMS, params_dict)\n\n        return True, FLAuthzContext.new_authz_context(site_names=[\"server\"], actions=[Action.TRAIN])",
  "def call_component(self, conn: Connection, args: [str]):\n        # only support server side for now\n        caller = conn.get_prop(self._CONN_KEY_CALLER)\n        if not isinstance(caller, ComponentCaller):\n            raise TypeError(\"caller must be ComponentCaller but got {}\".format(type(caller)))\n        action = conn.get_prop(self._CONN_KEY_ACTION)\n        comp_target = conn.get_prop(self._CONN_KEY_TARGET)\n        call_params = conn.get_prop(self._CONN_KEY_PARAMS)\n\n        result = caller.call_components(target=comp_target, action=action, params=call_params)\n\n        if not result:\n            conn.append_string(\"No result: no component responded to the call\")\n            return\n\n        # the result is a dict of: target => response\n        table = conn.append_table([\"Component\", \"Response\"])\n        for comp_name, resp in result.items():\n            table.add_row([comp_name, resp])",
  "class ServerAuxRunner(AuxRunner):\n    def __init__(self):\n        \"\"\"This class is for auxiliary channel communication on server side.\n\n        Note: The ServerEngine must create a new ServerAuxRunner object for each RUN, and make sure\n              it is added as an event handler.\n        \"\"\"\n        AuxRunner.__init__(self)\n\n    def send_aux_request(self, targets: [], topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> dict:\n        \"\"\"Send request through auxiliary channel.\n\n        Args:\n            targets (list): list of client names that the request will be sent to\n            topic (str): topic of the request\n            request (Shareable): request\n            timeout (float): how long to wait for result. 0 means fire-and-forget\n            fl_ctx (FLContext): the FL context\n\n        Returns:\n            A dict of results\n        \"\"\"\n        if not isinstance(request, Shareable):\n            raise ValueError(\"invalid request type: expect Shareable but got {}\".format(type(request)))\n\n        if not targets:\n            raise ValueError(\"targets must be specified\")\n\n        if targets is not None and not isinstance(targets, list):\n            raise TypeError(\"targets must be a list of Client or str, but got {}\".format(type(targets)))\n\n        if not isinstance(topic, str):\n            raise TypeError(\"invalid topic: expects str but got {}\".format(type(topic)))\n\n        if not topic:\n            raise ValueError(\"invalid topic: must not be empty\")\n\n        if topic == self.TOPIC_BULK:\n            raise ValueError('topic value \"{}\" is reserved'.format(topic))\n\n        if not isinstance(timeout, float):\n            raise TypeError(\"invalid timeout: expects float but got {}\".format(type(timeout)))\n\n        if timeout < 0:\n            raise ValueError(\"invalid timeout value {}: must >= 0.0\".format(timeout))\n\n        if not isinstance(fl_ctx, FLContext):\n            raise TypeError(\"invalid fl_ctx: expects FLContext but got {}\".format(type(fl_ctx)))\n\n        request.set_peer_props(fl_ctx.get_all_public_props())\n        request.set_header(ReservedHeaderKey.TOPIC, topic)\n\n        engine = fl_ctx.get_engine()\n        # assert isinstance(engine, ServerEngineInternalSpec)\n\n        target_names = []\n        for t in targets:\n            if isinstance(t, str):\n                name = t\n            elif isinstance(t, Client):\n                name = t.name\n            else:\n                raise ValueError(\"invalid target in list: got {}\".format(type(t)))\n\n            if name not in target_names:\n                target_names.append(t)\n\n        clients, invalid_names = engine.validate_clients(target_names)\n        if invalid_names:\n            raise ValueError(\"invalid target(s): {}\".format(invalid_names))\n        valid_tokens = []\n        for c in clients:\n            if c.token not in valid_tokens:\n                valid_tokens.append(c.token)\n\n        replies = engine.parent_aux_send(\n            targets=valid_tokens, topic=topic, request=request, timeout=timeout, fl_ctx=fl_ctx\n        )\n\n        return replies",
  "def __init__(self):\n        \"\"\"This class is for auxiliary channel communication on server side.\n\n        Note: The ServerEngine must create a new ServerAuxRunner object for each RUN, and make sure\n              it is added as an event handler.\n        \"\"\"\n        AuxRunner.__init__(self)",
  "def send_aux_request(self, targets: [], topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> dict:\n        \"\"\"Send request through auxiliary channel.\n\n        Args:\n            targets (list): list of client names that the request will be sent to\n            topic (str): topic of the request\n            request (Shareable): request\n            timeout (float): how long to wait for result. 0 means fire-and-forget\n            fl_ctx (FLContext): the FL context\n\n        Returns:\n            A dict of results\n        \"\"\"\n        if not isinstance(request, Shareable):\n            raise ValueError(\"invalid request type: expect Shareable but got {}\".format(type(request)))\n\n        if not targets:\n            raise ValueError(\"targets must be specified\")\n\n        if targets is not None and not isinstance(targets, list):\n            raise TypeError(\"targets must be a list of Client or str, but got {}\".format(type(targets)))\n\n        if not isinstance(topic, str):\n            raise TypeError(\"invalid topic: expects str but got {}\".format(type(topic)))\n\n        if not topic:\n            raise ValueError(\"invalid topic: must not be empty\")\n\n        if topic == self.TOPIC_BULK:\n            raise ValueError('topic value \"{}\" is reserved'.format(topic))\n\n        if not isinstance(timeout, float):\n            raise TypeError(\"invalid timeout: expects float but got {}\".format(type(timeout)))\n\n        if timeout < 0:\n            raise ValueError(\"invalid timeout value {}: must >= 0.0\".format(timeout))\n\n        if not isinstance(fl_ctx, FLContext):\n            raise TypeError(\"invalid fl_ctx: expects FLContext but got {}\".format(type(fl_ctx)))\n\n        request.set_peer_props(fl_ctx.get_all_public_props())\n        request.set_header(ReservedHeaderKey.TOPIC, topic)\n\n        engine = fl_ctx.get_engine()\n        # assert isinstance(engine, ServerEngineInternalSpec)\n\n        target_names = []\n        for t in targets:\n            if isinstance(t, str):\n                name = t\n            elif isinstance(t, Client):\n                name = t.name\n            else:\n                raise ValueError(\"invalid target in list: got {}\".format(type(t)))\n\n            if name not in target_names:\n                target_names.append(t)\n\n        clients, invalid_names = engine.validate_clients(target_names)\n        if invalid_names:\n            raise ValueError(\"invalid target(s): {}\".format(invalid_names))\n        valid_tokens = []\n        for c in clients:\n            if c.token not in valid_tokens:\n                valid_tokens.append(c.token)\n\n        replies = engine.parent_aux_send(\n            targets=valid_tokens, topic=topic, request=request, timeout=timeout, fl_ctx=fl_ctx\n        )\n\n        return replies",
  "class _CommandExecutor(object):\n    def __init__(self, cmd_name: str, validator: ShellCommandValidator):\n        self.cmd_name = cmd_name\n        self.validator = validator\n\n    def authorize_command(self, conn: Connection, args: List[str]):\n        if len(args) < 2:\n            conn.append_error(\"syntax error: missing target\")\n            return False, None\n\n        shell_cmd_args = [self.cmd_name]\n        for a in args[2:]:\n            shell_cmd_args.append(a)\n\n        shell_cmd = join_args(shell_cmd_args)\n\n        result = None\n        if self.validator:\n            err, result = self.validator.validate(shell_cmd_args[1:])\n            if len(err) > 0:\n                conn.append_error(err)\n                return False, None\n\n        # validate the command and make sure file destinations are protected\n        err = self.validate_shell_command(shell_cmd_args, result)\n        if len(err) > 0:\n            conn.append_error(err)\n            return False, None\n\n        site_name = args[1]\n        authz_ctx = FLAuthzContext.new_authz_context(site_names=[site_name], actions=[Action.VIEW])\n        conn.set_prop(\"shell_cmd\", shell_cmd)\n        return True, authz_ctx\n\n    def validate_shell_command(self, args: List[str], parse_result) -> str:\n        return \"\"\n\n    def execute_command(self, conn: Connection, args: List[str]):\n        authz_ctx = conn.get_prop(ConnProps.AUTHZ_CTX, None)\n        if not authz_ctx:\n            conn.append_error(\"program error: no authorization context\")\n            return\n\n        if not isinstance(authz_ctx, FLAuthzContext):\n            raise TypeError(\"authz_ctx must be FLAuthzContext but got {}\".format(type(authz_ctx)))\n        target = authz_ctx.site_names[0]\n        shell_cmd = conn.get_prop(\"shell_cmd\")\n        if target == \"server\":\n            # run the shell command on server\n            output = subprocess.getoutput(shell_cmd)\n            conn.append_string(output)\n            return\n\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n        clients, invalid_inputs = engine.validate_clients([target])\n        if len(invalid_inputs) > 0:\n            conn.append_error(\"invalid client: {}\".format(target))\n            return\n\n        if len(clients) > 1:\n            conn.append_error(\"this command can only be applied to one client at a time\")\n            return\n\n        valid_tokens = []\n        for c in clients:\n            valid_tokens.append(c.token)\n\n        req = new_message(conn=conn, topic=SysCommandTopic.SHELL, body=shell_cmd)\n        server = conn.server\n        reply = server.send_request_to_client(req, valid_tokens[0], timeout_secs=server.timeout)\n        if reply is None:\n            conn.append_error(\"no reply from client - timed out\")\n            return\n\n        if not isinstance(reply, ClientReply):\n            raise TypeError(\"reply must be ClientReply but got {}\".format(type(reply)))\n        if reply.reply is None:\n            conn.append_error(\"no reply from client - timed out\")\n            return\n        if not isinstance(reply.reply, Message):\n            raise TypeError(\"reply in ClientReply must be Message but got {}\".format(type(reply.reply)))\n        conn.append_string(reply.reply.body)\n\n    def get_usage(self):\n        if self.validator:\n            return self.validator.get_usage()\n        else:\n            return \"\"",
  "class _NoArgCmdExecutor(_CommandExecutor):\n    def __init__(self, cmd_name: str):\n        _CommandExecutor.__init__(self, cmd_name, None)\n\n    def validate_shell_command(self, args: List[str], parse_result):\n        if len(args) != 1:\n            return \"this command does not accept extra args\"\n\n        return \"\"",
  "class _FileCmdExecutor(_CommandExecutor):\n    def __init__(\n        self,\n        cmd_name: str,\n        validator: ShellCommandValidator,\n        text_file_only: bool = True,\n        single_file_only: bool = True,\n        file_required: bool = True,\n    ):\n        _CommandExecutor.__init__(self, cmd_name, validator)\n        self.text_file_only = text_file_only\n        self.single_file_only = single_file_only\n        self.file_required = file_required\n\n    def validate_shell_command(self, args: List[str], parse_result):\n        if self.file_required or parse_result.files:\n            if not hasattr(parse_result, \"files\"):\n                return \"a file is required as an argument\"\n            if self.single_file_only and len(parse_result.files) != 1:\n                return \"only one file is allowed\"\n\n            if isinstance(parse_result.files, list):\n                file_list = parse_result.files\n            else:\n                file_list = [parse_result.files]\n\n            for f in file_list:\n                if not isinstance(f, str):\n                    raise TypeError(\"file must be str but got {}\".format(type(f)))\n\n                if not re.match(\"^[A-Za-z0-9-._/]*$\", f):\n                    return \"unsupported file {}\".format(f)\n\n                if f.startswith(\"/\"):\n                    return \"absolute path is not allowed\"\n\n                paths = f.split(\"/\")\n                for p in paths:\n                    if p == \"..\":\n                        return \".. in path name is not allowed\"\n\n                if self.text_file_only:\n                    basename, file_extension = os.path.splitext(f)\n                    if file_extension not in [\".txt\", \".log\", \".json\", \".csv\", \".sh\", \".config\", \".py\"]:\n                        return (\n                            \"this command cannot be applied to file {}. Only files with the following extensions \"\n                            \"are permitted: .txt, .log, .json, .csv, .sh, .config, .py\".format(f)\n                        )\n\n        return \"\"",
  "class ShellCommandModule(CommandModule):\n    def get_spec(self):\n        pwd_exe = _NoArgCmdExecutor(\"pwd\")\n        ls_exe = _FileCmdExecutor(\n            \"ls\", LsValidator(), text_file_only=False, single_file_only=False, file_required=False\n        )\n        cat_exe = _FileCmdExecutor(\"cat\", CatValidator())\n        head_exe = _FileCmdExecutor(\"head\", HeadValidator())\n        tail_exe = _FileCmdExecutor(\"tail\", TailValidator())\n        grep_exe = _FileCmdExecutor(\"grep\", GrepValidator())\n\n        return CommandModuleSpec(\n            name=\"sys\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"pwd\",\n                    description=\"print the name of work directory\",\n                    usage=\"pwd target\\n\" + 'where target is \"server\" or client name\\n' + pwd_exe.get_usage(),\n                    handler_func=pwd_exe.execute_command,\n                    authz_func=pwd_exe.authorize_command,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"ls\",\n                    description=\"list files in work dir\",\n                    usage=\"ls target [options] [files]\\n \"\n                    + 'where target is \"server\" or client name\\n'\n                    + ls_exe.get_usage(),\n                    handler_func=ls_exe.execute_command,\n                    authz_func=ls_exe.authorize_command,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"cat\",\n                    description=\"show content of a file\",\n                    usage=\"cat target [options] fileName\\n \"\n                    + 'where target is \"server\" or client name\\n'\n                    + cat_exe.get_usage(),\n                    handler_func=cat_exe.execute_command,\n                    authz_func=cat_exe.authorize_command,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"head\",\n                    description=\"print the first 10 lines of a file\",\n                    usage=\"head target [options] fileName\\n \"\n                    + 'where target is \"server\" or client name\\n'\n                    + head_exe.get_usage(),\n                    handler_func=head_exe.execute_command,\n                    authz_func=head_exe.authorize_command,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"tail\",\n                    description=\"print the last 10 lines of a file\",\n                    usage=\"tail target [options] fileName\\n \"\n                    + 'where target is \"server\" or client name\\n'\n                    + tail_exe.get_usage(),\n                    handler_func=tail_exe.execute_command,\n                    authz_func=tail_exe.authorize_command,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"grep\",\n                    description=\"search for PATTERN in a file.\",\n                    usage=\"grep target [options] PATTERN fileName\\n \"\n                    + 'where target is \"server\" or client name\\n'\n                    + grep_exe.get_usage(),\n                    handler_func=grep_exe.execute_command,\n                    authz_func=grep_exe.authorize_command,\n                    visible=True,\n                ),\n            ],\n        )",
  "def __init__(self, cmd_name: str, validator: ShellCommandValidator):\n        self.cmd_name = cmd_name\n        self.validator = validator",
  "def authorize_command(self, conn: Connection, args: List[str]):\n        if len(args) < 2:\n            conn.append_error(\"syntax error: missing target\")\n            return False, None\n\n        shell_cmd_args = [self.cmd_name]\n        for a in args[2:]:\n            shell_cmd_args.append(a)\n\n        shell_cmd = join_args(shell_cmd_args)\n\n        result = None\n        if self.validator:\n            err, result = self.validator.validate(shell_cmd_args[1:])\n            if len(err) > 0:\n                conn.append_error(err)\n                return False, None\n\n        # validate the command and make sure file destinations are protected\n        err = self.validate_shell_command(shell_cmd_args, result)\n        if len(err) > 0:\n            conn.append_error(err)\n            return False, None\n\n        site_name = args[1]\n        authz_ctx = FLAuthzContext.new_authz_context(site_names=[site_name], actions=[Action.VIEW])\n        conn.set_prop(\"shell_cmd\", shell_cmd)\n        return True, authz_ctx",
  "def validate_shell_command(self, args: List[str], parse_result) -> str:\n        return \"\"",
  "def execute_command(self, conn: Connection, args: List[str]):\n        authz_ctx = conn.get_prop(ConnProps.AUTHZ_CTX, None)\n        if not authz_ctx:\n            conn.append_error(\"program error: no authorization context\")\n            return\n\n        if not isinstance(authz_ctx, FLAuthzContext):\n            raise TypeError(\"authz_ctx must be FLAuthzContext but got {}\".format(type(authz_ctx)))\n        target = authz_ctx.site_names[0]\n        shell_cmd = conn.get_prop(\"shell_cmd\")\n        if target == \"server\":\n            # run the shell command on server\n            output = subprocess.getoutput(shell_cmd)\n            conn.append_string(output)\n            return\n\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n        clients, invalid_inputs = engine.validate_clients([target])\n        if len(invalid_inputs) > 0:\n            conn.append_error(\"invalid client: {}\".format(target))\n            return\n\n        if len(clients) > 1:\n            conn.append_error(\"this command can only be applied to one client at a time\")\n            return\n\n        valid_tokens = []\n        for c in clients:\n            valid_tokens.append(c.token)\n\n        req = new_message(conn=conn, topic=SysCommandTopic.SHELL, body=shell_cmd)\n        server = conn.server\n        reply = server.send_request_to_client(req, valid_tokens[0], timeout_secs=server.timeout)\n        if reply is None:\n            conn.append_error(\"no reply from client - timed out\")\n            return\n\n        if not isinstance(reply, ClientReply):\n            raise TypeError(\"reply must be ClientReply but got {}\".format(type(reply)))\n        if reply.reply is None:\n            conn.append_error(\"no reply from client - timed out\")\n            return\n        if not isinstance(reply.reply, Message):\n            raise TypeError(\"reply in ClientReply must be Message but got {}\".format(type(reply.reply)))\n        conn.append_string(reply.reply.body)",
  "def get_usage(self):\n        if self.validator:\n            return self.validator.get_usage()\n        else:\n            return \"\"",
  "def __init__(self, cmd_name: str):\n        _CommandExecutor.__init__(self, cmd_name, None)",
  "def validate_shell_command(self, args: List[str], parse_result):\n        if len(args) != 1:\n            return \"this command does not accept extra args\"\n\n        return \"\"",
  "def __init__(\n        self,\n        cmd_name: str,\n        validator: ShellCommandValidator,\n        text_file_only: bool = True,\n        single_file_only: bool = True,\n        file_required: bool = True,\n    ):\n        _CommandExecutor.__init__(self, cmd_name, validator)\n        self.text_file_only = text_file_only\n        self.single_file_only = single_file_only\n        self.file_required = file_required",
  "def validate_shell_command(self, args: List[str], parse_result):\n        if self.file_required or parse_result.files:\n            if not hasattr(parse_result, \"files\"):\n                return \"a file is required as an argument\"\n            if self.single_file_only and len(parse_result.files) != 1:\n                return \"only one file is allowed\"\n\n            if isinstance(parse_result.files, list):\n                file_list = parse_result.files\n            else:\n                file_list = [parse_result.files]\n\n            for f in file_list:\n                if not isinstance(f, str):\n                    raise TypeError(\"file must be str but got {}\".format(type(f)))\n\n                if not re.match(\"^[A-Za-z0-9-._/]*$\", f):\n                    return \"unsupported file {}\".format(f)\n\n                if f.startswith(\"/\"):\n                    return \"absolute path is not allowed\"\n\n                paths = f.split(\"/\")\n                for p in paths:\n                    if p == \"..\":\n                        return \".. in path name is not allowed\"\n\n                if self.text_file_only:\n                    basename, file_extension = os.path.splitext(f)\n                    if file_extension not in [\".txt\", \".log\", \".json\", \".csv\", \".sh\", \".config\", \".py\"]:\n                        return (\n                            \"this command cannot be applied to file {}. Only files with the following extensions \"\n                            \"are permitted: .txt, .log, .json, .csv, .sh, .config, .py\".format(f)\n                        )\n\n        return \"\"",
  "def get_spec(self):\n        pwd_exe = _NoArgCmdExecutor(\"pwd\")\n        ls_exe = _FileCmdExecutor(\n            \"ls\", LsValidator(), text_file_only=False, single_file_only=False, file_required=False\n        )\n        cat_exe = _FileCmdExecutor(\"cat\", CatValidator())\n        head_exe = _FileCmdExecutor(\"head\", HeadValidator())\n        tail_exe = _FileCmdExecutor(\"tail\", TailValidator())\n        grep_exe = _FileCmdExecutor(\"grep\", GrepValidator())\n\n        return CommandModuleSpec(\n            name=\"sys\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"pwd\",\n                    description=\"print the name of work directory\",\n                    usage=\"pwd target\\n\" + 'where target is \"server\" or client name\\n' + pwd_exe.get_usage(),\n                    handler_func=pwd_exe.execute_command,\n                    authz_func=pwd_exe.authorize_command,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"ls\",\n                    description=\"list files in work dir\",\n                    usage=\"ls target [options] [files]\\n \"\n                    + 'where target is \"server\" or client name\\n'\n                    + ls_exe.get_usage(),\n                    handler_func=ls_exe.execute_command,\n                    authz_func=ls_exe.authorize_command,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"cat\",\n                    description=\"show content of a file\",\n                    usage=\"cat target [options] fileName\\n \"\n                    + 'where target is \"server\" or client name\\n'\n                    + cat_exe.get_usage(),\n                    handler_func=cat_exe.execute_command,\n                    authz_func=cat_exe.authorize_command,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"head\",\n                    description=\"print the first 10 lines of a file\",\n                    usage=\"head target [options] fileName\\n \"\n                    + 'where target is \"server\" or client name\\n'\n                    + head_exe.get_usage(),\n                    handler_func=head_exe.execute_command,\n                    authz_func=head_exe.authorize_command,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"tail\",\n                    description=\"print the last 10 lines of a file\",\n                    usage=\"tail target [options] fileName\\n \"\n                    + 'where target is \"server\" or client name\\n'\n                    + tail_exe.get_usage(),\n                    handler_func=tail_exe.execute_command,\n                    authz_func=tail_exe.authorize_command,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"grep\",\n                    description=\"search for PATTERN in a file.\",\n                    usage=\"grep target [options] PATTERN fileName\\n \"\n                    + 'where target is \"server\" or client name\\n'\n                    + grep_exe.get_usage(),\n                    handler_func=grep_exe.execute_command,\n                    authz_func=grep_exe.authorize_command,\n                    visible=True,\n                ),\n            ],\n        )",
  "class RunInfo(object):\n    def __init__(self, job_id, app_path):\n        \"\"\"Information for a run.\"\"\"\n        self.job_id = job_id\n        self.start_time = time.time()\n        self.app_path = app_path\n        self.status = MachineStatus.STOPPED",
  "class RunManager:\n    def __init__(\n        self,\n        server_name,\n        engine: ServerEngineSpec,\n        job_id,\n        workspace: Workspace,\n        components: {str: FLComponent},\n        client_manager: Optional[ClientManager] = None,\n        handlers: Optional[List[FLComponent]] = None,\n    ):\n        \"\"\"Manage run.\n\n        Args:\n            server_name: server name\n            engine (ServerEngineSpec): server engine\n            job_id: job id\n            workspace (Workspace): workspace\n            components (dict): A dict of extra python objects {id: object}\n            client_manager (ClientManager, optional): client manager\n            handlers (List[FLComponent], optional): handlers\n        \"\"\"\n        super().__init__()\n        self.server_name = server_name\n\n        self.client_manager = client_manager\n        self.handlers = handlers\n        self.aux_runner = ServerAuxRunner()\n        self.add_handler(self.aux_runner)\n\n        self.fl_ctx_mgr = FLContextManager(\n            engine=engine, identity_name=server_name, job_id=job_id, public_stickers={}, private_stickers={}\n        )\n\n        self.workspace = workspace\n        self.run_info = RunInfo(job_id=job_id, app_path=self.workspace.get_app_dir(job_id))\n\n        self.components = components\n\n    def get_server_name(self):\n        return self.server_name\n\n    def get_run_info(self):\n        return self.run_info\n\n    def get_handlers(self):\n        return self.handlers\n\n    def new_context(self) -> FLContext:\n        return self.fl_ctx_mgr.new_context()\n\n    def get_workspace(self) -> Workspace:\n        return self.workspace\n\n    def get_component(self, component_id: str) -> object:\n        return self.components.get(component_id)\n\n    def add_component(self, component_id: str, component):\n        self.components[component_id] = component\n\n    def fire_event(self, event_type: str, fl_ctx: FLContext):\n        fire_event(event=event_type, handlers=self.handlers, ctx=fl_ctx)\n\n    def add_handler(self, handler: FLComponent):\n        self.handlers.append(handler)",
  "def __init__(self, job_id, app_path):\n        \"\"\"Information for a run.\"\"\"\n        self.job_id = job_id\n        self.start_time = time.time()\n        self.app_path = app_path\n        self.status = MachineStatus.STOPPED",
  "def __init__(\n        self,\n        server_name,\n        engine: ServerEngineSpec,\n        job_id,\n        workspace: Workspace,\n        components: {str: FLComponent},\n        client_manager: Optional[ClientManager] = None,\n        handlers: Optional[List[FLComponent]] = None,\n    ):\n        \"\"\"Manage run.\n\n        Args:\n            server_name: server name\n            engine (ServerEngineSpec): server engine\n            job_id: job id\n            workspace (Workspace): workspace\n            components (dict): A dict of extra python objects {id: object}\n            client_manager (ClientManager, optional): client manager\n            handlers (List[FLComponent], optional): handlers\n        \"\"\"\n        super().__init__()\n        self.server_name = server_name\n\n        self.client_manager = client_manager\n        self.handlers = handlers\n        self.aux_runner = ServerAuxRunner()\n        self.add_handler(self.aux_runner)\n\n        self.fl_ctx_mgr = FLContextManager(\n            engine=engine, identity_name=server_name, job_id=job_id, public_stickers={}, private_stickers={}\n        )\n\n        self.workspace = workspace\n        self.run_info = RunInfo(job_id=job_id, app_path=self.workspace.get_app_dir(job_id))\n\n        self.components = components",
  "def get_server_name(self):\n        return self.server_name",
  "def get_run_info(self):\n        return self.run_info",
  "def get_handlers(self):\n        return self.handlers",
  "def new_context(self) -> FLContext:\n        return self.fl_ctx_mgr.new_context()",
  "def get_workspace(self) -> Workspace:\n        return self.workspace",
  "def get_component(self, component_id: str) -> object:\n        return self.components.get(component_id)",
  "def add_component(self, component_id: str, component):\n        self.components[component_id] = component",
  "def fire_event(self, event_type: str, fl_ctx: FLContext):\n        fire_event(event=event_type, handlers=self.handlers, ctx=fl_ctx)",
  "def add_handler(self, handler: FLComponent):\n        self.handlers.append(handler)",
  "class InfoCollectorCommandModule(CommandModule, CommandUtil):\n    \"\"\"This class is for server side info collector commands.\n\n    NOTE: we only support Server side info collector commands for now,\n    due to the complexity of client-side process/child-process architecture.\n    \"\"\"\n\n    CONN_KEY_COLLECTOR = \"collector\"\n\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=\"info\",\n            cmd_specs=[\n                CommandSpec(\n                    name=AdminCommandNames.SHOW_STATS,\n                    description=\"show current system stats for an actively running job\",\n                    usage=\"show_stats job_id server|client\",\n                    handler_func=self.show_stats,\n                    authz_func=self.authorize_info_collection,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.SHOW_ERRORS,\n                    description=\"show latest errors in an actively running job\",\n                    usage=\"show_errors job_id server|client\",\n                    handler_func=self.show_errors,\n                    authz_func=self.authorize_info_collection,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.RESET_ERRORS,\n                    description=\"reset errors\",\n                    usage=\"reset_errors\",\n                    handler_func=self.reset_errors,\n                    authz_func=self.authorize_info_collection,\n                    visible=True,\n                ),\n            ],\n        )\n\n    def authorize_info_collection(self, conn: Connection, args: List[str]):\n        if len(args) != 3:\n            conn.append_error(\"syntax error: missing job_id and target\")\n            return False, None\n\n        run_destination = args[1].lower()\n        if not run_destination.startswith(WorkspaceConstants.WORKSPACE_PREFIX):\n            conn.append_error(\"syntax error: run_destination must be run_XXX\")\n            return False, None\n        job_id = run_destination[len(WorkspaceConstants.WORKSPACE_PREFIX) :]\n        conn.set_prop(self.JOB_ID, job_id)\n\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        collector = engine.get_widget(WidgetID.INFO_COLLECTOR)\n        if not collector:\n            conn.append_error(\"info collector not available\")\n            return False, None\n\n        if not isinstance(collector, InfoCollector):\n            conn.append_error(\"system error: info collector not right object\")\n            return False, None\n\n        conn.set_prop(self.CONN_KEY_COLLECTOR, collector)\n\n        run_info = engine.get_app_run_info(job_id)\n        if not run_info:\n            conn.append_string(\n                \"Cannot find job: {}. Please make sure the first arg following the command is a valid job_id.\".format(\n                    job_id\n                )\n            )\n            return False, None\n\n        # return True, FLAuthzContext.new_authz_context(\n        #     site_names=['server'],\n        #     actions=[Action.VIEW])\n        auth_args = [args[0]]\n        auth_args.extend(args[2:])\n        return self.authorize_view(conn, auth_args)\n\n    def show_stats(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        job_id = conn.get_prop(self.JOB_ID)\n        target_type = args[2]\n        if target_type == self.TARGET_TYPE_SERVER:\n            result = engine.show_stats(job_id)\n            conn.append_any(result)\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            message = new_message(conn, topic=InfoCollectorTopic.SHOW_STATS, body=\"\")\n            message.set_header(RequestHeader.JOB_ID, job_id)\n            replies = self.send_request_to_clients(conn, message)\n            self._process_stats_replies(conn, replies)\n\n        # collector = conn.get_prop(self.CONN_KEY_COLLECTOR)\n        # result = collector.get_run_stats()\n        # conn.append_any(result)\n\n    def show_errors(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        job_id = conn.get_prop(self.JOB_ID)\n        target_type = args[2]\n        if target_type == self.TARGET_TYPE_SERVER:\n            result = engine.get_errors(job_id)\n            conn.append_any(result)\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            message = new_message(conn, topic=InfoCollectorTopic.SHOW_ERRORS, body=\"\")\n            replies = self.send_request_to_clients(conn, message)\n            self._process_stats_replies(conn, replies)\n\n    def reset_errors(self, conn: Connection, args: List[str]):\n        job_id = conn.get_prop(self.JOB_ID)\n        collector = conn.get_prop(self.CONN_KEY_COLLECTOR)\n        collector.reset_errors()\n        conn.append_string(\"errors reset\")\n\n    def _process_stats_replies(self, conn, replies):\n        if not replies:\n            conn.append_error(\"no responses from clients\")\n            return\n\n        engine = conn.app_ctx\n        for r in replies:\n            client_name = engine.get_client_name_from_token(r.client_token)\n\n            conn.append_string(f\"--- Client ---: {client_name}\")\n            try:\n                body = json.loads(r.reply.body)\n                conn.append_any(body)\n            except BaseException:\n                conn.append_string(\"Bad responses from clients\")",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=\"info\",\n            cmd_specs=[\n                CommandSpec(\n                    name=AdminCommandNames.SHOW_STATS,\n                    description=\"show current system stats for an actively running job\",\n                    usage=\"show_stats job_id server|client\",\n                    handler_func=self.show_stats,\n                    authz_func=self.authorize_info_collection,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.SHOW_ERRORS,\n                    description=\"show latest errors in an actively running job\",\n                    usage=\"show_errors job_id server|client\",\n                    handler_func=self.show_errors,\n                    authz_func=self.authorize_info_collection,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=AdminCommandNames.RESET_ERRORS,\n                    description=\"reset errors\",\n                    usage=\"reset_errors\",\n                    handler_func=self.reset_errors,\n                    authz_func=self.authorize_info_collection,\n                    visible=True,\n                ),\n            ],\n        )",
  "def authorize_info_collection(self, conn: Connection, args: List[str]):\n        if len(args) != 3:\n            conn.append_error(\"syntax error: missing job_id and target\")\n            return False, None\n\n        run_destination = args[1].lower()\n        if not run_destination.startswith(WorkspaceConstants.WORKSPACE_PREFIX):\n            conn.append_error(\"syntax error: run_destination must be run_XXX\")\n            return False, None\n        job_id = run_destination[len(WorkspaceConstants.WORKSPACE_PREFIX) :]\n        conn.set_prop(self.JOB_ID, job_id)\n\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        collector = engine.get_widget(WidgetID.INFO_COLLECTOR)\n        if not collector:\n            conn.append_error(\"info collector not available\")\n            return False, None\n\n        if not isinstance(collector, InfoCollector):\n            conn.append_error(\"system error: info collector not right object\")\n            return False, None\n\n        conn.set_prop(self.CONN_KEY_COLLECTOR, collector)\n\n        run_info = engine.get_app_run_info(job_id)\n        if not run_info:\n            conn.append_string(\n                \"Cannot find job: {}. Please make sure the first arg following the command is a valid job_id.\".format(\n                    job_id\n                )\n            )\n            return False, None\n\n        # return True, FLAuthzContext.new_authz_context(\n        #     site_names=['server'],\n        #     actions=[Action.VIEW])\n        auth_args = [args[0]]\n        auth_args.extend(args[2:])\n        return self.authorize_view(conn, auth_args)",
  "def show_stats(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        job_id = conn.get_prop(self.JOB_ID)\n        target_type = args[2]\n        if target_type == self.TARGET_TYPE_SERVER:\n            result = engine.show_stats(job_id)\n            conn.append_any(result)\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            message = new_message(conn, topic=InfoCollectorTopic.SHOW_STATS, body=\"\")\n            message.set_header(RequestHeader.JOB_ID, job_id)\n            replies = self.send_request_to_clients(conn, message)\n            self._process_stats_replies(conn, replies)",
  "def show_errors(self, conn: Connection, args: List[str]):\n        engine = conn.app_ctx\n        if not isinstance(engine, ServerEngineInternalSpec):\n            raise TypeError(\"engine must be ServerEngineInternalSpec but got {}\".format(type(engine)))\n\n        job_id = conn.get_prop(self.JOB_ID)\n        target_type = args[2]\n        if target_type == self.TARGET_TYPE_SERVER:\n            result = engine.get_errors(job_id)\n            conn.append_any(result)\n        elif target_type == self.TARGET_TYPE_CLIENT:\n            message = new_message(conn, topic=InfoCollectorTopic.SHOW_ERRORS, body=\"\")\n            replies = self.send_request_to_clients(conn, message)\n            self._process_stats_replies(conn, replies)",
  "def reset_errors(self, conn: Connection, args: List[str]):\n        job_id = conn.get_prop(self.JOB_ID)\n        collector = conn.get_prop(self.CONN_KEY_COLLECTOR)\n        collector.reset_errors()\n        conn.append_string(\"errors reset\")",
  "def _process_stats_replies(self, conn, replies):\n        if not replies:\n            conn.append_error(\"no responses from clients\")\n            return\n\n        engine = conn.app_ctx\n        for r in replies:\n            client_name = engine.get_client_name_from_token(r.client_token)\n\n            conn.append_string(f\"--- Client ---: {client_name}\")\n            try:\n                body = json.loads(r.reply.body)\n                conn.append_any(body)\n            except BaseException:\n                conn.append_string(\"Bad responses from clients\")",
  "def _send_to_clients(admin_server, client_sites: List[str], engine, message):\n    clients, invalid_inputs = engine.validate_clients(client_sites)\n    if invalid_inputs:\n        raise RuntimeError(f\"invalid clients: {invalid_inputs}.\")\n    requests = {}\n    for c in clients:\n        requests.update({c.token: message})\n    replies = admin_server.send_requests(requests, timeout_secs=admin_server.timeout)\n    return replies",
  "class JobRunner(FLComponent):\n    def __init__(self, workspace_root: str) -> None:\n        super().__init__()\n        self.workspace_root = workspace_root\n        self.ask_to_stop = False\n        self.scheduler = None\n        self.running_jobs = {}\n        self.lock = threading.Lock()\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.SYSTEM_START:\n            engine = fl_ctx.get_engine()\n            self.scheduler = engine.get_component(SystemComponents.JOB_SCHEDULER)\n        elif event_type in [EventType.JOB_COMPLETED, EventType.JOB_ABORTED, EventType.JOB_CANCELLED]:\n            self._save_workspace(fl_ctx)\n\n    def _deploy_clients(self, app_data, app_name, job_id, client_sites: List[str], fl_ctx):\n        engine = fl_ctx.get_engine()\n        # deploy app to all the client sites\n        admin_server = engine.server.admin_server\n        message = Message(topic=TrainingTopic.DEPLOY, body=app_data)\n        message.set_header(RequestHeader.JOB_ID, job_id)\n        message.set_header(RequestHeader.APP_NAME, app_name)\n        self.log_debug(fl_ctx, f\"Send deploy command to the clients for run: {job_id}\")\n        replies = _send_to_clients(admin_server, client_sites, engine, message)\n        return replies\n\n    def _deploy_job(self, job: Job, sites: dict, fl_ctx: FLContext) -> str:\n        \"\"\"Deploy the application to the list of participants\n\n        Args:\n            job: job to be deployed\n            sites: participating sites\n            fl_ctx: FLContext\n\n        Returns:\n            job_id\n        \"\"\"\n        fl_ctx.remove_prop(FLContextKey.JOB_RUN_NUMBER)\n        engine = fl_ctx.get_engine()\n        run_number = job.job_id\n        workspace = os.path.join(self.workspace_root, WorkspaceConstants.WORKSPACE_PREFIX + run_number)\n        count = 1\n        while os.path.exists(workspace):\n            run_number = job.job_id + \":\" + str(count)\n            workspace = os.path.join(self.workspace_root, WorkspaceConstants.WORKSPACE_PREFIX + run_number)\n            count += 1\n        fl_ctx.set_prop(FLContextKey.JOB_RUN_NUMBER, run_number)\n\n        for app_name, participants in job.get_deployment().items():\n            app_data = job.get_application(app_name, fl_ctx)\n\n            if len(participants) == 1 and participants[0].upper() == ALL_SITES:\n                participants = [\"server\"]\n                participants.extend([client.name for client in engine.get_clients()])\n\n            client_sites = []\n            for p in participants:\n                if p == \"server\":\n                    success = deploy_app(app_name=app_name, site_name=\"server\", workspace=workspace, app_data=app_data)\n                    self.log_info(\n                        fl_ctx, f\"Application {app_name} deployed to the server for job: {run_number}\", fire_event=False\n                    )\n                    if not success:\n                        raise RuntimeError(f\"Failed to deploy the App: {app_name} to the server\")\n                else:\n                    if p in sites:\n                        client_sites.append(p)\n\n            if client_sites:\n                replies = self._deploy_clients(app_data, app_name, run_number, client_sites, fl_ctx)\n                check_client_replies(replies=replies, client_sites=client_sites, command=\"deploy the App\")\n                display_sites = \",\".join(client_sites)\n                self.log_info(\n                    fl_ctx,\n                    f\"Application {app_name} deployed to the clients: {display_sites} for run: {run_number}\",\n                    fire_event=False,\n                )\n\n        self.fire_event(EventType.JOB_DEPLOYED, fl_ctx)\n        return run_number\n\n    def _start_run(self, job_id: str, job: Job, client_sites: dict, fl_ctx: FLContext):\n        \"\"\"Start the application\n\n        Args:\n            job_id: job_id\n            client_sites: participating sites\n            fl_ctx: FLContext\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        job_clients = engine.get_job_clients(client_sites)\n        err = engine.start_app_on_server(job_id, job_id=job.job_id, job_clients=job_clients)\n        if err:\n            raise RuntimeError(f\"Could not start the server App for job: {job_id}.\")\n\n        replies = engine.start_client_job(job_id, client_sites)\n        client_sites_names = list(client_sites.keys())\n        check_client_replies(replies=replies, client_sites=client_sites_names, command=f\"start job ({job_id})\")\n        display_sites = \",\".join(client_sites_names)\n\n        self.log_info(fl_ctx, f\"Started run: {job_id} for clients: {display_sites}\")\n        self.fire_event(EventType.JOB_STARTED, fl_ctx)\n\n    def _stop_run(self, job_id, fl_ctx: FLContext):\n        \"\"\"Stop the application\n\n        Args:\n            job_id: job_id to be stopped\n            fl_ctx: FLContext\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        run_process = engine.run_processes.get(job_id)\n        if run_process:\n            client_sites = run_process.get(RunProcessKey.PARTICIPANTS)\n            self.abort_client_run(job_id, client_sites, fl_ctx)\n\n            err = engine.abort_app_on_server(job_id)\n            if err:\n                self.log_error(fl_ctx, f\"Failed to abort the server for run: {job_id}\")\n\n    def abort_client_run(self, job_id, client_sites: List[str], fl_ctx):\n        \"\"\"Send the abort run command to the clients\n\n        Args:\n            job_id: job_id\n            client_sites: Clients to be aborted\n            fl_ctx: FLContext\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        admin_server = engine.server.admin_server\n        message = Message(topic=TrainingTopic.ABORT, body=\"\")\n        message.set_header(RequestHeader.JOB_ID, str(job_id))\n        self.log_debug(fl_ctx, f\"Send abort command to the clients for run: {job_id}\")\n        try:\n            replies = _send_to_clients(admin_server, client_sites, engine, message)\n            check_client_replies(replies=replies, client_sites=client_sites, command=\"abort the run\")\n        except RuntimeError as e:\n            self.log_error(fl_ctx, f\"Failed to abort run ({job_id}) on the clients: {e}\")\n\n    def _delete_run(self, job_id, client_sites: List[str], fl_ctx: FLContext):\n        \"\"\"Deletes the run workspace\n\n        Args:\n            job_id: job_id\n            client_sites: participating sites\n            fl_ctx: FLContext\n        \"\"\"\n        engine = fl_ctx.get_engine()\n\n        admin_server = engine.server.admin_server\n        message = Message(topic=TrainingTopic.DELETE_RUN, body=\"\")\n        message.set_header(RequestHeader.JOB_ID, str(job_id))\n        self.log_debug(fl_ctx, f\"Send delete_run command to the clients for run: {job_id}\")\n        try:\n            replies = _send_to_clients(admin_server, client_sites, engine, message)\n            check_client_replies(replies=replies, client_sites=client_sites, command=\"send delete_run command\")\n        except RuntimeError as e:\n            self.log_error(fl_ctx, f\"Failed to execute delete run ({job_id}) on the clients: {e}\")\n\n        err = engine.delete_job_id(job_id)\n        if err:\n            self.log_error(fl_ctx, f\"Failed to delete_run the server for run: {job_id}\")\n\n    def _job_complete_process(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        job_manager = engine.get_component(SystemComponents.JOB_MANAGER)\n        while not self.ask_to_stop:\n            for job_id in list(self.running_jobs.keys()):\n                if job_id not in engine.run_processes.keys():\n                    with self.lock:\n                        job = self.running_jobs.get(job_id)\n                        if job:\n                            if job_id in engine.execution_exception_run_processes:\n                                self.log_info(fl_ctx, f\"Try to abort run ({job_id}) on clients.\")\n                                run_process = engine.execution_exception_run_processes[job_id]\n\n                                # stop client run\n                                client_sites = run_process.get(RunProcessKey.PARTICIPANTS)\n                                self.abort_client_run(job_id, client_sites, fl_ctx)\n\n                                job_manager.set_status(job.job_id, RunStatus.FINISHED_EXECUTION_EXCEPTION, fl_ctx)\n                            else:\n                                job_manager.set_status(job.job_id, RunStatus.FINISHED_COMPLETED, fl_ctx)\n                            del self.running_jobs[job_id]\n                            fl_ctx.set_prop(FLContextKey.CURRENT_JOB_ID, job.job_id)\n                            self.fire_event(EventType.JOB_COMPLETED, fl_ctx)\n                            self.log_debug(fl_ctx, f\"Finished running job:{job.job_id}\")\n            time.sleep(1.0)\n\n    def _save_workspace(self, fl_ctx: FLContext):\n        job_id = fl_ctx.get_prop(FLContextKey.CURRENT_JOB_ID)\n        workspace = os.path.join(self.workspace_root, WorkspaceConstants.WORKSPACE_PREFIX + job_id)\n        workspace_data = zip_directory_to_bytes(workspace, \"\")\n        engine = fl_ctx.get_engine()\n        job_manager = engine.get_component(SystemComponents.JOB_MANAGER)\n\n        job_manager.save_workspace(job_id, workspace_data, fl_ctx)\n        shutil.rmtree(workspace)\n\n    def run(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n\n        threading.Thread(target=self._job_complete_process, args=[fl_ctx]).start()\n\n        job_manager = engine.get_component(SystemComponents.JOB_MANAGER)\n        if job_manager:\n            while not self.ask_to_stop:\n                # approved_jobs = job_manager.get_jobs_by_status(RunStatus.APPROVED, fl_ctx)\n                approved_jobs = job_manager.get_jobs_by_status(RunStatus.SUBMITTED, fl_ctx)\n                if self.scheduler:\n                    (ready_job, sites) = self.scheduler.schedule_job(job_candidates=approved_jobs, fl_ctx=fl_ctx)\n                    if ready_job:\n                        with self.lock:\n                            client_sites = {k: v for k, v in sites.items() if k != \"server\"}\n                            job_id = None\n                            try:\n                                self.log_info(fl_ctx, f\"Got the job:{ready_job.job_id} from the scheduler to run\")\n                                fl_ctx.set_prop(FLContextKey.CURRENT_JOB_ID, ready_job.job_id)\n                                job_id = self._deploy_job(ready_job, sites, fl_ctx)\n                                job_manager.set_status(ready_job.job_id, RunStatus.DISPATCHED, fl_ctx)\n                                self._start_run(\n                                    job_id=job_id,\n                                    job=ready_job,\n                                    client_sites=client_sites,\n                                    fl_ctx=fl_ctx,\n                                )\n                                self.running_jobs[job_id] = ready_job\n                                job_manager.set_status(ready_job.job_id, RunStatus.RUNNING, fl_ctx)\n                            except Exception as e:\n                                if job_id:\n                                    if job_id in self.running_jobs:\n                                        del self.running_jobs[job_id]\n                                    self._stop_run(job_id, fl_ctx)\n                                job_manager.set_status(ready_job.job_id, RunStatus.FAILED_TO_RUN, fl_ctx)\n                                self.fire_event(EventType.JOB_ABORTED, fl_ctx)\n                                self.log_error(fl_ctx, f\"Failed to run the Job ({ready_job.job_id}): {e}\")\n\n                time.sleep(1.0)\n        else:\n            self.log_error(fl_ctx, \"There's no Job Manager defined. Won't be able to run the jobs.\")\n\n    def restore_running_job(self, run_number: str, job_id: str, job_clients, snapshot, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        engine.start_app_on_server(run_number, job_id=job_id, job_clients=job_clients, snapshot=snapshot)\n\n        try:\n            job_manager = engine.get_component(SystemComponents.JOB_MANAGER)\n            job = job_manager.get_job(jid=job_id, fl_ctx=fl_ctx)\n            with self.lock:\n                self.running_jobs[job_id] = job\n        except Exception as e:\n            self.log_error(fl_ctx, f\"Failed to restore the job: {job_id} to the running job table: {e}.\")\n\n    def stop_run(self, job_id: str, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        job_manager = engine.get_component(SystemComponents.JOB_MANAGER)\n        with self.lock:\n            self._stop_run(job_id, fl_ctx)\n            job = self.running_jobs.get(job_id)\n            if job:\n                self.log_info(fl_ctx, f\"Stop the job run: {job_id}\")\n                fl_ctx.set_prop(FLContextKey.CURRENT_JOB_ID, job.job_id)\n                job_manager.set_status(job.job_id, RunStatus.FINISHED_ABORTED, fl_ctx)\n                del self.running_jobs[job_id]\n                self.fire_event(EventType.JOB_ABORTED, fl_ctx)\n            else:\n                raise RuntimeError(f\"Job run: {job_id} does not exist.\")\n\n    def stop_all_runs(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        for job_id in engine.run_processes.keys():\n            self.stop_run(job_id, fl_ctx)\n\n        self.log_info(fl_ctx, \"Stop all the running jobs.\")\n        self.ask_to_stop = True",
  "def __init__(self, workspace_root: str) -> None:\n        super().__init__()\n        self.workspace_root = workspace_root\n        self.ask_to_stop = False\n        self.scheduler = None\n        self.running_jobs = {}\n        self.lock = threading.Lock()",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.SYSTEM_START:\n            engine = fl_ctx.get_engine()\n            self.scheduler = engine.get_component(SystemComponents.JOB_SCHEDULER)\n        elif event_type in [EventType.JOB_COMPLETED, EventType.JOB_ABORTED, EventType.JOB_CANCELLED]:\n            self._save_workspace(fl_ctx)",
  "def _deploy_clients(self, app_data, app_name, job_id, client_sites: List[str], fl_ctx):\n        engine = fl_ctx.get_engine()\n        # deploy app to all the client sites\n        admin_server = engine.server.admin_server\n        message = Message(topic=TrainingTopic.DEPLOY, body=app_data)\n        message.set_header(RequestHeader.JOB_ID, job_id)\n        message.set_header(RequestHeader.APP_NAME, app_name)\n        self.log_debug(fl_ctx, f\"Send deploy command to the clients for run: {job_id}\")\n        replies = _send_to_clients(admin_server, client_sites, engine, message)\n        return replies",
  "def _deploy_job(self, job: Job, sites: dict, fl_ctx: FLContext) -> str:\n        \"\"\"Deploy the application to the list of participants\n\n        Args:\n            job: job to be deployed\n            sites: participating sites\n            fl_ctx: FLContext\n\n        Returns:\n            job_id\n        \"\"\"\n        fl_ctx.remove_prop(FLContextKey.JOB_RUN_NUMBER)\n        engine = fl_ctx.get_engine()\n        run_number = job.job_id\n        workspace = os.path.join(self.workspace_root, WorkspaceConstants.WORKSPACE_PREFIX + run_number)\n        count = 1\n        while os.path.exists(workspace):\n            run_number = job.job_id + \":\" + str(count)\n            workspace = os.path.join(self.workspace_root, WorkspaceConstants.WORKSPACE_PREFIX + run_number)\n            count += 1\n        fl_ctx.set_prop(FLContextKey.JOB_RUN_NUMBER, run_number)\n\n        for app_name, participants in job.get_deployment().items():\n            app_data = job.get_application(app_name, fl_ctx)\n\n            if len(participants) == 1 and participants[0].upper() == ALL_SITES:\n                participants = [\"server\"]\n                participants.extend([client.name for client in engine.get_clients()])\n\n            client_sites = []\n            for p in participants:\n                if p == \"server\":\n                    success = deploy_app(app_name=app_name, site_name=\"server\", workspace=workspace, app_data=app_data)\n                    self.log_info(\n                        fl_ctx, f\"Application {app_name} deployed to the server for job: {run_number}\", fire_event=False\n                    )\n                    if not success:\n                        raise RuntimeError(f\"Failed to deploy the App: {app_name} to the server\")\n                else:\n                    if p in sites:\n                        client_sites.append(p)\n\n            if client_sites:\n                replies = self._deploy_clients(app_data, app_name, run_number, client_sites, fl_ctx)\n                check_client_replies(replies=replies, client_sites=client_sites, command=\"deploy the App\")\n                display_sites = \",\".join(client_sites)\n                self.log_info(\n                    fl_ctx,\n                    f\"Application {app_name} deployed to the clients: {display_sites} for run: {run_number}\",\n                    fire_event=False,\n                )\n\n        self.fire_event(EventType.JOB_DEPLOYED, fl_ctx)\n        return run_number",
  "def _start_run(self, job_id: str, job: Job, client_sites: dict, fl_ctx: FLContext):\n        \"\"\"Start the application\n\n        Args:\n            job_id: job_id\n            client_sites: participating sites\n            fl_ctx: FLContext\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        job_clients = engine.get_job_clients(client_sites)\n        err = engine.start_app_on_server(job_id, job_id=job.job_id, job_clients=job_clients)\n        if err:\n            raise RuntimeError(f\"Could not start the server App for job: {job_id}.\")\n\n        replies = engine.start_client_job(job_id, client_sites)\n        client_sites_names = list(client_sites.keys())\n        check_client_replies(replies=replies, client_sites=client_sites_names, command=f\"start job ({job_id})\")\n        display_sites = \",\".join(client_sites_names)\n\n        self.log_info(fl_ctx, f\"Started run: {job_id} for clients: {display_sites}\")\n        self.fire_event(EventType.JOB_STARTED, fl_ctx)",
  "def _stop_run(self, job_id, fl_ctx: FLContext):\n        \"\"\"Stop the application\n\n        Args:\n            job_id: job_id to be stopped\n            fl_ctx: FLContext\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        run_process = engine.run_processes.get(job_id)\n        if run_process:\n            client_sites = run_process.get(RunProcessKey.PARTICIPANTS)\n            self.abort_client_run(job_id, client_sites, fl_ctx)\n\n            err = engine.abort_app_on_server(job_id)\n            if err:\n                self.log_error(fl_ctx, f\"Failed to abort the server for run: {job_id}\")",
  "def abort_client_run(self, job_id, client_sites: List[str], fl_ctx):\n        \"\"\"Send the abort run command to the clients\n\n        Args:\n            job_id: job_id\n            client_sites: Clients to be aborted\n            fl_ctx: FLContext\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        admin_server = engine.server.admin_server\n        message = Message(topic=TrainingTopic.ABORT, body=\"\")\n        message.set_header(RequestHeader.JOB_ID, str(job_id))\n        self.log_debug(fl_ctx, f\"Send abort command to the clients for run: {job_id}\")\n        try:\n            replies = _send_to_clients(admin_server, client_sites, engine, message)\n            check_client_replies(replies=replies, client_sites=client_sites, command=\"abort the run\")\n        except RuntimeError as e:\n            self.log_error(fl_ctx, f\"Failed to abort run ({job_id}) on the clients: {e}\")",
  "def _delete_run(self, job_id, client_sites: List[str], fl_ctx: FLContext):\n        \"\"\"Deletes the run workspace\n\n        Args:\n            job_id: job_id\n            client_sites: participating sites\n            fl_ctx: FLContext\n        \"\"\"\n        engine = fl_ctx.get_engine()\n\n        admin_server = engine.server.admin_server\n        message = Message(topic=TrainingTopic.DELETE_RUN, body=\"\")\n        message.set_header(RequestHeader.JOB_ID, str(job_id))\n        self.log_debug(fl_ctx, f\"Send delete_run command to the clients for run: {job_id}\")\n        try:\n            replies = _send_to_clients(admin_server, client_sites, engine, message)\n            check_client_replies(replies=replies, client_sites=client_sites, command=\"send delete_run command\")\n        except RuntimeError as e:\n            self.log_error(fl_ctx, f\"Failed to execute delete run ({job_id}) on the clients: {e}\")\n\n        err = engine.delete_job_id(job_id)\n        if err:\n            self.log_error(fl_ctx, f\"Failed to delete_run the server for run: {job_id}\")",
  "def _job_complete_process(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        job_manager = engine.get_component(SystemComponents.JOB_MANAGER)\n        while not self.ask_to_stop:\n            for job_id in list(self.running_jobs.keys()):\n                if job_id not in engine.run_processes.keys():\n                    with self.lock:\n                        job = self.running_jobs.get(job_id)\n                        if job:\n                            if job_id in engine.execution_exception_run_processes:\n                                self.log_info(fl_ctx, f\"Try to abort run ({job_id}) on clients.\")\n                                run_process = engine.execution_exception_run_processes[job_id]\n\n                                # stop client run\n                                client_sites = run_process.get(RunProcessKey.PARTICIPANTS)\n                                self.abort_client_run(job_id, client_sites, fl_ctx)\n\n                                job_manager.set_status(job.job_id, RunStatus.FINISHED_EXECUTION_EXCEPTION, fl_ctx)\n                            else:\n                                job_manager.set_status(job.job_id, RunStatus.FINISHED_COMPLETED, fl_ctx)\n                            del self.running_jobs[job_id]\n                            fl_ctx.set_prop(FLContextKey.CURRENT_JOB_ID, job.job_id)\n                            self.fire_event(EventType.JOB_COMPLETED, fl_ctx)\n                            self.log_debug(fl_ctx, f\"Finished running job:{job.job_id}\")\n            time.sleep(1.0)",
  "def _save_workspace(self, fl_ctx: FLContext):\n        job_id = fl_ctx.get_prop(FLContextKey.CURRENT_JOB_ID)\n        workspace = os.path.join(self.workspace_root, WorkspaceConstants.WORKSPACE_PREFIX + job_id)\n        workspace_data = zip_directory_to_bytes(workspace, \"\")\n        engine = fl_ctx.get_engine()\n        job_manager = engine.get_component(SystemComponents.JOB_MANAGER)\n\n        job_manager.save_workspace(job_id, workspace_data, fl_ctx)\n        shutil.rmtree(workspace)",
  "def run(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n\n        threading.Thread(target=self._job_complete_process, args=[fl_ctx]).start()\n\n        job_manager = engine.get_component(SystemComponents.JOB_MANAGER)\n        if job_manager:\n            while not self.ask_to_stop:\n                # approved_jobs = job_manager.get_jobs_by_status(RunStatus.APPROVED, fl_ctx)\n                approved_jobs = job_manager.get_jobs_by_status(RunStatus.SUBMITTED, fl_ctx)\n                if self.scheduler:\n                    (ready_job, sites) = self.scheduler.schedule_job(job_candidates=approved_jobs, fl_ctx=fl_ctx)\n                    if ready_job:\n                        with self.lock:\n                            client_sites = {k: v for k, v in sites.items() if k != \"server\"}\n                            job_id = None\n                            try:\n                                self.log_info(fl_ctx, f\"Got the job:{ready_job.job_id} from the scheduler to run\")\n                                fl_ctx.set_prop(FLContextKey.CURRENT_JOB_ID, ready_job.job_id)\n                                job_id = self._deploy_job(ready_job, sites, fl_ctx)\n                                job_manager.set_status(ready_job.job_id, RunStatus.DISPATCHED, fl_ctx)\n                                self._start_run(\n                                    job_id=job_id,\n                                    job=ready_job,\n                                    client_sites=client_sites,\n                                    fl_ctx=fl_ctx,\n                                )\n                                self.running_jobs[job_id] = ready_job\n                                job_manager.set_status(ready_job.job_id, RunStatus.RUNNING, fl_ctx)\n                            except Exception as e:\n                                if job_id:\n                                    if job_id in self.running_jobs:\n                                        del self.running_jobs[job_id]\n                                    self._stop_run(job_id, fl_ctx)\n                                job_manager.set_status(ready_job.job_id, RunStatus.FAILED_TO_RUN, fl_ctx)\n                                self.fire_event(EventType.JOB_ABORTED, fl_ctx)\n                                self.log_error(fl_ctx, f\"Failed to run the Job ({ready_job.job_id}): {e}\")\n\n                time.sleep(1.0)\n        else:\n            self.log_error(fl_ctx, \"There's no Job Manager defined. Won't be able to run the jobs.\")",
  "def restore_running_job(self, run_number: str, job_id: str, job_clients, snapshot, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        engine.start_app_on_server(run_number, job_id=job_id, job_clients=job_clients, snapshot=snapshot)\n\n        try:\n            job_manager = engine.get_component(SystemComponents.JOB_MANAGER)\n            job = job_manager.get_job(jid=job_id, fl_ctx=fl_ctx)\n            with self.lock:\n                self.running_jobs[job_id] = job\n        except Exception as e:\n            self.log_error(fl_ctx, f\"Failed to restore the job: {job_id} to the running job table: {e}.\")",
  "def stop_run(self, job_id: str, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        job_manager = engine.get_component(SystemComponents.JOB_MANAGER)\n        with self.lock:\n            self._stop_run(job_id, fl_ctx)\n            job = self.running_jobs.get(job_id)\n            if job:\n                self.log_info(fl_ctx, f\"Stop the job run: {job_id}\")\n                fl_ctx.set_prop(FLContextKey.CURRENT_JOB_ID, job.job_id)\n                job_manager.set_status(job.job_id, RunStatus.FINISHED_ABORTED, fl_ctx)\n                del self.running_jobs[job_id]\n                self.fire_event(EventType.JOB_ABORTED, fl_ctx)\n            else:\n                raise RuntimeError(f\"Job run: {job_id} does not exist.\")",
  "def stop_all_runs(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        for job_id in engine.run_processes.keys():\n            self.stop_run(job_id, fl_ctx)\n\n        self.log_info(fl_ctx, \"Stop all the running jobs.\")\n        self.ask_to_stop = True",
  "class ServiceSession:\n    def __init__(self, host: str = \"\", port: str = \"\", ssid: str = \"\") -> None:\n        self.host = host\n        self.service_port = port\n        self.ssid = ssid",
  "class ServerState(object):\n    NOT_IN_SERVICE = {ACTION: NIS, MESSAGE: \"Server not in service\"}\n    ABORT_CURRENT_RUN = {ACTION: ABORT_RUN, MESSAGE: \"Abort current run\"}\n    IN_SSERVICE = {ACTION: SERVICE, MESSAGE: \"Server in service\"}\n\n    def __init__(self, host: str = \"\", port: str = \"\", ssid: str = \"\") -> None:\n        self.host = host\n        self.service_port = port\n        self.ssid = ssid\n\n        self.logger = logging.getLogger(\"FederatedServer\")\n\n    def register(self, fl_ctx: FLContext) -> dict:\n        pass\n\n    def heartbeat(self, fl_ctx: FLContext) -> dict:\n        pass\n\n    def get_task(self, fl_ctx: FLContext) -> dict:\n        pass\n\n    def submit_result(self, fl_ctx: FLContext) -> dict:\n        pass\n\n    def aux_communicate(self, fl_ctx: FLContext) -> dict:\n        pass\n\n    def handle_sd_callback(self, sp: SP, fl_ctx: FLContext) -> ServerState:\n        pass",
  "class ColdState(ServerState):\n    def __init__(self, host: str = \"\", port: str = \"\", ssid: str = \"\") -> None:\n        super().__init__(host, port, ssid)\n\n    def register(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def heartbeat(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def get_task(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def submit_result(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def aux_communicate(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def handle_sd_callback(self, sp: SP, fl_ctx: FLContext) -> ServerState:\n        if sp and sp.primary is True:\n            if sp.name == self.host and sp.fl_port == self.service_port:\n                self.primary = True\n                self.ssid = sp.service_session_id\n                self.logger.info(\n                    f\"Got the primary sp: {sp.name} fl_port: {sp.fl_port} SSID: {sp.service_session_id}. \"\n                    f\"Turning to hot.\"\n                )\n                return Cold2HotState(host=self.host, port=self.service_port, ssid=sp.service_session_id)\n            else:\n                self.primary = False\n                return self\n        return self",
  "class Cold2HotState(ServerState):\n    def __init__(self, host: str = \"\", port: str = \"\", ssid: str = \"\") -> None:\n        super().__init__(host, port, ssid)\n\n    def register(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE\n\n    def heartbeat(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE\n\n    def get_task(self, fl_ctx: FLContext) -> dict:\n        return ServerState.ABORT_CURRENT_RUN\n\n    def submit_result(self, fl_ctx: FLContext) -> dict:\n        return ServerState.ABORT_CURRENT_RUN\n\n    def aux_communicate(self, fl_ctx: FLContext) -> dict:\n        return ServerState.ABORT_CURRENT_RUN\n\n    def handle_sd_callback(self, sp: SP, fl_ctx: FLContext) -> ServerState:\n        return self",
  "class HotState(ServerState):\n    def __init__(self, host: str = \"\", port: str = \"\", ssid: str = \"\") -> None:\n        super().__init__(host, port, ssid)\n\n    def register(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE\n\n    def heartbeat(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE\n\n    def get_task(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE\n\n    def submit_result(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE\n\n    def aux_communicate(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE\n\n    def handle_sd_callback(self, sp: SP, fl_ctx: FLContext) -> ServerState:\n        if sp and sp.primary is True:\n            if sp.name == self.host and sp.fl_port == self.service_port:\n                self.primary = True\n                if sp.service_session_id != self.ssid:\n                    self.ssid = sp.service_session_id\n                    self.logger.info(\n                        f\"Primary sp changed to: {sp.name} fl_port: {sp.fl_port} SSID: {sp.service_session_id}. \"\n                        f\"Turning to Cold\"\n                    )\n                    return Hot2ColdState(host=self.host, port=self.service_port, ssid=sp.service_session_id)\n                else:\n                    return self\n            else:\n                self.primary = False\n                self.logger.info(\n                    f\"Primary sp changed to: {sp.name} fl_port: {sp.fl_port} SSID: {sp.service_session_id}. \"\n                    f\"Turning to Cold\"\n                )\n                return Hot2ColdState(host=self.host, port=self.service_port)\n        return self",
  "class Hot2ColdState(ServerState):\n    def register(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def heartbeat(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def get_task(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def submit_result(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def aux_communicate(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def handle_sd_callback(self, sp: SP, fl_ctx: FLContext) -> ServerState:\n        return self",
  "class ShutdownState(ServerState):\n    def register(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def heartbeat(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def get_task(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def submit_result(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def aux_communicate(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE\n\n    def handle_sd_callback(self, sp: SP, fl_ctx: FLContext) -> ServerState:\n        return self",
  "def __init__(self, host: str = \"\", port: str = \"\", ssid: str = \"\") -> None:\n        self.host = host\n        self.service_port = port\n        self.ssid = ssid",
  "def __init__(self, host: str = \"\", port: str = \"\", ssid: str = \"\") -> None:\n        self.host = host\n        self.service_port = port\n        self.ssid = ssid\n\n        self.logger = logging.getLogger(\"FederatedServer\")",
  "def register(self, fl_ctx: FLContext) -> dict:\n        pass",
  "def heartbeat(self, fl_ctx: FLContext) -> dict:\n        pass",
  "def get_task(self, fl_ctx: FLContext) -> dict:\n        pass",
  "def submit_result(self, fl_ctx: FLContext) -> dict:\n        pass",
  "def aux_communicate(self, fl_ctx: FLContext) -> dict:\n        pass",
  "def handle_sd_callback(self, sp: SP, fl_ctx: FLContext) -> ServerState:\n        pass",
  "def __init__(self, host: str = \"\", port: str = \"\", ssid: str = \"\") -> None:\n        super().__init__(host, port, ssid)",
  "def register(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def heartbeat(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def get_task(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def submit_result(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def aux_communicate(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def handle_sd_callback(self, sp: SP, fl_ctx: FLContext) -> ServerState:\n        if sp and sp.primary is True:\n            if sp.name == self.host and sp.fl_port == self.service_port:\n                self.primary = True\n                self.ssid = sp.service_session_id\n                self.logger.info(\n                    f\"Got the primary sp: {sp.name} fl_port: {sp.fl_port} SSID: {sp.service_session_id}. \"\n                    f\"Turning to hot.\"\n                )\n                return Cold2HotState(host=self.host, port=self.service_port, ssid=sp.service_session_id)\n            else:\n                self.primary = False\n                return self\n        return self",
  "def __init__(self, host: str = \"\", port: str = \"\", ssid: str = \"\") -> None:\n        super().__init__(host, port, ssid)",
  "def register(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE",
  "def heartbeat(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE",
  "def get_task(self, fl_ctx: FLContext) -> dict:\n        return ServerState.ABORT_CURRENT_RUN",
  "def submit_result(self, fl_ctx: FLContext) -> dict:\n        return ServerState.ABORT_CURRENT_RUN",
  "def aux_communicate(self, fl_ctx: FLContext) -> dict:\n        return ServerState.ABORT_CURRENT_RUN",
  "def handle_sd_callback(self, sp: SP, fl_ctx: FLContext) -> ServerState:\n        return self",
  "def __init__(self, host: str = \"\", port: str = \"\", ssid: str = \"\") -> None:\n        super().__init__(host, port, ssid)",
  "def register(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE",
  "def heartbeat(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE",
  "def get_task(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE",
  "def submit_result(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE",
  "def aux_communicate(self, fl_ctx: FLContext) -> dict:\n        return ServerState.IN_SSERVICE",
  "def handle_sd_callback(self, sp: SP, fl_ctx: FLContext) -> ServerState:\n        if sp and sp.primary is True:\n            if sp.name == self.host and sp.fl_port == self.service_port:\n                self.primary = True\n                if sp.service_session_id != self.ssid:\n                    self.ssid = sp.service_session_id\n                    self.logger.info(\n                        f\"Primary sp changed to: {sp.name} fl_port: {sp.fl_port} SSID: {sp.service_session_id}. \"\n                        f\"Turning to Cold\"\n                    )\n                    return Hot2ColdState(host=self.host, port=self.service_port, ssid=sp.service_session_id)\n                else:\n                    return self\n            else:\n                self.primary = False\n                self.logger.info(\n                    f\"Primary sp changed to: {sp.name} fl_port: {sp.fl_port} SSID: {sp.service_session_id}. \"\n                    f\"Turning to Cold\"\n                )\n                return Hot2ColdState(host=self.host, port=self.service_port)\n        return self",
  "def register(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def heartbeat(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def get_task(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def submit_result(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def aux_communicate(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def handle_sd_callback(self, sp: SP, fl_ctx: FLContext) -> ServerState:\n        return self",
  "def register(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def heartbeat(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def get_task(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def submit_result(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def aux_communicate(self, fl_ctx: FLContext) -> dict:\n        return ServerState.NOT_IN_SERVICE",
  "def handle_sd_callback(self, sp: SP, fl_ctx: FLContext) -> ServerState:\n        return self",
  "class ClientConnection:\n    def __init__(self, client):\n        self.client = client\n\n    def send(self, data):\n        data = pickle.dumps(data)\n        self.client.send(data)\n\n    def recv(self):\n        return self.client.recv()",
  "class ServerEngine(ServerEngineInternalSpec):\n    def __init__(self, server, args, client_manager: ClientManager, snapshot_persistor, workers=3):\n        \"\"\"Server engine.\n\n        Args:\n            server: server\n            args: arguments\n            client_manager (ClientManager): client manager.\n            workers: number of worker threads.\n        \"\"\"\n        # TODO:: clean up the server function / requirement here should be BaseServer\n        self.server = server\n        self.args = args\n        self.run_processes = {}\n        self.execution_exception_run_processes = {}\n        self.run_manager = None\n        self.conf = None\n        # TODO:: does this class need client manager?\n        self.client_manager = client_manager\n\n        self.widgets = {\n            WidgetID.INFO_COLLECTOR: InfoCollector(),\n            # WidgetID.FED_EVENT_RUNNER: ServerFedEventRunner()\n        }\n\n        self.engine_info = EngineInfo()\n\n        if not workers >= 1:\n            raise ValueError(\"workers must >= 1 but got {}\".format(workers))\n\n        self.executor = ThreadPoolExecutor(max_workers=workers)\n        self.lock = Lock()\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n        self.asked_to_stop = False\n        self.snapshot_persistor = snapshot_persistor\n        self.parent_conn = None\n        self.parent_conn_lock = Lock()\n        self.job_runner = None\n        self.job_def_manager = None\n        self.snapshot_lock = multiprocessing.Lock()\n\n    def _get_server_app_folder(self):\n        return WorkspaceConstants.APP_PREFIX + \"server\"\n\n    def _get_client_app_folder(self, client_name):\n        return WorkspaceConstants.APP_PREFIX + client_name\n\n    def _get_run_folder(self, job_id):\n        return os.path.join(self.args.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(job_id))\n\n    def get_engine_info(self) -> EngineInfo:\n        self.engine_info.app_names = {}\n        if bool(self.run_processes):\n            self.engine_info.status = MachineStatus.STARTED\n        else:\n            self.engine_info.status = MachineStatus.STOPPED\n\n        for job_id, _ in self.run_processes.items():\n            run_folder = os.path.join(self.args.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(job_id))\n            app_file = os.path.join(run_folder, \"fl_app.txt\")\n            if os.path.exists(app_file):\n                with open(app_file, \"r\") as f:\n                    self.engine_info.app_names[job_id] = f.readline().strip()\n            else:\n                self.engine_info.app_names[job_id] = \"?\"\n\n        return self.engine_info\n\n    def get_run_info(self) -> RunInfo:\n        if self.run_manager:\n            return self.run_manager.get_run_info()\n        else:\n            return None\n\n    def create_parent_connection(self, port):\n        while not self.parent_conn:\n            try:\n                address = (\"localhost\", port)\n                self.parent_conn = CommandClient(address, authkey=\"parent process secret password\".encode())\n            except BaseException:\n                time.sleep(1.0)\n                pass\n\n        threading.Thread(target=self.heartbeat_to_parent, args=[]).start()\n\n    def heartbeat_to_parent(self):\n        while True:\n            try:\n                with self.parent_conn_lock:\n                    data = {ServerCommandKey.COMMAND: ServerCommandNames.HEARTBEAT, ServerCommandKey.DATA: {}}\n                    self.parent_conn.send(data)\n                time.sleep(1.0)\n            except BaseException:\n                # The parent process can not be reached. Terminate the child process.\n                break\n        # delay some time for the wrap up process before the child process self terminate.\n        time.sleep(30)\n        os.killpg(os.getpgid(os.getpid()), 9)\n\n    def delete_job_id(self, num):\n        job_id_folder = os.path.join(self.args.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(num))\n        if os.path.exists(job_id_folder):\n            shutil.rmtree(job_id_folder)\n        return \"\"\n\n    def get_clients(self) -> [Client]:\n        return list(self.client_manager.get_clients().values())\n\n    def validate_clients(self, client_names: List[str]) -> Tuple[List[Client], List[str]]:\n        return self._get_all_clients_from_inputs(client_names)\n\n    def start_app_on_server(self, run_number: str, job_id: str = None, job_clients=None, snapshot=None) -> str:\n        if run_number in self.run_processes.keys():\n            return f\"Server run_{run_number} already started.\"\n        else:\n            app_root = os.path.join(self._get_run_folder(run_number), self._get_server_app_folder())\n            if not os.path.exists(app_root):\n                return \"Server app does not exist. Please deploy the server app before starting.\"\n\n            self.engine_info.status = MachineStatus.STARTING\n\n            app_custom_folder = \"\"\n            if self.server.enable_byoc:\n                app_custom_folder = os.path.join(app_root, \"custom\")\n\n            open_ports = get_open_ports(2)\n            self._start_runner_process(\n                self.args, app_root, run_number, app_custom_folder, open_ports, job_id, job_clients, snapshot\n            )\n\n            threading.Thread(target=self._listen_command, args=(open_ports[0], run_number)).start()\n\n            self.engine_info.status = MachineStatus.STARTED\n            return \"\"\n\n    def _listen_command(self, listen_port, job_id):\n        address = (\"localhost\", int(listen_port))\n        listener = Listener(address, authkey=\"parent process secret password\".encode())\n        conn = listener.accept()\n\n        while job_id in self.run_processes.keys():\n            clients = self.run_processes.get(job_id).get(RunProcessKey.PARTICIPANTS)\n            job_id = self.run_processes.get(job_id).get(RunProcessKey.JOB_ID)\n            try:\n                if conn.poll(0.1):\n                    received_data = conn.recv()\n                    command = received_data.get(ServerCommandKey.COMMAND)\n                    data = received_data.get(ServerCommandKey.DATA)\n\n                    if command == ServerCommandNames.GET_CLIENTS:\n                        return_data = {ServerCommandKey.CLIENTS: clients, ServerCommandKey.JOB_ID: job_id}\n                        conn.send(return_data)\n                    elif command == ServerCommandNames.AUX_SEND:\n                        targets = data.get(\"targets\")\n                        topic = data.get(\"topic\")\n                        request = data.get(\"request\")\n                        timeout = data.get(\"timeout\")\n                        fl_ctx = data.get(\"fl_ctx\")\n                        replies = self.aux_send(\n                            targets=targets, topic=topic, request=request, timeout=timeout, fl_ctx=fl_ctx\n                        )\n                        conn.send(replies)\n            except BaseException as e:\n                self.logger.warning(f\"Failed to process the child process command: {e}\", exc_info=True)\n\n    def wait_for_complete(self, job_id):\n        while True:\n            try:\n                with self.lock:\n                    command_conn = self.get_command_conn(job_id)\n                    if command_conn:\n                        data = {ServerCommandKey.COMMAND: ServerCommandNames.HEARTBEAT, ServerCommandKey.DATA: {}}\n                        command_conn.send(data)\n                time.sleep(1.0)\n            except BaseException:\n                with self.lock:\n                    run_process_info = self.run_processes.pop(job_id)\n                    return_code = run_process_info[RunProcessKey.CHILD_PROCESS].poll()\n                    # if process exit but with Execution exception\n                    if return_code and return_code != 0:\n                        self.execution_exception_run_processes[job_id] = run_process_info\n                self.engine_info.status = MachineStatus.STOPPED\n                break\n\n    def _start_runner_process(\n        self, args, app_root, run_number, app_custom_folder, open_ports, job_id, job_clients, snapshot\n    ):\n        new_env = os.environ.copy()\n        if app_custom_folder != \"\":\n            new_env[\"PYTHONPATH\"] = new_env.get(\"PYTHONPATH\", \"\") + os.pathsep + app_custom_folder\n\n        listen_port = open_ports[1]\n        if snapshot:\n            restore_snapshot = True\n        else:\n            restore_snapshot = False\n        command_options = \"\"\n        for t in args.set:\n            command_options += \" \" + t\n        command = (\n            sys.executable\n            + \" -m nvflare.private.fed.app.server.runner_process -m \"\n            + args.workspace\n            + \" -s fed_server.json -r \"\n            + app_root\n            + \" -n \"\n            + str(run_number)\n            + \" -p \"\n            + str(listen_port)\n            + \" -c \"\n            + str(open_ports[0])\n            + \" --set\"\n            + command_options\n            + \" print_conf=True restore_snapshot=\"\n            + str(restore_snapshot)\n        )\n        # use os.setsid to create new process group ID\n\n        process = subprocess.Popen(shlex.split(command, True), preexec_fn=os.setsid, env=new_env)\n\n        if not job_id:\n            job_id = \"\"\n        if not job_clients:\n            job_clients = self.client_manager.clients\n\n        with self.lock:\n            self.run_processes[run_number] = {\n                RunProcessKey.LISTEN_PORT: listen_port,\n                RunProcessKey.CONNECTION: None,\n                RunProcessKey.CHILD_PROCESS: process,\n                RunProcessKey.JOB_ID: job_id,\n                RunProcessKey.PARTICIPANTS: job_clients,\n            }\n\n        threading.Thread(target=self.wait_for_complete, args=[run_number]).start()\n        return process\n\n    def get_job_clients(self, client_sites):\n        job_clients = {}\n        if client_sites:\n            for site, dispatch_info in client_sites.items():\n                client = self.get_client_from_name(site)\n                if client:\n                    job_clients[client.token] = client\n        return job_clients\n\n    def remove_custom_path(self):\n        regex = re.compile(\".*/run_.*/custom\")\n        custom_paths = list(filter(regex.search, sys.path))\n        for path in custom_paths:\n            sys.path.remove(path)\n\n    def abort_app_on_clients(self, clients: List[str]) -> str:\n        status = self.engine_info.status\n        if status == MachineStatus.STOPPED:\n            return \"Server app has not started.\"\n        if status == MachineStatus.STARTING:\n            return \"Server app is starting, please wait for started before abort.\"\n        return \"\"\n\n    def abort_app_on_server(self, job_id: str) -> str:\n        if job_id not in self.run_processes.keys():\n            return \"Server app has not started.\"\n\n        self.logger.info(\"Abort the server app run.\")\n\n        try:\n            with self.lock:\n                command_conn = self.get_command_conn(job_id)\n                if command_conn:\n                    data = {ServerCommandKey.COMMAND: AdminCommandNames.ABORT, ServerCommandKey.DATA: {}}\n                    command_conn.send(data)\n                    status_message = command_conn.recv()\n                    self.logger.info(f\"Abort server: {status_message}\")\n        except BaseException:\n            with self.lock:\n                child_process = self.run_processes.get(job_id, {}).get(RunProcessKey.CHILD_PROCESS, None)\n                if child_process:\n                    child_process.terminate()\n        finally:\n            with self.lock:\n                self.run_processes.pop(job_id)\n\n        self.engine_info.status = MachineStatus.STOPPED\n        return \"\"\n\n    def check_app_start_readiness(self, job_id: str) -> str:\n        if job_id not in self.run_processes.keys():\n            return f\"Server app run_{job_id} has not started.\"\n        return \"\"\n\n    def shutdown_server(self) -> str:\n        status = self.server.status\n        if status == ServerStatus.STARTING:\n            return \"Server app is starting, please wait for started before shutdown.\"\n\n        self.logger.info(\"FL server shutdown.\")\n\n        touch_file = os.path.join(self.args.workspace, \"shutdown.fl\")\n        _ = self.executor.submit(lambda p: server_shutdown(*p), [self.server, touch_file])\n        while self.server.status != ServerStatus.SHUTDOWN:\n            time.sleep(1.0)\n        return \"\"\n\n    def restart_server(self) -> str:\n        status = self.server.status\n        if status == ServerStatus.STARTING:\n            return \"Server is starting, please wait for started before restart.\"\n\n        self.logger.info(\"FL server restart.\")\n\n        touch_file = os.path.join(self.args.workspace, \"restart.fl\")\n        _ = self.executor.submit(lambda p: server_shutdown(*p), [self.server, touch_file])\n        while self.server.status != ServerStatus.SHUTDOWN:\n            time.sleep(1.0)\n        return \"\"\n\n    def get_widget(self, widget_id: str) -> Widget:\n        return self.widgets.get(widget_id)\n\n    def get_client_name_from_token(self, token: str) -> str:\n        client = self.server.client_manager.clients.get(token)\n        if client:\n            return client.name\n        else:\n            return \"\"\n\n    def get_all_clients(self):\n        return list(self.server.client_manager.clients.keys())\n\n    def get_client_from_name(self, client_name):\n        for c in self.get_clients():\n            if client_name == c.name:\n                return c\n        return None\n\n    def _get_all_clients_from_inputs(self, inputs):\n        clients = []\n        invalid_inputs = []\n        for item in inputs:\n            client = self.client_manager.clients.get(item)\n            # if item in self.get_all_clients():\n            if client:\n                clients.append(client)\n            else:\n                client = self.get_client_from_name(item)\n                if client:\n                    clients.append(client)\n                else:\n                    invalid_inputs.append(item)\n        return clients, invalid_inputs\n\n    def get_app_data(self, app_name: str) -> Tuple[str, object]:\n        fullpath_src = os.path.join(self.server.admin_server.file_upload_dir, app_name)\n        if not os.path.exists(fullpath_src):\n            return f\"App folder '{app_name}' does not exist in staging area.\", None\n\n        data = zip_directory_to_bytes(fullpath_src, \"\")\n        return \"\", data\n\n    def get_app_run_info(self, job_id) -> RunInfo:\n        run_info = None\n        try:\n            with self.lock:\n                command_conn = self.get_command_conn(job_id)\n                if command_conn:\n                    data = {ServerCommandKey.COMMAND: ServerCommandNames.GET_RUN_INFO, ServerCommandKey.DATA: {}}\n                    command_conn.send(data)\n                    run_info = command_conn.recv()\n        except BaseException:\n            self.logger.error(f\"Failed to get_app_run_info from run_{job_id}\")\n\n        return run_info\n\n    def set_run_manager(self, run_manager: RunManager):\n        self.run_manager = run_manager\n        for _, widget in self.widgets.items():\n            self.run_manager.add_handler(widget)\n\n    def set_job_runner(self, job_runner: JobRunner, job_manager: JobDefManagerSpec):\n        self.job_runner = job_runner\n        self.job_def_manager = job_manager\n\n    def set_configurator(self, conf: ServerJsonConfigurator):\n        if not isinstance(conf, ServerJsonConfigurator):\n            raise TypeError(\"conf must be ServerJsonConfigurator but got {}\".format(type(conf)))\n        self.conf = conf\n\n    def build_component(self, config_dict):\n        return self.conf.build_component(config_dict)\n\n    def new_context(self) -> FLContext:\n        if self.run_manager:\n            return self.run_manager.new_context()\n        else:\n            # return FLContext()\n            return FLContextManager(\n                engine=self, identity_name=self.server.project_name, job_id=\"\", public_stickers={}, private_stickers={}\n            ).new_context()\n\n    def get_component(self, component_id: str) -> object:\n        return self.run_manager.get_component(component_id)\n\n    def fire_event(self, event_type: str, fl_ctx: FLContext):\n        self.run_manager.fire_event(event_type, fl_ctx)\n\n    def get_staging_path_of_app(self, app_name: str) -> str:\n        return os.path.join(self.server.admin_server.file_upload_dir, app_name)\n\n    def deploy_app_to_server(self, run_destination: str, app_name: str, app_staging_path: str) -> str:\n        return self.deploy_app(run_destination, app_name, WorkspaceConstants.APP_PREFIX + \"server\")\n\n    def get_workspace(self) -> Workspace:\n        return self.run_manager.get_workspace()\n\n    def ask_to_stop(self):\n        self.asked_to_stop = True\n\n    def deploy_app(self, job_id, src, dst):\n        fullpath_src = os.path.join(self.server.admin_server.file_upload_dir, src)\n        fullpath_dst = os.path.join(self._get_run_folder(job_id), dst)\n        if not os.path.exists(fullpath_src):\n            return f\"App folder '{src}' does not exist in staging area.\"\n        if os.path.exists(fullpath_dst):\n            shutil.rmtree(fullpath_dst)\n        shutil.copytree(fullpath_src, fullpath_dst)\n\n        app_file = os.path.join(self._get_run_folder(job_id), \"fl_app.txt\")\n        if os.path.exists(app_file):\n            os.remove(app_file)\n        with open(app_file, \"wt\") as f:\n            f.write(f\"{src}\")\n\n        return \"\"\n\n    def remove_clients(self, clients: List[str]) -> str:\n        for client in clients:\n            self._remove_dead_client(client)\n        return \"\"\n\n    def _remove_dead_client(self, token):\n        _ = self.server.client_manager.remove_client(token)\n        self.server.remove_client_data(token)\n        if self.server.admin_server:\n            self.server.admin_server.client_dead(token)\n\n    def register_aux_message_handler(self, topic: str, message_handle_func):\n        self.run_manager.aux_runner.register_aux_message_handler(topic, message_handle_func)\n\n    def send_aux_request(self, targets: [], topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> dict:\n        try:\n            if not targets:\n                self.sync_clients_from_main_process()\n                targets = []\n                for t in self.get_clients():\n                    targets.append(t.name)\n            if targets:\n                return self.run_manager.aux_runner.send_aux_request(\n                    targets=targets, topic=topic, request=request, timeout=timeout, fl_ctx=fl_ctx\n                )\n            else:\n                return {}\n        except Exception as e:\n            self.logger.error(f\"Failed to send the aux_message: {topic} with exception: {e}.\")\n\n    def sync_clients_from_main_process(self):\n        with self.parent_conn_lock:\n            data = {ServerCommandKey.COMMAND: ServerCommandNames.GET_CLIENTS, ServerCommandKey.DATA: {}}\n            self.parent_conn.send(data)\n            return_data = self.parent_conn.recv()\n            clients = return_data.get(ServerCommandKey.CLIENTS)\n            self.client_manager.clients = clients\n\n    def parent_aux_send(self, targets: [], topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> dict:\n        with self.parent_conn_lock:\n            data = {\n                ServerCommandKey.COMMAND: ServerCommandNames.AUX_SEND,\n                ServerCommandKey.DATA: {\n                    \"targets\": targets,\n                    \"topic\": topic,\n                    \"request\": request,\n                    \"timeout\": timeout,\n                    \"fl_ctx\": get_serializable_data(fl_ctx),\n                },\n            }\n            self.parent_conn.send(data)\n            return_data = self.parent_conn.recv()\n            return return_data\n\n    def aux_send(self, targets: [], topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> dict:\n        # Send the aux messages through admin_server\n        request.set_peer_props(fl_ctx.get_all_public_props())\n\n        message = Message(topic=ReservedTopic.AUX_COMMAND, body=pickle.dumps(request))\n        message.set_header(RequestHeader.JOB_ID, str(fl_ctx.get_prop(FLContextKey.CURRENT_RUN)))\n        requests = {}\n        for n in targets:\n            requests.update({n: message})\n\n        replies = self.server.admin_server.send_requests(requests, timeout_secs=timeout)\n        results = {}\n        for r in replies:\n            client_name = self.get_client_name_from_token(r.client_token)\n            if r.reply:\n                try:\n                    results[client_name] = pickle.loads(r.reply.body)\n                except BaseException:\n                    results[client_name] = make_reply(ReturnCode.COMMUNICATION_ERROR)\n                    self.logger.error(\n                        f\"Received unexpected reply from client: {client_name}, \"\n                        f\"message body:{r.reply.body} processing topic:{topic}\"\n                    )\n            else:\n                results[client_name] = None\n\n        return results\n\n    def get_command_conn(self, job_id):\n        # this function need to be called with self.lock\n        port = self.run_processes.get(job_id, {}).get(RunProcessKey.LISTEN_PORT)\n        command_conn = self.run_processes.get(job_id, {}).get(RunProcessKey.CONNECTION, None)\n\n        if not command_conn:\n            try:\n                address = (\"localhost\", port)\n                command_conn = CommandClient(address, authkey=\"client process secret password\".encode())\n                command_conn = ClientConnection(command_conn)\n                self.run_processes[job_id][RunProcessKey.CONNECTION] = command_conn\n            except Exception:\n                pass\n        return command_conn\n\n    def persist_components(self, fl_ctx: FLContext, completed: bool):\n\n        # Call the State Persistor to persist all the component states\n        # 1. call every component to generate the component states data\n        #    Make sure to include the current round number\n        # 2. call persistence API to save the component states\n\n        try:\n            job_id = fl_ctx.get_job_id()\n            snapshot = RunSnapshot(job_id)\n            for component_id, component in self.run_manager.components.items():\n                if isinstance(component, FLComponent):\n                    snapshot.set_component_snapshot(\n                        component_id=component_id, component_state=component.get_persist_state(fl_ctx)\n                    )\n\n            snapshot.set_component_snapshot(\n                component_id=SnapshotKey.FL_CONTEXT, component_state=copy.deepcopy(get_serializable_data(fl_ctx).props)\n            )\n\n            workspace = fl_ctx.get_prop(FLContextKey.WORKSPACE_OBJECT)\n            data = zip_directory_to_bytes(workspace.get_run_dir(fl_ctx.get_prop(FLContextKey.CURRENT_RUN)), \"\")\n            snapshot.set_component_snapshot(component_id=SnapshotKey.WORKSPACE, component_state={\"content\": data})\n\n            job_info = fl_ctx.get_prop(FLContextKey.JOB_INFO)\n            if not job_info:\n                with self.parent_conn_lock:\n                    data = {ServerCommandKey.COMMAND: ServerCommandNames.GET_CLIENTS, ServerCommandKey.DATA: {}}\n                    self.parent_conn.send(data)\n                    return_data = self.parent_conn.recv()\n                    job_id = return_data.get(ServerCommandKey.JOB_ID)\n                    job_clients = return_data.get(ServerCommandKey.CLIENTS)\n                    fl_ctx.set_prop(FLContextKey.JOB_INFO, (job_id, job_clients))\n            else:\n                (job_id, job_clients) = job_info\n            snapshot.set_component_snapshot(\n                component_id=SnapshotKey.JOB_INFO,\n                component_state={SnapshotKey.JOB_CLIENTS: job_clients, SnapshotKey.JOB_ID: job_id},\n            )\n\n            snapshot.completed = completed\n\n            self.server.snapshot_location = self.snapshot_persistor.save(snapshot=snapshot)\n            if not completed:\n                self.logger.info(f\"persist the snapshot to: {self.server.snapshot_location}\")\n            else:\n                self.logger.info(f\"The snapshot: {self.server.snapshot_location} has been removed.\")\n        except BaseException as e:\n            self.logger.error(f\"Failed to persist the components. {str(e)}\")\n\n    def restore_components(self, snapshot: RunSnapshot, fl_ctx: FLContext):\n        for component_id, component in self.run_manager.components.items():\n            component.restore(snapshot.get_component_snapshot(component_id=component_id), fl_ctx)\n\n        fl_ctx.props.update(snapshot.get_component_snapshot(component_id=SnapshotKey.FL_CONTEXT))\n\n    def dispatch(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        return self.run_manager.aux_runner.dispatch(topic=topic, request=request, fl_ctx=fl_ctx)\n\n    def show_stats(self, job_id):\n        stats = None\n        try:\n            with self.lock:\n                command_conn = self.get_command_conn(job_id)\n                if command_conn:\n                    data = {ServerCommandKey.COMMAND: ServerCommandNames.SHOW_STATS, ServerCommandKey.DATA: {}}\n                    command_conn.send(data)\n                    stats = command_conn.recv()\n        except BaseException:\n            self.logger.error(f\"Failed to get_stats from run_{job_id}\")\n\n        return stats\n\n    def get_errors(self, job_id):\n        stats = None\n        try:\n            with self.lock:\n                command_conn = self.get_command_conn(job_id)\n                if command_conn:\n                    data = {ServerCommandKey.COMMAND: ServerCommandNames.GET_ERRORS, ServerCommandKey.DATA: {}}\n                    command_conn.send(data)\n                    stats = command_conn.recv()\n        except BaseException:\n            self.logger.error(f\"Failed to get_stats from run_{job_id}\")\n\n        return stats\n\n    def _send_admin_requests(self, requests, timeout_secs=10) -> List[ClientReply]:\n        return self.server.admin_server.send_requests(requests, timeout_secs=timeout_secs)\n\n    def check_client_resources(self, resource_reqs) -> Dict[str, Tuple[bool, str]]:\n        requests = {}\n        for site_name, resource_requirements in resource_reqs.items():\n            # assume server resource is unlimited\n            if site_name == \"server\":\n                continue\n            request = Message(topic=TrainingTopic.CHECK_RESOURCE, body=pickle.dumps(resource_requirements))\n            client = self.get_client_from_name(site_name)\n            if client:\n                requests.update({client.token: request})\n        replies = []\n        if requests:\n            replies = self._send_admin_requests(requests, 15)\n        result = {}\n        for r in replies:\n            site_name = self.get_client_name_from_token(r.client_token)\n            if r.reply:\n                resp = pickle.loads(r.reply.body)\n                result[site_name] = (\n                    resp.get_header(ShareableHeader.CHECK_RESOURCE_RESULT, False),\n                    resp.get_header(ShareableHeader.RESOURCE_RESERVE_TOKEN, \"\"),\n                )\n            else:\n                result[site_name] = (False, \"\")\n        return result\n\n    def cancel_client_resources(\n        self, resource_check_results: Dict[str, Tuple[bool, str]], resource_reqs: Dict[str, dict]\n    ):\n        requests = {}\n        for site_name, result in resource_check_results.items():\n            check_result, token = result\n            if check_result and token:\n                resource_requirements = resource_reqs[site_name]\n                request = Message(topic=TrainingTopic.CANCEL_RESOURCE, body=pickle.dumps(resource_requirements))\n                request.set_header(ShareableHeader.RESOURCE_RESERVE_TOKEN, token)\n                client = self.get_client_from_name(site_name)\n                if client:\n                    requests.update({client.token: request})\n        if requests:\n            _ = self._send_admin_requests(requests)\n\n    def start_client_job(self, job_id, client_sites):\n        requests = {}\n        for site, dispatch_info in client_sites.items():\n            resource_requirement = dispatch_info.resource_requirements\n            token = dispatch_info.token\n            request = Message(topic=TrainingTopic.START_JOB, body=pickle.dumps(resource_requirement))\n            request.set_header(RequestHeader.JOB_ID, job_id)\n            request.set_header(ShareableHeader.RESOURCE_RESERVE_TOKEN, token)\n            client = self.get_client_from_name(site)\n            if client:\n                requests.update({client.token: request})\n        replies = []\n        if requests:\n            replies = self._send_admin_requests(requests, timeout_secs=20)\n        return replies\n\n    def stop_all_jobs(self):\n        fl_ctx = self.new_context()\n        self.job_runner.stop_all_runs(fl_ctx)\n\n    def close(self):\n        self.executor.shutdown()",
  "def server_shutdown(server, touch_file):\n    with open(touch_file, \"a\"):\n        os.utime(touch_file, None)\n\n    try:\n        server.fl_shutdown()\n        server.admin_server.stop()\n        time.sleep(3.0)\n    finally:\n        server.status = ServerStatus.SHUTDOWN\n        sys.exit(2)",
  "def copy_new_server_properties(server, new_server):\n    # server.model_manager = new_server.model_manager\n    # server.model_saver = new_server.model_saver\n    server.builder = new_server.builder\n\n    server.wait_after_min_clients = new_server.wait_after_min_clients\n\n    server.outbound_filters = new_server.outbound_filters\n    server.inbound_filters = new_server.inbound_filters\n    server.cmd_modules = new_server.cmd_modules\n    server.processors = new_server.processors\n\n    # server.task_name = new_server.task_name\n    server.min_num_clients = new_server.min_num_clients\n    server.max_num_clients = new_server.max_num_clients\n    server.current_round = new_server.current_round\n    server.num_rounds = new_server.num_rounds\n    server.start_round = new_server.start_round\n\n    # server.heart_beat_timeout = new_server.heart_beat_timeout\n    # server.handlers = new_server.handlers\n\n    # clients = server.client_manager.clients\n    # server.client_manager = new_server.client_manager\n    # server.client_manager.clients = clients\n    server.client_manager.min_num_clients = new_server.client_manager.min_num_clients\n    server.client_manager.max_num_clients = new_server.client_manager.max_num_clients\n    server.client_manager.logger = new_server.client_manager.logger\n    server.client_manager.logger.disabled = False\n\n    server.reset_tokens()\n    server.contributed_clients.clear()\n    # server.accumulator.clear()\n\n    server.fl_ctx = new_server.fl_ctx\n\n    server.controller = new_server.controller",
  "def set_up_run_config(server, conf):\n    server.heart_beat_timeout = conf.heartbeat_timeout\n    server.runner_config = conf.runner_config\n    server.handlers = conf.handlers",
  "def __init__(self, client):\n        self.client = client",
  "def send(self, data):\n        data = pickle.dumps(data)\n        self.client.send(data)",
  "def recv(self):\n        return self.client.recv()",
  "def __init__(self, server, args, client_manager: ClientManager, snapshot_persistor, workers=3):\n        \"\"\"Server engine.\n\n        Args:\n            server: server\n            args: arguments\n            client_manager (ClientManager): client manager.\n            workers: number of worker threads.\n        \"\"\"\n        # TODO:: clean up the server function / requirement here should be BaseServer\n        self.server = server\n        self.args = args\n        self.run_processes = {}\n        self.execution_exception_run_processes = {}\n        self.run_manager = None\n        self.conf = None\n        # TODO:: does this class need client manager?\n        self.client_manager = client_manager\n\n        self.widgets = {\n            WidgetID.INFO_COLLECTOR: InfoCollector(),\n            # WidgetID.FED_EVENT_RUNNER: ServerFedEventRunner()\n        }\n\n        self.engine_info = EngineInfo()\n\n        if not workers >= 1:\n            raise ValueError(\"workers must >= 1 but got {}\".format(workers))\n\n        self.executor = ThreadPoolExecutor(max_workers=workers)\n        self.lock = Lock()\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n        self.asked_to_stop = False\n        self.snapshot_persistor = snapshot_persistor\n        self.parent_conn = None\n        self.parent_conn_lock = Lock()\n        self.job_runner = None\n        self.job_def_manager = None\n        self.snapshot_lock = multiprocessing.Lock()",
  "def _get_server_app_folder(self):\n        return WorkspaceConstants.APP_PREFIX + \"server\"",
  "def _get_client_app_folder(self, client_name):\n        return WorkspaceConstants.APP_PREFIX + client_name",
  "def _get_run_folder(self, job_id):\n        return os.path.join(self.args.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(job_id))",
  "def get_engine_info(self) -> EngineInfo:\n        self.engine_info.app_names = {}\n        if bool(self.run_processes):\n            self.engine_info.status = MachineStatus.STARTED\n        else:\n            self.engine_info.status = MachineStatus.STOPPED\n\n        for job_id, _ in self.run_processes.items():\n            run_folder = os.path.join(self.args.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(job_id))\n            app_file = os.path.join(run_folder, \"fl_app.txt\")\n            if os.path.exists(app_file):\n                with open(app_file, \"r\") as f:\n                    self.engine_info.app_names[job_id] = f.readline().strip()\n            else:\n                self.engine_info.app_names[job_id] = \"?\"\n\n        return self.engine_info",
  "def get_run_info(self) -> RunInfo:\n        if self.run_manager:\n            return self.run_manager.get_run_info()\n        else:\n            return None",
  "def create_parent_connection(self, port):\n        while not self.parent_conn:\n            try:\n                address = (\"localhost\", port)\n                self.parent_conn = CommandClient(address, authkey=\"parent process secret password\".encode())\n            except BaseException:\n                time.sleep(1.0)\n                pass\n\n        threading.Thread(target=self.heartbeat_to_parent, args=[]).start()",
  "def heartbeat_to_parent(self):\n        while True:\n            try:\n                with self.parent_conn_lock:\n                    data = {ServerCommandKey.COMMAND: ServerCommandNames.HEARTBEAT, ServerCommandKey.DATA: {}}\n                    self.parent_conn.send(data)\n                time.sleep(1.0)\n            except BaseException:\n                # The parent process can not be reached. Terminate the child process.\n                break\n        # delay some time for the wrap up process before the child process self terminate.\n        time.sleep(30)\n        os.killpg(os.getpgid(os.getpid()), 9)",
  "def delete_job_id(self, num):\n        job_id_folder = os.path.join(self.args.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(num))\n        if os.path.exists(job_id_folder):\n            shutil.rmtree(job_id_folder)\n        return \"\"",
  "def get_clients(self) -> [Client]:\n        return list(self.client_manager.get_clients().values())",
  "def validate_clients(self, client_names: List[str]) -> Tuple[List[Client], List[str]]:\n        return self._get_all_clients_from_inputs(client_names)",
  "def start_app_on_server(self, run_number: str, job_id: str = None, job_clients=None, snapshot=None) -> str:\n        if run_number in self.run_processes.keys():\n            return f\"Server run_{run_number} already started.\"\n        else:\n            app_root = os.path.join(self._get_run_folder(run_number), self._get_server_app_folder())\n            if not os.path.exists(app_root):\n                return \"Server app does not exist. Please deploy the server app before starting.\"\n\n            self.engine_info.status = MachineStatus.STARTING\n\n            app_custom_folder = \"\"\n            if self.server.enable_byoc:\n                app_custom_folder = os.path.join(app_root, \"custom\")\n\n            open_ports = get_open_ports(2)\n            self._start_runner_process(\n                self.args, app_root, run_number, app_custom_folder, open_ports, job_id, job_clients, snapshot\n            )\n\n            threading.Thread(target=self._listen_command, args=(open_ports[0], run_number)).start()\n\n            self.engine_info.status = MachineStatus.STARTED\n            return \"\"",
  "def _listen_command(self, listen_port, job_id):\n        address = (\"localhost\", int(listen_port))\n        listener = Listener(address, authkey=\"parent process secret password\".encode())\n        conn = listener.accept()\n\n        while job_id in self.run_processes.keys():\n            clients = self.run_processes.get(job_id).get(RunProcessKey.PARTICIPANTS)\n            job_id = self.run_processes.get(job_id).get(RunProcessKey.JOB_ID)\n            try:\n                if conn.poll(0.1):\n                    received_data = conn.recv()\n                    command = received_data.get(ServerCommandKey.COMMAND)\n                    data = received_data.get(ServerCommandKey.DATA)\n\n                    if command == ServerCommandNames.GET_CLIENTS:\n                        return_data = {ServerCommandKey.CLIENTS: clients, ServerCommandKey.JOB_ID: job_id}\n                        conn.send(return_data)\n                    elif command == ServerCommandNames.AUX_SEND:\n                        targets = data.get(\"targets\")\n                        topic = data.get(\"topic\")\n                        request = data.get(\"request\")\n                        timeout = data.get(\"timeout\")\n                        fl_ctx = data.get(\"fl_ctx\")\n                        replies = self.aux_send(\n                            targets=targets, topic=topic, request=request, timeout=timeout, fl_ctx=fl_ctx\n                        )\n                        conn.send(replies)\n            except BaseException as e:\n                self.logger.warning(f\"Failed to process the child process command: {e}\", exc_info=True)",
  "def wait_for_complete(self, job_id):\n        while True:\n            try:\n                with self.lock:\n                    command_conn = self.get_command_conn(job_id)\n                    if command_conn:\n                        data = {ServerCommandKey.COMMAND: ServerCommandNames.HEARTBEAT, ServerCommandKey.DATA: {}}\n                        command_conn.send(data)\n                time.sleep(1.0)\n            except BaseException:\n                with self.lock:\n                    run_process_info = self.run_processes.pop(job_id)\n                    return_code = run_process_info[RunProcessKey.CHILD_PROCESS].poll()\n                    # if process exit but with Execution exception\n                    if return_code and return_code != 0:\n                        self.execution_exception_run_processes[job_id] = run_process_info\n                self.engine_info.status = MachineStatus.STOPPED\n                break",
  "def _start_runner_process(\n        self, args, app_root, run_number, app_custom_folder, open_ports, job_id, job_clients, snapshot\n    ):\n        new_env = os.environ.copy()\n        if app_custom_folder != \"\":\n            new_env[\"PYTHONPATH\"] = new_env.get(\"PYTHONPATH\", \"\") + os.pathsep + app_custom_folder\n\n        listen_port = open_ports[1]\n        if snapshot:\n            restore_snapshot = True\n        else:\n            restore_snapshot = False\n        command_options = \"\"\n        for t in args.set:\n            command_options += \" \" + t\n        command = (\n            sys.executable\n            + \" -m nvflare.private.fed.app.server.runner_process -m \"\n            + args.workspace\n            + \" -s fed_server.json -r \"\n            + app_root\n            + \" -n \"\n            + str(run_number)\n            + \" -p \"\n            + str(listen_port)\n            + \" -c \"\n            + str(open_ports[0])\n            + \" --set\"\n            + command_options\n            + \" print_conf=True restore_snapshot=\"\n            + str(restore_snapshot)\n        )\n        # use os.setsid to create new process group ID\n\n        process = subprocess.Popen(shlex.split(command, True), preexec_fn=os.setsid, env=new_env)\n\n        if not job_id:\n            job_id = \"\"\n        if not job_clients:\n            job_clients = self.client_manager.clients\n\n        with self.lock:\n            self.run_processes[run_number] = {\n                RunProcessKey.LISTEN_PORT: listen_port,\n                RunProcessKey.CONNECTION: None,\n                RunProcessKey.CHILD_PROCESS: process,\n                RunProcessKey.JOB_ID: job_id,\n                RunProcessKey.PARTICIPANTS: job_clients,\n            }\n\n        threading.Thread(target=self.wait_for_complete, args=[run_number]).start()\n        return process",
  "def get_job_clients(self, client_sites):\n        job_clients = {}\n        if client_sites:\n            for site, dispatch_info in client_sites.items():\n                client = self.get_client_from_name(site)\n                if client:\n                    job_clients[client.token] = client\n        return job_clients",
  "def remove_custom_path(self):\n        regex = re.compile(\".*/run_.*/custom\")\n        custom_paths = list(filter(regex.search, sys.path))\n        for path in custom_paths:\n            sys.path.remove(path)",
  "def abort_app_on_clients(self, clients: List[str]) -> str:\n        status = self.engine_info.status\n        if status == MachineStatus.STOPPED:\n            return \"Server app has not started.\"\n        if status == MachineStatus.STARTING:\n            return \"Server app is starting, please wait for started before abort.\"\n        return \"\"",
  "def abort_app_on_server(self, job_id: str) -> str:\n        if job_id not in self.run_processes.keys():\n            return \"Server app has not started.\"\n\n        self.logger.info(\"Abort the server app run.\")\n\n        try:\n            with self.lock:\n                command_conn = self.get_command_conn(job_id)\n                if command_conn:\n                    data = {ServerCommandKey.COMMAND: AdminCommandNames.ABORT, ServerCommandKey.DATA: {}}\n                    command_conn.send(data)\n                    status_message = command_conn.recv()\n                    self.logger.info(f\"Abort server: {status_message}\")\n        except BaseException:\n            with self.lock:\n                child_process = self.run_processes.get(job_id, {}).get(RunProcessKey.CHILD_PROCESS, None)\n                if child_process:\n                    child_process.terminate()\n        finally:\n            with self.lock:\n                self.run_processes.pop(job_id)\n\n        self.engine_info.status = MachineStatus.STOPPED\n        return \"\"",
  "def check_app_start_readiness(self, job_id: str) -> str:\n        if job_id not in self.run_processes.keys():\n            return f\"Server app run_{job_id} has not started.\"\n        return \"\"",
  "def shutdown_server(self) -> str:\n        status = self.server.status\n        if status == ServerStatus.STARTING:\n            return \"Server app is starting, please wait for started before shutdown.\"\n\n        self.logger.info(\"FL server shutdown.\")\n\n        touch_file = os.path.join(self.args.workspace, \"shutdown.fl\")\n        _ = self.executor.submit(lambda p: server_shutdown(*p), [self.server, touch_file])\n        while self.server.status != ServerStatus.SHUTDOWN:\n            time.sleep(1.0)\n        return \"\"",
  "def restart_server(self) -> str:\n        status = self.server.status\n        if status == ServerStatus.STARTING:\n            return \"Server is starting, please wait for started before restart.\"\n\n        self.logger.info(\"FL server restart.\")\n\n        touch_file = os.path.join(self.args.workspace, \"restart.fl\")\n        _ = self.executor.submit(lambda p: server_shutdown(*p), [self.server, touch_file])\n        while self.server.status != ServerStatus.SHUTDOWN:\n            time.sleep(1.0)\n        return \"\"",
  "def get_widget(self, widget_id: str) -> Widget:\n        return self.widgets.get(widget_id)",
  "def get_client_name_from_token(self, token: str) -> str:\n        client = self.server.client_manager.clients.get(token)\n        if client:\n            return client.name\n        else:\n            return \"\"",
  "def get_all_clients(self):\n        return list(self.server.client_manager.clients.keys())",
  "def get_client_from_name(self, client_name):\n        for c in self.get_clients():\n            if client_name == c.name:\n                return c\n        return None",
  "def _get_all_clients_from_inputs(self, inputs):\n        clients = []\n        invalid_inputs = []\n        for item in inputs:\n            client = self.client_manager.clients.get(item)\n            # if item in self.get_all_clients():\n            if client:\n                clients.append(client)\n            else:\n                client = self.get_client_from_name(item)\n                if client:\n                    clients.append(client)\n                else:\n                    invalid_inputs.append(item)\n        return clients, invalid_inputs",
  "def get_app_data(self, app_name: str) -> Tuple[str, object]:\n        fullpath_src = os.path.join(self.server.admin_server.file_upload_dir, app_name)\n        if not os.path.exists(fullpath_src):\n            return f\"App folder '{app_name}' does not exist in staging area.\", None\n\n        data = zip_directory_to_bytes(fullpath_src, \"\")\n        return \"\", data",
  "def get_app_run_info(self, job_id) -> RunInfo:\n        run_info = None\n        try:\n            with self.lock:\n                command_conn = self.get_command_conn(job_id)\n                if command_conn:\n                    data = {ServerCommandKey.COMMAND: ServerCommandNames.GET_RUN_INFO, ServerCommandKey.DATA: {}}\n                    command_conn.send(data)\n                    run_info = command_conn.recv()\n        except BaseException:\n            self.logger.error(f\"Failed to get_app_run_info from run_{job_id}\")\n\n        return run_info",
  "def set_run_manager(self, run_manager: RunManager):\n        self.run_manager = run_manager\n        for _, widget in self.widgets.items():\n            self.run_manager.add_handler(widget)",
  "def set_job_runner(self, job_runner: JobRunner, job_manager: JobDefManagerSpec):\n        self.job_runner = job_runner\n        self.job_def_manager = job_manager",
  "def set_configurator(self, conf: ServerJsonConfigurator):\n        if not isinstance(conf, ServerJsonConfigurator):\n            raise TypeError(\"conf must be ServerJsonConfigurator but got {}\".format(type(conf)))\n        self.conf = conf",
  "def build_component(self, config_dict):\n        return self.conf.build_component(config_dict)",
  "def new_context(self) -> FLContext:\n        if self.run_manager:\n            return self.run_manager.new_context()\n        else:\n            # return FLContext()\n            return FLContextManager(\n                engine=self, identity_name=self.server.project_name, job_id=\"\", public_stickers={}, private_stickers={}\n            ).new_context()",
  "def get_component(self, component_id: str) -> object:\n        return self.run_manager.get_component(component_id)",
  "def fire_event(self, event_type: str, fl_ctx: FLContext):\n        self.run_manager.fire_event(event_type, fl_ctx)",
  "def get_staging_path_of_app(self, app_name: str) -> str:\n        return os.path.join(self.server.admin_server.file_upload_dir, app_name)",
  "def deploy_app_to_server(self, run_destination: str, app_name: str, app_staging_path: str) -> str:\n        return self.deploy_app(run_destination, app_name, WorkspaceConstants.APP_PREFIX + \"server\")",
  "def get_workspace(self) -> Workspace:\n        return self.run_manager.get_workspace()",
  "def ask_to_stop(self):\n        self.asked_to_stop = True",
  "def deploy_app(self, job_id, src, dst):\n        fullpath_src = os.path.join(self.server.admin_server.file_upload_dir, src)\n        fullpath_dst = os.path.join(self._get_run_folder(job_id), dst)\n        if not os.path.exists(fullpath_src):\n            return f\"App folder '{src}' does not exist in staging area.\"\n        if os.path.exists(fullpath_dst):\n            shutil.rmtree(fullpath_dst)\n        shutil.copytree(fullpath_src, fullpath_dst)\n\n        app_file = os.path.join(self._get_run_folder(job_id), \"fl_app.txt\")\n        if os.path.exists(app_file):\n            os.remove(app_file)\n        with open(app_file, \"wt\") as f:\n            f.write(f\"{src}\")\n\n        return \"\"",
  "def remove_clients(self, clients: List[str]) -> str:\n        for client in clients:\n            self._remove_dead_client(client)\n        return \"\"",
  "def _remove_dead_client(self, token):\n        _ = self.server.client_manager.remove_client(token)\n        self.server.remove_client_data(token)\n        if self.server.admin_server:\n            self.server.admin_server.client_dead(token)",
  "def register_aux_message_handler(self, topic: str, message_handle_func):\n        self.run_manager.aux_runner.register_aux_message_handler(topic, message_handle_func)",
  "def send_aux_request(self, targets: [], topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> dict:\n        try:\n            if not targets:\n                self.sync_clients_from_main_process()\n                targets = []\n                for t in self.get_clients():\n                    targets.append(t.name)\n            if targets:\n                return self.run_manager.aux_runner.send_aux_request(\n                    targets=targets, topic=topic, request=request, timeout=timeout, fl_ctx=fl_ctx\n                )\n            else:\n                return {}\n        except Exception as e:\n            self.logger.error(f\"Failed to send the aux_message: {topic} with exception: {e}.\")",
  "def sync_clients_from_main_process(self):\n        with self.parent_conn_lock:\n            data = {ServerCommandKey.COMMAND: ServerCommandNames.GET_CLIENTS, ServerCommandKey.DATA: {}}\n            self.parent_conn.send(data)\n            return_data = self.parent_conn.recv()\n            clients = return_data.get(ServerCommandKey.CLIENTS)\n            self.client_manager.clients = clients",
  "def parent_aux_send(self, targets: [], topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> dict:\n        with self.parent_conn_lock:\n            data = {\n                ServerCommandKey.COMMAND: ServerCommandNames.AUX_SEND,\n                ServerCommandKey.DATA: {\n                    \"targets\": targets,\n                    \"topic\": topic,\n                    \"request\": request,\n                    \"timeout\": timeout,\n                    \"fl_ctx\": get_serializable_data(fl_ctx),\n                },\n            }\n            self.parent_conn.send(data)\n            return_data = self.parent_conn.recv()\n            return return_data",
  "def aux_send(self, targets: [], topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> dict:\n        # Send the aux messages through admin_server\n        request.set_peer_props(fl_ctx.get_all_public_props())\n\n        message = Message(topic=ReservedTopic.AUX_COMMAND, body=pickle.dumps(request))\n        message.set_header(RequestHeader.JOB_ID, str(fl_ctx.get_prop(FLContextKey.CURRENT_RUN)))\n        requests = {}\n        for n in targets:\n            requests.update({n: message})\n\n        replies = self.server.admin_server.send_requests(requests, timeout_secs=timeout)\n        results = {}\n        for r in replies:\n            client_name = self.get_client_name_from_token(r.client_token)\n            if r.reply:\n                try:\n                    results[client_name] = pickle.loads(r.reply.body)\n                except BaseException:\n                    results[client_name] = make_reply(ReturnCode.COMMUNICATION_ERROR)\n                    self.logger.error(\n                        f\"Received unexpected reply from client: {client_name}, \"\n                        f\"message body:{r.reply.body} processing topic:{topic}\"\n                    )\n            else:\n                results[client_name] = None\n\n        return results",
  "def get_command_conn(self, job_id):\n        # this function need to be called with self.lock\n        port = self.run_processes.get(job_id, {}).get(RunProcessKey.LISTEN_PORT)\n        command_conn = self.run_processes.get(job_id, {}).get(RunProcessKey.CONNECTION, None)\n\n        if not command_conn:\n            try:\n                address = (\"localhost\", port)\n                command_conn = CommandClient(address, authkey=\"client process secret password\".encode())\n                command_conn = ClientConnection(command_conn)\n                self.run_processes[job_id][RunProcessKey.CONNECTION] = command_conn\n            except Exception:\n                pass\n        return command_conn",
  "def persist_components(self, fl_ctx: FLContext, completed: bool):\n\n        # Call the State Persistor to persist all the component states\n        # 1. call every component to generate the component states data\n        #    Make sure to include the current round number\n        # 2. call persistence API to save the component states\n\n        try:\n            job_id = fl_ctx.get_job_id()\n            snapshot = RunSnapshot(job_id)\n            for component_id, component in self.run_manager.components.items():\n                if isinstance(component, FLComponent):\n                    snapshot.set_component_snapshot(\n                        component_id=component_id, component_state=component.get_persist_state(fl_ctx)\n                    )\n\n            snapshot.set_component_snapshot(\n                component_id=SnapshotKey.FL_CONTEXT, component_state=copy.deepcopy(get_serializable_data(fl_ctx).props)\n            )\n\n            workspace = fl_ctx.get_prop(FLContextKey.WORKSPACE_OBJECT)\n            data = zip_directory_to_bytes(workspace.get_run_dir(fl_ctx.get_prop(FLContextKey.CURRENT_RUN)), \"\")\n            snapshot.set_component_snapshot(component_id=SnapshotKey.WORKSPACE, component_state={\"content\": data})\n\n            job_info = fl_ctx.get_prop(FLContextKey.JOB_INFO)\n            if not job_info:\n                with self.parent_conn_lock:\n                    data = {ServerCommandKey.COMMAND: ServerCommandNames.GET_CLIENTS, ServerCommandKey.DATA: {}}\n                    self.parent_conn.send(data)\n                    return_data = self.parent_conn.recv()\n                    job_id = return_data.get(ServerCommandKey.JOB_ID)\n                    job_clients = return_data.get(ServerCommandKey.CLIENTS)\n                    fl_ctx.set_prop(FLContextKey.JOB_INFO, (job_id, job_clients))\n            else:\n                (job_id, job_clients) = job_info\n            snapshot.set_component_snapshot(\n                component_id=SnapshotKey.JOB_INFO,\n                component_state={SnapshotKey.JOB_CLIENTS: job_clients, SnapshotKey.JOB_ID: job_id},\n            )\n\n            snapshot.completed = completed\n\n            self.server.snapshot_location = self.snapshot_persistor.save(snapshot=snapshot)\n            if not completed:\n                self.logger.info(f\"persist the snapshot to: {self.server.snapshot_location}\")\n            else:\n                self.logger.info(f\"The snapshot: {self.server.snapshot_location} has been removed.\")\n        except BaseException as e:\n            self.logger.error(f\"Failed to persist the components. {str(e)}\")",
  "def restore_components(self, snapshot: RunSnapshot, fl_ctx: FLContext):\n        for component_id, component in self.run_manager.components.items():\n            component.restore(snapshot.get_component_snapshot(component_id=component_id), fl_ctx)\n\n        fl_ctx.props.update(snapshot.get_component_snapshot(component_id=SnapshotKey.FL_CONTEXT))",
  "def dispatch(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        return self.run_manager.aux_runner.dispatch(topic=topic, request=request, fl_ctx=fl_ctx)",
  "def show_stats(self, job_id):\n        stats = None\n        try:\n            with self.lock:\n                command_conn = self.get_command_conn(job_id)\n                if command_conn:\n                    data = {ServerCommandKey.COMMAND: ServerCommandNames.SHOW_STATS, ServerCommandKey.DATA: {}}\n                    command_conn.send(data)\n                    stats = command_conn.recv()\n        except BaseException:\n            self.logger.error(f\"Failed to get_stats from run_{job_id}\")\n\n        return stats",
  "def get_errors(self, job_id):\n        stats = None\n        try:\n            with self.lock:\n                command_conn = self.get_command_conn(job_id)\n                if command_conn:\n                    data = {ServerCommandKey.COMMAND: ServerCommandNames.GET_ERRORS, ServerCommandKey.DATA: {}}\n                    command_conn.send(data)\n                    stats = command_conn.recv()\n        except BaseException:\n            self.logger.error(f\"Failed to get_stats from run_{job_id}\")\n\n        return stats",
  "def _send_admin_requests(self, requests, timeout_secs=10) -> List[ClientReply]:\n        return self.server.admin_server.send_requests(requests, timeout_secs=timeout_secs)",
  "def check_client_resources(self, resource_reqs) -> Dict[str, Tuple[bool, str]]:\n        requests = {}\n        for site_name, resource_requirements in resource_reqs.items():\n            # assume server resource is unlimited\n            if site_name == \"server\":\n                continue\n            request = Message(topic=TrainingTopic.CHECK_RESOURCE, body=pickle.dumps(resource_requirements))\n            client = self.get_client_from_name(site_name)\n            if client:\n                requests.update({client.token: request})\n        replies = []\n        if requests:\n            replies = self._send_admin_requests(requests, 15)\n        result = {}\n        for r in replies:\n            site_name = self.get_client_name_from_token(r.client_token)\n            if r.reply:\n                resp = pickle.loads(r.reply.body)\n                result[site_name] = (\n                    resp.get_header(ShareableHeader.CHECK_RESOURCE_RESULT, False),\n                    resp.get_header(ShareableHeader.RESOURCE_RESERVE_TOKEN, \"\"),\n                )\n            else:\n                result[site_name] = (False, \"\")\n        return result",
  "def cancel_client_resources(\n        self, resource_check_results: Dict[str, Tuple[bool, str]], resource_reqs: Dict[str, dict]\n    ):\n        requests = {}\n        for site_name, result in resource_check_results.items():\n            check_result, token = result\n            if check_result and token:\n                resource_requirements = resource_reqs[site_name]\n                request = Message(topic=TrainingTopic.CANCEL_RESOURCE, body=pickle.dumps(resource_requirements))\n                request.set_header(ShareableHeader.RESOURCE_RESERVE_TOKEN, token)\n                client = self.get_client_from_name(site_name)\n                if client:\n                    requests.update({client.token: request})\n        if requests:\n            _ = self._send_admin_requests(requests)",
  "def start_client_job(self, job_id, client_sites):\n        requests = {}\n        for site, dispatch_info in client_sites.items():\n            resource_requirement = dispatch_info.resource_requirements\n            token = dispatch_info.token\n            request = Message(topic=TrainingTopic.START_JOB, body=pickle.dumps(resource_requirement))\n            request.set_header(RequestHeader.JOB_ID, job_id)\n            request.set_header(ShareableHeader.RESOURCE_RESERVE_TOKEN, token)\n            client = self.get_client_from_name(site)\n            if client:\n                requests.update({client.token: request})\n        replies = []\n        if requests:\n            replies = self._send_admin_requests(requests, timeout_secs=20)\n        return replies",
  "def stop_all_jobs(self):\n        fl_ctx = self.new_context()\n        self.job_runner.stop_all_runs(fl_ctx)",
  "def close(self):\n        self.executor.shutdown()",
  "class ClientManager:\n    def __init__(self, project_name=None, min_num_clients=2, max_num_clients=10):\n        \"\"\"Manages client adding and removing.\n\n        Args:\n            project_name: project name\n            min_num_clients: minimum number of clients allowed.\n            max_num_clients: maximum number of clients allowed.\n        \"\"\"\n        self.project_name = project_name\n        # TODO:: remove min num clients\n        self.min_num_clients = min_num_clients\n        self.max_num_clients = max_num_clients\n        self.clients = dict()  # token => Client\n        self.lock = threading.Lock()\n\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    def authenticate(self, request, context):\n        client = self.login_client(request, context)\n        if not client:\n            return None\n\n        client_ip = context.peer().split(\":\")[1]\n\n        if len(self.clients) >= self.max_num_clients:\n            context.abort(grpc.StatusCode.RESOURCE_EXHAUSTED, \"Maximum number of clients reached\")\n\n        # new client will join the current round immediately\n        with self.lock:\n            self.clients.update({client.token: client})\n            self.logger.info(\n                \"Client: New client {} joined. Sent token: {}.  Total clients: {}\".format(\n                    request.client_name + \"@\" + client_ip, client.token, len(self.clients)\n                )\n            )\n        return client.token\n\n    def remove_client(self, token):\n        \"\"\"Remove a registered client.\n\n        Args:\n            token: client token\n\n        Returns:\n            The removed Client object\n        \"\"\"\n        with self.lock:\n            client = self.clients.pop(token)\n            self.logger.info(\n                \"Client Name:{} \\tToken: {} left.  Total clients: {}\".format(client.name, token, len(self.clients))\n            )\n            return client\n\n    def login_client(self, client_login, context):\n        if not self.is_valid_task(client_login.meta.project):\n            context.abort(grpc.StatusCode.INVALID_ARGUMENT, \"Requested task does not match the current server task\")\n        return self.authenticated_client(client_login, context)\n\n    def validate_client(self, client_state, context, allow_new=False):\n        \"\"\"Validate the client state message.\n\n        Args:\n            client_state: A ClientState message received by server\n            context: gRPC connection context\n            allow_new: whether to allow new client. Note that its task should still match server's.\n\n        Returns:\n             client id if it's a valid client\n        \"\"\"\n        token = client_state.token\n        if not token:\n            context.abort(grpc.StatusCode.INVALID_ARGUMENT, \"Could not read client uid from the payload\")\n            client = None\n        elif not self.is_valid_task(client_state.meta.project):\n            context.abort(grpc.StatusCode.INVALID_ARGUMENT, \"Requested task does not match the current server task\")\n            client = None\n        elif not (allow_new or self.is_from_authorized_client(token)):\n            context.abort(grpc.StatusCode.UNAUTHENTICATED, \"Unknown client identity\")\n            client = None\n        else:\n            client = self.clients.get(token)\n        return client\n\n    def authenticated_client(self, client_login, context) -> Client:\n        \"\"\"Use SSL certificate for authenticate the client.\n\n        Args:\n            client_login: client login request\n            context: gRPC connection context\n\n        Returns:\n            Client object.\n        \"\"\"\n        client = self.clients.get(client_login.token)\n        if not client:\n            cn_names = context.auth_context().get(\"x509_common_name\")\n            if cn_names:\n                client_name = cn_names[0].decode(\"utf-8\")\n                if client_login.client_name:\n                    if not client_login.client_name == client_name:\n                        context.abort(\n                            grpc.StatusCode.UNAUTHENTICATED, \"client ID does not match the SSL certificate CN\"\n                        )\n                        return None\n            else:\n                client_name = client_login.client_name\n\n            for token, client in self.clients.items():\n                if client.name == client_name:\n                    context.abort(\n                        grpc.StatusCode.FAILED_PRECONDITION,\n                        \"Client ID already registered as a client: {}\".format(client_name),\n                    )\n                    return None\n\n            client = Client(client_name, str(uuid.uuid4()))\n        return client\n\n    def is_from_authorized_client(self, token):\n        \"\"\"Check if a client is authorized.\n\n        Args:\n            token: client token\n\n        Returns:\n            True if it is a recognised client\n        \"\"\"\n        return token in self.clients\n\n    def is_valid_task(self, task):\n        \"\"\"Check whether the requested task matches the server's project_name.\n\n        Returns:\n            True if task name is the same as server's project name.\n        \"\"\"\n        return task.name == self.project_name\n\n    def heartbeat(self, token, client_name, context):\n        \"\"\"Update the heartbeat of the client.\n\n        Args:\n            token: client token\n            client_name: client name\n            context: grpc context\n\n        Returns:\n            If a new client needs to be created.\n        \"\"\"\n        with self.lock:\n            client = self.clients.get(token)\n            if client:\n                client.last_connect_time = time.time()\n                # self.clients.update({token: time.time()})\n                self.logger.debug(f\"Receive heartbeat from Client:{token}\")\n                return False\n            else:\n                for _token, _client in self.clients.items():\n                    if _client.name == client_name:\n                        context.abort(\n                            grpc.StatusCode.FAILED_PRECONDITION,\n                            \"Client ID already registered as a client: {}\".format(client_name),\n                        )\n                        self.logger.info(\n                            \"Failed to re-activate dead client:{} with token: {}. Client already exist.\".format(\n                                client_name, _token\n                            )\n                        )\n                        return False\n\n                client = Client(client_name, token)\n                client.last_connect_time = time.time()\n                # self._set_instance_name(client)\n                self.clients.update({token: client})\n                self.logger.info(\"Re-activate dead client:{} with token: {}\".format(client_name, token))\n\n                return True\n\n    def get_clients(self):\n        \"\"\"Get the list of registered clients.\n\n        Returns:\n            A dict of {client_token: client}\n        \"\"\"\n        return self.clients\n\n    def get_min_clients(self):\n        return self.min_num_clients\n\n    def get_max_clients(self):\n        return self.max_num_clients",
  "def __init__(self, project_name=None, min_num_clients=2, max_num_clients=10):\n        \"\"\"Manages client adding and removing.\n\n        Args:\n            project_name: project name\n            min_num_clients: minimum number of clients allowed.\n            max_num_clients: maximum number of clients allowed.\n        \"\"\"\n        self.project_name = project_name\n        # TODO:: remove min num clients\n        self.min_num_clients = min_num_clients\n        self.max_num_clients = max_num_clients\n        self.clients = dict()  # token => Client\n        self.lock = threading.Lock()\n\n        self.logger = logging.getLogger(self.__class__.__name__)",
  "def authenticate(self, request, context):\n        client = self.login_client(request, context)\n        if not client:\n            return None\n\n        client_ip = context.peer().split(\":\")[1]\n\n        if len(self.clients) >= self.max_num_clients:\n            context.abort(grpc.StatusCode.RESOURCE_EXHAUSTED, \"Maximum number of clients reached\")\n\n        # new client will join the current round immediately\n        with self.lock:\n            self.clients.update({client.token: client})\n            self.logger.info(\n                \"Client: New client {} joined. Sent token: {}.  Total clients: {}\".format(\n                    request.client_name + \"@\" + client_ip, client.token, len(self.clients)\n                )\n            )\n        return client.token",
  "def remove_client(self, token):\n        \"\"\"Remove a registered client.\n\n        Args:\n            token: client token\n\n        Returns:\n            The removed Client object\n        \"\"\"\n        with self.lock:\n            client = self.clients.pop(token)\n            self.logger.info(\n                \"Client Name:{} \\tToken: {} left.  Total clients: {}\".format(client.name, token, len(self.clients))\n            )\n            return client",
  "def login_client(self, client_login, context):\n        if not self.is_valid_task(client_login.meta.project):\n            context.abort(grpc.StatusCode.INVALID_ARGUMENT, \"Requested task does not match the current server task\")\n        return self.authenticated_client(client_login, context)",
  "def validate_client(self, client_state, context, allow_new=False):\n        \"\"\"Validate the client state message.\n\n        Args:\n            client_state: A ClientState message received by server\n            context: gRPC connection context\n            allow_new: whether to allow new client. Note that its task should still match server's.\n\n        Returns:\n             client id if it's a valid client\n        \"\"\"\n        token = client_state.token\n        if not token:\n            context.abort(grpc.StatusCode.INVALID_ARGUMENT, \"Could not read client uid from the payload\")\n            client = None\n        elif not self.is_valid_task(client_state.meta.project):\n            context.abort(grpc.StatusCode.INVALID_ARGUMENT, \"Requested task does not match the current server task\")\n            client = None\n        elif not (allow_new or self.is_from_authorized_client(token)):\n            context.abort(grpc.StatusCode.UNAUTHENTICATED, \"Unknown client identity\")\n            client = None\n        else:\n            client = self.clients.get(token)\n        return client",
  "def authenticated_client(self, client_login, context) -> Client:\n        \"\"\"Use SSL certificate for authenticate the client.\n\n        Args:\n            client_login: client login request\n            context: gRPC connection context\n\n        Returns:\n            Client object.\n        \"\"\"\n        client = self.clients.get(client_login.token)\n        if not client:\n            cn_names = context.auth_context().get(\"x509_common_name\")\n            if cn_names:\n                client_name = cn_names[0].decode(\"utf-8\")\n                if client_login.client_name:\n                    if not client_login.client_name == client_name:\n                        context.abort(\n                            grpc.StatusCode.UNAUTHENTICATED, \"client ID does not match the SSL certificate CN\"\n                        )\n                        return None\n            else:\n                client_name = client_login.client_name\n\n            for token, client in self.clients.items():\n                if client.name == client_name:\n                    context.abort(\n                        grpc.StatusCode.FAILED_PRECONDITION,\n                        \"Client ID already registered as a client: {}\".format(client_name),\n                    )\n                    return None\n\n            client = Client(client_name, str(uuid.uuid4()))\n        return client",
  "def is_from_authorized_client(self, token):\n        \"\"\"Check if a client is authorized.\n\n        Args:\n            token: client token\n\n        Returns:\n            True if it is a recognised client\n        \"\"\"\n        return token in self.clients",
  "def is_valid_task(self, task):\n        \"\"\"Check whether the requested task matches the server's project_name.\n\n        Returns:\n            True if task name is the same as server's project name.\n        \"\"\"\n        return task.name == self.project_name",
  "def heartbeat(self, token, client_name, context):\n        \"\"\"Update the heartbeat of the client.\n\n        Args:\n            token: client token\n            client_name: client name\n            context: grpc context\n\n        Returns:\n            If a new client needs to be created.\n        \"\"\"\n        with self.lock:\n            client = self.clients.get(token)\n            if client:\n                client.last_connect_time = time.time()\n                # self.clients.update({token: time.time()})\n                self.logger.debug(f\"Receive heartbeat from Client:{token}\")\n                return False\n            else:\n                for _token, _client in self.clients.items():\n                    if _client.name == client_name:\n                        context.abort(\n                            grpc.StatusCode.FAILED_PRECONDITION,\n                            \"Client ID already registered as a client: {}\".format(client_name),\n                        )\n                        self.logger.info(\n                            \"Failed to re-activate dead client:{} with token: {}. Client already exist.\".format(\n                                client_name, _token\n                            )\n                        )\n                        return False\n\n                client = Client(client_name, token)\n                client.last_connect_time = time.time()\n                # self._set_instance_name(client)\n                self.clients.update({token: client})\n                self.logger.info(\"Re-activate dead client:{} with token: {}\".format(client_name, token))\n\n                return True",
  "def get_clients(self):\n        \"\"\"Get the list of registered clients.\n\n        Returns:\n            A dict of {client_token: client}\n        \"\"\"\n        return self.clients",
  "def get_min_clients(self):\n        return self.min_num_clients",
  "def get_max_clients(self):\n        return self.max_num_clients",
  "class WorkFlow:\n    def __init__(self, id, responder: Responder):\n        \"\"\"Workflow is a responder with ID.\n\n        Args:\n            id: identification\n            responder (Responder): A responder\n        \"\"\"\n        self.id = id\n        self.responder = responder",
  "class ServerJsonConfigurator(FedJsonConfigurator):\n    def __init__(self, config_file_name: str, exclude_libs=True):\n        \"\"\"This class parses server config from json file.\n\n        Args:\n            config_file_name (str): json file to parse\n            exclude_libs (bool): whether to exclude libs\n        \"\"\"\n        base_pkgs = FL_PACKAGES\n        module_names = FL_MODULES\n\n        FedJsonConfigurator.__init__(\n            self,\n            config_file_name=config_file_name,\n            base_pkgs=base_pkgs,\n            module_names=module_names,\n            exclude_libs=exclude_libs,\n        )\n\n        self.runner_config = None\n\n        # if server doesn't hear heartbeat from client for this long, we'll consider the client dead\n        self.heartbeat_timeout = 60  # default to 1 minute\n\n        # server will ask client to come back for next task after this many secs\n        self.task_request_interval = 2  # default to 2 secs\n\n        # workflows to be executed\n        self.workflows = []\n\n    def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        FedJsonConfigurator.process_config_element(self, config_ctx, node)\n\n        element = node.element\n        path = node.path()\n\n        if path == \"server.heart_beat_timeout\":\n            self.heartbeat_timeout = element\n            if not isinstance(element, int) and not isinstance(element, float):\n                raise ConfigError('\"heart_beat_timeout\" must be a number, but got {}'.format(type(element)))\n\n            if element <= 0.0:\n                raise ConfigError('\"heart_beat_timeout\" must be positive number, but got {}'.format(element))\n\n            return\n\n        if path == \"server.task_request_interval\":\n            self.task_request_interval = element\n            if not isinstance(element, int) and not isinstance(element, float):\n                raise ConfigError('\"task_request_interval\" must be a number, but got {}'.format(type(element)))\n\n            if element < 1:\n                raise ConfigError('\"task_request_interval\" must >= 1, but got {}'.format(element))\n\n            return\n\n        if re.search(r\"^workflows\\.#[0-9]+$\", path):\n            workflow = self.build_component(element)\n            if not isinstance(workflow, Responder):\n                raise ConfigError(\n                    '\"workflow\" must be a Responder or Controller object, but got {}'.format(type(workflow))\n                )\n\n            cid = element.get(\"id\", None)\n            if not cid:\n                cid = type(workflow).__name__\n\n            if not isinstance(cid, str):\n                raise ConfigError('\"id\" must be str but got {}'.format(type(cid)))\n\n            if cid in self._get_all_workflows_ids():\n                raise ConfigError('duplicate workflow id \"{}\"'.format(cid))\n\n            if cid in self.components:\n                raise ConfigError('duplicate component id \"{}\"'.format(cid))\n\n            self.workflows.append(WorkFlow(cid, workflow))\n            self.components[cid] = workflow\n            return\n\n    def _get_all_workflows_ids(self):\n        ids = []\n        for t in self.workflows:\n            ids.append(t.id)\n        return ids\n\n    def build_component(self, config_dict):\n        t = super().build_component(config_dict)\n        if isinstance(t, FLComponent):\n            if type(t).__name__ not in [type(h).__name__ for h in self.handlers]:\n                self.handlers.append(t)\n        return t\n\n    def finalize_config(self, config_ctx: ConfigContext):\n        FedJsonConfigurator.finalize_config(self, config_ctx)\n\n        if not self.workflows:\n            raise ConfigError(\"workflows not specified\")\n\n        self.runner_config = ServerRunnerConfig(\n            heartbeat_timeout=self.heartbeat_timeout,\n            task_request_interval=self.task_request_interval,\n            workflows=self.workflows,\n            task_data_filters=self.data_filter_table,\n            task_result_filters=self.result_filter_table,\n            components=self.components,\n            handlers=self.handlers,\n        )",
  "def __init__(self, id, responder: Responder):\n        \"\"\"Workflow is a responder with ID.\n\n        Args:\n            id: identification\n            responder (Responder): A responder\n        \"\"\"\n        self.id = id\n        self.responder = responder",
  "def __init__(self, config_file_name: str, exclude_libs=True):\n        \"\"\"This class parses server config from json file.\n\n        Args:\n            config_file_name (str): json file to parse\n            exclude_libs (bool): whether to exclude libs\n        \"\"\"\n        base_pkgs = FL_PACKAGES\n        module_names = FL_MODULES\n\n        FedJsonConfigurator.__init__(\n            self,\n            config_file_name=config_file_name,\n            base_pkgs=base_pkgs,\n            module_names=module_names,\n            exclude_libs=exclude_libs,\n        )\n\n        self.runner_config = None\n\n        # if server doesn't hear heartbeat from client for this long, we'll consider the client dead\n        self.heartbeat_timeout = 60  # default to 1 minute\n\n        # server will ask client to come back for next task after this many secs\n        self.task_request_interval = 2  # default to 2 secs\n\n        # workflows to be executed\n        self.workflows = []",
  "def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        FedJsonConfigurator.process_config_element(self, config_ctx, node)\n\n        element = node.element\n        path = node.path()\n\n        if path == \"server.heart_beat_timeout\":\n            self.heartbeat_timeout = element\n            if not isinstance(element, int) and not isinstance(element, float):\n                raise ConfigError('\"heart_beat_timeout\" must be a number, but got {}'.format(type(element)))\n\n            if element <= 0.0:\n                raise ConfigError('\"heart_beat_timeout\" must be positive number, but got {}'.format(element))\n\n            return\n\n        if path == \"server.task_request_interval\":\n            self.task_request_interval = element\n            if not isinstance(element, int) and not isinstance(element, float):\n                raise ConfigError('\"task_request_interval\" must be a number, but got {}'.format(type(element)))\n\n            if element < 1:\n                raise ConfigError('\"task_request_interval\" must >= 1, but got {}'.format(element))\n\n            return\n\n        if re.search(r\"^workflows\\.#[0-9]+$\", path):\n            workflow = self.build_component(element)\n            if not isinstance(workflow, Responder):\n                raise ConfigError(\n                    '\"workflow\" must be a Responder or Controller object, but got {}'.format(type(workflow))\n                )\n\n            cid = element.get(\"id\", None)\n            if not cid:\n                cid = type(workflow).__name__\n\n            if not isinstance(cid, str):\n                raise ConfigError('\"id\" must be str but got {}'.format(type(cid)))\n\n            if cid in self._get_all_workflows_ids():\n                raise ConfigError('duplicate workflow id \"{}\"'.format(cid))\n\n            if cid in self.components:\n                raise ConfigError('duplicate component id \"{}\"'.format(cid))\n\n            self.workflows.append(WorkFlow(cid, workflow))\n            self.components[cid] = workflow\n            return",
  "def _get_all_workflows_ids(self):\n        ids = []\n        for t in self.workflows:\n            ids.append(t.id)\n        return ids",
  "def build_component(self, config_dict):\n        t = super().build_component(config_dict)\n        if isinstance(t, FLComponent):\n            if type(t).__name__ not in [type(h).__name__ for h in self.handlers]:\n                self.handlers.append(t)\n        return t",
  "def finalize_config(self, config_ctx: ConfigContext):\n        FedJsonConfigurator.finalize_config(self, config_ctx)\n\n        if not self.workflows:\n            raise ConfigError(\"workflows not specified\")\n\n        self.runner_config = ServerRunnerConfig(\n            heartbeat_timeout=self.heartbeat_timeout,\n            task_request_interval=self.task_request_interval,\n            workflows=self.workflows,\n            task_data_filters=self.data_filter_table,\n            task_result_filters=self.result_filter_table,\n            components=self.components,\n            handlers=self.handlers,\n        )",
  "def message_to_proto(message: Message) -> Proto_Message:\n    proto_message = Proto_Message()\n    proto_message.id = message.id\n    proto_message.topic = message.topic\n    if isinstance(message.body, str):\n        proto_message.body_type = \"str\"\n        proto_message.body = bytes(message.body, \"utf-8\")\n    elif isinstance(message.body, bytes):\n        proto_message.body_type = \"bytes\"\n        proto_message.body = message.body\n    else:\n        proto_message.body_type = \"unknown\"\n        proto_message.body = message.body\n\n    for k, v in message.headers.items():\n        proto_message.headers[k] = v\n    return proto_message",
  "def proto_to_message(proto: Proto_Message) -> Message:\n    if proto.body_type == \"str\":\n        message = Message(topic=proto.topic, body=proto.body.decode(\"utf-8\"))\n    elif proto.body_type == \"bytes\":\n        message = Message(topic=proto.topic, body=proto.body)\n    else:\n        message = Message(topic=proto.topic, body=proto.body)\n\n    message.id = proto.id\n    for k, v in proto.headers.items():\n        message.headers[k] = v\n    return message",
  "def ndarray_to_proto(nda: np.ndarray) -> NDArray:\n    \"\"\"Serializes a numpy array into an NDArray protobuf message.\n\n    Args:\n        nda (np.ndarray): numpy array to serialize.\n\n    Returns:\n        Returns an NDArray protobuf message.\n    \"\"\"\n    nda_bytes = BytesIO()\n    np.save(nda_bytes, nda, allow_pickle=False)\n\n    return NDArray(ndarray=nda_bytes.getvalue())",
  "def proto_to_ndarray(nda_proto: NDArray) -> np.ndarray:\n    \"\"\"Deserializes an NDArray protobuf message into a numpy array.\n\n    Args:\n        nda_proto (NDArray): NDArray protobuf message to deserialize.\n\n    Returns:\n        Returns a numpy.ndarray.\n    \"\"\"\n    nda_bytes = BytesIO(nda_proto.ndarray)\n\n    return np.load(nda_bytes, allow_pickle=False)",
  "def bytes_to_proto(data: bytes) -> NDArray:\n    \"\"\"Serializes a bytes into an NDArray protobuf message.\n\n    Args:\n        data : bytes data\n\n    Returns:\n        Returns an NDArray protobuf message.\n    \"\"\"\n    if not isinstance(data, bytes):\n        raise TypeError(\"data must be bytes but got {}\".format(type(data)))\n    return NDArray(ndarray=data)",
  "def proto_to_bytes(nda_proto: NDArray) -> bytes:\n    \"\"\"Deserializes an NDArray protobuf message into bytes.\n\n    Args:\n        nda_proto (NDArray): bytes.\n\n    Returns:\n        Returns bytes.\n    \"\"\"\n    nda_bytes = BytesIO(nda_proto.ndarray)\n\n    return nda_bytes.read()",
  "def shareable_to_modeldata(shareable, fl_ctx):\n    # make_init_proto message\n    model_data = ModelData()  # create an empty message\n\n    model_data.params[\"data\"].CopyFrom(make_shareable_data(shareable))\n\n    context_data = make_context_data(fl_ctx)\n    model_data.params[\"fl_context\"].CopyFrom(context_data)\n    return model_data",
  "def make_shareable_data(shareable):\n    return bytes_to_proto(shareable.to_bytes())",
  "def make_context_data(fl_ctx):\n    shared_fl_ctx = FLContext()\n    shared_fl_ctx.set_public_props(fl_ctx.get_all_public_props())\n    props = pickle.dumps(shared_fl_ctx)\n    context_data = bytes_to_proto(props)\n    return context_data",
  "def deploy_app(app_name, site_name, workspace, app_data):\n    try:\n        dest = os.path.join(workspace, WorkspaceConstants.APP_PREFIX + site_name)\n        # Remove the previous deployed app.\n        if os.path.exists(dest):\n            shutil.rmtree(dest)\n        if not os.path.exists(dest):\n            os.makedirs(dest)\n        unzip_all_from_bytes(app_data, dest)\n        app_file = os.path.join(workspace, \"fl_app.txt\")\n        if os.path.exists(app_file):\n            os.remove(app_file)\n        with open(app_file, \"wt\") as f:\n            f.write(f\"{app_name}\")\n        return True\n    except:\n        return False",
  "def add_logfile_handler(log_file):\n    root_logger = logging.getLogger()\n    main_handler = root_logger.handlers[0]\n    file_handler = RotatingFileHandler(log_file, maxBytes=20 * 1024 * 1024, backupCount=10)\n    file_handler.setLevel(main_handler.level)\n    file_handler.setFormatter(main_handler.formatter)\n    root_logger.addHandler(file_handler)",
  "def listen_command(listen_port, engine, execute_func, logger):\n    conn = None\n    listener = None\n    try:\n        address = (\"localhost\", listen_port)\n        listener = Listener(address, authkey=\"client process secret password\".encode())\n        conn = listener.accept()\n\n        execute_func(conn, engine)\n\n    except Exception as e:\n        logger.exception(f\"Could not create the listener for this process on port: {listen_port}: {e}.\", exc_info=True)\n    finally:\n        if conn:\n            conn.close()\n        if listener:\n            listener.close()",
  "def secure_content_check(config: str, site_type: str) -> List[str]:\n    \"\"\"To check the security contents.\n\n    Args:\n        config (str): The fed_XXX config\n        site_type (str): \"server\" or \"client\"\n\n    Returns:\n        A list of insecure content.\n    \"\"\"\n    insecure_list = []\n    data, sig = SecurityContentService.load_json(config)\n    if sig != LoadResult.OK:\n        insecure_list.append(config)\n\n    sites_to_check = data[\"servers\"] if site_type == \"server\" else [data[\"client\"]]\n\n    for site in sites_to_check:\n        for filename in [SSLConstants.CERT, SSLConstants.PRIVATE_KEY, SSLConstants.ROOT_CERT]:\n            content, sig = SecurityContentService.load_content(site.get(filename))\n            if sig != LoadResult.OK:\n                insecure_list.append(site.get(filename))\n\n    if site_type == \"server\":\n        if \"authorization.json\" in SecurityContentService.security_content_manager.signature:\n            data, sig = SecurityContentService.load_json(\"authorization.json\")\n            if sig != LoadResult.OK:\n                insecure_list.append(\"authorization.json\")\n\n    return insecure_list",
  "class ClientEngine(ClientEngineInternalSpec):\n    \"\"\"ClientEngine runs in the client parent process.\"\"\"\n\n    def __init__(self, client, client_name, sender, args, rank, workers=5):\n        \"\"\"To init the ClientEngine.\n\n        Args:\n            client: FL client object\n            client_name: client name\n            sender: sender object\n            args: command args\n            rank: local process rank\n            workers: number of workers\n        \"\"\"\n        super().__init__()\n        self.client = client\n        self.client_name = client_name\n        self.sender = sender\n        self.args = args\n        self.rank = rank\n        self.client.process = None\n        self.client_executor = ProcessExecutor(client.client_name, os.path.join(args.workspace, \"startup\"))\n\n        self.fl_ctx_mgr = FLContextManager(\n            engine=self, identity_name=client_name, job_id=\"\", public_stickers={}, private_stickers={}\n        )\n\n        self.status = MachineStatus.STOPPED\n\n        if workers < 1:\n            raise ValueError(\"workers must >= 1\")\n        self.executor = ThreadPoolExecutor(max_workers=workers)\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.fl_components = [x for x in self.client.components.values() if isinstance(x, FLComponent)]\n\n    def fire_event(self, event_type: str, fl_ctx: FLContext):\n        fire_event(event=event_type, handlers=self.fl_components, ctx=fl_ctx)\n\n    def set_agent(self, admin_agent):\n        self.admin_agent = admin_agent\n\n    def do_validate(self, req: Message):\n        self.logger.info(\"starting cross site validation.\")\n        _ = self.executor.submit(lambda p: _do_validate(*p), [self.sender, req])\n\n        return \"validate process started.\"\n\n    def new_context(self) -> FLContext:\n        return self.fl_ctx_mgr.new_context()\n\n    def get_component(self, component_id: str) -> object:\n        return self.client.components.get(component_id)\n\n    def get_engine_status(self):\n        running_jobs = []\n        for job_id in self.get_all_job_ids():\n            run_folder = os.path.join(self.args.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(job_id))\n            app_file = os.path.join(run_folder, \"fl_app.txt\")\n            if os.path.exists(app_file):\n                with open(app_file, \"r\") as f:\n                    app_name = f.readline().strip()\n            job = {\n                ClientStatusKey.APP_NAME: app_name,\n                ClientStatusKey.JOB_ID: job_id,\n                ClientStatusKey.STATUS: self.client_executor.check_status(self.client, job_id),\n            }\n            running_jobs.append(job)\n\n        result = {\n            ClientStatusKey.CLIENT_NAME: self.client.client_name,\n            ClientStatusKey.RUNNING_JOBS: running_jobs,\n        }\n        return result\n\n    def start_app(\n        self,\n        job_id: str,\n        allocated_resource: dict = None,\n        token: str = None,\n        resource_consumer=None,\n        resource_manager=None,\n    ) -> str:\n        status = self.client_executor.get_status(job_id)\n        if status == ClientStatus.STARTED:\n            return \"Client app already started.\"\n\n        app_root = os.path.join(\n            self.args.workspace,\n            WorkspaceConstants.WORKSPACE_PREFIX + str(job_id),\n            WorkspaceConstants.APP_PREFIX + self.client.client_name,\n        )\n        if not os.path.exists(app_root):\n            return f\"{ERROR_MSG_PREFIX}: Client app does not exist. Please deploy it before starting client.\"\n\n        if self.client.enable_byoc:\n            app_custom_folder = os.path.join(app_root, \"custom\")\n            try:\n                sys.path.index(app_custom_folder)\n            except ValueError:\n                self.remove_custom_path()\n                sys.path.append(app_custom_folder)\n        else:\n            app_custom_folder = \"\"\n\n        self.logger.info(\"Starting client app. rank: {}\".format(self.rank))\n\n        open_port = get_open_ports(1)[0]\n\n        self.client_executor.start_train(\n            self.client,\n            job_id,\n            self.args,\n            app_root,\n            app_custom_folder,\n            open_port,\n            allocated_resource,\n            token,\n            resource_consumer,\n            resource_manager,\n            list(self.client.servers.values())[0][\"target\"],\n        )\n\n        return \"Start the client app...\"\n\n    def get_client_name(self):\n        return self.client.client_name\n\n    def _write_token_file(self, job_id, open_port):\n        token_file = os.path.join(self.args.workspace, EngineConstant.CLIENT_TOKEN_FILE)\n        if os.path.exists(token_file):\n            os.remove(token_file)\n        with open(token_file, \"wt\") as f:\n            f.write(\n                \"%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n\"\n                % (\n                    self.client.token,\n                    self.client.ssid,\n                    job_id,\n                    self.client.client_name,\n                    open_port,\n                    list(self.client.servers.values())[0][\"target\"],\n                )\n            )\n\n    def remove_custom_path(self):\n        regex = re.compile(\".*/run_.*/custom\")\n        custom_paths = list(filter(regex.search, sys.path))\n        for path in custom_paths:\n            sys.path.remove(path)\n\n    def abort_app(self, job_id: str) -> str:\n        status = self.client_executor.get_status(job_id)\n        if status == ClientStatus.STOPPED:\n            return \"Client app already stopped.\"\n\n        if status == ClientStatus.NOT_STARTED:\n            return \"Client app has not started.\"\n\n        if status == ClientStatus.STARTING:\n            return \"Client app is starting, please wait for client to have started before abort.\"\n\n        self.client_executor.abort_train(self.client, job_id)\n\n        return \"Abort signal has been sent to the client App.\"\n\n    def abort_task(self, job_id: str) -> str:\n        status = self.client_executor.get_status(job_id)\n        if status == ClientStatus.NOT_STARTED:\n            return \"Client app has not started.\"\n\n        if status == ClientStatus.STARTING:\n            return \"Client app is starting, please wait for started before abort_task.\"\n\n        self.client_executor.abort_task(self.client, job_id)\n\n        return \"Abort signal has been sent to the current task.\"\n\n    def shutdown(self) -> str:\n        self.logger.info(\"Client shutdown...\")\n        touch_file = os.path.join(self.args.workspace, \"shutdown.fl\")\n        self.client_executor.close()\n        self.fire_event(EventType.SYSTEM_END, self.new_context())\n\n        _ = self.executor.submit(lambda p: _shutdown_client(*p), [self.client, self.admin_agent, touch_file])\n\n        self.executor.shutdown()\n        return \"Shutdown the client...\"\n\n    def restart(self) -> str:\n        self.logger.info(\"Client shutdown...\")\n        touch_file = os.path.join(self.args.workspace, \"restart.fl\")\n        self.client_executor.close()\n        self.fire_event(EventType.SYSTEM_END, self.new_context())\n        _ = self.executor.submit(lambda p: _shutdown_client(*p), [self.client, self.admin_agent, touch_file])\n\n        self.executor.shutdown()\n        return \"Restart the client...\"\n\n    def deploy_app(self, app_name: str, job_id: str, client_name: str, app_data) -> str:\n        workspace = os.path.join(self.args.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(job_id))\n\n        if deploy_app(app_name, client_name, workspace, app_data):\n            return f\"Deployed app {app_name} to {client_name}\"\n        else:\n            return f\"{ERROR_MSG_PREFIX}: Failed to deploy_app\"\n\n    def delete_run(self, job_id: str) -> str:\n        job_id_folder = os.path.join(self.args.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(job_id))\n        if os.path.exists(job_id_folder):\n            shutil.rmtree(job_id_folder)\n        return f\"Delete run folder: {job_id_folder}.\"\n\n    def get_current_run_info(self, job_id) -> ClientRunInfo:\n        return self.client_executor.get_run_info(job_id)\n\n    def get_errors(self, job_id):\n        return self.client_executor.get_errors(job_id)\n\n    def reset_errors(self, job_id):\n        self.client_executor.reset_errors(job_id)\n\n    def send_aux_command(self, shareable: Shareable, job_id):\n        return self.client_executor.send_aux_command(shareable, job_id)\n\n    def get_all_job_ids(self):\n        return self.client_executor.get_run_processes_keys()",
  "def _do_validate(sender, message):\n    print(\"starting the validate process .....\")\n    time.sleep(60)\n    print(\"Generating processing result ......\")\n    reply = Message(topic=message.topic, body=\"\")\n    sender.send_result(reply)\n    pass",
  "def _shutdown_client(federated_client, admin_agent, touch_file):\n    with open(touch_file, \"a\"):\n        os.utime(touch_file, None)\n\n    try:\n        print(\"About to shutdown the client...\")\n        federated_client.communicator.heartbeat_done = True\n        time.sleep(3)\n        federated_client.close()\n\n        if federated_client.process:\n            federated_client.process.terminate()\n\n        admin_agent.shutdown()\n    except BaseException as e:\n        traceback.print_exc()\n        print(\"Failed to shutdown client: \" + str(e))",
  "def __init__(self, client, client_name, sender, args, rank, workers=5):\n        \"\"\"To init the ClientEngine.\n\n        Args:\n            client: FL client object\n            client_name: client name\n            sender: sender object\n            args: command args\n            rank: local process rank\n            workers: number of workers\n        \"\"\"\n        super().__init__()\n        self.client = client\n        self.client_name = client_name\n        self.sender = sender\n        self.args = args\n        self.rank = rank\n        self.client.process = None\n        self.client_executor = ProcessExecutor(client.client_name, os.path.join(args.workspace, \"startup\"))\n\n        self.fl_ctx_mgr = FLContextManager(\n            engine=self, identity_name=client_name, job_id=\"\", public_stickers={}, private_stickers={}\n        )\n\n        self.status = MachineStatus.STOPPED\n\n        if workers < 1:\n            raise ValueError(\"workers must >= 1\")\n        self.executor = ThreadPoolExecutor(max_workers=workers)\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.fl_components = [x for x in self.client.components.values() if isinstance(x, FLComponent)]",
  "def fire_event(self, event_type: str, fl_ctx: FLContext):\n        fire_event(event=event_type, handlers=self.fl_components, ctx=fl_ctx)",
  "def set_agent(self, admin_agent):\n        self.admin_agent = admin_agent",
  "def do_validate(self, req: Message):\n        self.logger.info(\"starting cross site validation.\")\n        _ = self.executor.submit(lambda p: _do_validate(*p), [self.sender, req])\n\n        return \"validate process started.\"",
  "def new_context(self) -> FLContext:\n        return self.fl_ctx_mgr.new_context()",
  "def get_component(self, component_id: str) -> object:\n        return self.client.components.get(component_id)",
  "def get_engine_status(self):\n        running_jobs = []\n        for job_id in self.get_all_job_ids():\n            run_folder = os.path.join(self.args.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(job_id))\n            app_file = os.path.join(run_folder, \"fl_app.txt\")\n            if os.path.exists(app_file):\n                with open(app_file, \"r\") as f:\n                    app_name = f.readline().strip()\n            job = {\n                ClientStatusKey.APP_NAME: app_name,\n                ClientStatusKey.JOB_ID: job_id,\n                ClientStatusKey.STATUS: self.client_executor.check_status(self.client, job_id),\n            }\n            running_jobs.append(job)\n\n        result = {\n            ClientStatusKey.CLIENT_NAME: self.client.client_name,\n            ClientStatusKey.RUNNING_JOBS: running_jobs,\n        }\n        return result",
  "def start_app(\n        self,\n        job_id: str,\n        allocated_resource: dict = None,\n        token: str = None,\n        resource_consumer=None,\n        resource_manager=None,\n    ) -> str:\n        status = self.client_executor.get_status(job_id)\n        if status == ClientStatus.STARTED:\n            return \"Client app already started.\"\n\n        app_root = os.path.join(\n            self.args.workspace,\n            WorkspaceConstants.WORKSPACE_PREFIX + str(job_id),\n            WorkspaceConstants.APP_PREFIX + self.client.client_name,\n        )\n        if not os.path.exists(app_root):\n            return f\"{ERROR_MSG_PREFIX}: Client app does not exist. Please deploy it before starting client.\"\n\n        if self.client.enable_byoc:\n            app_custom_folder = os.path.join(app_root, \"custom\")\n            try:\n                sys.path.index(app_custom_folder)\n            except ValueError:\n                self.remove_custom_path()\n                sys.path.append(app_custom_folder)\n        else:\n            app_custom_folder = \"\"\n\n        self.logger.info(\"Starting client app. rank: {}\".format(self.rank))\n\n        open_port = get_open_ports(1)[0]\n\n        self.client_executor.start_train(\n            self.client,\n            job_id,\n            self.args,\n            app_root,\n            app_custom_folder,\n            open_port,\n            allocated_resource,\n            token,\n            resource_consumer,\n            resource_manager,\n            list(self.client.servers.values())[0][\"target\"],\n        )\n\n        return \"Start the client app...\"",
  "def get_client_name(self):\n        return self.client.client_name",
  "def _write_token_file(self, job_id, open_port):\n        token_file = os.path.join(self.args.workspace, EngineConstant.CLIENT_TOKEN_FILE)\n        if os.path.exists(token_file):\n            os.remove(token_file)\n        with open(token_file, \"wt\") as f:\n            f.write(\n                \"%s\\n%s\\n%s\\n%s\\n%s\\n%s\\n\"\n                % (\n                    self.client.token,\n                    self.client.ssid,\n                    job_id,\n                    self.client.client_name,\n                    open_port,\n                    list(self.client.servers.values())[0][\"target\"],\n                )\n            )",
  "def remove_custom_path(self):\n        regex = re.compile(\".*/run_.*/custom\")\n        custom_paths = list(filter(regex.search, sys.path))\n        for path in custom_paths:\n            sys.path.remove(path)",
  "def abort_app(self, job_id: str) -> str:\n        status = self.client_executor.get_status(job_id)\n        if status == ClientStatus.STOPPED:\n            return \"Client app already stopped.\"\n\n        if status == ClientStatus.NOT_STARTED:\n            return \"Client app has not started.\"\n\n        if status == ClientStatus.STARTING:\n            return \"Client app is starting, please wait for client to have started before abort.\"\n\n        self.client_executor.abort_train(self.client, job_id)\n\n        return \"Abort signal has been sent to the client App.\"",
  "def abort_task(self, job_id: str) -> str:\n        status = self.client_executor.get_status(job_id)\n        if status == ClientStatus.NOT_STARTED:\n            return \"Client app has not started.\"\n\n        if status == ClientStatus.STARTING:\n            return \"Client app is starting, please wait for started before abort_task.\"\n\n        self.client_executor.abort_task(self.client, job_id)\n\n        return \"Abort signal has been sent to the current task.\"",
  "def shutdown(self) -> str:\n        self.logger.info(\"Client shutdown...\")\n        touch_file = os.path.join(self.args.workspace, \"shutdown.fl\")\n        self.client_executor.close()\n        self.fire_event(EventType.SYSTEM_END, self.new_context())\n\n        _ = self.executor.submit(lambda p: _shutdown_client(*p), [self.client, self.admin_agent, touch_file])\n\n        self.executor.shutdown()\n        return \"Shutdown the client...\"",
  "def restart(self) -> str:\n        self.logger.info(\"Client shutdown...\")\n        touch_file = os.path.join(self.args.workspace, \"restart.fl\")\n        self.client_executor.close()\n        self.fire_event(EventType.SYSTEM_END, self.new_context())\n        _ = self.executor.submit(lambda p: _shutdown_client(*p), [self.client, self.admin_agent, touch_file])\n\n        self.executor.shutdown()\n        return \"Restart the client...\"",
  "def deploy_app(self, app_name: str, job_id: str, client_name: str, app_data) -> str:\n        workspace = os.path.join(self.args.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(job_id))\n\n        if deploy_app(app_name, client_name, workspace, app_data):\n            return f\"Deployed app {app_name} to {client_name}\"\n        else:\n            return f\"{ERROR_MSG_PREFIX}: Failed to deploy_app\"",
  "def delete_run(self, job_id: str) -> str:\n        job_id_folder = os.path.join(self.args.workspace, WorkspaceConstants.WORKSPACE_PREFIX + str(job_id))\n        if os.path.exists(job_id_folder):\n            shutil.rmtree(job_id_folder)\n        return f\"Delete run folder: {job_id_folder}.\"",
  "def get_current_run_info(self, job_id) -> ClientRunInfo:\n        return self.client_executor.get_run_info(job_id)",
  "def get_errors(self, job_id):\n        return self.client_executor.get_errors(job_id)",
  "def reset_errors(self, job_id):\n        self.client_executor.reset_errors(job_id)",
  "def send_aux_command(self, shareable: Shareable, job_id):\n        return self.client_executor.send_aux_command(shareable, job_id)",
  "def get_all_job_ids(self):\n        return self.client_executor.get_run_processes_keys()",
  "class ClientStatus(object):\n    NOT_STARTED = 0\n    STARTING = 1\n    STARTED = 2\n    STOPPED = 3\n    EXCEPTION = 4\n\n    status_messages = {\n        NOT_STARTED: \"not started\",\n        STARTING: \"starting\",\n        STARTED: \"started\",\n        STOPPED: \"stopped\",\n        EXCEPTION: \"exception\",\n    }",
  "def get_status_message(status):\n    return ClientStatus.status_messages.get(status)",
  "class AuxRequestProcessor(RequestProcessor):\n    def get_topics(self) -> [str]:\n        return [ReservedTopic.AUX_COMMAND]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n\n        shareable = pickle.loads(req.body)\n\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        result = engine.send_aux_command(shareable, job_id)\n        if not result:\n            result = make_reply(ReturnCode.EXECUTION_EXCEPTION)\n\n        result = pickle.dumps(result)\n        message = Message(topic=\"reply_\" + req.topic, body=result)\n        return message",
  "def get_topics(self) -> [str]:\n        return [ReservedTopic.AUX_COMMAND]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n\n        shareable = pickle.loads(req.body)\n\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        result = engine.send_aux_command(shareable, job_id)\n        if not result:\n            result = make_reply(ReturnCode.EXECUTION_EXCEPTION)\n\n        result = pickle.dumps(result)\n        message = Message(topic=\"reply_\" + req.topic, body=result)\n        return message",
  "class Sender(object):\n    \"\"\"The Sender object integrate the agent with the underline messaging system.\n\n    Make sure its methods are exception-proof!\n    \"\"\"\n\n    def send_reply(self, reply: Message):\n        \"\"\"Send the reply to the requester.\n\n        Args:\n            reply: reply message\n\n        \"\"\"\n        pass\n\n    def retrieve_requests(self) -> [Message]:\n        \"\"\"Send the message to retrieve pending requests from the Server.\n\n        Returns: list of messages.\n\n        \"\"\"\n        pass\n\n    def send_result(self, message: Message):\n        \"\"\"Send the processor results to server.\n\n        Args:\n            message: message\n\n        \"\"\"\n        pass\n\n    def close(self):\n        \"\"\"Call to close the sender.\n\n        Returns:\n\n        \"\"\"",
  "class RequestProcessor(object):\n    \"\"\"The RequestProcessor is responsible for processing a request.\"\"\"\n\n    def get_topics(self) -> [str]:\n        \"\"\"Get topics that this processor will handle.\n\n        Returns: list of topics\n\n        \"\"\"\n        pass\n\n    def process(self, req: Message, app_ctx) -> Message:\n        \"\"\"Called to process the specified request.\n\n        Args:\n            req: request message\n            app_ctx: application context\n\n        Returns: reply message\n\n        \"\"\"\n        pass",
  "class FedAdminAgent(object):\n    \"\"\"FedAdminAgent communicate with the FedAdminServer.\"\"\"\n\n    def __init__(self, client_name, sender: Sender, app_ctx, req_poll_interval=0.5, process_poll_interval=0.1):\n        \"\"\"Init the FedAdminAgent.\n\n        Args:\n            client_name: client name\n            sender: Sender object\n            app_ctx: application context\n            req_poll_interval: request polling interval\n            process_poll_interval: process polling interval\n        \"\"\"\n        if not isinstance(sender, Sender):\n            raise TypeError(\"sender must be an instance of Sender, but got {}\".format(type(sender)))\n\n        auditor = AuditService.get_auditor()\n        if not isinstance(auditor, Auditor):\n            raise TypeError(\"auditor must be an instance of Auditor, but got {}\".format(type(auditor)))\n\n        self.name = client_name\n        self.sender = sender\n        self.auditor = auditor\n        self.app_ctx = app_ctx\n        self.req_poll_interval = req_poll_interval\n        self.process_poll_interval = process_poll_interval\n        self.processors = {}\n        self.reqs = []\n        self.req_lock = threading.Lock()\n        self.retrieve_reqs_thread = None\n        self.process_req_thread = None\n        self.asked_to_stop = False\n\n    def register_processor(self, processor: RequestProcessor):\n        \"\"\"To register the RequestProcessor.\n\n        Args:\n            processor: RequestProcessor\n\n        \"\"\"\n        if not isinstance(processor, RequestProcessor):\n            raise TypeError(\"processor must be an instance of RequestProcessor, but got {}\".format(type(processor)))\n\n        topics = processor.get_topics()\n        for topic in topics:\n            assert topic not in self.processors, \"duplicate processors for topic {}\".format(topic)\n            self.processors[topic] = processor\n\n    def start(self):\n        \"\"\"To start the FedAdminAgent.\"\"\"\n        if self.retrieve_reqs_thread is None:\n            self.retrieve_reqs_thread = threading.Thread(target=_start_retriever, args=(self,))\n\n        # called from the main thread\n        if not self.retrieve_reqs_thread.is_alive():\n            self.retrieve_reqs_thread.start()\n\n        if self.process_req_thread is None:\n            self.process_req_thread = threading.Thread(target=_start_processor, args=(self,))\n\n        # called from the main thread\n        if not self.process_req_thread.is_alive():\n            self.process_req_thread.start()\n\n    def _run_retriever(self):\n        while True:\n            if self.asked_to_stop:\n                break\n\n            reqs = self.sender.retrieve_requests()\n            if reqs is not None and isinstance(reqs, list):\n                with self.req_lock:\n                    self.reqs.extend(reqs)\n\n            time.sleep(self.req_poll_interval)\n\n    def _run_processor(self):\n        while True:\n            if self.asked_to_stop:\n                break\n\n            with self.req_lock:\n                if len(self.reqs) > 0:\n                    req = self.reqs.pop(0)\n                else:\n                    req = None\n\n            if req:\n                assert isinstance(req, Message), \"request must be Message but got {}\".format(type(req))\n                topic = req.topic\n\n                # create audit record\n                if self.auditor:\n                    user_name = req.get_header(ConnProps.USER_NAME, \"\")\n                    ref_event_id = req.get_header(ConnProps.EVENT_ID, \"\")\n                    self.auditor.add_event(user=user_name, action=topic, ref=ref_event_id)\n\n                processor = self.processors.get(topic)\n                if processor:\n                    try:\n                        reply = processor.process(req, self.app_ctx)\n                        if reply is None:\n                            # simply ack\n                            reply = ok_reply()\n                        else:\n                            assert isinstance(\n                                reply, Message\n                            ), \"processor for topic {} failed to produce valid reply\".format(topic)\n                    except BaseException as e:\n                        traceback.print_exc()\n                        reply = error_reply(\"exception_occurred: {}\".format(e))\n                else:\n                    reply = error_reply(\"invalid_request\")\n\n                reply.set_ref_id(req.id)\n                self.sender.send_reply(reply)\n\n            time.sleep(self.process_poll_interval)\n\n    def shutdown(self):\n        \"\"\"To be called by the Client Engine to gracefully shutdown the agent.\"\"\"\n        self.asked_to_stop = True\n\n        if self.retrieve_reqs_thread and self.retrieve_reqs_thread.is_alive():\n            self.retrieve_reqs_thread.join()\n\n        if self.process_req_thread and self.process_req_thread.is_alive():\n            self.process_req_thread.join()\n\n        self.sender.close()",
  "def _start_retriever(agent: FedAdminAgent):\n    agent._run_retriever()",
  "def _start_processor(agent: FedAdminAgent):\n    agent._run_processor()",
  "def send_reply(self, reply: Message):\n        \"\"\"Send the reply to the requester.\n\n        Args:\n            reply: reply message\n\n        \"\"\"\n        pass",
  "def retrieve_requests(self) -> [Message]:\n        \"\"\"Send the message to retrieve pending requests from the Server.\n\n        Returns: list of messages.\n\n        \"\"\"\n        pass",
  "def send_result(self, message: Message):\n        \"\"\"Send the processor results to server.\n\n        Args:\n            message: message\n\n        \"\"\"\n        pass",
  "def close(self):\n        \"\"\"Call to close the sender.\n\n        Returns:\n\n        \"\"\"",
  "def get_topics(self) -> [str]:\n        \"\"\"Get topics that this processor will handle.\n\n        Returns: list of topics\n\n        \"\"\"\n        pass",
  "def process(self, req: Message, app_ctx) -> Message:\n        \"\"\"Called to process the specified request.\n\n        Args:\n            req: request message\n            app_ctx: application context\n\n        Returns: reply message\n\n        \"\"\"\n        pass",
  "def __init__(self, client_name, sender: Sender, app_ctx, req_poll_interval=0.5, process_poll_interval=0.1):\n        \"\"\"Init the FedAdminAgent.\n\n        Args:\n            client_name: client name\n            sender: Sender object\n            app_ctx: application context\n            req_poll_interval: request polling interval\n            process_poll_interval: process polling interval\n        \"\"\"\n        if not isinstance(sender, Sender):\n            raise TypeError(\"sender must be an instance of Sender, but got {}\".format(type(sender)))\n\n        auditor = AuditService.get_auditor()\n        if not isinstance(auditor, Auditor):\n            raise TypeError(\"auditor must be an instance of Auditor, but got {}\".format(type(auditor)))\n\n        self.name = client_name\n        self.sender = sender\n        self.auditor = auditor\n        self.app_ctx = app_ctx\n        self.req_poll_interval = req_poll_interval\n        self.process_poll_interval = process_poll_interval\n        self.processors = {}\n        self.reqs = []\n        self.req_lock = threading.Lock()\n        self.retrieve_reqs_thread = None\n        self.process_req_thread = None\n        self.asked_to_stop = False",
  "def register_processor(self, processor: RequestProcessor):\n        \"\"\"To register the RequestProcessor.\n\n        Args:\n            processor: RequestProcessor\n\n        \"\"\"\n        if not isinstance(processor, RequestProcessor):\n            raise TypeError(\"processor must be an instance of RequestProcessor, but got {}\".format(type(processor)))\n\n        topics = processor.get_topics()\n        for topic in topics:\n            assert topic not in self.processors, \"duplicate processors for topic {}\".format(topic)\n            self.processors[topic] = processor",
  "def start(self):\n        \"\"\"To start the FedAdminAgent.\"\"\"\n        if self.retrieve_reqs_thread is None:\n            self.retrieve_reqs_thread = threading.Thread(target=_start_retriever, args=(self,))\n\n        # called from the main thread\n        if not self.retrieve_reqs_thread.is_alive():\n            self.retrieve_reqs_thread.start()\n\n        if self.process_req_thread is None:\n            self.process_req_thread = threading.Thread(target=_start_processor, args=(self,))\n\n        # called from the main thread\n        if not self.process_req_thread.is_alive():\n            self.process_req_thread.start()",
  "def _run_retriever(self):\n        while True:\n            if self.asked_to_stop:\n                break\n\n            reqs = self.sender.retrieve_requests()\n            if reqs is not None and isinstance(reqs, list):\n                with self.req_lock:\n                    self.reqs.extend(reqs)\n\n            time.sleep(self.req_poll_interval)",
  "def _run_processor(self):\n        while True:\n            if self.asked_to_stop:\n                break\n\n            with self.req_lock:\n                if len(self.reqs) > 0:\n                    req = self.reqs.pop(0)\n                else:\n                    req = None\n\n            if req:\n                assert isinstance(req, Message), \"request must be Message but got {}\".format(type(req))\n                topic = req.topic\n\n                # create audit record\n                if self.auditor:\n                    user_name = req.get_header(ConnProps.USER_NAME, \"\")\n                    ref_event_id = req.get_header(ConnProps.EVENT_ID, \"\")\n                    self.auditor.add_event(user=user_name, action=topic, ref=ref_event_id)\n\n                processor = self.processors.get(topic)\n                if processor:\n                    try:\n                        reply = processor.process(req, self.app_ctx)\n                        if reply is None:\n                            # simply ack\n                            reply = ok_reply()\n                        else:\n                            assert isinstance(\n                                reply, Message\n                            ), \"processor for topic {} failed to produce valid reply\".format(topic)\n                    except BaseException as e:\n                        traceback.print_exc()\n                        reply = error_reply(\"exception_occurred: {}\".format(e))\n                else:\n                    reply = error_reply(\"invalid_request\")\n\n                reply.set_ref_id(req.id)\n                self.sender.send_reply(reply)\n\n            time.sleep(self.process_poll_interval)",
  "def shutdown(self):\n        \"\"\"To be called by the Client Engine to gracefully shutdown the agent.\"\"\"\n        self.asked_to_stop = True\n\n        if self.retrieve_reqs_thread and self.retrieve_reqs_thread.is_alive():\n            self.retrieve_reqs_thread.join()\n\n        if self.process_req_thread and self.process_req_thread.is_alive():\n            self.process_req_thread.join()\n\n        self.sender.close()",
  "class ClientRunnerConfig(object):\n    def __init__(\n        self,\n        task_table: dict,  # task_name => Executor\n        task_data_filters: dict,  # task_name => list of filters\n        task_result_filters: dict,  # task_name => list of filters\n        handlers=None,  # list of event handlers\n        components=None,  # dict of extra python objects: id => object\n    ):\n        \"\"\"To init ClientRunnerConfig.\n\n        Args:\n            task_table: task_name: Executor dict\n            task_data_filters: task_name => list of data filters\n            task_result_filters: task_name => list of result filters\n            handlers: list of event handlers\n            components: dict of extra python objects: id => object\n        \"\"\"\n        self.task_table = task_table\n        self.task_data_filters = task_data_filters\n        self.task_result_filters = task_result_filters\n        self.handlers = handlers\n        self.components = components",
  "class ClientRunner(FLComponent):\n    def __init__(\n        self,\n        config: ClientRunnerConfig,\n        job_id,\n        engine: ClientEngineSpec,\n        task_fetch_interval: int = 5,  # fetch task every 5 secs\n    ):\n        \"\"\"To init the ClientRunner.\n\n        Args:\n            config: ClientRunnerConfig\n            job_id: job id\n            engine: ClientEngine object\n            task_fetch_interval:  fetch task interval\n        \"\"\"\n        FLComponent.__init__(self)\n        self.task_table = config.task_table\n        self.task_data_filters = config.task_data_filters\n        self.task_result_filters = config.task_result_filters\n\n        self.job_id = job_id\n        self.engine = engine\n        self.task_fetch_interval = task_fetch_interval\n        self.run_abort_signal = Signal()\n        self.task_abort_signal = None\n        self.current_executor = None\n        self.current_task = None\n        self.asked_to_stop = False\n        self.task_lock = threading.Lock()\n        self.end_run_fired = False\n        self.end_run_lock = threading.Lock()\n\n        engine.register_aux_message_handler(topic=ReservedTopic.END_RUN, message_handle_func=self._handle_end_run)\n        engine.register_aux_message_handler(topic=ReservedTopic.ABORT_ASK, message_handle_func=self._handle_abort_task)\n\n    def _process_task(self, task: TaskAssignment, fl_ctx: FLContext) -> Shareable:\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ClientEngineSpec):\n            raise TypeError(\"engine must be ClientEngineSpec, but got {}\".format(type(engine)))\n\n        if not isinstance(task.data, Shareable):\n            self.log_error(\n                fl_ctx, \"got invalid task data in assignment: expect Shareable, but got {}\".format(type(task.data))\n            )\n            return make_reply(ReturnCode.BAD_TASK_DATA)\n\n        fl_ctx.set_prop(FLContextKey.TASK_DATA, value=task.data, private=True, sticky=False)\n        fl_ctx.set_prop(FLContextKey.TASK_NAME, value=task.name, private=True, sticky=False)\n        fl_ctx.set_prop(FLContextKey.TASK_ID, value=task.task_id, private=True, sticky=False)\n\n        peer_ctx = fl_ctx.get_peer_context()\n        if not peer_ctx:\n            self.log_error(fl_ctx, \"missing peer context in Server task assignment\")\n            return make_reply(ReturnCode.MISSING_PEER_CONTEXT)\n\n        if not isinstance(peer_ctx, FLContext):\n            self.log_error(\n                fl_ctx,\n                \"bad peer context in Server task assignment: expects FLContext but got {}\".format(type(peer_ctx)),\n            )\n            return make_reply(ReturnCode.BAD_PEER_CONTEXT)\n\n        task.data.set_peer_props(peer_ctx.get_all_public_props())\n        peer_job_id = peer_ctx.get_job_id()\n        if peer_job_id != self.job_id:\n            self.log_error(fl_ctx, \"bad task assignment: not for the same job_id\")\n            return make_reply(ReturnCode.RUN_MISMATCH)\n\n        executor = self.task_table.get(task.name)\n        if not executor:\n            self.log_error(fl_ctx, \"bad task assignment: no executor available for task {}\".format(task.name))\n            return make_reply(ReturnCode.TASK_UNKNOWN)\n\n        self.log_debug(fl_ctx, \"firing event EventType.BEFORE_TASK_DATA_FILTER\")\n        self.fire_event(EventType.BEFORE_TASK_DATA_FILTER, fl_ctx)\n        filter_list = self.task_data_filters.get(task.name)\n        if filter_list:\n            task_data = task.data\n            for f in filter_list:\n                try:\n                    task_data = f.process(task_data, fl_ctx)\n                except BaseException:\n                    self.log_exception(fl_ctx, \"processing error in Task Data Filter {}\".format(type(f)))\n                    return make_reply(ReturnCode.TASK_DATA_FILTER_ERROR)\n\n            if not isinstance(task_data, Shareable):\n                self.log_error(\n                    fl_ctx, \"task data was converted to wrong type: expect Shareable but got {}\".format(type(task_data))\n                )\n                return make_reply(ReturnCode.TASK_DATA_FILTER_ERROR)\n\n            task.data = task_data\n\n        self.log_debug(fl_ctx, \"firing event EventType.AFTER_TASK_DATA_FILTER\")\n        fl_ctx.set_prop(FLContextKey.TASK_DATA, value=task.data, private=True, sticky=False)\n        self.fire_event(EventType.AFTER_TASK_DATA_FILTER, fl_ctx)\n\n        self.log_debug(fl_ctx, \"firing event EventType.BEFORE_TASK_EXECUTION\")\n        fl_ctx.set_prop(FLContextKey.TASK_DATA, value=task.data, private=True, sticky=False)\n        self.fire_event(EventType.BEFORE_TASK_EXECUTION, fl_ctx)\n        try:\n            self.log_info(fl_ctx, \"invoking task executor {}\".format(type(executor)))\n\n            with self.task_lock:\n                self.task_abort_signal = Signal()\n                self.current_executor = executor\n                self.current_task = task\n\n            try:\n                reply = executor.execute(task.name, task.data, fl_ctx, self.task_abort_signal)\n            finally:\n                with self.task_lock:\n                    if self.task_abort_signal is None:\n                        task_aborted = True\n                    else:\n                        task_aborted = False\n\n                    self.task_abort_signal = None\n                    self.current_task = None\n                    self.current_executor = None\n                    if task_aborted:\n                        return make_reply(ReturnCode.TASK_ABORTED)\n\n            if not isinstance(reply, Shareable):\n                self.log_error(\n                    fl_ctx,\n                    \"bad result generated by executor {}: must be Shareable but got {}\".format(\n                        type(executor), type(reply)\n                    ),\n                )\n                return make_reply(ReturnCode.EXECUTION_RESULT_ERROR)\n        except RuntimeError as e:\n            self.log_exception(fl_ctx, f\"Critical RuntimeError happened with Exception {e}: Aborting the RUN!\")\n            self.asked_to_stop = True\n            return make_reply(ReturnCode.EXECUTION_RESULT_ERROR)\n        except BaseException:\n            self.log_exception(fl_ctx, \"processing error in task executor {}\".format(type(executor)))\n            return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n\n        fl_ctx.set_prop(FLContextKey.TASK_RESULT, value=reply, private=True, sticky=False)\n\n        self.log_debug(fl_ctx, \"firing event EventType.AFTER_TASK_EXECUTION\")\n        self.fire_event(EventType.AFTER_TASK_EXECUTION, fl_ctx)\n\n        self.log_debug(fl_ctx, \"firing event EventType.BEFORE_TASK_RESULT_FILTER\")\n        self.fire_event(EventType.BEFORE_TASK_RESULT_FILTER, fl_ctx)\n        filter_list = self.task_result_filters.get(task.name)\n        if filter_list:\n            for f in filter_list:\n                try:\n                    reply = f.process(reply, fl_ctx)\n                except BaseException:\n                    self.log_exception(fl_ctx, \"processing error in Task Result Filter {}\".format(type(f)))\n                    return make_reply(ReturnCode.TASK_RESULT_FILTER_ERROR)\n\n            if not isinstance(reply, Shareable):\n                self.log_error(\n                    fl_ctx, \"task result was converted to wrong type: expect Shareable but got {}\".format(type(reply))\n                )\n\n                return make_reply(ReturnCode.TASK_RESULT_FILTER_ERROR)\n\n        fl_ctx.set_prop(FLContextKey.TASK_RESULT, value=reply, private=True, sticky=False)\n\n        self.log_debug(fl_ctx, \"firing event EventType.AFTER_TASK_RESULT_FILTER\")\n        self.fire_event(EventType.AFTER_TASK_RESULT_FILTER, fl_ctx)\n        self.log_info(fl_ctx, \"finished processing task\")\n\n        if not isinstance(reply, Shareable):\n            self.log_error(\n                fl_ctx, \"task processing error: expects result to be Shareable, but got {}\".format(type(reply))\n            )\n            return make_reply(ReturnCode.EXECUTION_RESULT_ERROR)\n\n        return reply\n\n    def _try_run(self):\n        task_fetch_interval = self.task_fetch_interval\n        while not self.asked_to_stop:\n            with self.engine.new_context() as fl_ctx:\n                if self.run_abort_signal.triggered:\n                    self.log_info(fl_ctx, \"run abort signal received\")\n                    break\n\n                time.sleep(task_fetch_interval)\n\n                if self.run_abort_signal.triggered:\n                    self.log_info(fl_ctx, \"run abort signal received\")\n                    break\n\n                # reset to default fetch interval\n                task_fetch_interval = self.task_fetch_interval\n                self.log_debug(fl_ctx, \"fetching task from server ...\")\n                task = self.engine.get_task_assignment(fl_ctx)\n                if not task:\n                    self.log_debug(fl_ctx, \"no task received - will try in {} secs\".format(task_fetch_interval))\n                    continue\n\n                if task.name == SpecialTaskName.END_RUN:\n                    self.log_info(fl_ctx, \"server asked to end the run\")\n                    break\n\n                if task.name == SpecialTaskName.TRY_AGAIN:\n                    task_data = task.data\n                    if task_data and isinstance(task_data, Shareable):\n                        task_fetch_interval = task_data.get(TaskConstant.WAIT_TIME, self.task_fetch_interval)\n                    self.log_debug(\n                        fl_ctx, \"server asked to try again - will try in {} secs\".format(task_fetch_interval)\n                    )\n                    continue\n\n                self.log_info(fl_ctx, \"got task assignment: name={}, id={}\".format(task.name, task.task_id))\n\n                # create a new task abort signal\n                task_reply = self._process_task(task, fl_ctx)\n\n                if not isinstance(task_reply, Shareable):\n                    raise TypeError(\"task_reply must be Shareable, but got {}\".format(type(task_reply)))\n                self.log_debug(fl_ctx, \"firing event EventType.BEFORE_SEND_TASK_RESULT\")\n                self.fire_event(EventType.BEFORE_SEND_TASK_RESULT, fl_ctx)\n\n                # set the cookie in the reply!\n                task_data = task.data\n                if not isinstance(task_data, Shareable):\n                    raise TypeError(\"task_data must be Shareable, but got {}\".format(type(task_data)))\n\n                cookie_jar = task_data.get_cookie_jar()\n                if cookie_jar:\n                    task_reply.set_cookie_jar(cookie_jar)\n\n                reply_sent = self.engine.send_task_result(task_reply, fl_ctx)\n                if reply_sent:\n                    self.log_info(\n                        fl_ctx, \"result sent to server for task: name={}, id={}\".format(task.name, task.task_id)\n                    )\n                else:\n                    self.log_error(\n                        fl_ctx,\n                        \"failed to send result to server for task: name={}, id={}\".format(task.name, task.task_id),\n                    )\n                self.log_debug(fl_ctx, \"firing event EventType.AFTER_SEND_TASK_RESULT\")\n                self.fire_event(EventType.AFTER_SEND_TASK_RESULT, fl_ctx)\n\n    def run(self, app_root, args):\n        with self.engine.new_context() as fl_ctx:\n            self.fire_event(EventType.ABOUT_TO_START_RUN, fl_ctx)\n            fl_ctx.set_prop(FLContextKey.APP_ROOT, app_root, sticky=True)\n            fl_ctx.set_prop(FLContextKey.ARGS, args, sticky=True)\n            fl_ctx.set_prop(ReservedKey.RUN_ABORT_SIGNAL, self.run_abort_signal, private=True, sticky=True)\n            self.log_debug(fl_ctx, \"firing event EventType.START_RUN\")\n            self.fire_event(EventType.START_RUN, fl_ctx)\n            self.log_info(fl_ctx, \"client runner started\")\n        with self.end_run_lock:\n            self.end_run_fired = False\n\n        try:\n            self._try_run()\n        except BaseException as e:\n            with self.engine.new_context() as fl_ctx:\n                self.log_exception(fl_ctx, \"processing error in RUN execution: {}\".format(e))\n        finally:\n            # in case any task is still running, abort it\n            self._abort_current_task()\n\n            self.end_run_events_sequence(\"run method\")\n\n    def _abort_current_task(self):\n        with self.task_lock:\n            task_abort_signal = self.task_abort_signal\n            if task_abort_signal:\n                # set task_abort_signal to None to prevent triggering again\n                self.task_abort_signal = None\n                task_name = \"\"\n                task_id = \"\"\n                task = self.current_task\n                if task:\n                    task_name = task.name\n                    task_id = task.task_id\n\n                with self.engine.new_context() as fl_ctx:\n                    fl_ctx.set_prop(FLContextKey.TASK_NAME, value=task_name, private=True, sticky=False)\n                    fl_ctx.set_prop(FLContextKey.TASK_ID, value=task_id, private=True, sticky=False)\n\n                    task_abort_signal.trigger(True)\n                    self.log_info(fl_ctx, \"triggered task_abort_signal to stop task '{}'\".format(task_name))\n\n                    self.fire_event(EventType.ABORT_TASK, fl_ctx)\n                    self.log_info(fl_ctx, \"fired ABORT_TASK event to abort current task {}\".format(task_name))\n\n    def abort_task(self, task_names=None):\n        has_task_to_abort = False\n        with self.engine.new_context() as fl_ctx:\n            with self.task_lock:\n                if self.current_task:\n                    name = self.current_task.name\n                    if not task_names or name in task_names:\n                        has_task_to_abort = True\n                    else:\n                        self.log_info(\n                            fl_ctx, \"Ignored abort_task request since current task '{}' is not target\".format(name)\n                        )\n                else:\n                    self.log_info(fl_ctx, \"Ignored abort_task request since there is no current task\")\n\n        if has_task_to_abort:\n            self._abort_current_task()\n\n    def end_run_events_sequence(self, requester):\n        with self.engine.new_context() as fl_ctx:\n            self.log_info(fl_ctx, f\"{requester} requests end run events sequence\")\n            with self.end_run_lock:\n                if not self.end_run_fired:\n                    self.fire_event(EventType.ABOUT_TO_END_RUN, fl_ctx)\n                    self.log_info(fl_ctx, \"ABOUT_TO_END_RUN fired\")\n                    self.fire_event(EventType.END_RUN, fl_ctx)\n                    self.log_info(fl_ctx, \"END_RUN fired\")\n                    self.end_run_fired = True\n\n    def abort(self):\n        \"\"\"To Abort the current run.\n\n        Returns: N/A\n\n        \"\"\"\n        with self.engine.new_context() as fl_ctx:\n            self.log_info(fl_ctx, \"ABORT (RUN) command received\")\n        self._abort_current_task()\n        self.run_abort_signal.trigger(\"ABORT (RUN) triggered\")\n        self.asked_to_stop = True\n        self.end_run_events_sequence(\"ABORT (RUN)\")\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == InfoCollector.EVENT_TYPE_GET_STATS:\n            collector = fl_ctx.get_prop(InfoCollector.CTX_KEY_STATS_COLLECTOR)\n            if collector:\n                if not isinstance(collector, GroupInfoCollector):\n                    raise TypeError(\"collector must be GroupInfoCollector, but got {}\".format(type(collector)))\n                if self.current_task:\n                    current_task_name = self.current_task.name\n                else:\n                    current_task_name = \"None\"\n                collector.set_info(\n                    group_name=\"ClientRunner\",\n                    info={\"job_id\": self.job_id, \"current_task_name\": current_task_name, \"status\": \"started\"},\n                )\n        elif event_type == EventType.FATAL_TASK_ERROR:\n            reason = fl_ctx.get_prop(key=FLContextKey.EVENT_DATA, default=\"\")\n            self.log_error(fl_ctx, \"Aborting current task due to FATAL_TASK_ERROR received: {}\".format(reason))\n            self._abort_current_task()\n        elif event_type == EventType.FATAL_SYSTEM_ERROR:\n            reason = fl_ctx.get_prop(key=FLContextKey.EVENT_DATA, default=\"\")\n            self.log_error(fl_ctx, \"Aborting current RUN due to FATAL_SYSTEM_ERROR received: {}\".format(reason))\n            self.abort()\n\n    def _handle_end_run(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        self.log_info(fl_ctx, \"received aux request from Server to end current RUN\")\n        self.abort()\n        return make_reply(ReturnCode.OK)\n\n    def _handle_abort_task(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        self.log_info(fl_ctx, \"received aux request from Server to abort current task\")\n        task_names = request.get(\"task_names\", None)\n        self.abort_task(task_names)\n        return make_reply(ReturnCode.OK)",
  "def __init__(\n        self,\n        task_table: dict,  # task_name => Executor\n        task_data_filters: dict,  # task_name => list of filters\n        task_result_filters: dict,  # task_name => list of filters\n        handlers=None,  # list of event handlers\n        components=None,  # dict of extra python objects: id => object\n    ):\n        \"\"\"To init ClientRunnerConfig.\n\n        Args:\n            task_table: task_name: Executor dict\n            task_data_filters: task_name => list of data filters\n            task_result_filters: task_name => list of result filters\n            handlers: list of event handlers\n            components: dict of extra python objects: id => object\n        \"\"\"\n        self.task_table = task_table\n        self.task_data_filters = task_data_filters\n        self.task_result_filters = task_result_filters\n        self.handlers = handlers\n        self.components = components",
  "def __init__(\n        self,\n        config: ClientRunnerConfig,\n        job_id,\n        engine: ClientEngineSpec,\n        task_fetch_interval: int = 5,  # fetch task every 5 secs\n    ):\n        \"\"\"To init the ClientRunner.\n\n        Args:\n            config: ClientRunnerConfig\n            job_id: job id\n            engine: ClientEngine object\n            task_fetch_interval:  fetch task interval\n        \"\"\"\n        FLComponent.__init__(self)\n        self.task_table = config.task_table\n        self.task_data_filters = config.task_data_filters\n        self.task_result_filters = config.task_result_filters\n\n        self.job_id = job_id\n        self.engine = engine\n        self.task_fetch_interval = task_fetch_interval\n        self.run_abort_signal = Signal()\n        self.task_abort_signal = None\n        self.current_executor = None\n        self.current_task = None\n        self.asked_to_stop = False\n        self.task_lock = threading.Lock()\n        self.end_run_fired = False\n        self.end_run_lock = threading.Lock()\n\n        engine.register_aux_message_handler(topic=ReservedTopic.END_RUN, message_handle_func=self._handle_end_run)\n        engine.register_aux_message_handler(topic=ReservedTopic.ABORT_ASK, message_handle_func=self._handle_abort_task)",
  "def _process_task(self, task: TaskAssignment, fl_ctx: FLContext) -> Shareable:\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ClientEngineSpec):\n            raise TypeError(\"engine must be ClientEngineSpec, but got {}\".format(type(engine)))\n\n        if not isinstance(task.data, Shareable):\n            self.log_error(\n                fl_ctx, \"got invalid task data in assignment: expect Shareable, but got {}\".format(type(task.data))\n            )\n            return make_reply(ReturnCode.BAD_TASK_DATA)\n\n        fl_ctx.set_prop(FLContextKey.TASK_DATA, value=task.data, private=True, sticky=False)\n        fl_ctx.set_prop(FLContextKey.TASK_NAME, value=task.name, private=True, sticky=False)\n        fl_ctx.set_prop(FLContextKey.TASK_ID, value=task.task_id, private=True, sticky=False)\n\n        peer_ctx = fl_ctx.get_peer_context()\n        if not peer_ctx:\n            self.log_error(fl_ctx, \"missing peer context in Server task assignment\")\n            return make_reply(ReturnCode.MISSING_PEER_CONTEXT)\n\n        if not isinstance(peer_ctx, FLContext):\n            self.log_error(\n                fl_ctx,\n                \"bad peer context in Server task assignment: expects FLContext but got {}\".format(type(peer_ctx)),\n            )\n            return make_reply(ReturnCode.BAD_PEER_CONTEXT)\n\n        task.data.set_peer_props(peer_ctx.get_all_public_props())\n        peer_job_id = peer_ctx.get_job_id()\n        if peer_job_id != self.job_id:\n            self.log_error(fl_ctx, \"bad task assignment: not for the same job_id\")\n            return make_reply(ReturnCode.RUN_MISMATCH)\n\n        executor = self.task_table.get(task.name)\n        if not executor:\n            self.log_error(fl_ctx, \"bad task assignment: no executor available for task {}\".format(task.name))\n            return make_reply(ReturnCode.TASK_UNKNOWN)\n\n        self.log_debug(fl_ctx, \"firing event EventType.BEFORE_TASK_DATA_FILTER\")\n        self.fire_event(EventType.BEFORE_TASK_DATA_FILTER, fl_ctx)\n        filter_list = self.task_data_filters.get(task.name)\n        if filter_list:\n            task_data = task.data\n            for f in filter_list:\n                try:\n                    task_data = f.process(task_data, fl_ctx)\n                except BaseException:\n                    self.log_exception(fl_ctx, \"processing error in Task Data Filter {}\".format(type(f)))\n                    return make_reply(ReturnCode.TASK_DATA_FILTER_ERROR)\n\n            if not isinstance(task_data, Shareable):\n                self.log_error(\n                    fl_ctx, \"task data was converted to wrong type: expect Shareable but got {}\".format(type(task_data))\n                )\n                return make_reply(ReturnCode.TASK_DATA_FILTER_ERROR)\n\n            task.data = task_data\n\n        self.log_debug(fl_ctx, \"firing event EventType.AFTER_TASK_DATA_FILTER\")\n        fl_ctx.set_prop(FLContextKey.TASK_DATA, value=task.data, private=True, sticky=False)\n        self.fire_event(EventType.AFTER_TASK_DATA_FILTER, fl_ctx)\n\n        self.log_debug(fl_ctx, \"firing event EventType.BEFORE_TASK_EXECUTION\")\n        fl_ctx.set_prop(FLContextKey.TASK_DATA, value=task.data, private=True, sticky=False)\n        self.fire_event(EventType.BEFORE_TASK_EXECUTION, fl_ctx)\n        try:\n            self.log_info(fl_ctx, \"invoking task executor {}\".format(type(executor)))\n\n            with self.task_lock:\n                self.task_abort_signal = Signal()\n                self.current_executor = executor\n                self.current_task = task\n\n            try:\n                reply = executor.execute(task.name, task.data, fl_ctx, self.task_abort_signal)\n            finally:\n                with self.task_lock:\n                    if self.task_abort_signal is None:\n                        task_aborted = True\n                    else:\n                        task_aborted = False\n\n                    self.task_abort_signal = None\n                    self.current_task = None\n                    self.current_executor = None\n                    if task_aborted:\n                        return make_reply(ReturnCode.TASK_ABORTED)\n\n            if not isinstance(reply, Shareable):\n                self.log_error(\n                    fl_ctx,\n                    \"bad result generated by executor {}: must be Shareable but got {}\".format(\n                        type(executor), type(reply)\n                    ),\n                )\n                return make_reply(ReturnCode.EXECUTION_RESULT_ERROR)\n        except RuntimeError as e:\n            self.log_exception(fl_ctx, f\"Critical RuntimeError happened with Exception {e}: Aborting the RUN!\")\n            self.asked_to_stop = True\n            return make_reply(ReturnCode.EXECUTION_RESULT_ERROR)\n        except BaseException:\n            self.log_exception(fl_ctx, \"processing error in task executor {}\".format(type(executor)))\n            return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n\n        fl_ctx.set_prop(FLContextKey.TASK_RESULT, value=reply, private=True, sticky=False)\n\n        self.log_debug(fl_ctx, \"firing event EventType.AFTER_TASK_EXECUTION\")\n        self.fire_event(EventType.AFTER_TASK_EXECUTION, fl_ctx)\n\n        self.log_debug(fl_ctx, \"firing event EventType.BEFORE_TASK_RESULT_FILTER\")\n        self.fire_event(EventType.BEFORE_TASK_RESULT_FILTER, fl_ctx)\n        filter_list = self.task_result_filters.get(task.name)\n        if filter_list:\n            for f in filter_list:\n                try:\n                    reply = f.process(reply, fl_ctx)\n                except BaseException:\n                    self.log_exception(fl_ctx, \"processing error in Task Result Filter {}\".format(type(f)))\n                    return make_reply(ReturnCode.TASK_RESULT_FILTER_ERROR)\n\n            if not isinstance(reply, Shareable):\n                self.log_error(\n                    fl_ctx, \"task result was converted to wrong type: expect Shareable but got {}\".format(type(reply))\n                )\n\n                return make_reply(ReturnCode.TASK_RESULT_FILTER_ERROR)\n\n        fl_ctx.set_prop(FLContextKey.TASK_RESULT, value=reply, private=True, sticky=False)\n\n        self.log_debug(fl_ctx, \"firing event EventType.AFTER_TASK_RESULT_FILTER\")\n        self.fire_event(EventType.AFTER_TASK_RESULT_FILTER, fl_ctx)\n        self.log_info(fl_ctx, \"finished processing task\")\n\n        if not isinstance(reply, Shareable):\n            self.log_error(\n                fl_ctx, \"task processing error: expects result to be Shareable, but got {}\".format(type(reply))\n            )\n            return make_reply(ReturnCode.EXECUTION_RESULT_ERROR)\n\n        return reply",
  "def _try_run(self):\n        task_fetch_interval = self.task_fetch_interval\n        while not self.asked_to_stop:\n            with self.engine.new_context() as fl_ctx:\n                if self.run_abort_signal.triggered:\n                    self.log_info(fl_ctx, \"run abort signal received\")\n                    break\n\n                time.sleep(task_fetch_interval)\n\n                if self.run_abort_signal.triggered:\n                    self.log_info(fl_ctx, \"run abort signal received\")\n                    break\n\n                # reset to default fetch interval\n                task_fetch_interval = self.task_fetch_interval\n                self.log_debug(fl_ctx, \"fetching task from server ...\")\n                task = self.engine.get_task_assignment(fl_ctx)\n                if not task:\n                    self.log_debug(fl_ctx, \"no task received - will try in {} secs\".format(task_fetch_interval))\n                    continue\n\n                if task.name == SpecialTaskName.END_RUN:\n                    self.log_info(fl_ctx, \"server asked to end the run\")\n                    break\n\n                if task.name == SpecialTaskName.TRY_AGAIN:\n                    task_data = task.data\n                    if task_data and isinstance(task_data, Shareable):\n                        task_fetch_interval = task_data.get(TaskConstant.WAIT_TIME, self.task_fetch_interval)\n                    self.log_debug(\n                        fl_ctx, \"server asked to try again - will try in {} secs\".format(task_fetch_interval)\n                    )\n                    continue\n\n                self.log_info(fl_ctx, \"got task assignment: name={}, id={}\".format(task.name, task.task_id))\n\n                # create a new task abort signal\n                task_reply = self._process_task(task, fl_ctx)\n\n                if not isinstance(task_reply, Shareable):\n                    raise TypeError(\"task_reply must be Shareable, but got {}\".format(type(task_reply)))\n                self.log_debug(fl_ctx, \"firing event EventType.BEFORE_SEND_TASK_RESULT\")\n                self.fire_event(EventType.BEFORE_SEND_TASK_RESULT, fl_ctx)\n\n                # set the cookie in the reply!\n                task_data = task.data\n                if not isinstance(task_data, Shareable):\n                    raise TypeError(\"task_data must be Shareable, but got {}\".format(type(task_data)))\n\n                cookie_jar = task_data.get_cookie_jar()\n                if cookie_jar:\n                    task_reply.set_cookie_jar(cookie_jar)\n\n                reply_sent = self.engine.send_task_result(task_reply, fl_ctx)\n                if reply_sent:\n                    self.log_info(\n                        fl_ctx, \"result sent to server for task: name={}, id={}\".format(task.name, task.task_id)\n                    )\n                else:\n                    self.log_error(\n                        fl_ctx,\n                        \"failed to send result to server for task: name={}, id={}\".format(task.name, task.task_id),\n                    )\n                self.log_debug(fl_ctx, \"firing event EventType.AFTER_SEND_TASK_RESULT\")\n                self.fire_event(EventType.AFTER_SEND_TASK_RESULT, fl_ctx)",
  "def run(self, app_root, args):\n        with self.engine.new_context() as fl_ctx:\n            self.fire_event(EventType.ABOUT_TO_START_RUN, fl_ctx)\n            fl_ctx.set_prop(FLContextKey.APP_ROOT, app_root, sticky=True)\n            fl_ctx.set_prop(FLContextKey.ARGS, args, sticky=True)\n            fl_ctx.set_prop(ReservedKey.RUN_ABORT_SIGNAL, self.run_abort_signal, private=True, sticky=True)\n            self.log_debug(fl_ctx, \"firing event EventType.START_RUN\")\n            self.fire_event(EventType.START_RUN, fl_ctx)\n            self.log_info(fl_ctx, \"client runner started\")\n        with self.end_run_lock:\n            self.end_run_fired = False\n\n        try:\n            self._try_run()\n        except BaseException as e:\n            with self.engine.new_context() as fl_ctx:\n                self.log_exception(fl_ctx, \"processing error in RUN execution: {}\".format(e))\n        finally:\n            # in case any task is still running, abort it\n            self._abort_current_task()\n\n            self.end_run_events_sequence(\"run method\")",
  "def _abort_current_task(self):\n        with self.task_lock:\n            task_abort_signal = self.task_abort_signal\n            if task_abort_signal:\n                # set task_abort_signal to None to prevent triggering again\n                self.task_abort_signal = None\n                task_name = \"\"\n                task_id = \"\"\n                task = self.current_task\n                if task:\n                    task_name = task.name\n                    task_id = task.task_id\n\n                with self.engine.new_context() as fl_ctx:\n                    fl_ctx.set_prop(FLContextKey.TASK_NAME, value=task_name, private=True, sticky=False)\n                    fl_ctx.set_prop(FLContextKey.TASK_ID, value=task_id, private=True, sticky=False)\n\n                    task_abort_signal.trigger(True)\n                    self.log_info(fl_ctx, \"triggered task_abort_signal to stop task '{}'\".format(task_name))\n\n                    self.fire_event(EventType.ABORT_TASK, fl_ctx)\n                    self.log_info(fl_ctx, \"fired ABORT_TASK event to abort current task {}\".format(task_name))",
  "def abort_task(self, task_names=None):\n        has_task_to_abort = False\n        with self.engine.new_context() as fl_ctx:\n            with self.task_lock:\n                if self.current_task:\n                    name = self.current_task.name\n                    if not task_names or name in task_names:\n                        has_task_to_abort = True\n                    else:\n                        self.log_info(\n                            fl_ctx, \"Ignored abort_task request since current task '{}' is not target\".format(name)\n                        )\n                else:\n                    self.log_info(fl_ctx, \"Ignored abort_task request since there is no current task\")\n\n        if has_task_to_abort:\n            self._abort_current_task()",
  "def end_run_events_sequence(self, requester):\n        with self.engine.new_context() as fl_ctx:\n            self.log_info(fl_ctx, f\"{requester} requests end run events sequence\")\n            with self.end_run_lock:\n                if not self.end_run_fired:\n                    self.fire_event(EventType.ABOUT_TO_END_RUN, fl_ctx)\n                    self.log_info(fl_ctx, \"ABOUT_TO_END_RUN fired\")\n                    self.fire_event(EventType.END_RUN, fl_ctx)\n                    self.log_info(fl_ctx, \"END_RUN fired\")\n                    self.end_run_fired = True",
  "def abort(self):\n        \"\"\"To Abort the current run.\n\n        Returns: N/A\n\n        \"\"\"\n        with self.engine.new_context() as fl_ctx:\n            self.log_info(fl_ctx, \"ABORT (RUN) command received\")\n        self._abort_current_task()\n        self.run_abort_signal.trigger(\"ABORT (RUN) triggered\")\n        self.asked_to_stop = True\n        self.end_run_events_sequence(\"ABORT (RUN)\")",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == InfoCollector.EVENT_TYPE_GET_STATS:\n            collector = fl_ctx.get_prop(InfoCollector.CTX_KEY_STATS_COLLECTOR)\n            if collector:\n                if not isinstance(collector, GroupInfoCollector):\n                    raise TypeError(\"collector must be GroupInfoCollector, but got {}\".format(type(collector)))\n                if self.current_task:\n                    current_task_name = self.current_task.name\n                else:\n                    current_task_name = \"None\"\n                collector.set_info(\n                    group_name=\"ClientRunner\",\n                    info={\"job_id\": self.job_id, \"current_task_name\": current_task_name, \"status\": \"started\"},\n                )\n        elif event_type == EventType.FATAL_TASK_ERROR:\n            reason = fl_ctx.get_prop(key=FLContextKey.EVENT_DATA, default=\"\")\n            self.log_error(fl_ctx, \"Aborting current task due to FATAL_TASK_ERROR received: {}\".format(reason))\n            self._abort_current_task()\n        elif event_type == EventType.FATAL_SYSTEM_ERROR:\n            reason = fl_ctx.get_prop(key=FLContextKey.EVENT_DATA, default=\"\")\n            self.log_error(fl_ctx, \"Aborting current RUN due to FATAL_SYSTEM_ERROR received: {}\".format(reason))\n            self.abort()",
  "def _handle_end_run(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        self.log_info(fl_ctx, \"received aux request from Server to end current RUN\")\n        self.abort()\n        return make_reply(ReturnCode.OK)",
  "def _handle_abort_task(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        self.log_info(fl_ctx, \"received aux request from Server to abort current task\")\n        task_names = request.get(\"task_names\", None)\n        self.abort_task(task_names)\n        return make_reply(ReturnCode.OK)",
  "class StartAppProcessor(RequestProcessor):\n    def get_topics(self) -> List[str]:\n        return [TrainingTopic.START]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        result = engine.start_app(job_id)\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "class AbortAppProcessor(RequestProcessor):\n    def get_topics(self) -> List[str]:\n        return [TrainingTopic.ABORT]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        result = engine.abort_app(job_id)\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "class AbortTaskProcessor(RequestProcessor):\n    def get_topics(self) -> List[str]:\n        return [TrainingTopic.ABORT_TASK]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        result = engine.abort_task(job_id)\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "class ShutdownClientProcessor(RequestProcessor):\n    def get_topics(self) -> List[str]:\n        return [TrainingTopic.SHUTDOWN]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        result = engine.shutdown()\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "class RestartClientProcessor(RequestProcessor):\n    def get_topics(self) -> List[str]:\n        return [TrainingTopic.RESTART]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        result = engine.restart()\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "class DeployProcessor(RequestProcessor):\n    def get_topics(self) -> List[str]:\n        return [TrainingTopic.DEPLOY]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        app_name = req.get_header(RequestHeader.APP_NAME)\n        client_name = engine.get_client_name()\n        result = engine.deploy_app(app_name=app_name, job_id=job_id, client_name=client_name, app_data=req.body)\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "class DeleteRunNumberProcessor(RequestProcessor):\n    def get_topics(self) -> List[str]:\n        return [TrainingTopic.DELETE_RUN]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        result = engine.delete_run(job_id)\n        if not result:\n            result = \"OK\"\n        message = Message(topic=\"reply_\" + req.topic, body=result)\n        return message",
  "class ClientStatusProcessor(RequestProcessor):\n    def get_topics(self) -> List[str]:\n        return [TrainingTopic.CHECK_STATUS]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        result = engine.get_engine_status()\n        # run_info = engine.get_current_run_info()\n        # if not run_info or run_info.job_id < 0:\n        #     result = {\n        #         ClientStatusKey.RUN_NUM: 'none',\n        #         ClientStatusKey.CURRENT_TASK: 'none'\n        #     }\n        # else:\n        #     result = {\n        #         ClientStatusKey.RUN_NUM: str(run_info.job_id),\n        #         ClientStatusKey.CURRENT_TASK: run_info.current_task_name\n        #     }\n        result = json.dumps(result)\n        message = Message(topic=\"reply_\" + req.topic, body=result)\n        return message",
  "def get_topics(self) -> List[str]:\n        return [TrainingTopic.START]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        result = engine.start_app(job_id)\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "def get_topics(self) -> List[str]:\n        return [TrainingTopic.ABORT]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        result = engine.abort_app(job_id)\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "def get_topics(self) -> List[str]:\n        return [TrainingTopic.ABORT_TASK]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        result = engine.abort_task(job_id)\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "def get_topics(self) -> List[str]:\n        return [TrainingTopic.SHUTDOWN]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        result = engine.shutdown()\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "def get_topics(self) -> List[str]:\n        return [TrainingTopic.RESTART]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        result = engine.restart()\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "def get_topics(self) -> List[str]:\n        return [TrainingTopic.DEPLOY]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        app_name = req.get_header(RequestHeader.APP_NAME)\n        client_name = engine.get_client_name()\n        result = engine.deploy_app(app_name=app_name, job_id=job_id, client_name=client_name, app_data=req.body)\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "def get_topics(self) -> List[str]:\n        return [TrainingTopic.DELETE_RUN]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        result = engine.delete_run(job_id)\n        if not result:\n            result = \"OK\"\n        message = Message(topic=\"reply_\" + req.topic, body=result)\n        return message",
  "def get_topics(self) -> List[str]:\n        return [TrainingTopic.CHECK_STATUS]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n        result = engine.get_engine_status()\n        # run_info = engine.get_current_run_info()\n        # if not run_info or run_info.job_id < 0:\n        #     result = {\n        #         ClientStatusKey.RUN_NUM: 'none',\n        #         ClientStatusKey.CURRENT_TASK: 'none'\n        #     }\n        # else:\n        #     result = {\n        #         ClientStatusKey.RUN_NUM: str(run_info.job_id),\n        #         ClientStatusKey.CURRENT_TASK: run_info.current_task_name\n        #     }\n        result = json.dumps(result)\n        message = Message(topic=\"reply_\" + req.topic, body=result)\n        return message",
  "class SysInfoProcessor(RequestProcessor):\n    def get_topics(self) -> [str]:\n        return [SysCommandTopic.SYS_INFO]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        infos = dict(psutil.virtual_memory()._asdict())\n        if pynvml:\n            try:\n                pynvml.nvmlInit()\n                device_count = pynvml.nvmlDeviceGetCount()\n                gpu_info = {\"gpu_count\": device_count}\n                for index in range(device_count):\n                    handle = pynvml.nvmlDeviceGetHandleByIndex(index)\n                    gpu_info[f\"gpu_device_{index}\"] = pynvml.nvmlDeviceGetName(handle).decode(\"utf-8\")\n                pynvml.nvmlShutdown()\n                infos.update(gpu_info)\n            except pynvml.nvml.NVMLError_LibraryNotFound:\n                pass\n\n        # docker_image_tag = os.environ.get('DOCKER_IMAGE_TAG', 'N/A')\n        # infos.update({'docker_image_tag':docker_image_tag})\n        message = Message(topic=\"reply_\" + req.topic, body=json.dumps(infos))\n        print(\"return sys_info\")\n        print(infos)\n        return message",
  "def get_topics(self) -> [str]:\n        return [SysCommandTopic.SYS_INFO]",
  "def process(self, req: Message, app_ctx) -> Message:\n        infos = dict(psutil.virtual_memory()._asdict())\n        if pynvml:\n            try:\n                pynvml.nvmlInit()\n                device_count = pynvml.nvmlDeviceGetCount()\n                gpu_info = {\"gpu_count\": device_count}\n                for index in range(device_count):\n                    handle = pynvml.nvmlDeviceGetHandleByIndex(index)\n                    gpu_info[f\"gpu_device_{index}\"] = pynvml.nvmlDeviceGetName(handle).decode(\"utf-8\")\n                pynvml.nvmlShutdown()\n                infos.update(gpu_info)\n            except pynvml.nvml.NVMLError_LibraryNotFound:\n                pass\n\n        # docker_image_tag = os.environ.get('DOCKER_IMAGE_TAG', 'N/A')\n        # infos.update({'docker_image_tag':docker_image_tag})\n        message = Message(topic=\"reply_\" + req.topic, body=json.dumps(infos))\n        print(\"return sys_info\")\n        print(infos)\n        return message",
  "class ClientExecutor(object):\n    def __init__(self, uid, startup) -> None:\n        \"\"\"To init the ClientExecutor.\n\n        Args:\n            uid: client name\n            startup: startup folder\n        \"\"\"\n        pipe_path = startup + \"/comm\"\n        if not os.path.exists(pipe_path):\n            os.makedirs(pipe_path)\n\n        self.pipe = FilePipe(root_path=pipe_path, name=\"training\")\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    def start_train(\n        self,\n        client,\n        job_id,\n        args,\n        app_root,\n        app_custom_folder,\n        listen_port,\n        allocated_resource,\n        token,\n        resource_consumer,\n        resource_manager,\n        target: str,\n    ):\n        \"\"\"start_train method to start the FL client training.\n\n        Args:\n            client: the FL client object\n            job_id: the job_id\n            args: admin command arguments for starting the FL client training\n            app_root: the root folder of the running APP\n            app_custom_folder: FL application custom folder\n            listen_port: port to listen the command.\n            allocated_resource: allocated resources\n            token: token from resource manager\n            resource_consumer: resource consumer\n            resource_manager: resource manager\n            target: SP target location\n\n        \"\"\"\n        pass\n\n    def check_status(self, client, job_id) -> str:\n        \"\"\"To check the status of the running client.\n\n        Args:\n            client: the FL client object\n            job_id: the job_id\n\n        Returns:\n            A client status message\n        \"\"\"\n        pass\n\n    def abort_train(self, client, job_id):\n        \"\"\"To abort the client training.\n\n        Args:\n            client: the FL client object\n            job_id: the job_id\n        \"\"\"\n        pass\n\n    def abort_task(self, client, job_id):\n        \"\"\"To abort the client executing task.\n\n        Args:\n            client: the FL client object\n            job_id: the job_id\n        \"\"\"\n        pass\n\n    def get_run_info(self, job_id) -> dict:\n        \"\"\"Get the run information.\n\n        Args:\n            job_id: the job_id\n\n        Returns:\n            A dict of run information.\n        \"\"\"\n        pass\n\n    def get_errors(self, job_id):\n        \"\"\"Get the error information.\n\n        Returns:\n            A dict of error information.\n\n        \"\"\"\n        pass\n\n    def reset_errors(self, job_id):\n        \"\"\"Reset the error information.\"\"\"\n        pass\n\n    def send_aux_command(self, shareable: Shareable, job_id):\n        \"\"\"To send the aux command to child process.\n\n        Args:\n            shareable: aux message Shareable\n            job_id: the job_id\n        \"\"\"\n        pass\n\n    def cleanup(self):\n        \"\"\"Cleanup.\"\"\"\n        self.pipe.clear()",
  "class ProcessExecutor(ClientExecutor):\n    \"\"\"Run the Client executor in a child process.\"\"\"\n\n    def __init__(self, uid, startup):\n        \"\"\"To init the ProcessExecutor.\n\n        Args:\n            uid: client name\n            startup: startup folder\n        \"\"\"\n        ClientExecutor.__init__(self, uid, startup)\n\n        self.startup = startup\n        self.run_processes = {}\n        self.lock = threading.Lock()\n\n    def get_conn_client(self, job_id):\n        # should be call within self.lock\n        listen_port = self.run_processes.get(job_id, {}).get(RunProcessKey.LISTEN_PORT)\n        conn_client = self.run_processes.get(job_id, {}).get(RunProcessKey.CONNECTION, None)\n\n        if not conn_client:\n            try:\n                address = (\"localhost\", listen_port)\n                conn_client = Client(address, authkey=\"client process secret password\".encode())\n                self.run_processes[job_id][RunProcessKey.CONNECTION] = conn_client\n            except Exception:\n                pass\n\n        return conn_client\n\n    def start_train(\n        self,\n        client,\n        job_id,\n        args,\n        app_root,\n        app_custom_folder,\n        listen_port,\n        allocated_resource,\n        token,\n        resource_consumer: ResourceConsumerSpec,\n        resource_manager: ResourceManagerSpec,\n        target: str,\n    ):\n        if allocated_resource:\n            resource_consumer.consume(allocated_resource)\n\n        new_env = os.environ.copy()\n        if app_custom_folder != \"\":\n            new_env[\"PYTHONPATH\"] = new_env.get(\"PYTHONPATH\", \"\") + os.pathsep + app_custom_folder\n\n        command_options = \"\"\n        for t in args.set:\n            command_options += \" \" + t\n        command = (\n            f\"{sys.executable} -m nvflare.private.fed.app.client.worker_process -m \"\n            + args.workspace\n            + \" -w \"\n            + self.startup\n            + \" -t \"\n            + client.token\n            + \" -d \"\n            + client.ssid\n            + \" -n \"\n            + job_id\n            + \" -c \"\n            + client.client_name\n            + \" -p \"\n            + str(listen_port)\n            + \" -g \"\n            + target\n            + \" -s fed_client.json \"\n            \" --set\" + command_options + \" print_conf=True\"\n        )\n        # use os.setsid to create new process group ID\n        process = subprocess.Popen(shlex.split(command, True), preexec_fn=os.setsid, env=new_env)\n\n        print(\"training child process ID: {}\".format(process.pid))\n\n        client.multi_gpu = False\n\n        with self.lock:\n            self.run_processes[job_id] = {\n                RunProcessKey.LISTEN_PORT: listen_port,\n                RunProcessKey.CONNECTION: None,\n                RunProcessKey.CHILD_PROCESS: process,\n                RunProcessKey.STATUS: ClientStatus.STARTED,\n            }\n\n        thread = threading.Thread(\n            target=self._wait_child_process_finish,\n            args=(client, job_id, allocated_resource, token, resource_manager),\n        )\n        thread.start()\n\n    def check_status(self, client, job_id):\n        try:\n            with self.lock:\n                conn_client = self.get_conn_client(job_id)\n\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.CHECK_STATUS, \"data\": {}}\n                    conn_client.send(data)\n                    status_message = conn_client.recv()\n                    self.logger.debug(\"check status from process listener......\")\n                    return status_message\n                else:\n                    process_status = ClientStatus.NOT_STARTED\n                    return get_status_message(process_status)\n        except Exception as e:\n            self.logger.error(f\"check_status execution exception: {e}.\", exc_info=True)\n            return \"execution exception. Please try again.\"\n\n    def get_run_info(self, job_id):\n        try:\n            with self.lock:\n                conn_client = self.get_conn_client(job_id)\n\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.SHOW_STATS, \"data\": {}}\n                    conn_client.send(data)\n                    run_info = conn_client.recv()\n                    return run_info\n                else:\n                    return {}\n        except Exception as e:\n            self.logger.error(f\"get_run_info execution exception: {e}.\", exc_info=True)\n            return {\"error\": \"no info collector. Please try again.\"}\n\n    def get_errors(self, job_id):\n        try:\n            with self.lock:\n                conn_client = self.get_conn_client(job_id)\n\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.SHOW_ERRORS, \"data\": {}}\n                    conn_client.send(data)\n                    errors_info = conn_client.recv()\n                    return errors_info\n                else:\n                    return None\n        except Exception as e:\n            self.logger.error(f\"get_errors execution exception: {e}.\", exc_info=True)\n            return None\n\n    def reset_errors(self, job_id):\n        try:\n            with self.lock:\n                conn_client = self.get_conn_client(job_id)\n\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.RESET_ERRORS, \"data\": {}}\n                    conn_client.send(data)\n        except Exception as e:\n            self.logger.error(f\"reset_errors execution exception: {e}.\", exc_info=True)\n\n    def send_aux_command(self, shareable: Shareable, job_id):\n        try:\n            with self.lock:\n                conn_client = self.get_conn_client(job_id)\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.AUX_COMMAND, \"data\": shareable}\n                    conn_client.send(data)\n                    reply = conn_client.recv()\n                    return reply\n                else:\n                    return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n        except Exception:\n            return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n\n    def abort_train(self, client, job_id):\n        with self.lock:\n            # When the HeartBeat cleanup process try to abort the train, the job maybe already terminated,\n            # Use retry to avoid print out the error stack trace.\n            retry = 1\n            while retry >= 0:\n                process_status = self.run_processes.get(job_id, {}).get(RunProcessKey.STATUS, ClientStatus.NOT_STARTED)\n                if process_status == ClientStatus.STARTED:\n                    try:\n                        child_process = self.run_processes[job_id][RunProcessKey.CHILD_PROCESS]\n                        conn_client = self.get_conn_client(job_id)\n                        if conn_client:\n                            data = {\"command\": AdminCommandNames.ABORT, \"data\": {}}\n                            conn_client.send(data)\n                            self.logger.debug(\"abort sent\")\n\n                        threading.Thread(target=self._terminate_process, args=[child_process, job_id]).start()\n                        self.run_processes.pop(job_id)\n                        break\n                    except Exception as e:\n                        if retry == 0:\n                            self.logger.error(f\"abort_train execution exception: {e} for run: {job_id}.\", exc_info=True)\n                        retry -= 1\n                        time.sleep(5.0)\n                    finally:\n                        if conn_client:\n                            conn_client.close()\n                        self.cleanup()\n                else:\n                    self.logger.info(f\"run: {job_id} already terminated.\")\n                    break\n\n        self.logger.info(\"Client training was terminated.\")\n\n    def _terminate_process(self, child_process, job_id):\n        # wait for client to handle abort\n        time.sleep(10.0)\n        # kill the sub-process group directly\n        try:\n            os.killpg(os.getpgid(child_process.pid), 9)\n            self.logger.debug(\"kill signal sent\")\n        except Exception:\n            pass\n        child_process.terminate()\n        self.logger.info(f\"run ({job_id}): child worker process terminated\")\n\n    def abort_task(self, client, job_id):\n        with self.lock:\n            process_status = self.run_processes.get(job_id, {}).get(RunProcessKey.STATUS, ClientStatus.NOT_STARTED)\n            if process_status == ClientStatus.STARTED:\n                conn_client = self.get_conn_client(job_id)\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.ABORT_TASK, \"data\": {}}\n                    conn_client.send(data)\n                    self.logger.debug(\"abort_task sent\")\n\n    def _wait_child_process_finish(self, client, job_id, allocated_resource, token, resource_manager):\n        # wait for the listen_command thread to start, and send \"start\" message to wake up the connection.\n        start = time.time()\n        while True:\n            with self.lock:\n                conn_client = self.get_conn_client(job_id)\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.START_APP, \"data\": {}}\n                    conn_client.send(data)\n                    break\n            time.sleep(1.0)\n            if time.time() - start > 15:\n                break\n\n        self.logger.info(f\"run ({job_id}): waiting for child worker process to finish.\")\n        with self.lock:\n            child_process = self.run_processes.get(job_id, {}).get(RunProcessKey.CHILD_PROCESS)\n        if child_process:\n            child_process.wait()\n            return_code = child_process.returncode\n            self.logger.info(f\"run ({job_id}): child worker process finished with execution code: {return_code}\")\n\n        if allocated_resource:\n            resource_manager.free_resources(\n                resources=allocated_resource, token=token, fl_ctx=client.engine.new_context()\n            )\n\n        with self.lock:\n            conn_client = self.get_conn_client(job_id)\n            if conn_client:\n                conn_client.close()\n            if job_id in self.run_processes.keys():\n                self.run_processes.pop(job_id)\n\n    def get_status(self, job_id):\n        with self.lock:\n            process_status = self.run_processes.get(job_id, {}).get(RunProcessKey.STATUS, ClientStatus.STOPPED)\n            return process_status\n\n    def get_run_processes_keys(self):\n        with self.lock:\n            return [x for x in self.run_processes.keys()]\n\n    def close(self):\n        self.cleanup()",
  "def __init__(self, uid, startup) -> None:\n        \"\"\"To init the ClientExecutor.\n\n        Args:\n            uid: client name\n            startup: startup folder\n        \"\"\"\n        pipe_path = startup + \"/comm\"\n        if not os.path.exists(pipe_path):\n            os.makedirs(pipe_path)\n\n        self.pipe = FilePipe(root_path=pipe_path, name=\"training\")\n        self.logger = logging.getLogger(self.__class__.__name__)",
  "def start_train(\n        self,\n        client,\n        job_id,\n        args,\n        app_root,\n        app_custom_folder,\n        listen_port,\n        allocated_resource,\n        token,\n        resource_consumer,\n        resource_manager,\n        target: str,\n    ):\n        \"\"\"start_train method to start the FL client training.\n\n        Args:\n            client: the FL client object\n            job_id: the job_id\n            args: admin command arguments for starting the FL client training\n            app_root: the root folder of the running APP\n            app_custom_folder: FL application custom folder\n            listen_port: port to listen the command.\n            allocated_resource: allocated resources\n            token: token from resource manager\n            resource_consumer: resource consumer\n            resource_manager: resource manager\n            target: SP target location\n\n        \"\"\"\n        pass",
  "def check_status(self, client, job_id) -> str:\n        \"\"\"To check the status of the running client.\n\n        Args:\n            client: the FL client object\n            job_id: the job_id\n\n        Returns:\n            A client status message\n        \"\"\"\n        pass",
  "def abort_train(self, client, job_id):\n        \"\"\"To abort the client training.\n\n        Args:\n            client: the FL client object\n            job_id: the job_id\n        \"\"\"\n        pass",
  "def abort_task(self, client, job_id):\n        \"\"\"To abort the client executing task.\n\n        Args:\n            client: the FL client object\n            job_id: the job_id\n        \"\"\"\n        pass",
  "def get_run_info(self, job_id) -> dict:\n        \"\"\"Get the run information.\n\n        Args:\n            job_id: the job_id\n\n        Returns:\n            A dict of run information.\n        \"\"\"\n        pass",
  "def get_errors(self, job_id):\n        \"\"\"Get the error information.\n\n        Returns:\n            A dict of error information.\n\n        \"\"\"\n        pass",
  "def reset_errors(self, job_id):\n        \"\"\"Reset the error information.\"\"\"\n        pass",
  "def send_aux_command(self, shareable: Shareable, job_id):\n        \"\"\"To send the aux command to child process.\n\n        Args:\n            shareable: aux message Shareable\n            job_id: the job_id\n        \"\"\"\n        pass",
  "def cleanup(self):\n        \"\"\"Cleanup.\"\"\"\n        self.pipe.clear()",
  "def __init__(self, uid, startup):\n        \"\"\"To init the ProcessExecutor.\n\n        Args:\n            uid: client name\n            startup: startup folder\n        \"\"\"\n        ClientExecutor.__init__(self, uid, startup)\n\n        self.startup = startup\n        self.run_processes = {}\n        self.lock = threading.Lock()",
  "def get_conn_client(self, job_id):\n        # should be call within self.lock\n        listen_port = self.run_processes.get(job_id, {}).get(RunProcessKey.LISTEN_PORT)\n        conn_client = self.run_processes.get(job_id, {}).get(RunProcessKey.CONNECTION, None)\n\n        if not conn_client:\n            try:\n                address = (\"localhost\", listen_port)\n                conn_client = Client(address, authkey=\"client process secret password\".encode())\n                self.run_processes[job_id][RunProcessKey.CONNECTION] = conn_client\n            except Exception:\n                pass\n\n        return conn_client",
  "def start_train(\n        self,\n        client,\n        job_id,\n        args,\n        app_root,\n        app_custom_folder,\n        listen_port,\n        allocated_resource,\n        token,\n        resource_consumer: ResourceConsumerSpec,\n        resource_manager: ResourceManagerSpec,\n        target: str,\n    ):\n        if allocated_resource:\n            resource_consumer.consume(allocated_resource)\n\n        new_env = os.environ.copy()\n        if app_custom_folder != \"\":\n            new_env[\"PYTHONPATH\"] = new_env.get(\"PYTHONPATH\", \"\") + os.pathsep + app_custom_folder\n\n        command_options = \"\"\n        for t in args.set:\n            command_options += \" \" + t\n        command = (\n            f\"{sys.executable} -m nvflare.private.fed.app.client.worker_process -m \"\n            + args.workspace\n            + \" -w \"\n            + self.startup\n            + \" -t \"\n            + client.token\n            + \" -d \"\n            + client.ssid\n            + \" -n \"\n            + job_id\n            + \" -c \"\n            + client.client_name\n            + \" -p \"\n            + str(listen_port)\n            + \" -g \"\n            + target\n            + \" -s fed_client.json \"\n            \" --set\" + command_options + \" print_conf=True\"\n        )\n        # use os.setsid to create new process group ID\n        process = subprocess.Popen(shlex.split(command, True), preexec_fn=os.setsid, env=new_env)\n\n        print(\"training child process ID: {}\".format(process.pid))\n\n        client.multi_gpu = False\n\n        with self.lock:\n            self.run_processes[job_id] = {\n                RunProcessKey.LISTEN_PORT: listen_port,\n                RunProcessKey.CONNECTION: None,\n                RunProcessKey.CHILD_PROCESS: process,\n                RunProcessKey.STATUS: ClientStatus.STARTED,\n            }\n\n        thread = threading.Thread(\n            target=self._wait_child_process_finish,\n            args=(client, job_id, allocated_resource, token, resource_manager),\n        )\n        thread.start()",
  "def check_status(self, client, job_id):\n        try:\n            with self.lock:\n                conn_client = self.get_conn_client(job_id)\n\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.CHECK_STATUS, \"data\": {}}\n                    conn_client.send(data)\n                    status_message = conn_client.recv()\n                    self.logger.debug(\"check status from process listener......\")\n                    return status_message\n                else:\n                    process_status = ClientStatus.NOT_STARTED\n                    return get_status_message(process_status)\n        except Exception as e:\n            self.logger.error(f\"check_status execution exception: {e}.\", exc_info=True)\n            return \"execution exception. Please try again.\"",
  "def get_run_info(self, job_id):\n        try:\n            with self.lock:\n                conn_client = self.get_conn_client(job_id)\n\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.SHOW_STATS, \"data\": {}}\n                    conn_client.send(data)\n                    run_info = conn_client.recv()\n                    return run_info\n                else:\n                    return {}\n        except Exception as e:\n            self.logger.error(f\"get_run_info execution exception: {e}.\", exc_info=True)\n            return {\"error\": \"no info collector. Please try again.\"}",
  "def get_errors(self, job_id):\n        try:\n            with self.lock:\n                conn_client = self.get_conn_client(job_id)\n\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.SHOW_ERRORS, \"data\": {}}\n                    conn_client.send(data)\n                    errors_info = conn_client.recv()\n                    return errors_info\n                else:\n                    return None\n        except Exception as e:\n            self.logger.error(f\"get_errors execution exception: {e}.\", exc_info=True)\n            return None",
  "def reset_errors(self, job_id):\n        try:\n            with self.lock:\n                conn_client = self.get_conn_client(job_id)\n\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.RESET_ERRORS, \"data\": {}}\n                    conn_client.send(data)\n        except Exception as e:\n            self.logger.error(f\"reset_errors execution exception: {e}.\", exc_info=True)",
  "def send_aux_command(self, shareable: Shareable, job_id):\n        try:\n            with self.lock:\n                conn_client = self.get_conn_client(job_id)\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.AUX_COMMAND, \"data\": shareable}\n                    conn_client.send(data)\n                    reply = conn_client.recv()\n                    return reply\n                else:\n                    return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n        except Exception:\n            return make_reply(ReturnCode.EXECUTION_EXCEPTION)",
  "def abort_train(self, client, job_id):\n        with self.lock:\n            # When the HeartBeat cleanup process try to abort the train, the job maybe already terminated,\n            # Use retry to avoid print out the error stack trace.\n            retry = 1\n            while retry >= 0:\n                process_status = self.run_processes.get(job_id, {}).get(RunProcessKey.STATUS, ClientStatus.NOT_STARTED)\n                if process_status == ClientStatus.STARTED:\n                    try:\n                        child_process = self.run_processes[job_id][RunProcessKey.CHILD_PROCESS]\n                        conn_client = self.get_conn_client(job_id)\n                        if conn_client:\n                            data = {\"command\": AdminCommandNames.ABORT, \"data\": {}}\n                            conn_client.send(data)\n                            self.logger.debug(\"abort sent\")\n\n                        threading.Thread(target=self._terminate_process, args=[child_process, job_id]).start()\n                        self.run_processes.pop(job_id)\n                        break\n                    except Exception as e:\n                        if retry == 0:\n                            self.logger.error(f\"abort_train execution exception: {e} for run: {job_id}.\", exc_info=True)\n                        retry -= 1\n                        time.sleep(5.0)\n                    finally:\n                        if conn_client:\n                            conn_client.close()\n                        self.cleanup()\n                else:\n                    self.logger.info(f\"run: {job_id} already terminated.\")\n                    break\n\n        self.logger.info(\"Client training was terminated.\")",
  "def _terminate_process(self, child_process, job_id):\n        # wait for client to handle abort\n        time.sleep(10.0)\n        # kill the sub-process group directly\n        try:\n            os.killpg(os.getpgid(child_process.pid), 9)\n            self.logger.debug(\"kill signal sent\")\n        except Exception:\n            pass\n        child_process.terminate()\n        self.logger.info(f\"run ({job_id}): child worker process terminated\")",
  "def abort_task(self, client, job_id):\n        with self.lock:\n            process_status = self.run_processes.get(job_id, {}).get(RunProcessKey.STATUS, ClientStatus.NOT_STARTED)\n            if process_status == ClientStatus.STARTED:\n                conn_client = self.get_conn_client(job_id)\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.ABORT_TASK, \"data\": {}}\n                    conn_client.send(data)\n                    self.logger.debug(\"abort_task sent\")",
  "def _wait_child_process_finish(self, client, job_id, allocated_resource, token, resource_manager):\n        # wait for the listen_command thread to start, and send \"start\" message to wake up the connection.\n        start = time.time()\n        while True:\n            with self.lock:\n                conn_client = self.get_conn_client(job_id)\n                if conn_client:\n                    data = {\"command\": AdminCommandNames.START_APP, \"data\": {}}\n                    conn_client.send(data)\n                    break\n            time.sleep(1.0)\n            if time.time() - start > 15:\n                break\n\n        self.logger.info(f\"run ({job_id}): waiting for child worker process to finish.\")\n        with self.lock:\n            child_process = self.run_processes.get(job_id, {}).get(RunProcessKey.CHILD_PROCESS)\n        if child_process:\n            child_process.wait()\n            return_code = child_process.returncode\n            self.logger.info(f\"run ({job_id}): child worker process finished with execution code: {return_code}\")\n\n        if allocated_resource:\n            resource_manager.free_resources(\n                resources=allocated_resource, token=token, fl_ctx=client.engine.new_context()\n            )\n\n        with self.lock:\n            conn_client = self.get_conn_client(job_id)\n            if conn_client:\n                conn_client.close()\n            if job_id in self.run_processes.keys():\n                self.run_processes.pop(job_id)",
  "def get_status(self, job_id):\n        with self.lock:\n            process_status = self.run_processes.get(job_id, {}).get(RunProcessKey.STATUS, ClientStatus.STOPPED)\n            return process_status",
  "def get_run_processes_keys(self):\n        with self.lock:\n            return [x for x in self.run_processes.keys()]",
  "def close(self):\n        self.cleanup()",
  "class _ExecutorDef(object):\n    def __init__(self):\n        self.tasks = []\n        self.executor = None",
  "class ClientJsonConfigurator(FedJsonConfigurator):\n    def __init__(self, config_file_name: str, exclude_libs=True):\n        \"\"\"To init the ClientJsonConfigurator.\n\n        Args:\n            config_file_name: config file name\n            exclude_libs: True/False to exclude the libs folder\n        \"\"\"\n        base_pkgs = FL_PACKAGES\n        module_names = FL_MODULES\n\n        FedJsonConfigurator.__init__(\n            self,\n            config_file_name=config_file_name,\n            base_pkgs=base_pkgs,\n            module_names=module_names,\n            exclude_libs=exclude_libs,\n        )\n\n        self.runner_config = None\n        self.executors = []\n        self.current_exe = None\n\n    def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        FedJsonConfigurator.process_config_element(self, config_ctx, node)\n\n        element = node.element\n        path = node.path()\n\n        # executors\n        if re.search(r\"^executors\\.#[0-9]+$\", path):\n            self.current_exe = _ExecutorDef()\n            node.props[\"data\"] = self.current_exe\n            node.exit_cb = self._process_executor_def\n            return\n\n        if re.search(r\"^executors\\.#[0-9]+\\.tasks$\", path):\n            self.current_exe.tasks = element\n            return\n\n        if re.search(r\"^executors\\.#[0-9]+\\.executor$\", path):\n            self.current_exe.executor = self.build_component(element)\n            return\n\n    def build_component(self, config_dict):\n        t = super().build_component(config_dict)\n        if isinstance(t, FLComponent):\n            if type(t).__name__ not in [type(h).__name__ for h in self.handlers]:\n                self.handlers.append(t)\n        return t\n\n    def _process_executor_def(self, node: Node):\n        e = node.props[\"data\"]\n        if not isinstance(e, _ExecutorDef):\n            raise TypeError(\"e must be _ExecutorDef but got {}\".format(type(e)))\n        self.validate_tasks(e.tasks)\n\n        if not isinstance(e.executor, Executor):\n            raise ConfigError('\"executor\" must be an Executor object but got {}'.format(type(e.executor)))\n\n        self.executors.append(e)\n\n    def finalize_config(self, config_ctx: ConfigContext):\n        FedJsonConfigurator.finalize_config(self, config_ctx)\n\n        if len(self.executors) <= 0:\n            raise ConfigError(\"executors are not specified\")\n\n        task_table = {}\n        for e in self.executors:\n            for t in e.tasks:\n                if t in task_table:\n                    raise ConfigError('Multiple executors defined for task \"{}\"'.format(t))\n                task_table[t] = e.executor\n\n        self.runner_config = ClientRunnerConfig(\n            task_table=task_table,\n            task_data_filters=self.data_filter_table,\n            task_result_filters=self.result_filter_table,\n            components=self.components,\n            handlers=self.handlers,\n        )",
  "def __init__(self):\n        self.tasks = []\n        self.executor = None",
  "def __init__(self, config_file_name: str, exclude_libs=True):\n        \"\"\"To init the ClientJsonConfigurator.\n\n        Args:\n            config_file_name: config file name\n            exclude_libs: True/False to exclude the libs folder\n        \"\"\"\n        base_pkgs = FL_PACKAGES\n        module_names = FL_MODULES\n\n        FedJsonConfigurator.__init__(\n            self,\n            config_file_name=config_file_name,\n            base_pkgs=base_pkgs,\n            module_names=module_names,\n            exclude_libs=exclude_libs,\n        )\n\n        self.runner_config = None\n        self.executors = []\n        self.current_exe = None",
  "def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        FedJsonConfigurator.process_config_element(self, config_ctx, node)\n\n        element = node.element\n        path = node.path()\n\n        # executors\n        if re.search(r\"^executors\\.#[0-9]+$\", path):\n            self.current_exe = _ExecutorDef()\n            node.props[\"data\"] = self.current_exe\n            node.exit_cb = self._process_executor_def\n            return\n\n        if re.search(r\"^executors\\.#[0-9]+\\.tasks$\", path):\n            self.current_exe.tasks = element\n            return\n\n        if re.search(r\"^executors\\.#[0-9]+\\.executor$\", path):\n            self.current_exe.executor = self.build_component(element)\n            return",
  "def build_component(self, config_dict):\n        t = super().build_component(config_dict)\n        if isinstance(t, FLComponent):\n            if type(t).__name__ not in [type(h).__name__ for h in self.handlers]:\n                self.handlers.append(t)\n        return t",
  "def _process_executor_def(self, node: Node):\n        e = node.props[\"data\"]\n        if not isinstance(e, _ExecutorDef):\n            raise TypeError(\"e must be _ExecutorDef but got {}\".format(type(e)))\n        self.validate_tasks(e.tasks)\n\n        if not isinstance(e.executor, Executor):\n            raise ConfigError('\"executor\" must be an Executor object but got {}'.format(type(e.executor)))\n\n        self.executors.append(e)",
  "def finalize_config(self, config_ctx: ConfigContext):\n        FedJsonConfigurator.finalize_config(self, config_ctx)\n\n        if len(self.executors) <= 0:\n            raise ConfigError(\"executors are not specified\")\n\n        task_table = {}\n        for e in self.executors:\n            for t in e.tasks:\n                if t in task_table:\n                    raise ConfigError('Multiple executors defined for task \"{}\"'.format(t))\n                task_table[t] = e.executor\n\n        self.runner_config = ClientRunnerConfig(\n            task_table=task_table,\n            task_data_filters=self.data_filter_table,\n            task_result_filters=self.result_filter_table,\n            components=self.components,\n            handlers=self.handlers,\n        )",
  "class FederatedClient(FederatedClientBase):\n    \"\"\"Federated client-side implementation.\"\"\"\n\n    def __init__(\n        self,\n        client_name,\n        client_args,\n        secure_train,\n        server_args=None,\n        retry_timeout=30,\n        client_state_processors: Optional[List[Filter]] = None,\n        handlers: Optional[List[FLComponent]] = None,\n        executors: Optional[List[Executor]] = None,\n        compression=None,\n        enable_byoc=False,\n        overseer_agent=None,\n        args=None,\n        components=None,\n    ):\n        \"\"\"To init FederatedClient.\n\n        Args:\n            client_name: client name\n            client_args: client config args\n            secure_train: True/False to indicate secure train\n            server_args: server config args\n            retry_timeout: retry timeout seconds\n            client_state_processors: Client state processor filters\n            handlers: handlers\n            executors: executors\n            compression: communication compression algorithm\n            enable_byoc: True/False to allow byoc\n        \"\"\"\n        # We call the base implementation directly.\n        super().__init__(\n            client_name=client_name,\n            client_args=client_args,\n            secure_train=secure_train,\n            server_args=server_args,\n            retry_timeout=retry_timeout,\n            client_state_processors=client_state_processors,\n            handlers=handlers,\n            compression=compression,\n            overseer_agent=overseer_agent,\n            args=args,\n            components=components,\n        )\n\n        self.executors = executors\n        self.enable_byoc = enable_byoc\n\n    def fetch_task(self, fl_ctx: FLContext):\n        fire_event(EventType.BEFORE_PULL_TASK, self.handlers, fl_ctx)\n\n        pull_success, task_name, remote_tasks = self.pull_task(fl_ctx)\n        fire_event(EventType.AFTER_PULL_TASK, self.handlers, fl_ctx)\n        if task_name == SpecialTaskName.TRY_AGAIN:\n            self.logger.debug(f\"pull_task completed. Task name:{task_name} Status:{pull_success} \")\n        else:\n            self.logger.info(f\"pull_task completed. Task name:{task_name} Status:{pull_success} \")\n        return pull_success, task_name, remote_tasks\n\n    def extract_shareable(self, responses, fl_ctx: FLContext):\n        shareable = Shareable()\n        peer_context = FLContext()\n        for item in responses:\n            shareable = shareable.from_bytes(proto_to_bytes(item.data.params[\"data\"]))\n            peer_context = pickle.loads(proto_to_bytes(item.data.params[\"fl_context\"]))\n\n        fl_ctx.set_peer_context(peer_context)\n        shareable.set_peer_props(peer_context.get_all_public_props())\n\n        return shareable",
  "def __init__(\n        self,\n        client_name,\n        client_args,\n        secure_train,\n        server_args=None,\n        retry_timeout=30,\n        client_state_processors: Optional[List[Filter]] = None,\n        handlers: Optional[List[FLComponent]] = None,\n        executors: Optional[List[Executor]] = None,\n        compression=None,\n        enable_byoc=False,\n        overseer_agent=None,\n        args=None,\n        components=None,\n    ):\n        \"\"\"To init FederatedClient.\n\n        Args:\n            client_name: client name\n            client_args: client config args\n            secure_train: True/False to indicate secure train\n            server_args: server config args\n            retry_timeout: retry timeout seconds\n            client_state_processors: Client state processor filters\n            handlers: handlers\n            executors: executors\n            compression: communication compression algorithm\n            enable_byoc: True/False to allow byoc\n        \"\"\"\n        # We call the base implementation directly.\n        super().__init__(\n            client_name=client_name,\n            client_args=client_args,\n            secure_train=secure_train,\n            server_args=server_args,\n            retry_timeout=retry_timeout,\n            client_state_processors=client_state_processors,\n            handlers=handlers,\n            compression=compression,\n            overseer_agent=overseer_agent,\n            args=args,\n            components=components,\n        )\n\n        self.executors = executors\n        self.enable_byoc = enable_byoc",
  "def fetch_task(self, fl_ctx: FLContext):\n        fire_event(EventType.BEFORE_PULL_TASK, self.handlers, fl_ctx)\n\n        pull_success, task_name, remote_tasks = self.pull_task(fl_ctx)\n        fire_event(EventType.AFTER_PULL_TASK, self.handlers, fl_ctx)\n        if task_name == SpecialTaskName.TRY_AGAIN:\n            self.logger.debug(f\"pull_task completed. Task name:{task_name} Status:{pull_success} \")\n        else:\n            self.logger.info(f\"pull_task completed. Task name:{task_name} Status:{pull_success} \")\n        return pull_success, task_name, remote_tasks",
  "def extract_shareable(self, responses, fl_ctx: FLContext):\n        shareable = Shareable()\n        peer_context = FLContext()\n        for item in responses:\n            shareable = shareable.from_bytes(proto_to_bytes(item.data.params[\"data\"]))\n            peer_context = pickle.loads(proto_to_bytes(item.data.params[\"fl_context\"]))\n\n        fl_ctx.set_peer_context(peer_context)\n        shareable.set_peer_props(peer_context.get_all_public_props())\n\n        return shareable",
  "class ClientEngineExecutorSpec(ClientEngineSpec, ABC):\n    \"\"\"The ClientEngineExecutorSpec defines the ClientEngine APIs running in the child process.\"\"\"\n\n    @abstractmethod\n    def register_aux_message_handler(self, topic: str, message_handle_func):\n        \"\"\"Register aux message handling function with specified topics.\n\n        Exception is raised when:\n            a handler is already registered for the topic;\n            bad topic - must be a non-empty string\n            bad message_handle_func - must be callable\n\n        Implementation Note:\n        This method should simply call the ClientAuxRunner's register_aux_message_handler method.\n\n        Args:\n            topic: the topic to be handled by the func\n            message_handle_func: the func to handle the message. Must follow aux_message_handle_func_signature.\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def send_aux_request(self, topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Send a request to Server via the aux channel.\n\n        Implementation: simply calls the ClientAuxRunner's send_aux_request method.\n\n        Args:\n            topic: topic of the request\n            request: request to be sent\n            timeout: number of secs to wait for replies. 0 means fire-and-forget.\n            fl_ctx: FL context\n\n        Returns: a reply Shareable\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def fire_and_forget_aux_request(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Send an async request to Server via the aux channel.\n\n        Args:\n            topic: topic of the request\n            request: request to be sent\n            fl_ctx: FL context\n\n        Returns:\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def aux_send(self, topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Send the request to the Server.\n\n        If reply is received, make sure to set peer_ctx into the reply shareable!\n\n        Args:\n            topic: topic of the request\n            request: request Shareable to be sent\n            timeout: number of secs to wait for reply. 0 means fire-and-forget.\n            fl_ctx: fl context\n\n        Returns: a reply.\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def build_component(self, config_dict):\n        \"\"\"Build a component from the config_dict.\n\n        Args:\n            config_dict: config dict\n\n        \"\"\"\n\n    @abstractmethod\n    def abort_app(self, job_id: str, fl_ctx: FLContext):\n        \"\"\"Abort the running FL App on the client.\n\n        Args:\n            job_id: current_job_id\n            fl_ctx: FLContext\n\n        \"\"\"\n        pass",
  "def register_aux_message_handler(self, topic: str, message_handle_func):\n        \"\"\"Register aux message handling function with specified topics.\n\n        Exception is raised when:\n            a handler is already registered for the topic;\n            bad topic - must be a non-empty string\n            bad message_handle_func - must be callable\n\n        Implementation Note:\n        This method should simply call the ClientAuxRunner's register_aux_message_handler method.\n\n        Args:\n            topic: the topic to be handled by the func\n            message_handle_func: the func to handle the message. Must follow aux_message_handle_func_signature.\n\n        \"\"\"\n        pass",
  "def send_aux_request(self, topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Send a request to Server via the aux channel.\n\n        Implementation: simply calls the ClientAuxRunner's send_aux_request method.\n\n        Args:\n            topic: topic of the request\n            request: request to be sent\n            timeout: number of secs to wait for replies. 0 means fire-and-forget.\n            fl_ctx: FL context\n\n        Returns: a reply Shareable\n\n        \"\"\"\n        pass",
  "def fire_and_forget_aux_request(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Send an async request to Server via the aux channel.\n\n        Args:\n            topic: topic of the request\n            request: request to be sent\n            fl_ctx: FL context\n\n        Returns:\n\n        \"\"\"\n        pass",
  "def aux_send(self, topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Send the request to the Server.\n\n        If reply is received, make sure to set peer_ctx into the reply shareable!\n\n        Args:\n            topic: topic of the request\n            request: request Shareable to be sent\n            timeout: number of secs to wait for reply. 0 means fire-and-forget.\n            fl_ctx: fl context\n\n        Returns: a reply.\n\n        \"\"\"\n        pass",
  "def build_component(self, config_dict):\n        \"\"\"Build a component from the config_dict.\n\n        Args:\n            config_dict: config dict\n\n        \"\"\"",
  "def abort_app(self, job_id: str, fl_ctx: FLContext):\n        \"\"\"Abort the running FL App on the client.\n\n        Args:\n            job_id: current_job_id\n            fl_ctx: FLContext\n\n        \"\"\"\n        pass",
  "class AdminMessageSender(Sender):\n    \"\"\"AdminMessageSender to send the request message to the admin server.\"\"\"\n\n    def __init__(\n        self,\n        client_name,\n        root_cert=None,\n        ssl_cert=None,\n        private_key=None,\n        server_args=None,\n        secure=False,\n        is_multi_gpu=False,\n        rank=0,\n    ):\n        \"\"\"To init the AdminMessageSender.\n\n        Args:\n            client_name: client name\n            root_cert: root certificate\n            ssl_cert: SSL certificate\n            private_key: private key\n            server_args: server args\n            secure: True/False\n            is_multi_gpu: True/False\n            rank: local process rank\n        \"\"\"\n        self.client_name = client_name\n        self.root_cert = root_cert\n        self.ssl_cert = ssl_cert\n        self.private_key = private_key\n        self.secure = secure\n        self.servers = server_args\n        self.multi_gpu = is_multi_gpu\n        self.rank = rank\n\n        self.pool = ThreadPool(len(self.servers))\n\n    def send_reply(self, message: Message):\n        \"\"\"Call to send the request message.\n\n        Args:\n            message: request message\n\n        \"\"\"\n        if self.rank == 0:\n            # self.send_client_reply(message)\n            for taskname in tuple(self.servers):\n                self._send_client_reply(message, taskname)\n\n    def _send_client_reply(self, message, taskname):\n        try:\n            with self._set_up_channel(self.servers[taskname]) as channel:\n                stub = admin_service.AdminCommunicatingStub(channel)\n\n                reply = admin_msg.Reply()\n                reply.client_name = self.client_name\n                reply.message.CopyFrom(message_to_proto(message))\n                # reply.message = message_to_proto(message)\n                stub.SendReply(reply)\n        except BaseException:\n            pass\n\n    def retrieve_requests(self) -> [Message]:\n        \"\"\"Send the message to retrieve pending requests from the Server.\n\n        Returns: list of messages.\n\n        \"\"\"\n        messages = []\n        if self.rank == 0:\n            items = self.pool.map(self._retrieve_client_requests, tuple(self.servers))\n            for item in items:\n                messages.extend(item)\n\n        return messages\n\n    def _retrieve_client_requests(self, taskname):\n        try:\n            message_list = []\n            with self._set_up_channel(self.servers[taskname]) as channel:\n                stub = admin_service.AdminCommunicatingStub(channel)\n\n                client = admin_msg.Client()\n                client.client_name = self.client_name\n                messages = stub.Retrieve(client)\n                for i in messages.message:\n                    message_list.append(proto_to_message(i))\n        except Exception as e:\n            messages = None\n        return message_list\n\n    def send_result(self, message: Message):\n        \"\"\"Send the processor results to server.\n\n        Args:\n            message: message\n\n        \"\"\"\n        if self.rank == 0:\n            for taskname in tuple(self.servers):\n                try:\n                    with self._set_up_channel(self.servers[taskname]) as channel:\n                        stub = admin_service.AdminCommunicatingStub(channel)\n\n                        reply = admin_msg.Reply()\n                        reply.client_name = self.client_name\n                        reply.message.CopyFrom(message_to_proto(message))\n                        stub.SendResult(reply)\n                except BaseException:\n                    pass\n\n    def _set_up_channel(self, channel_dict):\n        \"\"\"Connect client to the server.\n\n        Args:\n            channel_dict: grpc channel parameters\n\n        Returns: an initialised grpc channel\n\n        \"\"\"\n        if self.secure:\n            with open(self.root_cert, \"rb\") as f:\n                trusted_certs = f.read()\n            with open(self.private_key, \"rb\") as f:\n                private_key = f.read()\n            with open(self.ssl_cert, \"rb\") as f:\n                certificate_chain = f.read()\n\n            call_credentials = grpc.metadata_call_credentials(\n                lambda context, callback: callback(((\"x-custom-token\", self.client_name),), None)\n            )\n            credentials = grpc.ssl_channel_credentials(\n                certificate_chain=certificate_chain, private_key=private_key, root_certificates=trusted_certs\n            )\n\n            composite_credentials = grpc.composite_channel_credentials(credentials, call_credentials)\n            channel = grpc.secure_channel(**channel_dict, credentials=composite_credentials)\n        else:\n            channel = grpc.insecure_channel(**channel_dict)\n        return channel\n\n    def close(self):\n        self.pool.close()",
  "def __init__(\n        self,\n        client_name,\n        root_cert=None,\n        ssl_cert=None,\n        private_key=None,\n        server_args=None,\n        secure=False,\n        is_multi_gpu=False,\n        rank=0,\n    ):\n        \"\"\"To init the AdminMessageSender.\n\n        Args:\n            client_name: client name\n            root_cert: root certificate\n            ssl_cert: SSL certificate\n            private_key: private key\n            server_args: server args\n            secure: True/False\n            is_multi_gpu: True/False\n            rank: local process rank\n        \"\"\"\n        self.client_name = client_name\n        self.root_cert = root_cert\n        self.ssl_cert = ssl_cert\n        self.private_key = private_key\n        self.secure = secure\n        self.servers = server_args\n        self.multi_gpu = is_multi_gpu\n        self.rank = rank\n\n        self.pool = ThreadPool(len(self.servers))",
  "def send_reply(self, message: Message):\n        \"\"\"Call to send the request message.\n\n        Args:\n            message: request message\n\n        \"\"\"\n        if self.rank == 0:\n            # self.send_client_reply(message)\n            for taskname in tuple(self.servers):\n                self._send_client_reply(message, taskname)",
  "def _send_client_reply(self, message, taskname):\n        try:\n            with self._set_up_channel(self.servers[taskname]) as channel:\n                stub = admin_service.AdminCommunicatingStub(channel)\n\n                reply = admin_msg.Reply()\n                reply.client_name = self.client_name\n                reply.message.CopyFrom(message_to_proto(message))\n                # reply.message = message_to_proto(message)\n                stub.SendReply(reply)\n        except BaseException:\n            pass",
  "def retrieve_requests(self) -> [Message]:\n        \"\"\"Send the message to retrieve pending requests from the Server.\n\n        Returns: list of messages.\n\n        \"\"\"\n        messages = []\n        if self.rank == 0:\n            items = self.pool.map(self._retrieve_client_requests, tuple(self.servers))\n            for item in items:\n                messages.extend(item)\n\n        return messages",
  "def _retrieve_client_requests(self, taskname):\n        try:\n            message_list = []\n            with self._set_up_channel(self.servers[taskname]) as channel:\n                stub = admin_service.AdminCommunicatingStub(channel)\n\n                client = admin_msg.Client()\n                client.client_name = self.client_name\n                messages = stub.Retrieve(client)\n                for i in messages.message:\n                    message_list.append(proto_to_message(i))\n        except Exception as e:\n            messages = None\n        return message_list",
  "def send_result(self, message: Message):\n        \"\"\"Send the processor results to server.\n\n        Args:\n            message: message\n\n        \"\"\"\n        if self.rank == 0:\n            for taskname in tuple(self.servers):\n                try:\n                    with self._set_up_channel(self.servers[taskname]) as channel:\n                        stub = admin_service.AdminCommunicatingStub(channel)\n\n                        reply = admin_msg.Reply()\n                        reply.client_name = self.client_name\n                        reply.message.CopyFrom(message_to_proto(message))\n                        stub.SendResult(reply)\n                except BaseException:\n                    pass",
  "def _set_up_channel(self, channel_dict):\n        \"\"\"Connect client to the server.\n\n        Args:\n            channel_dict: grpc channel parameters\n\n        Returns: an initialised grpc channel\n\n        \"\"\"\n        if self.secure:\n            with open(self.root_cert, \"rb\") as f:\n                trusted_certs = f.read()\n            with open(self.private_key, \"rb\") as f:\n                private_key = f.read()\n            with open(self.ssl_cert, \"rb\") as f:\n                certificate_chain = f.read()\n\n            call_credentials = grpc.metadata_call_credentials(\n                lambda context, callback: callback(((\"x-custom-token\", self.client_name),), None)\n            )\n            credentials = grpc.ssl_channel_credentials(\n                certificate_chain=certificate_chain, private_key=private_key, root_certificates=trusted_certs\n            )\n\n            composite_credentials = grpc.composite_channel_credentials(credentials, call_credentials)\n            channel = grpc.secure_channel(**channel_dict, credentials=composite_credentials)\n        else:\n            channel = grpc.insecure_channel(**channel_dict)\n        return channel",
  "def close(self):\n        self.pool.close()",
  "class CheckResourceProcessor(RequestProcessor):\n    def get_topics(self) -> List[str]:\n        return [TrainingTopic.CHECK_RESOURCE]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n\n        resource_manager = engine.get_component(SystemComponents.RESOURCE_MANAGER)\n        if not isinstance(resource_manager, ResourceManagerSpec):\n            raise RuntimeError(\n                f\"resource_manager should be of type ResourceManagerSpec, but got {type(resource_manager)}.\"\n            )\n        with engine.new_context() as fl_ctx:\n            result = Shareable()\n            try:\n                resource_spec = pickle.loads(req.body)\n                check_result, token = resource_manager.check_resources(\n                    resource_requirement=resource_spec, fl_ctx=fl_ctx\n                )\n                result.set_header(ShareableHeader.CHECK_RESOURCE_RESULT, check_result)\n                result.set_header(ShareableHeader.RESOURCE_RESERVE_TOKEN, token)\n            except Exception:\n                result.set_return_code(ReturnCode.EXECUTION_EXCEPTION)\n\n        return Message(topic=\"reply_\" + req.topic, body=pickle.dumps(result))",
  "class StartJobProcessor(RequestProcessor):\n    def get_topics(self) -> List[str]:\n        return [TrainingTopic.START_JOB]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n\n        resource_manager = engine.get_component(SystemComponents.RESOURCE_MANAGER)\n        if not isinstance(resource_manager, ResourceManagerSpec):\n            raise RuntimeError(\n                f\"resource_manager should be of type ResourceManagerSpec, but got {type(resource_manager)}.\"\n            )\n        resource_consumer = engine.get_component(SystemComponents.RESOURCE_CONSUMER)\n        if not isinstance(resource_consumer, ResourceConsumerSpec):\n            raise RuntimeError(\n                f\"resource_consumer should be of type ResourceConsumerSpec, but got {type(resource_consumer)}.\"\n            )\n\n        try:\n            with engine.new_context() as fl_ctx:\n                resource_spec = pickle.loads(req.body)\n                job_id = req.get_header(RequestHeader.JOB_ID)\n                token = req.get_header(ShareableHeader.RESOURCE_RESERVE_TOKEN)\n                allocated_resources = resource_manager.allocate_resources(\n                    resource_requirement=resource_spec, token=token, fl_ctx=fl_ctx\n                )\n            result = engine.start_app(\n                job_id,\n                allocated_resource=allocated_resources,\n                token=token,\n                resource_consumer=resource_consumer,\n                resource_manager=resource_manager,\n            )\n        except Exception as e:\n            result = f\"{ERROR_MSG_PREFIX}: Execution exception: {e}.\"\n\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "class CancelResourceProcessor(RequestProcessor):\n    def get_topics(self) -> List[str]:\n        return [TrainingTopic.CANCEL_RESOURCE]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n\n        resource_manager = engine.get_component(SystemComponents.RESOURCE_MANAGER)\n        if not isinstance(resource_manager, ResourceManagerSpec):\n            raise RuntimeError(\n                f\"resource_manager should be of type ResourceManagerSpec, but got {type(resource_manager)}.\"\n            )\n        with engine.new_context() as fl_ctx:\n            result = Shareable()\n            try:\n                # resource_spec = req.get_header(ShareableHeader.RESOURCE_SPEC)\n                resource_spec = pickle.loads(req.body)\n                token = req.get_header(ShareableHeader.RESOURCE_RESERVE_TOKEN)\n                resource_manager.cancel_resources(resource_requirement=resource_spec, token=token, fl_ctx=fl_ctx)\n            except Exception:\n                result.set_return_code(ReturnCode.EXECUTION_EXCEPTION)\n\n        return Message(topic=\"reply_\" + req.topic, body=pickle.dumps(result))",
  "def get_topics(self) -> List[str]:\n        return [TrainingTopic.CHECK_RESOURCE]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n\n        resource_manager = engine.get_component(SystemComponents.RESOURCE_MANAGER)\n        if not isinstance(resource_manager, ResourceManagerSpec):\n            raise RuntimeError(\n                f\"resource_manager should be of type ResourceManagerSpec, but got {type(resource_manager)}.\"\n            )\n        with engine.new_context() as fl_ctx:\n            result = Shareable()\n            try:\n                resource_spec = pickle.loads(req.body)\n                check_result, token = resource_manager.check_resources(\n                    resource_requirement=resource_spec, fl_ctx=fl_ctx\n                )\n                result.set_header(ShareableHeader.CHECK_RESOURCE_RESULT, check_result)\n                result.set_header(ShareableHeader.RESOURCE_RESERVE_TOKEN, token)\n            except Exception:\n                result.set_return_code(ReturnCode.EXECUTION_EXCEPTION)\n\n        return Message(topic=\"reply_\" + req.topic, body=pickle.dumps(result))",
  "def get_topics(self) -> List[str]:\n        return [TrainingTopic.START_JOB]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n\n        resource_manager = engine.get_component(SystemComponents.RESOURCE_MANAGER)\n        if not isinstance(resource_manager, ResourceManagerSpec):\n            raise RuntimeError(\n                f\"resource_manager should be of type ResourceManagerSpec, but got {type(resource_manager)}.\"\n            )\n        resource_consumer = engine.get_component(SystemComponents.RESOURCE_CONSUMER)\n        if not isinstance(resource_consumer, ResourceConsumerSpec):\n            raise RuntimeError(\n                f\"resource_consumer should be of type ResourceConsumerSpec, but got {type(resource_consumer)}.\"\n            )\n\n        try:\n            with engine.new_context() as fl_ctx:\n                resource_spec = pickle.loads(req.body)\n                job_id = req.get_header(RequestHeader.JOB_ID)\n                token = req.get_header(ShareableHeader.RESOURCE_RESERVE_TOKEN)\n                allocated_resources = resource_manager.allocate_resources(\n                    resource_requirement=resource_spec, token=token, fl_ctx=fl_ctx\n                )\n            result = engine.start_app(\n                job_id,\n                allocated_resource=allocated_resources,\n                token=token,\n                resource_consumer=resource_consumer,\n                resource_manager=resource_manager,\n            )\n        except Exception as e:\n            result = f\"{ERROR_MSG_PREFIX}: Execution exception: {e}.\"\n\n        if not result:\n            result = \"OK\"\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "def get_topics(self) -> List[str]:\n        return [TrainingTopic.CANCEL_RESOURCE]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n\n        resource_manager = engine.get_component(SystemComponents.RESOURCE_MANAGER)\n        if not isinstance(resource_manager, ResourceManagerSpec):\n            raise RuntimeError(\n                f\"resource_manager should be of type ResourceManagerSpec, but got {type(resource_manager)}.\"\n            )\n        with engine.new_context() as fl_ctx:\n            result = Shareable()\n            try:\n                # resource_spec = req.get_header(ShareableHeader.RESOURCE_SPEC)\n                resource_spec = pickle.loads(req.body)\n                token = req.get_header(ShareableHeader.RESOURCE_RESERVE_TOKEN)\n                resource_manager.cancel_resources(resource_requirement=resource_spec, token=token, fl_ctx=fl_ctx)\n            except Exception:\n                result.set_return_code(ReturnCode.EXECUTION_EXCEPTION)\n\n        return Message(topic=\"reply_\" + req.topic, body=pickle.dumps(result))",
  "def _get_client_state(project_name, token, ssid, fl_ctx: FLContext):\n    \"\"\"Client's metadata used to authenticate and communicate.\n\n    Args:\n        project_name: FL study project name\n        token: client token\n        ssid: service session ID\n        fl_ctx: FLContext\n\n    Returns:\n        A ClientState message\n\n    \"\"\"\n    state_message = fed_msg.ClientState(token=token, ssid=ssid)\n    state_message.meta.project.name = project_name\n    # state_message.meta.job_id = fl_ctx.get_prop(FLContextKey.CURRENT_RUN)\n\n    context_data = make_context_data(fl_ctx)\n    state_message.context[\"fl_context\"].CopyFrom(context_data)\n\n    return state_message",
  "def _get_client_ip():\n    \"\"\"Return localhost IP.\n\n    More robust than ``socket.gethostbyname(socket.gethostname())``. See\n    https://stackoverflow.com/questions/166506/finding-local-ip-addresses-using-pythons-stdlib/28950776#28950776\n    for more details.\n\n    Returns:\n        The host IP\n\n    \"\"\"\n    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    try:\n        s.connect((\"10.255.255.255\", 1))  # doesn't even have to be reachable\n        ip = s.getsockname()[0]\n    except Exception:\n        ip = \"127.0.0.1\"\n    finally:\n        s.close()\n    return ip",
  "def _get_communication_data(shareable, client_state, fl_ctx: FLContext, execute_task_name):\n    contrib = fed_msg.Contribution()\n    # set client auth. data\n    contrib.client.CopyFrom(client_state)\n    contrib.task_name = execute_task_name\n\n    current_model = shareable_to_modeldata(shareable, fl_ctx)\n    contrib.data.CopyFrom(current_model)\n\n    s = Struct()\n    contrib.meta_data.CopyFrom(s)\n\n    return contrib",
  "class Communicator:\n    def __init__(\n        self,\n        ssl_args=None,\n        secure_train=False,\n        retry_timeout=30,\n        client_state_processors: Optional[List[Filter]] = None,\n        compression=None,\n    ):\n        \"\"\"To init the Communicator.\n\n        Args:\n            ssl_args: SSL args\n            secure_train: True/False to indicate if secure train\n            retry_timeout: retry timeout in seconds\n            client_state_processors: Client state processor filters\n            compression: communicate compression algorithm\n        \"\"\"\n        self.ssl_args = ssl_args\n        self.secure_train = secure_train\n\n        self.verbose = False\n        self.should_stop = False\n        self.heartbeat_done = False\n        # TODO: should we change this back?\n        # self.retry = int(math.ceil(float(retry_timeout) / 5))\n        self.retry = 1\n        self.client_state_processors = client_state_processors\n        self.compression = compression\n\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    def set_up_channel(self, channel_dict, token=None):\n        \"\"\"Connect client to the server.\n\n        Args:\n            channel_dict: grpc channel parameters\n            token: client token\n\n        Returns:\n            An initialised grpc channel\n\n        \"\"\"\n        if self.secure_train:\n            with open(self.ssl_args[\"ssl_root_cert\"], \"rb\") as f:\n                trusted_certs = f.read()\n            with open(self.ssl_args[\"ssl_private_key\"], \"rb\") as f:\n                private_key = f.read()\n            with open(self.ssl_args[\"ssl_cert\"], \"rb\") as f:\n                certificate_chain = f.read()\n\n            credentials = grpc.ssl_channel_credentials(\n                certificate_chain=certificate_chain, private_key=private_key, root_certificates=trusted_certs\n            )\n\n            # make sure that all headers are in lowercase,\n            # otherwise grpc throws an exception\n            call_credentials = grpc.metadata_call_credentials(\n                lambda context, callback: callback(((\"x-custom-token\", token),), None)\n            )\n            # use this if you want standard \"Authorization\" header\n            # call_credentials = grpc.access_token_call_credentials(\n            #     \"x-custom-token\")\n            composite_credentials = grpc.composite_channel_credentials(credentials, call_credentials)\n            channel = grpc.secure_channel(\n                **channel_dict, credentials=composite_credentials, compression=self.compression\n            )\n\n        else:\n            channel = grpc.insecure_channel(**channel_dict, compression=self.compression)\n        return channel\n\n    def client_registration(self, client_name, servers, project_name):\n        \"\"\"Client's metadata used to authenticate and communicate.\n\n        Args:\n            client_name: client name\n            servers: FL servers\n            project_name: FL study project name\n\n        Returns:\n            The client's token\n\n        \"\"\"\n        local_ip = _get_client_ip()\n\n        login_message = fed_msg.ClientLogin(client_name=client_name, client_ip=local_ip)\n        login_message.meta.project.name = project_name\n\n        with self.set_up_channel(servers[project_name]) as channel:\n            stub = fed_service.FederatedTrainingStub(channel)\n            while True:\n                try:\n                    result = stub.Register(login_message)\n                    token = result.token\n                    ssid = result.ssid\n                    self.should_stop = False\n                    break\n                except grpc.RpcError as grpc_error:\n                    self.grpc_error_handler(\n                        servers[project_name],\n                        grpc_error,\n                        \"client_registration\",\n                        verbose=self.verbose,\n                    )\n                    excep = FLCommunicationError(grpc_error)\n                    if isinstance(grpc_error, grpc.Call):\n                        status_code = grpc_error.code()\n                        if grpc.StatusCode.UNAUTHENTICATED == status_code:\n                            raise excep\n                    time.sleep(5)\n            if self.should_stop:\n                raise excep\n            if result is None:\n                return None\n\n        return token, ssid\n\n    def getTask(self, servers, project_name, token, ssid, fl_ctx: FLContext):\n        \"\"\"Get a task from server.\n\n        Args:\n            servers: FL servers\n            project_name: FL study project name\n            token: client token\n            ssid: service session ID\n            fl_ctx: FLContext\n\n        Returns:\n            A CurrentTask message from server\n\n        \"\"\"\n        task, retry = None, self.retry\n        with self.set_up_channel(servers[project_name]) as channel:\n            stub = fed_service.FederatedTrainingStub(channel)\n            while retry > 0:\n                try:\n                    start_time = time.time()\n                    task = stub.GetTask(_get_client_state(project_name, token, ssid, fl_ctx))\n                    # Clear the stopping flag\n                    # if the connection to server recovered.\n                    self.should_stop = False\n\n                    end_time = time.time()\n\n                    if task.task_name == SpecialTaskName.TRY_AGAIN:\n                        self.logger.debug(\n                            f\"Received from {project_name} server \"\n                            f\" ({task.ByteSize()} Bytes). getTask time: {end_time - start_time} seconds\"\n                        )\n                    else:\n                        self.logger.info(\n                            f\"Received from {project_name} server \"\n                            f\" ({task.ByteSize()} Bytes). getTask time: {end_time - start_time} seconds\"\n                        )\n                    return task\n                except grpc.RpcError as grpc_error:\n                    self.grpc_error_handler(servers[project_name], grpc_error, \"getTask\", verbose=self.verbose)\n                    excep = FLCommunicationError(grpc_error)\n                    retry -= 1\n                    time.sleep(5)\n            if self.should_stop:\n                raise excep\n\n        # Failed to get global, return None\n        return None\n\n    def submitUpdate(\n        self, servers, project_name, token, ssid, fl_ctx: FLContext, client_name, shareable, execute_task_name\n    ):\n        \"\"\"Submit the task execution result back to the server.\n\n        Args:\n            servers: FL servers\n            project_name: server project name\n            token: client token\n            ssid: service session ID\n            fl_ctx: fl_ctx\n            client_name: client name\n            shareable: execution task result shareable\n            execute_task_name: execution task name\n\n        Returns:\n            A FederatedSummary message from the server.\n        \"\"\"\n        client_state = _get_client_state(project_name, token, ssid, fl_ctx)\n        client_state.client_name = client_name\n        contrib = _get_communication_data(shareable, client_state, fl_ctx, execute_task_name)\n\n        server_msg, retry = None, self.retry\n        with self.set_up_channel(servers[project_name]) as channel:\n            stub = fed_service.FederatedTrainingStub(channel)\n            while retry > 0:\n                try:\n                    start_time = time.time()\n                    self.logger.info(f\"Send submitUpdate to {project_name} server\")\n                    server_msg = stub.SubmitUpdate(contrib)\n                    # Clear the stopping flag\n                    # if the connection to server recovered.\n                    self.should_stop = False\n\n                    end_time = time.time()\n                    self.logger.info(\n                        f\"Received comments: {server_msg.meta.project.name} {server_msg.comment}.\"\n                        f\" SubmitUpdate time: {end_time - start_time} seconds\"\n                    )\n                    break\n                except grpc.RpcError as grpc_error:\n                    if isinstance(grpc_error, grpc.Call):\n                        if grpc_error.details().startswith(\"Contrib\"):\n                            self.logger.info(f\"submitUpdate failed: {grpc_error.details()}\")\n                            break  # outdated contribution, no need to retry\n                    self.grpc_error_handler(servers[project_name], grpc_error, \"submitUpdate\", verbose=self.verbose)\n                    retry -= 1\n                    time.sleep(5)\n        return server_msg\n\n    def auxCommunicate(\n        self, servers, project_name, token, ssid, fl_ctx: FLContext, client_name, shareable, topic, timeout\n    ):\n        \"\"\"Send the auxiliary communication message to the server.\n\n        Args:\n            servers: FL servers\n            project_name: server project name\n            token: client token\n            ssid: service session ID\n            fl_ctx: fl_ctx\n            client_name: client name\n            shareable: aux message shareable\n            topic: aux message topic\n            timeout: aux communication timeout\n\n        Returns:\n            An AuxReply message from server\n\n        \"\"\"\n        client_state = _get_client_state(project_name, token, ssid, fl_ctx)\n        client_state.client_name = client_name\n\n        aux_message = fed_msg.AuxMessage()\n        # set client auth. data\n        aux_message.client.CopyFrom(client_state)\n\n        # shareable.set_header(\"Topic\", topic)\n        aux_message.data[\"data\"].CopyFrom(make_shareable_data(shareable))\n        aux_message.data[\"fl_context\"].CopyFrom(make_context_data(fl_ctx))\n\n        server_msg, retry = None, self.retry\n        with self.set_up_channel(servers[project_name]) as channel:\n            stub = fed_service.FederatedTrainingStub(channel)\n            while retry > 0:\n                try:\n                    self.logger.debug(f\"Send AuxMessage to {project_name} server\")\n                    server_msg = stub.AuxCommunicate(aux_message, timeout=timeout)\n                    # Clear the stopping flag\n                    # if the connection to server recovered.\n                    self.should_stop = False\n\n                    break\n                except grpc.RpcError as grpc_error:\n                    self.grpc_error_handler(servers[project_name], grpc_error, \"AuxCommunicate\", verbose=self.verbose)\n                    retry -= 1\n                    time.sleep(5)\n        return server_msg\n\n    def quit_remote(self, servers, task_name, token, ssid, fl_ctx: FLContext):\n        \"\"\"Sending the last message to the server before leaving.\n\n        Args:\n            servers: FL servers\n            task_name: project name\n            token: FL client token\n            fl_ctx: FLContext\n\n        Returns:\n            server's reply to the last message\n\n        \"\"\"\n        server_message, retry = None, self.retry\n        with self.set_up_channel(servers[task_name]) as channel:\n            stub = fed_service.FederatedTrainingStub(channel)\n            while retry > 0:\n                try:\n                    start_time = time.time()\n                    self.logger.info(f\"Quitting server: {task_name}\")\n                    server_message = stub.Quit(_get_client_state(task_name, token, ssid, fl_ctx))\n                    # Clear the stopping flag\n                    # if the connection to server recovered.\n                    self.should_stop = False\n\n                    end_time = time.time()\n                    self.logger.info(\n                        f\"Received comment from server: {server_message.comment}. Quit time: {end_time - start_time} seconds\"\n                    )\n                    break\n                except grpc.RpcError as grpc_error:\n                    self.grpc_error_handler(servers[task_name], grpc_error, \"quit_remote\")\n                    retry -= 1\n                    time.sleep(3)\n        return server_message\n\n    def send_heartbeat(self, servers, task_name, token, ssid, client_name, engine: ClientEngineInternalSpec):\n        message = fed_msg.Token()\n        message.token = token\n        message.ssid = ssid\n        message.client_name = client_name\n\n        while not self.heartbeat_done:\n            try:\n                with self.set_up_channel(servers[task_name]) as channel:\n                    stub = fed_service.FederatedTrainingStub(channel)\n                    # retry the heartbeat call for 10 minutes\n                    retry = 2\n                    while retry > 0:\n                        try:\n                            self.logger.debug(f\"Send {task_name} heartbeat {token}\")\n                            job_ids = engine.get_all_job_ids()\n                            del message.jobs[:]\n                            message.jobs.extend(job_ids)\n                            response = stub.Heartbeat(message)\n                            self._clean_up_runs(engine, response)\n                            break\n                        except grpc.RpcError as grpc_error:\n                            self.logger.debug(grpc_error)\n                            retry -= 1\n                            time.sleep(5)\n\n                    time.sleep(30)\n            except BaseException as e:\n                self.logger.info(f\"Failed to send heartbeat. Will try again. Exception: {str(e)}\")\n                time.sleep(5)\n\n    def _clean_up_runs(self, engine, response):\n        abort_runs = list(set(response.abort_jobs))\n        display_runs = \",\".join(abort_runs)\n        try:\n            if abort_runs:\n                for job in abort_runs:\n                    engine.abort_app(job)\n                self.logger.info(f\"These runs: {display_runs} are not running on the server. Aborted them.\")\n        except:\n            self.logger.info(f\"Failed to clean up the runs: {display_runs}\")\n\n    def grpc_error_handler(self, service, grpc_error, action, verbose=False):\n        \"\"\"Handling grpc exceptions.\n\n        Args:\n            service: FL service\n            grpc_error: grpc error\n            action: action to take\n            verbose: verbose to error print out\n        \"\"\"\n        status_code = None\n        if isinstance(grpc_error, grpc.Call):\n            status_code = grpc_error.code()\n\n        if grpc.StatusCode.RESOURCE_EXHAUSTED == status_code:\n            if grpc_error.details().startswith(\"No token\"):\n                self.logger.info(\"No token for this client in current round. \" \"Waiting for server new round. \")\n                self.should_stop = False\n                return\n\n        self.logger.error(f\"Action: {action} grpc communication error.\")\n        if grpc.StatusCode.UNAVAILABLE == status_code:\n            self.logger.error(f\"Could not connect to server: {service.get('target')}\\t {grpc_error.details()}\")\n            self.should_stop = True\n\n        if grpc.StatusCode.OUT_OF_RANGE == status_code:\n            self.logger.error(\n                f\"Server training has stopped.\\t\" f\"Setting flag for stopping training. {grpc_error.details()}\"\n            )\n            self.should_stop = True\n\n        if verbose:\n            self.logger.info(grpc_error)",
  "def __init__(\n        self,\n        ssl_args=None,\n        secure_train=False,\n        retry_timeout=30,\n        client_state_processors: Optional[List[Filter]] = None,\n        compression=None,\n    ):\n        \"\"\"To init the Communicator.\n\n        Args:\n            ssl_args: SSL args\n            secure_train: True/False to indicate if secure train\n            retry_timeout: retry timeout in seconds\n            client_state_processors: Client state processor filters\n            compression: communicate compression algorithm\n        \"\"\"\n        self.ssl_args = ssl_args\n        self.secure_train = secure_train\n\n        self.verbose = False\n        self.should_stop = False\n        self.heartbeat_done = False\n        # TODO: should we change this back?\n        # self.retry = int(math.ceil(float(retry_timeout) / 5))\n        self.retry = 1\n        self.client_state_processors = client_state_processors\n        self.compression = compression\n\n        self.logger = logging.getLogger(self.__class__.__name__)",
  "def set_up_channel(self, channel_dict, token=None):\n        \"\"\"Connect client to the server.\n\n        Args:\n            channel_dict: grpc channel parameters\n            token: client token\n\n        Returns:\n            An initialised grpc channel\n\n        \"\"\"\n        if self.secure_train:\n            with open(self.ssl_args[\"ssl_root_cert\"], \"rb\") as f:\n                trusted_certs = f.read()\n            with open(self.ssl_args[\"ssl_private_key\"], \"rb\") as f:\n                private_key = f.read()\n            with open(self.ssl_args[\"ssl_cert\"], \"rb\") as f:\n                certificate_chain = f.read()\n\n            credentials = grpc.ssl_channel_credentials(\n                certificate_chain=certificate_chain, private_key=private_key, root_certificates=trusted_certs\n            )\n\n            # make sure that all headers are in lowercase,\n            # otherwise grpc throws an exception\n            call_credentials = grpc.metadata_call_credentials(\n                lambda context, callback: callback(((\"x-custom-token\", token),), None)\n            )\n            # use this if you want standard \"Authorization\" header\n            # call_credentials = grpc.access_token_call_credentials(\n            #     \"x-custom-token\")\n            composite_credentials = grpc.composite_channel_credentials(credentials, call_credentials)\n            channel = grpc.secure_channel(\n                **channel_dict, credentials=composite_credentials, compression=self.compression\n            )\n\n        else:\n            channel = grpc.insecure_channel(**channel_dict, compression=self.compression)\n        return channel",
  "def client_registration(self, client_name, servers, project_name):\n        \"\"\"Client's metadata used to authenticate and communicate.\n\n        Args:\n            client_name: client name\n            servers: FL servers\n            project_name: FL study project name\n\n        Returns:\n            The client's token\n\n        \"\"\"\n        local_ip = _get_client_ip()\n\n        login_message = fed_msg.ClientLogin(client_name=client_name, client_ip=local_ip)\n        login_message.meta.project.name = project_name\n\n        with self.set_up_channel(servers[project_name]) as channel:\n            stub = fed_service.FederatedTrainingStub(channel)\n            while True:\n                try:\n                    result = stub.Register(login_message)\n                    token = result.token\n                    ssid = result.ssid\n                    self.should_stop = False\n                    break\n                except grpc.RpcError as grpc_error:\n                    self.grpc_error_handler(\n                        servers[project_name],\n                        grpc_error,\n                        \"client_registration\",\n                        verbose=self.verbose,\n                    )\n                    excep = FLCommunicationError(grpc_error)\n                    if isinstance(grpc_error, grpc.Call):\n                        status_code = grpc_error.code()\n                        if grpc.StatusCode.UNAUTHENTICATED == status_code:\n                            raise excep\n                    time.sleep(5)\n            if self.should_stop:\n                raise excep\n            if result is None:\n                return None\n\n        return token, ssid",
  "def getTask(self, servers, project_name, token, ssid, fl_ctx: FLContext):\n        \"\"\"Get a task from server.\n\n        Args:\n            servers: FL servers\n            project_name: FL study project name\n            token: client token\n            ssid: service session ID\n            fl_ctx: FLContext\n\n        Returns:\n            A CurrentTask message from server\n\n        \"\"\"\n        task, retry = None, self.retry\n        with self.set_up_channel(servers[project_name]) as channel:\n            stub = fed_service.FederatedTrainingStub(channel)\n            while retry > 0:\n                try:\n                    start_time = time.time()\n                    task = stub.GetTask(_get_client_state(project_name, token, ssid, fl_ctx))\n                    # Clear the stopping flag\n                    # if the connection to server recovered.\n                    self.should_stop = False\n\n                    end_time = time.time()\n\n                    if task.task_name == SpecialTaskName.TRY_AGAIN:\n                        self.logger.debug(\n                            f\"Received from {project_name} server \"\n                            f\" ({task.ByteSize()} Bytes). getTask time: {end_time - start_time} seconds\"\n                        )\n                    else:\n                        self.logger.info(\n                            f\"Received from {project_name} server \"\n                            f\" ({task.ByteSize()} Bytes). getTask time: {end_time - start_time} seconds\"\n                        )\n                    return task\n                except grpc.RpcError as grpc_error:\n                    self.grpc_error_handler(servers[project_name], grpc_error, \"getTask\", verbose=self.verbose)\n                    excep = FLCommunicationError(grpc_error)\n                    retry -= 1\n                    time.sleep(5)\n            if self.should_stop:\n                raise excep\n\n        # Failed to get global, return None\n        return None",
  "def submitUpdate(\n        self, servers, project_name, token, ssid, fl_ctx: FLContext, client_name, shareable, execute_task_name\n    ):\n        \"\"\"Submit the task execution result back to the server.\n\n        Args:\n            servers: FL servers\n            project_name: server project name\n            token: client token\n            ssid: service session ID\n            fl_ctx: fl_ctx\n            client_name: client name\n            shareable: execution task result shareable\n            execute_task_name: execution task name\n\n        Returns:\n            A FederatedSummary message from the server.\n        \"\"\"\n        client_state = _get_client_state(project_name, token, ssid, fl_ctx)\n        client_state.client_name = client_name\n        contrib = _get_communication_data(shareable, client_state, fl_ctx, execute_task_name)\n\n        server_msg, retry = None, self.retry\n        with self.set_up_channel(servers[project_name]) as channel:\n            stub = fed_service.FederatedTrainingStub(channel)\n            while retry > 0:\n                try:\n                    start_time = time.time()\n                    self.logger.info(f\"Send submitUpdate to {project_name} server\")\n                    server_msg = stub.SubmitUpdate(contrib)\n                    # Clear the stopping flag\n                    # if the connection to server recovered.\n                    self.should_stop = False\n\n                    end_time = time.time()\n                    self.logger.info(\n                        f\"Received comments: {server_msg.meta.project.name} {server_msg.comment}.\"\n                        f\" SubmitUpdate time: {end_time - start_time} seconds\"\n                    )\n                    break\n                except grpc.RpcError as grpc_error:\n                    if isinstance(grpc_error, grpc.Call):\n                        if grpc_error.details().startswith(\"Contrib\"):\n                            self.logger.info(f\"submitUpdate failed: {grpc_error.details()}\")\n                            break  # outdated contribution, no need to retry\n                    self.grpc_error_handler(servers[project_name], grpc_error, \"submitUpdate\", verbose=self.verbose)\n                    retry -= 1\n                    time.sleep(5)\n        return server_msg",
  "def auxCommunicate(\n        self, servers, project_name, token, ssid, fl_ctx: FLContext, client_name, shareable, topic, timeout\n    ):\n        \"\"\"Send the auxiliary communication message to the server.\n\n        Args:\n            servers: FL servers\n            project_name: server project name\n            token: client token\n            ssid: service session ID\n            fl_ctx: fl_ctx\n            client_name: client name\n            shareable: aux message shareable\n            topic: aux message topic\n            timeout: aux communication timeout\n\n        Returns:\n            An AuxReply message from server\n\n        \"\"\"\n        client_state = _get_client_state(project_name, token, ssid, fl_ctx)\n        client_state.client_name = client_name\n\n        aux_message = fed_msg.AuxMessage()\n        # set client auth. data\n        aux_message.client.CopyFrom(client_state)\n\n        # shareable.set_header(\"Topic\", topic)\n        aux_message.data[\"data\"].CopyFrom(make_shareable_data(shareable))\n        aux_message.data[\"fl_context\"].CopyFrom(make_context_data(fl_ctx))\n\n        server_msg, retry = None, self.retry\n        with self.set_up_channel(servers[project_name]) as channel:\n            stub = fed_service.FederatedTrainingStub(channel)\n            while retry > 0:\n                try:\n                    self.logger.debug(f\"Send AuxMessage to {project_name} server\")\n                    server_msg = stub.AuxCommunicate(aux_message, timeout=timeout)\n                    # Clear the stopping flag\n                    # if the connection to server recovered.\n                    self.should_stop = False\n\n                    break\n                except grpc.RpcError as grpc_error:\n                    self.grpc_error_handler(servers[project_name], grpc_error, \"AuxCommunicate\", verbose=self.verbose)\n                    retry -= 1\n                    time.sleep(5)\n        return server_msg",
  "def quit_remote(self, servers, task_name, token, ssid, fl_ctx: FLContext):\n        \"\"\"Sending the last message to the server before leaving.\n\n        Args:\n            servers: FL servers\n            task_name: project name\n            token: FL client token\n            fl_ctx: FLContext\n\n        Returns:\n            server's reply to the last message\n\n        \"\"\"\n        server_message, retry = None, self.retry\n        with self.set_up_channel(servers[task_name]) as channel:\n            stub = fed_service.FederatedTrainingStub(channel)\n            while retry > 0:\n                try:\n                    start_time = time.time()\n                    self.logger.info(f\"Quitting server: {task_name}\")\n                    server_message = stub.Quit(_get_client_state(task_name, token, ssid, fl_ctx))\n                    # Clear the stopping flag\n                    # if the connection to server recovered.\n                    self.should_stop = False\n\n                    end_time = time.time()\n                    self.logger.info(\n                        f\"Received comment from server: {server_message.comment}. Quit time: {end_time - start_time} seconds\"\n                    )\n                    break\n                except grpc.RpcError as grpc_error:\n                    self.grpc_error_handler(servers[task_name], grpc_error, \"quit_remote\")\n                    retry -= 1\n                    time.sleep(3)\n        return server_message",
  "def send_heartbeat(self, servers, task_name, token, ssid, client_name, engine: ClientEngineInternalSpec):\n        message = fed_msg.Token()\n        message.token = token\n        message.ssid = ssid\n        message.client_name = client_name\n\n        while not self.heartbeat_done:\n            try:\n                with self.set_up_channel(servers[task_name]) as channel:\n                    stub = fed_service.FederatedTrainingStub(channel)\n                    # retry the heartbeat call for 10 minutes\n                    retry = 2\n                    while retry > 0:\n                        try:\n                            self.logger.debug(f\"Send {task_name} heartbeat {token}\")\n                            job_ids = engine.get_all_job_ids()\n                            del message.jobs[:]\n                            message.jobs.extend(job_ids)\n                            response = stub.Heartbeat(message)\n                            self._clean_up_runs(engine, response)\n                            break\n                        except grpc.RpcError as grpc_error:\n                            self.logger.debug(grpc_error)\n                            retry -= 1\n                            time.sleep(5)\n\n                    time.sleep(30)\n            except BaseException as e:\n                self.logger.info(f\"Failed to send heartbeat. Will try again. Exception: {str(e)}\")\n                time.sleep(5)",
  "def _clean_up_runs(self, engine, response):\n        abort_runs = list(set(response.abort_jobs))\n        display_runs = \",\".join(abort_runs)\n        try:\n            if abort_runs:\n                for job in abort_runs:\n                    engine.abort_app(job)\n                self.logger.info(f\"These runs: {display_runs} are not running on the server. Aborted them.\")\n        except:\n            self.logger.info(f\"Failed to clean up the runs: {display_runs}\")",
  "def grpc_error_handler(self, service, grpc_error, action, verbose=False):\n        \"\"\"Handling grpc exceptions.\n\n        Args:\n            service: FL service\n            grpc_error: grpc error\n            action: action to take\n            verbose: verbose to error print out\n        \"\"\"\n        status_code = None\n        if isinstance(grpc_error, grpc.Call):\n            status_code = grpc_error.code()\n\n        if grpc.StatusCode.RESOURCE_EXHAUSTED == status_code:\n            if grpc_error.details().startswith(\"No token\"):\n                self.logger.info(\"No token for this client in current round. \" \"Waiting for server new round. \")\n                self.should_stop = False\n                return\n\n        self.logger.error(f\"Action: {action} grpc communication error.\")\n        if grpc.StatusCode.UNAVAILABLE == status_code:\n            self.logger.error(f\"Could not connect to server: {service.get('target')}\\t {grpc_error.details()}\")\n            self.should_stop = True\n\n        if grpc.StatusCode.OUT_OF_RANGE == status_code:\n            self.logger.error(\n                f\"Server training has stopped.\\t\" f\"Setting flag for stopping training. {grpc_error.details()}\"\n            )\n            self.should_stop = True\n\n        if verbose:\n            self.logger.info(grpc_error)",
  "class ComponentCallerProcessor(RequestProcessor):\n    def get_topics(self) -> [str]:\n        return [ComponentCallerTopic.CALL_COMPONENT]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n\n        caller = engine.get_widget(WidgetID.COMPONENT_CALLER)\n        if not isinstance(caller, ComponentCaller):\n            raise TypeError(\"caller must be ComponentCaller, but got {}\".format(type(caller)))\n\n        run_info = engine.get_current_run_info()\n        if not run_info or run_info.job_id < 0:\n            result = {\"error\": \"app not running\"}\n        else:\n            comp_target = req.get_header(RequestHeader.COMPONENT_TARGET)\n            call_name = req.get_header(RequestHeader.CALL_NAME)\n            call_params = req.body\n            result = caller.call_components(target=comp_target, call_name=call_name, params=call_params)\n\n        if not isinstance(result, dict):\n            result = {}\n\n        return Message(topic=req.topic, body=result)",
  "def get_topics(self) -> [str]:\n        return [ComponentCallerTopic.CALL_COMPONENT]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n\n        caller = engine.get_widget(WidgetID.COMPONENT_CALLER)\n        if not isinstance(caller, ComponentCaller):\n            raise TypeError(\"caller must be ComponentCaller, but got {}\".format(type(caller)))\n\n        run_info = engine.get_current_run_info()\n        if not run_info or run_info.job_id < 0:\n            result = {\"error\": \"app not running\"}\n        else:\n            comp_target = req.get_header(RequestHeader.COMPONENT_TARGET)\n            call_name = req.get_header(RequestHeader.CALL_NAME)\n            call_params = req.body\n            result = caller.call_components(target=comp_target, call_name=call_name, params=call_params)\n\n        if not isinstance(result, dict):\n            result = {}\n\n        return Message(topic=req.topic, body=result)",
  "class ClientRunInfo(object):\n    def __init__(self, job_id):\n        \"\"\"To init the ClientRunInfo.\n\n        Args:\n            job_id: job id\n        \"\"\"\n        self.job_id = job_id\n        self.current_task_name = \"\"\n        self.start_time = None",
  "class ClientRunManager(ClientEngineExecutorSpec):\n    \"\"\"ClientRunManager provides the ClientEngine APIs implementation running in the child process.\"\"\"\n\n    def __init__(\n        self,\n        client_name: str,\n        job_id: str,\n        workspace: Workspace,\n        client: FederatedClient,\n        components: Dict[str, FLComponent],\n        handlers: Optional[List[FLComponent]] = None,\n        conf: ClientJsonConfigurator = None,\n    ) -> None:\n        \"\"\"To init the ClientRunManager.\n\n        Args:\n            client_name: client name\n            job_id: job id\n            workspace: workspacee\n            client: FL client object\n            components: available FL components\n            handlers: available handlers\n            conf: ClientJsonConfigurator object\n        \"\"\"\n        super().__init__()\n\n        self.client = client\n        self.handlers = handlers\n        self.workspace = workspace\n        self.components = components\n        self.aux_runner = ClientAuxRunner()\n        self.add_handler(self.aux_runner)\n        self.conf = conf\n\n        self.fl_ctx_mgr = FLContextManager(\n            engine=self, identity_name=client_name, job_id=job_id, public_stickers={}, private_stickers={}\n        )\n\n        self.run_info = ClientRunInfo(job_id=job_id)\n\n        self.widgets = {WidgetID.INFO_COLLECTOR: InfoCollector(), WidgetID.FED_EVENT_RUNNER: ClientFedEventRunner()}\n        for _, widget in self.widgets.items():\n            self.handlers.append(widget)\n\n    def get_task_assignment(self, fl_ctx: FLContext) -> TaskAssignment:\n        pull_success, task_name, remote_tasks = self.client.fetch_task(fl_ctx)\n        task = None\n        if pull_success:\n            shareable = self.client.extract_shareable(remote_tasks, fl_ctx)\n            # task_id = fl_ctx.get_peer_context().get_cookie(FLContextKey.TASK_ID)\n            task_id = shareable.get_header(key=FLContextKey.TASK_ID)\n            task = TaskAssignment(name=task_name, task_id=task_id, data=shareable)\n        return task\n\n    def new_context(self) -> FLContext:\n        return self.fl_ctx_mgr.new_context()\n\n    def send_task_result(self, result: Shareable, fl_ctx: FLContext) -> bool:\n        try:\n            self.client.push_results(result, fl_ctx)  # push task execution results\n            return True\n        except BaseException:\n            return False\n\n    def get_workspace(self) -> Workspace:\n        return self.workspace\n\n    def get_run_info(self) -> ClientRunInfo:\n        return self.run_info\n\n    def show_errors(self) -> ClientRunInfo:\n        return self.run_info\n\n    def reset_errors(self) -> ClientRunInfo:\n        return self.run_info\n\n    def dispatch(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        return self.aux_runner.dispatch(topic=topic, request=request, fl_ctx=fl_ctx)\n\n    def get_component(self, component_id: str) -> object:\n        return self.components.get(component_id)\n\n    def get_all_components(self) -> dict:\n        return self.components\n\n    def get_widget(self, widget_id: str) -> Widget:\n        return self.widgets.get(widget_id)\n\n    def fire_event(self, event_type: str, fl_ctx: FLContext):\n        fire_event(event=event_type, handlers=self.handlers, ctx=fl_ctx)\n\n    def add_handler(self, handler: FLComponent):\n        self.handlers.append(handler)\n\n    def build_component(self, config_dict):\n        if not self.conf:\n            raise RuntimeError(\"No configurator set up.\")\n        return self.conf.build_component(config_dict)\n\n    def aux_send(self, topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> Shareable:\n        reply = self.client.aux_send(topic, request, timeout, fl_ctx)\n        if reply:\n            return self.client.extract_shareable(reply, fl_ctx)\n        else:\n            return make_reply(ReturnCode.COMMUNICATION_ERROR)\n\n    def send_aux_request(self, topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> Shareable:\n        return self.aux_runner.send_aux_request(topic, request, timeout, fl_ctx)\n\n    def register_aux_message_handler(self, topic: str, message_handle_func):\n        self.aux_runner.register_aux_message_handler(topic, message_handle_func)\n\n    def fire_and_forget_aux_request(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        return self.send_aux_request(topic, request, 0.0, fl_ctx)\n\n    def abort_app(self, job_id: str, fl_ctx: FLContext):\n        runner = fl_ctx.get_prop(key=FLContextKey.RUNNER, default=None)\n        if isinstance(runner, ClientRunner):\n            runner.abort()",
  "def __init__(self, job_id):\n        \"\"\"To init the ClientRunInfo.\n\n        Args:\n            job_id: job id\n        \"\"\"\n        self.job_id = job_id\n        self.current_task_name = \"\"\n        self.start_time = None",
  "def __init__(\n        self,\n        client_name: str,\n        job_id: str,\n        workspace: Workspace,\n        client: FederatedClient,\n        components: Dict[str, FLComponent],\n        handlers: Optional[List[FLComponent]] = None,\n        conf: ClientJsonConfigurator = None,\n    ) -> None:\n        \"\"\"To init the ClientRunManager.\n\n        Args:\n            client_name: client name\n            job_id: job id\n            workspace: workspacee\n            client: FL client object\n            components: available FL components\n            handlers: available handlers\n            conf: ClientJsonConfigurator object\n        \"\"\"\n        super().__init__()\n\n        self.client = client\n        self.handlers = handlers\n        self.workspace = workspace\n        self.components = components\n        self.aux_runner = ClientAuxRunner()\n        self.add_handler(self.aux_runner)\n        self.conf = conf\n\n        self.fl_ctx_mgr = FLContextManager(\n            engine=self, identity_name=client_name, job_id=job_id, public_stickers={}, private_stickers={}\n        )\n\n        self.run_info = ClientRunInfo(job_id=job_id)\n\n        self.widgets = {WidgetID.INFO_COLLECTOR: InfoCollector(), WidgetID.FED_EVENT_RUNNER: ClientFedEventRunner()}\n        for _, widget in self.widgets.items():\n            self.handlers.append(widget)",
  "def get_task_assignment(self, fl_ctx: FLContext) -> TaskAssignment:\n        pull_success, task_name, remote_tasks = self.client.fetch_task(fl_ctx)\n        task = None\n        if pull_success:\n            shareable = self.client.extract_shareable(remote_tasks, fl_ctx)\n            # task_id = fl_ctx.get_peer_context().get_cookie(FLContextKey.TASK_ID)\n            task_id = shareable.get_header(key=FLContextKey.TASK_ID)\n            task = TaskAssignment(name=task_name, task_id=task_id, data=shareable)\n        return task",
  "def new_context(self) -> FLContext:\n        return self.fl_ctx_mgr.new_context()",
  "def send_task_result(self, result: Shareable, fl_ctx: FLContext) -> bool:\n        try:\n            self.client.push_results(result, fl_ctx)  # push task execution results\n            return True\n        except BaseException:\n            return False",
  "def get_workspace(self) -> Workspace:\n        return self.workspace",
  "def get_run_info(self) -> ClientRunInfo:\n        return self.run_info",
  "def show_errors(self) -> ClientRunInfo:\n        return self.run_info",
  "def reset_errors(self) -> ClientRunInfo:\n        return self.run_info",
  "def dispatch(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        return self.aux_runner.dispatch(topic=topic, request=request, fl_ctx=fl_ctx)",
  "def get_component(self, component_id: str) -> object:\n        return self.components.get(component_id)",
  "def get_all_components(self) -> dict:\n        return self.components",
  "def get_widget(self, widget_id: str) -> Widget:\n        return self.widgets.get(widget_id)",
  "def fire_event(self, event_type: str, fl_ctx: FLContext):\n        fire_event(event=event_type, handlers=self.handlers, ctx=fl_ctx)",
  "def add_handler(self, handler: FLComponent):\n        self.handlers.append(handler)",
  "def build_component(self, config_dict):\n        if not self.conf:\n            raise RuntimeError(\"No configurator set up.\")\n        return self.conf.build_component(config_dict)",
  "def aux_send(self, topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> Shareable:\n        reply = self.client.aux_send(topic, request, timeout, fl_ctx)\n        if reply:\n            return self.client.extract_shareable(reply, fl_ctx)\n        else:\n            return make_reply(ReturnCode.COMMUNICATION_ERROR)",
  "def send_aux_request(self, topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> Shareable:\n        return self.aux_runner.send_aux_request(topic, request, timeout, fl_ctx)",
  "def register_aux_message_handler(self, topic: str, message_handle_func):\n        self.aux_runner.register_aux_message_handler(topic, message_handle_func)",
  "def fire_and_forget_aux_request(self, topic: str, request: Shareable, fl_ctx: FLContext) -> Shareable:\n        return self.send_aux_request(topic, request, 0.0, fl_ctx)",
  "def abort_app(self, job_id: str, fl_ctx: FLContext):\n        runner = fl_ctx.get_prop(key=FLContextKey.RUNNER, default=None)\n        if isinstance(runner, ClientRunner):\n            runner.abort()",
  "class ShellCommandProcessor(RequestProcessor):\n    def get_topics(self) -> [str]:\n        return [SysCommandTopic.SHELL]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        shell_cmd = req.body\n        output = subprocess.getoutput(shell_cmd)\n        return Message(topic=\"reply_\" + req.topic, body=output)",
  "def get_topics(self) -> [str]:\n        return [SysCommandTopic.SHELL]",
  "def process(self, req: Message, app_ctx) -> Message:\n        shell_cmd = req.body\n        output = subprocess.getoutput(shell_cmd)\n        return Message(topic=\"reply_\" + req.topic, body=output)",
  "class CommandAgent(object):\n    def __init__(self, federated_client, listen_port, client_runner) -> None:\n        \"\"\"To init the CommandAgent.\n\n        Args:\n            federated_client: FL client object\n            listen_port: port to listen the command\n            client_runner: ClientRunner object\n        \"\"\"\n        self.federated_client = federated_client\n        self.listen_port = int(listen_port)\n        self.client_runner = client_runner\n        self.thread = None\n        self.asked_to_stop = False\n\n        self.commands = AdminCommands.commands\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    def start(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        self.thread = threading.Thread(\n            target=listen_command, args=[self.listen_port, engine, self.execute_command, self.logger]\n        )\n        self.thread.start()\n\n    def execute_command(self, conn, engine):\n        while not self.asked_to_stop:\n            try:\n                if conn.poll(1.0):\n                    msg = conn.recv()\n                    command_name = msg.get(\"command\")\n                    data = msg.get(\"data\")\n                    command = AdminCommands.get_command(command_name)\n                    if command:\n                        with engine.new_context() as new_fl_ctx:\n                            reply = command.process(data=data, fl_ctx=new_fl_ctx)\n                            if reply:\n                                conn.send(reply)\n            except EOFError:\n                self.logger.info(\"listener communication terminated.\")\n                break\n            except Exception as e:\n                # traceback.print_exc()\n                self.logger.error(f\"Process communication error: {self.listen_port}: {e}.\", exc_info=False)\n\n    def shutdown(self):\n        self.asked_to_stop = True\n\n        if self.thread and self.thread.is_alive():\n            self.thread.join()",
  "def __init__(self, federated_client, listen_port, client_runner) -> None:\n        \"\"\"To init the CommandAgent.\n\n        Args:\n            federated_client: FL client object\n            listen_port: port to listen the command\n            client_runner: ClientRunner object\n        \"\"\"\n        self.federated_client = federated_client\n        self.listen_port = int(listen_port)\n        self.client_runner = client_runner\n        self.thread = None\n        self.asked_to_stop = False\n\n        self.commands = AdminCommands.commands\n        self.logger = logging.getLogger(self.__class__.__name__)",
  "def start(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        self.thread = threading.Thread(\n            target=listen_command, args=[self.listen_port, engine, self.execute_command, self.logger]\n        )\n        self.thread.start()",
  "def execute_command(self, conn, engine):\n        while not self.asked_to_stop:\n            try:\n                if conn.poll(1.0):\n                    msg = conn.recv()\n                    command_name = msg.get(\"command\")\n                    data = msg.get(\"data\")\n                    command = AdminCommands.get_command(command_name)\n                    if command:\n                        with engine.new_context() as new_fl_ctx:\n                            reply = command.process(data=data, fl_ctx=new_fl_ctx)\n                            if reply:\n                                conn.send(reply)\n            except EOFError:\n                self.logger.info(\"listener communication terminated.\")\n                break\n            except Exception as e:\n                # traceback.print_exc()\n                self.logger.error(f\"Process communication error: {self.listen_port}: {e}.\", exc_info=False)",
  "def shutdown(self):\n        self.asked_to_stop = True\n\n        if self.thread and self.thread.is_alive():\n            self.thread.join()",
  "class ClientRequestProcessors:\n    request_processors = [\n        StartAppProcessor(),\n        ClientStatusProcessor(),\n        AbortAppProcessor(),\n        ShutdownClientProcessor(),\n        DeployProcessor(),\n        ValidateRequestProcessor(),\n        ShellCommandProcessor(),\n        DeleteRunNumberProcessor(),\n        SysInfoProcessor(),\n        RestartClientProcessor(),\n        # StartClientMGpuProcessor(),\n        ClientInfoProcessor(),\n        AbortTaskProcessor(),\n        # SetRunNumberProcessor(),\n        AuxRequestProcessor(),\n        StartJobProcessor(),\n        CheckResourceProcessor(),\n        CancelResourceProcessor(),\n    ]\n\n    @staticmethod\n    def register_cmd_module(request_processor):\n        from .admin import RequestProcessor\n\n        if not isinstance(request_processor, RequestProcessor):\n            raise TypeError(\"request_processor must be RequestProcessor, but got {}\".format(type(request_processor)))\n\n        ClientRequestProcessors.request_processors.append(request_processor)",
  "def register_cmd_module(request_processor):\n        from .admin import RequestProcessor\n\n        if not isinstance(request_processor, RequestProcessor):\n            raise TypeError(\"request_processor must be RequestProcessor, but got {}\".format(type(request_processor)))\n\n        ClientRequestProcessors.request_processors.append(request_processor)",
  "class ClientInfoProcessor(RequestProcessor):\n    def get_topics(self) -> [str]:\n        return [\n            InfoCollectorTopic.SHOW_STATS,\n            InfoCollectorTopic.SHOW_ERRORS,\n            InfoCollectorTopic.RESET_ERRORS,\n        ]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        if req.topic == InfoCollectorTopic.SHOW_STATS:\n            result = engine.get_current_run_info(job_id)\n        elif req.topic == InfoCollectorTopic.SHOW_ERRORS:\n            result = engine.get_errors(job_id)\n        elif req.topic == InfoCollectorTopic.RESET_ERRORS:\n            engine.reset_errors(job_id)\n            result = {\"status\": \"OK\"}\n        else:\n            result = {\"error\": \"invalid topic {}\".format(req.topic)}\n\n        if not isinstance(result, dict):\n            result = {}\n\n        result = json.dumps(result)\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "def get_topics(self) -> [str]:\n        return [\n            InfoCollectorTopic.SHOW_STATS,\n            InfoCollectorTopic.SHOW_ERRORS,\n            InfoCollectorTopic.RESET_ERRORS,\n        ]",
  "def process(self, req: Message, app_ctx) -> Message:\n        engine = app_ctx\n        if not isinstance(engine, ClientEngineInternalSpec):\n            raise TypeError(\"engine must be ClientEngineInternalSpec, but got {}\".format(type(engine)))\n\n        job_id = req.get_header(RequestHeader.JOB_ID)\n        if req.topic == InfoCollectorTopic.SHOW_STATS:\n            result = engine.get_current_run_info(job_id)\n        elif req.topic == InfoCollectorTopic.SHOW_ERRORS:\n            result = engine.get_errors(job_id)\n        elif req.topic == InfoCollectorTopic.RESET_ERRORS:\n            engine.reset_errors(job_id)\n            result = {\"status\": \"OK\"}\n        else:\n            result = {\"error\": \"invalid topic {}\".format(req.topic)}\n\n        if not isinstance(result, dict):\n            result = {}\n\n        result = json.dumps(result)\n        return Message(topic=\"reply_\" + req.topic, body=result)",
  "class ClientAuxRunner(AuxRunner):\n    \"\"\"ClientAuxRunner to send the aux messages to the server.\n\n    Note: The ClientEngine must create a new ClientAuxRunner object for each RUN, and make sure\n    it is added as an event handler!\n\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"To init the ClientAuxRunner.\"\"\"\n        AuxRunner.__init__(self)\n        self.abort_signal = None\n        self.sender = None\n        self.asked_to_stop = False\n        self.engine = None\n        self.fnf_requests = []\n        self.fnf_lock = threading.Lock()\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        AuxRunner.handle_event(self, event_type, fl_ctx)\n        if event_type == EventType.START_RUN:\n            self.engine = fl_ctx.get_engine()\n            self.abort_signal = fl_ctx.get_run_abort_signal()\n            self.sender = threading.Thread(target=self._send_fnf_requests, args=())\n            self.sender.start()\n        elif event_type == EventType.END_RUN:\n            self.asked_to_stop = True\n            if self.sender and self.sender.is_alive():\n                self.sender.join()\n\n    def send_aux_request(self, topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> Shareable:\n        if not isinstance(topic, str):\n            raise TypeError(\"invalid topic: expects str but got {}\".format(type(topic)))\n\n        if not topic:\n            raise ValueError(\"invalid topic: must not be empty\")\n\n        if topic == self.TOPIC_BULK:\n            raise ValueError('topic value \"{}\" is reserved'.format(topic))\n\n        if not isinstance(timeout, float):\n            raise TypeError(\"invalid timeout: expects float but got {}\".format(type(timeout)))\n\n        if timeout < 0:\n            raise ValueError(\"invalid timeout value {}: must >= 0.0\".format(timeout))\n\n        if not isinstance(fl_ctx, FLContext):\n            raise TypeError(\"fl_ctx must be FLContext but got {}\".format(type(fl_ctx)))\n\n        req_to_send = request\n        req_to_send.set_header(ReservedHeaderKey.TOPIC, topic)\n        req_to_send.set_peer_props(fl_ctx.get_all_public_props())\n\n        if timeout <= 0.0:\n            # this is fire-and-forget request\n            with self.fnf_lock:\n                self.fnf_requests.append(req_to_send)\n            return make_reply(ReturnCode.OK)\n\n        # send regular request\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ClientEngineExecutorSpec):\n            raise TypeError(\"engine must be ClientEngineExecutorSpec, but got {}\".format(type(engine)))\n\n        reply = engine.aux_send(topic=topic, request=req_to_send, timeout=timeout, fl_ctx=fl_ctx)\n\n        # check whether the RUN should be aborted\n        if not isinstance(reply, Shareable):\n            self.log_error(fl_ctx, \"bad reply from peer: expect Shareable but got {}\".format(type(reply)))\n            return make_reply(ReturnCode.ERROR)\n\n        rc = reply.get_return_code()\n        if rc == ReturnCode.RUN_MISMATCH:\n            self.log_info(fl_ctx, \"got RUN_MISMATCH - asked engine to abort app\")\n            engine.abort_app(job_id=self.run_num, fl_ctx=fl_ctx)\n\n        return reply\n\n    def _send_fnf_requests(self):\n        topic = self.TOPIC_BULK\n        sleep_time = 0.5\n        while True:\n            time.sleep(sleep_time)\n            if self.abort_signal.triggered:\n                break\n\n            if len(self.fnf_requests) <= 0:\n                if self.asked_to_stop:\n                    break\n                else:\n                    sleep_time = 1.0\n                    continue\n\n            with self.engine.new_context() as fl_ctx:\n                bulk = Shareable()\n                bulk.set_header(ReservedHeaderKey.TOPIC, topic)\n                bulk.set_peer_props(fl_ctx.get_all_public_props())\n                with self.fnf_lock:\n                    bulk[self.DATA_KEY_BULK] = self.fnf_requests\n                    reply = self.engine.aux_send(topic=topic, request=bulk, timeout=15.0, fl_ctx=fl_ctx)\n                    rc = reply.get_return_code()\n                    if rc != ReturnCode.COMMUNICATION_ERROR:\n                        # if communication error we'll retry\n                        self.fnf_requests = []\n            sleep_time = 0.5",
  "def __init__(self):\n        \"\"\"To init the ClientAuxRunner.\"\"\"\n        AuxRunner.__init__(self)\n        self.abort_signal = None\n        self.sender = None\n        self.asked_to_stop = False\n        self.engine = None\n        self.fnf_requests = []\n        self.fnf_lock = threading.Lock()",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        AuxRunner.handle_event(self, event_type, fl_ctx)\n        if event_type == EventType.START_RUN:\n            self.engine = fl_ctx.get_engine()\n            self.abort_signal = fl_ctx.get_run_abort_signal()\n            self.sender = threading.Thread(target=self._send_fnf_requests, args=())\n            self.sender.start()\n        elif event_type == EventType.END_RUN:\n            self.asked_to_stop = True\n            if self.sender and self.sender.is_alive():\n                self.sender.join()",
  "def send_aux_request(self, topic: str, request: Shareable, timeout: float, fl_ctx: FLContext) -> Shareable:\n        if not isinstance(topic, str):\n            raise TypeError(\"invalid topic: expects str but got {}\".format(type(topic)))\n\n        if not topic:\n            raise ValueError(\"invalid topic: must not be empty\")\n\n        if topic == self.TOPIC_BULK:\n            raise ValueError('topic value \"{}\" is reserved'.format(topic))\n\n        if not isinstance(timeout, float):\n            raise TypeError(\"invalid timeout: expects float but got {}\".format(type(timeout)))\n\n        if timeout < 0:\n            raise ValueError(\"invalid timeout value {}: must >= 0.0\".format(timeout))\n\n        if not isinstance(fl_ctx, FLContext):\n            raise TypeError(\"fl_ctx must be FLContext but got {}\".format(type(fl_ctx)))\n\n        req_to_send = request\n        req_to_send.set_header(ReservedHeaderKey.TOPIC, topic)\n        req_to_send.set_peer_props(fl_ctx.get_all_public_props())\n\n        if timeout <= 0.0:\n            # this is fire-and-forget request\n            with self.fnf_lock:\n                self.fnf_requests.append(req_to_send)\n            return make_reply(ReturnCode.OK)\n\n        # send regular request\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ClientEngineExecutorSpec):\n            raise TypeError(\"engine must be ClientEngineExecutorSpec, but got {}\".format(type(engine)))\n\n        reply = engine.aux_send(topic=topic, request=req_to_send, timeout=timeout, fl_ctx=fl_ctx)\n\n        # check whether the RUN should be aborted\n        if not isinstance(reply, Shareable):\n            self.log_error(fl_ctx, \"bad reply from peer: expect Shareable but got {}\".format(type(reply)))\n            return make_reply(ReturnCode.ERROR)\n\n        rc = reply.get_return_code()\n        if rc == ReturnCode.RUN_MISMATCH:\n            self.log_info(fl_ctx, \"got RUN_MISMATCH - asked engine to abort app\")\n            engine.abort_app(job_id=self.run_num, fl_ctx=fl_ctx)\n\n        return reply",
  "def _send_fnf_requests(self):\n        topic = self.TOPIC_BULK\n        sleep_time = 0.5\n        while True:\n            time.sleep(sleep_time)\n            if self.abort_signal.triggered:\n                break\n\n            if len(self.fnf_requests) <= 0:\n                if self.asked_to_stop:\n                    break\n                else:\n                    sleep_time = 1.0\n                    continue\n\n            with self.engine.new_context() as fl_ctx:\n                bulk = Shareable()\n                bulk.set_header(ReservedHeaderKey.TOPIC, topic)\n                bulk.set_peer_props(fl_ctx.get_all_public_props())\n                with self.fnf_lock:\n                    bulk[self.DATA_KEY_BULK] = self.fnf_requests\n                    reply = self.engine.aux_send(topic=topic, request=bulk, timeout=15.0, fl_ctx=fl_ctx)\n                    rc = reply.get_return_code()\n                    if rc != ReturnCode.COMMUNICATION_ERROR:\n                        # if communication error we'll retry\n                        self.fnf_requests = []\n            sleep_time = 0.5",
  "class ClientEngineInternalSpec(ClientEngineSpec, ABC):\n    \"\"\"The ClientEngineInternalSpec defines the ClientEngine APIs running in the parent process.\"\"\"\n\n    def get_task_assignment(self, fl_ctx: FLContext) -> TaskAssignment:\n        pass\n\n    def send_task_result(self, result: Shareable, fl_ctx: FLContext) -> bool:\n        pass\n\n    def get_workspace(self) -> Workspace:\n        pass\n\n    def get_all_components(self) -> dict:\n        pass\n\n    @abstractmethod\n    def get_engine_status(self):\n        pass\n\n    @abstractmethod\n    def get_client_name(self) -> str:\n        \"\"\"Get the ClientEngine client_name.\n\n        Returns: the client_name\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def deploy_app(self, app_name: str, job_id: str, client_name: str, app_data) -> str:\n        \"\"\"Deploys the app to specified run.\n\n        Args:\n            app_name: FL_app name\n            job_id: job that the app is to be deployed to\n            client_name: name of the client\n            app_data: zip data of the app\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def start_app(\n        self,\n        job_id: str,\n        allocated_resource: dict = None,\n        token: str = None,\n        resource_consumer=None,\n        resource_manager=None,\n    ) -> str:\n        \"\"\"Starts the app for the specified run.\n\n        Args:\n            job_id: job_id\n            allocated_resource: allocated resource\n            token: token\n            resource_consumer: resource consumer\n            resource_manager: resource manager\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def abort_app(self, job_id: str) -> str:\n        \"\"\"Aborts the app execution for the specified run.\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def abort_task(self, job_id: str) -> str:\n        \"\"\"Abort the client current executing task.\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_run(self, job_id: str) -> str:\n        \"\"\"Deletes the specified run.\n\n        Args:\n            job_id: job_id\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def shutdown(self) -> str:\n        \"\"\"Shuts down the FL client.\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def restart(self) -> str:\n        \"\"\"Restarts the FL client.\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_all_job_ids(self) -> []:\n        \"\"\"Get all the client job_id.\n\n        Returns: list of all the job_id\n\n        \"\"\"\n        pass",
  "def get_task_assignment(self, fl_ctx: FLContext) -> TaskAssignment:\n        pass",
  "def send_task_result(self, result: Shareable, fl_ctx: FLContext) -> bool:\n        pass",
  "def get_workspace(self) -> Workspace:\n        pass",
  "def get_all_components(self) -> dict:\n        pass",
  "def get_engine_status(self):\n        pass",
  "def get_client_name(self) -> str:\n        \"\"\"Get the ClientEngine client_name.\n\n        Returns: the client_name\n\n        \"\"\"\n        pass",
  "def deploy_app(self, app_name: str, job_id: str, client_name: str, app_data) -> str:\n        \"\"\"Deploys the app to specified run.\n\n        Args:\n            app_name: FL_app name\n            job_id: job that the app is to be deployed to\n            client_name: name of the client\n            app_data: zip data of the app\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass",
  "def start_app(\n        self,\n        job_id: str,\n        allocated_resource: dict = None,\n        token: str = None,\n        resource_consumer=None,\n        resource_manager=None,\n    ) -> str:\n        \"\"\"Starts the app for the specified run.\n\n        Args:\n            job_id: job_id\n            allocated_resource: allocated resource\n            token: token\n            resource_consumer: resource consumer\n            resource_manager: resource manager\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass",
  "def abort_app(self, job_id: str) -> str:\n        \"\"\"Aborts the app execution for the specified run.\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass",
  "def abort_task(self, job_id: str) -> str:\n        \"\"\"Abort the client current executing task.\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass",
  "def delete_run(self, job_id: str) -> str:\n        \"\"\"Deletes the specified run.\n\n        Args:\n            job_id: job_id\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass",
  "def shutdown(self) -> str:\n        \"\"\"Shuts down the FL client.\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass",
  "def restart(self) -> str:\n        \"\"\"Restarts the FL client.\n\n        Returns:\n            A string message.\n        \"\"\"\n        pass",
  "def get_all_job_ids(self) -> []:\n        \"\"\"Get all the client job_id.\n\n        Returns: list of all the job_id\n\n        \"\"\"\n        pass",
  "class CommandProcessor(object):\n    \"\"\"The CommandProcessor is responsible for processing a command from parent process.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"Get command name that this processor will handle.\n\n        Returns: name of the command\n\n        \"\"\"\n        pass\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the specified command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Return: reply message\n\n        \"\"\"\n        pass",
  "class CheckStatusCommand(CommandProcessor):\n    \"\"\"To implement the check_status command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get thee command name.\n\n        Returns: AdminCommandNames.CHECK_STATUSv\n\n        \"\"\"\n        return AdminCommandNames.CHECK_STATUS\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the check_status command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: status message\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        federated_client = engine.client\n        return get_status_message(federated_client.status)",
  "class AbortCommand(CommandProcessor):\n    \"\"\"To implement the abort command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.ABORT\n\n        \"\"\"\n        return AdminCommandNames.ABORT\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: abort command message\n\n        \"\"\"\n        client_runner = fl_ctx.get_prop(FLContextKey.RUNNER)\n        return client_runner.abort()",
  "class AbortTaskCommand(CommandProcessor):\n    \"\"\"To implement the abort_task command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.ABORT_TASK\n\n        \"\"\"\n        return AdminCommandNames.ABORT_TASK\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort_task command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: abort_task command message\n\n        \"\"\"\n        client_runner = fl_ctx.get_prop(FLContextKey.RUNNER)\n        if client_runner:\n            client_runner.abort_task()\n        return None",
  "class ShowStatsCommand(CommandProcessor):\n    \"\"\"To implement the show_stats command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.SHOW_STATS\n\n        \"\"\"\n        return AdminCommandNames.SHOW_STATS\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort_task command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: show_stats command message\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        collector = engine.get_widget(WidgetID.INFO_COLLECTOR)\n        if not collector:\n            result = {\"error\": \"no info collector\"}\n        else:\n            if not isinstance(collector, InfoCollector):\n                raise TypeError(\"collector must be an instance of InfoCollector, but got {}\".format(type(collector)))\n\n            result = collector.get_run_stats()\n\n        if not result:\n            result = \"No stats info\"\n        return result",
  "class ShowErrorsCommand(CommandProcessor):\n    \"\"\"To implement the show_errors command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.SHOW_ERRORS\n\n        \"\"\"\n        return AdminCommandNames.SHOW_ERRORS\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the show_errors command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: show_errors command message\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        collector = engine.get_widget(WidgetID.INFO_COLLECTOR)\n        if not collector:\n            result = {\"error\": \"no info collector\"}\n        else:\n            if not isinstance(collector, InfoCollector):\n                raise TypeError(\"collector must be an instance of InfoCollector, but got {}\".format(type(collector)))\n\n            result = collector.get_errors()\n\n        # CommandAgent is expecting data, could not be None\n        if result is None:\n            result = \"No Errors\"\n        return result",
  "class ResetErrorsCommand(CommandProcessor):\n    \"\"\"To implement the reset_errors command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.RESET_ERRORS\n\n        \"\"\"\n        return AdminCommandNames.RESET_ERRORS\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the reset_errors command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: reset_errors command message\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        engine.reset_errors()",
  "class AuxCommand(CommandProcessor):\n    \"\"\"To implement the Aux communication command.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.AUX_COMMAND\n\n        \"\"\"\n        return AdminCommandNames.AUX_COMMAND\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the Aux communication command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: Aux communication command message\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n\n        topic = data.get_header(ReservedHeaderKey.TOPIC)\n        return engine.dispatch(topic=topic, request=data, fl_ctx=fl_ctx)",
  "class ByeCommand(CommandProcessor):\n    \"\"\"To implement the ShutdownCommand.\"\"\"\n\n    def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.SHUTDOWN\n\n        \"\"\"\n        return AdminCommandNames.SHUTDOWN\n\n    def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the Shutdown command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: Shutdown command message\n\n        \"\"\"\n        return None",
  "class AdminCommands(object):\n    \"\"\"AdminCommands contains all the commands for processing the commands from the parent process.\"\"\"\n\n    commands = [\n        CheckStatusCommand(),\n        AbortCommand(),\n        AbortTaskCommand(),\n        ByeCommand(),\n        ShowStatsCommand(),\n        ShowErrorsCommand(),\n        ResetErrorsCommand(),\n        AuxCommand(),\n    ]\n\n    @staticmethod\n    def get_command(command_name):\n        \"\"\"Call to return the AdminCommand object.\n\n        Args:\n            command_name: AdminCommand name\n\n        Returns: AdminCommand object\n\n        \"\"\"\n        for command in AdminCommands.commands:\n            if command_name == command.get_command_name():\n                return command\n        return None\n\n    @staticmethod\n    def register_command(command_processor: CommandProcessor):\n        \"\"\"Call to register the AdminCommand processor.\n\n        Args:\n            command_processor: AdminCommand processor\n\n        \"\"\"\n        if not isinstance(command_processor, CommandProcessor):\n            raise TypeError(\n                \"command_processor must be an instance of CommandProcessor, but got {}\".format(type(command_processor))\n            )\n\n        AdminCommands.commands.append(command_processor)",
  "def get_command_name(self) -> str:\n        \"\"\"Get command name that this processor will handle.\n\n        Returns: name of the command\n\n        \"\"\"\n        pass",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the specified command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Return: reply message\n\n        \"\"\"\n        pass",
  "def get_command_name(self) -> str:\n        \"\"\"To get thee command name.\n\n        Returns: AdminCommandNames.CHECK_STATUSv\n\n        \"\"\"\n        return AdminCommandNames.CHECK_STATUS",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the check_status command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: status message\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        federated_client = engine.client\n        return get_status_message(federated_client.status)",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.ABORT\n\n        \"\"\"\n        return AdminCommandNames.ABORT",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: abort command message\n\n        \"\"\"\n        client_runner = fl_ctx.get_prop(FLContextKey.RUNNER)\n        return client_runner.abort()",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.ABORT_TASK\n\n        \"\"\"\n        return AdminCommandNames.ABORT_TASK",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort_task command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: abort_task command message\n\n        \"\"\"\n        client_runner = fl_ctx.get_prop(FLContextKey.RUNNER)\n        if client_runner:\n            client_runner.abort_task()\n        return None",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.SHOW_STATS\n\n        \"\"\"\n        return AdminCommandNames.SHOW_STATS",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the abort_task command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: show_stats command message\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        collector = engine.get_widget(WidgetID.INFO_COLLECTOR)\n        if not collector:\n            result = {\"error\": \"no info collector\"}\n        else:\n            if not isinstance(collector, InfoCollector):\n                raise TypeError(\"collector must be an instance of InfoCollector, but got {}\".format(type(collector)))\n\n            result = collector.get_run_stats()\n\n        if not result:\n            result = \"No stats info\"\n        return result",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.SHOW_ERRORS\n\n        \"\"\"\n        return AdminCommandNames.SHOW_ERRORS",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the show_errors command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: show_errors command message\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        collector = engine.get_widget(WidgetID.INFO_COLLECTOR)\n        if not collector:\n            result = {\"error\": \"no info collector\"}\n        else:\n            if not isinstance(collector, InfoCollector):\n                raise TypeError(\"collector must be an instance of InfoCollector, but got {}\".format(type(collector)))\n\n            result = collector.get_errors()\n\n        # CommandAgent is expecting data, could not be None\n        if result is None:\n            result = \"No Errors\"\n        return result",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.RESET_ERRORS\n\n        \"\"\"\n        return AdminCommandNames.RESET_ERRORS",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the reset_errors command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: reset_errors command message\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        engine.reset_errors()",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.AUX_COMMAND\n\n        \"\"\"\n        return AdminCommandNames.AUX_COMMAND",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the Aux communication command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: Aux communication command message\n\n        \"\"\"\n        engine = fl_ctx.get_engine()\n\n        topic = data.get_header(ReservedHeaderKey.TOPIC)\n        return engine.dispatch(topic=topic, request=data, fl_ctx=fl_ctx)",
  "def get_command_name(self) -> str:\n        \"\"\"To get the command name.\n\n        Returns: AdminCommandNames.SHUTDOWN\n\n        \"\"\"\n        return AdminCommandNames.SHUTDOWN",
  "def process(self, data: Shareable, fl_ctx: FLContext):\n        \"\"\"Called to process the Shutdown command.\n\n        Args:\n            data: process data\n            fl_ctx: FLContext\n\n        Returns: Shutdown command message\n\n        \"\"\"\n        return None",
  "def get_command(command_name):\n        \"\"\"Call to return the AdminCommand object.\n\n        Args:\n            command_name: AdminCommand name\n\n        Returns: AdminCommand object\n\n        \"\"\"\n        for command in AdminCommands.commands:\n            if command_name == command.get_command_name():\n                return command\n        return None",
  "def register_command(command_processor: CommandProcessor):\n        \"\"\"Call to register the AdminCommand processor.\n\n        Args:\n            command_processor: AdminCommand processor\n\n        \"\"\"\n        if not isinstance(command_processor, CommandProcessor):\n            raise TypeError(\n                \"command_processor must be an instance of CommandProcessor, but got {}\".format(type(command_processor))\n            )\n\n        AdminCommands.commands.append(command_processor)",
  "class ValidateRequestProcessor(RequestProcessor):\n    def get_topics(self) -> [str]:\n        return [\"validate\"]\n\n    def process(self, req: Message, app_ctx) -> Message:\n        cai = app_ctx\n\n        result = cai.do_validate(req)\n        message = Message(topic=\"reply_\" + req.topic, body=result)\n        return message",
  "def get_topics(self) -> [str]:\n        return [\"validate\"]",
  "def process(self, req: Message, app_ctx) -> Message:\n        cai = app_ctx\n\n        result = cai.do_validate(req)\n        message = Message(topic=\"reply_\" + req.topic, body=result)\n        return message",
  "class FederatedClientBase:\n    \"\"\"The client-side base implementation of federated learning.\n\n    This class provide the tools function which will be used in both FedClient and FedClientLite.\n    \"\"\"\n\n    def __init__(\n        self,\n        client_name,\n        client_args,\n        secure_train,\n        server_args=None,\n        retry_timeout=30,\n        client_state_processors: Optional[List[Filter]] = None,\n        handlers: Optional[List[FLComponent]] = None,\n        compression=None,\n        overseer_agent=None,\n        args=None,\n        components=None,\n    ):\n        \"\"\"To init FederatedClientBase.\n\n        Args:\n            client_name: client name\n            client_args: client config args\n            secure_train: True/False to indicate secure train\n            server_args: server config args\n            retry_timeout: retry timeout\n            client_state_processors: client state processor filters\n            handlers: handlers\n            compression: communication compression algorithm\n        \"\"\"\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n        self.client_name = client_name\n        self.token = None\n        self.ssid = None\n        self.client_args = client_args\n        self.servers = server_args\n\n        self.communicator = Communicator(\n            ssl_args=client_args,\n            secure_train=secure_train,\n            retry_timeout=retry_timeout,\n            client_state_processors=client_state_processors,\n            compression=compression,\n        )\n\n        self.secure_train = secure_train\n        self.handlers = handlers\n        self.components = components\n\n        self.heartbeat_done = False\n        self.fl_ctx = FLContext()\n        self.platform = None\n        self.abort_signal = Signal()\n        self.engine = None\n\n        self.status = ClientStatus.NOT_STARTED\n        self.remote_tasks = None\n\n        self.sp_established = False\n        self.overseer_agent = overseer_agent\n\n        self.overseer_agent = self._init_agent(args)\n\n        if secure_train:\n            if self.overseer_agent:\n                self.overseer_agent.set_secure_context(\n                    ca_path=client_args[\"ssl_root_cert\"],\n                    cert_path=client_args[\"ssl_cert\"],\n                    prv_key_path=client_args[\"ssl_private_key\"],\n                )\n\n        self.overseer_agent.start(self.overseer_callback)\n\n    def _init_agent(self, args=None):\n        kv_list = parse_vars(args.set)\n        sp = kv_list.get(\"sp\")\n\n        if sp:\n            fl_ctx = FLContext()\n            fl_ctx.set_prop(FLContextKey.SP_END_POINT, sp)\n            self.overseer_agent.initialize(fl_ctx)\n\n        return self.overseer_agent\n\n    def overseer_callback(self, overseer_agent):\n        if overseer_agent.is_shutdown():\n            self.engine.shutdown()\n            return\n\n        sp = overseer_agent.get_primary_sp()\n        self.set_primary_sp(sp)\n\n    def set_sp(self, project_name, sp: SP):\n        if sp and sp.primary is True:\n            server = self.servers[project_name].get(\"target\")\n            location = sp.name + \":\" + sp.fl_port\n            if server != location:\n                self.servers[project_name][\"target\"] = location\n                self.sp_established = True\n                self.logger.info(f\"Got the new primary SP: {location}\")\n\n            if self.ssid and self.ssid != sp.service_session_id:\n                self.ssid = sp.service_session_id\n                thread = threading.Thread(target=self._switch_ssid)\n                thread.start()\n\n    def _switch_ssid(self):\n        if self.engine:\n            for job_id in self.engine.get_all_job_ids():\n                self.engine.abort_task(job_id)\n        # self.register()\n        self.logger.info(f\"Primary SP switched to new SSID: {self.ssid}\")\n\n    def client_register(self, project_name):\n        \"\"\"Register the client to the FL server.\n\n        Args:\n            project_name: FL study project name.\n        \"\"\"\n        if not self.token:\n            try:\n                self.token, self.ssid = self.communicator.client_registration(\n                    self.client_name, self.servers, project_name\n                )\n                if self.token is not None:\n                    self.fl_ctx.set_prop(FLContextKey.CLIENT_NAME, self.client_name, private=False)\n                    self.fl_ctx.set_prop(EngineConstant.FL_TOKEN, self.token, private=False)\n                    self.logger.info(\n                        \"Successfully registered client:{} for project {}. Token:{} SSID:{}\".format(\n                            self.client_name, project_name, self.token, self.ssid\n                        )\n                    )\n\n            except FLCommunicationError:\n                self.communicator.heartbeat_done = True\n\n    def fetch_execute_task(self, project_name, fl_ctx: FLContext):\n        \"\"\"Fetch a task from the server.\n\n        Args:\n            project_name: FL study project name\n            fl_ctx: FLContext\n\n        Returns:\n            A CurrentTask message from server\n        \"\"\"\n        try:\n            self.logger.debug(\"Starting to fetch execute task.\")\n            task = self.communicator.getTask(self.servers, project_name, self.token, self.ssid, fl_ctx)\n\n            return task\n        except FLCommunicationError as e:\n            self.logger.info(e)\n\n    def push_execute_result(self, project_name, shareable: Shareable, fl_ctx: FLContext):\n        \"\"\"Submit execution results of a task to server.\n\n        Args:\n            project_name: FL study project name\n            shareable: Shareable object\n            fl_ctx: FLContext\n\n        Returns:\n            A FederatedSummary message from the server.\n        \"\"\"\n        try:\n            self.logger.info(\"Starting to push execute result.\")\n            execute_task_name = fl_ctx.get_prop(FLContextKey.TASK_NAME)\n            message = self.communicator.submitUpdate(\n                self.servers,\n                project_name,\n                self.token,\n                self.ssid,\n                fl_ctx,\n                self.client_name,\n                shareable,\n                execute_task_name,\n            )\n\n            return message\n        except FLCommunicationError as e:\n            self.logger.info(e)\n\n    def send_aux_message(self, project_name, topic: str, shareable: Shareable, timeout: float, fl_ctx: FLContext):\n        \"\"\"Send auxiliary message to the server.\n\n        Args:\n            project_name: FL study project name\n            topic: aux topic name\n            shareable: Shareable object\n            timeout: communication timeout\n            fl_ctx: FLContext\n\n        Returns:\n            A reply message\n        \"\"\"\n        try:\n            self.logger.debug(\"Starting to send aux message.\")\n            message = self.communicator.auxCommunicate(\n                self.servers, project_name, self.token, self.ssid, fl_ctx, self.client_name, shareable, topic, timeout\n            )\n\n            return message\n        except FLCommunicationError as e:\n            self.logger.info(e)\n\n    def send_heartbeat(self, project_name):\n        try:\n            if self.token:\n                while not self.engine:\n                    time.sleep(1.0)\n                self.communicator.send_heartbeat(\n                    self.servers, project_name, self.token, self.ssid, self.client_name, self.engine\n                )\n        except FLCommunicationError as e:\n            self.communicator.heartbeat_done = True\n\n    def heartbeat(self):\n        \"\"\"Sends a heartbeat from the client to the server.\"\"\"\n        pool = None\n        try:\n            pool = ThreadPool(len(self.servers))\n            return pool.map(self.send_heartbeat, tuple(self.servers))\n        finally:\n            if pool:\n                pool.terminate()\n\n    def pull_task(self, fl_ctx: FLContext):\n        \"\"\"Fetch remote models and update the local client's session.\"\"\"\n        pool = None\n        try:\n            pool = ThreadPool(len(self.servers))\n            self.remote_tasks = pool.map(partial(self.fetch_execute_task, fl_ctx=fl_ctx), tuple(self.servers))\n            pull_success, task_name = self.check_progress(self.remote_tasks)\n            # # Update app_ctx's current round info\n            # if self.app_context and self.remote_models[0] is not None:\n            #     self.app_context.global_round = self.remote_models[0].meta.current_round\n            # TODO: if some of the servers failed\n            # return self.model_manager.assign_current_model(self.remote_models)\n            return pull_success, task_name, self.remote_tasks\n        finally:\n            if pool:\n                pool.terminate()\n\n    def push_results(self, shareable: Shareable, fl_ctx: FLContext):\n        \"\"\"Push the local model to multiple servers.\"\"\"\n        pool = None\n        try:\n            pool = ThreadPool(len(self.servers))\n            return pool.map(partial(self.push_execute_result, shareable=shareable, fl_ctx=fl_ctx), tuple(self.servers))\n        finally:\n            if pool:\n                pool.terminate()\n\n    def aux_send(self, topic, shareable: Shareable, timeout: float, fl_ctx: FLContext):\n        \"\"\"Push the local model to multiple servers.\"\"\"\n        pool = None\n        try:\n            pool = ThreadPool(len(self.servers))\n            messages = pool.map(\n                partial(self.send_aux_message, topic=topic, shareable=shareable, timeout=timeout, fl_ctx=fl_ctx),\n                tuple(self.servers),\n            )\n            if messages is not None and messages[0] is not None:\n                # Only handle single server communication for now.\n                return messages\n            else:\n                return None\n        finally:\n            if pool:\n                pool.terminate()\n\n    def register(self):\n        \"\"\"Push the local model to multiple servers.\"\"\"\n        pool = None\n        try:\n            pool = ThreadPool(len(self.servers))\n            return pool.map(self.client_register, tuple(self.servers))\n        finally:\n            if pool:\n                pool.terminate()\n\n    def set_primary_sp(self, sp):\n        pool = None\n        try:\n            pool = ThreadPool(len(self.servers))\n            return pool.map(partial(self.set_sp, sp=sp), tuple(self.servers))\n        finally:\n            if pool:\n                pool.terminate()\n\n    def run_heartbeat(self):\n        \"\"\"Periodically runs the heartbeat.\"\"\"\n        self.heartbeat()\n\n    def start_heartbeat(self):\n        heartbeat_thread = threading.Thread(target=self.run_heartbeat)\n        heartbeat_thread.start()\n\n    def quit_remote(self, task_name, fl_ctx: FLContext):\n        \"\"\"Sending the last message to the server before leaving.\n\n        Args:\n            task_name: task name\n            fl_ctx: FLContext\n\n        Returns: N/A\n\n        \"\"\"\n        return self.communicator.quit_remote(self.servers, task_name, self.token, self.ssid, fl_ctx)\n\n    def set_client_engine(self, engine):\n        self.engine = engine\n\n    def close(self):\n        \"\"\"Quit the remote federated server, close the local session.\"\"\"\n        self.logger.info(\"Shutting down client\")\n        self.overseer_agent.end()\n\n        return 0\n\n    def check_progress(self, remote_tasks):\n        if remote_tasks[0] is not None:\n            self.server_meta = remote_tasks[0].meta\n            return True, remote_tasks[0].task_name\n        else:\n            return False, None",
  "def __init__(\n        self,\n        client_name,\n        client_args,\n        secure_train,\n        server_args=None,\n        retry_timeout=30,\n        client_state_processors: Optional[List[Filter]] = None,\n        handlers: Optional[List[FLComponent]] = None,\n        compression=None,\n        overseer_agent=None,\n        args=None,\n        components=None,\n    ):\n        \"\"\"To init FederatedClientBase.\n\n        Args:\n            client_name: client name\n            client_args: client config args\n            secure_train: True/False to indicate secure train\n            server_args: server config args\n            retry_timeout: retry timeout\n            client_state_processors: client state processor filters\n            handlers: handlers\n            compression: communication compression algorithm\n        \"\"\"\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n        self.client_name = client_name\n        self.token = None\n        self.ssid = None\n        self.client_args = client_args\n        self.servers = server_args\n\n        self.communicator = Communicator(\n            ssl_args=client_args,\n            secure_train=secure_train,\n            retry_timeout=retry_timeout,\n            client_state_processors=client_state_processors,\n            compression=compression,\n        )\n\n        self.secure_train = secure_train\n        self.handlers = handlers\n        self.components = components\n\n        self.heartbeat_done = False\n        self.fl_ctx = FLContext()\n        self.platform = None\n        self.abort_signal = Signal()\n        self.engine = None\n\n        self.status = ClientStatus.NOT_STARTED\n        self.remote_tasks = None\n\n        self.sp_established = False\n        self.overseer_agent = overseer_agent\n\n        self.overseer_agent = self._init_agent(args)\n\n        if secure_train:\n            if self.overseer_agent:\n                self.overseer_agent.set_secure_context(\n                    ca_path=client_args[\"ssl_root_cert\"],\n                    cert_path=client_args[\"ssl_cert\"],\n                    prv_key_path=client_args[\"ssl_private_key\"],\n                )\n\n        self.overseer_agent.start(self.overseer_callback)",
  "def _init_agent(self, args=None):\n        kv_list = parse_vars(args.set)\n        sp = kv_list.get(\"sp\")\n\n        if sp:\n            fl_ctx = FLContext()\n            fl_ctx.set_prop(FLContextKey.SP_END_POINT, sp)\n            self.overseer_agent.initialize(fl_ctx)\n\n        return self.overseer_agent",
  "def overseer_callback(self, overseer_agent):\n        if overseer_agent.is_shutdown():\n            self.engine.shutdown()\n            return\n\n        sp = overseer_agent.get_primary_sp()\n        self.set_primary_sp(sp)",
  "def set_sp(self, project_name, sp: SP):\n        if sp and sp.primary is True:\n            server = self.servers[project_name].get(\"target\")\n            location = sp.name + \":\" + sp.fl_port\n            if server != location:\n                self.servers[project_name][\"target\"] = location\n                self.sp_established = True\n                self.logger.info(f\"Got the new primary SP: {location}\")\n\n            if self.ssid and self.ssid != sp.service_session_id:\n                self.ssid = sp.service_session_id\n                thread = threading.Thread(target=self._switch_ssid)\n                thread.start()",
  "def _switch_ssid(self):\n        if self.engine:\n            for job_id in self.engine.get_all_job_ids():\n                self.engine.abort_task(job_id)\n        # self.register()\n        self.logger.info(f\"Primary SP switched to new SSID: {self.ssid}\")",
  "def client_register(self, project_name):\n        \"\"\"Register the client to the FL server.\n\n        Args:\n            project_name: FL study project name.\n        \"\"\"\n        if not self.token:\n            try:\n                self.token, self.ssid = self.communicator.client_registration(\n                    self.client_name, self.servers, project_name\n                )\n                if self.token is not None:\n                    self.fl_ctx.set_prop(FLContextKey.CLIENT_NAME, self.client_name, private=False)\n                    self.fl_ctx.set_prop(EngineConstant.FL_TOKEN, self.token, private=False)\n                    self.logger.info(\n                        \"Successfully registered client:{} for project {}. Token:{} SSID:{}\".format(\n                            self.client_name, project_name, self.token, self.ssid\n                        )\n                    )\n\n            except FLCommunicationError:\n                self.communicator.heartbeat_done = True",
  "def fetch_execute_task(self, project_name, fl_ctx: FLContext):\n        \"\"\"Fetch a task from the server.\n\n        Args:\n            project_name: FL study project name\n            fl_ctx: FLContext\n\n        Returns:\n            A CurrentTask message from server\n        \"\"\"\n        try:\n            self.logger.debug(\"Starting to fetch execute task.\")\n            task = self.communicator.getTask(self.servers, project_name, self.token, self.ssid, fl_ctx)\n\n            return task\n        except FLCommunicationError as e:\n            self.logger.info(e)",
  "def push_execute_result(self, project_name, shareable: Shareable, fl_ctx: FLContext):\n        \"\"\"Submit execution results of a task to server.\n\n        Args:\n            project_name: FL study project name\n            shareable: Shareable object\n            fl_ctx: FLContext\n\n        Returns:\n            A FederatedSummary message from the server.\n        \"\"\"\n        try:\n            self.logger.info(\"Starting to push execute result.\")\n            execute_task_name = fl_ctx.get_prop(FLContextKey.TASK_NAME)\n            message = self.communicator.submitUpdate(\n                self.servers,\n                project_name,\n                self.token,\n                self.ssid,\n                fl_ctx,\n                self.client_name,\n                shareable,\n                execute_task_name,\n            )\n\n            return message\n        except FLCommunicationError as e:\n            self.logger.info(e)",
  "def send_aux_message(self, project_name, topic: str, shareable: Shareable, timeout: float, fl_ctx: FLContext):\n        \"\"\"Send auxiliary message to the server.\n\n        Args:\n            project_name: FL study project name\n            topic: aux topic name\n            shareable: Shareable object\n            timeout: communication timeout\n            fl_ctx: FLContext\n\n        Returns:\n            A reply message\n        \"\"\"\n        try:\n            self.logger.debug(\"Starting to send aux message.\")\n            message = self.communicator.auxCommunicate(\n                self.servers, project_name, self.token, self.ssid, fl_ctx, self.client_name, shareable, topic, timeout\n            )\n\n            return message\n        except FLCommunicationError as e:\n            self.logger.info(e)",
  "def send_heartbeat(self, project_name):\n        try:\n            if self.token:\n                while not self.engine:\n                    time.sleep(1.0)\n                self.communicator.send_heartbeat(\n                    self.servers, project_name, self.token, self.ssid, self.client_name, self.engine\n                )\n        except FLCommunicationError as e:\n            self.communicator.heartbeat_done = True",
  "def heartbeat(self):\n        \"\"\"Sends a heartbeat from the client to the server.\"\"\"\n        pool = None\n        try:\n            pool = ThreadPool(len(self.servers))\n            return pool.map(self.send_heartbeat, tuple(self.servers))\n        finally:\n            if pool:\n                pool.terminate()",
  "def pull_task(self, fl_ctx: FLContext):\n        \"\"\"Fetch remote models and update the local client's session.\"\"\"\n        pool = None\n        try:\n            pool = ThreadPool(len(self.servers))\n            self.remote_tasks = pool.map(partial(self.fetch_execute_task, fl_ctx=fl_ctx), tuple(self.servers))\n            pull_success, task_name = self.check_progress(self.remote_tasks)\n            # # Update app_ctx's current round info\n            # if self.app_context and self.remote_models[0] is not None:\n            #     self.app_context.global_round = self.remote_models[0].meta.current_round\n            # TODO: if some of the servers failed\n            # return self.model_manager.assign_current_model(self.remote_models)\n            return pull_success, task_name, self.remote_tasks\n        finally:\n            if pool:\n                pool.terminate()",
  "def push_results(self, shareable: Shareable, fl_ctx: FLContext):\n        \"\"\"Push the local model to multiple servers.\"\"\"\n        pool = None\n        try:\n            pool = ThreadPool(len(self.servers))\n            return pool.map(partial(self.push_execute_result, shareable=shareable, fl_ctx=fl_ctx), tuple(self.servers))\n        finally:\n            if pool:\n                pool.terminate()",
  "def aux_send(self, topic, shareable: Shareable, timeout: float, fl_ctx: FLContext):\n        \"\"\"Push the local model to multiple servers.\"\"\"\n        pool = None\n        try:\n            pool = ThreadPool(len(self.servers))\n            messages = pool.map(\n                partial(self.send_aux_message, topic=topic, shareable=shareable, timeout=timeout, fl_ctx=fl_ctx),\n                tuple(self.servers),\n            )\n            if messages is not None and messages[0] is not None:\n                # Only handle single server communication for now.\n                return messages\n            else:\n                return None\n        finally:\n            if pool:\n                pool.terminate()",
  "def register(self):\n        \"\"\"Push the local model to multiple servers.\"\"\"\n        pool = None\n        try:\n            pool = ThreadPool(len(self.servers))\n            return pool.map(self.client_register, tuple(self.servers))\n        finally:\n            if pool:\n                pool.terminate()",
  "def set_primary_sp(self, sp):\n        pool = None\n        try:\n            pool = ThreadPool(len(self.servers))\n            return pool.map(partial(self.set_sp, sp=sp), tuple(self.servers))\n        finally:\n            if pool:\n                pool.terminate()",
  "def run_heartbeat(self):\n        \"\"\"Periodically runs the heartbeat.\"\"\"\n        self.heartbeat()",
  "def start_heartbeat(self):\n        heartbeat_thread = threading.Thread(target=self.run_heartbeat)\n        heartbeat_thread.start()",
  "def quit_remote(self, task_name, fl_ctx: FLContext):\n        \"\"\"Sending the last message to the server before leaving.\n\n        Args:\n            task_name: task name\n            fl_ctx: FLContext\n\n        Returns: N/A\n\n        \"\"\"\n        return self.communicator.quit_remote(self.servers, task_name, self.token, self.ssid, fl_ctx)",
  "def set_client_engine(self, engine):\n        self.engine = engine",
  "def close(self):\n        \"\"\"Quit the remote federated server, close the local session.\"\"\"\n        self.logger.info(\"Shutting down client\")\n        self.overseer_agent.end()\n\n        return 0",
  "def check_progress(self, remote_tasks):\n        if remote_tasks[0] is not None:\n            self.server_meta = remote_tasks[0].meta\n            return True, remote_tasks[0].task_name\n        else:\n            return False, None",
  "class ModelDescriptor:\n    def __init__(self, name: str, location: str, model_format: str, props: dict = None) -> None:\n        \"\"\"The class to describe the model.\n\n        Args:\n            name: model name\n            location: model location\n            model_format: model format\n            props: additional properties of the model\n        \"\"\"\n        super().__init__()\n        self.name = name\n        self.location = location\n        self.model_format = model_format\n        self.props = props",
  "def __init__(self, name: str, location: str, model_format: str, props: dict = None) -> None:\n        \"\"\"The class to describe the model.\n\n        Args:\n            name: model name\n            location: model location\n            model_format: model format\n            props: additional properties of the model\n        \"\"\"\n        super().__init__()\n        self.name = name\n        self.location = location\n        self.model_format = model_format\n        self.props = props",
  "class ExecutorTasks:\n\n    TRAIN = \"train\"\n    VALIDATE = \"validate\"\n    CROSS_VALIDATION = \"__cross_validation\"\n    SUBMIT_BEST = \"__submit_best\"\n    REPORT_STATUS = \"report_status\"",
  "class AppConstants(object):\n\n    CONFIG_PATH = \"config_path\"\n    MODEL_NETWORK = \"model_network\"\n    MULTI_GPU = \"multi_gpu\"\n    TRAIN_CONTEXT = \"train_context\"\n    DEVICE = \"device\"\n    MODEL_NAME = \"model_name\"\n    MODEL_URL = \"model_url\"\n    START_ROUND = \"start_round\"\n    CURRENT_ROUND = \"current_round\"\n    CONTRIBUTION_ROUND = \"contribution_round\"\n    CONTRIBUTION_CLIENT = \"contribution_client\"\n    NUM_ROUNDS = \"num_rounds\"\n    WAIT_AFTER_MIN_CLIENTS = \"wait_after_min_clients\"\n\n    NUM_TOTAL_STEPS = \"num_total_steps\"  # TOTAL_STEPS\n    NUM_EPOCHS_CURRENT_ROUND = \"num_epochs_current_round\"  # CURRENT_EPOCHS\n    NUM_TOTAL_EPOCHS = \"num_total_epochs\"  # LOCAL_EPOCHS\n    LOCAL_EPOCHS = \"local_epochs\"\n\n    IS_FIRST_ROUND = \"is_first_round\"\n    MY_RANK = \"my_rank\"\n    INITIAL_LEARNING_RATE = \"initial_learning_rate\"\n    CURRENT_LEARNING_RATE = \"current_learning_rate\"\n    NUMBER_OF_GPUS = \"number_of_gpus\"\n    META_COOKIE = \"cookie\"\n    META_DATA = \"meta_data\"\n    GLOBAL_MODEL = \"global_model\"\n\n    IS_BEST = \"is_best\"\n    FAILURE = \"failure\"\n\n    LOG_DIR = \"model_log_dir\"\n    CKPT_PRELOAD_PATH = \"ckpt_preload_path\"\n\n    DXO = \"DXO\"\n\n    PHASE = \"_phase_\"\n    PHASE_INIT = \"_init_\"\n    PHASE_TRAIN = \"train\"\n    PHASE_MODEL_VALIDATION = \"model_validation\"\n    PHASE_FINISHED = \"_finished_\"\n\n    STATUS_WAIT = \"_wait_\"\n    STATUS_DONE = \"_done_\"\n    STATUS_TRAINING = \"_training_\"\n    STATUS_IDLE = \"_idle_\"\n\n    MODEL_LOAD_PATH = \"_model_load_path\"\n    MODEL_SAVE_PATH = \"_model_save_path\"\n    DEFAULT_MODEL_DIR = \"models\"\n\n    ROUND = \"_round_\"\n    MODEL_WEIGHTS = \"_model_weights_\"\n    AGGREGATION_RESULT = \"_aggregation_result\"\n    AGGREGATION_TRIGGERED = \"_aggregation_triggered\"\n    AGGREGATION_ACCEPTED = \"_aggregation_accepted\"\n    TRAIN_SHAREABLE = \"_train_shareable_\"\n    TRAINING_RESULT = \"_training_result_\"\n\n    SUBMIT_MODEL_FAILURE_REASON = \"_submit_model_failure_reason\"\n    CROSS_VAL_DIR = \"cross_site_val\"\n    CROSS_VAL_MODEL_DIR_NAME = \"model_shareables\"\n    CROSS_VAL_RESULTS_DIR_NAME = \"result_shareables\"\n    CROSS_VAL_MODEL_PATH = \"_cross_val_model_path_\"\n    CROSS_VAL_RESULTS_PATH = \"_cross_val_results_path_\"\n    RECEIVED_MODEL = \"_receive_model_\"\n    RECEIVED_MODEL_OWNER = \"_receive_model_owner_\"\n    MODEL_TO_VALIDATE = \"_model_to_validate_\"\n    DATA_CLIENT = \"_data_client_\"\n    VALIDATION_RESULT = \"_validation_result_\"\n\n    TASK_SUBMIT_MODEL = \"submit_model\"\n    TASK_VALIDATION = \"validate\"\n\n    CROSS_VAL_SERVER_MODEL = \"_cross_val_server_model_\"\n    CROSS_VAL_CLIENT_MODEL = \"_cross_val_client_model_\"\n    PARTICIPATING_CLIENTS = \"_particpating_clients_\"\n\n    MODEL_OWNER = \"_model_owner_\"\n\n    DEFAULT_FORMATTER_ID = \"formatter\"\n    DEFAULT_MODEL_LOCATOR_ID = \"model_locator\"\n\n    TASK_END_RUN = \"_end_run_\"\n    TASK_TRAIN = \"train\"\n\n    DEFAULT_AGGREGATOR_ID = \"aggregator\"\n    DEFAULT_PERSISTOR_ID = \"persistor\"\n    DEFAULT_SHAREABLE_GENERATOR_ID = \"shareable_generator\"\n\n    SUBMIT_MODEL_NAME = \"submit_model_name\"\n    VALIDATE_TYPE = \"_validate_type\"",
  "class EnvironmentKey(object):\n\n    CHECKPOINT_DIR = \"APP_CKPT_DIR\"\n    CHECKPOINT_FILE_NAME = \"APP_CKPT\"",
  "class DefaultCheckpointFileName(object):\n\n    GLOBAL_MODEL = \"FL_global_model.pt\"\n    BEST_GLOBAL_MODEL = \"best_FL_global_model.pt\"",
  "class ModelName(object):\n\n    BEST_MODEL = \"best_model\"\n    FINAL_MODEL = \"final_model\"",
  "class ModelFormat(object):\n\n    PT_CHECKPOINT = \"pt_checkpoint\"\n    TORCH_SCRIPT = \"torch_script\"\n    PT_ONNX = \"pt_onnx\"\n    TF_CHECKPOINT = \"tf_checkpoint\"\n    KERAS = \"keras_model\"",
  "class ValidateType(object):\n\n    BEFORE_TRAIN_VALIDATE = \"before_train_validate\"\n    MODEL_VALIDATE = \"model_validate\"",
  "class AlgorithmConstants(object):\n\n    SCAFFOLD_CTRL_DIFF = \"scaffold_c_diff\"\n    SCAFFOLD_CTRL_GLOBAL = \"scaffold_c_global\"\n    SCAFFOLD_CTRL_AGGREGATOR_ID = \"scaffold_ctrl_aggregator\"",
  "class AppEventType(object):\n    \"\"\"Defines application events.\"\"\"\n\n    START_ROUND = \"_start_round\"\n    END_ROUND = \"_end_round\"\n\n    BEFORE_AGGREGATION = \"_before_aggregation\"\n    END_AGGREGATION = \"_end_aggregation\"\n\n    SUBMIT_LOCAL_BEST_MODEL = \"_submit_local_best_model\"\n    SERVER_RECEIVE_BEST_MODEL = \"_server_receive_best_model\"\n    RECEIVE_VALIDATION_MODEL = \"_receive_validation_model\"\n    SEND_VALIDATION_RESULTS = \"_send_validation_results\"\n    RECEIVE_VALIDATION_RESULTS = \"_receive_validation_results\"\n\n    BEFORE_INITIALIZE = \"_before_initialize\"\n    AFTER_INITIALIZE = \"_after_initialize\"\n    BEFORE_TRAIN = \"_before_train\"\n    AFTER_TRAIN = \"_after_train\"\n\n    BEFORE_SHAREABLE_TO_LEARNABLE = \"_before_model_update\"\n    AFTER_SHAREABLE_TO_LEARNABLE = \"_after_model_update\"\n    BEFORE_LEARNABLE_PERSIST = \"_before_save_model\"\n    AFTER_LEARNABLE_PERSIST = \"_after_save_model\"\n    BEFORE_SEND_BEST_MODEL = \"_before_send_best_model\"\n    AFTER_SEND_BEST_MODEL = \"_after_send_best_model\"\n    LOCAL_BEST_MODEL_AVAILABLE = \"_local_best_model_available\"\n    GLOBAL_BEST_MODEL_AVAILABLE = \"_global_best_model_available\"\n    BEFORE_GET_VALIDATION_MODELS = \"_before_get_validation_models\"\n    AFTER_GET_VALIDATION_MODELS = \"_after_get_validation_models\"\n    SEND_MODEL_FOR_VALIDATION = \"_send_model_for_validation\"\n    BEFORE_VALIDATE_MODEL = \"_before_validate_model\"\n    AFTER_VALIDATE_MODEL = \"_after_validate_model\"\n    BEFORE_SUBMIT_VALIDATION_RESULTS = \"_before_submit_validation_results\"\n    AFTER_SUBMIT_VALIDATION_RESULTS = \"_after_submit_validation_results\"\n\n    # Events\n    ROUND_STARTED = \"_round_started\"\n    ROUND_DONE = \"_round_done\"\n    INITIAL_MODEL_LOADED = \"_initial_model_loaded\"\n    BEFORE_TRAIN_TASK = \"_before_train_task\"\n    RECEIVE_CONTRIBUTION = \"_receive_contribution\"\n    AFTER_CONTRIBUTION_ACCEPT = \"_after_contribution_accept\"\n    AFTER_AGGREGATION = \"_after_aggregation\"\n    BEFORE_CONTRIBUTION_ACCEPT = \"_before_contribution_accept\"\n    GLOBAL_WEIGHTS_UPDATED = \"_global_weights_updated\"\n    TRAINING_STARTED = \"_training_started\"\n    TRAINING_FINISHED = \"_training_finished\"\n    TRAIN_DONE = \"_train_done\"\n\n    CROSS_VAL_INIT = \"_cross_val_init\"\n    VALIDATION_RESULT_RECEIVED = \"_validation_result_received\"\n    RECEIVE_BEST_MODEL = \"_receive_best_model\"",
  "class PercentilePrivacy(Filter):\n    def __init__(self, percentile=10, gamma=0.01):\n        \"\"\"Implementation of \"largest percentile to share\" privacy preserving policy.\n\n        Shokri and Shmatikov, Privacy-preserving deep learning, CCS '15\n\n        Args:\n            percentile (int, optional): Only abs diff greater than this percentile is updated.\n              Allowed range 0..100.  Defaults to 10.\n            gamma (float, optional): The upper limit to truncate abs values of weight diff. Defaults to 0.01.  Any weight diff with abs<gamma will become 0.\n        \"\"\"\n        super().__init__()\n\n        # must be in 0..100, only update abs diff greater than percentile\n        self.percentile = percentile\n        # must be positive\n        self.gamma = gamma  # truncate absolute value of delta W\n\n    def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Compute the percentile on the abs delta_W.\n\n        Only share the params where absolute delta_W greater than\n        the percentile value\n\n        Args:\n            shareable: information from client\n            fl_ctx: context provided by workflow\n\n        Returns:\n            Shareable: a shareable containing the truncated weight diff\n        \"\"\"\n        self.log_debug(fl_ctx, \"inside filter\")\n\n        rc = shareable.get_return_code()\n        if rc != ReturnCode.OK:\n            # don't process if RC not OK\n            return shareable\n\n        try:\n            dxo = from_shareable(shareable)\n        except:\n            self.log_exception(fl_ctx, \"shareable data is not a valid DXO\")\n            return shareable\n\n        if dxo.data is None:\n            self.log_debug(fl_ctx, \"no data to filter\")\n            return shareable\n\n        self.logger.debug(\"check gamma\")\n        if self.gamma <= 0:\n            self.log_debug(fl_ctx, \"no partial model: gamma: {}\".format(self.gamma))\n            return shareable  # do nothing\n        if self.percentile < 0 or self.percentile > 100:\n            self.log_debug(fl_ctx, \"no partial model: percentile: {}\".format(self.percentile))\n            return shareable  # do nothing\n\n        # invariant to local steps\n        model_diff = dxo.data\n        total_steps = dxo.get_meta_prop(MetaKey.NUM_STEPS_CURRENT_ROUND, 1)\n\n        delta_w = {name: model_diff[name] / total_steps for name in model_diff}\n        # abs delta\n        all_abs_values = np.concatenate([np.abs(delta_w[name].ravel()) for name in delta_w])\n        cutoff = np.percentile(a=all_abs_values, q=self.percentile, overwrite_input=False)\n        self.log_info(\n            fl_ctx,\n            f\"Max abs delta_w: {np.max(all_abs_values)}, Min abs delta_w: {np.min(all_abs_values)},\"\n            f\"cutoff: {cutoff}, scale: {total_steps}.\",\n        )\n\n        for name in delta_w:\n            diff_w = delta_w[name]\n            if np.ndim(diff_w) == 0:  # single scalar, no clipping\n                delta_w[name] = diff_w * total_steps\n                continue\n            selector = (diff_w > -cutoff) & (diff_w < cutoff)\n            diff_w[selector] = 0.0\n            diff_w = np.clip(diff_w, a_min=-self.gamma, a_max=self.gamma)\n            delta_w[name] = diff_w * total_steps\n\n        dxo.data = delta_w\n        return dxo.update_shareable(shareable)",
  "def __init__(self, percentile=10, gamma=0.01):\n        \"\"\"Implementation of \"largest percentile to share\" privacy preserving policy.\n\n        Shokri and Shmatikov, Privacy-preserving deep learning, CCS '15\n\n        Args:\n            percentile (int, optional): Only abs diff greater than this percentile is updated.\n              Allowed range 0..100.  Defaults to 10.\n            gamma (float, optional): The upper limit to truncate abs values of weight diff. Defaults to 0.01.  Any weight diff with abs<gamma will become 0.\n        \"\"\"\n        super().__init__()\n\n        # must be in 0..100, only update abs diff greater than percentile\n        self.percentile = percentile\n        # must be positive\n        self.gamma = gamma",
  "def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Compute the percentile on the abs delta_W.\n\n        Only share the params where absolute delta_W greater than\n        the percentile value\n\n        Args:\n            shareable: information from client\n            fl_ctx: context provided by workflow\n\n        Returns:\n            Shareable: a shareable containing the truncated weight diff\n        \"\"\"\n        self.log_debug(fl_ctx, \"inside filter\")\n\n        rc = shareable.get_return_code()\n        if rc != ReturnCode.OK:\n            # don't process if RC not OK\n            return shareable\n\n        try:\n            dxo = from_shareable(shareable)\n        except:\n            self.log_exception(fl_ctx, \"shareable data is not a valid DXO\")\n            return shareable\n\n        if dxo.data is None:\n            self.log_debug(fl_ctx, \"no data to filter\")\n            return shareable\n\n        self.logger.debug(\"check gamma\")\n        if self.gamma <= 0:\n            self.log_debug(fl_ctx, \"no partial model: gamma: {}\".format(self.gamma))\n            return shareable  # do nothing\n        if self.percentile < 0 or self.percentile > 100:\n            self.log_debug(fl_ctx, \"no partial model: percentile: {}\".format(self.percentile))\n            return shareable  # do nothing\n\n        # invariant to local steps\n        model_diff = dxo.data\n        total_steps = dxo.get_meta_prop(MetaKey.NUM_STEPS_CURRENT_ROUND, 1)\n\n        delta_w = {name: model_diff[name] / total_steps for name in model_diff}\n        # abs delta\n        all_abs_values = np.concatenate([np.abs(delta_w[name].ravel()) for name in delta_w])\n        cutoff = np.percentile(a=all_abs_values, q=self.percentile, overwrite_input=False)\n        self.log_info(\n            fl_ctx,\n            f\"Max abs delta_w: {np.max(all_abs_values)}, Min abs delta_w: {np.min(all_abs_values)},\"\n            f\"cutoff: {cutoff}, scale: {total_steps}.\",\n        )\n\n        for name in delta_w:\n            diff_w = delta_w[name]\n            if np.ndim(diff_w) == 0:  # single scalar, no clipping\n                delta_w[name] = diff_w * total_steps\n                continue\n            selector = (diff_w > -cutoff) & (diff_w < cutoff)\n            diff_w[selector] = 0.0\n            diff_w = np.clip(diff_w, a_min=-self.gamma, a_max=self.gamma)\n            delta_w[name] = diff_w * total_steps\n\n        dxo.data = delta_w\n        return dxo.update_shareable(shareable)",
  "class ConvertWeights(Filter):\n\n    WEIGHTS_TO_DIFF = \"weights_to_diff\"\n    DIFF_TO_WEIGHTS = \"diff_to_weights\"\n\n    def __init__(self, direction: str):\n        \"\"\"Convert WEIGHTS to WEIGHT_DIFF or vice versa.\n\n        Args:\n            direction (str): control conversion direction.  Either weights_to_diff or diff_to_weights.\n\n        Raises:\n            ValueError: when the direction string is neither weights_to_diff nor diff_to_weights\n        \"\"\"\n        Filter.__init__(self)\n        if direction not in (self.WEIGHTS_TO_DIFF, self.DIFF_TO_WEIGHTS):\n            raise ValueError(\n                \"invalid convert direction {}: must be in {}\".format(\n                    direction, (self.WEIGHTS_TO_DIFF, self.DIFF_TO_WEIGHTS)\n                )\n            )\n\n        self.direction = direction\n\n    def _get_base_weights(self, fl_ctx: FLContext):\n        task_data = fl_ctx.get_prop(FLContextKey.TASK_DATA, None)\n        if not isinstance(task_data, Shareable):\n            self.log_error(fl_ctx, \"invalid task data: expect Shareable but got {}\".format(type(task_data)))\n            return None\n\n        try:\n            dxo = from_shareable(task_data)\n        except ValueError:\n            self.log_error(fl_ctx, \"invalid task data: no DXO\")\n            return None\n\n        if dxo.data_kind != DataKind.WEIGHTS:\n            self.log_info(fl_ctx, \"ignored task: expect data to be WEIGHTS but got {}\".format(dxo.data_kind))\n            return None\n\n        processed_algo = dxo.get_meta_prop(MetaKey.PROCESSED_ALGORITHM, None)\n        if processed_algo:\n            self.log_info(fl_ctx, \"ignored task since its processed by {}\".format(processed_algo))\n            return None\n\n        return dxo.data\n\n    def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Called by runners to perform weight conversion.\n\n        When the return code of shareable is not ReturnCode.OK, this\n        function will not perform any process and returns the shareable back.\n\n        Args:\n            shareable (Shareable): shareable must conform to DXO format.\n            fl_ctx (FLContext): this context must include TASK_DATA, which is another shareable containing base weights.\n              If not, the input shareable will be returned.\n\n        Returns:\n            Shareable: a shareable with converted weights\n        \"\"\"\n        rc = shareable.get_return_code()\n        if rc != ReturnCode.OK:\n            # don't process if RC not OK\n            return shareable\n\n        base_weights = self._get_base_weights(fl_ctx)\n        if not base_weights:\n            return shareable\n\n        try:\n            dxo = from_shareable(shareable)\n        except ValueError:\n            self.log_error(fl_ctx, \"invalid task result: no DXO\")\n            return shareable\n\n        processed_algo = dxo.get_meta_prop(MetaKey.PROCESSED_ALGORITHM, None)\n        if processed_algo:\n            self.log_info(fl_ctx, \"cannot process task result since its processed by {}\".format(processed_algo))\n            return shareable\n\n        if self.direction == self.WEIGHTS_TO_DIFF:\n            if dxo.data_kind != DataKind.WEIGHTS:\n                self.log_warning(fl_ctx, \"cannot process task result: expect WEIGHTS but got {}\".format(dxo.data_kind))\n                return shareable\n\n            new_weights = dxo.data\n            for k, _ in new_weights.items():\n                if k in base_weights:\n                    new_weights[k] -= base_weights[k]\n            dxo.data_kind = DataKind.WEIGHT_DIFF\n        else:\n            # diff to weights\n            if dxo.data_kind != DataKind.WEIGHT_DIFF:\n                self.log_warning(\n                    fl_ctx, \"cannot process task result: expect WEIGHT_DIFF but got {}\".format(dxo.data_kind)\n                )\n                return shareable\n\n            new_weights = dxo.data\n            for k, _ in new_weights.items():\n                if k in base_weights:\n                    new_weights[k] += base_weights[k]\n            dxo.data_kind = DataKind.WEIGHTS\n\n        return dxo.update_shareable(shareable)",
  "def __init__(self, direction: str):\n        \"\"\"Convert WEIGHTS to WEIGHT_DIFF or vice versa.\n\n        Args:\n            direction (str): control conversion direction.  Either weights_to_diff or diff_to_weights.\n\n        Raises:\n            ValueError: when the direction string is neither weights_to_diff nor diff_to_weights\n        \"\"\"\n        Filter.__init__(self)\n        if direction not in (self.WEIGHTS_TO_DIFF, self.DIFF_TO_WEIGHTS):\n            raise ValueError(\n                \"invalid convert direction {}: must be in {}\".format(\n                    direction, (self.WEIGHTS_TO_DIFF, self.DIFF_TO_WEIGHTS)\n                )\n            )\n\n        self.direction = direction",
  "def _get_base_weights(self, fl_ctx: FLContext):\n        task_data = fl_ctx.get_prop(FLContextKey.TASK_DATA, None)\n        if not isinstance(task_data, Shareable):\n            self.log_error(fl_ctx, \"invalid task data: expect Shareable but got {}\".format(type(task_data)))\n            return None\n\n        try:\n            dxo = from_shareable(task_data)\n        except ValueError:\n            self.log_error(fl_ctx, \"invalid task data: no DXO\")\n            return None\n\n        if dxo.data_kind != DataKind.WEIGHTS:\n            self.log_info(fl_ctx, \"ignored task: expect data to be WEIGHTS but got {}\".format(dxo.data_kind))\n            return None\n\n        processed_algo = dxo.get_meta_prop(MetaKey.PROCESSED_ALGORITHM, None)\n        if processed_algo:\n            self.log_info(fl_ctx, \"ignored task since its processed by {}\".format(processed_algo))\n            return None\n\n        return dxo.data",
  "def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Called by runners to perform weight conversion.\n\n        When the return code of shareable is not ReturnCode.OK, this\n        function will not perform any process and returns the shareable back.\n\n        Args:\n            shareable (Shareable): shareable must conform to DXO format.\n            fl_ctx (FLContext): this context must include TASK_DATA, which is another shareable containing base weights.\n              If not, the input shareable will be returned.\n\n        Returns:\n            Shareable: a shareable with converted weights\n        \"\"\"\n        rc = shareable.get_return_code()\n        if rc != ReturnCode.OK:\n            # don't process if RC not OK\n            return shareable\n\n        base_weights = self._get_base_weights(fl_ctx)\n        if not base_weights:\n            return shareable\n\n        try:\n            dxo = from_shareable(shareable)\n        except ValueError:\n            self.log_error(fl_ctx, \"invalid task result: no DXO\")\n            return shareable\n\n        processed_algo = dxo.get_meta_prop(MetaKey.PROCESSED_ALGORITHM, None)\n        if processed_algo:\n            self.log_info(fl_ctx, \"cannot process task result since its processed by {}\".format(processed_algo))\n            return shareable\n\n        if self.direction == self.WEIGHTS_TO_DIFF:\n            if dxo.data_kind != DataKind.WEIGHTS:\n                self.log_warning(fl_ctx, \"cannot process task result: expect WEIGHTS but got {}\".format(dxo.data_kind))\n                return shareable\n\n            new_weights = dxo.data\n            for k, _ in new_weights.items():\n                if k in base_weights:\n                    new_weights[k] -= base_weights[k]\n            dxo.data_kind = DataKind.WEIGHT_DIFF\n        else:\n            # diff to weights\n            if dxo.data_kind != DataKind.WEIGHT_DIFF:\n                self.log_warning(\n                    fl_ctx, \"cannot process task result: expect WEIGHT_DIFF but got {}\".format(dxo.data_kind)\n                )\n                return shareable\n\n            new_weights = dxo.data\n            for k, _ in new_weights.items():\n                if k in base_weights:\n                    new_weights[k] += base_weights[k]\n            dxo.data_kind = DataKind.WEIGHTS\n\n        return dxo.update_shareable(shareable)",
  "class ExcludeVars(Filter):\n    def __init__(self, exclude_vars: Union[List[str], str, None] = None):\n        \"\"\"Exclude/Remove variables from Shareable.\n\n        Args:\n            exclude_vars (Union[List[str], str, None] , optional): variables/layer names to be excluded.\n\n        Notes:\n            Based on different types of exclude_vars, this filter has different behavior:\n                if a list of variable/layer names, only specified variables will be excluded.\n                if a string, it will be converted into a regular expression, only matched variables will be excluded.\n                if not provided or other formats the Shareable remains unchanged.\n        \"\"\"\n        super().__init__()\n        self.exclude_vars = exclude_vars\n        self.skip = False\n        if self.exclude_vars is not None:\n            if not (isinstance(self.exclude_vars, list) or isinstance(self.exclude_vars, str)):\n                self.skip = True\n                self.logger.debug(\n                    \"Need to provide a list of layer names or a string for regex matching, but got {}\".format(\n                        type(self.exclude_vars)\n                    )\n                )\n                return\n\n            if isinstance(self.exclude_vars, list):\n                for var in self.exclude_vars:\n                    if not isinstance(var, str):\n                        self.skip = True\n                        self.logger.debug(\n                            \"encrypt_layers needs to be a list of layer names to encrypt, but contains element of type {}\".format(\n                                type(var)\n                            )\n                        )\n                        return\n                self.logger.debug(f\"Excluding {self.exclude_vars} from shareable\")\n            elif isinstance(self.exclude_vars, str):\n                self.exclude_vars = re.compile(self.exclude_vars) if self.exclude_vars else None\n                if self.exclude_vars is None:\n                    self.skip = True\n                self.logger.debug(f'Excluding all layers based on regex matches with \"{self.exclude_vars}\"')\n        else:\n            self.logger.debug(\"Not excluding anything\")\n            self.skip = True\n\n    def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Called by upper layer to remove variables in weights/weight_diff dictionary.\n\n        When the return code of shareable is not ReturnCode.OK, this\n        function will not perform any process and returns the shareable back.\n\n        Args:\n            shareable (Shareable): shareable must conform to DXO format.\n            fl_ctx (FLContext): only used for logging.\n\n        Returns:\n            Shareable: a shareable with excluded weights\n        \"\"\"\n        if self.skip:\n            return shareable\n\n        rc = shareable.get_return_code()\n        if rc != ReturnCode.OK:\n            # don't process if RC not OK\n            return shareable\n\n        try:\n            dxo = from_shareable(shareable)\n        except:\n            self.log_exception(fl_ctx, \"shareable data is not a valid DXO\")\n            return shareable\n\n        if dxo.data is None:\n            self.log_debug(fl_ctx, \"no data to filter\")\n            return shareable\n\n        weights = dxo.data\n        # remove variables\n        n_excluded = 0\n        var_names = list(weights.keys())  # make a copy of keys\n        n_vars = len(var_names)\n\n        for var_name in var_names:\n            if (isinstance(self.exclude_vars, re.Pattern) and self.exclude_vars.search(var_name)) or (\n                isinstance(self.exclude_vars, list) and var_name in self.exclude_vars\n            ):\n                self.log_debug(fl_ctx, f\"Excluding {var_name}\")\n                weights.pop(var_name, None)\n                n_excluded += 1\n\n        if isinstance(self.exclude_vars, re.Pattern) and n_excluded == 0:\n            self.log_warning(fl_ctx, f\"No matching layers found with regex {self.exclude_vars}\")\n\n        self.log_debug(fl_ctx, f\"Excluded {n_excluded} of {n_vars} variables. {len(weights.keys())} remaining.\")\n\n        dxo.data = weights\n        return dxo.update_shareable(shareable)",
  "def __init__(self, exclude_vars: Union[List[str], str, None] = None):\n        \"\"\"Exclude/Remove variables from Shareable.\n\n        Args:\n            exclude_vars (Union[List[str], str, None] , optional): variables/layer names to be excluded.\n\n        Notes:\n            Based on different types of exclude_vars, this filter has different behavior:\n                if a list of variable/layer names, only specified variables will be excluded.\n                if a string, it will be converted into a regular expression, only matched variables will be excluded.\n                if not provided or other formats the Shareable remains unchanged.\n        \"\"\"\n        super().__init__()\n        self.exclude_vars = exclude_vars\n        self.skip = False\n        if self.exclude_vars is not None:\n            if not (isinstance(self.exclude_vars, list) or isinstance(self.exclude_vars, str)):\n                self.skip = True\n                self.logger.debug(\n                    \"Need to provide a list of layer names or a string for regex matching, but got {}\".format(\n                        type(self.exclude_vars)\n                    )\n                )\n                return\n\n            if isinstance(self.exclude_vars, list):\n                for var in self.exclude_vars:\n                    if not isinstance(var, str):\n                        self.skip = True\n                        self.logger.debug(\n                            \"encrypt_layers needs to be a list of layer names to encrypt, but contains element of type {}\".format(\n                                type(var)\n                            )\n                        )\n                        return\n                self.logger.debug(f\"Excluding {self.exclude_vars} from shareable\")\n            elif isinstance(self.exclude_vars, str):\n                self.exclude_vars = re.compile(self.exclude_vars) if self.exclude_vars else None\n                if self.exclude_vars is None:\n                    self.skip = True\n                self.logger.debug(f'Excluding all layers based on regex matches with \"{self.exclude_vars}\"')\n        else:\n            self.logger.debug(\"Not excluding anything\")\n            self.skip = True",
  "def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Called by upper layer to remove variables in weights/weight_diff dictionary.\n\n        When the return code of shareable is not ReturnCode.OK, this\n        function will not perform any process and returns the shareable back.\n\n        Args:\n            shareable (Shareable): shareable must conform to DXO format.\n            fl_ctx (FLContext): only used for logging.\n\n        Returns:\n            Shareable: a shareable with excluded weights\n        \"\"\"\n        if self.skip:\n            return shareable\n\n        rc = shareable.get_return_code()\n        if rc != ReturnCode.OK:\n            # don't process if RC not OK\n            return shareable\n\n        try:\n            dxo = from_shareable(shareable)\n        except:\n            self.log_exception(fl_ctx, \"shareable data is not a valid DXO\")\n            return shareable\n\n        if dxo.data is None:\n            self.log_debug(fl_ctx, \"no data to filter\")\n            return shareable\n\n        weights = dxo.data\n        # remove variables\n        n_excluded = 0\n        var_names = list(weights.keys())  # make a copy of keys\n        n_vars = len(var_names)\n\n        for var_name in var_names:\n            if (isinstance(self.exclude_vars, re.Pattern) and self.exclude_vars.search(var_name)) or (\n                isinstance(self.exclude_vars, list) and var_name in self.exclude_vars\n            ):\n                self.log_debug(fl_ctx, f\"Excluding {var_name}\")\n                weights.pop(var_name, None)\n                n_excluded += 1\n\n        if isinstance(self.exclude_vars, re.Pattern) and n_excluded == 0:\n            self.log_warning(fl_ctx, f\"No matching layers found with regex {self.exclude_vars}\")\n\n        self.log_debug(fl_ctx, f\"Excluded {n_excluded} of {n_vars} variables. {len(weights.keys())} remaining.\")\n\n        dxo.data = weights\n        return dxo.update_shareable(shareable)",
  "class SVTPrivacy(Filter):\n    def __init__(self, fraction=0.1, epsilon=0.1, noise_var=0.1, gamma=1e-5, tau=1e-6):\n        \"\"\"Implementation of the standard Sparse Vector Technique (SVT) differential privacy algorithm.\n\n        lambda_rho = gamma * 2.0 / epsilon\n        threshold = tau + np.random.laplace(scale=lambda_rho)\n\n        Args:\n            fraction (float, optional): used to determine dataset threshold. Defaults to 0.1.\n            epsilon (float, optional): Defaults to 0.1.\n            noise_var (float, optional): additive noise. Defaults to 0.1.\n            gamma (float, optional): Defaults to 1e-5.\n            tau (float, optional): Defaults to 1e-6.\n        \"\"\"\n        super().__init__()\n\n        self.frac = fraction  # fraction of the model to upload\n        self.eps_1 = epsilon\n        self.eps_2 = None  # to be derived from eps_1\n        self.eps_3 = noise_var\n        self.gamma = gamma\n        self.tau = tau\n\n    def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Compute the differentially private SVT.\n\n        Args:\n            shareable: information from client\n            fl_ctx: context provided by workflow\n\n        Returns:\n            Shareable: updated shareable\n        \"\"\"\n        self.log_debug(fl_ctx, \"inside filter\")\n\n        rc = shareable.get_return_code()\n        if rc != ReturnCode.OK:\n            # don't process if RC not OK\n            return shareable\n\n        try:\n            dxo = from_shareable(shareable)\n        except:\n            self.log_exception(fl_ctx, \"shareable data is not a valid DXO\")\n            return shareable\n\n        if dxo.data is None:\n            self.log_debug(fl_ctx, \"no data to filter\")\n            return shareable\n\n        model_diff = dxo.data\n        total_steps = dxo.get_meta_prop(MetaKey.NUM_STEPS_CURRENT_ROUND, 1)\n\n        delta_w = np.concatenate([model_diff[name].ravel() / np.float(total_steps) for name in sorted(model_diff)])\n        self.log_info(\n            fl_ctx,\n            \"Delta_w: Max abs: {}, Min abs: {}, Median abs: {}.\".format(\n                np.max(np.abs(delta_w)), np.min(np.abs(delta_w)), np.median(np.abs(delta_w))\n            ),\n        )\n\n        # precompute thresholds\n        n_upload = np.minimum(np.ceil(np.float(delta_w.size) * self.frac), np.float(delta_w.size))\n\n        # eps_1: threshold with noise\n        lambda_rho = self.gamma * 2.0 / self.eps_1\n        threshold = self.tau + np.random.laplace(scale=lambda_rho)\n        # eps_2: query with noise\n        self.eps_2 = self.eps_1 * (2.0 * n_upload) ** (2.0 / 3.0)\n        lambda_nu = self.gamma * 4.0 * n_upload / self.eps_2\n        self.logger.info(\n            \"total params: %s, epsilon: %s, \"\n            \"perparam budget %s, threshold tau: %s + f(eps_1) = %s, \"\n            \"clip gamma: %s\",\n            delta_w.size,\n            self.eps_1,\n            self.eps_1 / n_upload,\n            self.tau,\n            threshold,\n            self.gamma,\n        )\n\n        # selecting weights with additive noise\n        accepted, candidate_idx = [], np.arange(delta_w.size)\n        _clipped_w = np.abs(np.clip(delta_w, a_min=-self.gamma, a_max=self.gamma))\n        while len(accepted) < n_upload:\n            nu_i = np.random.laplace(scale=lambda_nu, size=candidate_idx.shape)\n            above_threshold = (_clipped_w[candidate_idx] + nu_i) >= threshold\n            accepted += candidate_idx[above_threshold].tolist()\n            candidate_idx = candidate_idx[~above_threshold]\n            self.log_info(fl_ctx, \"selected {} responses, requested {}\".format(len(accepted), n_upload))\n        accepted = np.random.choice(accepted, size=np.int64(n_upload))\n        # eps_3 return with noise\n        noise = np.random.laplace(scale=self.gamma * 2.0 / self.eps_3, size=accepted.shape)\n        self.log_info(fl_ctx, \"noise max: {}, median {}\".format(np.max(np.abs(noise)), np.median(np.abs(noise))))\n        delta_w[accepted] = np.clip(delta_w[accepted] + noise, a_min=-self.gamma, a_max=self.gamma)\n        candidate_idx = list(set(np.arange(delta_w.size)) - set(accepted))\n        delta_w[candidate_idx] = 0.0\n\n        # resume original format\n        dp_w, _start = {}, 0\n        for name in sorted(model_diff):\n            if np.ndim(model_diff[name]) == 0:\n                dp_w[name] = model_diff[name]\n                _start += 1\n                continue\n            value = delta_w[_start : (_start + model_diff[name].size)]\n            dp_w[name] = value.reshape(model_diff[name].shape) * np.float(total_steps)\n            _start += model_diff[name].size\n\n        # We update the shareable weights only.  Headers are unchanged.\n        dxo.data = dp_w\n        return dxo.update_shareable(shareable)",
  "def __init__(self, fraction=0.1, epsilon=0.1, noise_var=0.1, gamma=1e-5, tau=1e-6):\n        \"\"\"Implementation of the standard Sparse Vector Technique (SVT) differential privacy algorithm.\n\n        lambda_rho = gamma * 2.0 / epsilon\n        threshold = tau + np.random.laplace(scale=lambda_rho)\n\n        Args:\n            fraction (float, optional): used to determine dataset threshold. Defaults to 0.1.\n            epsilon (float, optional): Defaults to 0.1.\n            noise_var (float, optional): additive noise. Defaults to 0.1.\n            gamma (float, optional): Defaults to 1e-5.\n            tau (float, optional): Defaults to 1e-6.\n        \"\"\"\n        super().__init__()\n\n        self.frac = fraction  # fraction of the model to upload\n        self.eps_1 = epsilon\n        self.eps_2 = None  # to be derived from eps_1\n        self.eps_3 = noise_var\n        self.gamma = gamma\n        self.tau = tau",
  "def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Compute the differentially private SVT.\n\n        Args:\n            shareable: information from client\n            fl_ctx: context provided by workflow\n\n        Returns:\n            Shareable: updated shareable\n        \"\"\"\n        self.log_debug(fl_ctx, \"inside filter\")\n\n        rc = shareable.get_return_code()\n        if rc != ReturnCode.OK:\n            # don't process if RC not OK\n            return shareable\n\n        try:\n            dxo = from_shareable(shareable)\n        except:\n            self.log_exception(fl_ctx, \"shareable data is not a valid DXO\")\n            return shareable\n\n        if dxo.data is None:\n            self.log_debug(fl_ctx, \"no data to filter\")\n            return shareable\n\n        model_diff = dxo.data\n        total_steps = dxo.get_meta_prop(MetaKey.NUM_STEPS_CURRENT_ROUND, 1)\n\n        delta_w = np.concatenate([model_diff[name].ravel() / np.float(total_steps) for name in sorted(model_diff)])\n        self.log_info(\n            fl_ctx,\n            \"Delta_w: Max abs: {}, Min abs: {}, Median abs: {}.\".format(\n                np.max(np.abs(delta_w)), np.min(np.abs(delta_w)), np.median(np.abs(delta_w))\n            ),\n        )\n\n        # precompute thresholds\n        n_upload = np.minimum(np.ceil(np.float(delta_w.size) * self.frac), np.float(delta_w.size))\n\n        # eps_1: threshold with noise\n        lambda_rho = self.gamma * 2.0 / self.eps_1\n        threshold = self.tau + np.random.laplace(scale=lambda_rho)\n        # eps_2: query with noise\n        self.eps_2 = self.eps_1 * (2.0 * n_upload) ** (2.0 / 3.0)\n        lambda_nu = self.gamma * 4.0 * n_upload / self.eps_2\n        self.logger.info(\n            \"total params: %s, epsilon: %s, \"\n            \"perparam budget %s, threshold tau: %s + f(eps_1) = %s, \"\n            \"clip gamma: %s\",\n            delta_w.size,\n            self.eps_1,\n            self.eps_1 / n_upload,\n            self.tau,\n            threshold,\n            self.gamma,\n        )\n\n        # selecting weights with additive noise\n        accepted, candidate_idx = [], np.arange(delta_w.size)\n        _clipped_w = np.abs(np.clip(delta_w, a_min=-self.gamma, a_max=self.gamma))\n        while len(accepted) < n_upload:\n            nu_i = np.random.laplace(scale=lambda_nu, size=candidate_idx.shape)\n            above_threshold = (_clipped_w[candidate_idx] + nu_i) >= threshold\n            accepted += candidate_idx[above_threshold].tolist()\n            candidate_idx = candidate_idx[~above_threshold]\n            self.log_info(fl_ctx, \"selected {} responses, requested {}\".format(len(accepted), n_upload))\n        accepted = np.random.choice(accepted, size=np.int64(n_upload))\n        # eps_3 return with noise\n        noise = np.random.laplace(scale=self.gamma * 2.0 / self.eps_3, size=accepted.shape)\n        self.log_info(fl_ctx, \"noise max: {}, median {}\".format(np.max(np.abs(noise)), np.median(np.abs(noise))))\n        delta_w[accepted] = np.clip(delta_w[accepted] + noise, a_min=-self.gamma, a_max=self.gamma)\n        candidate_idx = list(set(np.arange(delta_w.size)) - set(accepted))\n        delta_w[candidate_idx] = 0.0\n\n        # resume original format\n        dp_w, _start = {}, 0\n        for name in sorted(model_diff):\n            if np.ndim(model_diff[name]) == 0:\n                dp_w[name] = model_diff[name]\n                _start += 1\n                continue\n            value = delta_w[_start : (_start + model_diff[name].size)]\n            dp_w[name] = value.reshape(model_diff[name].shape) * np.float(total_steps)\n            _start += model_diff[name].size\n\n        # We update the shareable weights only.  Headers are unchanged.\n        dxo.data = dp_w\n        return dxo.update_shareable(shareable)",
  "class FullModelShareableGenerator(ShareableGenerator):\n    def learnable_to_shareable(self, model_learnable: ModelLearnable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Convert ModelLearnable to Shareable.\n\n        Args:\n            model_learnable (ModelLearnable): model to be converted\n            fl_ctx (FLContext): FL context\n\n        Returns:\n            Shareable: a shareable containing a DXO object.\n        \"\"\"\n        dxo = model_learnable_to_dxo(model_learnable)\n        return dxo.to_shareable()\n\n    def shareable_to_learnable(self, shareable: Shareable, fl_ctx: FLContext) -> ModelLearnable:\n        \"\"\"Convert Shareable to ModelLearnable.\n\n        Supporting TYPE == TYPE_WEIGHT_DIFF or TYPE_WEIGHTS\n\n        Args:\n            shareable (Shareable): Shareable that contains a DXO object\n            fl_ctx (FLContext): FL context\n\n        Returns:\n            A ModelLearnable object\n\n        Raises:\n            TypeError: if shareable is not of type shareable\n            ValueError: if data_kind is not `DataKind.WEIGHTS` and is not `DataKind.WEIGHT_DIFF`\n        \"\"\"\n        if not isinstance(shareable, Shareable):\n            raise TypeError(\"shareable must be Shareable, but got {}.\".format(type(shareable)))\n\n        base_model = fl_ctx.get_prop(AppConstants.GLOBAL_MODEL)\n        if not base_model:\n            self.system_panic(reason=\"No global base model!\", fl_ctx=fl_ctx)\n            return base_model\n\n        weights = base_model[ModelLearnableKey.WEIGHTS]\n        dxo = from_shareable(shareable)\n\n        if dxo.data_kind == DataKind.WEIGHT_DIFF:\n            if dxo.data is not None:\n                model_diff = dxo.data\n                for v_name, v_value in model_diff.items():\n                    weights[v_name] = weights[v_name] + v_value\n        elif dxo.data_kind == DataKind.WEIGHTS:\n            weights = dxo.data\n            if not weights:\n                self.log_info(fl_ctx, \"No model weights found. Model will not be updated.\")\n            else:\n                base_model[ModelLearnableKey.WEIGHTS] = weights\n        else:\n            raise ValueError(\n                \"data_kind should be either DataKind.WEIGHTS or DataKind.WEIGHT_DIFF, but got {}\".format(dxo.data_kind)\n            )\n\n        base_model[ModelLearnableKey.META] = dxo.get_meta_props()\n        return base_model",
  "def learnable_to_shareable(self, model_learnable: ModelLearnable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Convert ModelLearnable to Shareable.\n\n        Args:\n            model_learnable (ModelLearnable): model to be converted\n            fl_ctx (FLContext): FL context\n\n        Returns:\n            Shareable: a shareable containing a DXO object.\n        \"\"\"\n        dxo = model_learnable_to_dxo(model_learnable)\n        return dxo.to_shareable()",
  "def shareable_to_learnable(self, shareable: Shareable, fl_ctx: FLContext) -> ModelLearnable:\n        \"\"\"Convert Shareable to ModelLearnable.\n\n        Supporting TYPE == TYPE_WEIGHT_DIFF or TYPE_WEIGHTS\n\n        Args:\n            shareable (Shareable): Shareable that contains a DXO object\n            fl_ctx (FLContext): FL context\n\n        Returns:\n            A ModelLearnable object\n\n        Raises:\n            TypeError: if shareable is not of type shareable\n            ValueError: if data_kind is not `DataKind.WEIGHTS` and is not `DataKind.WEIGHT_DIFF`\n        \"\"\"\n        if not isinstance(shareable, Shareable):\n            raise TypeError(\"shareable must be Shareable, but got {}.\".format(type(shareable)))\n\n        base_model = fl_ctx.get_prop(AppConstants.GLOBAL_MODEL)\n        if not base_model:\n            self.system_panic(reason=\"No global base model!\", fl_ctx=fl_ctx)\n            return base_model\n\n        weights = base_model[ModelLearnableKey.WEIGHTS]\n        dxo = from_shareable(shareable)\n\n        if dxo.data_kind == DataKind.WEIGHT_DIFF:\n            if dxo.data is not None:\n                model_diff = dxo.data\n                for v_name, v_value in model_diff.items():\n                    weights[v_name] = weights[v_name] + v_value\n        elif dxo.data_kind == DataKind.WEIGHTS:\n            weights = dxo.data\n            if not weights:\n                self.log_info(fl_ctx, \"No model weights found. Model will not be updated.\")\n            else:\n                base_model[ModelLearnableKey.WEIGHTS] = weights\n        else:\n            raise ValueError(\n                \"data_kind should be either DataKind.WEIGHTS or DataKind.WEIGHT_DIFF, but got {}\".format(dxo.data_kind)\n            )\n\n        base_model[ModelLearnableKey.META] = dxo.get_meta_props()\n        return base_model",
  "class LearnerExecutor(Executor):\n    def __init__(\n        self,\n        learner_id,\n        train_task=AppConstants.TASK_TRAIN,\n        submit_model_task=AppConstants.TASK_SUBMIT_MODEL,\n        validate_task=AppConstants.TASK_VALIDATION,\n    ):\n        \"\"\"Key component to run learner on clients.\n\n        Args:\n            learner_id (str): id pointing to the learner object\n            train_task (str, optional): label to dispatch train task. Defaults to AppConstants.TASK_TRAIN.\n            submit_model_task (str, optional): label to dispatch submit model task. Defaults to AppConstants.TASK_SUBMIT_MODEL.\n            validate_task (str, optional): label to dispatch validation task. Defaults to AppConstants.TASK_VALIDATION.\n        \"\"\"\n        super().__init__()\n        self.learner_id = learner_id\n        self.learner = None\n        self.train_task = train_task\n        self.submit_model_task = submit_model_task\n        self.validate_task = validate_task\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.initialize(fl_ctx)\n        elif event_type == EventType.ABORT_TASK:\n            try:\n                if self.learner:\n                    self.learner.abort(fl_ctx)\n            except Exception as e:\n                self.log_exception(fl_ctx, f\"learner abort exception: {e}\")\n        elif event_type == EventType.END_RUN:\n            self.finalize(fl_ctx)\n\n    def initialize(self, fl_ctx: FLContext):\n        try:\n            engine = fl_ctx.get_engine()\n            self.learner = engine.get_component(self.learner_id)\n            if not isinstance(self.learner, Learner):\n                raise TypeError(f\"learner must be Learner type. Got: {type(self.learner)}\")\n            self.learner.initialize(engine.get_all_components(), fl_ctx)\n        except Exception as e:\n            self.log_exception(fl_ctx, f\"learner initialize exception: {e}\")\n\n    def execute(self, task_name: str, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        self.log_info(fl_ctx, f\"Client trainer got task: {task_name}\")\n\n        try:\n            if task_name == self.train_task:\n                return self.train(shareable, fl_ctx, abort_signal)\n            elif task_name == self.submit_model_task:\n                return self.submit_model(shareable, fl_ctx)\n            elif task_name == self.validate_task:\n                return self.validate(shareable, fl_ctx, abort_signal)\n            else:\n                self.log_error(fl_ctx, f\"Could not handle task: {task_name}\")\n                return make_reply(ReturnCode.TASK_UNKNOWN)\n        except Exception as e:\n            # Task execution error, return EXECUTION_EXCEPTION Shareable\n            self.log_exception(fl_ctx, f\"learner execute exception: {e}\")\n            return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n\n    def train(self, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        self.log_debug(fl_ctx, f\"train abort signal: {abort_signal.triggered}\")\n\n        shareable.set_header(AppConstants.VALIDATE_TYPE, ValidateType.BEFORE_TRAIN_VALIDATE)\n        validate_result: Shareable = self.learner.validate(shareable, fl_ctx, abort_signal)\n\n        train_result = self.learner.train(shareable, fl_ctx, abort_signal)\n        if not (train_result and isinstance(train_result, Shareable)):\n            return make_reply(ReturnCode.EMPTY_RESULT)\n\n        # if the learner returned the valid BEFORE_TRAIN_VALIDATE result, set the INITIAL_METRICS in\n        # the train result, which can be used for best model selection.\n        if (\n            validate_result\n            and isinstance(validate_result, Shareable)\n            and validate_result.get_return_code() == ReturnCode.OK\n        ):\n            try:\n                metrics_dxo = from_shareable(validate_result)\n                train_dxo = from_shareable(train_result)\n                train_dxo.meta[MetaKey.INITIAL_METRICS] = metrics_dxo.data.get(MetaKey.INITIAL_METRICS, 0)\n                return train_dxo.to_shareable()\n            except ValueError:\n                return train_result\n        else:\n            return train_result\n\n    def submit_model(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        model_name = shareable.get_header(AppConstants.SUBMIT_MODEL_NAME)\n        submit_model_result = self.learner.get_model_for_validation(model_name, fl_ctx)\n        if submit_model_result and isinstance(submit_model_result, Shareable):\n            return submit_model_result\n        else:\n            return make_reply(ReturnCode.EMPTY_RESULT)\n\n    def validate(self, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        self.log_debug(fl_ctx, f\"validate abort_signal {abort_signal.triggered}\")\n\n        shareable.set_header(AppConstants.VALIDATE_TYPE, ValidateType.MODEL_VALIDATE)\n        validate_result: Shareable = self.learner.validate(shareable, fl_ctx, abort_signal)\n        if validate_result and isinstance(validate_result, Shareable):\n            return validate_result\n        else:\n            return make_reply(ReturnCode.EMPTY_RESULT)\n\n    def finalize(self, fl_ctx: FLContext):\n        try:\n            if self.learner:\n                self.learner.finalize(fl_ctx)\n        except Exception as e:\n            self.log_exception(fl_ctx, f\"learner finalize exception: {e}\")",
  "def __init__(\n        self,\n        learner_id,\n        train_task=AppConstants.TASK_TRAIN,\n        submit_model_task=AppConstants.TASK_SUBMIT_MODEL,\n        validate_task=AppConstants.TASK_VALIDATION,\n    ):\n        \"\"\"Key component to run learner on clients.\n\n        Args:\n            learner_id (str): id pointing to the learner object\n            train_task (str, optional): label to dispatch train task. Defaults to AppConstants.TASK_TRAIN.\n            submit_model_task (str, optional): label to dispatch submit model task. Defaults to AppConstants.TASK_SUBMIT_MODEL.\n            validate_task (str, optional): label to dispatch validation task. Defaults to AppConstants.TASK_VALIDATION.\n        \"\"\"\n        super().__init__()\n        self.learner_id = learner_id\n        self.learner = None\n        self.train_task = train_task\n        self.submit_model_task = submit_model_task\n        self.validate_task = validate_task",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.initialize(fl_ctx)\n        elif event_type == EventType.ABORT_TASK:\n            try:\n                if self.learner:\n                    self.learner.abort(fl_ctx)\n            except Exception as e:\n                self.log_exception(fl_ctx, f\"learner abort exception: {e}\")\n        elif event_type == EventType.END_RUN:\n            self.finalize(fl_ctx)",
  "def initialize(self, fl_ctx: FLContext):\n        try:\n            engine = fl_ctx.get_engine()\n            self.learner = engine.get_component(self.learner_id)\n            if not isinstance(self.learner, Learner):\n                raise TypeError(f\"learner must be Learner type. Got: {type(self.learner)}\")\n            self.learner.initialize(engine.get_all_components(), fl_ctx)\n        except Exception as e:\n            self.log_exception(fl_ctx, f\"learner initialize exception: {e}\")",
  "def execute(self, task_name: str, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        self.log_info(fl_ctx, f\"Client trainer got task: {task_name}\")\n\n        try:\n            if task_name == self.train_task:\n                return self.train(shareable, fl_ctx, abort_signal)\n            elif task_name == self.submit_model_task:\n                return self.submit_model(shareable, fl_ctx)\n            elif task_name == self.validate_task:\n                return self.validate(shareable, fl_ctx, abort_signal)\n            else:\n                self.log_error(fl_ctx, f\"Could not handle task: {task_name}\")\n                return make_reply(ReturnCode.TASK_UNKNOWN)\n        except Exception as e:\n            # Task execution error, return EXECUTION_EXCEPTION Shareable\n            self.log_exception(fl_ctx, f\"learner execute exception: {e}\")\n            return make_reply(ReturnCode.EXECUTION_EXCEPTION)",
  "def train(self, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        self.log_debug(fl_ctx, f\"train abort signal: {abort_signal.triggered}\")\n\n        shareable.set_header(AppConstants.VALIDATE_TYPE, ValidateType.BEFORE_TRAIN_VALIDATE)\n        validate_result: Shareable = self.learner.validate(shareable, fl_ctx, abort_signal)\n\n        train_result = self.learner.train(shareable, fl_ctx, abort_signal)\n        if not (train_result and isinstance(train_result, Shareable)):\n            return make_reply(ReturnCode.EMPTY_RESULT)\n\n        # if the learner returned the valid BEFORE_TRAIN_VALIDATE result, set the INITIAL_METRICS in\n        # the train result, which can be used for best model selection.\n        if (\n            validate_result\n            and isinstance(validate_result, Shareable)\n            and validate_result.get_return_code() == ReturnCode.OK\n        ):\n            try:\n                metrics_dxo = from_shareable(validate_result)\n                train_dxo = from_shareable(train_result)\n                train_dxo.meta[MetaKey.INITIAL_METRICS] = metrics_dxo.data.get(MetaKey.INITIAL_METRICS, 0)\n                return train_dxo.to_shareable()\n            except ValueError:\n                return train_result\n        else:\n            return train_result",
  "def submit_model(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        model_name = shareable.get_header(AppConstants.SUBMIT_MODEL_NAME)\n        submit_model_result = self.learner.get_model_for_validation(model_name, fl_ctx)\n        if submit_model_result and isinstance(submit_model_result, Shareable):\n            return submit_model_result\n        else:\n            return make_reply(ReturnCode.EMPTY_RESULT)",
  "def validate(self, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        self.log_debug(fl_ctx, f\"validate abort_signal {abort_signal.triggered}\")\n\n        shareable.set_header(AppConstants.VALIDATE_TYPE, ValidateType.MODEL_VALIDATE)\n        validate_result: Shareable = self.learner.validate(shareable, fl_ctx, abort_signal)\n        if validate_result and isinstance(validate_result, Shareable):\n            return validate_result\n        else:\n            return make_reply(ReturnCode.EMPTY_RESULT)",
  "def finalize(self, fl_ctx: FLContext):\n        try:\n            if self.learner:\n                self.learner.finalize(fl_ctx)\n        except Exception as e:\n            self.log_exception(fl_ctx, f\"learner finalize exception: {e}\")",
  "class WorkerComponentBuilder(ComponentBuilder):\n    FL_PACKAGES = [\"nvflare\"]\n    FL_MODULES = [\"client\", \"app\"]\n\n    def __init__(self) -> None:\n        \"\"\"Component to build workers.\"\"\"\n        super().__init__()\n        self.module_scanner = ModuleScanner(WorkerComponentBuilder.FL_PACKAGES, WorkerComponentBuilder.FL_MODULES, True)\n\n    def get_module_scanner(self):\n        return self.module_scanner",
  "class MultiProcessExecutor(Executor):\n    def __init__(self, executor_id=None, num_of_processes=1, components=None):\n        \"\"\"Manage the multi-process execution life cycle.\n\n        Arguments:\n            executor_id: executor component ID\n            num_of_processes: number of processes to create\n            components: a dictionary for component classes to their arguments\n        \"\"\"\n        super().__init__()\n        self.executor_id = executor_id\n\n        self.components = {}\n        self.handlers = []\n        self._build_components(components)\n\n        if not isinstance(num_of_processes, int):\n            raise TypeError(\"{} must be an instance of int but got {}\".format(num_of_processes, type(num_of_processes)))\n        if num_of_processes < 1:\n            raise ValueError(f\"{num_of_processes} must >= 1.\")\n        self.num_of_processes = num_of_processes\n        self.executor = None\n\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.conn_clients = []\n        self.exe_process = None\n        self.open_ports = []\n\n        self.stop_execute = False\n        self.relay_threads = []\n        self.finalized = False\n        self.event_lock = threading.Lock()\n        self.relay_lock = threading.Lock()\n\n    @abstractmethod\n    def get_multi_process_command(self) -> str:\n        \"\"\"Provide the command for starting multi-process execution.\n\n        Returns:\n            multi-process starting command\n        \"\"\"\n        return \"\"\n\n    def _build_components(self, components):\n        component_builder = WorkerComponentBuilder()\n        for item in components:\n            cid = item.get(\"id\", None)\n            if not cid:\n                raise TypeError(\"missing component id\")\n            self.components[cid] = component_builder.build_component(item)\n            if isinstance(self.components[cid], FLComponent):\n                self.handlers.append(self.components[cid])\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.initialize(fl_ctx)\n        elif event_type == EventType.END_RUN:\n            self.finalize(fl_ctx)\n\n        self._pass_event_to_rank_processes(event_type, fl_ctx)\n\n    def _pass_event_to_rank_processes(self, event_type: str, fl_ctx: FLContext):\n        event_site = fl_ctx.get_prop(FLContextKey.EVENT_ORIGIN_SITE)\n\n        if event_site != CommunicateData.SUB_WORKER_PROCESS:\n            with self.event_lock:\n                try:\n                    data = {\n                        CommunicationMetaData.COMMAND: CommunicateData.HANDLE_EVENT,\n                        CommunicationMetaData.FL_CTX: get_serializable_data(fl_ctx),\n                        CommunicationMetaData.EVENT_TYPE: event_type,\n                    }\n                    # send the init data to all the child processes\n                    for conn_client in self.conn_clients:\n                        conn_client[CommunicationMetaData.HANDLE_CONN].send(data)\n\n                    return_data = self.conn_clients[0][CommunicationMetaData.HANDLE_CONN].recv()\n                    # update the fl_ctx from the child process return data.\n                    fl_ctx.props.update(return_data[CommunicationMetaData.FL_CTX].props)\n                except BaseException as e:\n                    # Warning: Have to set fire_event=False, otherwise it will cause dead loop on the event handling!!!\n                    self.log_warning(\n                        fl_ctx, f\"Failed to relay the event to child processes. Event: {event_type}\", fire_event=False\n                    )\n\n    def initialize(self, fl_ctx: FLContext):\n        self.executor = self.components.get(self.executor_id, None)\n        if not isinstance(self.executor, Executor):\n            raise ValueError(\n                \"invalid executor {}: expect Executor but got {}\".format(self.executor_id, type(self.executor))\n            )\n        self._initialize_multi_process(fl_ctx)\n\n    def _initialize_multi_process(self, fl_ctx: FLContext):\n\n        try:\n            self.open_ports = get_open_ports(self.num_of_processes * 3)\n\n            command = (\n                self.get_multi_process_command()\n                + \" -m nvflare.private.fed.app.client.sub_worker_process\"\n                + \" -m \"\n                + fl_ctx.get_prop(FLContextKey.ARGS).workspace\n                + \" --ports \"\n                + \"-\".join([str(i) for i in self.open_ports])\n            )\n            self.logger.info(f\"multi_process_executor command: {command}\")\n            # use os.setsid to create new process group ID\n            self.exe_process = subprocess.Popen(shlex.split(command, \" \"), preexec_fn=os.setsid, env=os.environ.copy())\n\n            for i in range(self.num_of_processes):\n                listen_port = self.open_ports[i * 3 + 2]\n                thread = threading.Thread(target=self._relay_fire_event, args=(listen_port, fl_ctx))\n                self.relay_threads.append(thread)\n                thread.start()\n\n                open_port = self.open_ports[i * 3]\n                exe_conn = self._create_connection(open_port)\n\n                open_port = self.open_ports[i * 3 + 1]\n                handle_conn = self._create_connection(open_port)\n\n                self.conn_clients.append(\n                    {CommunicationMetaData.EXE_CONN: exe_conn, CommunicationMetaData.HANDLE_CONN: handle_conn}\n                )\n            self.logger.info(f\"Created the connections to child processes on ports: {str(self.open_ports)}\")\n\n            data = {\n                CommunicationMetaData.FL_CTX: get_serializable_data(fl_ctx),\n                CommunicationMetaData.COMPONENTS: self.components,\n                CommunicationMetaData.HANDLERS: self.handlers,\n                CommunicationMetaData.LOCAL_EXECUTOR: self.executor,\n            }\n\n            # send the init data to all the child processes\n            responses = []\n            for conn_client in self.conn_clients:\n                conn_client[CommunicationMetaData.EXE_CONN].send(data)\n                responses.append(False)\n\n            while True:\n                run_abort_signal = fl_ctx.get_run_abort_signal()\n                if run_abort_signal and run_abort_signal.triggered:\n                    self.finalize(fl_ctx)\n                    break\n\n                # Make sure to receive responses from all rank processes.\n                index = 0\n                received_all = True\n                for conn_client in self.conn_clients:\n                    received_all = received_all and responses[index]\n                    if not responses[index]:\n                        if conn_client[CommunicationMetaData.EXE_CONN].poll(0.2):\n                            conn_client[CommunicationMetaData.EXE_CONN].recv()\n                            responses[index] = True\n                    index += 1\n                if received_all:\n                    break\n        except:\n            self.log_exception(fl_ctx, \"error initializing multi_process executor\")\n\n    def _relay_fire_event(self, listen_port, fl_ctx: FLContext):\n        address = (\"localhost\", int(listen_port))\n        listener = Listener(address, authkey=CommunicationMetaData.PARENT_PASSWORD.encode())\n        conn = listener.accept()\n\n        while not self.stop_execute:\n            try:\n                if conn.poll(0.1):\n                    data = conn.recv()\n                    event_type = data[CommunicationMetaData.EVENT_TYPE]\n                    rank_number = data[CommunicationMetaData.RANK_NUMBER]\n\n                    with self.relay_lock:\n                        fl_ctx.props.update(data[CommunicationMetaData.FL_CTX].props)\n\n                        fl_ctx.set_prop(FLContextKey.FROM_RANK_NUMBER, rank_number, private=True, sticky=False)\n                        fl_ctx.set_prop(\n                            FLContextKey.EVENT_ORIGIN_SITE,\n                            CommunicateData.SUB_WORKER_PROCESS,\n                            private=True,\n                            sticky=False,\n                        )\n                        engine = fl_ctx.get_engine()\n                        engine.fire_event(event_type, fl_ctx)\n\n                        return_data = {CommunicationMetaData.FL_CTX: get_serializable_data(fl_ctx)}\n                    conn.send(return_data)\n            except:\n                self.logger.warning(\"Failed to relay the fired events from rank_processes.\")\n\n    def _create_connection(self, open_port):\n        conn = None\n        while not conn:\n            try:\n                address = (\"localhost\", open_port)\n                conn = Client(address, authkey=CommunicationMetaData.CHILD_PASSWORD.encode())\n            except BaseException as e:\n                time.sleep(1.0)\n                pass\n        return conn\n\n    def execute(self, task_name: str, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        if not self.executor:\n            raise RuntimeError(\"There's no executor for task {}\".format(task_name))\n\n        return self._execute_multi_process(\n            task_name=task_name, shareable=shareable, fl_ctx=fl_ctx, abort_signal=abort_signal\n        )\n\n    def _execute_multi_process(\n        self, task_name: str, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal\n    ) -> Shareable:\n\n        if abort_signal.triggered:\n            self.finalize(fl_ctx)\n            return make_reply(ReturnCode.OK)\n\n        try:\n            data = {\n                CommunicationMetaData.COMMAND: CommunicateData.EXECUTE,\n                CommunicationMetaData.TASK_NAME: task_name,\n                CommunicationMetaData.SHAREABLE: shareable,\n                CommunicationMetaData.FL_CTX: get_serializable_data(fl_ctx),\n            }\n\n            # send the execute command to all the child processes\n            for conn_client in self.conn_clients:\n                conn_client[CommunicationMetaData.EXE_CONN].send(data)\n\n            while True:\n                if abort_signal.triggered:\n                    self.finalize(fl_ctx)\n                    return make_reply(ReturnCode.OK)\n\n                if self.conn_clients[0][CommunicationMetaData.EXE_CONN].poll(1.0):\n                    # Only need to receive the Shareable and FLContext update from rank 0 process.\n                    return_data = self.conn_clients[0][CommunicationMetaData.EXE_CONN].recv()\n                    shareable = return_data[CommunicationMetaData.SHAREABLE]\n                    fl_ctx.props.update(return_data[CommunicationMetaData.FL_CTX].props)\n                    return shareable\n        except BaseException as e:\n            self.log_error(fl_ctx, \"Multi-Process Execution error.\")\n            return make_reply(ReturnCode.EXECUTION_RESULT_ERROR)\n\n    def finalize(self, fl_ctx: FLContext):\n        \"\"\"This is called when exiting/aborting the executor.\"\"\"\n        if self.finalized:\n            return\n\n        self.finalized = True\n        self.stop_execute = True\n\n        data = {CommunicationMetaData.COMMAND: CommunicateData.CLOSE}\n        for conn_client in self.conn_clients:\n            try:\n                conn_client[CommunicationMetaData.EXE_CONN].send(data)\n                conn_client[CommunicationMetaData.HANDLE_CONN].send(data)\n                self.logger.info(\"close command sent to rank processes.\")\n            except:\n                self.logger.warning(\"Failed to send the close command. \")\n        try:\n            os.killpg(os.getpgid(self.exe_process.pid), 9)\n            self.logger.debug(\"kill signal sent\")\n        except Exception as e:\n            pass\n\n        if self.exe_process:\n            self.exe_process.terminate()\n\n        # wait for all relay threads to join!\n        for t in self.relay_threads:\n            if t.is_alive():\n                t.join()\n\n        self.log_info(fl_ctx, \"Multi-Process Executor finalized!\", fire_event=False)",
  "def __init__(self) -> None:\n        \"\"\"Component to build workers.\"\"\"\n        super().__init__()\n        self.module_scanner = ModuleScanner(WorkerComponentBuilder.FL_PACKAGES, WorkerComponentBuilder.FL_MODULES, True)",
  "def get_module_scanner(self):\n        return self.module_scanner",
  "def __init__(self, executor_id=None, num_of_processes=1, components=None):\n        \"\"\"Manage the multi-process execution life cycle.\n\n        Arguments:\n            executor_id: executor component ID\n            num_of_processes: number of processes to create\n            components: a dictionary for component classes to their arguments\n        \"\"\"\n        super().__init__()\n        self.executor_id = executor_id\n\n        self.components = {}\n        self.handlers = []\n        self._build_components(components)\n\n        if not isinstance(num_of_processes, int):\n            raise TypeError(\"{} must be an instance of int but got {}\".format(num_of_processes, type(num_of_processes)))\n        if num_of_processes < 1:\n            raise ValueError(f\"{num_of_processes} must >= 1.\")\n        self.num_of_processes = num_of_processes\n        self.executor = None\n\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.conn_clients = []\n        self.exe_process = None\n        self.open_ports = []\n\n        self.stop_execute = False\n        self.relay_threads = []\n        self.finalized = False\n        self.event_lock = threading.Lock()\n        self.relay_lock = threading.Lock()",
  "def get_multi_process_command(self) -> str:\n        \"\"\"Provide the command for starting multi-process execution.\n\n        Returns:\n            multi-process starting command\n        \"\"\"\n        return \"\"",
  "def _build_components(self, components):\n        component_builder = WorkerComponentBuilder()\n        for item in components:\n            cid = item.get(\"id\", None)\n            if not cid:\n                raise TypeError(\"missing component id\")\n            self.components[cid] = component_builder.build_component(item)\n            if isinstance(self.components[cid], FLComponent):\n                self.handlers.append(self.components[cid])",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.initialize(fl_ctx)\n        elif event_type == EventType.END_RUN:\n            self.finalize(fl_ctx)\n\n        self._pass_event_to_rank_processes(event_type, fl_ctx)",
  "def _pass_event_to_rank_processes(self, event_type: str, fl_ctx: FLContext):\n        event_site = fl_ctx.get_prop(FLContextKey.EVENT_ORIGIN_SITE)\n\n        if event_site != CommunicateData.SUB_WORKER_PROCESS:\n            with self.event_lock:\n                try:\n                    data = {\n                        CommunicationMetaData.COMMAND: CommunicateData.HANDLE_EVENT,\n                        CommunicationMetaData.FL_CTX: get_serializable_data(fl_ctx),\n                        CommunicationMetaData.EVENT_TYPE: event_type,\n                    }\n                    # send the init data to all the child processes\n                    for conn_client in self.conn_clients:\n                        conn_client[CommunicationMetaData.HANDLE_CONN].send(data)\n\n                    return_data = self.conn_clients[0][CommunicationMetaData.HANDLE_CONN].recv()\n                    # update the fl_ctx from the child process return data.\n                    fl_ctx.props.update(return_data[CommunicationMetaData.FL_CTX].props)\n                except BaseException as e:\n                    # Warning: Have to set fire_event=False, otherwise it will cause dead loop on the event handling!!!\n                    self.log_warning(\n                        fl_ctx, f\"Failed to relay the event to child processes. Event: {event_type}\", fire_event=False\n                    )",
  "def initialize(self, fl_ctx: FLContext):\n        self.executor = self.components.get(self.executor_id, None)\n        if not isinstance(self.executor, Executor):\n            raise ValueError(\n                \"invalid executor {}: expect Executor but got {}\".format(self.executor_id, type(self.executor))\n            )\n        self._initialize_multi_process(fl_ctx)",
  "def _initialize_multi_process(self, fl_ctx: FLContext):\n\n        try:\n            self.open_ports = get_open_ports(self.num_of_processes * 3)\n\n            command = (\n                self.get_multi_process_command()\n                + \" -m nvflare.private.fed.app.client.sub_worker_process\"\n                + \" -m \"\n                + fl_ctx.get_prop(FLContextKey.ARGS).workspace\n                + \" --ports \"\n                + \"-\".join([str(i) for i in self.open_ports])\n            )\n            self.logger.info(f\"multi_process_executor command: {command}\")\n            # use os.setsid to create new process group ID\n            self.exe_process = subprocess.Popen(shlex.split(command, \" \"), preexec_fn=os.setsid, env=os.environ.copy())\n\n            for i in range(self.num_of_processes):\n                listen_port = self.open_ports[i * 3 + 2]\n                thread = threading.Thread(target=self._relay_fire_event, args=(listen_port, fl_ctx))\n                self.relay_threads.append(thread)\n                thread.start()\n\n                open_port = self.open_ports[i * 3]\n                exe_conn = self._create_connection(open_port)\n\n                open_port = self.open_ports[i * 3 + 1]\n                handle_conn = self._create_connection(open_port)\n\n                self.conn_clients.append(\n                    {CommunicationMetaData.EXE_CONN: exe_conn, CommunicationMetaData.HANDLE_CONN: handle_conn}\n                )\n            self.logger.info(f\"Created the connections to child processes on ports: {str(self.open_ports)}\")\n\n            data = {\n                CommunicationMetaData.FL_CTX: get_serializable_data(fl_ctx),\n                CommunicationMetaData.COMPONENTS: self.components,\n                CommunicationMetaData.HANDLERS: self.handlers,\n                CommunicationMetaData.LOCAL_EXECUTOR: self.executor,\n            }\n\n            # send the init data to all the child processes\n            responses = []\n            for conn_client in self.conn_clients:\n                conn_client[CommunicationMetaData.EXE_CONN].send(data)\n                responses.append(False)\n\n            while True:\n                run_abort_signal = fl_ctx.get_run_abort_signal()\n                if run_abort_signal and run_abort_signal.triggered:\n                    self.finalize(fl_ctx)\n                    break\n\n                # Make sure to receive responses from all rank processes.\n                index = 0\n                received_all = True\n                for conn_client in self.conn_clients:\n                    received_all = received_all and responses[index]\n                    if not responses[index]:\n                        if conn_client[CommunicationMetaData.EXE_CONN].poll(0.2):\n                            conn_client[CommunicationMetaData.EXE_CONN].recv()\n                            responses[index] = True\n                    index += 1\n                if received_all:\n                    break\n        except:\n            self.log_exception(fl_ctx, \"error initializing multi_process executor\")",
  "def _relay_fire_event(self, listen_port, fl_ctx: FLContext):\n        address = (\"localhost\", int(listen_port))\n        listener = Listener(address, authkey=CommunicationMetaData.PARENT_PASSWORD.encode())\n        conn = listener.accept()\n\n        while not self.stop_execute:\n            try:\n                if conn.poll(0.1):\n                    data = conn.recv()\n                    event_type = data[CommunicationMetaData.EVENT_TYPE]\n                    rank_number = data[CommunicationMetaData.RANK_NUMBER]\n\n                    with self.relay_lock:\n                        fl_ctx.props.update(data[CommunicationMetaData.FL_CTX].props)\n\n                        fl_ctx.set_prop(FLContextKey.FROM_RANK_NUMBER, rank_number, private=True, sticky=False)\n                        fl_ctx.set_prop(\n                            FLContextKey.EVENT_ORIGIN_SITE,\n                            CommunicateData.SUB_WORKER_PROCESS,\n                            private=True,\n                            sticky=False,\n                        )\n                        engine = fl_ctx.get_engine()\n                        engine.fire_event(event_type, fl_ctx)\n\n                        return_data = {CommunicationMetaData.FL_CTX: get_serializable_data(fl_ctx)}\n                    conn.send(return_data)\n            except:\n                self.logger.warning(\"Failed to relay the fired events from rank_processes.\")",
  "def _create_connection(self, open_port):\n        conn = None\n        while not conn:\n            try:\n                address = (\"localhost\", open_port)\n                conn = Client(address, authkey=CommunicationMetaData.CHILD_PASSWORD.encode())\n            except BaseException as e:\n                time.sleep(1.0)\n                pass\n        return conn",
  "def execute(self, task_name: str, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        if not self.executor:\n            raise RuntimeError(\"There's no executor for task {}\".format(task_name))\n\n        return self._execute_multi_process(\n            task_name=task_name, shareable=shareable, fl_ctx=fl_ctx, abort_signal=abort_signal\n        )",
  "def _execute_multi_process(\n        self, task_name: str, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal\n    ) -> Shareable:\n\n        if abort_signal.triggered:\n            self.finalize(fl_ctx)\n            return make_reply(ReturnCode.OK)\n\n        try:\n            data = {\n                CommunicationMetaData.COMMAND: CommunicateData.EXECUTE,\n                CommunicationMetaData.TASK_NAME: task_name,\n                CommunicationMetaData.SHAREABLE: shareable,\n                CommunicationMetaData.FL_CTX: get_serializable_data(fl_ctx),\n            }\n\n            # send the execute command to all the child processes\n            for conn_client in self.conn_clients:\n                conn_client[CommunicationMetaData.EXE_CONN].send(data)\n\n            while True:\n                if abort_signal.triggered:\n                    self.finalize(fl_ctx)\n                    return make_reply(ReturnCode.OK)\n\n                if self.conn_clients[0][CommunicationMetaData.EXE_CONN].poll(1.0):\n                    # Only need to receive the Shareable and FLContext update from rank 0 process.\n                    return_data = self.conn_clients[0][CommunicationMetaData.EXE_CONN].recv()\n                    shareable = return_data[CommunicationMetaData.SHAREABLE]\n                    fl_ctx.props.update(return_data[CommunicationMetaData.FL_CTX].props)\n                    return shareable\n        except BaseException as e:\n            self.log_error(fl_ctx, \"Multi-Process Execution error.\")\n            return make_reply(ReturnCode.EXECUTION_RESULT_ERROR)",
  "def finalize(self, fl_ctx: FLContext):\n        \"\"\"This is called when exiting/aborting the executor.\"\"\"\n        if self.finalized:\n            return\n\n        self.finalized = True\n        self.stop_execute = True\n\n        data = {CommunicationMetaData.COMMAND: CommunicateData.CLOSE}\n        for conn_client in self.conn_clients:\n            try:\n                conn_client[CommunicationMetaData.EXE_CONN].send(data)\n                conn_client[CommunicationMetaData.HANDLE_CONN].send(data)\n                self.logger.info(\"close command sent to rank processes.\")\n            except:\n                self.logger.warning(\"Failed to send the close command. \")\n        try:\n            os.killpg(os.getpgid(self.exe_process.pid), 9)\n            self.logger.debug(\"kill signal sent\")\n        except Exception as e:\n            pass\n\n        if self.exe_process:\n            self.exe_process.terminate()\n\n        # wait for all relay threads to join!\n        for t in self.relay_threads:\n            if t.is_alive():\n                t.join()\n\n        self.log_info(fl_ctx, \"Multi-Process Executor finalized!\", fire_event=False)",
  "class ValidationJsonGenerator(Widget):\n    def __init__(self, results_dir=AppConstants.CROSS_VAL_DIR, json_file_name=\"cross_val_results.json\"):\n        \"\"\"Catches VALIDATION_RESULT_RECEIVED event and generates a results.json containing accuracy of each\n        validated model.\n\n        Args:\n            results_dir (str, optional): Name of the results directory. Defaults to cross_site_val\n            json_file_name (str, optional): Name of the json file. Defaults to cross_val_results.json\n        \"\"\"\n        super(ValidationJsonGenerator, self).__init__()\n\n        self._results_dir = results_dir\n        self._val_results = {}\n        self._json_file_name = json_file_name\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self._val_results.clear()\n        elif event_type == AppEventType.VALIDATION_RESULT_RECEIVED:\n            model_owner = fl_ctx.get_prop(AppConstants.MODEL_OWNER, None)\n            data_client = fl_ctx.get_prop(AppConstants.DATA_CLIENT, None)\n            val_results = fl_ctx.get_prop(AppConstants.VALIDATION_RESULT, None)\n\n            if not model_owner:\n                self.log_error(\n                    fl_ctx, \"model_owner unknown. Validation result will not be saved to json\", fire_event=False\n                )\n            if not data_client:\n                self.log_error(\n                    fl_ctx, \"data_client unknown. Validation result will not be saved to json\", fire_event=False\n                )\n\n            if val_results:\n                try:\n                    dxo = from_shareable(val_results)\n                    dxo.validate()\n\n                    if dxo.data_kind == DataKind.METRICS:\n                        if data_client not in self._val_results:\n                            self._val_results[data_client] = {}\n                        self._val_results[data_client][model_owner] = dxo.data\n                    else:\n                        self.log_error(\n                            fl_ctx, f\"Expected dxo of kind METRICS but got {dxo.data_kind} instead.\", fire_event=False\n                        )\n                except:\n                    self.log_exception(fl_ctx, \"Exception in handling validation result.\", fire_event=False)\n            else:\n                self.log_error(fl_ctx, \"Validation result not found.\", fire_event=False)\n        elif event_type == EventType.END_RUN:\n            run_dir = fl_ctx.get_engine().get_workspace().get_run_dir(fl_ctx.get_job_id())\n            cross_val_res_dir = os.path.join(run_dir, self._results_dir)\n            if not os.path.exists(cross_val_res_dir):\n                os.makedirs(cross_val_res_dir)\n\n            res_file_path = os.path.join(cross_val_res_dir, self._json_file_name)\n            with open(res_file_path, \"w\") as f:\n                json.dump(self._val_results, f)",
  "def __init__(self, results_dir=AppConstants.CROSS_VAL_DIR, json_file_name=\"cross_val_results.json\"):\n        \"\"\"Catches VALIDATION_RESULT_RECEIVED event and generates a results.json containing accuracy of each\n        validated model.\n\n        Args:\n            results_dir (str, optional): Name of the results directory. Defaults to cross_site_val\n            json_file_name (str, optional): Name of the json file. Defaults to cross_val_results.json\n        \"\"\"\n        super(ValidationJsonGenerator, self).__init__()\n\n        self._results_dir = results_dir\n        self._val_results = {}\n        self._json_file_name = json_file_name",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self._val_results.clear()\n        elif event_type == AppEventType.VALIDATION_RESULT_RECEIVED:\n            model_owner = fl_ctx.get_prop(AppConstants.MODEL_OWNER, None)\n            data_client = fl_ctx.get_prop(AppConstants.DATA_CLIENT, None)\n            val_results = fl_ctx.get_prop(AppConstants.VALIDATION_RESULT, None)\n\n            if not model_owner:\n                self.log_error(\n                    fl_ctx, \"model_owner unknown. Validation result will not be saved to json\", fire_event=False\n                )\n            if not data_client:\n                self.log_error(\n                    fl_ctx, \"data_client unknown. Validation result will not be saved to json\", fire_event=False\n                )\n\n            if val_results:\n                try:\n                    dxo = from_shareable(val_results)\n                    dxo.validate()\n\n                    if dxo.data_kind == DataKind.METRICS:\n                        if data_client not in self._val_results:\n                            self._val_results[data_client] = {}\n                        self._val_results[data_client][model_owner] = dxo.data\n                    else:\n                        self.log_error(\n                            fl_ctx, f\"Expected dxo of kind METRICS but got {dxo.data_kind} instead.\", fire_event=False\n                        )\n                except:\n                    self.log_exception(fl_ctx, \"Exception in handling validation result.\", fire_event=False)\n            else:\n                self.log_error(fl_ctx, \"Validation result not found.\", fire_event=False)\n        elif event_type == EventType.END_RUN:\n            run_dir = fl_ctx.get_engine().get_workspace().get_run_dir(fl_ctx.get_job_id())\n            cross_val_res_dir = os.path.join(run_dir, self._results_dir)\n            if not os.path.exists(cross_val_res_dir):\n                os.makedirs(cross_val_res_dir)\n\n            res_file_path = os.path.join(cross_val_res_dir, self._json_file_name)\n            with open(res_file_path, \"w\") as f:\n                json.dump(self._val_results, f)",
  "class IntimeModelSelector(Widget):\n    def __init__(self, weigh_by_local_iter=False, aggregation_weights=None):\n        \"\"\"Handler to determine if the model is globally best.\n\n        Args:\n            weigh_by_local_iter (bool, optional): whether the metrics should be weighted by trainer's iteration number.\n            aggregation_weights (dict, optional): a mapping of client name to float for aggregation. Defaults to None.\n        \"\"\"\n        super().__init__()\n\n        self.val_metric = self.best_val_metric = -np.inf\n        self.weigh_by_local_iter = weigh_by_local_iter\n        self.validation_metric_name = MetaKey.INITIAL_METRICS\n        self.aggregation_weights = aggregation_weights or {}\n\n        self.logger.debug(f\"model selection weights control: {aggregation_weights}\")\n        self._reset_stats()\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self._startup(fl_ctx)\n        elif event_type == EventType.BEFORE_PROCESS_SUBMISSION:\n            self._before_accept(fl_ctx)\n        elif event_type == AppEventType.BEFORE_AGGREGATION:\n            self._before_aggregate(fl_ctx)\n\n    def _startup(self, fl_ctx):\n        self._reset_stats()\n\n    def _reset_stats(self):\n        self.validation_metric_weighted_sum = 0\n        self.validation_metric_sum_of_weights = 0\n\n    def _before_accept(self, fl_ctx: FLContext):\n        peer_ctx = fl_ctx.get_peer_context()\n        shareable: Shareable = peer_ctx.get_prop(FLContextKey.SHAREABLE)\n        try:\n            dxo = from_shareable(shareable)\n        except:\n            self.log_exception(fl_ctx, \"shareable data is not a valid DXO\")\n            return False\n\n        if dxo.data_kind not in (DataKind.WEIGHT_DIFF, DataKind.WEIGHTS, DataKind.COLLECTION):\n            self.log_debug(fl_ctx, \"cannot handle {}\".format(dxo.data_kind))\n            return False\n\n        if dxo.data is None:\n            self.log_debug(fl_ctx, \"no data to filter\")\n            return False\n\n        contribution_round = shareable.get_header(AppConstants.CONTRIBUTION_ROUND)\n        client_name = shareable.get_peer_prop(ReservedKey.IDENTITY_NAME, default=\"?\")\n\n        current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n\n        if current_round == 0:\n            self.log_debug(fl_ctx, \"skipping round 0\")\n            return False  # There is no aggregated model at round 0\n\n        if contribution_round != current_round:\n            self.log_debug(\n                fl_ctx,\n                f\"discarding shareable from {client_name} for round: {contribution_round}. Current round is: {current_round}\",\n            )\n            return False\n\n        validation_metric = dxo.get_meta_prop(self.validation_metric_name)\n        if validation_metric is None:\n            self.log_debug(fl_ctx, f\"validation metric not existing in {client_name}\")\n            return False\n        else:\n            self.log_info(fl_ctx, f\"validation metric {validation_metric} from client {client_name}\")\n\n        if self.weigh_by_local_iter:\n            n_iter = dxo.get_meta_prop(MetaKey.NUM_STEPS_CURRENT_ROUND, 1.0)\n        else:\n            n_iter = 1.0\n\n        aggregation_weights = self.aggregation_weights.get(client_name, 1.0)\n        self.log_debug(fl_ctx, f\"aggregation weight: {aggregation_weights}\")\n\n        self.validation_metric_weighted_sum += validation_metric * n_iter * aggregation_weights\n        self.validation_metric_sum_of_weights += n_iter\n        return True\n\n    def _before_aggregate(self, fl_ctx):\n        if self.validation_metric_sum_of_weights == 0:\n            self.log_debug(fl_ctx, \"nothing accumulated\")\n            return False\n        self.val_metric = self.validation_metric_weighted_sum / self.validation_metric_sum_of_weights\n        self.logger.debug(f\"weighted validation metric {self.val_metric}\")\n        if self.val_metric > self.best_val_metric:\n            self.best_val_metric = self.val_metric\n            current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n            self.log_info(fl_ctx, f\"new best validation metric at round {current_round}: {self.best_val_metric}\")\n\n            # Fire event to notify that the current global model is a new best\n            self.fire_event(AppEventType.GLOBAL_BEST_MODEL_AVAILABLE, fl_ctx)\n\n        self._reset_stats()\n        return True",
  "class IntimeModelSelectionHandler(IntimeModelSelector):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.logger.warning(\"'IntimeModelSelectionHandler' was renamed to 'IntimeModelSelector'\")",
  "def __init__(self, weigh_by_local_iter=False, aggregation_weights=None):\n        \"\"\"Handler to determine if the model is globally best.\n\n        Args:\n            weigh_by_local_iter (bool, optional): whether the metrics should be weighted by trainer's iteration number.\n            aggregation_weights (dict, optional): a mapping of client name to float for aggregation. Defaults to None.\n        \"\"\"\n        super().__init__()\n\n        self.val_metric = self.best_val_metric = -np.inf\n        self.weigh_by_local_iter = weigh_by_local_iter\n        self.validation_metric_name = MetaKey.INITIAL_METRICS\n        self.aggregation_weights = aggregation_weights or {}\n\n        self.logger.debug(f\"model selection weights control: {aggregation_weights}\")\n        self._reset_stats()",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self._startup(fl_ctx)\n        elif event_type == EventType.BEFORE_PROCESS_SUBMISSION:\n            self._before_accept(fl_ctx)\n        elif event_type == AppEventType.BEFORE_AGGREGATION:\n            self._before_aggregate(fl_ctx)",
  "def _startup(self, fl_ctx):\n        self._reset_stats()",
  "def _reset_stats(self):\n        self.validation_metric_weighted_sum = 0\n        self.validation_metric_sum_of_weights = 0",
  "def _before_accept(self, fl_ctx: FLContext):\n        peer_ctx = fl_ctx.get_peer_context()\n        shareable: Shareable = peer_ctx.get_prop(FLContextKey.SHAREABLE)\n        try:\n            dxo = from_shareable(shareable)\n        except:\n            self.log_exception(fl_ctx, \"shareable data is not a valid DXO\")\n            return False\n\n        if dxo.data_kind not in (DataKind.WEIGHT_DIFF, DataKind.WEIGHTS, DataKind.COLLECTION):\n            self.log_debug(fl_ctx, \"cannot handle {}\".format(dxo.data_kind))\n            return False\n\n        if dxo.data is None:\n            self.log_debug(fl_ctx, \"no data to filter\")\n            return False\n\n        contribution_round = shareable.get_header(AppConstants.CONTRIBUTION_ROUND)\n        client_name = shareable.get_peer_prop(ReservedKey.IDENTITY_NAME, default=\"?\")\n\n        current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n\n        if current_round == 0:\n            self.log_debug(fl_ctx, \"skipping round 0\")\n            return False  # There is no aggregated model at round 0\n\n        if contribution_round != current_round:\n            self.log_debug(\n                fl_ctx,\n                f\"discarding shareable from {client_name} for round: {contribution_round}. Current round is: {current_round}\",\n            )\n            return False\n\n        validation_metric = dxo.get_meta_prop(self.validation_metric_name)\n        if validation_metric is None:\n            self.log_debug(fl_ctx, f\"validation metric not existing in {client_name}\")\n            return False\n        else:\n            self.log_info(fl_ctx, f\"validation metric {validation_metric} from client {client_name}\")\n\n        if self.weigh_by_local_iter:\n            n_iter = dxo.get_meta_prop(MetaKey.NUM_STEPS_CURRENT_ROUND, 1.0)\n        else:\n            n_iter = 1.0\n\n        aggregation_weights = self.aggregation_weights.get(client_name, 1.0)\n        self.log_debug(fl_ctx, f\"aggregation weight: {aggregation_weights}\")\n\n        self.validation_metric_weighted_sum += validation_metric * n_iter * aggregation_weights\n        self.validation_metric_sum_of_weights += n_iter\n        return True",
  "def _before_aggregate(self, fl_ctx):\n        if self.validation_metric_sum_of_weights == 0:\n            self.log_debug(fl_ctx, \"nothing accumulated\")\n            return False\n        self.val_metric = self.validation_metric_weighted_sum / self.validation_metric_sum_of_weights\n        self.logger.debug(f\"weighted validation metric {self.val_metric}\")\n        if self.val_metric > self.best_val_metric:\n            self.best_val_metric = self.val_metric\n            current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n            self.log_info(fl_ctx, f\"new best validation metric at round {current_round}: {self.best_val_metric}\")\n\n            # Fire event to notify that the current global model is a new best\n            self.fire_event(AppEventType.GLOBAL_BEST_MODEL_AVAILABLE, fl_ctx)\n\n        self._reset_stats()\n        return True",
  "def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.logger.warning(\"'IntimeModelSelectionHandler' was renamed to 'IntimeModelSelector'\")",
  "def send_analytic_dxo(comp: FLComponent, dxo: DXO, fl_ctx: FLContext, event_type: str = ANALYTIC_EVENT_TYPE):\n    \"\"\"Sends analytic dxo.\n\n    Args:\n        comp (FLComponent): An FLComponent.\n        dxo (DXO): analytic data in dxo.\n        fl_ctx (FLContext): fl context info.\n        event_type (str): Event type.\n    \"\"\"\n    if not isinstance(comp, FLComponent):\n        raise TypeError(f\"expect comp to be an instance of FLComponent, but got {type(comp)}\")\n    if not isinstance(dxo, DXO):\n        raise TypeError(f\"expect dxo to be an instance of DXO, but got {type(dxo)}\")\n    if not isinstance(fl_ctx, FLContext):\n        raise TypeError(f\"expect fl_ctx to be an instance of FLContext, but got {type(fl_ctx)}\")\n\n    fl_ctx.set_prop(key=FLContextKey.EVENT_DATA, value=dxo.to_shareable(), private=True, sticky=False)\n    comp.fire_event(event_type=event_type, fl_ctx=fl_ctx)",
  "def create_analytic_dxo(tag: str, value, data_type: AnalyticsDataType, **kwargs) -> DXO:\n    \"\"\"Creates the analytic DXO.\n\n    Args:\n        tag (str): the tag associated with this value.\n        value: the analytic data.\n        data_type (AnalyticsDataType): analytic data type.\n        kwargs: additional arguments to be passed into the receiver side's function.\n\n    Returns:\n        A DXO object that contains the analytic data.\n    \"\"\"\n    data = AnalyticsData(tag=tag, value=value, data_type=data_type, kwargs=kwargs)\n    dxo = data.to_dxo()\n    return dxo",
  "class AnalyticsSender(Widget):\n    def __init__(self, event_type=ANALYTIC_EVENT_TYPE):\n        \"\"\"Sends analytics data.\n\n        Note::\n            This class implements some common methods follows signatures from PyTorch SummaryWriter.\n            It provides a convenient way for Learner to use.\n\n        Args:\n            event_type (str): event type to fire.\n        \"\"\"\n        super().__init__()\n        self.engine = None\n        self.event_type = event_type\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.engine = fl_ctx.get_engine()\n\n    def _add(\n        self,\n        tag: str,\n        value,\n        data_type: AnalyticsDataType,\n        global_step: Optional[int] = None,\n        kwargs: Optional[dict] = None,\n    ):\n        kwargs = kwargs if kwargs else {}\n        if global_step:\n            if not isinstance(global_step, int):\n                raise TypeError(f\"Expect global step to be an instance of int, but got {type(global_step)}\")\n            kwargs[\"global_step\"] = global_step\n        dxo = create_analytic_dxo(tag=tag, value=value, data_type=data_type, **kwargs)\n        with self.engine.new_context() as fl_ctx:\n            send_analytic_dxo(self, dxo=dxo, fl_ctx=fl_ctx, event_type=self.event_type)\n\n    def add_scalar(self, tag: str, scalar: float, global_step: Optional[int] = None, **kwargs):\n        \"\"\"Sends a scalar.\n\n        Args:\n            tag (str): Data identifier.\n            scalar (float): Value to send.\n            global_step (optional, int): Global step value.\n            **kwargs: Additional arguments to pass to the receiver side.\n        \"\"\"\n        self._add(tag=tag, value=scalar, data_type=AnalyticsDataType.SCALAR, global_step=global_step, kwargs=kwargs)\n\n    def add_scalars(self, tag: str, scalars: dict, global_step: Optional[int] = None, **kwargs):\n        \"\"\"Sends scalars.\n\n        Args:\n            tag (str): The parent name for the tags.\n            scalars (dict): Key-value pair storing the tag and corresponding values.\n            global_step (optional, int): Global step value.\n            **kwargs: Additional arguments to pass to the receiver side.\n        \"\"\"\n        self._add(tag=tag, value=scalars, data_type=AnalyticsDataType.SCALARS, global_step=global_step, kwargs=kwargs)\n\n    def add_text(self, tag: str, text: str, global_step: Optional[int] = None, **kwargs):\n        \"\"\"Sends a text.\n\n        Args:\n            tag (str): Data identifier.\n            text (str): String to send.\n            global_step (optional, int): Global step value.\n            **kwargs: Additional arguments to pass to the receiver side.\n        \"\"\"\n        self._add(tag=tag, value=text, data_type=AnalyticsDataType.TEXT, global_step=global_step, kwargs=kwargs)\n\n    def add_image(self, tag: str, image, global_step: Optional[int] = None, **kwargs):\n        \"\"\"Sends an image.\n\n        Args:\n            tag (str): Data identifier.\n            image: Image to send.\n            global_step (optional, int): Global step value.\n            **kwargs: Additional arguments to pass to the receiver side.\n        \"\"\"\n        self._add(tag=tag, value=image, data_type=AnalyticsDataType.IMAGE, global_step=global_step, kwargs=kwargs)\n\n    def flush(self):\n        \"\"\"Flushes out the message.\n\n        This is doing nothing, it is defined for mimic the PyTorch SummaryWriter behavior.\n        \"\"\"\n        pass\n\n    def close(self):\n        \"\"\"Close resources.\"\"\"\n        if self.engine:\n            self.engine = None",
  "class AnalyticsReceiver(Widget, ABC):\n    def __init__(self, events: Optional[List[str]] = None):\n        \"\"\"Receives analytic data.\n\n        Args:\n            events (optional, List[str]): A list of event that this receiver will handle.\n        \"\"\"\n        super().__init__()\n        if events is None:\n            events = [ANALYTIC_EVENT_TYPE, f\"fed.{ANALYTIC_EVENT_TYPE}\"]\n        self.events = events\n        self._save_lock = Lock()\n        self._end = False\n\n    @abstractmethod\n    def initialize(self, fl_ctx: FLContext):\n        \"\"\"Initializes the receiver.\n\n        Args:\n            fl_ctx (FLContext): fl context.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def save(self, fl_ctx: FLContext, shareable: Shareable, record_origin: str):\n        \"\"\"Saves the received data.\n\n        Args:\n            fl_ctx (FLContext): fl context.\n            shareable (Shareable): the received message.\n            record_origin (str): the sender of this message / record.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def finalize(self, fl_ctx: FLContext):\n        \"\"\"Finalizes the receiver.\n\n        Args:\n            fl_ctx (FLContext): fl context.\n        \"\"\"\n        pass\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.initialize(fl_ctx)\n        elif event_type in self.events:\n            if self._end:\n                self.log_debug(fl_ctx, f\"Already received end run event, drop event {event_type}.\", fire_event=False)\n                return\n            data = fl_ctx.get_prop(FLContextKey.EVENT_DATA, None)\n            if data is None:\n                self.log_error(fl_ctx, \"Missing event data.\", fire_event=False)\n                return\n            if not isinstance(data, Shareable):\n                self.log_error(\n                    fl_ctx, f\"Expect data to be an instance of Shareable but got {type(data)}\", fire_event=False\n                )\n                return\n\n            # if fed event use peer name to save\n            if fl_ctx.get_prop(FLContextKey.EVENT_SCOPE) == EventScope.FEDERATION:\n                record_origin = data.get_peer_prop(ReservedKey.IDENTITY_NAME, None)\n            else:\n                record_origin = fl_ctx.get_identity_name()\n\n            if record_origin is None:\n                self.log_error(fl_ctx, \"record_origin can't be None.\", fire_event=False)\n                return\n            with self._save_lock:\n                self.save(shareable=data, fl_ctx=fl_ctx, record_origin=record_origin)\n        elif event_type == EventType.END_RUN:\n            self._end = True\n            self.finalize(fl_ctx)",
  "def __init__(self, event_type=ANALYTIC_EVENT_TYPE):\n        \"\"\"Sends analytics data.\n\n        Note::\n            This class implements some common methods follows signatures from PyTorch SummaryWriter.\n            It provides a convenient way for Learner to use.\n\n        Args:\n            event_type (str): event type to fire.\n        \"\"\"\n        super().__init__()\n        self.engine = None\n        self.event_type = event_type",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.engine = fl_ctx.get_engine()",
  "def _add(\n        self,\n        tag: str,\n        value,\n        data_type: AnalyticsDataType,\n        global_step: Optional[int] = None,\n        kwargs: Optional[dict] = None,\n    ):\n        kwargs = kwargs if kwargs else {}\n        if global_step:\n            if not isinstance(global_step, int):\n                raise TypeError(f\"Expect global step to be an instance of int, but got {type(global_step)}\")\n            kwargs[\"global_step\"] = global_step\n        dxo = create_analytic_dxo(tag=tag, value=value, data_type=data_type, **kwargs)\n        with self.engine.new_context() as fl_ctx:\n            send_analytic_dxo(self, dxo=dxo, fl_ctx=fl_ctx, event_type=self.event_type)",
  "def add_scalar(self, tag: str, scalar: float, global_step: Optional[int] = None, **kwargs):\n        \"\"\"Sends a scalar.\n\n        Args:\n            tag (str): Data identifier.\n            scalar (float): Value to send.\n            global_step (optional, int): Global step value.\n            **kwargs: Additional arguments to pass to the receiver side.\n        \"\"\"\n        self._add(tag=tag, value=scalar, data_type=AnalyticsDataType.SCALAR, global_step=global_step, kwargs=kwargs)",
  "def add_scalars(self, tag: str, scalars: dict, global_step: Optional[int] = None, **kwargs):\n        \"\"\"Sends scalars.\n\n        Args:\n            tag (str): The parent name for the tags.\n            scalars (dict): Key-value pair storing the tag and corresponding values.\n            global_step (optional, int): Global step value.\n            **kwargs: Additional arguments to pass to the receiver side.\n        \"\"\"\n        self._add(tag=tag, value=scalars, data_type=AnalyticsDataType.SCALARS, global_step=global_step, kwargs=kwargs)",
  "def add_text(self, tag: str, text: str, global_step: Optional[int] = None, **kwargs):\n        \"\"\"Sends a text.\n\n        Args:\n            tag (str): Data identifier.\n            text (str): String to send.\n            global_step (optional, int): Global step value.\n            **kwargs: Additional arguments to pass to the receiver side.\n        \"\"\"\n        self._add(tag=tag, value=text, data_type=AnalyticsDataType.TEXT, global_step=global_step, kwargs=kwargs)",
  "def add_image(self, tag: str, image, global_step: Optional[int] = None, **kwargs):\n        \"\"\"Sends an image.\n\n        Args:\n            tag (str): Data identifier.\n            image: Image to send.\n            global_step (optional, int): Global step value.\n            **kwargs: Additional arguments to pass to the receiver side.\n        \"\"\"\n        self._add(tag=tag, value=image, data_type=AnalyticsDataType.IMAGE, global_step=global_step, kwargs=kwargs)",
  "def flush(self):\n        \"\"\"Flushes out the message.\n\n        This is doing nothing, it is defined for mimic the PyTorch SummaryWriter behavior.\n        \"\"\"\n        pass",
  "def close(self):\n        \"\"\"Close resources.\"\"\"\n        if self.engine:\n            self.engine = None",
  "def __init__(self, events: Optional[List[str]] = None):\n        \"\"\"Receives analytic data.\n\n        Args:\n            events (optional, List[str]): A list of event that this receiver will handle.\n        \"\"\"\n        super().__init__()\n        if events is None:\n            events = [ANALYTIC_EVENT_TYPE, f\"fed.{ANALYTIC_EVENT_TYPE}\"]\n        self.events = events\n        self._save_lock = Lock()\n        self._end = False",
  "def initialize(self, fl_ctx: FLContext):\n        \"\"\"Initializes the receiver.\n\n        Args:\n            fl_ctx (FLContext): fl context.\n        \"\"\"\n        pass",
  "def save(self, fl_ctx: FLContext, shareable: Shareable, record_origin: str):\n        \"\"\"Saves the received data.\n\n        Args:\n            fl_ctx (FLContext): fl context.\n            shareable (Shareable): the received message.\n            record_origin (str): the sender of this message / record.\n        \"\"\"\n        pass",
  "def finalize(self, fl_ctx: FLContext):\n        \"\"\"Finalizes the receiver.\n\n        Args:\n            fl_ctx (FLContext): fl context.\n        \"\"\"\n        pass",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.initialize(fl_ctx)\n        elif event_type in self.events:\n            if self._end:\n                self.log_debug(fl_ctx, f\"Already received end run event, drop event {event_type}.\", fire_event=False)\n                return\n            data = fl_ctx.get_prop(FLContextKey.EVENT_DATA, None)\n            if data is None:\n                self.log_error(fl_ctx, \"Missing event data.\", fire_event=False)\n                return\n            if not isinstance(data, Shareable):\n                self.log_error(\n                    fl_ctx, f\"Expect data to be an instance of Shareable but got {type(data)}\", fire_event=False\n                )\n                return\n\n            # if fed event use peer name to save\n            if fl_ctx.get_prop(FLContextKey.EVENT_SCOPE) == EventScope.FEDERATION:\n                record_origin = data.get_peer_prop(ReservedKey.IDENTITY_NAME, None)\n            else:\n                record_origin = fl_ctx.get_identity_name()\n\n            if record_origin is None:\n                self.log_error(fl_ctx, \"record_origin can't be None.\", fire_event=False)\n                return\n            with self._save_lock:\n                self.save(shareable=data, fl_ctx=fl_ctx, record_origin=record_origin)\n        elif event_type == EventType.END_RUN:\n            self._end = True\n            self.finalize(fl_ctx)",
  "class _CtxPropReq(object):\n    \"\"\"Requirements of a prop in the FLContext.\n\n    Arguments:\n        dtype: data type of the prop.\n        is_private: if this prop is private.\n        is_sticky: if this prop is sticky.\n        allow_none: if this prop can be None\n    \"\"\"\n\n    def __init__(self, dtype, is_private, is_sticky, allow_none: bool = False):\n        self.dtype = dtype\n        self.is_private = is_private\n        self.is_sticky = is_sticky\n        self.allow_none = allow_none",
  "class _EventReq(object):\n    \"\"\"Requirements for FL and peer context when an event is fired.\n\n    Arguments:\n        ctx_reqs: A dictionary that describes the requirements for fl_ctx. It maps property names to _CtxPropReq\n        peer_ctx_reqs: A dictionary that describes the requirements for peer_ctx. It maps property names to _CtxPropReq\n    \"\"\"\n\n    def __init__(\n        self,\n        ctx_reqs: Dict[str, _CtxPropReq],\n        peer_ctx_reqs: Dict[str, _CtxPropReq],\n        ctx_block_list: [str] = None,\n        peer_ctx_block_list: [str] = None,\n    ):\n        self.ctx_reqs = ctx_reqs  # prop name => _CtxPropReq\n        self.peer_ctx_reqs = peer_ctx_reqs\n\n        if ctx_block_list is None:\n            ctx_block_list = []\n\n        if peer_ctx_block_list is None:\n            peer_ctx_block_list = []\n\n        self.ctx_block_list = ctx_block_list\n        self.peer_ctx_block_list = peer_ctx_block_list",
  "class _EventStats(object):\n    \"\"\"Stats of each event.\"\"\"\n\n    def __init__(self):\n        self.call_count = 0\n        self.prop_missing = 0\n        self.prop_none_value = 0\n        self.prop_dtype_mismatch = 0\n        self.prop_attr_mismatch = 0\n        self.prop_block_list_violation = 0\n        self.peer_ctx_missing = 0",
  "class EventRecorder(Widget):\n\n    _KEY_CTX_TYPE = \"ctx_type\"\n    _KEY_EVENT_TYPE = \"event_type\"\n    _KEY_EVENT_STATS = \"event_stats\"\n    _KEY_EVENT_REQ = \"event_req\"\n\n    def __init__(self, log_file_name=None):\n        \"\"\"A component to record all system-wide events.\n\n        Args:\n            log_file_name (str, optional): the log filename to save recorded events. Defaults to None.\n        \"\"\"\n        super().__init__()\n\n        all_ctx_reqs = {\n            \"__run_num__\": _CtxPropReq(dtype=str, is_private=False, is_sticky=True),\n            \"__identity_name__\": _CtxPropReq(dtype=str, is_private=False, is_sticky=True),\n        }\n\n        run_req = _EventReq(ctx_reqs=all_ctx_reqs, peer_ctx_reqs={})\n        self.event_reqs = {EventType.START_RUN: run_req, EventType.END_RUN: run_req}  # event type => _EventReq\n        self.event_stats = {}  # event_type => _EventStats\n        self._log_handler_added = False\n        self.log_file_name = log_file_name if log_file_name else \"event_recorded.txt\"\n\n    def event_tag(self, fl_ctx: FLContext):\n        event_type = fl_ctx.get_prop(self._KEY_EVENT_TYPE, \"?\")\n        event_id = fl_ctx.get_prop(FLContextKey.EVENT_ID, None)\n        if event_id:\n            return \"[type={}, id={}]\".format(event_type, event_id)\n        else:\n            return \"[{}]\".format(event_type)\n\n    def event_error_tag(self, fl_ctx: FLContext):\n        ctx_type = fl_ctx.get_prop(self._KEY_CTX_TYPE, \"?\")\n        return \"Event {}: in {},\".format(self.event_tag(fl_ctx), ctx_type)\n\n    def validate_prop(self, prop_name: str, req: _CtxPropReq, fl_ctx: FLContext):\n        stats = fl_ctx.get_prop(self._KEY_EVENT_STATS, None)\n\n        detail = fl_ctx.get_prop_detail(prop_name)\n        if not isinstance(detail, dict):\n            stats.prop_missing += 1\n            self.logger.error(\"{} required prop '{}' doesn't exist\".format(self.event_error_tag(fl_ctx), prop_name))\n            return\n\n        value = detail[\"value\"]\n        if value is None and not req.allow_none:\n            stats.prop_none_value += 1\n            self.logger.error(\n                \"{} prop '{}' is None, but None is not allowed\".format(self.event_error_tag(fl_ctx), prop_name)\n            )\n\n        if req.dtype is not None:\n            if not isinstance(value, req.dtype):\n                stats.prop_dtype_mismatch += 1\n                self.logger.error(\n                    \"{} prop '{}' should be {}, but got {}\".format(\n                        self.event_error_tag(fl_ctx), prop_name, req.dtype, type(value)\n                    )\n                )\n\n        if req.is_private and not detail[\"private\"]:\n            stats.prop_attr_mismatch += 1\n            self.logger.error(\n                \"{} prop '{}' should be private but is public\".format(self.event_error_tag(fl_ctx), prop_name)\n            )\n\n        if req.is_private is not None and not req.is_private and detail[\"private\"]:\n            stats.prop_attr_mismatch += 1\n            self.logger.error(\n                \"{} prop '{}' should be public but is private\".format(self.event_error_tag(fl_ctx), prop_name)\n            )\n\n        if req.is_sticky and not detail[\"sticky\"]:\n            stats.prop_attr_mismatch += 1\n            self.logger.error(\n                \"{} prop '{}' should be sticky but is non-sticky\".format(self.event_error_tag(fl_ctx), prop_name)\n            )\n\n        if req.is_sticky is not None and not req.is_sticky and detail[\"sticky\"]:\n            stats.prop_attr_mismatch += 1\n            self.logger.error(\n                \"{} prop '{}' should be non-sticky but is sticky\".format(self.event_error_tag(fl_ctx), prop_name)\n            )\n\n    def check_block_list(self, block_list, fl_ctx: FLContext):\n        stats = fl_ctx.get_prop(self._KEY_EVENT_STATS, None)\n        for prop_name in block_list:\n            detail = fl_ctx.get_prop_detail(prop_name)\n            if detail:\n                stats.prop_block_list_violation += 1\n                self.logger.error(\"{} prop {} is not expected\".format(self.event_error_tag(fl_ctx), prop_name))\n\n    def check_props(self, fl_ctx: FLContext):\n        event_req = fl_ctx.get_prop(self._KEY_EVENT_REQ)\n        stats = fl_ctx.get_prop(self._KEY_EVENT_STATS)\n\n        for prop_name, req in event_req.ctx_reqs.items():\n            self.validate_prop(prop_name, req, fl_ctx)\n\n        self.check_block_list(event_req.ctx_block_list, fl_ctx)\n\n        if event_req.peer_ctx_reqs:\n            peer_ctx = fl_ctx.get_peer_context()\n            if not peer_ctx:\n                stats.peer_ctx_missing += 1\n                self.logger.error(\"{} expected peer_ctx not present\".format(self.event_error_tag(fl_ctx)))\n            else:\n                for prop_name, req in event_req.peer_ctx_reqs.items():\n                    self.validate_prop(prop_name, req, peer_ctx)\n                self.check_block_list(event_req.peer_ctx_block_list, peer_ctx)\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if not self._log_handler_added:\n            workspace = fl_ctx.get_engine().get_workspace()\n            app_dir = workspace.get_app_dir(fl_ctx.get_job_id())\n            output_file_handler = logging.FileHandler(os.path.join(app_dir, self.log_file_name))\n            formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n            output_file_handler.setFormatter(formatter)\n            self.logger.addHandler(output_file_handler)\n            self._log_handler_added = True\n        event_stats = self.event_stats.get(event_type, None)\n        if not event_stats:\n            event_stats = _EventStats()\n            self.event_stats[event_type] = event_stats\n\n        fl_ctx.set_prop(key=self._KEY_EVENT_STATS, value=event_stats, private=True, sticky=False)\n        fl_ctx.set_prop(key=self._KEY_EVENT_TYPE, value=event_type, private=True, sticky=False)\n        fl_ctx.set_prop(key=self._KEY_CTX_TYPE, value=\"fl_ctx\", private=True, sticky=False)\n\n        self.log_info(fl_ctx, \"Got event {}\".format(self.event_tag(fl_ctx)), fire_event=False)\n        event_stats.call_count += 1\n\n        peer_ctx = fl_ctx.get_peer_context()\n        if peer_ctx:\n            event_id = fl_ctx.get_prop(FLContextKey.EVENT_ID)\n            peer_ctx.set_prop(key=FLContextKey.EVENT_ID, value=event_id, private=True, sticky=False)\n            peer_ctx.set_prop(key=self._KEY_EVENT_STATS, value=event_stats, private=True, sticky=False)\n            peer_ctx.set_prop(key=self._KEY_EVENT_TYPE, value=event_type, private=True, sticky=False)\n            peer_ctx.set_prop(key=self._KEY_CTX_TYPE, value=\"peer_ctx\", private=True, sticky=False)\n            self.log_info(\n                fl_ctx, \"Peer Context for event {}: {}\".format(self.event_tag(fl_ctx), peer_ctx), fire_event=False\n            )\n\n        event_req = self.event_reqs.get(event_type, None)\n        fl_ctx.set_prop(key=self._KEY_EVENT_REQ, value=event_req, private=True, sticky=False)\n        if event_req:\n            self.check_props(fl_ctx)\n\n        if event_type == EventType.END_RUN:\n            # print stats\n            for e, s in self.event_stats.items():\n                self.log_info(fl_ctx, \"Stats of {}: {}\".format(e, vars(s)), fire_event=False)",
  "class ServerEventRecorder(EventRecorder):\n    def __init__(self):\n        \"\"\"Server-specific event recorder.\"\"\"\n        super().__init__()\n\n        task_data_filter_reqs = _EventReq(\n            ctx_reqs={\n                \"__engine__\": _CtxPropReq(dtype=ServerEngineSpec, is_private=True, is_sticky=True),\n                FLContextKey.TASK_ID: _CtxPropReq(dtype=str, is_private=True, is_sticky=False),\n                FLContextKey.TASK_NAME: _CtxPropReq(dtype=str, is_private=True, is_sticky=False),\n                FLContextKey.TASK_DATA: _CtxPropReq(dtype=Shareable, is_private=True, is_sticky=False, allow_none=True),\n                \"testPrivateServerSticky\": _CtxPropReq(dtype=str, is_private=True, is_sticky=True),\n                \"testPublicServerSticky\": _CtxPropReq(dtype=str, is_private=False, is_sticky=True),\n            },\n            ctx_block_list=[\n                \"testPrivateServerNonSticky\",\n                \"testPublicServerNonSticky\",\n                \"testPrivateClientNonSticky\",\n                \"testPublicClientNonSticky\",\n                \"testPrivateClientSticky\",\n                \"testPublicClientSticky\",\n            ],\n            peer_ctx_reqs={\n                \"__run_num__\": _CtxPropReq(dtype=str, is_private=None, is_sticky=None),\n                \"__identity_name__\": _CtxPropReq(dtype=str, is_private=None, is_sticky=None),\n                \"testPublicClientSticky\": _CtxPropReq(dtype=str, is_private=None, is_sticky=None),\n            },\n            peer_ctx_block_list=[\n                \"__engine__\",\n                \"testPrivateClientSticky\",\n                \"testPrivateClientNonSticky\",\n                \"testPublicClientNonSticky\",\n            ],\n        )\n        self.event_reqs.update(\n            {\n                EventType.BEFORE_TASK_DATA_FILTER: task_data_filter_reqs,\n                EventType.AFTER_TASK_DATA_FILTER: task_data_filter_reqs,\n            }\n        )\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            fl_ctx.set_prop(\n                key=\"testPrivateServerSticky\", value=\"this is a server private sticky\", private=True, sticky=True\n            )\n\n            fl_ctx.set_prop(\n                key=\"testPublicServerSticky\", value=\"this is a server public sticky\", private=False, sticky=True\n            )\n\n            fl_ctx.set_prop(\n                key=\"testPrivateServerNonSticky\",\n                value=\"this is a server private non-sticky\",\n                private=True,\n                sticky=False,\n            )\n\n            fl_ctx.set_prop(\n                key=\"testPublicServerNonSticky\", value=\"this is a server public non-sticky\", private=False, sticky=False\n            )\n\n        super().handle_event(event_type, fl_ctx)",
  "class ClientEventRecorder(EventRecorder):\n    def __init__(self):\n        \"\"\"Client-specific event recorder.\"\"\"\n        super().__init__()\n\n        task_data_filter_reqs = _EventReq(\n            ctx_reqs={\n                \"__engine__\": _CtxPropReq(dtype=ClientEngineSpec, is_private=True, is_sticky=True),\n                FLContextKey.TASK_ID: _CtxPropReq(dtype=str, is_private=True, is_sticky=False),\n                FLContextKey.TASK_NAME: _CtxPropReq(dtype=str, is_private=True, is_sticky=False),\n                FLContextKey.TASK_DATA: _CtxPropReq(dtype=Shareable, is_private=True, is_sticky=False, allow_none=True),\n                \"testPrivateClientSticky\": _CtxPropReq(dtype=str, is_private=True, is_sticky=True),\n                \"testPublicClientSticky\": _CtxPropReq(dtype=str, is_private=False, is_sticky=True),\n            },\n            ctx_block_list=[\n                \"testPrivateServerNonSticky\",\n                \"testPublicServerNonSticky\",\n                \"testPrivateClientNonSticky\",\n                \"testPublicClientNonSticky\",\n                \"testPrivateServerSticky\",\n                \"testPublicServerSticky\",\n            ],\n            peer_ctx_reqs={\n                \"__run_num__\": _CtxPropReq(dtype=str, is_private=None, is_sticky=None),\n                \"__identity_name__\": _CtxPropReq(dtype=str, is_private=None, is_sticky=None),\n                \"testPublicServerSticky\": _CtxPropReq(dtype=str, is_private=None, is_sticky=None),\n            },\n            peer_ctx_block_list=[\n                \"__engine__\",\n                \"testPrivateServerSticky\",\n                \"testPrivateServerNonSticky\",\n                \"testPublicServerNonSticky\",\n            ],\n        )\n        self.event_reqs.update(\n            {\n                EventType.BEFORE_TASK_DATA_FILTER: task_data_filter_reqs,\n                EventType.AFTER_TASK_DATA_FILTER: task_data_filter_reqs,\n            }\n        )\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            fl_ctx.set_prop(\n                key=\"testPrivateClientSticky\", value=\"this is a client private sticky\", private=True, sticky=True\n            )\n\n            fl_ctx.set_prop(\n                key=\"testPublicClientSticky\", value=\"this is a client public sticky\", private=False, sticky=True\n            )\n\n            fl_ctx.set_prop(\n                key=\"testPrivateClientNonSticky\",\n                value=\"this is a client private non-sticky\",\n                private=True,\n                sticky=False,\n            )\n\n            fl_ctx.set_prop(\n                key=\"testPublicClientNonSticky\", value=\"this is a client public non-sticky\", private=False, sticky=False\n            )\n\n        super().handle_event(event_type, fl_ctx)",
  "def __init__(self, dtype, is_private, is_sticky, allow_none: bool = False):\n        self.dtype = dtype\n        self.is_private = is_private\n        self.is_sticky = is_sticky\n        self.allow_none = allow_none",
  "def __init__(\n        self,\n        ctx_reqs: Dict[str, _CtxPropReq],\n        peer_ctx_reqs: Dict[str, _CtxPropReq],\n        ctx_block_list: [str] = None,\n        peer_ctx_block_list: [str] = None,\n    ):\n        self.ctx_reqs = ctx_reqs  # prop name => _CtxPropReq\n        self.peer_ctx_reqs = peer_ctx_reqs\n\n        if ctx_block_list is None:\n            ctx_block_list = []\n\n        if peer_ctx_block_list is None:\n            peer_ctx_block_list = []\n\n        self.ctx_block_list = ctx_block_list\n        self.peer_ctx_block_list = peer_ctx_block_list",
  "def __init__(self):\n        self.call_count = 0\n        self.prop_missing = 0\n        self.prop_none_value = 0\n        self.prop_dtype_mismatch = 0\n        self.prop_attr_mismatch = 0\n        self.prop_block_list_violation = 0\n        self.peer_ctx_missing = 0",
  "def __init__(self, log_file_name=None):\n        \"\"\"A component to record all system-wide events.\n\n        Args:\n            log_file_name (str, optional): the log filename to save recorded events. Defaults to None.\n        \"\"\"\n        super().__init__()\n\n        all_ctx_reqs = {\n            \"__run_num__\": _CtxPropReq(dtype=str, is_private=False, is_sticky=True),\n            \"__identity_name__\": _CtxPropReq(dtype=str, is_private=False, is_sticky=True),\n        }\n\n        run_req = _EventReq(ctx_reqs=all_ctx_reqs, peer_ctx_reqs={})\n        self.event_reqs = {EventType.START_RUN: run_req, EventType.END_RUN: run_req}  # event type => _EventReq\n        self.event_stats = {}  # event_type => _EventStats\n        self._log_handler_added = False\n        self.log_file_name = log_file_name if log_file_name else \"event_recorded.txt\"",
  "def event_tag(self, fl_ctx: FLContext):\n        event_type = fl_ctx.get_prop(self._KEY_EVENT_TYPE, \"?\")\n        event_id = fl_ctx.get_prop(FLContextKey.EVENT_ID, None)\n        if event_id:\n            return \"[type={}, id={}]\".format(event_type, event_id)\n        else:\n            return \"[{}]\".format(event_type)",
  "def event_error_tag(self, fl_ctx: FLContext):\n        ctx_type = fl_ctx.get_prop(self._KEY_CTX_TYPE, \"?\")\n        return \"Event {}: in {},\".format(self.event_tag(fl_ctx), ctx_type)",
  "def validate_prop(self, prop_name: str, req: _CtxPropReq, fl_ctx: FLContext):\n        stats = fl_ctx.get_prop(self._KEY_EVENT_STATS, None)\n\n        detail = fl_ctx.get_prop_detail(prop_name)\n        if not isinstance(detail, dict):\n            stats.prop_missing += 1\n            self.logger.error(\"{} required prop '{}' doesn't exist\".format(self.event_error_tag(fl_ctx), prop_name))\n            return\n\n        value = detail[\"value\"]\n        if value is None and not req.allow_none:\n            stats.prop_none_value += 1\n            self.logger.error(\n                \"{} prop '{}' is None, but None is not allowed\".format(self.event_error_tag(fl_ctx), prop_name)\n            )\n\n        if req.dtype is not None:\n            if not isinstance(value, req.dtype):\n                stats.prop_dtype_mismatch += 1\n                self.logger.error(\n                    \"{} prop '{}' should be {}, but got {}\".format(\n                        self.event_error_tag(fl_ctx), prop_name, req.dtype, type(value)\n                    )\n                )\n\n        if req.is_private and not detail[\"private\"]:\n            stats.prop_attr_mismatch += 1\n            self.logger.error(\n                \"{} prop '{}' should be private but is public\".format(self.event_error_tag(fl_ctx), prop_name)\n            )\n\n        if req.is_private is not None and not req.is_private and detail[\"private\"]:\n            stats.prop_attr_mismatch += 1\n            self.logger.error(\n                \"{} prop '{}' should be public but is private\".format(self.event_error_tag(fl_ctx), prop_name)\n            )\n\n        if req.is_sticky and not detail[\"sticky\"]:\n            stats.prop_attr_mismatch += 1\n            self.logger.error(\n                \"{} prop '{}' should be sticky but is non-sticky\".format(self.event_error_tag(fl_ctx), prop_name)\n            )\n\n        if req.is_sticky is not None and not req.is_sticky and detail[\"sticky\"]:\n            stats.prop_attr_mismatch += 1\n            self.logger.error(\n                \"{} prop '{}' should be non-sticky but is sticky\".format(self.event_error_tag(fl_ctx), prop_name)\n            )",
  "def check_block_list(self, block_list, fl_ctx: FLContext):\n        stats = fl_ctx.get_prop(self._KEY_EVENT_STATS, None)\n        for prop_name in block_list:\n            detail = fl_ctx.get_prop_detail(prop_name)\n            if detail:\n                stats.prop_block_list_violation += 1\n                self.logger.error(\"{} prop {} is not expected\".format(self.event_error_tag(fl_ctx), prop_name))",
  "def check_props(self, fl_ctx: FLContext):\n        event_req = fl_ctx.get_prop(self._KEY_EVENT_REQ)\n        stats = fl_ctx.get_prop(self._KEY_EVENT_STATS)\n\n        for prop_name, req in event_req.ctx_reqs.items():\n            self.validate_prop(prop_name, req, fl_ctx)\n\n        self.check_block_list(event_req.ctx_block_list, fl_ctx)\n\n        if event_req.peer_ctx_reqs:\n            peer_ctx = fl_ctx.get_peer_context()\n            if not peer_ctx:\n                stats.peer_ctx_missing += 1\n                self.logger.error(\"{} expected peer_ctx not present\".format(self.event_error_tag(fl_ctx)))\n            else:\n                for prop_name, req in event_req.peer_ctx_reqs.items():\n                    self.validate_prop(prop_name, req, peer_ctx)\n                self.check_block_list(event_req.peer_ctx_block_list, peer_ctx)",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if not self._log_handler_added:\n            workspace = fl_ctx.get_engine().get_workspace()\n            app_dir = workspace.get_app_dir(fl_ctx.get_job_id())\n            output_file_handler = logging.FileHandler(os.path.join(app_dir, self.log_file_name))\n            formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n            output_file_handler.setFormatter(formatter)\n            self.logger.addHandler(output_file_handler)\n            self._log_handler_added = True\n        event_stats = self.event_stats.get(event_type, None)\n        if not event_stats:\n            event_stats = _EventStats()\n            self.event_stats[event_type] = event_stats\n\n        fl_ctx.set_prop(key=self._KEY_EVENT_STATS, value=event_stats, private=True, sticky=False)\n        fl_ctx.set_prop(key=self._KEY_EVENT_TYPE, value=event_type, private=True, sticky=False)\n        fl_ctx.set_prop(key=self._KEY_CTX_TYPE, value=\"fl_ctx\", private=True, sticky=False)\n\n        self.log_info(fl_ctx, \"Got event {}\".format(self.event_tag(fl_ctx)), fire_event=False)\n        event_stats.call_count += 1\n\n        peer_ctx = fl_ctx.get_peer_context()\n        if peer_ctx:\n            event_id = fl_ctx.get_prop(FLContextKey.EVENT_ID)\n            peer_ctx.set_prop(key=FLContextKey.EVENT_ID, value=event_id, private=True, sticky=False)\n            peer_ctx.set_prop(key=self._KEY_EVENT_STATS, value=event_stats, private=True, sticky=False)\n            peer_ctx.set_prop(key=self._KEY_EVENT_TYPE, value=event_type, private=True, sticky=False)\n            peer_ctx.set_prop(key=self._KEY_CTX_TYPE, value=\"peer_ctx\", private=True, sticky=False)\n            self.log_info(\n                fl_ctx, \"Peer Context for event {}: {}\".format(self.event_tag(fl_ctx), peer_ctx), fire_event=False\n            )\n\n        event_req = self.event_reqs.get(event_type, None)\n        fl_ctx.set_prop(key=self._KEY_EVENT_REQ, value=event_req, private=True, sticky=False)\n        if event_req:\n            self.check_props(fl_ctx)\n\n        if event_type == EventType.END_RUN:\n            # print stats\n            for e, s in self.event_stats.items():\n                self.log_info(fl_ctx, \"Stats of {}: {}\".format(e, vars(s)), fire_event=False)",
  "def __init__(self):\n        \"\"\"Server-specific event recorder.\"\"\"\n        super().__init__()\n\n        task_data_filter_reqs = _EventReq(\n            ctx_reqs={\n                \"__engine__\": _CtxPropReq(dtype=ServerEngineSpec, is_private=True, is_sticky=True),\n                FLContextKey.TASK_ID: _CtxPropReq(dtype=str, is_private=True, is_sticky=False),\n                FLContextKey.TASK_NAME: _CtxPropReq(dtype=str, is_private=True, is_sticky=False),\n                FLContextKey.TASK_DATA: _CtxPropReq(dtype=Shareable, is_private=True, is_sticky=False, allow_none=True),\n                \"testPrivateServerSticky\": _CtxPropReq(dtype=str, is_private=True, is_sticky=True),\n                \"testPublicServerSticky\": _CtxPropReq(dtype=str, is_private=False, is_sticky=True),\n            },\n            ctx_block_list=[\n                \"testPrivateServerNonSticky\",\n                \"testPublicServerNonSticky\",\n                \"testPrivateClientNonSticky\",\n                \"testPublicClientNonSticky\",\n                \"testPrivateClientSticky\",\n                \"testPublicClientSticky\",\n            ],\n            peer_ctx_reqs={\n                \"__run_num__\": _CtxPropReq(dtype=str, is_private=None, is_sticky=None),\n                \"__identity_name__\": _CtxPropReq(dtype=str, is_private=None, is_sticky=None),\n                \"testPublicClientSticky\": _CtxPropReq(dtype=str, is_private=None, is_sticky=None),\n            },\n            peer_ctx_block_list=[\n                \"__engine__\",\n                \"testPrivateClientSticky\",\n                \"testPrivateClientNonSticky\",\n                \"testPublicClientNonSticky\",\n            ],\n        )\n        self.event_reqs.update(\n            {\n                EventType.BEFORE_TASK_DATA_FILTER: task_data_filter_reqs,\n                EventType.AFTER_TASK_DATA_FILTER: task_data_filter_reqs,\n            }\n        )",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            fl_ctx.set_prop(\n                key=\"testPrivateServerSticky\", value=\"this is a server private sticky\", private=True, sticky=True\n            )\n\n            fl_ctx.set_prop(\n                key=\"testPublicServerSticky\", value=\"this is a server public sticky\", private=False, sticky=True\n            )\n\n            fl_ctx.set_prop(\n                key=\"testPrivateServerNonSticky\",\n                value=\"this is a server private non-sticky\",\n                private=True,\n                sticky=False,\n            )\n\n            fl_ctx.set_prop(\n                key=\"testPublicServerNonSticky\", value=\"this is a server public non-sticky\", private=False, sticky=False\n            )\n\n        super().handle_event(event_type, fl_ctx)",
  "def __init__(self):\n        \"\"\"Client-specific event recorder.\"\"\"\n        super().__init__()\n\n        task_data_filter_reqs = _EventReq(\n            ctx_reqs={\n                \"__engine__\": _CtxPropReq(dtype=ClientEngineSpec, is_private=True, is_sticky=True),\n                FLContextKey.TASK_ID: _CtxPropReq(dtype=str, is_private=True, is_sticky=False),\n                FLContextKey.TASK_NAME: _CtxPropReq(dtype=str, is_private=True, is_sticky=False),\n                FLContextKey.TASK_DATA: _CtxPropReq(dtype=Shareable, is_private=True, is_sticky=False, allow_none=True),\n                \"testPrivateClientSticky\": _CtxPropReq(dtype=str, is_private=True, is_sticky=True),\n                \"testPublicClientSticky\": _CtxPropReq(dtype=str, is_private=False, is_sticky=True),\n            },\n            ctx_block_list=[\n                \"testPrivateServerNonSticky\",\n                \"testPublicServerNonSticky\",\n                \"testPrivateClientNonSticky\",\n                \"testPublicClientNonSticky\",\n                \"testPrivateServerSticky\",\n                \"testPublicServerSticky\",\n            ],\n            peer_ctx_reqs={\n                \"__run_num__\": _CtxPropReq(dtype=str, is_private=None, is_sticky=None),\n                \"__identity_name__\": _CtxPropReq(dtype=str, is_private=None, is_sticky=None),\n                \"testPublicServerSticky\": _CtxPropReq(dtype=str, is_private=None, is_sticky=None),\n            },\n            peer_ctx_block_list=[\n                \"__engine__\",\n                \"testPrivateServerSticky\",\n                \"testPrivateServerNonSticky\",\n                \"testPublicServerNonSticky\",\n            ],\n        )\n        self.event_reqs.update(\n            {\n                EventType.BEFORE_TASK_DATA_FILTER: task_data_filter_reqs,\n                EventType.AFTER_TASK_DATA_FILTER: task_data_filter_reqs,\n            }\n        )",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            fl_ctx.set_prop(\n                key=\"testPrivateClientSticky\", value=\"this is a client private sticky\", private=True, sticky=True\n            )\n\n            fl_ctx.set_prop(\n                key=\"testPublicClientSticky\", value=\"this is a client public sticky\", private=False, sticky=True\n            )\n\n            fl_ctx.set_prop(\n                key=\"testPrivateClientNonSticky\",\n                value=\"this is a client private non-sticky\",\n                private=True,\n                sticky=False,\n            )\n\n            fl_ctx.set_prop(\n                key=\"testPublicClientNonSticky\", value=\"this is a client public non-sticky\", private=False, sticky=False\n            )\n\n        super().handle_event(event_type, fl_ctx)",
  "class ConvertToFedEvent(Widget):\n    def __init__(self, events_to_convert: List[str], fed_event_prefix=FED_EVENT_PREFIX):\n        \"\"\"Converts local event to federated events.\n\n        Args:\n            events_to_convert (List[str]): A list of event names to be converted.\n            fed_event_prefix (str): The prefix that will be added to the converted event's name.\n        \"\"\"\n        super().__init__()\n        self.events_to_convert = events_to_convert\n        self.fed_event_prefix = fed_event_prefix\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type in self.events_to_convert:\n            event_scope = fl_ctx.get_prop(key=FLContextKey.EVENT_SCOPE, default=EventScope.LOCAL)\n            if event_scope == EventScope.FEDERATION:\n                # already a fed event\n                return\n            data = fl_ctx.get_prop(FLContextKey.EVENT_DATA, None)\n            if data is None:\n                self.log_error(fl_ctx, \"Missing event data.\")\n                return\n            if not isinstance(data, Shareable):\n                self.log_error(fl_ctx, f\"Expect data to be shareable but got {type(data)}\")\n                return\n            self.fire_fed_event(self.fed_event_prefix + event_type, data, fl_ctx)",
  "def __init__(self, events_to_convert: List[str], fed_event_prefix=FED_EVENT_PREFIX):\n        \"\"\"Converts local event to federated events.\n\n        Args:\n            events_to_convert (List[str]): A list of event names to be converted.\n            fed_event_prefix (str): The prefix that will be added to the converted event's name.\n        \"\"\"\n        super().__init__()\n        self.events_to_convert = events_to_convert\n        self.fed_event_prefix = fed_event_prefix",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type in self.events_to_convert:\n            event_scope = fl_ctx.get_prop(key=FLContextKey.EVENT_SCOPE, default=EventScope.LOCAL)\n            if event_scope == EventScope.FEDERATION:\n                # already a fed event\n                return\n            data = fl_ctx.get_prop(FLContextKey.EVENT_DATA, None)\n            if data is None:\n                self.log_error(fl_ctx, \"Missing event data.\")\n                return\n            if not isinstance(data, Shareable):\n                self.log_error(fl_ctx, f\"Expect data to be shareable but got {type(data)}\")\n                return\n            self.fire_fed_event(self.fed_event_prefix + event_type, data, fl_ctx)",
  "class WeightedAggregationHelper(object):\n    def __init__(self, exclude_vars: Optional[str] = None):\n        \"\"\"Perform weighted aggregation.\n\n        Args:\n            exclude_vars (str, optional): regex string to match excluded vars during aggregation. Defaults to None.\n        \"\"\"\n        super().__init__()\n        self.exclude_vars = re.compile(exclude_vars) if exclude_vars else None\n        self.reset_stats()\n        self.total = dict()\n        self.counts = dict()\n        self.history = list()\n\n    def reset_stats(self):\n        self.total = {}\n        self.counts = {}\n        self.history = []\n\n    def add(self, data, weight, contributor_name, contribution_round):\n        \"\"\"Compute weighted sum and sum of weights.\"\"\"\n        for k, v in data.items():\n            if self.exclude_vars is not None and self.exclude_vars.search(k):\n                continue\n            weighted_value = v * weight\n            current_total = self.total.get(k, None)\n            if current_total is None:\n                self.total[k] = weighted_value\n                self.counts[k] = weight\n            else:\n                self.total[k] = current_total + weighted_value\n                self.counts[k] = self.counts[k] + weight\n        self.history.append(\n            {\n                \"contributor_name\": contributor_name,\n                \"round\": contribution_round,\n                \"weight\": weight,\n            }\n        )\n\n    def get_result(self):\n        \"\"\"Divide weighted sum by sum of weights.\"\"\"\n        aggregated_dict = {k: v / self.counts[k] for k, v in self.total.items()}\n        self.reset_stats()\n        return aggregated_dict\n\n    def get_history(self):\n        return self.history\n\n    def get_len(self):\n        return len(self.get_history())",
  "def __init__(self, exclude_vars: Optional[str] = None):\n        \"\"\"Perform weighted aggregation.\n\n        Args:\n            exclude_vars (str, optional): regex string to match excluded vars during aggregation. Defaults to None.\n        \"\"\"\n        super().__init__()\n        self.exclude_vars = re.compile(exclude_vars) if exclude_vars else None\n        self.reset_stats()\n        self.total = dict()\n        self.counts = dict()\n        self.history = list()",
  "def reset_stats(self):\n        self.total = {}\n        self.counts = {}\n        self.history = []",
  "def add(self, data, weight, contributor_name, contribution_round):\n        \"\"\"Compute weighted sum and sum of weights.\"\"\"\n        for k, v in data.items():\n            if self.exclude_vars is not None and self.exclude_vars.search(k):\n                continue\n            weighted_value = v * weight\n            current_total = self.total.get(k, None)\n            if current_total is None:\n                self.total[k] = weighted_value\n                self.counts[k] = weight\n            else:\n                self.total[k] = current_total + weighted_value\n                self.counts[k] = self.counts[k] + weight\n        self.history.append(\n            {\n                \"contributor_name\": contributor_name,\n                \"round\": contribution_round,\n                \"weight\": weight,\n            }\n        )",
  "def get_result(self):\n        \"\"\"Divide weighted sum by sum of weights.\"\"\"\n        aggregated_dict = {k: v / self.counts[k] for k, v in self.total.items()}\n        self.reset_stats()\n        return aggregated_dict",
  "def get_history(self):\n        return self.history",
  "def get_len(self):\n        return len(self.get_history())",
  "class DXOAggregator(FLComponent):\n    def __init__(\n        self,\n        exclude_vars: Optional[str] = None,\n        aggregation_weights: Optional[Dict[str, Any]] = None,\n        expected_data_kind: DataKind = DataKind.WEIGHT_DIFF,\n        name_postfix: str = \"\",\n    ):\n        \"\"\"Perform accumulated weighted aggregation for one kind of corresponding DXO from contributors.\n\n        Args:\n            exclude_vars (str, optional): Regex to match excluded vars during aggregation. Defaults to None.\n            aggregation_weights (Dict[str, Any], optional): Aggregation weight for each contributor.\n                                Defaults to None.\n            expected_data_kind (DataKind): Expected DataKind for this DXO.\n            name_postfix: optional postfix to give to class name and show in logger output.\n        \"\"\"\n        super().__init__()\n        self.expected_data_kind = expected_data_kind\n        self.aggregation_weights = aggregation_weights or {}\n        self.logger.debug(f\"aggregation weights control: {aggregation_weights}\")\n\n        self.aggregation_helper = WeightedAggregationHelper(exclude_vars=exclude_vars)\n\n        self.warning_count = {}\n        self.warning_limit = 10\n\n        if name_postfix:\n            self._name += name_postfix\n            self.logger = logging.getLogger(self._name)\n\n    def reset_aggregation_helper(self):\n        if self.aggregation_helper:\n            self.aggregation_helper.reset_stats()\n\n    def accept(self, dxo: DXO, contributor_name, contribution_round, fl_ctx: FLContext) -> bool:\n        \"\"\"Store DXO and update aggregator's internal state\n        Args:\n            dxo: information from contributor\n            contributor_name: name of the contributor\n            contribution_round: round of the contribution\n            fl_ctx: context provided by workflow\n        Returns:\n            The boolean to indicate if DXO is accepted.\n        \"\"\"\n\n        if not isinstance(dxo, DXO):\n            self.log_error(fl_ctx, f\"Expected DXO but got {type(dxo)}\")\n            return False\n\n        if dxo.data_kind not in (DataKind.WEIGHT_DIFF, DataKind.WEIGHTS):\n            self.log_error(fl_ctx, \"cannot handle data kind {}\".format(dxo.data_kind))\n            return False\n\n        if dxo.data_kind != self.expected_data_kind:\n            self.log_error(fl_ctx, \"expected {} but got {}\".format(self.expected_data_kind, dxo.data_kind))\n            return False\n\n        processed_algorithm = dxo.get_meta_prop(MetaKey.PROCESSED_ALGORITHM)\n        if processed_algorithm is not None:\n            self.log_error(fl_ctx, f\"unable to accept DXO processed by {processed_algorithm}\")\n            return False\n\n        current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n        self.log_debug(fl_ctx, f\"current_round: {current_round}\")\n\n        data = dxo.data\n        if data is None:\n            self.log_error(fl_ctx, \"no data to aggregate\")\n            return False\n\n        n_iter = dxo.get_meta_prop(MetaKey.NUM_STEPS_CURRENT_ROUND)\n        if contribution_round != current_round:\n            self.log_warning(\n                fl_ctx,\n                f\"discarding DXO from {contributor_name} at round: \"\n                f\"{contribution_round}. Current round is: {current_round}\",\n            )\n            return False\n\n        for item in self.aggregation_helper.get_history():\n            if contributor_name == item[\"contributor_name\"]:\n                prev_round = item[\"round\"]\n                self.log_warning(\n                    fl_ctx,\n                    f\"discarding DXO from {contributor_name} at round: \"\n                    f\"{contribution_round} as {prev_round} accepted already\",\n                )\n                return False\n\n        if n_iter is None:\n            if self.warning_count.get(contributor_name, 0) <= self.warning_limit:\n                self.log_warning(\n                    fl_ctx,\n                    f\"NUM_STEPS_CURRENT_ROUND missing in meta of DXO\"\n                    f\" from {contributor_name} and set to default value, 1.0. \"\n                    f\" This kind of message will show {self.warning_limit} times at most.\",\n                )\n                if contributor_name in self.warning_count:\n                    self.warning_count[contributor_name] = self.warning_count[contributor_name] + 1\n                else:\n                    self.warning_count[contributor_name] = 0\n            n_iter = 1.0\n        float_n_iter = float(n_iter)\n        aggregation_weight = self.aggregation_weights.get(contributor_name)\n        if aggregation_weight is None:\n            if self.warning_count.get(contributor_name, 0) <= self.warning_limit:\n                self.log_warning(\n                    fl_ctx,\n                    f\"Aggregation_weight missing for {contributor_name} and set to default value, 1.0\"\n                    f\" This kind of message will show {self.warning_limit} times at most.\",\n                )\n                if contributor_name in self.warning_count:\n                    self.warning_count[contributor_name] = self.warning_count[contributor_name] + 1\n                else:\n                    self.warning_count[contributor_name] = 0\n            aggregation_weight = 1.0\n\n        # aggregate\n        self.aggregation_helper.add(data, aggregation_weight * float_n_iter, contributor_name, contribution_round)\n        self.log_debug(fl_ctx, \"End accept\")\n        return True\n\n    def aggregate(self, fl_ctx: FLContext) -> DXO:\n        \"\"\"Called when workflow determines to generate DXO to send back to contributors\n        Args:\n            fl_ctx (FLContext): context provided by workflow\n        Returns:\n            DXO: the weighted mean of accepted DXOs from contributors\n        \"\"\"\n\n        self.log_debug(fl_ctx, \"Start aggregation\")\n        current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n        self.log_info(fl_ctx, f\"aggregating {self.aggregation_helper.get_len()} update(s) at round {current_round}\")\n        self.log_debug(fl_ctx, f\"complete history {self.aggregation_helper.get_len()}\")\n        aggregated_dict = self.aggregation_helper.get_result()\n        self.log_debug(fl_ctx, \"End aggregation\")\n\n        dxo = DXO(data_kind=self.expected_data_kind, data=aggregated_dict)\n        return dxo",
  "def __init__(\n        self,\n        exclude_vars: Optional[str] = None,\n        aggregation_weights: Optional[Dict[str, Any]] = None,\n        expected_data_kind: DataKind = DataKind.WEIGHT_DIFF,\n        name_postfix: str = \"\",\n    ):\n        \"\"\"Perform accumulated weighted aggregation for one kind of corresponding DXO from contributors.\n\n        Args:\n            exclude_vars (str, optional): Regex to match excluded vars during aggregation. Defaults to None.\n            aggregation_weights (Dict[str, Any], optional): Aggregation weight for each contributor.\n                                Defaults to None.\n            expected_data_kind (DataKind): Expected DataKind for this DXO.\n            name_postfix: optional postfix to give to class name and show in logger output.\n        \"\"\"\n        super().__init__()\n        self.expected_data_kind = expected_data_kind\n        self.aggregation_weights = aggregation_weights or {}\n        self.logger.debug(f\"aggregation weights control: {aggregation_weights}\")\n\n        self.aggregation_helper = WeightedAggregationHelper(exclude_vars=exclude_vars)\n\n        self.warning_count = {}\n        self.warning_limit = 10\n\n        if name_postfix:\n            self._name += name_postfix\n            self.logger = logging.getLogger(self._name)",
  "def reset_aggregation_helper(self):\n        if self.aggregation_helper:\n            self.aggregation_helper.reset_stats()",
  "def accept(self, dxo: DXO, contributor_name, contribution_round, fl_ctx: FLContext) -> bool:\n        \"\"\"Store DXO and update aggregator's internal state\n        Args:\n            dxo: information from contributor\n            contributor_name: name of the contributor\n            contribution_round: round of the contribution\n            fl_ctx: context provided by workflow\n        Returns:\n            The boolean to indicate if DXO is accepted.\n        \"\"\"\n\n        if not isinstance(dxo, DXO):\n            self.log_error(fl_ctx, f\"Expected DXO but got {type(dxo)}\")\n            return False\n\n        if dxo.data_kind not in (DataKind.WEIGHT_DIFF, DataKind.WEIGHTS):\n            self.log_error(fl_ctx, \"cannot handle data kind {}\".format(dxo.data_kind))\n            return False\n\n        if dxo.data_kind != self.expected_data_kind:\n            self.log_error(fl_ctx, \"expected {} but got {}\".format(self.expected_data_kind, dxo.data_kind))\n            return False\n\n        processed_algorithm = dxo.get_meta_prop(MetaKey.PROCESSED_ALGORITHM)\n        if processed_algorithm is not None:\n            self.log_error(fl_ctx, f\"unable to accept DXO processed by {processed_algorithm}\")\n            return False\n\n        current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n        self.log_debug(fl_ctx, f\"current_round: {current_round}\")\n\n        data = dxo.data\n        if data is None:\n            self.log_error(fl_ctx, \"no data to aggregate\")\n            return False\n\n        n_iter = dxo.get_meta_prop(MetaKey.NUM_STEPS_CURRENT_ROUND)\n        if contribution_round != current_round:\n            self.log_warning(\n                fl_ctx,\n                f\"discarding DXO from {contributor_name} at round: \"\n                f\"{contribution_round}. Current round is: {current_round}\",\n            )\n            return False\n\n        for item in self.aggregation_helper.get_history():\n            if contributor_name == item[\"contributor_name\"]:\n                prev_round = item[\"round\"]\n                self.log_warning(\n                    fl_ctx,\n                    f\"discarding DXO from {contributor_name} at round: \"\n                    f\"{contribution_round} as {prev_round} accepted already\",\n                )\n                return False\n\n        if n_iter is None:\n            if self.warning_count.get(contributor_name, 0) <= self.warning_limit:\n                self.log_warning(\n                    fl_ctx,\n                    f\"NUM_STEPS_CURRENT_ROUND missing in meta of DXO\"\n                    f\" from {contributor_name} and set to default value, 1.0. \"\n                    f\" This kind of message will show {self.warning_limit} times at most.\",\n                )\n                if contributor_name in self.warning_count:\n                    self.warning_count[contributor_name] = self.warning_count[contributor_name] + 1\n                else:\n                    self.warning_count[contributor_name] = 0\n            n_iter = 1.0\n        float_n_iter = float(n_iter)\n        aggregation_weight = self.aggregation_weights.get(contributor_name)\n        if aggregation_weight is None:\n            if self.warning_count.get(contributor_name, 0) <= self.warning_limit:\n                self.log_warning(\n                    fl_ctx,\n                    f\"Aggregation_weight missing for {contributor_name} and set to default value, 1.0\"\n                    f\" This kind of message will show {self.warning_limit} times at most.\",\n                )\n                if contributor_name in self.warning_count:\n                    self.warning_count[contributor_name] = self.warning_count[contributor_name] + 1\n                else:\n                    self.warning_count[contributor_name] = 0\n            aggregation_weight = 1.0\n\n        # aggregate\n        self.aggregation_helper.add(data, aggregation_weight * float_n_iter, contributor_name, contribution_round)\n        self.log_debug(fl_ctx, \"End accept\")\n        return True",
  "def aggregate(self, fl_ctx: FLContext) -> DXO:\n        \"\"\"Called when workflow determines to generate DXO to send back to contributors\n        Args:\n            fl_ctx (FLContext): context provided by workflow\n        Returns:\n            DXO: the weighted mean of accepted DXOs from contributors\n        \"\"\"\n\n        self.log_debug(fl_ctx, \"Start aggregation\")\n        current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n        self.log_info(fl_ctx, f\"aggregating {self.aggregation_helper.get_len()} update(s) at round {current_round}\")\n        self.log_debug(fl_ctx, f\"complete history {self.aggregation_helper.get_len()}\")\n        aggregated_dict = self.aggregation_helper.get_result()\n        self.log_debug(fl_ctx, \"End aggregation\")\n\n        dxo = DXO(data_kind=self.expected_data_kind, data=aggregated_dict)\n        return dxo",
  "def _is_nested_aggregation_weights(aggregation_weights):\n    if not aggregation_weights:\n        return False\n    if not isinstance(aggregation_weights, dict):\n        return False\n    first_value = next(iter(aggregation_weights.items()))[1]\n    if not isinstance(first_value, dict):\n        return False\n    return True",
  "def _get_missing_keys(ref_dict: dict, dict_to_check: dict):\n    result = []\n    for k in ref_dict:\n        if k not in dict_to_check:\n            result.append(k)\n    return result",
  "class InTimeAccumulateWeightedAggregator(Aggregator):\n    def __init__(\n        self,\n        exclude_vars: Union[str, Dict[str, str], None] = None,\n        aggregation_weights: Union[Dict[str, Any], Dict[str, Dict[str, Any]], None] = None,\n        expected_data_kind: Union[DataKind, Dict[str, DataKind]] = DataKind.WEIGHT_DIFF,\n    ):\n        \"\"\"Perform accumulated weighted aggregation.\n\n        This is often used as the default aggregation method and can be used for FedAvg. It parses the shareable and\n        aggregates the contained DXO(s).\n\n        Args:\n            exclude_vars (Union[str, Dict[str, str]], optional):\n                Regular expression string to match excluded vars during aggregation. Defaults to None.\n                Can be one string or a dict of {dxo_name: regex strings} corresponding to each aggregated DXO\n                when processing a DXO of `DataKind.COLLECTION`.\n            aggregation_weights (Union[Dict[str, Any], Dict[str, Dict[str, Any]]], optional):\n                Aggregation weight for each contributor. Defaults to None.\n                Can be one dict of {contrib_name: aggr_weight} or a dict of dicts corresponding to each aggregated DXO\n                when processing a DXO of `DataKind.COLLECTION`.\n            expected_data_kind (Union[DataKind, Dict[str, DataKind]]):\n                DataKind for DXO. Defaults to DataKind.WEIGHT_DIFF\n                Can be one DataKind or a dict of {dxo_name: DataKind} corresponding to each aggregated DXO\n                when processing a DXO of `DataKind.COLLECTION`. Only the keys in this dict will be processed.\n        \"\"\"\n        super().__init__()\n        self.logger.debug(f\"exclude vars: {exclude_vars}\")\n        self.logger.debug(f\"aggregation weights control: {aggregation_weights}\")\n        self.logger.debug(f\"expected data kind: {expected_data_kind}\")\n\n        self._single_dxo_key = \"\"\n\n        # Check expected data kind\n        if isinstance(expected_data_kind, dict):\n            for k, v in expected_data_kind.items():\n                if v not in [DataKind.WEIGHT_DIFF, DataKind.WEIGHTS]:\n                    raise ValueError(\n                        f\"expected_data_kind[{k}] = {v} is not {DataKind.WEIGHT_DIFF} or {DataKind.WEIGHTS}\"\n                    )\n            self.expected_data_kind = expected_data_kind\n        else:\n            if expected_data_kind not in [DataKind.WEIGHT_DIFF, DataKind.WEIGHTS]:\n                raise ValueError(\n                    f\"expected_data_kind = {expected_data_kind} is not {DataKind.WEIGHT_DIFF} or {DataKind.WEIGHTS}\"\n                )\n            self.expected_data_kind = {self._single_dxo_key: expected_data_kind}\n\n        # Check exclude_vars\n        if exclude_vars:\n            if not isinstance(exclude_vars, dict) and not isinstance(exclude_vars, str):\n                raise ValueError(\n                    f\"exclude_vars = {exclude_vars} should be a regex string but got {type(exclude_vars)}.\"\n                )\n            if isinstance(exclude_vars, dict):\n                missing_keys = _get_missing_keys(expected_data_kind, exclude_vars)\n                if len(missing_keys) != 0:\n                    raise ValueError(\n                        \"A dict exclude_vars should specify exclude_vars for every key in expected_data_kind. \"\n                        f\"But missed these keys: {missing_keys}\"\n                    )\n\n        exclude_vars_dict = dict()\n        for k in self.expected_data_kind.keys():\n            if isinstance(exclude_vars, dict):\n                if k in exclude_vars:\n                    if not isinstance(exclude_vars[k], str):\n                        raise ValueError(\n                            f\"exclude_vars[{k}] = {exclude_vars[k]} should be a regex string but got {type(exclude_vars[k])}.\"\n                        )\n                    exclude_vars_dict[k] = exclude_vars[k]\n            else:\n                # assume same exclude vars for each entry of DXO collection.\n                exclude_vars_dict[k] = exclude_vars\n        if self._single_dxo_key in self.expected_data_kind:\n            exclude_vars_dict[self._single_dxo_key] = exclude_vars\n        self.exclude_vars = exclude_vars_dict\n\n        # Check aggregation weights\n        if _is_nested_aggregation_weights(aggregation_weights):\n            missing_keys = _get_missing_keys(expected_data_kind, aggregation_weights)\n            if len(missing_keys) != 0:\n                raise ValueError(\n                    \"A dict of dict aggregation_weights should specify aggregation_weights \"\n                    f\"for every key in expected_data_kind. But missed these keys: {missing_keys}\"\n                )\n\n        aggregation_weights = aggregation_weights or {}\n        aggregation_weights_dict = dict()\n        for k in self.expected_data_kind.keys():\n            if k in aggregation_weights:\n                aggregation_weights_dict[k] = aggregation_weights[k]\n            else:\n                # assume same aggregation weights for each entry of DXO collection.\n                aggregation_weights_dict[k] = aggregation_weights\n        self.aggregation_weights = aggregation_weights_dict\n\n        # Set up DXO aggregators\n        self.dxo_aggregators = dict()\n        for k in self.expected_data_kind.keys():\n            self.dxo_aggregators.update(\n                {\n                    k: DXOAggregator(\n                        exclude_vars=self.exclude_vars[k],\n                        aggregation_weights=self.aggregation_weights[k],\n                        expected_data_kind=self.expected_data_kind[k],\n                        name_postfix=k,\n                    )\n                }\n            )\n\n    def accept(self, shareable: Shareable, fl_ctx: FLContext) -> bool:\n        \"\"\"Store shareable and update aggregator's internal state\n\n        Args:\n            shareable: information from contributor\n            fl_ctx: context provided by workflow\n\n        Returns:\n            The first boolean indicates if this shareable is accepted.\n            The second boolean indicates if aggregate can be called.\n        \"\"\"\n        try:\n            dxo = from_shareable(shareable)\n        except BaseException:\n            self.log_exception(fl_ctx, \"shareable data is not a valid DXO\")\n            return False\n\n        if dxo.data_kind not in (DataKind.WEIGHT_DIFF, DataKind.WEIGHTS, DataKind.COLLECTION):\n            self.log_error(\n                fl_ctx,\n                f\"cannot handle data kind {dxo.data_kind}, \"\n                f\"expecting DataKind.WEIGHT_DIFF, DataKind.WEIGHTS, or DataKind.COLLECTION.\",\n            )\n            return False\n\n        contributor_name = shareable.get_peer_prop(key=ReservedKey.IDENTITY_NAME, default=\"?\")\n        contribution_round = shareable.get_header(AppConstants.CONTRIBUTION_ROUND)\n\n        rc = shareable.get_return_code()\n        if rc and rc != ReturnCode.OK:\n            self.log_warning(fl_ctx, f\"Contributor {contributor_name} returned rc: {rc}. Disregarding contribution.\")\n            return False\n\n        # Accept expected DXO(s) in shareable\n        n_accepted = 0\n        for key in self.expected_data_kind.keys():\n            if key == self._single_dxo_key:  # expecting a single DXO\n                sub_dxo = dxo\n            else:  # expecting a collection of DXOs\n                sub_dxo = dxo.data.get(key)\n            if not isinstance(sub_dxo, DXO):\n                self.log_warning(fl_ctx, f\"Collection does not contain DXO for key {key} but {type(sub_dxo)}.\")\n                continue\n\n            accepted = self.dxo_aggregators[key].accept(\n                dxo=sub_dxo, contributor_name=contributor_name, contribution_round=contribution_round, fl_ctx=fl_ctx\n            )\n            if not accepted:\n                return False\n            else:\n                n_accepted += 1\n\n        if n_accepted > 0:\n            return True\n        else:\n            self.log_warning(fl_ctx, f\"Did not accept any DXOs from {contributor_name} in round {contribution_round}!\")\n            return False\n\n    def aggregate(self, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Called when workflow determines to generate shareable to send back to contributors\n\n        Args:\n            fl_ctx (FLContext): context provided by workflow\n\n        Returns:\n            Shareable: the weighted mean of accepted shareables from contributors\n        \"\"\"\n\n        self.log_debug(fl_ctx, \"Start aggregation\")\n        result_dxo_dict = dict()\n        # Aggregate the expected DXO(s)\n        for key in self.expected_data_kind.keys():\n            aggregated_dxo = self.dxo_aggregators[key].aggregate(fl_ctx)\n            if key == self._single_dxo_key:  # return single DXO with aggregation results\n                return aggregated_dxo.to_shareable()\n            self.log_info(fl_ctx, f\"Aggregated contributions matching key '{key}'.\")\n            result_dxo_dict.update({key: aggregated_dxo})\n        # return collection of DXOs with aggregation results\n        collection_dxo = DXO(data_kind=DataKind.COLLECTION, data=result_dxo_dict)\n        return collection_dxo.to_shareable()",
  "def __init__(\n        self,\n        exclude_vars: Union[str, Dict[str, str], None] = None,\n        aggregation_weights: Union[Dict[str, Any], Dict[str, Dict[str, Any]], None] = None,\n        expected_data_kind: Union[DataKind, Dict[str, DataKind]] = DataKind.WEIGHT_DIFF,\n    ):\n        \"\"\"Perform accumulated weighted aggregation.\n\n        This is often used as the default aggregation method and can be used for FedAvg. It parses the shareable and\n        aggregates the contained DXO(s).\n\n        Args:\n            exclude_vars (Union[str, Dict[str, str]], optional):\n                Regular expression string to match excluded vars during aggregation. Defaults to None.\n                Can be one string or a dict of {dxo_name: regex strings} corresponding to each aggregated DXO\n                when processing a DXO of `DataKind.COLLECTION`.\n            aggregation_weights (Union[Dict[str, Any], Dict[str, Dict[str, Any]]], optional):\n                Aggregation weight for each contributor. Defaults to None.\n                Can be one dict of {contrib_name: aggr_weight} or a dict of dicts corresponding to each aggregated DXO\n                when processing a DXO of `DataKind.COLLECTION`.\n            expected_data_kind (Union[DataKind, Dict[str, DataKind]]):\n                DataKind for DXO. Defaults to DataKind.WEIGHT_DIFF\n                Can be one DataKind or a dict of {dxo_name: DataKind} corresponding to each aggregated DXO\n                when processing a DXO of `DataKind.COLLECTION`. Only the keys in this dict will be processed.\n        \"\"\"\n        super().__init__()\n        self.logger.debug(f\"exclude vars: {exclude_vars}\")\n        self.logger.debug(f\"aggregation weights control: {aggregation_weights}\")\n        self.logger.debug(f\"expected data kind: {expected_data_kind}\")\n\n        self._single_dxo_key = \"\"\n\n        # Check expected data kind\n        if isinstance(expected_data_kind, dict):\n            for k, v in expected_data_kind.items():\n                if v not in [DataKind.WEIGHT_DIFF, DataKind.WEIGHTS]:\n                    raise ValueError(\n                        f\"expected_data_kind[{k}] = {v} is not {DataKind.WEIGHT_DIFF} or {DataKind.WEIGHTS}\"\n                    )\n            self.expected_data_kind = expected_data_kind\n        else:\n            if expected_data_kind not in [DataKind.WEIGHT_DIFF, DataKind.WEIGHTS]:\n                raise ValueError(\n                    f\"expected_data_kind = {expected_data_kind} is not {DataKind.WEIGHT_DIFF} or {DataKind.WEIGHTS}\"\n                )\n            self.expected_data_kind = {self._single_dxo_key: expected_data_kind}\n\n        # Check exclude_vars\n        if exclude_vars:\n            if not isinstance(exclude_vars, dict) and not isinstance(exclude_vars, str):\n                raise ValueError(\n                    f\"exclude_vars = {exclude_vars} should be a regex string but got {type(exclude_vars)}.\"\n                )\n            if isinstance(exclude_vars, dict):\n                missing_keys = _get_missing_keys(expected_data_kind, exclude_vars)\n                if len(missing_keys) != 0:\n                    raise ValueError(\n                        \"A dict exclude_vars should specify exclude_vars for every key in expected_data_kind. \"\n                        f\"But missed these keys: {missing_keys}\"\n                    )\n\n        exclude_vars_dict = dict()\n        for k in self.expected_data_kind.keys():\n            if isinstance(exclude_vars, dict):\n                if k in exclude_vars:\n                    if not isinstance(exclude_vars[k], str):\n                        raise ValueError(\n                            f\"exclude_vars[{k}] = {exclude_vars[k]} should be a regex string but got {type(exclude_vars[k])}.\"\n                        )\n                    exclude_vars_dict[k] = exclude_vars[k]\n            else:\n                # assume same exclude vars for each entry of DXO collection.\n                exclude_vars_dict[k] = exclude_vars\n        if self._single_dxo_key in self.expected_data_kind:\n            exclude_vars_dict[self._single_dxo_key] = exclude_vars\n        self.exclude_vars = exclude_vars_dict\n\n        # Check aggregation weights\n        if _is_nested_aggregation_weights(aggregation_weights):\n            missing_keys = _get_missing_keys(expected_data_kind, aggregation_weights)\n            if len(missing_keys) != 0:\n                raise ValueError(\n                    \"A dict of dict aggregation_weights should specify aggregation_weights \"\n                    f\"for every key in expected_data_kind. But missed these keys: {missing_keys}\"\n                )\n\n        aggregation_weights = aggregation_weights or {}\n        aggregation_weights_dict = dict()\n        for k in self.expected_data_kind.keys():\n            if k in aggregation_weights:\n                aggregation_weights_dict[k] = aggregation_weights[k]\n            else:\n                # assume same aggregation weights for each entry of DXO collection.\n                aggregation_weights_dict[k] = aggregation_weights\n        self.aggregation_weights = aggregation_weights_dict\n\n        # Set up DXO aggregators\n        self.dxo_aggregators = dict()\n        for k in self.expected_data_kind.keys():\n            self.dxo_aggregators.update(\n                {\n                    k: DXOAggregator(\n                        exclude_vars=self.exclude_vars[k],\n                        aggregation_weights=self.aggregation_weights[k],\n                        expected_data_kind=self.expected_data_kind[k],\n                        name_postfix=k,\n                    )\n                }\n            )",
  "def accept(self, shareable: Shareable, fl_ctx: FLContext) -> bool:\n        \"\"\"Store shareable and update aggregator's internal state\n\n        Args:\n            shareable: information from contributor\n            fl_ctx: context provided by workflow\n\n        Returns:\n            The first boolean indicates if this shareable is accepted.\n            The second boolean indicates if aggregate can be called.\n        \"\"\"\n        try:\n            dxo = from_shareable(shareable)\n        except BaseException:\n            self.log_exception(fl_ctx, \"shareable data is not a valid DXO\")\n            return False\n\n        if dxo.data_kind not in (DataKind.WEIGHT_DIFF, DataKind.WEIGHTS, DataKind.COLLECTION):\n            self.log_error(\n                fl_ctx,\n                f\"cannot handle data kind {dxo.data_kind}, \"\n                f\"expecting DataKind.WEIGHT_DIFF, DataKind.WEIGHTS, or DataKind.COLLECTION.\",\n            )\n            return False\n\n        contributor_name = shareable.get_peer_prop(key=ReservedKey.IDENTITY_NAME, default=\"?\")\n        contribution_round = shareable.get_header(AppConstants.CONTRIBUTION_ROUND)\n\n        rc = shareable.get_return_code()\n        if rc and rc != ReturnCode.OK:\n            self.log_warning(fl_ctx, f\"Contributor {contributor_name} returned rc: {rc}. Disregarding contribution.\")\n            return False\n\n        # Accept expected DXO(s) in shareable\n        n_accepted = 0\n        for key in self.expected_data_kind.keys():\n            if key == self._single_dxo_key:  # expecting a single DXO\n                sub_dxo = dxo\n            else:  # expecting a collection of DXOs\n                sub_dxo = dxo.data.get(key)\n            if not isinstance(sub_dxo, DXO):\n                self.log_warning(fl_ctx, f\"Collection does not contain DXO for key {key} but {type(sub_dxo)}.\")\n                continue\n\n            accepted = self.dxo_aggregators[key].accept(\n                dxo=sub_dxo, contributor_name=contributor_name, contribution_round=contribution_round, fl_ctx=fl_ctx\n            )\n            if not accepted:\n                return False\n            else:\n                n_accepted += 1\n\n        if n_accepted > 0:\n            return True\n        else:\n            self.log_warning(fl_ctx, f\"Did not accept any DXOs from {contributor_name} in round {contribution_round}!\")\n            return False",
  "def aggregate(self, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Called when workflow determines to generate shareable to send back to contributors\n\n        Args:\n            fl_ctx (FLContext): context provided by workflow\n\n        Returns:\n            Shareable: the weighted mean of accepted shareables from contributors\n        \"\"\"\n\n        self.log_debug(fl_ctx, \"Start aggregation\")\n        result_dxo_dict = dict()\n        # Aggregate the expected DXO(s)\n        for key in self.expected_data_kind.keys():\n            aggregated_dxo = self.dxo_aggregators[key].aggregate(fl_ctx)\n            if key == self._single_dxo_key:  # return single DXO with aggregation results\n                return aggregated_dxo.to_shareable()\n            self.log_info(fl_ctx, f\"Aggregated contributions matching key '{key}'.\")\n            result_dxo_dict.update({key: aggregated_dxo})\n        # return collection of DXOs with aggregation results\n        collection_dxo = DXO(data_kind=DataKind.COLLECTION, data=result_dxo_dict)\n        return collection_dxo.to_shareable()",
  "class AccumulateWeightedAggregator(InTimeAccumulateWeightedAggregator):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.logger.warning(\n            \"'AccumulateWeightedAggregator' was deprecated, please use \" \"'InTimeAccumulateWeightedAggregator'\"\n        )",
  "def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.logger.warning(\n            \"'AccumulateWeightedAggregator' was deprecated, please use \" \"'InTimeAccumulateWeightedAggregator'\"\n        )",
  "class PTModelReaderWriter(ModelProcessor):\n    def __init__(self):\n        \"\"\"Perform the actual read/write operation for PyTorch-based models.\"\"\"\n        self._name = self.__class__.__name__\n        self.logger = logging.getLogger(self._name)\n\n    def extract_model(self, network, multi_processes: bool, model_vars: dict, fl_ctx: FLContext) -> dict:\n        net = network\n        if multi_processes:\n            net = net.module\n        local_state_dict = net.state_dict()\n\n        self.logger.debug(\"setup local_model_dict\")\n        local_model_dict = {}\n        for var_name in local_state_dict:\n            try:\n                local_model_dict[var_name] = local_state_dict[var_name].cpu().numpy()\n            except Exception as e:\n                raise ValueError(\"Did not work:\", str(e))\n        self.logger.debug(f\"local_model_dict {len(local_model_dict)}\")\n\n        return local_model_dict\n\n    def apply_model(self, network, multi_processes: bool, model_params: dict, fl_ctx: FLContext, options=None):\n        \"\"\"Set the local model according to model_data.\n\n        Args:\n            model_params: model data information\n            fl_ctx (FLContext): FL Context delivered by workflow\n            options: . Defaults to None.\n\n        Raises:\n            RuntimeError: Raised when being unable to apply model_params to the network\n\n        Returns:\n            a list of ops applied to model\n        \"\"\"\n        try:\n            net = network\n            if multi_processes:\n                net = net.module\n            assign_ops, updated_local_model = feed_vars(net, model_params)\n            self.logger.debug(f\"assign_ops: {len(assign_ops)}\")\n            self.logger.debug(f\"updated_local_model: {len(updated_local_model)}\")\n            # self.fitter.net.load_state_dict(updated_local_model)\n            net.load_state_dict(updated_local_model)\n            return assign_ops\n        except Exception as e:\n            raise RuntimeError(\"load_state_dict Exception:\", str(e))",
  "def __init__(self):\n        \"\"\"Perform the actual read/write operation for PyTorch-based models.\"\"\"\n        self._name = self.__class__.__name__\n        self.logger = logging.getLogger(self._name)",
  "def extract_model(self, network, multi_processes: bool, model_vars: dict, fl_ctx: FLContext) -> dict:\n        net = network\n        if multi_processes:\n            net = net.module\n        local_state_dict = net.state_dict()\n\n        self.logger.debug(\"setup local_model_dict\")\n        local_model_dict = {}\n        for var_name in local_state_dict:\n            try:\n                local_model_dict[var_name] = local_state_dict[var_name].cpu().numpy()\n            except Exception as e:\n                raise ValueError(\"Did not work:\", str(e))\n        self.logger.debug(f\"local_model_dict {len(local_model_dict)}\")\n\n        return local_model_dict",
  "def apply_model(self, network, multi_processes: bool, model_params: dict, fl_ctx: FLContext, options=None):\n        \"\"\"Set the local model according to model_data.\n\n        Args:\n            model_params: model data information\n            fl_ctx (FLContext): FL Context delivered by workflow\n            options: . Defaults to None.\n\n        Raises:\n            RuntimeError: Raised when being unable to apply model_params to the network\n\n        Returns:\n            a list of ops applied to model\n        \"\"\"\n        try:\n            net = network\n            if multi_processes:\n                net = net.module\n            assign_ops, updated_local_model = feed_vars(net, model_params)\n            self.logger.debug(f\"assign_ops: {len(assign_ops)}\")\n            self.logger.debug(f\"updated_local_model: {len(updated_local_model)}\")\n            # self.fitter.net.load_state_dict(updated_local_model)\n            net.load_state_dict(updated_local_model)\n            return assign_ops\n        except Exception as e:\n            raise RuntimeError(\"load_state_dict Exception:\", str(e))",
  "class PTFileModelPersistor(ModelPersistor):\n    def __init__(\n        self,\n        exclude_vars=None,\n        model=None,\n        global_model_file_name=DefaultCheckpointFileName.GLOBAL_MODEL,\n        best_global_model_file_name=DefaultCheckpointFileName.BEST_GLOBAL_MODEL,\n        source_ckpt_file_full_name=None,\n    ):\n        \"\"\"Persist pytorch-based model to/from file system.\n\n        This Model Persistor tries to load PT model data in following three ways:\n\n            1. Load from a specified source checkpoint file\n            2. Load from a location from the app folder\n            3. Load from a torch model object\n\n        The Persistor tries method 1 first if the source_ckpt_file_full_name is specified;\n        If source_ckpt_file_full_name is not specified, it tries the method 2;\n        If no checkpoint location is specified in the app folder, it tries method 3.\n\n        Method 2 - Load from a location from the app folder\n        It is assumed that the app folder must contain the environments.json file. Among other things, this\n        JSON file must specify where to find the checkpoint file. It does so with two JSON elements:\n\n            - APP_CKPT_DIR: specifies the folder (within the app) where the checkpoint file resides.\n            - APP_CKPT: specifies the base file name of the checkpoint\n\n        Here is an example of the environments.json content::\n\n            {\n                \"APP_CKPT_DIR\": \"model\",\n                \"APP_CKPT\": \"pretrained_model.pt\"\n            }\n\n        In this example, the checkpoint file is located in the \"model\" folder within the app and is named\n        pretrained_model.pt.\n\n        Method 3 - Load from a torch model object. In this case, the 'model' arg must be a valid torch\n        model, or the component ID of a valid torch model included in the \"components\" section of\n        your config_fed_server.json.\n\n        If all 3 methods fail, system_panic() is called.\n\n        If checkpoint folder name is specified, then global model and best global model will be saved to it;\n        Otherwise they will be saved directly in the app folder.\n\n        Args:\n            exclude_vars (str, optional): regex expression specifying weight vars to be excluded from training. Defaults to None.\n            model (str, optional): torch model object or component id of the model object. Defaults to None.\n            global_model_file_name (str, optional): file name for saving global model. Defaults to DefaultCheckpointFileName.GLOBAL_MODEL.\n            best_global_model_file_name (str, optional): file name for saving best global model. Defaults to DefaultCheckpointFileName.BEST_GLOBAL_MODEL.\n            source_ckpt_file_full_name (str, optional): full file name for source model checkpoint file. Defaults to None.\n\n        Raises:\n            ValueError: when source_ckpt_file_full_name does not exist\n        \"\"\"\n        super().__init__()\n        self.exclude_vars = re.compile(exclude_vars) if exclude_vars else None\n        self.model = model\n        self.log_dir = None\n        self.ckpt_preload_path = None\n        self.persistence_manager = None\n        self.ckpt_dir_env_key = EnvironmentKey.CHECKPOINT_DIR\n        self.ckpt_file_name_env_key = EnvironmentKey.CHECKPOINT_FILE_NAME\n        self.global_model_file_name = global_model_file_name\n        self.best_global_model_file_name = best_global_model_file_name\n        self.source_ckpt_file_full_name = source_ckpt_file_full_name\n\n        self.default_train_conf = None\n\n        if source_ckpt_file_full_name and not os.path.exists(source_ckpt_file_full_name):\n            raise ValueError(\"specified source checkpoint model file {} does not exist\")\n\n    def _initialize(self, fl_ctx: FLContext):\n        app_root = fl_ctx.get_prop(FLContextKey.APP_ROOT)\n        env = None\n        run_args = fl_ctx.get_prop(FLContextKey.ARGS)\n        if run_args:\n            env_config_file_name = os.path.join(app_root, run_args.env)\n            if os.path.exists(env_config_file_name):\n                try:\n                    with open(env_config_file_name) as file:\n                        env = json.load(file)\n                except:\n                    self.system_panic(\n                        reason=\"error opening env config file {}\".format(env_config_file_name), fl_ctx=fl_ctx\n                    )\n                    return\n\n        if env is not None:\n            if env.get(self.ckpt_dir_env_key, None):\n                fl_ctx.set_prop(AppConstants.LOG_DIR, env[self.ckpt_dir_env_key], private=True, sticky=True)\n            if env.get(self.ckpt_file_name_env_key) is not None:\n                fl_ctx.set_prop(\n                    AppConstants.CKPT_PRELOAD_PATH, env[self.ckpt_file_name_env_key], private=True, sticky=True\n                )\n\n        log_dir = fl_ctx.get_prop(AppConstants.LOG_DIR)\n        if log_dir:\n            self.log_dir = os.path.join(app_root, log_dir)\n        else:\n            self.log_dir = app_root\n\n        self._ckpt_save_path = os.path.join(self.log_dir, self.global_model_file_name)\n        self._best_ckpt_save_path = os.path.join(self.log_dir, self.best_global_model_file_name)\n\n        ckpt_preload_path = fl_ctx.get_prop(AppConstants.CKPT_PRELOAD_PATH)\n        if ckpt_preload_path:\n            self.ckpt_preload_path = os.path.join(app_root, ckpt_preload_path)\n\n        if not os.path.exists(self.log_dir):\n            os.makedirs(self.log_dir)\n\n        if isinstance(self.model, str):\n            # treat it as model component ID\n            model_component_id = self.model\n            engine = fl_ctx.get_engine()\n            self.model = engine.get_component(model_component_id)\n            if not self.model:\n                self.system_panic(reason=\"cannot find model component '{}'\".format(model_component_id), fl_ctx=fl_ctx)\n                return\n            if not isinstance(self.model, torch.nn.Module):\n                self.system_panic(\n                    reason=\"expect model component '{}' to be torch.nn.Module but got {}\".format(\n                        model_component_id, type(self.model)\n                    ),\n                    fl_ctx=fl_ctx,\n                )\n                return\n        elif self.model and not isinstance(self.model, torch.nn.Module):\n            self.system_panic(\n                reason=\"expect model to be torch.nn.Module but got {}\".format(type(self.model)), fl_ctx=fl_ctx\n            )\n            return\n\n        fl_ctx.sync_sticky()\n\n    def load_model(self, fl_ctx: FLContext) -> ModelLearnable:\n        \"\"\"Convert initialised model into Learnable/Model format.\n\n        Args:\n            fl_ctx (FLContext): FL Context delivered by workflow\n\n        Returns:\n            Model: a Learnable/Model object\n        \"\"\"\n        src_file_name = None\n        if self.source_ckpt_file_full_name:\n            src_file_name = self.source_ckpt_file_full_name\n        elif self.ckpt_preload_path:\n            src_file_name = self.ckpt_preload_path\n\n        if src_file_name:\n            try:\n                device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n                data = torch.load(src_file_name, map_location=device)\n                # \"checkpoint may contain 'model', 'optimizer', 'lr_scheduler', etc. or only contain model dict directly.\"\n            except:\n                self.log_exception(fl_ctx, \"error loading checkpoint from {}\".format(src_file_name))\n                self.system_panic(reason=\"cannot load model checkpoint\", fl_ctx=fl_ctx)\n                return None\n        else:\n            # if no pretrained model provided, use the generated network weights from APP config\n            # note that, if set \"determinism\" in the config, the init model weights will always be the same\n            try:\n                data = self.model.state_dict() if self.model is not None else OrderedDict()\n            except:\n                self.log_exception(fl_ctx, \"error getting state_dict from model object\")\n                self.system_panic(reason=\"cannot create state_dict from model object\", fl_ctx=fl_ctx)\n                return None\n\n        if self.model:\n            self.default_train_conf = {\"train\": {\"model\": type(self.model).__name__}}\n\n        self.persistence_manager = PTModelPersistenceFormatManager(data, default_train_conf=self.default_train_conf)\n        return self.persistence_manager.to_model_learnable(self.exclude_vars)\n\n    def handle_event(self, event: str, fl_ctx: FLContext):\n        if event == EventType.START_RUN:\n            self._initialize(fl_ctx)\n        elif event == AppEventType.GLOBAL_BEST_MODEL_AVAILABLE:\n            # save the current model as the best model!\n            self.save_model_file(self._best_ckpt_save_path)\n\n    def save_model_file(self, save_path: str):\n        save_dict = self.persistence_manager.to_persistence_dict()\n        torch.save(save_dict, save_path)\n\n    def save_model(self, ml: ModelLearnable, fl_ctx: FLContext):\n        self.persistence_manager.update(ml)\n        self.save_model_file(self._ckpt_save_path)\n\n    def get_model(self, model_file, fl_ctx: FLContext) -> ModelLearnable:\n        try:\n            # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n            # Use the \"cpu\" to load the global model weights, avoid GPU out of memory\n            device = \"cpu\"\n            location = os.path.join(self.log_dir, model_file)\n            data = torch.load(location, map_location=device)\n            persistence_manager = PTModelPersistenceFormatManager(data, default_train_conf=self.default_train_conf)\n            return persistence_manager.to_model_learnable(self.exclude_vars)\n        except BaseException as e:\n            self.log_exception(fl_ctx, \"error loading checkpoint from {}\".format(model_file))\n            return {}\n\n    def get_model_inventory(self, fl_ctx: FLContext) -> {str: ModelDescriptor}:\n        model_inventory = {}\n        location = os.path.join(self.log_dir, self.global_model_file_name)\n        if os.path.exists(location):\n            model_inventory[self.global_model_file_name] = ModelDescriptor(\n                name=self.global_model_file_name,\n                location=location,\n                model_format=self.persistence_manager.get_persist_model_format(),\n                props={},\n            )\n\n        location = os.path.join(self.log_dir, self.best_global_model_file_name)\n        if os.path.exists(location):\n            model_inventory[self.best_global_model_file_name] = ModelDescriptor(\n                name=self.best_global_model_file_name,\n                location=location,\n                model_format=self.persistence_manager.get_persist_model_format(),\n                props={},\n            )\n\n        return model_inventory",
  "def __init__(\n        self,\n        exclude_vars=None,\n        model=None,\n        global_model_file_name=DefaultCheckpointFileName.GLOBAL_MODEL,\n        best_global_model_file_name=DefaultCheckpointFileName.BEST_GLOBAL_MODEL,\n        source_ckpt_file_full_name=None,\n    ):\n        \"\"\"Persist pytorch-based model to/from file system.\n\n        This Model Persistor tries to load PT model data in following three ways:\n\n            1. Load from a specified source checkpoint file\n            2. Load from a location from the app folder\n            3. Load from a torch model object\n\n        The Persistor tries method 1 first if the source_ckpt_file_full_name is specified;\n        If source_ckpt_file_full_name is not specified, it tries the method 2;\n        If no checkpoint location is specified in the app folder, it tries method 3.\n\n        Method 2 - Load from a location from the app folder\n        It is assumed that the app folder must contain the environments.json file. Among other things, this\n        JSON file must specify where to find the checkpoint file. It does so with two JSON elements:\n\n            - APP_CKPT_DIR: specifies the folder (within the app) where the checkpoint file resides.\n            - APP_CKPT: specifies the base file name of the checkpoint\n\n        Here is an example of the environments.json content::\n\n            {\n                \"APP_CKPT_DIR\": \"model\",\n                \"APP_CKPT\": \"pretrained_model.pt\"\n            }\n\n        In this example, the checkpoint file is located in the \"model\" folder within the app and is named\n        pretrained_model.pt.\n\n        Method 3 - Load from a torch model object. In this case, the 'model' arg must be a valid torch\n        model, or the component ID of a valid torch model included in the \"components\" section of\n        your config_fed_server.json.\n\n        If all 3 methods fail, system_panic() is called.\n\n        If checkpoint folder name is specified, then global model and best global model will be saved to it;\n        Otherwise they will be saved directly in the app folder.\n\n        Args:\n            exclude_vars (str, optional): regex expression specifying weight vars to be excluded from training. Defaults to None.\n            model (str, optional): torch model object or component id of the model object. Defaults to None.\n            global_model_file_name (str, optional): file name for saving global model. Defaults to DefaultCheckpointFileName.GLOBAL_MODEL.\n            best_global_model_file_name (str, optional): file name for saving best global model. Defaults to DefaultCheckpointFileName.BEST_GLOBAL_MODEL.\n            source_ckpt_file_full_name (str, optional): full file name for source model checkpoint file. Defaults to None.\n\n        Raises:\n            ValueError: when source_ckpt_file_full_name does not exist\n        \"\"\"\n        super().__init__()\n        self.exclude_vars = re.compile(exclude_vars) if exclude_vars else None\n        self.model = model\n        self.log_dir = None\n        self.ckpt_preload_path = None\n        self.persistence_manager = None\n        self.ckpt_dir_env_key = EnvironmentKey.CHECKPOINT_DIR\n        self.ckpt_file_name_env_key = EnvironmentKey.CHECKPOINT_FILE_NAME\n        self.global_model_file_name = global_model_file_name\n        self.best_global_model_file_name = best_global_model_file_name\n        self.source_ckpt_file_full_name = source_ckpt_file_full_name\n\n        self.default_train_conf = None\n\n        if source_ckpt_file_full_name and not os.path.exists(source_ckpt_file_full_name):\n            raise ValueError(\"specified source checkpoint model file {} does not exist\")",
  "def _initialize(self, fl_ctx: FLContext):\n        app_root = fl_ctx.get_prop(FLContextKey.APP_ROOT)\n        env = None\n        run_args = fl_ctx.get_prop(FLContextKey.ARGS)\n        if run_args:\n            env_config_file_name = os.path.join(app_root, run_args.env)\n            if os.path.exists(env_config_file_name):\n                try:\n                    with open(env_config_file_name) as file:\n                        env = json.load(file)\n                except:\n                    self.system_panic(\n                        reason=\"error opening env config file {}\".format(env_config_file_name), fl_ctx=fl_ctx\n                    )\n                    return\n\n        if env is not None:\n            if env.get(self.ckpt_dir_env_key, None):\n                fl_ctx.set_prop(AppConstants.LOG_DIR, env[self.ckpt_dir_env_key], private=True, sticky=True)\n            if env.get(self.ckpt_file_name_env_key) is not None:\n                fl_ctx.set_prop(\n                    AppConstants.CKPT_PRELOAD_PATH, env[self.ckpt_file_name_env_key], private=True, sticky=True\n                )\n\n        log_dir = fl_ctx.get_prop(AppConstants.LOG_DIR)\n        if log_dir:\n            self.log_dir = os.path.join(app_root, log_dir)\n        else:\n            self.log_dir = app_root\n\n        self._ckpt_save_path = os.path.join(self.log_dir, self.global_model_file_name)\n        self._best_ckpt_save_path = os.path.join(self.log_dir, self.best_global_model_file_name)\n\n        ckpt_preload_path = fl_ctx.get_prop(AppConstants.CKPT_PRELOAD_PATH)\n        if ckpt_preload_path:\n            self.ckpt_preload_path = os.path.join(app_root, ckpt_preload_path)\n\n        if not os.path.exists(self.log_dir):\n            os.makedirs(self.log_dir)\n\n        if isinstance(self.model, str):\n            # treat it as model component ID\n            model_component_id = self.model\n            engine = fl_ctx.get_engine()\n            self.model = engine.get_component(model_component_id)\n            if not self.model:\n                self.system_panic(reason=\"cannot find model component '{}'\".format(model_component_id), fl_ctx=fl_ctx)\n                return\n            if not isinstance(self.model, torch.nn.Module):\n                self.system_panic(\n                    reason=\"expect model component '{}' to be torch.nn.Module but got {}\".format(\n                        model_component_id, type(self.model)\n                    ),\n                    fl_ctx=fl_ctx,\n                )\n                return\n        elif self.model and not isinstance(self.model, torch.nn.Module):\n            self.system_panic(\n                reason=\"expect model to be torch.nn.Module but got {}\".format(type(self.model)), fl_ctx=fl_ctx\n            )\n            return\n\n        fl_ctx.sync_sticky()",
  "def load_model(self, fl_ctx: FLContext) -> ModelLearnable:\n        \"\"\"Convert initialised model into Learnable/Model format.\n\n        Args:\n            fl_ctx (FLContext): FL Context delivered by workflow\n\n        Returns:\n            Model: a Learnable/Model object\n        \"\"\"\n        src_file_name = None\n        if self.source_ckpt_file_full_name:\n            src_file_name = self.source_ckpt_file_full_name\n        elif self.ckpt_preload_path:\n            src_file_name = self.ckpt_preload_path\n\n        if src_file_name:\n            try:\n                device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n                data = torch.load(src_file_name, map_location=device)\n                # \"checkpoint may contain 'model', 'optimizer', 'lr_scheduler', etc. or only contain model dict directly.\"\n            except:\n                self.log_exception(fl_ctx, \"error loading checkpoint from {}\".format(src_file_name))\n                self.system_panic(reason=\"cannot load model checkpoint\", fl_ctx=fl_ctx)\n                return None\n        else:\n            # if no pretrained model provided, use the generated network weights from APP config\n            # note that, if set \"determinism\" in the config, the init model weights will always be the same\n            try:\n                data = self.model.state_dict() if self.model is not None else OrderedDict()\n            except:\n                self.log_exception(fl_ctx, \"error getting state_dict from model object\")\n                self.system_panic(reason=\"cannot create state_dict from model object\", fl_ctx=fl_ctx)\n                return None\n\n        if self.model:\n            self.default_train_conf = {\"train\": {\"model\": type(self.model).__name__}}\n\n        self.persistence_manager = PTModelPersistenceFormatManager(data, default_train_conf=self.default_train_conf)\n        return self.persistence_manager.to_model_learnable(self.exclude_vars)",
  "def handle_event(self, event: str, fl_ctx: FLContext):\n        if event == EventType.START_RUN:\n            self._initialize(fl_ctx)\n        elif event == AppEventType.GLOBAL_BEST_MODEL_AVAILABLE:\n            # save the current model as the best model!\n            self.save_model_file(self._best_ckpt_save_path)",
  "def save_model_file(self, save_path: str):\n        save_dict = self.persistence_manager.to_persistence_dict()\n        torch.save(save_dict, save_path)",
  "def save_model(self, ml: ModelLearnable, fl_ctx: FLContext):\n        self.persistence_manager.update(ml)\n        self.save_model_file(self._ckpt_save_path)",
  "def get_model(self, model_file, fl_ctx: FLContext) -> ModelLearnable:\n        try:\n            # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n            # Use the \"cpu\" to load the global model weights, avoid GPU out of memory\n            device = \"cpu\"\n            location = os.path.join(self.log_dir, model_file)\n            data = torch.load(location, map_location=device)\n            persistence_manager = PTModelPersistenceFormatManager(data, default_train_conf=self.default_train_conf)\n            return persistence_manager.to_model_learnable(self.exclude_vars)\n        except BaseException as e:\n            self.log_exception(fl_ctx, \"error loading checkpoint from {}\".format(model_file))\n            return {}",
  "def get_model_inventory(self, fl_ctx: FLContext) -> {str: ModelDescriptor}:\n        model_inventory = {}\n        location = os.path.join(self.log_dir, self.global_model_file_name)\n        if os.path.exists(location):\n            model_inventory[self.global_model_file_name] = ModelDescriptor(\n                name=self.global_model_file_name,\n                location=location,\n                model_format=self.persistence_manager.get_persist_model_format(),\n                props={},\n            )\n\n        location = os.path.join(self.log_dir, self.best_global_model_file_name)\n        if os.path.exists(location):\n            model_inventory[self.best_global_model_file_name] = ModelDescriptor(\n                name=self.best_global_model_file_name,\n                location=location,\n                model_format=self.persistence_manager.get_persist_model_format(),\n                props={},\n            )\n\n        return model_inventory",
  "class PTMultiProcessExecutor(MultiProcessExecutor):\n    def get_multi_process_command(self) -> str:\n        return (\n            f\"{sys.executable} -m torch.distributed.run --nproc_per_node=\"\n            + str(self.num_of_processes)\n            + \" --nnodes=1 --node_rank=0\"\n            + ' --master_addr=\"localhost\" --master_port='\n            + str(get_open_ports(1)[0])\n        )",
  "def get_multi_process_command(self) -> str:\n        return (\n            f\"{sys.executable} -m torch.distributed.run --nproc_per_node=\"\n            + str(self.num_of_processes)\n            + \" --nnodes=1 --node_rank=0\"\n            + ' --master_addr=\"localhost\" --master_port='\n            + str(get_open_ports(1)[0])\n        )",
  "class PTFedOptModelShareableGenerator(FullModelShareableGenerator):\n    def __init__(\n        self,\n        optimizer_args: dict = None,\n        lr_scheduler_args: dict = None,\n        source_model=\"model\",\n        device=None,\n    ):\n        \"\"\"Implement the FedOpt algorithm.\n\n        The algorithm is proposed in Reddi, Sashank, et al. \"Adaptive federated optimization.\" arXiv preprint arXiv:2003.00295 (2020).\n        This SharableGenerator will update the global model using the specified\n        PyTorch optimizer and learning rate scheduler.\n\n        Args:\n            optimizer_args: dictionary of optimizer arguments, e.g.\n                {'path': 'torch.optim.SGD', 'args': {'lr': 1.0}} (default).\n            lr_scheduler_args: dictionary of server-side learning rate scheduler arguments, e.g.\n                {'path': 'torch.optim.lr_scheduler.CosineAnnealingLR', 'args': {'T_max': 100}} (default: None).\n            source_model: either a valid torch model object or a component ID of a torch model object\n            device: specify the device to run server-side optimization, e.g. \"cpu\" or \"cuda:0\"\n                (will default to cuda if available and no device is specified).\n\n        Raises:\n            TypeError: when any of input arguments does not have correct type\n        \"\"\"\n        super().__init__()\n        if not optimizer_args:\n            self.logger(\"No optimizer_args provided. Using FedOpt with SGD and lr 1.0\")\n            optimizer_args = {\"name\": \"SGD\", \"args\": {\"lr\": 1.0}}\n\n        if not isinstance(optimizer_args, dict):\n            raise TypeError(\n                \"optimizer_args must be a dict of format, e.g. {'path': 'torch.optim.SGD', 'args': {'lr': 1.0}}.\"\n            )\n        if lr_scheduler_args is not None:\n            if not isinstance(lr_scheduler_args, dict):\n                raise TypeError(\n                    \"optimizer_args must be a dict of format, e.g. \"\n                    \"{'path': 'torch.optim.lr_scheduler.CosineAnnealingLR', 'args': {'T_max': 100}}.\"\n                )\n        self.source_model = source_model\n        self.optimizer_args = optimizer_args\n        self.lr_scheduler_args = lr_scheduler_args\n        self.model = None\n        self.optimizer = None\n        self.lr_scheduler = None\n        if device is None:\n            self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        else:\n            self.device = torch.device(device)\n        self.optimizer_name = None\n        self.lr_scheduler_name = None\n\n    def _get_component_name(self, component_args):\n        if component_args is not None:\n            name = component_args.get(\"path\", None)\n            if name is None:\n                name = component_args.get(\"name\", None)\n            return name\n        else:\n            return None\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            # Initialize the optimizer with current global model params\n            engine = fl_ctx.get_engine()\n\n            if isinstance(self.source_model, str):\n                self.model = engine.get_component(self.source_model)\n            else:\n                self.model = self.source_model\n\n            if self.model is None:\n                self.system_panic(\n                    \"Model is not available\",\n                    fl_ctx,\n                )\n                return\n            elif not isinstance(self.model, torch.nn.Module):\n                self.system_panic(\n                    f\"Expected model to be a torch.nn.Module but got {type(self.model)}\",\n                    fl_ctx,\n                )\n                return\n            else:\n                print(\"server model\", self.model)\n\n            self.model.to(self.device)\n\n            # set up optimizer\n            try:\n                # use provided or default optimizer arguments and add the model parameters\n                if \"args\" not in self.optimizer_args:\n                    self.optimizer_args[\"args\"] = {}\n                self.optimizer_args[\"args\"][\"params\"] = self.model.parameters()\n                self.optimizer = engine.build_component(self.optimizer_args)\n                # get optimizer name for log\n                self.optimizer_name = self._get_component_name(self.optimizer_args)\n            except BaseException as e:\n                self.system_panic(\n                    f\"Exception while parsing `optimizer_args`: \" f\"{self.optimizer_args} with Exception {e}\",\n                    fl_ctx,\n                )\n                return\n\n            # set up lr scheduler\n            if self.lr_scheduler_args is not None:\n                try:\n                    self.lr_scheduler_name = self._get_component_name(self.lr_scheduler_args)\n                    # use provided or default lr scheduler argument and add the optimizer\n                    if \"args\" not in self.lr_scheduler_args:\n                        self.lr_scheduler_args[\"args\"] = {}\n                    self.lr_scheduler_args[\"args\"][\"optimizer\"] = self.optimizer\n                    self.lr_scheduler = engine.build_component(self.lr_scheduler_args)\n                except BaseException as e:\n                    self.system_panic(\n                        f\"Exception while parsing `lr_scheduler_args`: \" f\"{self.lr_scheduler_args} with Exception {e}\",\n                        fl_ctx,\n                    )\n                    return\n\n    def server_update(self, model_diff):\n        \"\"\"Updates the global model using the specified optimizer.\n\n        Args:\n            model_diff: the aggregated model differences from clients.\n\n        Returns:\n            The updated PyTorch model state dictionary.\n\n        \"\"\"\n        self.model.train()\n        self.optimizer.zero_grad()\n\n        # Apply the update to the model. We must multiply weights_delta by -1.0 to\n        # view it as a gradient that should be applied to the server_optimizer.\n        for name, param in self.model.named_parameters():\n            param.grad = torch.tensor(-1.0 * model_diff[name]).to(self.device)\n\n        self.optimizer.step()\n        if self.lr_scheduler is not None:\n            self.lr_scheduler.step()\n\n        return self.model.state_dict()\n\n    def shareable_to_learnable(self, shareable: Shareable, fl_ctx: FLContext) -> Learnable:\n        \"\"\"Convert Shareable to Learnable while doing a FedOpt update step.\n\n        Supporting data_kind == DataKind.WEIGHT_DIFF\n\n        Args:\n            shareable (Shareable): Shareable to be converted\n            fl_ctx (FLContext): FL context\n\n        Returns:\n            Model: Updated global ModelLearnable.\n        \"\"\"\n        # check types\n        dxo = from_shareable(shareable)\n\n        if dxo.data_kind != DataKind.WEIGHT_DIFF:\n            self.system_panic(\n                \"FedOpt is only implemented for \" \"data_kind == DataKind.WEIGHT_DIFF\",\n                fl_ctx,\n            )\n            return Learnable()\n\n        processed_algorithm = dxo.get_meta_prop(MetaKey.PROCESSED_ALGORITHM)\n        if processed_algorithm is not None:\n            self.system_panic(\n                f\"FedOpt is not implemented for shareable processed by {processed_algorithm}\",\n                fl_ctx,\n            )\n            return Learnable()\n\n        model_diff = dxo.data\n\n        start = time.time()\n        weights = self.server_update(model_diff)\n        secs = time.time() - start\n\n        # convert to numpy dict of weights\n        start = time.time()\n        for key in weights:\n            weights[key] = weights[key].detach().cpu().numpy()\n        secs_detach = time.time() - start\n\n        self.log_info(\n            fl_ctx,\n            f\"FedOpt ({self.optimizer_name}, {self.device}) server model update \"\n            f\"round {fl_ctx.get_prop(AppConstants.CURRENT_ROUND)}, \"\n            f\"{self.lr_scheduler_name if self.lr_scheduler_name else ''} \"\n            f\"lr: {self.optimizer.param_groups[-1]['lr']}, \"\n            f\"update: {secs} secs., detach: {secs_detach} secs.\",\n        )\n        # TODO: write server-side lr to tensorboard\n\n        return make_model_learnable(weights, dxo.get_meta_props())",
  "def __init__(\n        self,\n        optimizer_args: dict = None,\n        lr_scheduler_args: dict = None,\n        source_model=\"model\",\n        device=None,\n    ):\n        \"\"\"Implement the FedOpt algorithm.\n\n        The algorithm is proposed in Reddi, Sashank, et al. \"Adaptive federated optimization.\" arXiv preprint arXiv:2003.00295 (2020).\n        This SharableGenerator will update the global model using the specified\n        PyTorch optimizer and learning rate scheduler.\n\n        Args:\n            optimizer_args: dictionary of optimizer arguments, e.g.\n                {'path': 'torch.optim.SGD', 'args': {'lr': 1.0}} (default).\n            lr_scheduler_args: dictionary of server-side learning rate scheduler arguments, e.g.\n                {'path': 'torch.optim.lr_scheduler.CosineAnnealingLR', 'args': {'T_max': 100}} (default: None).\n            source_model: either a valid torch model object or a component ID of a torch model object\n            device: specify the device to run server-side optimization, e.g. \"cpu\" or \"cuda:0\"\n                (will default to cuda if available and no device is specified).\n\n        Raises:\n            TypeError: when any of input arguments does not have correct type\n        \"\"\"\n        super().__init__()\n        if not optimizer_args:\n            self.logger(\"No optimizer_args provided. Using FedOpt with SGD and lr 1.0\")\n            optimizer_args = {\"name\": \"SGD\", \"args\": {\"lr\": 1.0}}\n\n        if not isinstance(optimizer_args, dict):\n            raise TypeError(\n                \"optimizer_args must be a dict of format, e.g. {'path': 'torch.optim.SGD', 'args': {'lr': 1.0}}.\"\n            )\n        if lr_scheduler_args is not None:\n            if not isinstance(lr_scheduler_args, dict):\n                raise TypeError(\n                    \"optimizer_args must be a dict of format, e.g. \"\n                    \"{'path': 'torch.optim.lr_scheduler.CosineAnnealingLR', 'args': {'T_max': 100}}.\"\n                )\n        self.source_model = source_model\n        self.optimizer_args = optimizer_args\n        self.lr_scheduler_args = lr_scheduler_args\n        self.model = None\n        self.optimizer = None\n        self.lr_scheduler = None\n        if device is None:\n            self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        else:\n            self.device = torch.device(device)\n        self.optimizer_name = None\n        self.lr_scheduler_name = None",
  "def _get_component_name(self, component_args):\n        if component_args is not None:\n            name = component_args.get(\"path\", None)\n            if name is None:\n                name = component_args.get(\"name\", None)\n            return name\n        else:\n            return None",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            # Initialize the optimizer with current global model params\n            engine = fl_ctx.get_engine()\n\n            if isinstance(self.source_model, str):\n                self.model = engine.get_component(self.source_model)\n            else:\n                self.model = self.source_model\n\n            if self.model is None:\n                self.system_panic(\n                    \"Model is not available\",\n                    fl_ctx,\n                )\n                return\n            elif not isinstance(self.model, torch.nn.Module):\n                self.system_panic(\n                    f\"Expected model to be a torch.nn.Module but got {type(self.model)}\",\n                    fl_ctx,\n                )\n                return\n            else:\n                print(\"server model\", self.model)\n\n            self.model.to(self.device)\n\n            # set up optimizer\n            try:\n                # use provided or default optimizer arguments and add the model parameters\n                if \"args\" not in self.optimizer_args:\n                    self.optimizer_args[\"args\"] = {}\n                self.optimizer_args[\"args\"][\"params\"] = self.model.parameters()\n                self.optimizer = engine.build_component(self.optimizer_args)\n                # get optimizer name for log\n                self.optimizer_name = self._get_component_name(self.optimizer_args)\n            except BaseException as e:\n                self.system_panic(\n                    f\"Exception while parsing `optimizer_args`: \" f\"{self.optimizer_args} with Exception {e}\",\n                    fl_ctx,\n                )\n                return\n\n            # set up lr scheduler\n            if self.lr_scheduler_args is not None:\n                try:\n                    self.lr_scheduler_name = self._get_component_name(self.lr_scheduler_args)\n                    # use provided or default lr scheduler argument and add the optimizer\n                    if \"args\" not in self.lr_scheduler_args:\n                        self.lr_scheduler_args[\"args\"] = {}\n                    self.lr_scheduler_args[\"args\"][\"optimizer\"] = self.optimizer\n                    self.lr_scheduler = engine.build_component(self.lr_scheduler_args)\n                except BaseException as e:\n                    self.system_panic(\n                        f\"Exception while parsing `lr_scheduler_args`: \" f\"{self.lr_scheduler_args} with Exception {e}\",\n                        fl_ctx,\n                    )\n                    return",
  "def server_update(self, model_diff):\n        \"\"\"Updates the global model using the specified optimizer.\n\n        Args:\n            model_diff: the aggregated model differences from clients.\n\n        Returns:\n            The updated PyTorch model state dictionary.\n\n        \"\"\"\n        self.model.train()\n        self.optimizer.zero_grad()\n\n        # Apply the update to the model. We must multiply weights_delta by -1.0 to\n        # view it as a gradient that should be applied to the server_optimizer.\n        for name, param in self.model.named_parameters():\n            param.grad = torch.tensor(-1.0 * model_diff[name]).to(self.device)\n\n        self.optimizer.step()\n        if self.lr_scheduler is not None:\n            self.lr_scheduler.step()\n\n        return self.model.state_dict()",
  "def shareable_to_learnable(self, shareable: Shareable, fl_ctx: FLContext) -> Learnable:\n        \"\"\"Convert Shareable to Learnable while doing a FedOpt update step.\n\n        Supporting data_kind == DataKind.WEIGHT_DIFF\n\n        Args:\n            shareable (Shareable): Shareable to be converted\n            fl_ctx (FLContext): FL context\n\n        Returns:\n            Model: Updated global ModelLearnable.\n        \"\"\"\n        # check types\n        dxo = from_shareable(shareable)\n\n        if dxo.data_kind != DataKind.WEIGHT_DIFF:\n            self.system_panic(\n                \"FedOpt is only implemented for \" \"data_kind == DataKind.WEIGHT_DIFF\",\n                fl_ctx,\n            )\n            return Learnable()\n\n        processed_algorithm = dxo.get_meta_prop(MetaKey.PROCESSED_ALGORITHM)\n        if processed_algorithm is not None:\n            self.system_panic(\n                f\"FedOpt is not implemented for shareable processed by {processed_algorithm}\",\n                fl_ctx,\n            )\n            return Learnable()\n\n        model_diff = dxo.data\n\n        start = time.time()\n        weights = self.server_update(model_diff)\n        secs = time.time() - start\n\n        # convert to numpy dict of weights\n        start = time.time()\n        for key in weights:\n            weights[key] = weights[key].detach().cpu().numpy()\n        secs_detach = time.time() - start\n\n        self.log_info(\n            fl_ctx,\n            f\"FedOpt ({self.optimizer_name}, {self.device}) server model update \"\n            f\"round {fl_ctx.get_prop(AppConstants.CURRENT_ROUND)}, \"\n            f\"{self.lr_scheduler_name if self.lr_scheduler_name else ''} \"\n            f\"lr: {self.optimizer.param_groups[-1]['lr']}, \"\n            f\"update: {secs} secs., detach: {secs_detach} secs.\",\n        )\n        # TODO: write server-side lr to tensorboard\n\n        return make_model_learnable(weights, dxo.get_meta_props())",
  "def get_lr_values(optimizer: Optimizer):\n    \"\"\"\n    This function is used to get the learning rates of the optimizer.\n    \"\"\"\n    return [group[\"lr\"] for group in optimizer.state_dict()[\"param_groups\"]]",
  "class PTScaffoldHelper(object):\n    \"\"\"Helper to be used with SCAFFOLD components.\n    Implements the functions used for the algorithm proposed in\n    Karimireddy et al. \"SCAFFOLD: Stochastic Controlled Averaging for Federated Learning\"\n    (https://arxiv.org/abs/1910.06378) using PyTorch.\n    SCAFFOLD-related functions are based on https://github.com/Xtra-Computing/NIID-Bench.\n    See also Li et al. \"Federated Learning on Non-IID Data Silos: An Experimental Study\"\n    (https://arxiv.org/abs/2102.02079).\n    \"\"\"\n\n    def __init__(self):\n        # SCAFFOLD control terms\n        self.cnt = 0\n        self.c_global = None\n        self.c_local = None\n        self.c_delta_para = None\n\n    def init(self, model):\n        # create models for SCAFFOLD correction terms\n        self.c_global = copy.deepcopy(model)\n        self.c_local = copy.deepcopy(model)\n        # Initialize correction term with zeros\n        c_init_para = model.state_dict()\n        for k in c_init_para.keys():\n            c_init_para[k] = torch.zeros_like(c_init_para[k])\n        self.c_global.load_state_dict(c_init_para)\n        self.c_local.load_state_dict(c_init_para)\n\n    def get_params(self):\n        self.cnt = 0\n        # Adapted from https://github.com/Xtra-Computing/NIID-Bench/blob/main/experiments.py#L371\n        c_global_para = self.c_global.state_dict()\n        c_local_para = self.c_local.state_dict()\n        return c_global_para, c_local_para\n\n    def model_update(self, model, curr_lr, c_global_para, c_local_para):\n        # Update model using scaffold controls\n        # See https://github.com/Xtra-Computing/NIID-Bench/blob/main/experiments.py#L391\n        net_para = model.state_dict()\n        for key in net_para:\n            net_para[key] = net_para[key] - curr_lr * (c_global_para[key] - c_local_para[key])\n        model.load_state_dict(net_para)\n\n        self.cnt += 1\n\n    def terms_update(self, model, curr_lr, c_global_para, c_local_para, model_global):\n        # Update the local scaffold controls\n        # See https://github.com/Xtra-Computing/NIID-Bench/blob/main/experiments.py#L403\n\n        c_new_para = self.c_local.state_dict()\n        self.c_delta_para = copy.deepcopy(self.c_local.state_dict())\n        global_model_para = model_global.state_dict()\n        net_para = model.state_dict()\n        for key in net_para:\n            c_new_para[key] = (\n                c_new_para[key] - c_global_para[key] + (global_model_para[key] - net_para[key]) / (self.cnt * curr_lr)\n            )\n            self.c_delta_para[key] = (c_new_para[key] - c_local_para[key]).cpu().numpy()\n        self.c_local.load_state_dict(c_new_para)\n\n    def load_global_controls(self, weights):\n        self.c_global.load_state_dict(weights)\n\n    def get_delta_controls(self):\n        if self.c_delta_para is None:\n            raise ValueError(\"c_delta_para hasn't been computed yet!\")\n        return self.c_delta_para",
  "def __init__(self):\n        # SCAFFOLD control terms\n        self.cnt = 0\n        self.c_global = None\n        self.c_local = None\n        self.c_delta_para = None",
  "def init(self, model):\n        # create models for SCAFFOLD correction terms\n        self.c_global = copy.deepcopy(model)\n        self.c_local = copy.deepcopy(model)\n        # Initialize correction term with zeros\n        c_init_para = model.state_dict()\n        for k in c_init_para.keys():\n            c_init_para[k] = torch.zeros_like(c_init_para[k])\n        self.c_global.load_state_dict(c_init_para)\n        self.c_local.load_state_dict(c_init_para)",
  "def get_params(self):\n        self.cnt = 0\n        # Adapted from https://github.com/Xtra-Computing/NIID-Bench/blob/main/experiments.py#L371\n        c_global_para = self.c_global.state_dict()\n        c_local_para = self.c_local.state_dict()\n        return c_global_para, c_local_para",
  "def model_update(self, model, curr_lr, c_global_para, c_local_para):\n        # Update model using scaffold controls\n        # See https://github.com/Xtra-Computing/NIID-Bench/blob/main/experiments.py#L391\n        net_para = model.state_dict()\n        for key in net_para:\n            net_para[key] = net_para[key] - curr_lr * (c_global_para[key] - c_local_para[key])\n        model.load_state_dict(net_para)\n\n        self.cnt += 1",
  "def terms_update(self, model, curr_lr, c_global_para, c_local_para, model_global):\n        # Update the local scaffold controls\n        # See https://github.com/Xtra-Computing/NIID-Bench/blob/main/experiments.py#L403\n\n        c_new_para = self.c_local.state_dict()\n        self.c_delta_para = copy.deepcopy(self.c_local.state_dict())\n        global_model_para = model_global.state_dict()\n        net_para = model.state_dict()\n        for key in net_para:\n            c_new_para[key] = (\n                c_new_para[key] - c_global_para[key] + (global_model_para[key] - net_para[key]) / (self.cnt * curr_lr)\n            )\n            self.c_delta_para[key] = (c_new_para[key] - c_local_para[key]).cpu().numpy()\n        self.c_local.load_state_dict(c_new_para)",
  "def load_global_controls(self, weights):\n        self.c_global.load_state_dict(weights)",
  "def get_delta_controls(self):\n        if self.c_delta_para is None:\n            raise ValueError(\"c_delta_para hasn't been computed yet!\")\n        return self.c_delta_para",
  "class PTDittoHelper(object):\n    def __init__(\n        self, criterion, model, optimizer, device, app_dir: str, ditto_lambda: float = 0.1, model_epochs: int = 1\n    ):\n        \"\"\"Helper to be used with Ditto components.\n        Implements the functions used for the algorithm proposed in\n        Li et al. \"Ditto: Fair and Robust Federated Learning Through Personalization\"\n        (https://arxiv.org/abs/2012.04221) using PyTorch.\n\n        Args:\n            criterion: base loss criterion\n            model: the personalized model of Ditto method\n            optimizer: training optimizer for personalized model\n            device: device for personalized model training\n            app_dir: needed for local personalized model saving\n            ditto_lambda: lambda weight for Ditto prox loss term when combining with the base loss, defaults to 0.1\n            model_epochs: training epoch for personalized model, defaults to 1\n\n        Returns:\n            None\n        \"\"\"\n\n        self.criterion = criterion\n        self.model = model\n        self.optimizer = optimizer\n        if device is None:\n            self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        else:\n            self.device = device\n        self.model_epochs = model_epochs\n        # initialize Ditto criterion\n        self.prox_criterion = PTFedProxLoss(mu=ditto_lambda)\n        # check criterion, model, and optimizer type\n        if not isinstance(self.criterion, torch.nn.modules.loss._Loss):\n            raise ValueError(f\"criterion component must be torch loss. \" f\"But got: {type(self.criterion)}\")\n        if not isinstance(self.model, torch.nn.Module):\n            raise ValueError(f\"model component must be torch model. \" f\"But got: {type(self.model)}\")\n        if not isinstance(self.optimizer, torch.optim.Optimizer):\n            raise ValueError(f\"optimizer component must be torch optimizer. \" f\"But got: {type(self.optimizer)}\")\n        if not isinstance(self.device, torch.device):\n            raise ValueError(f\"device component must be torch device. \" f\"But got: {type(self.device)}\")\n\n        # initialize other recording related parameters\n        self.epoch_global = 0\n        self.epoch_of_start_time = 0\n        self.best_metric: int = 0\n        self.model_file_path = os.path.join(app_dir, \"personalized_model.pt\")\n        self.best_model_file_path = os.path.join(app_dir, \"best_personalized_model.pt\")\n\n    def load_model(self, global_weights):\n        # load local model from last round's record if model exist,\n        # otherwise initialize from global model weights for the first round.\n        if os.path.exists(self.model_file_path):\n            model_data = torch.load(self.model_file_path)\n            self.model.load_state_dict(model_data[\"model\"])\n            self.epoch_of_start_time = model_data[\"epoch\"]\n        else:\n            self.model.load_state_dict(global_weights)\n            self.epoch_of_start_time = 0\n        if os.path.exists(self.best_model_file_path):\n            model_data = torch.load(self.best_model_file_path)\n            self.best_metric = model_data[\"best_metric\"]\n\n    def save_model(self, is_best=False):\n        # save personalized model locally\n        model_weights = self.model.state_dict()\n        save_dict = {\"model\": model_weights, \"epoch\": self.epoch_global}\n        if is_best:\n            save_dict.update({\"best_metric\": self.best_metric})\n            torch.save(save_dict, self.best_model_file_path)\n        else:\n            torch.save(save_dict, self.model_file_path)\n\n    def update_metric_save_model(self, metric):\n        self.save_model(is_best=False)\n        if metric > self.best_metric:\n            self.best_metric = metric\n            self.save_model(is_best=True)\n\n    @abstractmethod\n    def local_train(self, train_loader, model_global, abort_signal: Signal, writer):\n        # Train personal model for self.model_epochs, and keep track of curves\n        # This part is task dependent, need customization\n        # Basic idea is to train personalized model with prox term as compare to model_global\n        raise NotImplementedError",
  "def __init__(\n        self, criterion, model, optimizer, device, app_dir: str, ditto_lambda: float = 0.1, model_epochs: int = 1\n    ):\n        \"\"\"Helper to be used with Ditto components.\n        Implements the functions used for the algorithm proposed in\n        Li et al. \"Ditto: Fair and Robust Federated Learning Through Personalization\"\n        (https://arxiv.org/abs/2012.04221) using PyTorch.\n\n        Args:\n            criterion: base loss criterion\n            model: the personalized model of Ditto method\n            optimizer: training optimizer for personalized model\n            device: device for personalized model training\n            app_dir: needed for local personalized model saving\n            ditto_lambda: lambda weight for Ditto prox loss term when combining with the base loss, defaults to 0.1\n            model_epochs: training epoch for personalized model, defaults to 1\n\n        Returns:\n            None\n        \"\"\"\n\n        self.criterion = criterion\n        self.model = model\n        self.optimizer = optimizer\n        if device is None:\n            self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        else:\n            self.device = device\n        self.model_epochs = model_epochs\n        # initialize Ditto criterion\n        self.prox_criterion = PTFedProxLoss(mu=ditto_lambda)\n        # check criterion, model, and optimizer type\n        if not isinstance(self.criterion, torch.nn.modules.loss._Loss):\n            raise ValueError(f\"criterion component must be torch loss. \" f\"But got: {type(self.criterion)}\")\n        if not isinstance(self.model, torch.nn.Module):\n            raise ValueError(f\"model component must be torch model. \" f\"But got: {type(self.model)}\")\n        if not isinstance(self.optimizer, torch.optim.Optimizer):\n            raise ValueError(f\"optimizer component must be torch optimizer. \" f\"But got: {type(self.optimizer)}\")\n        if not isinstance(self.device, torch.device):\n            raise ValueError(f\"device component must be torch device. \" f\"But got: {type(self.device)}\")\n\n        # initialize other recording related parameters\n        self.epoch_global = 0\n        self.epoch_of_start_time = 0\n        self.best_metric: int = 0\n        self.model_file_path = os.path.join(app_dir, \"personalized_model.pt\")\n        self.best_model_file_path = os.path.join(app_dir, \"best_personalized_model.pt\")",
  "def load_model(self, global_weights):\n        # load local model from last round's record if model exist,\n        # otherwise initialize from global model weights for the first round.\n        if os.path.exists(self.model_file_path):\n            model_data = torch.load(self.model_file_path)\n            self.model.load_state_dict(model_data[\"model\"])\n            self.epoch_of_start_time = model_data[\"epoch\"]\n        else:\n            self.model.load_state_dict(global_weights)\n            self.epoch_of_start_time = 0\n        if os.path.exists(self.best_model_file_path):\n            model_data = torch.load(self.best_model_file_path)\n            self.best_metric = model_data[\"best_metric\"]",
  "def save_model(self, is_best=False):\n        # save personalized model locally\n        model_weights = self.model.state_dict()\n        save_dict = {\"model\": model_weights, \"epoch\": self.epoch_global}\n        if is_best:\n            save_dict.update({\"best_metric\": self.best_metric})\n            torch.save(save_dict, self.best_model_file_path)\n        else:\n            torch.save(save_dict, self.model_file_path)",
  "def update_metric_save_model(self, metric):\n        self.save_model(is_best=False)\n        if metric > self.best_metric:\n            self.best_metric = metric\n            self.save_model(is_best=True)",
  "def local_train(self, train_loader, model_global, abort_signal: Signal, writer):\n        # Train personal model for self.model_epochs, and keep track of curves\n        # This part is task dependent, need customization\n        # Basic idea is to train personalized model with prox term as compare to model_global\n        raise NotImplementedError",
  "def feed_vars(model: nn.Module, model_params):\n    \"\"\"Feed variable values from model_params to pytorch state_dict.\n\n    Args:\n        model (nn.Module): the local pytorch model\n        model_params: a ModelData message\n\n    Returns:\n        a list of params and a dictionary of vars to params\n    \"\"\"\n    _logger = logging.getLogger(\"AssignVariables\")\n    _logger.debug(\"AssignVariables...\")\n\n    to_assign = []\n    n_ext = len(model_params)\n    _logger.debug(f\"n_ext {n_ext}\")\n\n    local_var_dict = model.state_dict()\n    for var_name in local_var_dict:\n        try:\n            if var_name in tuple(model_params):\n                nd = model_params[var_name]\n                to_assign.append(nd)\n                local_var_dict[var_name] = torch.as_tensor(\n                    nd\n                )  # update local state dict TODO: enable setting of datatype\n        except Exception as e:\n            print(\"pt_feed_vars Exception:\", str(e))\n            raise RuntimeError(str(e))\n\n    _logger.debug(\"Updated local variables to be assigned.\")\n\n    n_assign = len(to_assign)\n    _logger.info(f\"Vars {n_ext} of {n_assign} assigned.\")\n    return to_assign, local_var_dict",
  "class PTModelPersistenceFormatManager(object):\n\n    PERSISTENCE_KEY_MODEL = \"model\"\n    PERSISTENCE_KEY_TRAIN_CONF = \"train_conf\"\n    PERSISTENCE_KEY_META_PROPS = \"meta_props\"\n\n    def __init__(self, data: dict, default_train_conf=None):\n        \"\"\"Manage the format for model persistence.\n\n        Args:\n            data (dict): either the dictionary mapping variables to values or a dict of dict.\n            default_train_conf (dict, optional): configuration for train. Defaults to None.\n\n        Raises:\n            TypeError: when data is not a dictionary\n        \"\"\"\n        if not isinstance(data, dict):\n            raise TypeError(\"data must be a dict but got {}\".format(type(data)))\n\n        self.var_dict = None\n        self.meta = None\n        self.train_conf = None\n        self.other_props = {}  # other props from the original data that need to be kept\n\n        if self.PERSISTENCE_KEY_MODEL not in data:\n            # this is a simple weight dict\n            self.var_dict = data\n        else:\n            # dict of dicts\n            self.var_dict = data[self.PERSISTENCE_KEY_MODEL]\n            self.meta = data.get(self.PERSISTENCE_KEY_META_PROPS, None)\n            self.train_conf = data.get(self.PERSISTENCE_KEY_TRAIN_CONF, None)\n\n            # we need to keep other props, if any, so they can be kept when persisted\n            for k, v in data.items():\n                if k not in [\n                    self.PERSISTENCE_KEY_MODEL,\n                    self.PERSISTENCE_KEY_META_PROPS,\n                    self.PERSISTENCE_KEY_TRAIN_CONF,\n                ]:\n                    self.other_props[k] = v\n\n        if not self.train_conf:\n            self.train_conf = default_train_conf\n\n    def _get_processed_vars(self) -> dict:\n        if self.meta:\n            return self.meta.get(MetaKey.PROCESSED_KEYS, {})\n        else:\n            return {}\n\n    def to_model_learnable(self, exclude_vars) -> ModelLearnable:\n        processed_vars = self._get_processed_vars()\n\n        weights = {}\n        for k, v in self.var_dict.items():\n            if exclude_vars and exclude_vars.search(k):\n                continue\n\n            is_processed = processed_vars.get(k, False)\n            if is_processed:\n                weights[k] = v\n            else:\n                weights[k] = v.cpu().numpy()\n\n        return make_model_learnable(weights, self.meta)\n\n    def to_persistence_dict(self) -> dict:\n        processed_vars = self._get_processed_vars()\n        weights_dict = OrderedDict()\n        for k, v in self.var_dict.items():\n            is_processed = processed_vars.get(k, False)\n            if is_processed:\n                weights_dict[k] = v\n            else:\n                weights_dict[k] = torch.as_tensor(v)\n\n        # always use complex format for saving\n        persistence_dict = OrderedDict()\n        persistence_dict[self.PERSISTENCE_KEY_MODEL] = weights_dict\n        if self.meta:\n            persistence_dict[self.PERSISTENCE_KEY_META_PROPS] = self.meta\n        if self.train_conf:\n            persistence_dict[self.PERSISTENCE_KEY_TRAIN_CONF] = self.train_conf\n        if self.other_props:\n            for k, v in self.other_props.items():\n                persistence_dict[k] = v\n        return persistence_dict\n\n    def update(self, ml: ModelLearnable):\n        \"\"\"Update the persistence data with the learned values.\n\n        Args:\n            ml (ModelLearnable): updated information to be merged into existing ModelLearnable\n        \"\"\"\n        err = validate_model_learnable(ml)\n        if err:\n            raise ValueError(err)\n        self.meta = ml.get(ModelLearnableKey.META, None)\n\n        # update with value of the model learnable\n        # note that the original weights that are not learned are still kept!\n        learned_weights = ml.get(ModelLearnableKey.WEIGHTS, {})\n        for k, v in learned_weights.items():\n            self.var_dict[k] = v\n\n    def get_persist_model_format(self):\n        return ModelFormat.PT_CHECKPOINT",
  "def __init__(self, data: dict, default_train_conf=None):\n        \"\"\"Manage the format for model persistence.\n\n        Args:\n            data (dict): either the dictionary mapping variables to values or a dict of dict.\n            default_train_conf (dict, optional): configuration for train. Defaults to None.\n\n        Raises:\n            TypeError: when data is not a dictionary\n        \"\"\"\n        if not isinstance(data, dict):\n            raise TypeError(\"data must be a dict but got {}\".format(type(data)))\n\n        self.var_dict = None\n        self.meta = None\n        self.train_conf = None\n        self.other_props = {}  # other props from the original data that need to be kept\n\n        if self.PERSISTENCE_KEY_MODEL not in data:\n            # this is a simple weight dict\n            self.var_dict = data\n        else:\n            # dict of dicts\n            self.var_dict = data[self.PERSISTENCE_KEY_MODEL]\n            self.meta = data.get(self.PERSISTENCE_KEY_META_PROPS, None)\n            self.train_conf = data.get(self.PERSISTENCE_KEY_TRAIN_CONF, None)\n\n            # we need to keep other props, if any, so they can be kept when persisted\n            for k, v in data.items():\n                if k not in [\n                    self.PERSISTENCE_KEY_MODEL,\n                    self.PERSISTENCE_KEY_META_PROPS,\n                    self.PERSISTENCE_KEY_TRAIN_CONF,\n                ]:\n                    self.other_props[k] = v\n\n        if not self.train_conf:\n            self.train_conf = default_train_conf",
  "def _get_processed_vars(self) -> dict:\n        if self.meta:\n            return self.meta.get(MetaKey.PROCESSED_KEYS, {})\n        else:\n            return {}",
  "def to_model_learnable(self, exclude_vars) -> ModelLearnable:\n        processed_vars = self._get_processed_vars()\n\n        weights = {}\n        for k, v in self.var_dict.items():\n            if exclude_vars and exclude_vars.search(k):\n                continue\n\n            is_processed = processed_vars.get(k, False)\n            if is_processed:\n                weights[k] = v\n            else:\n                weights[k] = v.cpu().numpy()\n\n        return make_model_learnable(weights, self.meta)",
  "def to_persistence_dict(self) -> dict:\n        processed_vars = self._get_processed_vars()\n        weights_dict = OrderedDict()\n        for k, v in self.var_dict.items():\n            is_processed = processed_vars.get(k, False)\n            if is_processed:\n                weights_dict[k] = v\n            else:\n                weights_dict[k] = torch.as_tensor(v)\n\n        # always use complex format for saving\n        persistence_dict = OrderedDict()\n        persistence_dict[self.PERSISTENCE_KEY_MODEL] = weights_dict\n        if self.meta:\n            persistence_dict[self.PERSISTENCE_KEY_META_PROPS] = self.meta\n        if self.train_conf:\n            persistence_dict[self.PERSISTENCE_KEY_TRAIN_CONF] = self.train_conf\n        if self.other_props:\n            for k, v in self.other_props.items():\n                persistence_dict[k] = v\n        return persistence_dict",
  "def update(self, ml: ModelLearnable):\n        \"\"\"Update the persistence data with the learned values.\n\n        Args:\n            ml (ModelLearnable): updated information to be merged into existing ModelLearnable\n        \"\"\"\n        err = validate_model_learnable(ml)\n        if err:\n            raise ValueError(err)\n        self.meta = ml.get(ModelLearnableKey.META, None)\n\n        # update with value of the model learnable\n        # note that the original weights that are not learned are still kept!\n        learned_weights = ml.get(ModelLearnableKey.WEIGHTS, {})\n        for k, v in learned_weights.items():\n            self.var_dict[k] = v",
  "def get_persist_model_format(self):\n        return ModelFormat.PT_CHECKPOINT",
  "class PTFileModelLocator(ModelLocator):\n    def __init__(self, pt_persistor_id: str):\n        \"\"\"The ModelLocator's job is to find and locate the models inventory saved during training.\n\n        Args:\n            pt_persistor_id (str): ModelPersistor component ID\n        \"\"\"\n        super().__init__()\n\n        self.pt_persistor_id = pt_persistor_id\n\n        self.model_persistor = None\n        self.model_inventory = {}\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self._initialize(fl_ctx)\n\n    def _initialize(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        self.model_persistor: PTFileModelPersistor = engine.get_component(self.pt_persistor_id)\n        if self.model_persistor is None or not isinstance(self.model_persistor, PTFileModelPersistor):\n            raise ValueError(\n                f\"pt_persistor_id component must be PTFileModelPersistor. \" f\"But got: {type(self.model_persistor)}\"\n            )\n\n    def get_model_names(self, fl_ctx: FLContext) -> List[str]:\n        \"\"\"Returns the list of model names that should be included from server in cross site validation.add().\n\n        Args:\n            fl_ctx (FLContext): FL Context object.\n\n        Returns:\n            List[str]: List of model names.\n        \"\"\"\n        self.model_inventory: dict = self.model_persistor.get_model_inventory(fl_ctx)\n        return list(self.model_inventory.keys())\n\n    def locate_model(self, model_name, fl_ctx: FLContext) -> DXO:\n        \"\"\"Call to locate and load the model weights of model_name.\n\n        Args:\n            model_name: name of the model\n            fl_ctx: FLContext\n\n        Returns: model_weight DXO\n\n        \"\"\"\n        if model_name not in list(self.model_inventory.keys()):\n            raise ValueError(f\"model inventory does not contain: {model_name}\")\n\n        model_learnable = self.model_persistor.get_model(model_name, fl_ctx)\n        dxo = model_learnable_to_dxo(model_learnable)\n\n        return dxo",
  "def __init__(self, pt_persistor_id: str):\n        \"\"\"The ModelLocator's job is to find and locate the models inventory saved during training.\n\n        Args:\n            pt_persistor_id (str): ModelPersistor component ID\n        \"\"\"\n        super().__init__()\n\n        self.pt_persistor_id = pt_persistor_id\n\n        self.model_persistor = None\n        self.model_inventory = {}",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self._initialize(fl_ctx)",
  "def _initialize(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        self.model_persistor: PTFileModelPersistor = engine.get_component(self.pt_persistor_id)\n        if self.model_persistor is None or not isinstance(self.model_persistor, PTFileModelPersistor):\n            raise ValueError(\n                f\"pt_persistor_id component must be PTFileModelPersistor. \" f\"But got: {type(self.model_persistor)}\"\n            )",
  "def get_model_names(self, fl_ctx: FLContext) -> List[str]:\n        \"\"\"Returns the list of model names that should be included from server in cross site validation.add().\n\n        Args:\n            fl_ctx (FLContext): FL Context object.\n\n        Returns:\n            List[str]: List of model names.\n        \"\"\"\n        self.model_inventory: dict = self.model_persistor.get_model_inventory(fl_ctx)\n        return list(self.model_inventory.keys())",
  "def locate_model(self, model_name, fl_ctx: FLContext) -> DXO:\n        \"\"\"Call to locate and load the model weights of model_name.\n\n        Args:\n            model_name: name of the model\n            fl_ctx: FLContext\n\n        Returns: model_weight DXO\n\n        \"\"\"\n        if model_name not in list(self.model_inventory.keys()):\n            raise ValueError(f\"model inventory does not contain: {model_name}\")\n\n        model_learnable = self.model_persistor.get_model(model_name, fl_ctx)\n        dxo = model_learnable_to_dxo(model_learnable)\n\n        return dxo",
  "class PTFedProxLoss(_Loss):\n    def __init__(self, mu: float = 0.01) -> None:\n        \"\"\"Compute FedProx loss: a loss penalizing the deviation from global model.\n\n        Args:\n            mu: weighting parameter\n        \"\"\"\n        super().__init__()\n        if mu < 0.0:\n            raise ValueError(\"mu should be no less than 0.0\")\n        self.mu = mu\n\n    def forward(self, input, target) -> torch.Tensor:\n        \"\"\"Forward pass in training.\n\n        Args:\n            input (nn.Module): the local pytorch model\n            target (nn.Module): the copy of global pytorch model when local clients received it\n                                at the beginning of each local round\n\n        Returns:\n            FedProx loss term\n        \"\"\"\n        prox_loss: torch.Tensor = 0.0\n        for param, ref in zip(input.named_parameters(), target.named_parameters()):\n            prox_loss += (self.mu / 2) * torch.sum((param[1] - ref[1]) ** 2)\n\n        return prox_loss",
  "def __init__(self, mu: float = 0.01) -> None:\n        \"\"\"Compute FedProx loss: a loss penalizing the deviation from global model.\n\n        Args:\n            mu: weighting parameter\n        \"\"\"\n        super().__init__()\n        if mu < 0.0:\n            raise ValueError(\"mu should be no less than 0.0\")\n        self.mu = mu",
  "def forward(self, input, target) -> torch.Tensor:\n        \"\"\"Forward pass in training.\n\n        Args:\n            input (nn.Module): the local pytorch model\n            target (nn.Module): the copy of global pytorch model when local clients received it\n                                at the beginning of each local round\n\n        Returns:\n            FedProx loss term\n        \"\"\"\n        prox_loss: torch.Tensor = 0.0\n        for param, ref in zip(input.named_parameters(), target.named_parameters()):\n            prox_loss += (self.mu / 2) * torch.sum((param[1] - ref[1]) ** 2)\n\n        return prox_loss",
  "class TBAnalyticsReceiver(AnalyticsReceiver):\n    def __init__(self, tb_folder=\"tb_events\", events: Optional[List[str]] = None):\n        \"\"\"Receives analytic data and saved as TensorBoard.\n\n        Folder structure::\n\n             inside run_XX folder\n            - workspace\n               - run_01 (already created):\n                   - output_dir (default: tb_events):\n                      - peer_name_1:\n                      - peer_name_2:\n\n               - run_02 (already created):\n                   - output_dir (default: tb_events):\n                      - peer_name_1:\n                      - peer_name_2:\n\n        Args:\n            tb_folder (str): the folder to store tensorboard files.\n            events (optional, List[str]): A list of events to be handled by this receiver.\n        \"\"\"\n        super().__init__(events=events)\n        self.writers_table = {}\n        self.tb_folder = tb_folder\n        self.root_log_dir = None\n\n    def initialize(self, fl_ctx: FLContext):\n        workspace = fl_ctx.get_engine().get_workspace()\n        run_dir = workspace.get_run_dir(fl_ctx.get_job_id())\n        root_log_dir = os.path.join(run_dir, self.tb_folder)\n        os.makedirs(root_log_dir, exist_ok=True)\n        self.root_log_dir = root_log_dir\n\n    def save(self, fl_ctx: FLContext, shareable: Shareable, record_origin):\n        dxo = from_shareable(shareable)\n        analytic_data = AnalyticsData.from_dxo(dxo)\n\n        writer = self.writers_table.get(record_origin)\n        if writer is None:\n            peer_log_dir = os.path.join(self.root_log_dir, record_origin)\n            writer = SummaryWriter(log_dir=peer_log_dir)\n            self.writers_table[record_origin] = writer\n\n        # depend on the type in dxo do different things\n        for k, v in dxo.data.items():\n            tag_name = f\"{k}\"\n            self.log_debug(\n                fl_ctx,\n                f\"save tag {tag_name} and value {v} with type {analytic_data.data_type} from {record_origin}\",\n                fire_event=False,\n            )\n            func_name = FUNCTION_MAPPING.get(analytic_data.data_type, None)\n            if func_name is None:\n                self.log_error(fl_ctx, f\"The data_type {analytic_data.data_type} is not supported.\", fire_event=False)\n                continue\n\n            func = getattr(writer, func_name)\n            if isinstance(analytic_data.kwargs, dict):\n                func(tag_name, v, **analytic_data.kwargs)\n            else:\n                func(tag_name, v)\n\n    def finalize(self, fl_ctx: FLContext):\n        for writer in self.writers_table.values():\n            writer.flush()\n            writer.close()",
  "def __init__(self, tb_folder=\"tb_events\", events: Optional[List[str]] = None):\n        \"\"\"Receives analytic data and saved as TensorBoard.\n\n        Folder structure::\n\n             inside run_XX folder\n            - workspace\n               - run_01 (already created):\n                   - output_dir (default: tb_events):\n                      - peer_name_1:\n                      - peer_name_2:\n\n               - run_02 (already created):\n                   - output_dir (default: tb_events):\n                      - peer_name_1:\n                      - peer_name_2:\n\n        Args:\n            tb_folder (str): the folder to store tensorboard files.\n            events (optional, List[str]): A list of events to be handled by this receiver.\n        \"\"\"\n        super().__init__(events=events)\n        self.writers_table = {}\n        self.tb_folder = tb_folder\n        self.root_log_dir = None",
  "def initialize(self, fl_ctx: FLContext):\n        workspace = fl_ctx.get_engine().get_workspace()\n        run_dir = workspace.get_run_dir(fl_ctx.get_job_id())\n        root_log_dir = os.path.join(run_dir, self.tb_folder)\n        os.makedirs(root_log_dir, exist_ok=True)\n        self.root_log_dir = root_log_dir",
  "def save(self, fl_ctx: FLContext, shareable: Shareable, record_origin):\n        dxo = from_shareable(shareable)\n        analytic_data = AnalyticsData.from_dxo(dxo)\n\n        writer = self.writers_table.get(record_origin)\n        if writer is None:\n            peer_log_dir = os.path.join(self.root_log_dir, record_origin)\n            writer = SummaryWriter(log_dir=peer_log_dir)\n            self.writers_table[record_origin] = writer\n\n        # depend on the type in dxo do different things\n        for k, v in dxo.data.items():\n            tag_name = f\"{k}\"\n            self.log_debug(\n                fl_ctx,\n                f\"save tag {tag_name} and value {v} with type {analytic_data.data_type} from {record_origin}\",\n                fire_event=False,\n            )\n            func_name = FUNCTION_MAPPING.get(analytic_data.data_type, None)\n            if func_name is None:\n                self.log_error(fl_ctx, f\"The data_type {analytic_data.data_type} is not supported.\", fire_event=False)\n                continue\n\n            func = getattr(writer, func_name)\n            if isinstance(analytic_data.kwargs, dict):\n                func(tag_name, v, **analytic_data.kwargs)\n            else:\n                func(tag_name, v)",
  "def finalize(self, fl_ctx: FLContext):\n        for writer in self.writers_table.values():\n            writer.flush()\n            writer.close()",
  "class DefaultJobScheduler(JobSchedulerSpec, FLComponent):\n    def __init__(\n        self,\n        max_jobs: int = 1,\n    ):\n        super().__init__()\n        self.max_jobs = max_jobs\n        self.scheduled_jobs = []\n        self.lock = threading.Lock()\n\n    def _check_client_resources(self, resource_reqs: Dict[str, dict], fl_ctx: FLContext) -> Dict[str, Tuple[bool, str]]:\n        \"\"\"Checks resources on each site.\n\n        Args:\n            resource_reqs (dict): {client_name: resource_requirements}\n\n        Returns:\n            A dict of {client_name: client_check_result}\n            where client_check_result is a tuple of {client check OK, resource reserve token if any}\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ServerEngineSpec):\n            raise RuntimeError(f\"engine inside fl_ctx should be of type ServerEngineSpec, but got {type(engine)}.\")\n\n        result = engine.check_client_resources(resource_reqs)\n        self.log_debug(fl_ctx, f\"check client resources result: {result}\")\n\n        return result\n\n    def _cancel_resources(\n        self, resource_reqs: Dict[str, dict], resource_check_results: Dict[str, Tuple[bool, str]], fl_ctx: FLContext\n    ):\n        \"\"\"Cancels any reserved resources based on resource check results.\n\n        Args:\n            resource_reqs (dict): {client_name: resource_requirements}\n            resource_check_results: A dict of {client_name: client_check_result}\n                where client_check_result is a tuple of {client check OK, resource reserve token if any}\n            fl_ctx: FL context\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ServerEngineSpec):\n            raise RuntimeError(f\"engine inside fl_ctx should be of type ServerEngineSpec, but got {type(engine)}.\")\n\n        engine.cancel_client_resources(resource_check_results, resource_reqs)\n        self.log_debug(fl_ctx, f\"cancel client resources using check results: {resource_check_results}\")\n        return False, None\n\n    def _try_job(self, job: Job, fl_ctx) -> (bool, Optional[Dict[str, DispatchInfo]]):\n        engine = fl_ctx.get_engine()\n        online_clients = engine.get_clients()\n        online_site_names = [x.name for x in online_clients]\n\n        if not job.deploy_map:\n            raise RuntimeError(f\"Job ({job.job_id}) does not have deploy_map, can't be scheduled.\")\n\n        applicable_sites = []\n        sites_to_app = {}\n        for app_name in job.deploy_map:\n            for site_name in job.deploy_map[app_name]:\n                if site_name.upper() == ALL_SITES:\n                    # deploy_map: {\"app_name\": [\"ALL_SITES\"]} will be treated as deploying to all online clients\n                    applicable_sites = online_site_names\n                    sites_to_app = {x: app_name for x in online_site_names}\n                    sites_to_app[SERVER_SITE_NAME] = app_name\n                elif site_name in online_site_names:\n                    applicable_sites.append(site_name)\n                    sites_to_app[site_name] = app_name\n                elif site_name == SERVER_SITE_NAME:\n                    sites_to_app[SERVER_SITE_NAME] = app_name\n        self.log_debug(fl_ctx, f\"Job {job.job_id} is checking against applicable sites: {applicable_sites}\")\n\n        required_sites = job.required_sites if job.required_sites else []\n        if required_sites:\n            for s in required_sites:\n                if s not in applicable_sites:\n                    self.log_debug(fl_ctx, f\"Job {job.job_id} can't be scheduled: required site {s} is not connected.\")\n                    return False, None\n\n        if job.min_sites and len(applicable_sites) < job.min_sites:\n            self.log_debug(\n                fl_ctx,\n                f\"Job {job.job_id} can't be scheduled: connected sites ({len(applicable_sites)}) \"\n                f\"are less than min_sites ({job.min_sites}).\",\n            )\n            return False, None\n\n        # we are assuming server resource is sufficient\n        resource_reqs = {}\n        for site_name in applicable_sites:\n            if site_name in job.resource_spec:\n                resource_reqs[site_name] = job.resource_spec[site_name]\n            else:\n                resource_reqs[site_name] = {}\n        resource_check_results = self._check_client_resources(resource_reqs=resource_reqs, fl_ctx=fl_ctx)\n\n        if not resource_check_results:\n            self.log_debug(fl_ctx, f\"Job {job.job_id} can't be scheduled: resource check results is None or empty.\")\n            return False, None\n\n        required_sites_not_enough_resource = list(required_sites)\n        num_sites_ok = 0\n        sites_dispatch_info = {}\n        for site_name, check_result in resource_check_results.items():\n            if check_result[0]:\n                sites_dispatch_info[site_name] = DispatchInfo(\n                    app_name=sites_to_app[site_name],\n                    resource_requirements=resource_reqs[site_name],\n                    token=check_result[1],\n                )\n                num_sites_ok += 1\n                if site_name in required_sites:\n                    required_sites_not_enough_resource.remove(site_name)\n\n        if num_sites_ok < job.min_sites:\n            self.log_debug(fl_ctx, f\"Job {job.job_id} can't be scheduled: not enough sites have enough resources.\")\n            return self._cancel_resources(\n                resource_reqs=job.resource_spec, resource_check_results=resource_check_results, fl_ctx=fl_ctx\n            )\n\n        if required_sites_not_enough_resource:\n            self.log_debug(\n                fl_ctx,\n                f\"Job {job.job_id} can't be scheduled: required sites: {required_sites_not_enough_resource}\"\n                f\" don't have enough resources.\",\n            )\n            return self._cancel_resources(\n                resource_reqs=job.resource_spec, resource_check_results=resource_check_results, fl_ctx=fl_ctx\n            )\n\n        # add server dispatch info\n        sites_dispatch_info[SERVER_SITE_NAME] = DispatchInfo(\n            app_name=sites_to_app[SERVER_SITE_NAME], resource_requirements={}, token=None\n        )\n\n        return True, sites_dispatch_info\n\n    def _exceed_max_jobs(self, fl_ctx: FLContext) -> bool:\n        exceed_limit = False\n        with self.lock:\n            if len(self.scheduled_jobs) >= self.max_jobs:\n                self.log_debug(\n                    fl_ctx,\n                    f\"Skipping schedule job because scheduled_jobs ({len(self.scheduled_jobs)}) \"\n                    f\"is greater than max_jobs ({self.max_jobs})\",\n                )\n                exceed_limit = True\n        return exceed_limit\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.JOB_STARTED:\n            with self.lock:\n                job_id = fl_ctx.get_prop(FLContextKey.CURRENT_JOB_ID)\n                if job_id not in self.scheduled_jobs:\n                    self.scheduled_jobs.append(job_id)\n        elif event_type == EventType.JOB_COMPLETED or event_type == EventType.JOB_ABORTED:\n            with self.lock:\n                job_id = fl_ctx.get_prop(FLContextKey.CURRENT_JOB_ID)\n                if job_id in self.scheduled_jobs:\n                    self.scheduled_jobs.remove(job_id)\n\n    def schedule_job(\n        self, job_candidates: List[Job], fl_ctx: FLContext\n    ) -> (Optional[Job], Optional[Dict[str, DispatchInfo]]):\n        self.log_debug(fl_ctx, f\"Current scheduled_jobs is {self.scheduled_jobs}\")\n        if self._exceed_max_jobs(fl_ctx=fl_ctx):\n            return None, None\n\n        # sort by submitted time\n        job_candidates.sort(key=lambda j: j.meta.get(JobMetaKey.SUBMIT_TIME, 0.0))\n\n        for job in job_candidates:\n            ok, sites_dispatch_info = self._try_job(job, fl_ctx)\n            self.log_debug(fl_ctx, f\"Try to schedule job {job.job_id}, get result: {ok}, {sites_dispatch_info}.\")\n            if ok:\n                return job, sites_dispatch_info\n        self.log_debug(fl_ctx, \"No job is scheduled.\")\n        return None, None",
  "def __init__(\n        self,\n        max_jobs: int = 1,\n    ):\n        super().__init__()\n        self.max_jobs = max_jobs\n        self.scheduled_jobs = []\n        self.lock = threading.Lock()",
  "def _check_client_resources(self, resource_reqs: Dict[str, dict], fl_ctx: FLContext) -> Dict[str, Tuple[bool, str]]:\n        \"\"\"Checks resources on each site.\n\n        Args:\n            resource_reqs (dict): {client_name: resource_requirements}\n\n        Returns:\n            A dict of {client_name: client_check_result}\n            where client_check_result is a tuple of {client check OK, resource reserve token if any}\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ServerEngineSpec):\n            raise RuntimeError(f\"engine inside fl_ctx should be of type ServerEngineSpec, but got {type(engine)}.\")\n\n        result = engine.check_client_resources(resource_reqs)\n        self.log_debug(fl_ctx, f\"check client resources result: {result}\")\n\n        return result",
  "def _cancel_resources(\n        self, resource_reqs: Dict[str, dict], resource_check_results: Dict[str, Tuple[bool, str]], fl_ctx: FLContext\n    ):\n        \"\"\"Cancels any reserved resources based on resource check results.\n\n        Args:\n            resource_reqs (dict): {client_name: resource_requirements}\n            resource_check_results: A dict of {client_name: client_check_result}\n                where client_check_result is a tuple of {client check OK, resource reserve token if any}\n            fl_ctx: FL context\n        \"\"\"\n        engine = fl_ctx.get_engine()\n        if not isinstance(engine, ServerEngineSpec):\n            raise RuntimeError(f\"engine inside fl_ctx should be of type ServerEngineSpec, but got {type(engine)}.\")\n\n        engine.cancel_client_resources(resource_check_results, resource_reqs)\n        self.log_debug(fl_ctx, f\"cancel client resources using check results: {resource_check_results}\")\n        return False, None",
  "def _try_job(self, job: Job, fl_ctx) -> (bool, Optional[Dict[str, DispatchInfo]]):\n        engine = fl_ctx.get_engine()\n        online_clients = engine.get_clients()\n        online_site_names = [x.name for x in online_clients]\n\n        if not job.deploy_map:\n            raise RuntimeError(f\"Job ({job.job_id}) does not have deploy_map, can't be scheduled.\")\n\n        applicable_sites = []\n        sites_to_app = {}\n        for app_name in job.deploy_map:\n            for site_name in job.deploy_map[app_name]:\n                if site_name.upper() == ALL_SITES:\n                    # deploy_map: {\"app_name\": [\"ALL_SITES\"]} will be treated as deploying to all online clients\n                    applicable_sites = online_site_names\n                    sites_to_app = {x: app_name for x in online_site_names}\n                    sites_to_app[SERVER_SITE_NAME] = app_name\n                elif site_name in online_site_names:\n                    applicable_sites.append(site_name)\n                    sites_to_app[site_name] = app_name\n                elif site_name == SERVER_SITE_NAME:\n                    sites_to_app[SERVER_SITE_NAME] = app_name\n        self.log_debug(fl_ctx, f\"Job {job.job_id} is checking against applicable sites: {applicable_sites}\")\n\n        required_sites = job.required_sites if job.required_sites else []\n        if required_sites:\n            for s in required_sites:\n                if s not in applicable_sites:\n                    self.log_debug(fl_ctx, f\"Job {job.job_id} can't be scheduled: required site {s} is not connected.\")\n                    return False, None\n\n        if job.min_sites and len(applicable_sites) < job.min_sites:\n            self.log_debug(\n                fl_ctx,\n                f\"Job {job.job_id} can't be scheduled: connected sites ({len(applicable_sites)}) \"\n                f\"are less than min_sites ({job.min_sites}).\",\n            )\n            return False, None\n\n        # we are assuming server resource is sufficient\n        resource_reqs = {}\n        for site_name in applicable_sites:\n            if site_name in job.resource_spec:\n                resource_reqs[site_name] = job.resource_spec[site_name]\n            else:\n                resource_reqs[site_name] = {}\n        resource_check_results = self._check_client_resources(resource_reqs=resource_reqs, fl_ctx=fl_ctx)\n\n        if not resource_check_results:\n            self.log_debug(fl_ctx, f\"Job {job.job_id} can't be scheduled: resource check results is None or empty.\")\n            return False, None\n\n        required_sites_not_enough_resource = list(required_sites)\n        num_sites_ok = 0\n        sites_dispatch_info = {}\n        for site_name, check_result in resource_check_results.items():\n            if check_result[0]:\n                sites_dispatch_info[site_name] = DispatchInfo(\n                    app_name=sites_to_app[site_name],\n                    resource_requirements=resource_reqs[site_name],\n                    token=check_result[1],\n                )\n                num_sites_ok += 1\n                if site_name in required_sites:\n                    required_sites_not_enough_resource.remove(site_name)\n\n        if num_sites_ok < job.min_sites:\n            self.log_debug(fl_ctx, f\"Job {job.job_id} can't be scheduled: not enough sites have enough resources.\")\n            return self._cancel_resources(\n                resource_reqs=job.resource_spec, resource_check_results=resource_check_results, fl_ctx=fl_ctx\n            )\n\n        if required_sites_not_enough_resource:\n            self.log_debug(\n                fl_ctx,\n                f\"Job {job.job_id} can't be scheduled: required sites: {required_sites_not_enough_resource}\"\n                f\" don't have enough resources.\",\n            )\n            return self._cancel_resources(\n                resource_reqs=job.resource_spec, resource_check_results=resource_check_results, fl_ctx=fl_ctx\n            )\n\n        # add server dispatch info\n        sites_dispatch_info[SERVER_SITE_NAME] = DispatchInfo(\n            app_name=sites_to_app[SERVER_SITE_NAME], resource_requirements={}, token=None\n        )\n\n        return True, sites_dispatch_info",
  "def _exceed_max_jobs(self, fl_ctx: FLContext) -> bool:\n        exceed_limit = False\n        with self.lock:\n            if len(self.scheduled_jobs) >= self.max_jobs:\n                self.log_debug(\n                    fl_ctx,\n                    f\"Skipping schedule job because scheduled_jobs ({len(self.scheduled_jobs)}) \"\n                    f\"is greater than max_jobs ({self.max_jobs})\",\n                )\n                exceed_limit = True\n        return exceed_limit",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.JOB_STARTED:\n            with self.lock:\n                job_id = fl_ctx.get_prop(FLContextKey.CURRENT_JOB_ID)\n                if job_id not in self.scheduled_jobs:\n                    self.scheduled_jobs.append(job_id)\n        elif event_type == EventType.JOB_COMPLETED or event_type == EventType.JOB_ABORTED:\n            with self.lock:\n                job_id = fl_ctx.get_prop(FLContextKey.CURRENT_JOB_ID)\n                if job_id in self.scheduled_jobs:\n                    self.scheduled_jobs.remove(job_id)",
  "def schedule_job(\n        self, job_candidates: List[Job], fl_ctx: FLContext\n    ) -> (Optional[Job], Optional[Dict[str, DispatchInfo]]):\n        self.log_debug(fl_ctx, f\"Current scheduled_jobs is {self.scheduled_jobs}\")\n        if self._exceed_max_jobs(fl_ctx=fl_ctx):\n            return None, None\n\n        # sort by submitted time\n        job_candidates.sort(key=lambda j: j.meta.get(JobMetaKey.SUBMIT_TIME, 0.0))\n\n        for job in job_candidates:\n            ok, sites_dispatch_info = self._try_job(job, fl_ctx)\n            self.log_debug(fl_ctx, f\"Try to schedule job {job.job_id}, get result: {ok}, {sites_dispatch_info}.\")\n            if ok:\n                return job, sites_dispatch_info\n        self.log_debug(fl_ctx, \"No job is scheduled.\")\n        return None, None",
  "class StorageStatePersistor(StatePersistor):\n    def __init__(self, storage: StorageSpec, uri_root: str):\n        \"\"\"Creates a StorageStatePersistor.\n\n        Args:\n            storage: StorageSpec object\n            uri_root: where to store the states.\n        \"\"\"\n\n        self.storage = storage\n        self.uri_root = uri_root\n\n    def save(self, snapshot: RunSnapshot) -> str:\n        \"\"\"Call to save the snapshot of the FL state to storage.\n\n        Args:\n            snapshot: RunSnapshot object\n\n        Returns:\n            storage location\n        \"\"\"\n        path = os.path.join(self.uri_root, snapshot.job_id)\n        if snapshot.completed:\n            full_uri = self.storage.delete_object(path)\n        else:\n            full_uri = self.storage.create_object(\n                uri=path, data=pickle.dumps(snapshot), meta={}, overwrite_existing=True\n            )\n\n        return full_uri\n\n    def retrieve(self) -> FLSnapshot:\n        \"\"\"Call to load the persisted FL components snapshot from the persisted location.\n\n        Returns:\n            retrieved Snapshot\n        \"\"\"\n        all_items = self.storage.list_objects(self.uri_root)\n        fl_snapshot = FLSnapshot()\n        for item in all_items:\n            snapshot = pickle.loads(self.storage.get_data(item))\n            fl_snapshot.add_snapshot(snapshot.job_id, snapshot)\n        return fl_snapshot\n\n    def retrieve_run(self, job_id: str) -> RunSnapshot:\n        \"\"\"Call to load the persisted RunSnapshot of a job from the persisted location.\n\n        Args:\n            job_id: job_id\n\n        Returns:\n            RunSnapshot of the job_id\n\n        \"\"\"\n        path = os.path.join(self.uri_root, job_id)\n        snapshot = pickle.loads(self.storage.get_data(uri=path))\n        return snapshot\n\n    def delete(self):\n        \"\"\"Deletes the FL snapshot.\"\"\"\n\n        all_items = self.storage.list_objects(self.uri_root)\n        for item in all_items:\n            self.storage.delete_object(item)\n\n    def delete_run(self, job_id: str):\n        \"\"\"Deletes the RunSnapshot of a job.\n\n        Args:\n            job_id: job_id\n        \"\"\"\n        path = os.path.join(self.uri_root, job_id)\n        self.storage.delete_object(path)",
  "def __init__(self, storage: StorageSpec, uri_root: str):\n        \"\"\"Creates a StorageStatePersistor.\n\n        Args:\n            storage: StorageSpec object\n            uri_root: where to store the states.\n        \"\"\"\n\n        self.storage = storage\n        self.uri_root = uri_root",
  "def save(self, snapshot: RunSnapshot) -> str:\n        \"\"\"Call to save the snapshot of the FL state to storage.\n\n        Args:\n            snapshot: RunSnapshot object\n\n        Returns:\n            storage location\n        \"\"\"\n        path = os.path.join(self.uri_root, snapshot.job_id)\n        if snapshot.completed:\n            full_uri = self.storage.delete_object(path)\n        else:\n            full_uri = self.storage.create_object(\n                uri=path, data=pickle.dumps(snapshot), meta={}, overwrite_existing=True\n            )\n\n        return full_uri",
  "def retrieve(self) -> FLSnapshot:\n        \"\"\"Call to load the persisted FL components snapshot from the persisted location.\n\n        Returns:\n            retrieved Snapshot\n        \"\"\"\n        all_items = self.storage.list_objects(self.uri_root)\n        fl_snapshot = FLSnapshot()\n        for item in all_items:\n            snapshot = pickle.loads(self.storage.get_data(item))\n            fl_snapshot.add_snapshot(snapshot.job_id, snapshot)\n        return fl_snapshot",
  "def retrieve_run(self, job_id: str) -> RunSnapshot:\n        \"\"\"Call to load the persisted RunSnapshot of a job from the persisted location.\n\n        Args:\n            job_id: job_id\n\n        Returns:\n            RunSnapshot of the job_id\n\n        \"\"\"\n        path = os.path.join(self.uri_root, job_id)\n        snapshot = pickle.loads(self.storage.get_data(uri=path))\n        return snapshot",
  "def delete(self):\n        \"\"\"Deletes the FL snapshot.\"\"\"\n\n        all_items = self.storage.list_objects(self.uri_root)\n        for item in all_items:\n            self.storage.delete_object(item)",
  "def delete_run(self, job_id: str):\n        \"\"\"Deletes the RunSnapshot of a job.\n\n        Args:\n            job_id: job_id\n        \"\"\"\n        path = os.path.join(self.uri_root, job_id)\n        self.storage.delete_object(path)",
  "class GPUResourceConsumer(ResourceConsumerSpec):\n    def __init__(self, gpu_resource_key=\"gpu\"):\n        super().__init__()\n        self.gpu_resource_key = gpu_resource_key\n        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n\n    def consume(self, resources: dict):\n        gpu_numbers = []\n        if self.gpu_resource_key in resources:\n            gpu_numbers = [str(x) for x in resources[self.gpu_resource_key]]\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(gpu_numbers)",
  "def __init__(self, gpu_resource_key=\"gpu\"):\n        super().__init__()\n        self.gpu_resource_key = gpu_resource_key\n        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"",
  "def consume(self, resources: dict):\n        gpu_numbers = []\n        if self.gpu_resource_key in resources:\n            gpu_numbers = [str(x) for x in resources[self.gpu_resource_key]]\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(gpu_numbers)",
  "class HEInTimeAccumulateWeightedAggregator(Aggregator):\n    def __init__(\n        self,\n        exclude_vars=None,\n        aggregation_weights=None,\n        tenseal_context_file=\"server_context.tenseal\",\n        weigh_by_local_iter=False,\n        expected_data_kind=\"WEIGHT_DIFF\",\n        expected_algorithm=he.HE_ALGORITHM_CKKS,\n    ):\n        \"\"\"In time aggregator for `Shareables` encrypted using homomorphic encryption (HE) with TenSEAL https://github.com/OpenMined/TenSEAL.\n\n        Args:\n            exclude_vars ([list], optional): variable names that should be excluded from aggregation (use regular expression). Defaults to None.\n            aggregation_weights ([dict], optional): dictionary of client aggregation. Defaults to None.\n            tenseal_context_file (str, optional): [description]. Defaults to \"server_context.tenseal\".\n            weigh_by_local_iter (bool, optional): If true, multiply client weights on first in encryption space\n                                 (default: `False` which is recommended for HE, first multiply happens in `HEModelEncryptor`)].\n            expected_data_kind (str, optional): the data_kind this aggregator can process. Defaults to \"WEIGHT_DIFF\".\n            expected_algorithm ([str], optional): the HE algorithm it can process. Defaults to he.HE_ALGORITHM_CKKS.\n\n        Raises:\n            ValueError: mismatched data_kind or HE algorithm\n        \"\"\"\n        super().__init__()\n        self.tenseal_context = None\n        self.tenseal_context_file = tenseal_context_file\n        if expected_data_kind not in [DataKind.WEIGHT_DIFF, DataKind.WEIGHTS]:\n            raise ValueError(f\"expected_data_kind={expected_data_kind} not in WEIGHT_DIFF or WEIGHTS\")\n        self.expected_data_kind = expected_data_kind\n        self.expected_algorithm = expected_algorithm\n        if self.expected_algorithm != he.HE_ALGORITHM_CKKS:\n            raise ValueError(f\"expected algorithm {self.expected_algorithm} not supported\")\n        self.exclude_vars = re.compile(exclude_vars) if exclude_vars else None\n        self.aggregation_weights = aggregation_weights or {}\n        self.reset_stats()\n        self.weigh_by_local_iter = weigh_by_local_iter\n        self.logger.info(f\"client weights control: {self.aggregation_weights}\")\n        if not self.weigh_by_local_iter:\n            if self.aggregation_weights:\n                self.logger.warning(\"aggregation_weights will be ignored if weigh_by_local_iter=False\")\n            self.logger.info(\"Only divide by sum of local (weighted) iterations.\")\n        self.warning_count = dict()\n        self.warning_limit = 0\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.tenseal_context = load_tenseal_context_from_workspace(self.tenseal_context_file, fl_ctx)\n        elif event_type == EventType.END_RUN:\n            self.tenseal_context = None\n\n    def reset_stats(self):\n        self.total = dict()\n        self.counts = dict()\n        self.contribution_count = 0\n        self.history = list()\n        self.merged_encrypted_layers = dict()  # thread-safety is handled by workflow\n\n    def accept(self, shareable: Shareable, fl_ctx: FLContext) -> bool:\n        \"\"\"Accepts and adds the client updates to current average in HE encrypted space.\n\n        Args:\n            shareable: a shareable from client\n            fl_ctx: FL Contenxt associated with this shareable\n\n        Returns:\n            bool to indicate if this shareable is accepted.\n        \"\"\"\n        dxo = from_shareable(shareable)\n        if dxo.data_kind != self.expected_data_kind:\n            self.log_error(\n                fl_ctx,\n                f\"expected {self.expected_data_kind} type DXO only but received {dxo.data_kind}, skipping this shareable.\",\n            )\n            return False\n\n        enc_algo = dxo.get_meta_prop(key=MetaKey.PROCESSED_ALGORITHM, default=None)\n        if enc_algo != self.expected_algorithm:\n            self.log_error(fl_ctx, \"unsupported encryption algorithm {enc_algo}\")\n            return False\n\n        current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n        client_name = shareable.get_peer_prop(ReservedKey.IDENTITY_NAME, \"?\")\n        contribution_round = shareable.get_header(AppConstants.CONTRIBUTION_ROUND)\n\n        rc = shareable.get_return_code()\n        if rc and rc != ReturnCode.OK:\n            self.log_debug(fl_ctx, f\"Client {client_name} returned rc: {rc}. Disregarding contribution.\")\n            return False\n\n        self.log_debug(fl_ctx, f\"current_round: {current_round}\")\n\n        if contribution_round != current_round:\n            self.log_debug(\n                fl_ctx,\n                \"Discarded the contribution from {client_name} for round: {contribution_round}. Current round is: {current_round}\",\n            )\n            return False\n\n        start_time = time.time()\n\n        for item in self.history:\n            if client_name == item[\"client_name\"]:\n                prev_round = item[\"round\"]\n                self.log_info(\n                    fl_ctx,\n                    f\"discarding shareable from {client_name} at round: {contribution_round} as {prev_round} accepted already\",\n                )\n                return False\n\n        self.log_info(fl_ctx, f\"Adding contribution from {client_name}.\")\n\n        n_iter = dxo.get_meta_prop(key=MetaKey.NUM_STEPS_CURRENT_ROUND)\n        if n_iter is None:\n            if self.warning_count.get(client_name, 0) <= self.warning_limit:\n                self.log_warning(\n                    fl_ctx,\n                    f\"NUM_STEPS_CURRENT_ROUND missing\"\n                    f\" from {client_name} and set to default value, 1.0. \"\n                    f\" This kind of message will show {self.warning_limit} times at most.\",\n                )\n                if client_name in self.warning_count:\n                    self.warning_count[client_name] = self.warning_count[client_name] + 1\n                else:\n                    self.warning_count[client_name] = 0\n            n_iter = 1.0\n        float_n_iter = np.float(n_iter)\n\n        aggregation_weight = self.aggregation_weights.get(client_name)\n        if aggregation_weight is None:\n            aggregation_weight = 1.0\n\n        aggr_data = dxo.data\n        encrypted_layers = dxo.get_meta_prop(MetaKey.PROCESSED_KEYS)\n        # TODO: test support of different encrypted layers for different clients!\n\n        if encrypted_layers is None:\n            self.log_error(fl_ctx, \"encrypted_layers is None!\")\n            return False\n\n        for k, v in aggr_data.items():\n            if self.exclude_vars is not None and self.exclude_vars.search(k):\n                continue\n            if encrypted_layers[k]:\n                if self.weigh_by_local_iter:\n                    weighted_value = ts.ckks_vector_from(self.tenseal_context, v) * (aggregation_weight * float_n_iter)\n                else:\n                    weighted_value = ts.ckks_vector_from(self.tenseal_context, v)\n                self.merged_encrypted_layers[k] = True  # any client can set this true\n            else:\n                if self.weigh_by_local_iter:\n                    weighted_value = v * (aggregation_weight * float_n_iter)\n                else:\n                    weighted_value = v\n                if k not in self.merged_encrypted_layers:\n                    self.merged_encrypted_layers[k] = False  # only set False if no other client set it to True\n            current_total = self.total.get(k, None)\n            if current_total is None:\n                self.total[k] = weighted_value\n                self.counts[k] = n_iter\n            else:\n                self.total[k] = current_total + weighted_value\n                self.counts[k] = self.counts[k] + n_iter\n\n        self.contribution_count += 1\n\n        end_time = time.time()\n        n_encrypted, n_total = count_encrypted_layers(self.merged_encrypted_layers)\n        self.log_info(fl_ctx, f\"{n_encrypted} of {n_total} layers encrypted\")\n        self.log_info(fl_ctx, f\"Round {current_round} adding {client_name} time is {end_time - start_time} seconds\")\n\n        self.history.append(\n            {\n                \"client_name\": client_name,\n                \"round\": contribution_round,\n                \"aggregation_weight\": aggregation_weight,\n                \"n_iter\": n_iter,\n            }\n        )\n        return True\n\n    def aggregate(self, fl_ctx: FLContext) -> Shareable:\n        start_time = time.time()\n        current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n\n        aggregated_dict = dict()\n        for k, v in self.total.items():\n            aggregated_dict[k] = v * (1.0 / self.counts[k])\n        end_time = time.time()\n        self.log_info(\n            fl_ctx,\n            f\"Aggregated {self.contribution_count} contributions for round {current_round} time is {end_time - start_time} seconds\",\n        )\n\n        dxo = DXO(data_kind=self.expected_data_kind, data=aggregated_dict)\n        dxo.set_meta_prop(MetaKey.PROCESSED_KEYS, self.merged_encrypted_layers)\n        dxo.set_meta_prop(MetaKey.PROCESSED_ALGORITHM, self.expected_algorithm)\n        n_encrypted, n_total = count_encrypted_layers(self.merged_encrypted_layers)\n        self.log_info(fl_ctx, f\"{n_encrypted} of {n_total} layers encrypted\")\n\n        fl_ctx.set_prop(AppConstants.DXO, dxo, private=True, sticky=False)\n\n        self.reset_stats()  # only reset dictionary after adding merged_encrypted_layers to dictionary\n        return dxo.to_shareable()",
  "def __init__(\n        self,\n        exclude_vars=None,\n        aggregation_weights=None,\n        tenseal_context_file=\"server_context.tenseal\",\n        weigh_by_local_iter=False,\n        expected_data_kind=\"WEIGHT_DIFF\",\n        expected_algorithm=he.HE_ALGORITHM_CKKS,\n    ):\n        \"\"\"In time aggregator for `Shareables` encrypted using homomorphic encryption (HE) with TenSEAL https://github.com/OpenMined/TenSEAL.\n\n        Args:\n            exclude_vars ([list], optional): variable names that should be excluded from aggregation (use regular expression). Defaults to None.\n            aggregation_weights ([dict], optional): dictionary of client aggregation. Defaults to None.\n            tenseal_context_file (str, optional): [description]. Defaults to \"server_context.tenseal\".\n            weigh_by_local_iter (bool, optional): If true, multiply client weights on first in encryption space\n                                 (default: `False` which is recommended for HE, first multiply happens in `HEModelEncryptor`)].\n            expected_data_kind (str, optional): the data_kind this aggregator can process. Defaults to \"WEIGHT_DIFF\".\n            expected_algorithm ([str], optional): the HE algorithm it can process. Defaults to he.HE_ALGORITHM_CKKS.\n\n        Raises:\n            ValueError: mismatched data_kind or HE algorithm\n        \"\"\"\n        super().__init__()\n        self.tenseal_context = None\n        self.tenseal_context_file = tenseal_context_file\n        if expected_data_kind not in [DataKind.WEIGHT_DIFF, DataKind.WEIGHTS]:\n            raise ValueError(f\"expected_data_kind={expected_data_kind} not in WEIGHT_DIFF or WEIGHTS\")\n        self.expected_data_kind = expected_data_kind\n        self.expected_algorithm = expected_algorithm\n        if self.expected_algorithm != he.HE_ALGORITHM_CKKS:\n            raise ValueError(f\"expected algorithm {self.expected_algorithm} not supported\")\n        self.exclude_vars = re.compile(exclude_vars) if exclude_vars else None\n        self.aggregation_weights = aggregation_weights or {}\n        self.reset_stats()\n        self.weigh_by_local_iter = weigh_by_local_iter\n        self.logger.info(f\"client weights control: {self.aggregation_weights}\")\n        if not self.weigh_by_local_iter:\n            if self.aggregation_weights:\n                self.logger.warning(\"aggregation_weights will be ignored if weigh_by_local_iter=False\")\n            self.logger.info(\"Only divide by sum of local (weighted) iterations.\")\n        self.warning_count = dict()\n        self.warning_limit = 0",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.tenseal_context = load_tenseal_context_from_workspace(self.tenseal_context_file, fl_ctx)\n        elif event_type == EventType.END_RUN:\n            self.tenseal_context = None",
  "def reset_stats(self):\n        self.total = dict()\n        self.counts = dict()\n        self.contribution_count = 0\n        self.history = list()\n        self.merged_encrypted_layers = dict()",
  "def accept(self, shareable: Shareable, fl_ctx: FLContext) -> bool:\n        \"\"\"Accepts and adds the client updates to current average in HE encrypted space.\n\n        Args:\n            shareable: a shareable from client\n            fl_ctx: FL Contenxt associated with this shareable\n\n        Returns:\n            bool to indicate if this shareable is accepted.\n        \"\"\"\n        dxo = from_shareable(shareable)\n        if dxo.data_kind != self.expected_data_kind:\n            self.log_error(\n                fl_ctx,\n                f\"expected {self.expected_data_kind} type DXO only but received {dxo.data_kind}, skipping this shareable.\",\n            )\n            return False\n\n        enc_algo = dxo.get_meta_prop(key=MetaKey.PROCESSED_ALGORITHM, default=None)\n        if enc_algo != self.expected_algorithm:\n            self.log_error(fl_ctx, \"unsupported encryption algorithm {enc_algo}\")\n            return False\n\n        current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n        client_name = shareable.get_peer_prop(ReservedKey.IDENTITY_NAME, \"?\")\n        contribution_round = shareable.get_header(AppConstants.CONTRIBUTION_ROUND)\n\n        rc = shareable.get_return_code()\n        if rc and rc != ReturnCode.OK:\n            self.log_debug(fl_ctx, f\"Client {client_name} returned rc: {rc}. Disregarding contribution.\")\n            return False\n\n        self.log_debug(fl_ctx, f\"current_round: {current_round}\")\n\n        if contribution_round != current_round:\n            self.log_debug(\n                fl_ctx,\n                \"Discarded the contribution from {client_name} for round: {contribution_round}. Current round is: {current_round}\",\n            )\n            return False\n\n        start_time = time.time()\n\n        for item in self.history:\n            if client_name == item[\"client_name\"]:\n                prev_round = item[\"round\"]\n                self.log_info(\n                    fl_ctx,\n                    f\"discarding shareable from {client_name} at round: {contribution_round} as {prev_round} accepted already\",\n                )\n                return False\n\n        self.log_info(fl_ctx, f\"Adding contribution from {client_name}.\")\n\n        n_iter = dxo.get_meta_prop(key=MetaKey.NUM_STEPS_CURRENT_ROUND)\n        if n_iter is None:\n            if self.warning_count.get(client_name, 0) <= self.warning_limit:\n                self.log_warning(\n                    fl_ctx,\n                    f\"NUM_STEPS_CURRENT_ROUND missing\"\n                    f\" from {client_name} and set to default value, 1.0. \"\n                    f\" This kind of message will show {self.warning_limit} times at most.\",\n                )\n                if client_name in self.warning_count:\n                    self.warning_count[client_name] = self.warning_count[client_name] + 1\n                else:\n                    self.warning_count[client_name] = 0\n            n_iter = 1.0\n        float_n_iter = np.float(n_iter)\n\n        aggregation_weight = self.aggregation_weights.get(client_name)\n        if aggregation_weight is None:\n            aggregation_weight = 1.0\n\n        aggr_data = dxo.data\n        encrypted_layers = dxo.get_meta_prop(MetaKey.PROCESSED_KEYS)\n        # TODO: test support of different encrypted layers for different clients!\n\n        if encrypted_layers is None:\n            self.log_error(fl_ctx, \"encrypted_layers is None!\")\n            return False\n\n        for k, v in aggr_data.items():\n            if self.exclude_vars is not None and self.exclude_vars.search(k):\n                continue\n            if encrypted_layers[k]:\n                if self.weigh_by_local_iter:\n                    weighted_value = ts.ckks_vector_from(self.tenseal_context, v) * (aggregation_weight * float_n_iter)\n                else:\n                    weighted_value = ts.ckks_vector_from(self.tenseal_context, v)\n                self.merged_encrypted_layers[k] = True  # any client can set this true\n            else:\n                if self.weigh_by_local_iter:\n                    weighted_value = v * (aggregation_weight * float_n_iter)\n                else:\n                    weighted_value = v\n                if k not in self.merged_encrypted_layers:\n                    self.merged_encrypted_layers[k] = False  # only set False if no other client set it to True\n            current_total = self.total.get(k, None)\n            if current_total is None:\n                self.total[k] = weighted_value\n                self.counts[k] = n_iter\n            else:\n                self.total[k] = current_total + weighted_value\n                self.counts[k] = self.counts[k] + n_iter\n\n        self.contribution_count += 1\n\n        end_time = time.time()\n        n_encrypted, n_total = count_encrypted_layers(self.merged_encrypted_layers)\n        self.log_info(fl_ctx, f\"{n_encrypted} of {n_total} layers encrypted\")\n        self.log_info(fl_ctx, f\"Round {current_round} adding {client_name} time is {end_time - start_time} seconds\")\n\n        self.history.append(\n            {\n                \"client_name\": client_name,\n                \"round\": contribution_round,\n                \"aggregation_weight\": aggregation_weight,\n                \"n_iter\": n_iter,\n            }\n        )\n        return True",
  "def aggregate(self, fl_ctx: FLContext) -> Shareable:\n        start_time = time.time()\n        current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n\n        aggregated_dict = dict()\n        for k, v in self.total.items():\n            aggregated_dict[k] = v * (1.0 / self.counts[k])\n        end_time = time.time()\n        self.log_info(\n            fl_ctx,\n            f\"Aggregated {self.contribution_count} contributions for round {current_round} time is {end_time - start_time} seconds\",\n        )\n\n        dxo = DXO(data_kind=self.expected_data_kind, data=aggregated_dict)\n        dxo.set_meta_prop(MetaKey.PROCESSED_KEYS, self.merged_encrypted_layers)\n        dxo.set_meta_prop(MetaKey.PROCESSED_ALGORITHM, self.expected_algorithm)\n        n_encrypted, n_total = count_encrypted_layers(self.merged_encrypted_layers)\n        self.log_info(fl_ctx, f\"{n_encrypted} of {n_total} layers encrypted\")\n\n        fl_ctx.set_prop(AppConstants.DXO, dxo, private=True, sticky=False)\n\n        self.reset_stats()  # only reset dictionary after adding merged_encrypted_layers to dictionary\n        return dxo.to_shareable()",
  "def load_tenseal_context_from_workspace(ctx_file_name: str, fl_ctx: FLContext):\n    \"\"\"Loads homomorphic encryption (HE) context from TenSEAL (https://github.com/OpenMined/TenSEAL) containing encryption keys and parameters.\n\n    Args:\n        ctx_file_name: filepath of TensSEAL context file\n        fl_ctx: FL context\n\n    Returns:\n        TenSEAL context\n\n    \"\"\"\n    is_secure_mode = fl_ctx.get_prop(FLContextKey.SECURE_MODE, True)\n    data, rc = SecurityContentService.load_content(ctx_file_name)\n\n    bad_rcs = [LoadResult.INVALID_CONTENT, LoadResult.NO_SUCH_CONTENT]\n    if is_secure_mode:\n        bad_rcs.extend([LoadResult.INVALID_SIGNATURE, LoadResult.NOT_SIGNED])\n\n    if rc in bad_rcs:\n        raise ValueError(\"Cannot load tenseal_context {}: {}\".format(ctx_file_name, rc))\n\n    context = ts.context_from(data)\n    return context",
  "def count_encrypted_layers(encrypted_layers: dict):\n    \"\"\"Count number of encrypted layers homomorphic encryption (HE) layers/variables.\"\"\"\n    n_total = len(encrypted_layers)\n    n_encrypted = 0\n    for e in encrypted_layers.keys():\n        if encrypted_layers[e]:\n            n_encrypted += 1\n    return n_encrypted, n_total",
  "class HEModelEncryptor(Filter):\n    def __init__(\n        self,\n        tenseal_context_file=\"client_context.tenseal\",\n        encrypt_layers=None,\n        aggregation_weights=None,\n        weigh_by_local_iter=True,\n    ):\n        \"\"\"Filter to encrypt Shareable object using homomorphic encryption (HE) with TenSEAL https://github.com/OpenMined/TenSEAL.\n\n        Args:\n            tenseal_context_file: tenseal context files containing encryption keys and parameters\n            encrypt_layers: if not specified (None), all layers are being encrypted;\n                            if list of variable/layer names, only specified variables are encrypted;\n                            if string containing regular expression (e.g. \"conv\"), only matched variables are being encrypted.\n            aggregation_weights: dictionary of client aggregation `{\"client1\": 1.0, \"client2\": 2.0, \"client3\": 3.0}`;\n                                 defaults to a weight of 1.0 if not specified.\n            weigh_by_local_iter: If true, multiply client weights on first before encryption (default: `True` which is recommended for HE)\n\n        \"\"\"\n        super().__init__()\n        self.logger.info(\"Using HE model encryptor.\")\n        self.tenseal_context = None\n        self.tenseal_context_file = tenseal_context_file\n        self.aggregation_weights = aggregation_weights or {}\n        self.logger.info(f\"client weights control: {self.aggregation_weights}\")\n        self.weigh_by_local_iter = weigh_by_local_iter\n        self.n_iter = None\n        self.client_name = None\n        self.aggregation_weight = None\n\n        # choose which layers to encrypt\n        if encrypt_layers is not None:\n            if not (isinstance(encrypt_layers, list) or isinstance(encrypt_layers, str)):\n                raise ValueError(\n                    \"Must provide a list of layer names or a string for regex matching, but got {}\".format(\n                        type(encrypt_layers)\n                    )\n                )\n        if isinstance(encrypt_layers, list):\n            for encrypt_layer in encrypt_layers:\n                if not isinstance(encrypt_layer, str):\n                    raise ValueError(\n                        \"encrypt_layers needs to be a list of layer names to encrypt, but found element of type {}\".format(\n                            type(encrypt_layer)\n                        )\n                    )\n            self.encrypt_layers = encrypt_layers\n            self.logger.info(f\"Encrypting {len(encrypt_layers)} layers\")\n        elif isinstance(encrypt_layers, str):\n            self.encrypt_layers = re.compile(encrypt_layers) if encrypt_layers else None\n            self.logger.info(f'Encrypting all layers based on regex matches with \"{encrypt_layers}\"')\n        else:\n            self.encrypt_layers = [True]  # needs to be list for logic in encryption()\n            self.logger.info(\"Encrypting all layers\")\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.tenseal_context = load_tenseal_context_from_workspace(self.tenseal_context_file, fl_ctx)\n        elif event_type == EventType.END_RUN:\n            self.tenseal_context = None\n\n    def encryption(self, params, fl_ctx: FLContext):\n        n_params = len(params.keys())\n        self.log_info(fl_ctx, f\"Running HE Encryption algorithm on {n_params} variables\")\n\n        # parse regex encrypt layers\n        if isinstance(self.encrypt_layers, re.Pattern):\n            re_pattern = self.encrypt_layers\n            self.encrypt_layers = []\n            for var_name in params:\n                if re_pattern.search(var_name):\n                    self.encrypt_layers.append(var_name)\n            self.log_info(fl_ctx, f\"Regex found {self.encrypt_layers} matching layers.\")\n            if len(self.encrypt_layers) == 0:\n                raise ValueError(f\"No matching layers found with regex {re_pattern}\")\n\n        start_time = time.time()\n        n_encrypted, n_total = 0, 0\n        encryption_dict = {}\n        vmins, vmaxs = [], []\n        for i, param_name in enumerate(params.keys()):\n            values = params[param_name].ravel()\n            _n = np.size(values)\n            n_total += _n\n\n            # weigh before encryption\n            if self.aggregation_weight:\n                values = values * np.float(self.aggregation_weight)\n            if self.weigh_by_local_iter:\n                values = values * np.float(self.n_iter)\n\n            if param_name in self.encrypt_layers or self.encrypt_layers[0] is True:\n                self.log_info(fl_ctx, f\"Encrypting vars {i+1} of {n_params}: {param_name} with {_n} values\")\n                vmin = np.min(params[param_name])\n                vmax = np.max(params[param_name])\n                vmins.append(vmin)\n                vmaxs.append(vmax)\n                params[param_name] = ts.ckks_vector(self.tenseal_context, values).serialize()\n                encryption_dict[param_name] = True\n                n_encrypted += _n\n            elif isinstance(values, CKKSVector):\n                self.log_error(\n                    fl_ctx, f\"{i} of {n_params}: {param_name} = {np.shape(params[param_name])} already encrypted!\"\n                )\n                raise ValueError(\"This should not happen!\")\n            else:\n                params[param_name] = values\n                encryption_dict[param_name] = False\n        end_time = time.time()\n        if n_encrypted == 0:\n            raise ValueError(\"Nothing has been encrypted! Check provided encrypt_layers list of layer names or regex.\")\n        self.log_info(\n            fl_ctx,\n            f\"Encryption time for {n_encrypted} of {n_total} params\"\n            f\" (encrypted value range [{np.min(vmins)}, {np.max(vmaxs)}])\"\n            f\" {end_time - start_time} seconds.\",\n        )\n        # params is a dictionary.  keys are layer names.  values are either weights or serialized ckks_vector of weights.\n        # encryption_dict: keys are layer names.  values are True for serialized ckks_vectors, False elsewhere.\n        return params, encryption_dict\n\n    def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Filter process apply to the Shareable object.\n\n        Args:\n            shareable: shareable\n            fl_ctx: FLContext\n\n        Returns:\n            a Shareable object with encrypted model weights\n\n        \"\"\"\n        rc = shareable.get_return_code()\n        if rc != ReturnCode.OK:\n            # don't process if RC not OK\n            return shareable\n\n        dxo = from_shareable(shareable)\n\n        if self.aggregation_weights:\n            self.client_name = shareable.get_peer_prop(ReservedKey.IDENTITY_NAME, default=\"?\")\n            self.aggregation_weight = self.aggregation_weights.get(self.client_name, 1.0)\n            self.log_info(fl_ctx, f\"weighting {self.client_name} by aggregation weight {self.aggregation_weight}\")\n\n        if self.weigh_by_local_iter:\n            self.n_iter = dxo.get_meta_prop(MetaKey.NUM_STEPS_CURRENT_ROUND, None)\n            if self.n_iter is None:\n                raise ValueError(\"DXO data does not have local iterations for weighting!\")\n            self.log_info(fl_ctx, f\"weighting by local iter before encryption with {self.n_iter}\")\n        try:\n            new_dxo = self._process(dxo, fl_ctx)\n            new_dxo.update_shareable(shareable)\n        except BaseException as e:\n            self.log_exception(fl_ctx, f\"Exception occurred: {e}\")\n\n        return shareable\n\n    def _process(self, dxo: DXO, fl_ctx: FLContext) -> DXO:\n        self.log_info(fl_ctx, \"Running HE encryption...\")\n        encrypted_params, encryption_dict = self.encryption(params=dxo.data, fl_ctx=fl_ctx)\n        new_dxo = DXO(data_kind=dxo.data_kind, data=encrypted_params, meta=dxo.meta)\n        new_dxo.set_meta_prop(key=MetaKey.PROCESSED_KEYS, value=encryption_dict)\n        new_dxo.set_meta_prop(key=MetaKey.PROCESSED_ALGORITHM, value=he.HE_ALGORITHM_CKKS)\n        n_encrypted, n_total = count_encrypted_layers(encryption_dict)\n        self.log_info(fl_ctx, f\"{n_encrypted} of {n_total} layers encrypted\")\n        return new_dxo",
  "def __init__(\n        self,\n        tenseal_context_file=\"client_context.tenseal\",\n        encrypt_layers=None,\n        aggregation_weights=None,\n        weigh_by_local_iter=True,\n    ):\n        \"\"\"Filter to encrypt Shareable object using homomorphic encryption (HE) with TenSEAL https://github.com/OpenMined/TenSEAL.\n\n        Args:\n            tenseal_context_file: tenseal context files containing encryption keys and parameters\n            encrypt_layers: if not specified (None), all layers are being encrypted;\n                            if list of variable/layer names, only specified variables are encrypted;\n                            if string containing regular expression (e.g. \"conv\"), only matched variables are being encrypted.\n            aggregation_weights: dictionary of client aggregation `{\"client1\": 1.0, \"client2\": 2.0, \"client3\": 3.0}`;\n                                 defaults to a weight of 1.0 if not specified.\n            weigh_by_local_iter: If true, multiply client weights on first before encryption (default: `True` which is recommended for HE)\n\n        \"\"\"\n        super().__init__()\n        self.logger.info(\"Using HE model encryptor.\")\n        self.tenseal_context = None\n        self.tenseal_context_file = tenseal_context_file\n        self.aggregation_weights = aggregation_weights or {}\n        self.logger.info(f\"client weights control: {self.aggregation_weights}\")\n        self.weigh_by_local_iter = weigh_by_local_iter\n        self.n_iter = None\n        self.client_name = None\n        self.aggregation_weight = None\n\n        # choose which layers to encrypt\n        if encrypt_layers is not None:\n            if not (isinstance(encrypt_layers, list) or isinstance(encrypt_layers, str)):\n                raise ValueError(\n                    \"Must provide a list of layer names or a string for regex matching, but got {}\".format(\n                        type(encrypt_layers)\n                    )\n                )\n        if isinstance(encrypt_layers, list):\n            for encrypt_layer in encrypt_layers:\n                if not isinstance(encrypt_layer, str):\n                    raise ValueError(\n                        \"encrypt_layers needs to be a list of layer names to encrypt, but found element of type {}\".format(\n                            type(encrypt_layer)\n                        )\n                    )\n            self.encrypt_layers = encrypt_layers\n            self.logger.info(f\"Encrypting {len(encrypt_layers)} layers\")\n        elif isinstance(encrypt_layers, str):\n            self.encrypt_layers = re.compile(encrypt_layers) if encrypt_layers else None\n            self.logger.info(f'Encrypting all layers based on regex matches with \"{encrypt_layers}\"')\n        else:\n            self.encrypt_layers = [True]  # needs to be list for logic in encryption()\n            self.logger.info(\"Encrypting all layers\")",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.tenseal_context = load_tenseal_context_from_workspace(self.tenseal_context_file, fl_ctx)\n        elif event_type == EventType.END_RUN:\n            self.tenseal_context = None",
  "def encryption(self, params, fl_ctx: FLContext):\n        n_params = len(params.keys())\n        self.log_info(fl_ctx, f\"Running HE Encryption algorithm on {n_params} variables\")\n\n        # parse regex encrypt layers\n        if isinstance(self.encrypt_layers, re.Pattern):\n            re_pattern = self.encrypt_layers\n            self.encrypt_layers = []\n            for var_name in params:\n                if re_pattern.search(var_name):\n                    self.encrypt_layers.append(var_name)\n            self.log_info(fl_ctx, f\"Regex found {self.encrypt_layers} matching layers.\")\n            if len(self.encrypt_layers) == 0:\n                raise ValueError(f\"No matching layers found with regex {re_pattern}\")\n\n        start_time = time.time()\n        n_encrypted, n_total = 0, 0\n        encryption_dict = {}\n        vmins, vmaxs = [], []\n        for i, param_name in enumerate(params.keys()):\n            values = params[param_name].ravel()\n            _n = np.size(values)\n            n_total += _n\n\n            # weigh before encryption\n            if self.aggregation_weight:\n                values = values * np.float(self.aggregation_weight)\n            if self.weigh_by_local_iter:\n                values = values * np.float(self.n_iter)\n\n            if param_name in self.encrypt_layers or self.encrypt_layers[0] is True:\n                self.log_info(fl_ctx, f\"Encrypting vars {i+1} of {n_params}: {param_name} with {_n} values\")\n                vmin = np.min(params[param_name])\n                vmax = np.max(params[param_name])\n                vmins.append(vmin)\n                vmaxs.append(vmax)\n                params[param_name] = ts.ckks_vector(self.tenseal_context, values).serialize()\n                encryption_dict[param_name] = True\n                n_encrypted += _n\n            elif isinstance(values, CKKSVector):\n                self.log_error(\n                    fl_ctx, f\"{i} of {n_params}: {param_name} = {np.shape(params[param_name])} already encrypted!\"\n                )\n                raise ValueError(\"This should not happen!\")\n            else:\n                params[param_name] = values\n                encryption_dict[param_name] = False\n        end_time = time.time()\n        if n_encrypted == 0:\n            raise ValueError(\"Nothing has been encrypted! Check provided encrypt_layers list of layer names or regex.\")\n        self.log_info(\n            fl_ctx,\n            f\"Encryption time for {n_encrypted} of {n_total} params\"\n            f\" (encrypted value range [{np.min(vmins)}, {np.max(vmaxs)}])\"\n            f\" {end_time - start_time} seconds.\",\n        )\n        # params is a dictionary.  keys are layer names.  values are either weights or serialized ckks_vector of weights.\n        # encryption_dict: keys are layer names.  values are True for serialized ckks_vectors, False elsewhere.\n        return params, encryption_dict",
  "def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Filter process apply to the Shareable object.\n\n        Args:\n            shareable: shareable\n            fl_ctx: FLContext\n\n        Returns:\n            a Shareable object with encrypted model weights\n\n        \"\"\"\n        rc = shareable.get_return_code()\n        if rc != ReturnCode.OK:\n            # don't process if RC not OK\n            return shareable\n\n        dxo = from_shareable(shareable)\n\n        if self.aggregation_weights:\n            self.client_name = shareable.get_peer_prop(ReservedKey.IDENTITY_NAME, default=\"?\")\n            self.aggregation_weight = self.aggregation_weights.get(self.client_name, 1.0)\n            self.log_info(fl_ctx, f\"weighting {self.client_name} by aggregation weight {self.aggregation_weight}\")\n\n        if self.weigh_by_local_iter:\n            self.n_iter = dxo.get_meta_prop(MetaKey.NUM_STEPS_CURRENT_ROUND, None)\n            if self.n_iter is None:\n                raise ValueError(\"DXO data does not have local iterations for weighting!\")\n            self.log_info(fl_ctx, f\"weighting by local iter before encryption with {self.n_iter}\")\n        try:\n            new_dxo = self._process(dxo, fl_ctx)\n            new_dxo.update_shareable(shareable)\n        except BaseException as e:\n            self.log_exception(fl_ctx, f\"Exception occurred: {e}\")\n\n        return shareable",
  "def _process(self, dxo: DXO, fl_ctx: FLContext) -> DXO:\n        self.log_info(fl_ctx, \"Running HE encryption...\")\n        encrypted_params, encryption_dict = self.encryption(params=dxo.data, fl_ctx=fl_ctx)\n        new_dxo = DXO(data_kind=dxo.data_kind, data=encrypted_params, meta=dxo.meta)\n        new_dxo.set_meta_prop(key=MetaKey.PROCESSED_KEYS, value=encryption_dict)\n        new_dxo.set_meta_prop(key=MetaKey.PROCESSED_ALGORITHM, value=he.HE_ALGORITHM_CKKS)\n        n_encrypted, n_total = count_encrypted_layers(encryption_dict)\n        self.log_info(fl_ctx, f\"{n_encrypted} of {n_total} layers encrypted\")\n        return new_dxo",
  "class HEModelDecryptor(Filter):\n    def __init__(self, tenseal_context_file=\"client_context.tenseal\"):\n        \"\"\"Filter to decrypt Shareable object using homomorphic encryption (HE) with TenSEAL https://github.com/OpenMined/TenSEAL.\n\n        Args:\n            tenseal_context_file: tenseal context files containing decryption keys and parameters\n\n        \"\"\"\n        super().__init__()\n        self.logger.info(\"Using HE model decryptor.\")\n        self.tenseal_context = None\n        self.tenseal_context_file = tenseal_context_file\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.tenseal_context = load_tenseal_context_from_workspace(self.tenseal_context_file, fl_ctx)\n        elif event_type == EventType.END_RUN:\n            self.tenseal_context = None\n\n    def decryption(self, params, encrypted_layers, fl_ctx: FLContext):\n\n        n_params = len(params.keys())\n        self.log_info(fl_ctx, f\"Running HE Decryption algorithm {n_params} variables\")\n        if encrypted_layers is None:\n            raise ValueError(\"encrypted_layers is None!\")\n\n        start_time = time.time()\n        n_decrypted, n_total = 0, 0\n        for i, param_name in enumerate(params.keys()):\n            values = params[param_name]\n            if encrypted_layers[param_name]:\n                _n = values.size()\n                n_total += _n\n                if isinstance(values, CKKSVector):\n                    self.log_info(fl_ctx, f\"Decrypting vars {i+1} of {n_params}: {param_name} with {_n} values\")\n                    params[param_name] = values.decrypt()\n                    n_decrypted += _n\n                else:\n                    self.log_info(\n                        fl_ctx,\n                        f\"{i} of {n_params}: {param_name} = {np.shape(params[param_name])} already decrypted (RAW)!\",\n                    )\n                    raise ValueError(\"Should be encrypted at this point!\")\n            else:\n                params[param_name] = values\n        end_time = time.time()\n        self.log_info(fl_ctx, f\"Decryption time for {n_decrypted} of {n_total} params {end_time - start_time} seconds.\")\n\n        return params\n\n    def to_ckks_vector(self, params, encrypted_layers, fl_ctx: FLContext):\n        \"\"\"Convert encrypted arrays to CKKS vector.\"\"\"\n        if encrypted_layers is None:\n            raise ValueError(\"encrypted_layers is None!\")\n        start_time = time.time()\n        result = {}\n        n_total = 0\n        self.log_info(fl_ctx, f\"params {len(params)} {type(params)}\")\n        for v in params:\n            ndarray = params[v]\n            if encrypted_layers[v]:\n                if np.size(ndarray) > 1:\n                    raise ValueError(f\"size of {v} should not be larger 1 but is {np.size(ndarray)}!\")\n                result[v] = ts.ckks_vector_from(self.tenseal_context, ndarray)\n                n = result[v].size()\n            else:\n                result[v] = ndarray\n                n = np.size(ndarray)\n            n_total += n\n        end_time = time.time()\n        self.log_info(fl_ctx, f\"to_ckks_vector time for {n_total} values: {end_time - start_time} seconds.\")\n        return result\n\n    def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Filter process apply to the Shareable object.\n\n        Args:\n            shareable: shareable\n            fl_ctx: FLContext\n\n        Returns:\n            a Shareable object with decrypted model weights\n\n        \"\"\"\n        rc = shareable.get_return_code()\n        if rc != ReturnCode.OK:\n            # don't process if RC not OK\n            return shareable\n\n        try:\n            return self._process(shareable, fl_ctx)\n        except BaseException as e:\n            self.log_exception(fl_ctx, \"error performing HE decryption\")\n            raise ValueError(f\"HEModelDecryptor Exception {e}\")\n\n    def _process(self, shareable: Shareable, fl_ctx: FLContext):\n        self.log_info(fl_ctx, \"Running decryption...\")\n        dxo = from_shareable(shareable)\n\n        encrypted_layers = dxo.get_meta_prop(key=MetaKey.PROCESSED_KEYS, default=None)\n        if not encrypted_layers:\n            self.log_warning(fl_ctx, \"dxo does not contain PROCESSED_KEYS (do nothing)\")\n            return shareable\n\n        encrypted_algo = dxo.get_meta_prop(key=MetaKey.PROCESSED_ALGORITHM, default=None)\n        if encrypted_algo != he.HE_ALGORITHM_CKKS:\n            self.log_error(fl_ctx, \"shareable is not HE CKKS encrypted\")\n            return shareable\n\n        n_encrypted, n_total = count_encrypted_layers(encrypted_layers)\n        self.log_info(fl_ctx, f\"{n_encrypted} of {n_total} layers encrypted\")\n        decrypted_params = self.decryption(\n            params=self.to_ckks_vector(params=dxo.data, encrypted_layers=encrypted_layers, fl_ctx=fl_ctx),\n            encrypted_layers=encrypted_layers,\n            fl_ctx=fl_ctx,\n        )\n\n        dxo.data = decrypted_params\n        dxo.remove_meta_props([MetaKey.PROCESSED_ALGORITHM, MetaKey.PROCESSED_KEYS])\n        dxo.update_shareable(shareable)\n\n        return shareable",
  "def __init__(self, tenseal_context_file=\"client_context.tenseal\"):\n        \"\"\"Filter to decrypt Shareable object using homomorphic encryption (HE) with TenSEAL https://github.com/OpenMined/TenSEAL.\n\n        Args:\n            tenseal_context_file: tenseal context files containing decryption keys and parameters\n\n        \"\"\"\n        super().__init__()\n        self.logger.info(\"Using HE model decryptor.\")\n        self.tenseal_context = None\n        self.tenseal_context_file = tenseal_context_file",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.tenseal_context = load_tenseal_context_from_workspace(self.tenseal_context_file, fl_ctx)\n        elif event_type == EventType.END_RUN:\n            self.tenseal_context = None",
  "def decryption(self, params, encrypted_layers, fl_ctx: FLContext):\n\n        n_params = len(params.keys())\n        self.log_info(fl_ctx, f\"Running HE Decryption algorithm {n_params} variables\")\n        if encrypted_layers is None:\n            raise ValueError(\"encrypted_layers is None!\")\n\n        start_time = time.time()\n        n_decrypted, n_total = 0, 0\n        for i, param_name in enumerate(params.keys()):\n            values = params[param_name]\n            if encrypted_layers[param_name]:\n                _n = values.size()\n                n_total += _n\n                if isinstance(values, CKKSVector):\n                    self.log_info(fl_ctx, f\"Decrypting vars {i+1} of {n_params}: {param_name} with {_n} values\")\n                    params[param_name] = values.decrypt()\n                    n_decrypted += _n\n                else:\n                    self.log_info(\n                        fl_ctx,\n                        f\"{i} of {n_params}: {param_name} = {np.shape(params[param_name])} already decrypted (RAW)!\",\n                    )\n                    raise ValueError(\"Should be encrypted at this point!\")\n            else:\n                params[param_name] = values\n        end_time = time.time()\n        self.log_info(fl_ctx, f\"Decryption time for {n_decrypted} of {n_total} params {end_time - start_time} seconds.\")\n\n        return params",
  "def to_ckks_vector(self, params, encrypted_layers, fl_ctx: FLContext):\n        \"\"\"Convert encrypted arrays to CKKS vector.\"\"\"\n        if encrypted_layers is None:\n            raise ValueError(\"encrypted_layers is None!\")\n        start_time = time.time()\n        result = {}\n        n_total = 0\n        self.log_info(fl_ctx, f\"params {len(params)} {type(params)}\")\n        for v in params:\n            ndarray = params[v]\n            if encrypted_layers[v]:\n                if np.size(ndarray) > 1:\n                    raise ValueError(f\"size of {v} should not be larger 1 but is {np.size(ndarray)}!\")\n                result[v] = ts.ckks_vector_from(self.tenseal_context, ndarray)\n                n = result[v].size()\n            else:\n                result[v] = ndarray\n                n = np.size(ndarray)\n            n_total += n\n        end_time = time.time()\n        self.log_info(fl_ctx, f\"to_ckks_vector time for {n_total} values: {end_time - start_time} seconds.\")\n        return result",
  "def process(self, shareable: Shareable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Filter process apply to the Shareable object.\n\n        Args:\n            shareable: shareable\n            fl_ctx: FLContext\n\n        Returns:\n            a Shareable object with decrypted model weights\n\n        \"\"\"\n        rc = shareable.get_return_code()\n        if rc != ReturnCode.OK:\n            # don't process if RC not OK\n            return shareable\n\n        try:\n            return self._process(shareable, fl_ctx)\n        except BaseException as e:\n            self.log_exception(fl_ctx, \"error performing HE decryption\")\n            raise ValueError(f\"HEModelDecryptor Exception {e}\")",
  "def _process(self, shareable: Shareable, fl_ctx: FLContext):\n        self.log_info(fl_ctx, \"Running decryption...\")\n        dxo = from_shareable(shareable)\n\n        encrypted_layers = dxo.get_meta_prop(key=MetaKey.PROCESSED_KEYS, default=None)\n        if not encrypted_layers:\n            self.log_warning(fl_ctx, \"dxo does not contain PROCESSED_KEYS (do nothing)\")\n            return shareable\n\n        encrypted_algo = dxo.get_meta_prop(key=MetaKey.PROCESSED_ALGORITHM, default=None)\n        if encrypted_algo != he.HE_ALGORITHM_CKKS:\n            self.log_error(fl_ctx, \"shareable is not HE CKKS encrypted\")\n            return shareable\n\n        n_encrypted, n_total = count_encrypted_layers(encrypted_layers)\n        self.log_info(fl_ctx, f\"{n_encrypted} of {n_total} layers encrypted\")\n        decrypted_params = self.decryption(\n            params=self.to_ckks_vector(params=dxo.data, encrypted_layers=encrypted_layers, fl_ctx=fl_ctx),\n            encrypted_layers=encrypted_layers,\n            fl_ctx=fl_ctx,\n        )\n\n        dxo.data = decrypted_params\n        dxo.remove_meta_props([MetaKey.PROCESSED_ALGORITHM, MetaKey.PROCESSED_KEYS])\n        dxo.update_shareable(shareable)\n\n        return shareable",
  "class HEPTModelReaderWriter(PTModelReaderWriter):\n    def apply_model(self, network, multi_processes: bool, model_params: dict, fl_ctx: FLContext, options=None):\n        \"\"\"Write global model back to local model.\n\n        Needed to extract local parameter shape to reshape decrypted vectors.\n\n        Args:\n            network (pytorch.nn): network object to read/write\n            multi_processes (bool): is the workflow in multi_processes environment\n            model_params (dict): which parameters to read/write\n            fl_ctx (FLContext): FL system-wide contenxt\n            options (dict, optional): additional information on how to process read/write. Defaults to None.\n\n        Raises:\n            RuntimeError: unable to reshape the network layers or mismatch between network layers and model_params\n\n        Returns:\n            list: a list of parameters been processed\n        \"\"\"\n        try:\n            # net = self.fitter.net\n            net = network\n            # if self.fitter.multi_gpu:\n            if multi_processes:\n                net = net.module\n\n            # reshape decrypted parameters\n            local_var_dict = net.state_dict()\n            for var_name in local_var_dict:\n                if var_name in model_params:\n                    try:\n                        self.logger.debug(\n                            f\"Reshaping {var_name}: {np.shape(model_params[var_name])} to\"\n                            f\" {local_var_dict[var_name].shape}\",\n                        )\n                        model_params[var_name] = np.reshape(model_params[var_name], local_var_dict[var_name].shape)\n                    except Exception as e:\n                        raise RuntimeError(f\"{self._name} reshaping Exception: {str(e)}\")\n\n            assign_ops, updated_local_model = feed_vars(net, model_params)\n            self.logger.debug(f\"assign_ops: {len(assign_ops)}\")\n            self.logger.debug(f\"updated_local_model: {len(updated_local_model)}\")\n            net.load_state_dict(updated_local_model)\n            return assign_ops\n        except BaseException as e:\n            raise RuntimeError(f\"{self._name} apply_model Exception: {str(e)}\")",
  "def apply_model(self, network, multi_processes: bool, model_params: dict, fl_ctx: FLContext, options=None):\n        \"\"\"Write global model back to local model.\n\n        Needed to extract local parameter shape to reshape decrypted vectors.\n\n        Args:\n            network (pytorch.nn): network object to read/write\n            multi_processes (bool): is the workflow in multi_processes environment\n            model_params (dict): which parameters to read/write\n            fl_ctx (FLContext): FL system-wide contenxt\n            options (dict, optional): additional information on how to process read/write. Defaults to None.\n\n        Raises:\n            RuntimeError: unable to reshape the network layers or mismatch between network layers and model_params\n\n        Returns:\n            list: a list of parameters been processed\n        \"\"\"\n        try:\n            # net = self.fitter.net\n            net = network\n            # if self.fitter.multi_gpu:\n            if multi_processes:\n                net = net.module\n\n            # reshape decrypted parameters\n            local_var_dict = net.state_dict()\n            for var_name in local_var_dict:\n                if var_name in model_params:\n                    try:\n                        self.logger.debug(\n                            f\"Reshaping {var_name}: {np.shape(model_params[var_name])} to\"\n                            f\" {local_var_dict[var_name].shape}\",\n                        )\n                        model_params[var_name] = np.reshape(model_params[var_name], local_var_dict[var_name].shape)\n                    except Exception as e:\n                        raise RuntimeError(f\"{self._name} reshaping Exception: {str(e)}\")\n\n            assign_ops, updated_local_model = feed_vars(net, model_params)\n            self.logger.debug(f\"assign_ops: {len(assign_ops)}\")\n            self.logger.debug(f\"updated_local_model: {len(updated_local_model)}\")\n            net.load_state_dict(updated_local_model)\n            return assign_ops\n        except BaseException as e:\n            raise RuntimeError(f\"{self._name} apply_model Exception: {str(e)}\")",
  "class HEModelShareableGenerator(FullModelShareableGenerator):\n    def __init__(self, tenseal_context_file=\"server_context.tenseal\"):\n        \"\"\"This ShareableGenerator converts between Shareable and Learnable objects.\n\n        This conversion is done with homomorphic encryption (HE) support using TenSEAL https://github.com/OpenMined/TenSEAL.\n\n        Args:\n            tenseal_context_file: tenseal context files containing decryption keys and parameters\n        \"\"\"\n        super().__init__()\n        self.tenseal_context = None\n        self.tenseal_context_file = tenseal_context_file\n        self.is_encrypted = False\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.tenseal_context = load_tenseal_context_from_workspace(self.tenseal_context_file, fl_ctx)\n        elif event_type == EventType.END_RUN:\n            self.tenseal_context = None\n\n    def add_to_global_weights(self, fl_ctx: FLContext, new_val, base_weights, v_name, encrypt_layers):\n        if encrypt_layers is None:\n            raise ValueError(\"encrypted layers info missing!\")\n\n        current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n        start_round = fl_ctx.get_prop(AppConstants.START_ROUND, 0)\n        if current_round > start_round and encrypt_layers[v_name]:\n            if encrypt_layers.get(v_name, False):\n                try:\n                    binary_global_var = base_weights[v_name]\n                    global_var = ts.ckks_vector_from(\n                        self.tenseal_context, binary_global_var\n                    )  # now the global model weights are encrypted\n                    n_vars_total = global_var.size()\n                except BaseException as e:\n                    raise ValueError(\"add_to_global_weights Exception\", str(e))\n        else:\n            global_var = base_weights[v_name].ravel()\n            n_vars_total = np.size(global_var)\n\n        # update the global model\n        updated_vars = new_val + global_var\n\n        if encrypt_layers[v_name]:  # only works with standard aggregation\n            self.log_info(fl_ctx, f\"serialize encrypted {v_name}\")\n            updated_vars = updated_vars.serialize()\n\n        return updated_vars, n_vars_total\n\n    def _shareable_to_learnable(self, shareable: Shareable, fl_ctx: FLContext) -> ModelLearnable:\n        dxo = from_shareable(shareable)\n        enc_algorithm = dxo.get_meta_prop(MetaKey.PROCESSED_ALGORITHM)\n        if enc_algorithm != he.HE_ALGORITHM_CKKS:\n            raise ValueError(\"expected encryption algorithm {} but got {}\".format(he.HE_ALGORITHM_CKKS, enc_algorithm))\n\n        encrypt_layers = dxo.get_meta_prop(MetaKey.PROCESSED_KEYS)\n        if encrypt_layers is None:\n            raise ValueError(\"DXO in shareable missing PROCESSED_KEYS property\")\n\n        if len(encrypt_layers) == 0:\n            raise ValueError(f\"encrypt_layers is empty: {encrypt_layers}\")\n\n        base_model = fl_ctx.get_prop(AppConstants.GLOBAL_MODEL)\n        if not base_model:\n            self.system_panic(reason=\"No global base model!\", fl_ctx=fl_ctx)\n            return base_model\n\n        base_weights = base_model[ModelLearnableKey.WEIGHTS]\n\n        if dxo.data_kind == DataKind.WEIGHT_DIFF:\n            start_time = time.time()\n            model_diff = dxo.data\n            if not model_diff:\n                raise ValueError(f\"{self._name} DXO data is empty!\")\n\n            n_vars = len(model_diff.items())\n            n_params = 0\n            for v_name, v_value in model_diff.items():\n                self.log_debug(fl_ctx, f\"adding {v_name} to global model...\")\n                # v_value += model[v_name]\n                updated_vars, n_vars_total = self.add_to_global_weights(\n                    fl_ctx, v_value, base_weights, v_name, encrypt_layers\n                )\n                n_params += n_vars_total\n                base_weights[v_name] = updated_vars\n                self.log_debug(fl_ctx, f\"assigned new {v_name}\")\n\n            end_time = time.time()\n            self.log_info(\n                fl_ctx,\n                f\"Updated global model {n_vars} vars with {n_params} params in {end_time - start_time} seconds\",\n            )\n        elif dxo.data_kind == DataKind.WEIGHTS:\n            weights = dxo.data\n            for v_name in weights.keys():\n                if encrypt_layers[v_name]:\n                    self.log_info(fl_ctx, f\"serialize encrypted {dxo.data_kind}: {v_name}\")\n                    weights[v_name] = weights[v_name].serialize()\n            base_model[ModelLearnableKey.WEIGHTS] = weights\n        else:\n            raise NotImplementedError(f\"data type {dxo.data_kind} not supported!\")\n\n        self.log_debug(fl_ctx, \"returning model\")\n        base_model[ModelLearnableKey.META] = dxo.get_meta_props()\n        return base_model\n\n    def shareable_to_learnable(self, shareable: Shareable, fl_ctx: FLContext) -> ModelLearnable:\n        \"\"\"Updates the global model in `Learnable` in encrypted space.\n\n        Args:\n            shareable: shareable\n            fl_ctx: FLContext\n\n        Returns:\n            Learnable object\n        \"\"\"\n        self.log_info(fl_ctx, \"shareable_to_learnable...\")\n        try:\n            return self._shareable_to_learnable(shareable, fl_ctx)\n        except BaseException as e:\n            self.log_exception(fl_ctx, \"error converting shareable to model\")\n            raise ValueError(f\"{self._name} Exception {e}\")",
  "def __init__(self, tenseal_context_file=\"server_context.tenseal\"):\n        \"\"\"This ShareableGenerator converts between Shareable and Learnable objects.\n\n        This conversion is done with homomorphic encryption (HE) support using TenSEAL https://github.com/OpenMined/TenSEAL.\n\n        Args:\n            tenseal_context_file: tenseal context files containing decryption keys and parameters\n        \"\"\"\n        super().__init__()\n        self.tenseal_context = None\n        self.tenseal_context_file = tenseal_context_file\n        self.is_encrypted = False",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.START_RUN:\n            self.tenseal_context = load_tenseal_context_from_workspace(self.tenseal_context_file, fl_ctx)\n        elif event_type == EventType.END_RUN:\n            self.tenseal_context = None",
  "def add_to_global_weights(self, fl_ctx: FLContext, new_val, base_weights, v_name, encrypt_layers):\n        if encrypt_layers is None:\n            raise ValueError(\"encrypted layers info missing!\")\n\n        current_round = fl_ctx.get_prop(AppConstants.CURRENT_ROUND)\n        start_round = fl_ctx.get_prop(AppConstants.START_ROUND, 0)\n        if current_round > start_round and encrypt_layers[v_name]:\n            if encrypt_layers.get(v_name, False):\n                try:\n                    binary_global_var = base_weights[v_name]\n                    global_var = ts.ckks_vector_from(\n                        self.tenseal_context, binary_global_var\n                    )  # now the global model weights are encrypted\n                    n_vars_total = global_var.size()\n                except BaseException as e:\n                    raise ValueError(\"add_to_global_weights Exception\", str(e))\n        else:\n            global_var = base_weights[v_name].ravel()\n            n_vars_total = np.size(global_var)\n\n        # update the global model\n        updated_vars = new_val + global_var\n\n        if encrypt_layers[v_name]:  # only works with standard aggregation\n            self.log_info(fl_ctx, f\"serialize encrypted {v_name}\")\n            updated_vars = updated_vars.serialize()\n\n        return updated_vars, n_vars_total",
  "def _shareable_to_learnable(self, shareable: Shareable, fl_ctx: FLContext) -> ModelLearnable:\n        dxo = from_shareable(shareable)\n        enc_algorithm = dxo.get_meta_prop(MetaKey.PROCESSED_ALGORITHM)\n        if enc_algorithm != he.HE_ALGORITHM_CKKS:\n            raise ValueError(\"expected encryption algorithm {} but got {}\".format(he.HE_ALGORITHM_CKKS, enc_algorithm))\n\n        encrypt_layers = dxo.get_meta_prop(MetaKey.PROCESSED_KEYS)\n        if encrypt_layers is None:\n            raise ValueError(\"DXO in shareable missing PROCESSED_KEYS property\")\n\n        if len(encrypt_layers) == 0:\n            raise ValueError(f\"encrypt_layers is empty: {encrypt_layers}\")\n\n        base_model = fl_ctx.get_prop(AppConstants.GLOBAL_MODEL)\n        if not base_model:\n            self.system_panic(reason=\"No global base model!\", fl_ctx=fl_ctx)\n            return base_model\n\n        base_weights = base_model[ModelLearnableKey.WEIGHTS]\n\n        if dxo.data_kind == DataKind.WEIGHT_DIFF:\n            start_time = time.time()\n            model_diff = dxo.data\n            if not model_diff:\n                raise ValueError(f\"{self._name} DXO data is empty!\")\n\n            n_vars = len(model_diff.items())\n            n_params = 0\n            for v_name, v_value in model_diff.items():\n                self.log_debug(fl_ctx, f\"adding {v_name} to global model...\")\n                # v_value += model[v_name]\n                updated_vars, n_vars_total = self.add_to_global_weights(\n                    fl_ctx, v_value, base_weights, v_name, encrypt_layers\n                )\n                n_params += n_vars_total\n                base_weights[v_name] = updated_vars\n                self.log_debug(fl_ctx, f\"assigned new {v_name}\")\n\n            end_time = time.time()\n            self.log_info(\n                fl_ctx,\n                f\"Updated global model {n_vars} vars with {n_params} params in {end_time - start_time} seconds\",\n            )\n        elif dxo.data_kind == DataKind.WEIGHTS:\n            weights = dxo.data\n            for v_name in weights.keys():\n                if encrypt_layers[v_name]:\n                    self.log_info(fl_ctx, f\"serialize encrypted {dxo.data_kind}: {v_name}\")\n                    weights[v_name] = weights[v_name].serialize()\n            base_model[ModelLearnableKey.WEIGHTS] = weights\n        else:\n            raise NotImplementedError(f\"data type {dxo.data_kind} not supported!\")\n\n        self.log_debug(fl_ctx, \"returning model\")\n        base_model[ModelLearnableKey.META] = dxo.get_meta_props()\n        return base_model",
  "def shareable_to_learnable(self, shareable: Shareable, fl_ctx: FLContext) -> ModelLearnable:\n        \"\"\"Updates the global model in `Learnable` in encrypted space.\n\n        Args:\n            shareable: shareable\n            fl_ctx: FLContext\n\n        Returns:\n            Learnable object\n        \"\"\"\n        self.log_info(fl_ctx, \"shareable_to_learnable...\")\n        try:\n            return self._shareable_to_learnable(shareable, fl_ctx)\n        except BaseException as e:\n            self.log_exception(fl_ctx, \"error converting shareable to model\")\n            raise ValueError(f\"{self._name} Exception {e}\")",
  "def _get_run_dir(fl_ctx: FLContext):\n    engine = fl_ctx.get_engine()\n    if engine is None:\n        raise RuntimeError(\"engine is missing in fl_ctx.\")\n    job_id = fl_ctx.get_prop(FLContextKey.CURRENT_RUN)\n    if job_id is None:\n        raise RuntimeError(\"job_id is missing in fl_ctx.\")\n    run_dir = engine.get_workspace().get_run_dir(job_id)\n    return run_dir",
  "class NPModelPersistor(ModelPersistor):\n    def __init__(self, model_dir=\"models\", model_name=\"server.npy\"):\n        super().__init__()\n\n        self.model_dir = model_dir\n        self.model_name = model_name\n\n        # This is default model that will be used if not local model is provided.\n        self.default_data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=np.float32)\n\n    def load_model(self, fl_ctx: FLContext) -> ModelLearnable:\n        run_dir = _get_run_dir(fl_ctx)\n        model_path = os.path.join(run_dir, self.model_dir, self.model_name)\n        try:\n            # try loading previous model\n            data = np.load(model_path)\n        except Exception as e:\n            self.log_exception(\n                fl_ctx,\n                f\"Unable to load model from {model_path}: {e}. Using default data instead.\",\n                fire_event=False,\n            )\n            data = self.default_data.copy()\n\n        model_learnable = make_model_learnable(weights={NPConstants.NUMPY_KEY: data}, meta_props={})\n\n        self.log_info(fl_ctx, f\"Loaded initial model: {model_learnable[ModelLearnableKey.WEIGHTS]}\")\n        return model_learnable\n\n    def save_model(self, model_learnable: ModelLearnable, fl_ctx: FLContext):\n        run_dir = _get_run_dir(fl_ctx)\n        model_root_dir = os.path.join(run_dir, self.model_dir)\n        if not os.path.exists(model_root_dir):\n            os.makedirs(model_root_dir)\n\n        model_path = os.path.join(model_root_dir, self.model_name)\n        np.save(model_path, model_learnable[ModelLearnableKey.WEIGHTS][NPConstants.NUMPY_KEY])\n        self.log_info(fl_ctx, f\"Saved numpy model to: {model_path}\")",
  "def __init__(self, model_dir=\"models\", model_name=\"server.npy\"):\n        super().__init__()\n\n        self.model_dir = model_dir\n        self.model_name = model_name\n\n        # This is default model that will be used if not local model is provided.\n        self.default_data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=np.float32)",
  "def load_model(self, fl_ctx: FLContext) -> ModelLearnable:\n        run_dir = _get_run_dir(fl_ctx)\n        model_path = os.path.join(run_dir, self.model_dir, self.model_name)\n        try:\n            # try loading previous model\n            data = np.load(model_path)\n        except Exception as e:\n            self.log_exception(\n                fl_ctx,\n                f\"Unable to load model from {model_path}: {e}. Using default data instead.\",\n                fire_event=False,\n            )\n            data = self.default_data.copy()\n\n        model_learnable = make_model_learnable(weights={NPConstants.NUMPY_KEY: data}, meta_props={})\n\n        self.log_info(fl_ctx, f\"Loaded initial model: {model_learnable[ModelLearnableKey.WEIGHTS]}\")\n        return model_learnable",
  "def save_model(self, model_learnable: ModelLearnable, fl_ctx: FLContext):\n        run_dir = _get_run_dir(fl_ctx)\n        model_root_dir = os.path.join(run_dir, self.model_dir)\n        if not os.path.exists(model_root_dir):\n            os.makedirs(model_root_dir)\n\n        model_path = os.path.join(model_root_dir, self.model_name)\n        np.save(model_path, model_learnable[ModelLearnableKey.WEIGHTS][NPConstants.NUMPY_KEY])\n        self.log_info(fl_ctx, f\"Saved numpy model to: {model_path}\")",
  "class NPConstants:\n    NUMPY_KEY = \"numpy_key\"",
  "class NPModelLocator(ModelLocator):\n    SERVER_MODEL_NAME = \"server\"\n\n    def __init__(self, model_dir=\"models\", model_name=\"server.npy\"):\n        \"\"\"The ModelLocator's job is to find the models to be included for cross site evaluation\n        located on server. This NPModelLocator finds and extracts \"server\" model that is saved during training.\n\n        Args:\n            model_dir (str): Directory to look for models in. Defaults to \"model\"\n            model_name (str). Name of the model. Defaults to \"server.npy\"\n        \"\"\"\n        super().__init__()\n\n        self.model_dir = model_dir\n        self.model_file_name = model_name\n\n    def get_model_names(self, fl_ctx: FLContext) -> List[str]:\n        \"\"\"Returns the list of model names that should be included from server in cross site validation.add()\n\n        Args:\n            fl_ctx (FLContext): FL Context object.\n\n        Returns:\n            List[str]: List of model names.\n        \"\"\"\n        return [NPModelLocator.SERVER_MODEL_NAME]\n\n    def locate_model(self, model_name, fl_ctx: FLContext) -> DXO:\n        dxo = None\n        engine = fl_ctx.get_engine()\n\n        if model_name == NPModelLocator.SERVER_MODEL_NAME:\n            try:\n                job_id = fl_ctx.get_prop(FLContextKey.CURRENT_RUN)\n                run_dir = engine.get_workspace().get_run_dir(job_id)\n                model_path = os.path.join(run_dir, self.model_dir)\n\n                model_load_path = os.path.join(model_path, self.model_file_name)\n                np_data = None\n                try:\n                    np_data = np.load(model_load_path, allow_pickle=True)\n                    self.log_info(fl_ctx, f\"Loaded {model_name} model from {model_load_path}.\")\n                except Exception as e:\n                    self.log_error(fl_ctx, f\"Unable to load NP Model: {e}.\")\n\n                if np_data is not None:\n                    weights = {NPConstants.NUMPY_KEY: np_data}\n                    dxo = DXO(data_kind=DataKind.WEIGHTS, data=weights, meta={})\n            except Exception as e:\n                self.log_exception(fl_ctx, f\"Exception in retrieving {NPModelLocator.SERVER_MODEL_NAME} model: {e}.\")\n\n        return dxo",
  "def __init__(self, model_dir=\"models\", model_name=\"server.npy\"):\n        \"\"\"The ModelLocator's job is to find the models to be included for cross site evaluation\n        located on server. This NPModelLocator finds and extracts \"server\" model that is saved during training.\n\n        Args:\n            model_dir (str): Directory to look for models in. Defaults to \"model\"\n            model_name (str). Name of the model. Defaults to \"server.npy\"\n        \"\"\"\n        super().__init__()\n\n        self.model_dir = model_dir\n        self.model_file_name = model_name",
  "def get_model_names(self, fl_ctx: FLContext) -> List[str]:\n        \"\"\"Returns the list of model names that should be included from server in cross site validation.add()\n\n        Args:\n            fl_ctx (FLContext): FL Context object.\n\n        Returns:\n            List[str]: List of model names.\n        \"\"\"\n        return [NPModelLocator.SERVER_MODEL_NAME]",
  "def locate_model(self, model_name, fl_ctx: FLContext) -> DXO:\n        dxo = None\n        engine = fl_ctx.get_engine()\n\n        if model_name == NPModelLocator.SERVER_MODEL_NAME:\n            try:\n                job_id = fl_ctx.get_prop(FLContextKey.CURRENT_RUN)\n                run_dir = engine.get_workspace().get_run_dir(job_id)\n                model_path = os.path.join(run_dir, self.model_dir)\n\n                model_load_path = os.path.join(model_path, self.model_file_name)\n                np_data = None\n                try:\n                    np_data = np.load(model_load_path, allow_pickle=True)\n                    self.log_info(fl_ctx, f\"Loaded {model_name} model from {model_load_path}.\")\n                except Exception as e:\n                    self.log_error(fl_ctx, f\"Unable to load NP Model: {e}.\")\n\n                if np_data is not None:\n                    weights = {NPConstants.NUMPY_KEY: np_data}\n                    dxo = DXO(data_kind=DataKind.WEIGHTS, data=weights, meta={})\n            except Exception as e:\n                self.log_exception(fl_ctx, f\"Exception in retrieving {NPModelLocator.SERVER_MODEL_NAME} model: {e}.\")\n\n        return dxo",
  "class NPTrainer(Executor):\n    def __init__(\n        self,\n        delta=1,\n        sleep_time=0,\n        train_task_name=AppConstants.TASK_TRAIN,\n        submit_model_task_name=AppConstants.TASK_SUBMIT_MODEL,\n        model_name=\"best_numpy.npy\",\n        model_dir=\"model\",\n    ):\n        # Init functions of components should be very minimal. Init\n        # is called when json is read. A big init will cause json loading to halt\n        # for long time.\n        super().__init__()\n\n        if not (isinstance(delta, float) or isinstance(delta, int)):\n            raise TypeError(\"delta must be an instance of float or int.\")\n\n        self._delta = delta\n        self._model_name = model_name\n        self._model_dir = model_dir\n        self._sleep_time = sleep_time\n        self._train_task_name = train_task_name\n        self._submit_model_task_name = submit_model_task_name\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        # if event_type == EventType.START_RUN:\n        #     Create all major components here. This is a simple app that doesn't need any components.\n        # elif event_type == EventType.END_RUN:\n        #     # Clean up resources (closing files, joining threads, removing dirs etc.)\n        pass\n\n    def _train(self, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal):\n        # First we extract DXO from the shareable.\n        try:\n            incoming_dxo = from_shareable(shareable)\n        except BaseException as e:\n            self.system_panic(f\"Unable to convert shareable to model definition. Exception {e.__str__()}\", fl_ctx)\n            return make_reply(ReturnCode.BAD_TASK_DATA)\n\n        # Information about workflow is retrieved from the shareable header.\n        current_round = shareable.get_header(AppConstants.CURRENT_ROUND, None)\n        total_rounds = shareable.get_header(AppConstants.NUM_ROUNDS, None)\n\n        # Ensure that data is of type weights. Extract model data.\n        if incoming_dxo.data_kind != DataKind.WEIGHTS:\n            self.system_panic(\"Model DXO should be of kind DataKind.WEIGHTS.\", fl_ctx)\n            return make_reply(ReturnCode.BAD_TASK_DATA)\n        np_data = incoming_dxo.data\n\n        # Display properties.\n        self.log_info(fl_ctx, f\"Incoming data kind: {incoming_dxo.data_kind}\")\n        self.log_info(fl_ctx, f\"Model: \\n{np_data}\")\n        self.log_info(fl_ctx, f\"Current Round: {current_round}\")\n        self.log_info(fl_ctx, f\"Total Rounds: {total_rounds}\")\n        self.log_info(fl_ctx, f\"Client identity: {fl_ctx.get_identity_name()}\")\n\n        # Check abort signal\n        if abort_signal.triggered:\n            return make_reply(ReturnCode.TASK_ABORTED)\n\n        # Doing some dummy training.\n        if np_data:\n            if NPConstants.NUMPY_KEY in np_data:\n                np_data[NPConstants.NUMPY_KEY] += self._delta\n            else:\n                self.log_error(fl_ctx, \"numpy_key not found in model.\")\n                return make_reply(ReturnCode.BAD_TASK_DATA)\n        else:\n            self.log_error(fl_ctx, \"No model weights found in shareable.\")\n            return make_reply(ReturnCode.BAD_TASK_DATA)\n\n        # We check abort_signal regularly to make sure\n        if abort_signal.triggered:\n            return make_reply(ReturnCode.TASK_ABORTED)\n\n        # Save local numpy model\n        try:\n            self._save_local_model(fl_ctx, np_data)\n        except Exception as e:\n            self.log_error(fl_ctx, f\"Exception in saving local model: {e}.\")\n\n        self.log_info(\n            fl_ctx,\n            f\"Model after training: {np_data}\",\n        )\n\n        # Checking abort signal again.\n        if abort_signal.triggered:\n            return make_reply(ReturnCode.TASK_ABORTED)\n\n        # Prepare a DXO for our updated model. Create shareable and return\n        outgoing_dxo = DXO(data_kind=incoming_dxo.data_kind, data=np_data, meta={})\n        return outgoing_dxo.to_shareable()\n\n    def _submit_model(self, fl_ctx: FLContext, abort_signal: Signal):\n        # Retrieve the local model saved during training.\n        np_data = None\n        try:\n            np_data = self._load_local_model(fl_ctx)\n        except Exception as e:\n            self.log_error(fl_ctx, f\"Unable to load model: {e}\")\n\n        # Checking abort signal\n        if abort_signal.triggered:\n            return make_reply(ReturnCode.TASK_ABORTED)\n\n        # Create DXO and shareable from model data.\n        model_shareable = Shareable()\n        if np_data:\n            outgoing_dxo = DXO(data_kind=DataKind.WEIGHTS, data=np_data)\n            model_shareable = outgoing_dxo.to_shareable()\n        else:\n            # Set return code.\n            self.log_error(fl_ctx, \"local model not found.\")\n            model_shareable.set_return_code(ReturnCode.EXECUTION_RESULT_ERROR)\n\n        return model_shareable\n\n    def execute(\n        self,\n        task_name: str,\n        shareable: Shareable,\n        fl_ctx: FLContext,\n        abort_signal: Signal,\n    ) -> Shareable:\n        # Any long tasks should check abort_signal regularly. Otherwise, abort client\n        # will not work.\n        count, interval = 0, 0.5\n        while count < self._sleep_time:\n            if abort_signal.triggered:\n                return make_reply(ReturnCode.TASK_ABORTED)\n            time.sleep(interval)\n            count += interval\n\n        self.log_info(fl_ctx, f\"Task name: {task_name}\")\n        try:\n            if task_name == self._train_task_name:\n                return self._train(shareable=shareable, fl_ctx=fl_ctx, abort_signal=abort_signal)\n            elif task_name == self._submit_model_task_name:\n                return self._submit_model(fl_ctx=fl_ctx, abort_signal=abort_signal)\n            else:\n                # If unknown task name, set RC accordingly.\n                return make_reply(ReturnCode.TASK_UNKNOWN)\n        except Exception as e:\n            self.log_exception(fl_ctx, f\"Exception in NPTrainer execute: {e}.\")\n            return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n\n    def _load_local_model(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        job_id = fl_ctx.get_prop(FLContextKey.CURRENT_RUN)\n        run_dir = engine.get_workspace().get_run_dir(job_id)\n        model_path = os.path.join(run_dir, self._model_dir)\n\n        model_load_path = os.path.join(model_path, self._model_name)\n        try:\n            np_data = np.load(model_load_path)\n        except Exception as e:\n            self.log_error(fl_ctx, f\"Unable to load local model: {e.__str__()}\")\n            return None\n\n        model = ModelLearnable()\n        model[NPConstants.NUMPY_KEY] = np_data\n\n        return model\n\n    def _save_local_model(self, fl_ctx: FLContext, model: dict):\n        # Save local model\n        engine = fl_ctx.get_engine()\n        job_id = fl_ctx.get_prop(FLContextKey.CURRENT_RUN)\n        run_dir = engine.get_workspace().get_run_dir(job_id)\n        model_path = os.path.join(run_dir, self._model_dir)\n        if not os.path.exists(model_path):\n            os.makedirs(model_path)\n\n        model_save_path = os.path.join(model_path, self._model_name)\n        np.save(model_save_path, model[NPConstants.NUMPY_KEY])\n        self.log_info(fl_ctx, f\"Saved numpy model to: {model_save_path}\")",
  "def __init__(\n        self,\n        delta=1,\n        sleep_time=0,\n        train_task_name=AppConstants.TASK_TRAIN,\n        submit_model_task_name=AppConstants.TASK_SUBMIT_MODEL,\n        model_name=\"best_numpy.npy\",\n        model_dir=\"model\",\n    ):\n        # Init functions of components should be very minimal. Init\n        # is called when json is read. A big init will cause json loading to halt\n        # for long time.\n        super().__init__()\n\n        if not (isinstance(delta, float) or isinstance(delta, int)):\n            raise TypeError(\"delta must be an instance of float or int.\")\n\n        self._delta = delta\n        self._model_name = model_name\n        self._model_dir = model_dir\n        self._sleep_time = sleep_time\n        self._train_task_name = train_task_name\n        self._submit_model_task_name = submit_model_task_name",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        # if event_type == EventType.START_RUN:\n        #     Create all major components here. This is a simple app that doesn't need any components.\n        # elif event_type == EventType.END_RUN:\n        #     # Clean up resources (closing files, joining threads, removing dirs etc.)\n        pass",
  "def _train(self, shareable: Shareable, fl_ctx: FLContext, abort_signal: Signal):\n        # First we extract DXO from the shareable.\n        try:\n            incoming_dxo = from_shareable(shareable)\n        except BaseException as e:\n            self.system_panic(f\"Unable to convert shareable to model definition. Exception {e.__str__()}\", fl_ctx)\n            return make_reply(ReturnCode.BAD_TASK_DATA)\n\n        # Information about workflow is retrieved from the shareable header.\n        current_round = shareable.get_header(AppConstants.CURRENT_ROUND, None)\n        total_rounds = shareable.get_header(AppConstants.NUM_ROUNDS, None)\n\n        # Ensure that data is of type weights. Extract model data.\n        if incoming_dxo.data_kind != DataKind.WEIGHTS:\n            self.system_panic(\"Model DXO should be of kind DataKind.WEIGHTS.\", fl_ctx)\n            return make_reply(ReturnCode.BAD_TASK_DATA)\n        np_data = incoming_dxo.data\n\n        # Display properties.\n        self.log_info(fl_ctx, f\"Incoming data kind: {incoming_dxo.data_kind}\")\n        self.log_info(fl_ctx, f\"Model: \\n{np_data}\")\n        self.log_info(fl_ctx, f\"Current Round: {current_round}\")\n        self.log_info(fl_ctx, f\"Total Rounds: {total_rounds}\")\n        self.log_info(fl_ctx, f\"Client identity: {fl_ctx.get_identity_name()}\")\n\n        # Check abort signal\n        if abort_signal.triggered:\n            return make_reply(ReturnCode.TASK_ABORTED)\n\n        # Doing some dummy training.\n        if np_data:\n            if NPConstants.NUMPY_KEY in np_data:\n                np_data[NPConstants.NUMPY_KEY] += self._delta\n            else:\n                self.log_error(fl_ctx, \"numpy_key not found in model.\")\n                return make_reply(ReturnCode.BAD_TASK_DATA)\n        else:\n            self.log_error(fl_ctx, \"No model weights found in shareable.\")\n            return make_reply(ReturnCode.BAD_TASK_DATA)\n\n        # We check abort_signal regularly to make sure\n        if abort_signal.triggered:\n            return make_reply(ReturnCode.TASK_ABORTED)\n\n        # Save local numpy model\n        try:\n            self._save_local_model(fl_ctx, np_data)\n        except Exception as e:\n            self.log_error(fl_ctx, f\"Exception in saving local model: {e}.\")\n\n        self.log_info(\n            fl_ctx,\n            f\"Model after training: {np_data}\",\n        )\n\n        # Checking abort signal again.\n        if abort_signal.triggered:\n            return make_reply(ReturnCode.TASK_ABORTED)\n\n        # Prepare a DXO for our updated model. Create shareable and return\n        outgoing_dxo = DXO(data_kind=incoming_dxo.data_kind, data=np_data, meta={})\n        return outgoing_dxo.to_shareable()",
  "def _submit_model(self, fl_ctx: FLContext, abort_signal: Signal):\n        # Retrieve the local model saved during training.\n        np_data = None\n        try:\n            np_data = self._load_local_model(fl_ctx)\n        except Exception as e:\n            self.log_error(fl_ctx, f\"Unable to load model: {e}\")\n\n        # Checking abort signal\n        if abort_signal.triggered:\n            return make_reply(ReturnCode.TASK_ABORTED)\n\n        # Create DXO and shareable from model data.\n        model_shareable = Shareable()\n        if np_data:\n            outgoing_dxo = DXO(data_kind=DataKind.WEIGHTS, data=np_data)\n            model_shareable = outgoing_dxo.to_shareable()\n        else:\n            # Set return code.\n            self.log_error(fl_ctx, \"local model not found.\")\n            model_shareable.set_return_code(ReturnCode.EXECUTION_RESULT_ERROR)\n\n        return model_shareable",
  "def execute(\n        self,\n        task_name: str,\n        shareable: Shareable,\n        fl_ctx: FLContext,\n        abort_signal: Signal,\n    ) -> Shareable:\n        # Any long tasks should check abort_signal regularly. Otherwise, abort client\n        # will not work.\n        count, interval = 0, 0.5\n        while count < self._sleep_time:\n            if abort_signal.triggered:\n                return make_reply(ReturnCode.TASK_ABORTED)\n            time.sleep(interval)\n            count += interval\n\n        self.log_info(fl_ctx, f\"Task name: {task_name}\")\n        try:\n            if task_name == self._train_task_name:\n                return self._train(shareable=shareable, fl_ctx=fl_ctx, abort_signal=abort_signal)\n            elif task_name == self._submit_model_task_name:\n                return self._submit_model(fl_ctx=fl_ctx, abort_signal=abort_signal)\n            else:\n                # If unknown task name, set RC accordingly.\n                return make_reply(ReturnCode.TASK_UNKNOWN)\n        except Exception as e:\n            self.log_exception(fl_ctx, f\"Exception in NPTrainer execute: {e}.\")\n            return make_reply(ReturnCode.EXECUTION_EXCEPTION)",
  "def _load_local_model(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        job_id = fl_ctx.get_prop(FLContextKey.CURRENT_RUN)\n        run_dir = engine.get_workspace().get_run_dir(job_id)\n        model_path = os.path.join(run_dir, self._model_dir)\n\n        model_load_path = os.path.join(model_path, self._model_name)\n        try:\n            np_data = np.load(model_load_path)\n        except Exception as e:\n            self.log_error(fl_ctx, f\"Unable to load local model: {e.__str__()}\")\n            return None\n\n        model = ModelLearnable()\n        model[NPConstants.NUMPY_KEY] = np_data\n\n        return model",
  "def _save_local_model(self, fl_ctx: FLContext, model: dict):\n        # Save local model\n        engine = fl_ctx.get_engine()\n        job_id = fl_ctx.get_prop(FLContextKey.CURRENT_RUN)\n        run_dir = engine.get_workspace().get_run_dir(job_id)\n        model_path = os.path.join(run_dir, self._model_dir)\n        if not os.path.exists(model_path):\n            os.makedirs(model_path)\n\n        model_save_path = os.path.join(model_path, self._model_name)\n        np.save(model_save_path, model[NPConstants.NUMPY_KEY])\n        self.log_info(fl_ctx, f\"Saved numpy model to: {model_save_path}\")",
  "class NPValidator(Executor):\n    def __init__(\n        self,\n        epsilon=1,\n        sleep_time=0,\n        validate_task_name=AppConstants.TASK_VALIDATION,\n    ):\n        # Init functions of components should be very minimal. Init\n        # is called when json is read. A big init will cause json loading to halt\n        # for long time.\n        super().__init__()\n\n        self.logger = logging.getLogger(\"NPValidator\")\n        self._random_epsilon = epsilon\n        self._sleep_time = sleep_time\n        self._validate_task_name = validate_task_name\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        # if event_type == EventType.START_RUN:\n        #     Create all major components here. This is a simple app that doesn't need any components.\n        # elif event_type == EventType.END_RUN:\n        #     # Clean up resources (closing files, joining threads, removing dirs etc.)\n        pass\n\n    def execute(\n        self,\n        task_name: str,\n        shareable: Shareable,\n        fl_ctx: FLContext,\n        abort_signal: Signal,\n    ) -> Shareable:\n        # Any long tasks should check abort_signal regularly.\n        # Otherwise, abort client will not work.\n        count, interval = 0, 0.5\n        while count < self._sleep_time:\n            if abort_signal.triggered:\n                return make_reply(ReturnCode.TASK_ABORTED)\n            time.sleep(interval)\n            count += interval\n\n        if task_name == self._validate_task_name:\n            try:\n                # First we extract DXO from the shareable.\n                try:\n                    model_dxo = from_shareable(shareable)\n                except Exception as e:\n                    self.log_error(fl_ctx, f\"Unable to extract model dxo from shareable. Exception: {e.__str__()}\")\n                    return make_reply(ReturnCode.BAD_TASK_DATA)\n\n                # Get model from shareable. data_kind must be WEIGHTS.\n                if model_dxo.data and model_dxo.data_kind == DataKind.WEIGHTS:\n                    model = model_dxo.data\n                else:\n                    self.log_error(\n                        fl_ctx, \"Model DXO doesn't have data or is not of type DataKind.WEIGHTS. Unable to validate.\"\n                    )\n                    return make_reply(ReturnCode.BAD_TASK_DATA)\n\n                # Check if key exists in model\n                if NPConstants.NUMPY_KEY not in model:\n                    self.log_error(fl_ctx, \"numpy_key not in model. Unable to validate.\")\n                    return make_reply(ReturnCode.BAD_TASK_DATA)\n\n                # The workflow provides MODEL_OWNER information in the shareable header.\n                model_name = shareable.get_header(AppConstants.MODEL_OWNER, \"?\")\n\n                # Print properties.\n                self.log_info(fl_ctx, f\"Model: \\n{model}\")\n                self.log_info(fl_ctx, f\"Task name: {task_name}\")\n                self.log_info(fl_ctx, f\"Client identity: {fl_ctx.get_identity_name()}\")\n                self.log_info(fl_ctx, f\"Validating model from {model_name}.\")\n\n                # Check abort signal regularly.\n                if abort_signal.triggered:\n                    return make_reply(ReturnCode.TASK_ABORTED)\n\n                # Do some dummy validation.\n                random_epsilon = np.random.random()\n                self.log_info(fl_ctx, f\"Adding random epsilon {random_epsilon} in validation.\")\n                val_results = {}\n                np_data = model[NPConstants.NUMPY_KEY]\n                np_data = np.sum(np_data / np.max(np_data))\n                val_results[\"accuracy\"] = np_data + random_epsilon\n\n                # Check abort signal regularly.\n                if abort_signal.triggered:\n                    return make_reply(ReturnCode.TASK_ABORTED)\n\n                self.log_info(fl_ctx, f\"Validation result: {val_results}\")\n\n                # Create DXO for metrics and return shareable.\n                metric_dxo = DXO(data_kind=DataKind.METRICS, data=val_results)\n                return metric_dxo.to_shareable()\n            except Exception as e:\n                self.log_exception(fl_ctx, f\"Exception in NPValidator execute: {e}.\")\n                return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n        else:\n            return make_reply(ReturnCode.TASK_UNKNOWN)",
  "def __init__(\n        self,\n        epsilon=1,\n        sleep_time=0,\n        validate_task_name=AppConstants.TASK_VALIDATION,\n    ):\n        # Init functions of components should be very minimal. Init\n        # is called when json is read. A big init will cause json loading to halt\n        # for long time.\n        super().__init__()\n\n        self.logger = logging.getLogger(\"NPValidator\")\n        self._random_epsilon = epsilon\n        self._sleep_time = sleep_time\n        self._validate_task_name = validate_task_name",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        # if event_type == EventType.START_RUN:\n        #     Create all major components here. This is a simple app that doesn't need any components.\n        # elif event_type == EventType.END_RUN:\n        #     # Clean up resources (closing files, joining threads, removing dirs etc.)\n        pass",
  "def execute(\n        self,\n        task_name: str,\n        shareable: Shareable,\n        fl_ctx: FLContext,\n        abort_signal: Signal,\n    ) -> Shareable:\n        # Any long tasks should check abort_signal regularly.\n        # Otherwise, abort client will not work.\n        count, interval = 0, 0.5\n        while count < self._sleep_time:\n            if abort_signal.triggered:\n                return make_reply(ReturnCode.TASK_ABORTED)\n            time.sleep(interval)\n            count += interval\n\n        if task_name == self._validate_task_name:\n            try:\n                # First we extract DXO from the shareable.\n                try:\n                    model_dxo = from_shareable(shareable)\n                except Exception as e:\n                    self.log_error(fl_ctx, f\"Unable to extract model dxo from shareable. Exception: {e.__str__()}\")\n                    return make_reply(ReturnCode.BAD_TASK_DATA)\n\n                # Get model from shareable. data_kind must be WEIGHTS.\n                if model_dxo.data and model_dxo.data_kind == DataKind.WEIGHTS:\n                    model = model_dxo.data\n                else:\n                    self.log_error(\n                        fl_ctx, \"Model DXO doesn't have data or is not of type DataKind.WEIGHTS. Unable to validate.\"\n                    )\n                    return make_reply(ReturnCode.BAD_TASK_DATA)\n\n                # Check if key exists in model\n                if NPConstants.NUMPY_KEY not in model:\n                    self.log_error(fl_ctx, \"numpy_key not in model. Unable to validate.\")\n                    return make_reply(ReturnCode.BAD_TASK_DATA)\n\n                # The workflow provides MODEL_OWNER information in the shareable header.\n                model_name = shareable.get_header(AppConstants.MODEL_OWNER, \"?\")\n\n                # Print properties.\n                self.log_info(fl_ctx, f\"Model: \\n{model}\")\n                self.log_info(fl_ctx, f\"Task name: {task_name}\")\n                self.log_info(fl_ctx, f\"Client identity: {fl_ctx.get_identity_name()}\")\n                self.log_info(fl_ctx, f\"Validating model from {model_name}.\")\n\n                # Check abort signal regularly.\n                if abort_signal.triggered:\n                    return make_reply(ReturnCode.TASK_ABORTED)\n\n                # Do some dummy validation.\n                random_epsilon = np.random.random()\n                self.log_info(fl_ctx, f\"Adding random epsilon {random_epsilon} in validation.\")\n                val_results = {}\n                np_data = model[NPConstants.NUMPY_KEY]\n                np_data = np.sum(np_data / np.max(np_data))\n                val_results[\"accuracy\"] = np_data + random_epsilon\n\n                # Check abort signal regularly.\n                if abort_signal.triggered:\n                    return make_reply(ReturnCode.TASK_ABORTED)\n\n                self.log_info(fl_ctx, f\"Validation result: {val_results}\")\n\n                # Create DXO for metrics and return shareable.\n                metric_dxo = DXO(data_kind=DataKind.METRICS, data=val_results)\n                return metric_dxo.to_shareable()\n            except Exception as e:\n                self.log_exception(fl_ctx, f\"Exception in NPValidator execute: {e}.\")\n                return make_reply(ReturnCode.EXECUTION_EXCEPTION)\n        else:\n            return make_reply(ReturnCode.TASK_UNKNOWN)",
  "class NPFormatter(Formatter):\n    def __init__(self) -> None:\n        super().__init__()\n\n    def format(self, fl_ctx: FLContext) -> str:\n        \"\"\"The format function gets validation shareable locations from the dictionary. It loads each shareable,\n        get the validation results and converts it into human-readable string.\n\n        Args:\n            fl_ctx (FLContext): FLContext object.\n\n        Returns:\n            str: Human readable validation results.\n        \"\"\"\n        # Get the val shareables\n        validation_shareables_dict = fl_ctx.get_prop(AppConstants.VALIDATION_RESULT, {})\n\n        # Result dictionary\n        res = {}\n\n        try:\n            # This is a 2d dictionary with each validation result at\n            # validation_shareables_dict[data_client][model_client]\n            for data_client in validation_shareables_dict.keys():\n                validation_dict = validation_shareables_dict[data_client]\n                if validation_dict:\n                    res[data_client] = {}\n                    for model_name in validation_dict.keys():\n                        dxo_path = validation_dict[model_name]\n\n                        # Load the shareable\n                        with open(dxo_path, \"rb\") as f:\n                            metric_dxo = from_bytes(f.read())\n\n                        # Get metrics from shareable\n                        if metric_dxo and metric_dxo.data_kind == DataKind.METRICS:\n                            metrics = metric_dxo.data\n                            res[data_client][model_name] = metrics\n        except Exception as e:\n            self.log_error(fl_ctx, f\"Exception: {e.__str__()}\")\n\n        return f\"{res}\"",
  "def __init__(self) -> None:\n        super().__init__()",
  "def format(self, fl_ctx: FLContext) -> str:\n        \"\"\"The format function gets validation shareable locations from the dictionary. It loads each shareable,\n        get the validation results and converts it into human-readable string.\n\n        Args:\n            fl_ctx (FLContext): FLContext object.\n\n        Returns:\n            str: Human readable validation results.\n        \"\"\"\n        # Get the val shareables\n        validation_shareables_dict = fl_ctx.get_prop(AppConstants.VALIDATION_RESULT, {})\n\n        # Result dictionary\n        res = {}\n\n        try:\n            # This is a 2d dictionary with each validation result at\n            # validation_shareables_dict[data_client][model_client]\n            for data_client in validation_shareables_dict.keys():\n                validation_dict = validation_shareables_dict[data_client]\n                if validation_dict:\n                    res[data_client] = {}\n                    for model_name in validation_dict.keys():\n                        dxo_path = validation_dict[model_name]\n\n                        # Load the shareable\n                        with open(dxo_path, \"rb\") as f:\n                            metric_dxo = from_bytes(f.read())\n\n                        # Get metrics from shareable\n                        if metric_dxo and metric_dxo.data_kind == DataKind.METRICS:\n                            metrics = metric_dxo.data\n                            res[data_client][model_name] = metrics\n        except Exception as e:\n            self.log_error(fl_ctx, f\"Exception: {e.__str__()}\")\n\n        return f\"{res}\"",
  "class Learnable(dict):\n    def to_bytes(self) -> bytes:\n        \"\"\"Method to serialize the Learnable object into bytes.\n\n        Returns:\n            object serialized in bytes.\n\n        \"\"\"\n        return pickle.dumps(self)\n\n    @classmethod\n    def from_bytes(cls, data: bytes):\n        \"\"\"Method to convert the object bytes into Learnable object.\n\n        Args:\n            data: a bytes object\n\n        Returns:\n            an object loaded by pickle from data\n\n        \"\"\"\n        return pickle.loads(data)",
  "def to_bytes(self) -> bytes:\n        \"\"\"Method to serialize the Learnable object into bytes.\n\n        Returns:\n            object serialized in bytes.\n\n        \"\"\"\n        return pickle.dumps(self)",
  "def from_bytes(cls, data: bytes):\n        \"\"\"Method to convert the object bytes into Learnable object.\n\n        Args:\n            data: a bytes object\n\n        Returns:\n            an object loaded by pickle from data\n\n        \"\"\"\n        return pickle.loads(data)",
  "class ModelLocator(FLComponent):\n    def get_model_names(self, fl_ctx: FLContext) -> List[str]:\n        \"\"\"List the name of the models.\n\n        Args:\n            fl_ctx (FLContext): FL Context object\n\n        Returns:\n            List[str]: List of names for models\n        \"\"\"\n        pass\n\n    def locate_model(self, model_name, fl_ctx: FLContext) -> DXO:\n        \"\"\"Locate a single model by it's name.\n\n        Args:\n            model_name (str): Name of the model.\n            fl_ctx (FLContext): FL Context object.\n\n        Returns:\n            DXO: a DXO object\n        \"\"\"\n        pass",
  "def get_model_names(self, fl_ctx: FLContext) -> List[str]:\n        \"\"\"List the name of the models.\n\n        Args:\n            fl_ctx (FLContext): FL Context object\n\n        Returns:\n            List[str]: List of names for models\n        \"\"\"\n        pass",
  "def locate_model(self, model_name, fl_ctx: FLContext) -> DXO:\n        \"\"\"Locate a single model by it's name.\n\n        Args:\n            model_name (str): Name of the model.\n            fl_ctx (FLContext): FL Context object.\n\n        Returns:\n            DXO: a DXO object\n        \"\"\"\n        pass",
  "class Aggregator(FLComponent, ABC):\n    @abstractmethod\n    def accept(self, shareable: Shareable, fl_ctx: FLContext) -> bool:\n        \"\"\"Accept the shareable submitted by the client.\n\n        Args:\n            shareable: submitted Shareable object\n            fl_ctx: FLContext\n\n        Returns:\n            first boolean to indicate if the contribution has been accepted.\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def aggregate(self, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Perform the aggregation for all the received Shareable from the clients.\n\n        Args:\n            fl_ctx: FLContext\n\n        Returns:\n            shareable\n        \"\"\"\n        pass",
  "def accept(self, shareable: Shareable, fl_ctx: FLContext) -> bool:\n        \"\"\"Accept the shareable submitted by the client.\n\n        Args:\n            shareable: submitted Shareable object\n            fl_ctx: FLContext\n\n        Returns:\n            first boolean to indicate if the contribution has been accepted.\n\n        \"\"\"\n        pass",
  "def aggregate(self, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Perform the aggregation for all the received Shareable from the clients.\n\n        Args:\n            fl_ctx: FLContext\n\n        Returns:\n            shareable\n        \"\"\"\n        pass",
  "class ModelLearnableKey(object):\n    WEIGHTS = \"weights\"\n    META = \"meta\"",
  "def validate_model_learnable(model_learnable: ModelLearnable) -> str:\n    \"\"\"Check whether the specified model is a valid Model Shareable.\n\n    Args:\n        model_learnable (ModelLearnable): model to be validated\n\n    Returns:\n        str: error text or empty string if no error\n    \"\"\"\n    if not isinstance(model_learnable, ModelLearnable):\n        return \"invalid model learnable: expect Model type but got {}\".format(type(model_learnable))\n\n    if ModelLearnableKey.WEIGHTS not in model_learnable:\n        return \"invalid model learnable: missing weights\"\n\n    if ModelLearnableKey.META not in model_learnable:\n        return \"invalid model learnable: missing meta\"\n\n    return \"\"",
  "def make_model_learnable(weights, meta_props) -> ModelLearnable:\n    ml = ModelLearnable()\n    ml[ModelLearnableKey.WEIGHTS] = weights\n    ml[ModelLearnableKey.META] = meta_props\n    return ml",
  "def model_learnable_to_dxo(ml: ModelLearnable) -> DXO:\n    err = validate_model_learnable(ml)\n    if err:\n        raise ValueError(err)\n\n    return DXO(data_kind=DataKind.WEIGHTS, data=ml[ModelLearnableKey.WEIGHTS], meta=ml[ModelLearnableKey.META])",
  "class ShareableGenerator(FLComponent, ABC):\n    @abstractmethod\n    def learnable_to_shareable(self, model: Learnable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Generate the initial Shareable from the Learnable object.\n\n        Args:\n            model: model object\n            fl_ctx: FLContext\n\n        Returns:\n            shareable\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def shareable_to_learnable(self, shareable: Shareable, fl_ctx: FLContext) -> Learnable:\n        \"\"\"Construct the Learnable object from Shareable.\n\n        Args:\n            shareable: shareable\n            fl_ctx: FLContext\n\n        Returns:\n            model object\n\n        \"\"\"\n        pass",
  "def learnable_to_shareable(self, model: Learnable, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Generate the initial Shareable from the Learnable object.\n\n        Args:\n            model: model object\n            fl_ctx: FLContext\n\n        Returns:\n            shareable\n\n        \"\"\"\n        pass",
  "def shareable_to_learnable(self, shareable: Shareable, fl_ctx: FLContext) -> Learnable:\n        \"\"\"Construct the Learnable object from Shareable.\n\n        Args:\n            shareable: shareable\n            fl_ctx: FLContext\n\n        Returns:\n            model object\n\n        \"\"\"\n        pass",
  "class Formatter(FLComponent):\n    @abstractmethod\n    def format(self, fl_ctx: FLContext) -> str:\n        \"\"\"Format the data into human readable string.\n\n        Args:\n            fl_ctx (FLContext): FL Context object.\n\n        Returns:\n            str: Human readable string.\n        \"\"\"\n        pass",
  "def format(self, fl_ctx: FLContext) -> str:\n        \"\"\"Format the data into human readable string.\n\n        Args:\n            fl_ctx (FLContext): FL Context object.\n\n        Returns:\n            str: Human readable string.\n        \"\"\"\n        pass",
  "class LearnablePersistor(FLComponent, ABC):\n    @abstractmethod\n    def load(self, fl_ctx: FLContext) -> Learnable:\n        \"\"\"Load the Learnable object.\n\n        Args:\n            fl_ctx: FLContext\n\n        Returns:\n            Learnable object loaded\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def save(self, learnable: Learnable, fl_ctx: FLContext):\n        \"\"\"Persist the Learnable object.\n\n        Args:\n            learnable: the Learnable object to be saved\n            fl_ctx: FLContext\n\n        \"\"\"\n        pass",
  "def load(self, fl_ctx: FLContext) -> Learnable:\n        \"\"\"Load the Learnable object.\n\n        Args:\n            fl_ctx: FLContext\n\n        Returns:\n            Learnable object loaded\n\n        \"\"\"\n        pass",
  "def save(self, learnable: Learnable, fl_ctx: FLContext):\n        \"\"\"Persist the Learnable object.\n\n        Args:\n            learnable: the Learnable object to be saved\n            fl_ctx: FLContext\n\n        \"\"\"\n        pass",
  "class ModelProcessor(ABC):\n    @abstractmethod\n    def extract_model(self, network, multi_processes: bool, model_vars: dict, fl_ctx: FLContext) -> dict:\n        \"\"\"Call to extract the current model from the training network.\n\n        Args:\n            network: training network\n            multi_processes: boolean to indicates if it's a multi-processes\n            model_vars: global model dict\n            fl_ctx: FLContext\n\n        Returns:\n            a dictionary representing the model\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def apply_model(self, network, multi_processes: bool, model_params: dict, fl_ctx: FLContext, options=None):\n        \"\"\"Call to apply the model parameters to the training network.\n\n        Args:\n            network: training network\n            multi_processes: boolean to indicates if it's a multi-processes\n            model_params: model parameters to apply\n            fl_ctx: FLContext\n            options: optional information that can be used for this process\n\n        \"\"\"\n        pass",
  "def extract_model(self, network, multi_processes: bool, model_vars: dict, fl_ctx: FLContext) -> dict:\n        \"\"\"Call to extract the current model from the training network.\n\n        Args:\n            network: training network\n            multi_processes: boolean to indicates if it's a multi-processes\n            model_vars: global model dict\n            fl_ctx: FLContext\n\n        Returns:\n            a dictionary representing the model\n        \"\"\"\n        pass",
  "def apply_model(self, network, multi_processes: bool, model_params: dict, fl_ctx: FLContext, options=None):\n        \"\"\"Call to apply the model parameters to the training network.\n\n        Args:\n            network: training network\n            multi_processes: boolean to indicates if it's a multi-processes\n            model_params: model parameters to apply\n            fl_ctx: FLContext\n            options: optional information that can be used for this process\n\n        \"\"\"\n        pass",
  "class Learner(FLComponent):\n    def initialize(self, parts: dict, fl_ctx: FLContext):\n        \"\"\"Initialize the Learner object. This is called before the Learner can train or validate.\n\n        This is called only once.\n\n        Args:\n            parts: components to be used by the Trainer\n            fl_ctx: FLContext of the running environment\n        \"\"\"\n        pass\n\n    def train(self, data: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        \"\"\"Called to perform training. Can be called many times during the lifetime of the Learner.\n\n        Args:\n            data: the training input data (e.g. model weights)\n            fl_ctx: FLContext of the running environment\n            abort_signal: signal to abort the train\n\n        Returns: train result in Shareable\n\n        \"\"\"\n        return make_reply(ReturnCode.TASK_UNSUPPORTED)\n\n    def get_model_for_validation(self, model_name: str, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Called to return the trained model from the Learner.\n\n        Args:\n            model_name: type of the model for validation\n            fl_ctx: FLContext of the running environment\n\n        Returns: trained model for validation\n\n        \"\"\"\n        return make_reply(ReturnCode.TASK_UNSUPPORTED)\n\n    def validate(self, data: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        \"\"\"Called to perform validation. Can be called many times during the lifetime of the Learner.\n\n        Args:\n            data: the training input data (e.g. model weights)\n            fl_ctx: FLContext of the running environment\n            abort_signal: signal to abort the train\n\n        Returns: validate result in Shareable\n\n        \"\"\"\n        return make_reply(ReturnCode.TASK_UNSUPPORTED)\n\n    def abort(self, fl_ctx: FLContext):\n        \"\"\"Called (from another thread) to abort the current task (validate or train).\n\n        Note: this is to abort the current task only, not the Trainer. After aborting, the Learner.\n        may still be called to perform another task.\n\n        Args:\n            fl_ctx: FLContext of the running environment\n\n        \"\"\"\n        pass\n\n    def finalize(self, fl_ctx: FLContext):\n        \"\"\"Called to finalize the Learner (close/release resources gracefully).\n\n        After this call, the Learner will be destroyed.\n\n        Args:\n            fl_ctx: FLContext of the running environment\n\n        \"\"\"\n        pass",
  "def initialize(self, parts: dict, fl_ctx: FLContext):\n        \"\"\"Initialize the Learner object. This is called before the Learner can train or validate.\n\n        This is called only once.\n\n        Args:\n            parts: components to be used by the Trainer\n            fl_ctx: FLContext of the running environment\n        \"\"\"\n        pass",
  "def train(self, data: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        \"\"\"Called to perform training. Can be called many times during the lifetime of the Learner.\n\n        Args:\n            data: the training input data (e.g. model weights)\n            fl_ctx: FLContext of the running environment\n            abort_signal: signal to abort the train\n\n        Returns: train result in Shareable\n\n        \"\"\"\n        return make_reply(ReturnCode.TASK_UNSUPPORTED)",
  "def get_model_for_validation(self, model_name: str, fl_ctx: FLContext) -> Shareable:\n        \"\"\"Called to return the trained model from the Learner.\n\n        Args:\n            model_name: type of the model for validation\n            fl_ctx: FLContext of the running environment\n\n        Returns: trained model for validation\n\n        \"\"\"\n        return make_reply(ReturnCode.TASK_UNSUPPORTED)",
  "def validate(self, data: Shareable, fl_ctx: FLContext, abort_signal: Signal) -> Shareable:\n        \"\"\"Called to perform validation. Can be called many times during the lifetime of the Learner.\n\n        Args:\n            data: the training input data (e.g. model weights)\n            fl_ctx: FLContext of the running environment\n            abort_signal: signal to abort the train\n\n        Returns: validate result in Shareable\n\n        \"\"\"\n        return make_reply(ReturnCode.TASK_UNSUPPORTED)",
  "def abort(self, fl_ctx: FLContext):\n        \"\"\"Called (from another thread) to abort the current task (validate or train).\n\n        Note: this is to abort the current task only, not the Trainer. After aborting, the Learner.\n        may still be called to perform another task.\n\n        Args:\n            fl_ctx: FLContext of the running environment\n\n        \"\"\"\n        pass",
  "def finalize(self, fl_ctx: FLContext):\n        \"\"\"Called to finalize the Learner (close/release resources gracefully).\n\n        After this call, the Learner will be destroyed.\n\n        Args:\n            fl_ctx: FLContext of the running environment\n\n        \"\"\"\n        pass",
  "class ModelPersistor(LearnablePersistor, ABC):\n    def load(self, fl_ctx: FLContext):\n        return self.load_model(fl_ctx)\n\n    def save(self, learnable: ModelLearnable, fl_ctx: FLContext):\n        self.save_model(learnable, fl_ctx)\n\n    @abstractmethod\n    def load_model(self, fl_ctx: FLContext) -> ModelLearnable:\n        \"\"\"Initialize and load the model.\n\n        Args:\n            fl_ctx: FLContext\n\n        Returns:\n            Model object\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def save_model(self, model: ModelLearnable, fl_ctx: FLContext):\n        \"\"\"Persist the model object.\n\n        Args:\n            model: Model object to be saved\n            fl_ctx: FLContext\n\n        \"\"\"\n        pass\n\n    def get_model_inventory(self, fl_ctx: FLContext) -> {str: ModelDescriptor}:\n        \"\"\"Get the model inventory of the ModelPersister.\n\n        Args:\n            fl_ctx: FLContext\n\n        Returns: { model_kind: ModelDescriptor }\n\n        \"\"\"\n        pass\n\n    def get_model(self, model_file, fl_ctx: FLContext) -> object:\n        pass",
  "def load(self, fl_ctx: FLContext):\n        return self.load_model(fl_ctx)",
  "def save(self, learnable: ModelLearnable, fl_ctx: FLContext):\n        self.save_model(learnable, fl_ctx)",
  "def load_model(self, fl_ctx: FLContext) -> ModelLearnable:\n        \"\"\"Initialize and load the model.\n\n        Args:\n            fl_ctx: FLContext\n\n        Returns:\n            Model object\n\n        \"\"\"\n        pass",
  "def save_model(self, model: ModelLearnable, fl_ctx: FLContext):\n        \"\"\"Persist the model object.\n\n        Args:\n            model: Model object to be saved\n            fl_ctx: FLContext\n\n        \"\"\"\n        pass",
  "def get_model_inventory(self, fl_ctx: FLContext) -> {str: ModelDescriptor}:\n        \"\"\"Get the model inventory of the ModelPersister.\n\n        Args:\n            fl_ctx: FLContext\n\n        Returns: { model_kind: ModelDescriptor }\n\n        \"\"\"\n        pass",
  "def get_model(self, model_file, fl_ctx: FLContext) -> object:\n        pass",
  "class CyclicController(Controller):\n    def __init__(\n        self,\n        num_rounds: int = 5,\n        task_assignment_timeout: int = 10,\n        persistor_id=\"persistor\",\n        shareable_generator_id=\"shareable_generator\",\n        task_name=\"train\",\n    ):\n        \"\"\"A sample implementation to demonstrate how to use relay method for Cyclic Federated Learning.\n\n        Args:\n            num_rounds (int, optional): number of rounds this controller should perform. Defaults to 5.\n            task_assignment_timeout (int, optional): timeout (in sec) to determine if one client fails to request the task which it is assigned to . Defaults to 10.\n            persistor_id (str, optional): id of the persistor so this controller can save a global model. Defaults to \"persistor\".\n            shareable_generator_id (str, optional): id of shareable generator. Defaults to \"shareable_generator\".\n            task_name (str, optional): the task name that clients know how to handle. Defaults to \"train\".\n\n        Raises:\n            TypeError: when any of input arguments does not have correct type\n        \"\"\"\n        super().__init__()\n        if not isinstance(num_rounds, int):\n            raise TypeError(\"num_rounds must be int but got {}\".format(type(num_rounds)))\n        if not isinstance(task_assignment_timeout, int):\n            raise TypeError(\"task_assignment_timeout must be int but got {}\".format(type(task_assignment_timeout)))\n        if not isinstance(persistor_id, str):\n            raise TypeError(\"persistor_id must be a string but got {}\".format(type(persistor_id)))\n        if not isinstance(shareable_generator_id, str):\n            raise TypeError(\"shareable_generator_id must be a string but got {}\".format(type(shareable_generator_id)))\n        if not isinstance(task_name, str):\n            raise TypeError(\"task_name must be a string but got {}\".format(type(task_name)))\n        self._num_rounds = num_rounds\n        self._start_round = 0\n        self._end_round = self._start_round + self._num_rounds\n        self._current_round = 0\n        self._last_learnable = None\n        self.persistor_id = persistor_id\n        self.shareable_generator_id = shareable_generator_id\n        self.task_assignment_timeout = task_assignment_timeout\n        self.task_name = task_name\n\n    def start_controller(self, fl_ctx: FLContext):\n        self.log_debug(fl_ctx, \"starting controller\")\n        self.persistor = fl_ctx.get_engine().get_component(self.persistor_id)\n        self.shareable_generator = fl_ctx.get_engine().get_component(self.shareable_generator_id)\n        if not isinstance(self.persistor, LearnablePersistor):\n            self.system_panic(\n                f\"Persistor {self.persistor_id} must be a Persistor instance, but got {type(self.persistor)}\", fl_ctx\n            )\n        if not isinstance(self.shareable_generator, ShareableGenerator):\n            self.system_panic(\n                f\"Shareable generator {self.shareable_generator_id} must be a Shareable Generator instance, but got {type(self.shareable_generator)}\",\n                fl_ctx,\n            )\n        self._last_learnable = self.persistor.load(fl_ctx)\n        fl_ctx.set_prop(AppConstants.GLOBAL_MODEL, self._last_learnable, private=True, sticky=True)\n        self.fire_event(AppEventType.INITIAL_MODEL_LOADED, fl_ctx)\n\n    def _process_result(self, client_task: ClientTask, fl_ctx: FLContext):\n        # submitted shareable is stored in client_task.result\n        # we need to update task.data with that shareable so the next target\n        # will get the updated shareable\n        task = client_task.task\n\n        # update the global learnable with the received result (shareable)\n        # e.g. the received result could be weight_diffs, the learnable could be full weights.\n        self._last_learnable = self.shareable_generator.shareable_to_learnable(client_task.result, fl_ctx)\n\n        # prepare task shareable data for next client\n        task.data = self.shareable_generator.learnable_to_shareable(self._last_learnable, fl_ctx)\n\n    def control_flow(self, abort_signal: Signal, fl_ctx: FLContext):\n        try:\n            engine = fl_ctx.get_engine()\n            self.log_debug(fl_ctx, \"Cyclic starting.\")\n\n            for self._current_round in range(self._start_round, self._end_round):\n                if abort_signal.triggered:\n                    return\n\n                self.log_debug(fl_ctx, \"Starting current round={}.\".format(self._current_round))\n                fl_ctx.set_prop(AppConstants.CURRENT_ROUND, self._current_round, private=True, sticky=False)\n\n                # Task for one cyclic\n                targets = engine.get_clients()\n                random.shuffle(targets)\n                targets_names = [t.name for t in targets]\n                self.log_debug(fl_ctx, f\"Relay on {targets_names}\")\n\n                shareable = self.shareable_generator.learnable_to_shareable(self._last_learnable, fl_ctx)\n                shareable.set_header(AppConstants.CURRENT_ROUND, self._current_round)\n\n                task = Task(\n                    name=self.task_name,\n                    data=shareable,\n                    result_received_cb=self._process_result,\n                )\n\n                self.relay_and_wait(\n                    task=task,\n                    targets=targets,\n                    task_assignment_timeout=self.task_assignment_timeout,\n                    fl_ctx=fl_ctx,\n                    dynamic_targets=False,\n                    abort_signal=abort_signal,\n                )\n                self.persistor.save(self._last_learnable, fl_ctx)\n                self.log_debug(fl_ctx, \"Ending current round={}.\".format(self._current_round))\n                engine.persist_components(fl_ctx, completed=False)\n\n            self.log_debug(fl_ctx, \"Cyclic ended.\")\n        except BaseException as e:\n            error_msg = f\"Cyclic control_flow exception {e}\"\n            self.log_error(fl_ctx, error_msg)\n            self.system_panic(str(e), fl_ctx)\n\n    def stop_controller(self, fl_ctx: FLContext):\n        self.persistor.save(learnable=self._last_learnable, fl_ctx=fl_ctx)\n        self.log_debug(fl_ctx, \"controller stopped\")\n\n    def process_result_of_unknown_task(\n        self,\n        client: Client,\n        task_name: str,\n        client_task_id: str,\n        result: Shareable,\n        fl_ctx: FLContext,\n    ):\n        self.log_warning(fl_ctx, f\"Dropped result of unknown task: {task_name} from client {client.name}.\")\n\n    def get_persist_state(self, fl_ctx: FLContext) -> dict:\n        return {\n            \"current_round\": self._current_round,\n            \"end_round\": self._end_round,\n            \"last_learnable\": self._last_learnable,\n        }\n\n    def restore(self, state_data: dict, fl_ctx: FLContext):\n        try:\n            self._current_round = state_data.get(\"current_round\")\n            self._end_round = state_data.get(\"end_round\")\n            self._last_learnable = state_data.get(\"last_learnable\")\n            self._start_round = self._current_round\n        finally:\n            pass",
  "def __init__(\n        self,\n        num_rounds: int = 5,\n        task_assignment_timeout: int = 10,\n        persistor_id=\"persistor\",\n        shareable_generator_id=\"shareable_generator\",\n        task_name=\"train\",\n    ):\n        \"\"\"A sample implementation to demonstrate how to use relay method for Cyclic Federated Learning.\n\n        Args:\n            num_rounds (int, optional): number of rounds this controller should perform. Defaults to 5.\n            task_assignment_timeout (int, optional): timeout (in sec) to determine if one client fails to request the task which it is assigned to . Defaults to 10.\n            persistor_id (str, optional): id of the persistor so this controller can save a global model. Defaults to \"persistor\".\n            shareable_generator_id (str, optional): id of shareable generator. Defaults to \"shareable_generator\".\n            task_name (str, optional): the task name that clients know how to handle. Defaults to \"train\".\n\n        Raises:\n            TypeError: when any of input arguments does not have correct type\n        \"\"\"\n        super().__init__()\n        if not isinstance(num_rounds, int):\n            raise TypeError(\"num_rounds must be int but got {}\".format(type(num_rounds)))\n        if not isinstance(task_assignment_timeout, int):\n            raise TypeError(\"task_assignment_timeout must be int but got {}\".format(type(task_assignment_timeout)))\n        if not isinstance(persistor_id, str):\n            raise TypeError(\"persistor_id must be a string but got {}\".format(type(persistor_id)))\n        if not isinstance(shareable_generator_id, str):\n            raise TypeError(\"shareable_generator_id must be a string but got {}\".format(type(shareable_generator_id)))\n        if not isinstance(task_name, str):\n            raise TypeError(\"task_name must be a string but got {}\".format(type(task_name)))\n        self._num_rounds = num_rounds\n        self._start_round = 0\n        self._end_round = self._start_round + self._num_rounds\n        self._current_round = 0\n        self._last_learnable = None\n        self.persistor_id = persistor_id\n        self.shareable_generator_id = shareable_generator_id\n        self.task_assignment_timeout = task_assignment_timeout\n        self.task_name = task_name",
  "def start_controller(self, fl_ctx: FLContext):\n        self.log_debug(fl_ctx, \"starting controller\")\n        self.persistor = fl_ctx.get_engine().get_component(self.persistor_id)\n        self.shareable_generator = fl_ctx.get_engine().get_component(self.shareable_generator_id)\n        if not isinstance(self.persistor, LearnablePersistor):\n            self.system_panic(\n                f\"Persistor {self.persistor_id} must be a Persistor instance, but got {type(self.persistor)}\", fl_ctx\n            )\n        if not isinstance(self.shareable_generator, ShareableGenerator):\n            self.system_panic(\n                f\"Shareable generator {self.shareable_generator_id} must be a Shareable Generator instance, but got {type(self.shareable_generator)}\",\n                fl_ctx,\n            )\n        self._last_learnable = self.persistor.load(fl_ctx)\n        fl_ctx.set_prop(AppConstants.GLOBAL_MODEL, self._last_learnable, private=True, sticky=True)\n        self.fire_event(AppEventType.INITIAL_MODEL_LOADED, fl_ctx)",
  "def _process_result(self, client_task: ClientTask, fl_ctx: FLContext):\n        # submitted shareable is stored in client_task.result\n        # we need to update task.data with that shareable so the next target\n        # will get the updated shareable\n        task = client_task.task\n\n        # update the global learnable with the received result (shareable)\n        # e.g. the received result could be weight_diffs, the learnable could be full weights.\n        self._last_learnable = self.shareable_generator.shareable_to_learnable(client_task.result, fl_ctx)\n\n        # prepare task shareable data for next client\n        task.data = self.shareable_generator.learnable_to_shareable(self._last_learnable, fl_ctx)",
  "def control_flow(self, abort_signal: Signal, fl_ctx: FLContext):\n        try:\n            engine = fl_ctx.get_engine()\n            self.log_debug(fl_ctx, \"Cyclic starting.\")\n\n            for self._current_round in range(self._start_round, self._end_round):\n                if abort_signal.triggered:\n                    return\n\n                self.log_debug(fl_ctx, \"Starting current round={}.\".format(self._current_round))\n                fl_ctx.set_prop(AppConstants.CURRENT_ROUND, self._current_round, private=True, sticky=False)\n\n                # Task for one cyclic\n                targets = engine.get_clients()\n                random.shuffle(targets)\n                targets_names = [t.name for t in targets]\n                self.log_debug(fl_ctx, f\"Relay on {targets_names}\")\n\n                shareable = self.shareable_generator.learnable_to_shareable(self._last_learnable, fl_ctx)\n                shareable.set_header(AppConstants.CURRENT_ROUND, self._current_round)\n\n                task = Task(\n                    name=self.task_name,\n                    data=shareable,\n                    result_received_cb=self._process_result,\n                )\n\n                self.relay_and_wait(\n                    task=task,\n                    targets=targets,\n                    task_assignment_timeout=self.task_assignment_timeout,\n                    fl_ctx=fl_ctx,\n                    dynamic_targets=False,\n                    abort_signal=abort_signal,\n                )\n                self.persistor.save(self._last_learnable, fl_ctx)\n                self.log_debug(fl_ctx, \"Ending current round={}.\".format(self._current_round))\n                engine.persist_components(fl_ctx, completed=False)\n\n            self.log_debug(fl_ctx, \"Cyclic ended.\")\n        except BaseException as e:\n            error_msg = f\"Cyclic control_flow exception {e}\"\n            self.log_error(fl_ctx, error_msg)\n            self.system_panic(str(e), fl_ctx)",
  "def stop_controller(self, fl_ctx: FLContext):\n        self.persistor.save(learnable=self._last_learnable, fl_ctx=fl_ctx)\n        self.log_debug(fl_ctx, \"controller stopped\")",
  "def process_result_of_unknown_task(\n        self,\n        client: Client,\n        task_name: str,\n        client_task_id: str,\n        result: Shareable,\n        fl_ctx: FLContext,\n    ):\n        self.log_warning(fl_ctx, f\"Dropped result of unknown task: {task_name} from client {client.name}.\")",
  "def get_persist_state(self, fl_ctx: FLContext) -> dict:\n        return {\n            \"current_round\": self._current_round,\n            \"end_round\": self._end_round,\n            \"last_learnable\": self._last_learnable,\n        }",
  "def restore(self, state_data: dict, fl_ctx: FLContext):\n        try:\n            self._current_round = state_data.get(\"current_round\")\n            self._end_round = state_data.get(\"end_round\")\n            self._last_learnable = state_data.get(\"last_learnable\")\n            self._start_round = self._current_round\n        finally:\n            pass",
  "class CrossSiteModelEval(Controller):\n    def __init__(\n        self,\n        task_check_period=0.5,\n        cross_val_dir=AppConstants.CROSS_VAL_DIR,\n        submit_model_timeout=600,\n        validation_timeout: int = 6000,\n        model_locator_id=\"\",\n        formatter_id=\"\",\n        submit_model_task_name=AppConstants.TASK_SUBMIT_MODEL,\n        validation_task_name=AppConstants.TASK_VALIDATION,\n        cleanup_models=False,\n        participating_clients=None,\n        wait_for_clients_timeout=300,\n    ):\n        \"\"\"Cross Site Model Validation workflow.\n\n        Args:\n            task_check_period (float, optional): How often to check for new tasks or tasks being finished.\n                Defaults to 0.5.\n            cross_val_dir (str, optional): Path to cross site validation directory relative to run directory.\n                Defaults to \"cross_site_val\".\n            submit_model_timeout (int, optional): Timeout of submit_model_task. Defaults to 600 secs.\n            validation_timeout (int, optional): Timeout for validate_model task. Defaults to 6000 secs.\n            model_locator_id (str, optional): ID for model_locator component. Defaults to \"\".\n            formatter_id (str, optional): ID for formatter component. Defaults to \"\".\n            submit_model_task_name (str, optional): Name of submit_model task. Defaults to \"\".\n            validation_task_name (str, optional): Name of validate_model task. Defaults to \"validate\".\n            cleanup_models (bool, optional): Whether or not models should be deleted after run. Defaults to False.\n            participating_clients (list, optional): List of participating client names. If not provided, defaults\n                to all clients connected at start of controller.\n            wait_for_clients_timeout (int, optional): Timeout for clients to appear. Defaults to 300 secs\n        \"\"\"\n        super(CrossSiteModelEval, self).__init__(task_check_period=task_check_period)\n\n        if not isinstance(task_check_period, float):\n            raise TypeError(\"task_check_period must be float but got {}\".format(type(task_check_period)))\n        if not isinstance(cross_val_dir, str):\n            raise TypeError(\"cross_val_dir must be a string but got {}\".format(type(cross_val_dir)))\n        if not isinstance(submit_model_timeout, int):\n            raise TypeError(\"submit_model_timeout must be int but got {}\".format(type(submit_model_timeout)))\n        if not isinstance(validation_timeout, int):\n            raise TypeError(\"validation_timeout must be int but got {}\".format(type(validation_timeout)))\n        if not isinstance(model_locator_id, str):\n            raise TypeError(\"model_locator_id must be a string but got {}\".format(type(model_locator_id)))\n        if not isinstance(formatter_id, str):\n            raise TypeError(\"formatter_id must be a string but got {}\".format(type(formatter_id)))\n        if not isinstance(submit_model_task_name, str):\n            raise TypeError(\"submit_model_task_name must be a string but got {}\".format(type(submit_model_task_name)))\n        if not isinstance(validation_task_name, str):\n            raise TypeError(\"validation_task_name must be a string but got {}\".format(type(validation_task_name)))\n        if not isinstance(cleanup_models, bool):\n            raise TypeError(\"cleanup_models must be bool but got {}\".format(type(cleanup_models)))\n\n        if participating_clients:\n            if not isinstance(participating_clients, list):\n                raise TypeError(\"participating_clients must be a list but got {}\".format(type(participating_clients)))\n            if not all(isinstance(x, str) for x in participating_clients):\n                raise TypeError(\"participating_clients must be strings\")\n\n        if submit_model_timeout < 0:\n            raise ValueError(\"submit_model_timeout must be greater than or equal to 0.\")\n        if validation_timeout < 0:\n            raise ValueError(\"model_validate_timeout must be greater than or equal to 0.\")\n        if wait_for_clients_timeout < 0:\n            raise ValueError(\"wait_for_clients_timeout must be greater than or equal to 0.\")\n\n        self._cross_val_dir = cross_val_dir\n        self._model_locator_id = model_locator_id\n        self._formatter_id = formatter_id\n        self._submit_model_task_name = submit_model_task_name\n        self._validation_task_name = validation_task_name\n        self._submit_model_timeout = submit_model_timeout\n        self._validation_timeout = validation_timeout\n        self._wait_for_clients_timeout = wait_for_clients_timeout\n        self._cleanup_models = cleanup_models\n        self._participating_clients = participating_clients\n\n        self._val_results = {}\n        self._server_models = {}\n        self._client_models = {}\n\n        self._formatter = None\n        self._cross_val_models_dir = None\n        self._cross_val_results_dir = None\n        self._model_locator = None\n\n    def start_controller(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        if not engine:\n            self.system_panic(\"Engine not found. Workflow exiting.\", fl_ctx)\n            return\n\n        # If the list of participating clients is not provided, include all clients currently available.\n        if not self._participating_clients:\n            clients = engine.get_clients()\n            self._participating_clients = [c.name for c in clients]\n\n        # Create shareable dirs for models and results\n        workspace: Workspace = engine.get_workspace()\n        run_dir = workspace.get_run_dir(fl_ctx.get_job_id())\n        cross_val_path = os.path.join(run_dir, self._cross_val_dir)\n        self._cross_val_models_dir = os.path.join(cross_val_path, AppConstants.CROSS_VAL_MODEL_DIR_NAME)\n        self._cross_val_results_dir = os.path.join(cross_val_path, AppConstants.CROSS_VAL_RESULTS_DIR_NAME)\n\n        # Fire the init event.\n        fl_ctx.set_prop(AppConstants.CROSS_VAL_MODEL_PATH, self._cross_val_models_dir)\n        fl_ctx.set_prop(AppConstants.CROSS_VAL_RESULTS_PATH, self._cross_val_results_dir)\n        self.fire_event(AppEventType.CROSS_VAL_INIT, fl_ctx)\n\n        # Cleanup/create the cross val models and results directories\n        if os.path.exists(self._cross_val_models_dir):\n            shutil.rmtree(self._cross_val_models_dir)\n        if os.path.exists(self._cross_val_results_dir):\n            shutil.rmtree(self._cross_val_results_dir)\n\n        # Recreate new directories.\n        os.makedirs(self._cross_val_models_dir)\n        os.makedirs(self._cross_val_results_dir)\n\n        # Get components\n        if self._model_locator_id:\n            self._model_locator = engine.get_component(self._model_locator_id)\n            if not isinstance(self._model_locator, ModelLocator):\n                self.system_panic(\n                    reason=\"bad model locator {}: expect ModelLocator but got {}\".format(\n                        self._model_locator_id, type(self._model_locator)\n                    ),\n                    fl_ctx=fl_ctx,\n                )\n                return\n\n        if self._formatter_id:\n            self._formatter = engine.get_component(self._formatter_id)\n            if not isinstance(self._formatter, Formatter):\n                self.system_panic(\n                    reason=f\"formatter {self._formatter_id} is not an instance of Formatter.\", fl_ctx=fl_ctx\n                )\n                return\n\n        if not self._formatter:\n            self.log_info(fl_ctx, \"Formatter not found. Stats will not be printed.\")\n\n        for c_name in self._participating_clients:\n            self._client_models[c_name] = None\n            self._val_results[c_name] = {}\n\n    def control_flow(self, abort_signal: Signal, fl_ctx: FLContext):\n        try:\n            # wait until there are some clients\n            engine = fl_ctx.get_engine()\n            start_time = time.time()\n            while not self._participating_clients:\n                self._participating_clients = [c.name for c in engine.get_clients()]\n                if time.time() - start_time > self._wait_for_clients_timeout:\n                    self.log_info(fl_ctx, \"No clients available - quit model validation.\")\n                    return\n\n                self.log_info(fl_ctx, \"No clients available - waiting ...\")\n                time.sleep(2.0)\n                if abort_signal.triggered:\n                    self.log_info(fl_ctx, \"Abort signal triggered. Finishing model validation.\")\n                    return\n\n            self.log_info(fl_ctx, f\"Beginning model validation with clients: {self._participating_clients}.\")\n\n            if self._submit_model_task_name:\n                shareable = Shareable()\n                shareable.set_header(AppConstants.SUBMIT_MODEL_NAME, ModelName.BEST_MODEL)\n                submit_model_task = Task(\n                    name=self._submit_model_task_name,\n                    data=shareable,\n                    result_received_cb=self._receive_local_model_cb,\n                    timeout=self._submit_model_timeout,\n                )\n                self.broadcast(\n                    task=submit_model_task,\n                    targets=self._participating_clients,\n                    fl_ctx=fl_ctx,\n                    min_responses=len(self._participating_clients),\n                )\n\n            if abort_signal.triggered:\n                self.log_info(fl_ctx, \"Abort signal triggered. Finishing model validation.\")\n                return\n\n            # Load server models and assign those tasks\n            if self._model_locator:\n                success = self._locate_server_models(fl_ctx)\n                if not success:\n                    return\n\n                for server_model in self._server_models:\n                    self._send_validation_task(server_model, fl_ctx)\n            else:\n                self.log_info(fl_ctx, \"ModelLocator not present. No server models will be included.\")\n\n            while self.get_num_standing_tasks():\n                if abort_signal.triggered:\n                    self.log_info(fl_ctx, \"Abort signal triggered. Finishing cross site validation.\")\n                    return\n                self.log_debug(fl_ctx, \"Checking standing tasks to see if cross site validation finished.\")\n                time.sleep(self._task_check_period)\n        except BaseException as e:\n            error_msg = f\"Exception in cross site validator control_flow: {e.__str__()}\"\n            self.log_exception(fl_ctx, error_msg)\n            self.system_panic(error_msg, fl_ctx)\n\n    def stop_controller(self, fl_ctx: FLContext):\n        self.cancel_all_tasks(fl_ctx=fl_ctx)\n\n        if self._cleanup_models:\n            self.log_info(fl_ctx, \"Removing local models kept for validation.\")\n            for model_name, model_path in self._server_models.items():\n                if model_path and os.path.isfile(model_path):\n                    os.remove(model_path)\n                    self.log_debug(fl_ctx, f\"Removing server model {model_name} at {model_path}.\")\n            for model_name, model_path in self._client_models.items():\n                if model_path and os.path.isfile(model_path):\n                    os.remove(model_path)\n                    self.log_debug(fl_ctx, f\"Removing client {model_name}'s model at {model_path}.\")\n\n    def _receive_local_model_cb(self, client_task: ClientTask, fl_ctx: FLContext):\n        client_name = client_task.client.name\n        result: Shareable = client_task.result\n\n        self._accept_local_model(client_name=client_name, result=result, fl_ctx=fl_ctx)\n\n        # Cleanup task result\n        client_task.result = None\n\n    def _before_send_validate_task_cb(self, client_task: ClientTask, fl_ctx: FLContext):\n        model_name = client_task.task.props[AppConstants.MODEL_OWNER]\n\n        try:\n            model_dxo: DXO = self._load_validation_content(model_name, self._cross_val_models_dir, fl_ctx)\n        except ValueError as v_e:\n            reason = f\"Error in loading model shareable for {model_name}. CrossSiteValidator exiting.\"\n            self.log_error(fl_ctx, reason)\n            self.system_panic(reason, fl_ctx)\n            return\n\n        if not model_dxo:\n            self.system_panic(\n                f\"Model contents for {model_name} not found in {self._cross_val_models_dir}. \"\n                \"CrossSiteValidator exiting\",\n                fl_ctx=fl_ctx,\n            )\n            return\n\n        model_shareable = model_dxo.to_shareable()\n        model_shareable.set_header(AppConstants.MODEL_OWNER, model_name)\n        model_shareable.add_cookie(AppConstants.MODEL_OWNER, model_name)\n        client_task.task.data = model_shareable\n\n        fl_ctx.set_prop(AppConstants.DATA_CLIENT, client_task.client, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.MODEL_OWNER, model_name, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.MODEL_TO_VALIDATE, model_shareable, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.PARTICIPATING_CLIENTS, self._participating_clients, private=True, sticky=False)\n        self.fire_event(AppEventType.SEND_MODEL_FOR_VALIDATION, fl_ctx)\n\n    def _after_send_validate_task_cb(self, client_task: ClientTask, fl_ctx: FLContext):\n        # Once task is sent clear data to restore memory\n        client_task.task.data = None\n\n    def _receive_val_result_cb(self, client_task: ClientTask, fl_ctx: FLContext):\n        # Find name of the client sending this\n        result = client_task.result\n        client_name = client_task.client.name\n\n        self._accept_val_result(client_name=client_name, result=result, fl_ctx=fl_ctx)\n\n        client_task.result = None\n\n    def _locate_server_models(self, fl_ctx: FLContext) -> bool:\n        # Load models from model_locator\n        self.log_info(fl_ctx, \"Locating server models.\")\n        server_model_names = self._model_locator.get_model_names(fl_ctx)\n\n        unique_names = []\n        for name in server_model_names:\n            # Get the model\n            dxo = self._model_locator.locate_model(name, fl_ctx)\n            if not isinstance(dxo, DXO):\n                self.system_panic(f\"ModelLocator produced invalid data: expect DXO but got {type(dxo)}.\", fl_ctx)\n                return False\n\n            # Save to workspace\n            unique_name = \"SRV_\" + name\n            unique_names.append(unique_name)\n            try:\n                save_path = self._save_validation_content(unique_name, self._cross_val_models_dir, dxo, fl_ctx)\n            except:\n                self.log_exception(fl_ctx, f\"Unable to save shareable contents of server model {unique_name}\")\n                self.system_panic(f\"Unable to save shareable contents of server model {unique_name}\", fl_ctx)\n                return False\n\n            self._server_models[unique_name] = save_path\n            self._val_results[unique_name] = {}\n\n        if unique_names:\n            self.log_info(fl_ctx, f\"Server models loaded: {unique_names}.\")\n        else:\n            self.log_info(fl_ctx, \"no server models to validate!\")\n        return True\n\n    def _accept_local_model(self, client_name: str, result: Shareable, fl_ctx: FLContext):\n        fl_ctx.set_prop(AppConstants.RECEIVED_MODEL, result, private=False, sticky=False)\n        fl_ctx.set_prop(AppConstants.RECEIVED_MODEL_OWNER, client_name, private=False, sticky=False)\n        fl_ctx.set_prop(AppConstants.CROSS_VAL_DIR, self._cross_val_dir, private=False, sticky=False)\n        self.fire_event(AppEventType.RECEIVE_BEST_MODEL, fl_ctx)\n\n        # get return code\n        rc = result.get_return_code()\n        if rc and rc != ReturnCode.OK:\n            # Raise errors if bad peer context or execution exception.\n            if rc in [ReturnCode.MISSING_PEER_CONTEXT, ReturnCode.BAD_PEER_CONTEXT]:\n                self.log_error(fl_ctx, \"Peer context is bad or missing. No model submitted for this client.\")\n            elif rc in [ReturnCode.EXECUTION_EXCEPTION, ReturnCode.TASK_UNKNOWN]:\n                self.log_error(\n                    fl_ctx, \"Execution Exception on client during model submission. No model submitted for this client.\"\n                )\n            # Ignore contribution if result invalid.\n            elif rc in [\n                ReturnCode.EXECUTION_RESULT_ERROR,\n                ReturnCode.TASK_DATA_FILTER_ERROR,\n                ReturnCode.TASK_RESULT_FILTER_ERROR,\n                ReturnCode.TASK_UNKNOWN,\n            ]:\n                self.log_error(fl_ctx, \"Execution result is not a shareable. Model submission will be ignored.\")\n            else:\n                self.log_error(fl_ctx, \"Return code set. Model submission from client will be ignored.\")\n        else:\n            # Save shareable in models directory.\n            try:\n                self.log_debug(fl_ctx, \"Extracting DXO from shareable.\")\n                dxo = from_shareable(result)\n                save_path = self._save_validation_content(client_name, self._cross_val_models_dir, dxo, fl_ctx)\n            except ValueError as v_e:\n                self.log_error(\n                    fl_ctx, f\"Unable to save shareable contents of {client_name}'s model. Exception: {str(v_e)}\"\n                )\n                self.log_warning(fl_ctx, f\"Ignoring client {client_name}'s model.\")\n                return\n\n            self.log_info(fl_ctx, f\"Received local model from client {client_name}.\")\n\n            self._client_models[client_name] = save_path\n\n            # Send a model to this client to validate\n            self._send_validation_task(client_name, fl_ctx)\n\n    def _send_validation_task(self, model_name: str, fl_ctx: FLContext):\n        self.log_info(fl_ctx, f\"Sending {model_name} model to all participating clients for validation.\")\n\n        # Create validation task and broadcast to all participating clients.\n        task = Task(\n            name=self._validation_task_name,\n            data=Shareable(),\n            before_task_sent_cb=self._before_send_validate_task_cb,\n            after_task_sent_cb=self._after_send_validate_task_cb,\n            result_received_cb=self._receive_val_result_cb,\n            timeout=self._validation_timeout,\n            props={AppConstants.MODEL_OWNER: model_name},\n        )\n\n        self.broadcast(\n            task=task,\n            fl_ctx=fl_ctx,\n            targets=self._participating_clients,\n            min_responses=len(self._participating_clients),\n            wait_time_after_min_received=0,\n        )\n\n    def _accept_val_result(self, client_name: str, result: Shareable, fl_ctx: FLContext):\n        model_owner = result.get_cookie(AppConstants.MODEL_OWNER, \"\")\n\n        # Fire event. This needs to be a new local context per each client\n        fl_ctx.set_prop(AppConstants.MODEL_OWNER, model_owner, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.DATA_CLIENT, client_name, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.VALIDATION_RESULT, result, private=True, sticky=False)\n        self.fire_event(AppEventType.VALIDATION_RESULT_RECEIVED, fl_ctx)\n\n        rc = result.get_return_code()\n        if rc and rc != ReturnCode.OK:\n            # Raise errors if bad peer context or execution exception.\n            if rc in [ReturnCode.MISSING_PEER_CONTEXT, ReturnCode.BAD_PEER_CONTEXT]:\n                self.log_error(fl_ctx, \"Peer context is bad or missing.\")\n            elif rc in [ReturnCode.EXECUTION_EXCEPTION, ReturnCode.TASK_UNKNOWN]:\n                self.log_error(fl_ctx, \"Execution Exception in model validation.\")\n            elif rc in [\n                ReturnCode.EXECUTION_RESULT_ERROR,\n                ReturnCode.TASK_DATA_FILTER_ERROR,\n                ReturnCode.TASK_RESULT_FILTER_ERROR,\n            ]:\n                self.log_error(fl_ctx, \"Execution result is not a shareable. Validation results will be ignored.\")\n            else:\n                self.log_error(\n                    fl_ctx,\n                    f\"Client {client_name} sent results for validating {model_owner} model with return code set.\"\n                    \" Logging empty results.\",\n                )\n\n            self._val_results[client_name][model_owner] = {}\n        else:\n            save_file_name = client_name + \"_\" + model_owner\n\n            try:\n                dxo = from_shareable(result)\n                self._save_validation_content(save_file_name, self._cross_val_results_dir, dxo, fl_ctx)\n                self._val_results[client_name][model_owner] = os.path.join(self._cross_val_results_dir, save_file_name)\n\n                self.log_info(fl_ctx, f\"Client {client_name} sent results for validating {model_owner} model.\")\n            except ValueError as v_e:\n                reason = (\n                    f\"Unable to save validation result from {client_name} of {model_owner}'s model. \"\n                    f\"Exception: {str(v_e)}\"\n                )\n                self.log_exception(fl_ctx, reason)\n\n    def _save_validation_content(self, name: str, save_dir: str, dxo: DXO, fl_ctx: FLContext) -> str:\n        \"\"\"Saves shareable to given directory within the app_dir.\n\n        Args:\n            name (str): Name of shareable\n            save_dir (str): Relative path to directory in which to save\n            shareable (Shareable): Shareable object\n            fl_ctx (FLContext): FLContext object\n\n        Returns:\n            str: Path to the file saved.\n        \"\"\"\n        # Save the model with name as the filename to shareable directory\n        data_filename = os.path.join(save_dir, name)\n\n        try:\n            bytes_to_save = dxo.to_bytes()\n        except Exception as e:\n            raise ValueError(f\"Unable to extract shareable contents. Exception: {(e.__str__())}\") from e\n\n        # Save contents to path\n        try:\n            with open(data_filename, \"wb\") as f:\n                f.write(bytes_to_save)\n        except Exception as e:\n            raise ValueError(f\"Unable to save shareable contents: {str(e)}\") from e\n\n        self.log_debug(fl_ctx, f\"Saved cross validation model with name: {name}.\")\n\n        return data_filename\n\n    def _load_validation_content(self, name: str, load_dir: str, fl_ctx: FLContext) -> Union[DXO, None]:\n        # Load shareable from disk\n        shareable_filename = os.path.join(load_dir, name)\n        dxo: DXO = None\n\n        # load shareable\n        try:\n            with open(shareable_filename, \"rb\") as f:\n                data = f.read()\n\n            dxo: DXO = from_bytes(data)\n\n            self.log_debug(fl_ctx, f\"Loading cross validation shareable content with name: {name}.\")\n        except Exception as e:\n            raise ValueError(f\"Exception in loading shareable content for {name}: {str(e)}\")\n\n        return dxo\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        super().handle_event(event_type=event_type, fl_ctx=fl_ctx)\n        if event_type == InfoCollector.EVENT_TYPE_GET_STATS:\n            if self._formatter:\n                collector = fl_ctx.get_prop(InfoCollector.CTX_KEY_STATS_COLLECTOR, None)\n                if collector:\n                    if not isinstance(collector, GroupInfoCollector):\n                        raise TypeError(\"collector must be GroupInfoCollector but got {}\".format(type(collector)))\n\n                    fl_ctx.set_prop(AppConstants.VALIDATION_RESULT, self._val_results, private=True, sticky=False)\n                    val_info = self._formatter.format(fl_ctx)\n\n                    collector.add_info(\n                        group_name=self._name,\n                        info={\"val_results\": val_info},\n                    )\n            else:\n                self.log_warning(fl_ctx, \"No formatter provided. Validation results can't be printed.\")\n\n    def process_result_of_unknown_task(\n        self, client: Client, task_name: str, client_task_id: str, result: Shareable, fl_ctx: FLContext\n    ):\n        if task_name == self._submit_model_task_name:\n            self._accept_local_model(client_name=client.name, result=result, fl_ctx=fl_ctx)\n        elif task_name == self._validation_task_name:\n            self._accept_val_result(client_name=client.name, result=result, fl_ctx=fl_ctx)\n        else:\n            self.log_error(fl_ctx, \"Ignoring result from unknown task.\")",
  "def __init__(\n        self,\n        task_check_period=0.5,\n        cross_val_dir=AppConstants.CROSS_VAL_DIR,\n        submit_model_timeout=600,\n        validation_timeout: int = 6000,\n        model_locator_id=\"\",\n        formatter_id=\"\",\n        submit_model_task_name=AppConstants.TASK_SUBMIT_MODEL,\n        validation_task_name=AppConstants.TASK_VALIDATION,\n        cleanup_models=False,\n        participating_clients=None,\n        wait_for_clients_timeout=300,\n    ):\n        \"\"\"Cross Site Model Validation workflow.\n\n        Args:\n            task_check_period (float, optional): How often to check for new tasks or tasks being finished.\n                Defaults to 0.5.\n            cross_val_dir (str, optional): Path to cross site validation directory relative to run directory.\n                Defaults to \"cross_site_val\".\n            submit_model_timeout (int, optional): Timeout of submit_model_task. Defaults to 600 secs.\n            validation_timeout (int, optional): Timeout for validate_model task. Defaults to 6000 secs.\n            model_locator_id (str, optional): ID for model_locator component. Defaults to \"\".\n            formatter_id (str, optional): ID for formatter component. Defaults to \"\".\n            submit_model_task_name (str, optional): Name of submit_model task. Defaults to \"\".\n            validation_task_name (str, optional): Name of validate_model task. Defaults to \"validate\".\n            cleanup_models (bool, optional): Whether or not models should be deleted after run. Defaults to False.\n            participating_clients (list, optional): List of participating client names. If not provided, defaults\n                to all clients connected at start of controller.\n            wait_for_clients_timeout (int, optional): Timeout for clients to appear. Defaults to 300 secs\n        \"\"\"\n        super(CrossSiteModelEval, self).__init__(task_check_period=task_check_period)\n\n        if not isinstance(task_check_period, float):\n            raise TypeError(\"task_check_period must be float but got {}\".format(type(task_check_period)))\n        if not isinstance(cross_val_dir, str):\n            raise TypeError(\"cross_val_dir must be a string but got {}\".format(type(cross_val_dir)))\n        if not isinstance(submit_model_timeout, int):\n            raise TypeError(\"submit_model_timeout must be int but got {}\".format(type(submit_model_timeout)))\n        if not isinstance(validation_timeout, int):\n            raise TypeError(\"validation_timeout must be int but got {}\".format(type(validation_timeout)))\n        if not isinstance(model_locator_id, str):\n            raise TypeError(\"model_locator_id must be a string but got {}\".format(type(model_locator_id)))\n        if not isinstance(formatter_id, str):\n            raise TypeError(\"formatter_id must be a string but got {}\".format(type(formatter_id)))\n        if not isinstance(submit_model_task_name, str):\n            raise TypeError(\"submit_model_task_name must be a string but got {}\".format(type(submit_model_task_name)))\n        if not isinstance(validation_task_name, str):\n            raise TypeError(\"validation_task_name must be a string but got {}\".format(type(validation_task_name)))\n        if not isinstance(cleanup_models, bool):\n            raise TypeError(\"cleanup_models must be bool but got {}\".format(type(cleanup_models)))\n\n        if participating_clients:\n            if not isinstance(participating_clients, list):\n                raise TypeError(\"participating_clients must be a list but got {}\".format(type(participating_clients)))\n            if not all(isinstance(x, str) for x in participating_clients):\n                raise TypeError(\"participating_clients must be strings\")\n\n        if submit_model_timeout < 0:\n            raise ValueError(\"submit_model_timeout must be greater than or equal to 0.\")\n        if validation_timeout < 0:\n            raise ValueError(\"model_validate_timeout must be greater than or equal to 0.\")\n        if wait_for_clients_timeout < 0:\n            raise ValueError(\"wait_for_clients_timeout must be greater than or equal to 0.\")\n\n        self._cross_val_dir = cross_val_dir\n        self._model_locator_id = model_locator_id\n        self._formatter_id = formatter_id\n        self._submit_model_task_name = submit_model_task_name\n        self._validation_task_name = validation_task_name\n        self._submit_model_timeout = submit_model_timeout\n        self._validation_timeout = validation_timeout\n        self._wait_for_clients_timeout = wait_for_clients_timeout\n        self._cleanup_models = cleanup_models\n        self._participating_clients = participating_clients\n\n        self._val_results = {}\n        self._server_models = {}\n        self._client_models = {}\n\n        self._formatter = None\n        self._cross_val_models_dir = None\n        self._cross_val_results_dir = None\n        self._model_locator = None",
  "def start_controller(self, fl_ctx: FLContext):\n        engine = fl_ctx.get_engine()\n        if not engine:\n            self.system_panic(\"Engine not found. Workflow exiting.\", fl_ctx)\n            return\n\n        # If the list of participating clients is not provided, include all clients currently available.\n        if not self._participating_clients:\n            clients = engine.get_clients()\n            self._participating_clients = [c.name for c in clients]\n\n        # Create shareable dirs for models and results\n        workspace: Workspace = engine.get_workspace()\n        run_dir = workspace.get_run_dir(fl_ctx.get_job_id())\n        cross_val_path = os.path.join(run_dir, self._cross_val_dir)\n        self._cross_val_models_dir = os.path.join(cross_val_path, AppConstants.CROSS_VAL_MODEL_DIR_NAME)\n        self._cross_val_results_dir = os.path.join(cross_val_path, AppConstants.CROSS_VAL_RESULTS_DIR_NAME)\n\n        # Fire the init event.\n        fl_ctx.set_prop(AppConstants.CROSS_VAL_MODEL_PATH, self._cross_val_models_dir)\n        fl_ctx.set_prop(AppConstants.CROSS_VAL_RESULTS_PATH, self._cross_val_results_dir)\n        self.fire_event(AppEventType.CROSS_VAL_INIT, fl_ctx)\n\n        # Cleanup/create the cross val models and results directories\n        if os.path.exists(self._cross_val_models_dir):\n            shutil.rmtree(self._cross_val_models_dir)\n        if os.path.exists(self._cross_val_results_dir):\n            shutil.rmtree(self._cross_val_results_dir)\n\n        # Recreate new directories.\n        os.makedirs(self._cross_val_models_dir)\n        os.makedirs(self._cross_val_results_dir)\n\n        # Get components\n        if self._model_locator_id:\n            self._model_locator = engine.get_component(self._model_locator_id)\n            if not isinstance(self._model_locator, ModelLocator):\n                self.system_panic(\n                    reason=\"bad model locator {}: expect ModelLocator but got {}\".format(\n                        self._model_locator_id, type(self._model_locator)\n                    ),\n                    fl_ctx=fl_ctx,\n                )\n                return\n\n        if self._formatter_id:\n            self._formatter = engine.get_component(self._formatter_id)\n            if not isinstance(self._formatter, Formatter):\n                self.system_panic(\n                    reason=f\"formatter {self._formatter_id} is not an instance of Formatter.\", fl_ctx=fl_ctx\n                )\n                return\n\n        if not self._formatter:\n            self.log_info(fl_ctx, \"Formatter not found. Stats will not be printed.\")\n\n        for c_name in self._participating_clients:\n            self._client_models[c_name] = None\n            self._val_results[c_name] = {}",
  "def control_flow(self, abort_signal: Signal, fl_ctx: FLContext):\n        try:\n            # wait until there are some clients\n            engine = fl_ctx.get_engine()\n            start_time = time.time()\n            while not self._participating_clients:\n                self._participating_clients = [c.name for c in engine.get_clients()]\n                if time.time() - start_time > self._wait_for_clients_timeout:\n                    self.log_info(fl_ctx, \"No clients available - quit model validation.\")\n                    return\n\n                self.log_info(fl_ctx, \"No clients available - waiting ...\")\n                time.sleep(2.0)\n                if abort_signal.triggered:\n                    self.log_info(fl_ctx, \"Abort signal triggered. Finishing model validation.\")\n                    return\n\n            self.log_info(fl_ctx, f\"Beginning model validation with clients: {self._participating_clients}.\")\n\n            if self._submit_model_task_name:\n                shareable = Shareable()\n                shareable.set_header(AppConstants.SUBMIT_MODEL_NAME, ModelName.BEST_MODEL)\n                submit_model_task = Task(\n                    name=self._submit_model_task_name,\n                    data=shareable,\n                    result_received_cb=self._receive_local_model_cb,\n                    timeout=self._submit_model_timeout,\n                )\n                self.broadcast(\n                    task=submit_model_task,\n                    targets=self._participating_clients,\n                    fl_ctx=fl_ctx,\n                    min_responses=len(self._participating_clients),\n                )\n\n            if abort_signal.triggered:\n                self.log_info(fl_ctx, \"Abort signal triggered. Finishing model validation.\")\n                return\n\n            # Load server models and assign those tasks\n            if self._model_locator:\n                success = self._locate_server_models(fl_ctx)\n                if not success:\n                    return\n\n                for server_model in self._server_models:\n                    self._send_validation_task(server_model, fl_ctx)\n            else:\n                self.log_info(fl_ctx, \"ModelLocator not present. No server models will be included.\")\n\n            while self.get_num_standing_tasks():\n                if abort_signal.triggered:\n                    self.log_info(fl_ctx, \"Abort signal triggered. Finishing cross site validation.\")\n                    return\n                self.log_debug(fl_ctx, \"Checking standing tasks to see if cross site validation finished.\")\n                time.sleep(self._task_check_period)\n        except BaseException as e:\n            error_msg = f\"Exception in cross site validator control_flow: {e.__str__()}\"\n            self.log_exception(fl_ctx, error_msg)\n            self.system_panic(error_msg, fl_ctx)",
  "def stop_controller(self, fl_ctx: FLContext):\n        self.cancel_all_tasks(fl_ctx=fl_ctx)\n\n        if self._cleanup_models:\n            self.log_info(fl_ctx, \"Removing local models kept for validation.\")\n            for model_name, model_path in self._server_models.items():\n                if model_path and os.path.isfile(model_path):\n                    os.remove(model_path)\n                    self.log_debug(fl_ctx, f\"Removing server model {model_name} at {model_path}.\")\n            for model_name, model_path in self._client_models.items():\n                if model_path and os.path.isfile(model_path):\n                    os.remove(model_path)\n                    self.log_debug(fl_ctx, f\"Removing client {model_name}'s model at {model_path}.\")",
  "def _receive_local_model_cb(self, client_task: ClientTask, fl_ctx: FLContext):\n        client_name = client_task.client.name\n        result: Shareable = client_task.result\n\n        self._accept_local_model(client_name=client_name, result=result, fl_ctx=fl_ctx)\n\n        # Cleanup task result\n        client_task.result = None",
  "def _before_send_validate_task_cb(self, client_task: ClientTask, fl_ctx: FLContext):\n        model_name = client_task.task.props[AppConstants.MODEL_OWNER]\n\n        try:\n            model_dxo: DXO = self._load_validation_content(model_name, self._cross_val_models_dir, fl_ctx)\n        except ValueError as v_e:\n            reason = f\"Error in loading model shareable for {model_name}. CrossSiteValidator exiting.\"\n            self.log_error(fl_ctx, reason)\n            self.system_panic(reason, fl_ctx)\n            return\n\n        if not model_dxo:\n            self.system_panic(\n                f\"Model contents for {model_name} not found in {self._cross_val_models_dir}. \"\n                \"CrossSiteValidator exiting\",\n                fl_ctx=fl_ctx,\n            )\n            return\n\n        model_shareable = model_dxo.to_shareable()\n        model_shareable.set_header(AppConstants.MODEL_OWNER, model_name)\n        model_shareable.add_cookie(AppConstants.MODEL_OWNER, model_name)\n        client_task.task.data = model_shareable\n\n        fl_ctx.set_prop(AppConstants.DATA_CLIENT, client_task.client, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.MODEL_OWNER, model_name, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.MODEL_TO_VALIDATE, model_shareable, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.PARTICIPATING_CLIENTS, self._participating_clients, private=True, sticky=False)\n        self.fire_event(AppEventType.SEND_MODEL_FOR_VALIDATION, fl_ctx)",
  "def _after_send_validate_task_cb(self, client_task: ClientTask, fl_ctx: FLContext):\n        # Once task is sent clear data to restore memory\n        client_task.task.data = None",
  "def _receive_val_result_cb(self, client_task: ClientTask, fl_ctx: FLContext):\n        # Find name of the client sending this\n        result = client_task.result\n        client_name = client_task.client.name\n\n        self._accept_val_result(client_name=client_name, result=result, fl_ctx=fl_ctx)\n\n        client_task.result = None",
  "def _locate_server_models(self, fl_ctx: FLContext) -> bool:\n        # Load models from model_locator\n        self.log_info(fl_ctx, \"Locating server models.\")\n        server_model_names = self._model_locator.get_model_names(fl_ctx)\n\n        unique_names = []\n        for name in server_model_names:\n            # Get the model\n            dxo = self._model_locator.locate_model(name, fl_ctx)\n            if not isinstance(dxo, DXO):\n                self.system_panic(f\"ModelLocator produced invalid data: expect DXO but got {type(dxo)}.\", fl_ctx)\n                return False\n\n            # Save to workspace\n            unique_name = \"SRV_\" + name\n            unique_names.append(unique_name)\n            try:\n                save_path = self._save_validation_content(unique_name, self._cross_val_models_dir, dxo, fl_ctx)\n            except:\n                self.log_exception(fl_ctx, f\"Unable to save shareable contents of server model {unique_name}\")\n                self.system_panic(f\"Unable to save shareable contents of server model {unique_name}\", fl_ctx)\n                return False\n\n            self._server_models[unique_name] = save_path\n            self._val_results[unique_name] = {}\n\n        if unique_names:\n            self.log_info(fl_ctx, f\"Server models loaded: {unique_names}.\")\n        else:\n            self.log_info(fl_ctx, \"no server models to validate!\")\n        return True",
  "def _accept_local_model(self, client_name: str, result: Shareable, fl_ctx: FLContext):\n        fl_ctx.set_prop(AppConstants.RECEIVED_MODEL, result, private=False, sticky=False)\n        fl_ctx.set_prop(AppConstants.RECEIVED_MODEL_OWNER, client_name, private=False, sticky=False)\n        fl_ctx.set_prop(AppConstants.CROSS_VAL_DIR, self._cross_val_dir, private=False, sticky=False)\n        self.fire_event(AppEventType.RECEIVE_BEST_MODEL, fl_ctx)\n\n        # get return code\n        rc = result.get_return_code()\n        if rc and rc != ReturnCode.OK:\n            # Raise errors if bad peer context or execution exception.\n            if rc in [ReturnCode.MISSING_PEER_CONTEXT, ReturnCode.BAD_PEER_CONTEXT]:\n                self.log_error(fl_ctx, \"Peer context is bad or missing. No model submitted for this client.\")\n            elif rc in [ReturnCode.EXECUTION_EXCEPTION, ReturnCode.TASK_UNKNOWN]:\n                self.log_error(\n                    fl_ctx, \"Execution Exception on client during model submission. No model submitted for this client.\"\n                )\n            # Ignore contribution if result invalid.\n            elif rc in [\n                ReturnCode.EXECUTION_RESULT_ERROR,\n                ReturnCode.TASK_DATA_FILTER_ERROR,\n                ReturnCode.TASK_RESULT_FILTER_ERROR,\n                ReturnCode.TASK_UNKNOWN,\n            ]:\n                self.log_error(fl_ctx, \"Execution result is not a shareable. Model submission will be ignored.\")\n            else:\n                self.log_error(fl_ctx, \"Return code set. Model submission from client will be ignored.\")\n        else:\n            # Save shareable in models directory.\n            try:\n                self.log_debug(fl_ctx, \"Extracting DXO from shareable.\")\n                dxo = from_shareable(result)\n                save_path = self._save_validation_content(client_name, self._cross_val_models_dir, dxo, fl_ctx)\n            except ValueError as v_e:\n                self.log_error(\n                    fl_ctx, f\"Unable to save shareable contents of {client_name}'s model. Exception: {str(v_e)}\"\n                )\n                self.log_warning(fl_ctx, f\"Ignoring client {client_name}'s model.\")\n                return\n\n            self.log_info(fl_ctx, f\"Received local model from client {client_name}.\")\n\n            self._client_models[client_name] = save_path\n\n            # Send a model to this client to validate\n            self._send_validation_task(client_name, fl_ctx)",
  "def _send_validation_task(self, model_name: str, fl_ctx: FLContext):\n        self.log_info(fl_ctx, f\"Sending {model_name} model to all participating clients for validation.\")\n\n        # Create validation task and broadcast to all participating clients.\n        task = Task(\n            name=self._validation_task_name,\n            data=Shareable(),\n            before_task_sent_cb=self._before_send_validate_task_cb,\n            after_task_sent_cb=self._after_send_validate_task_cb,\n            result_received_cb=self._receive_val_result_cb,\n            timeout=self._validation_timeout,\n            props={AppConstants.MODEL_OWNER: model_name},\n        )\n\n        self.broadcast(\n            task=task,\n            fl_ctx=fl_ctx,\n            targets=self._participating_clients,\n            min_responses=len(self._participating_clients),\n            wait_time_after_min_received=0,\n        )",
  "def _accept_val_result(self, client_name: str, result: Shareable, fl_ctx: FLContext):\n        model_owner = result.get_cookie(AppConstants.MODEL_OWNER, \"\")\n\n        # Fire event. This needs to be a new local context per each client\n        fl_ctx.set_prop(AppConstants.MODEL_OWNER, model_owner, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.DATA_CLIENT, client_name, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.VALIDATION_RESULT, result, private=True, sticky=False)\n        self.fire_event(AppEventType.VALIDATION_RESULT_RECEIVED, fl_ctx)\n\n        rc = result.get_return_code()\n        if rc and rc != ReturnCode.OK:\n            # Raise errors if bad peer context or execution exception.\n            if rc in [ReturnCode.MISSING_PEER_CONTEXT, ReturnCode.BAD_PEER_CONTEXT]:\n                self.log_error(fl_ctx, \"Peer context is bad or missing.\")\n            elif rc in [ReturnCode.EXECUTION_EXCEPTION, ReturnCode.TASK_UNKNOWN]:\n                self.log_error(fl_ctx, \"Execution Exception in model validation.\")\n            elif rc in [\n                ReturnCode.EXECUTION_RESULT_ERROR,\n                ReturnCode.TASK_DATA_FILTER_ERROR,\n                ReturnCode.TASK_RESULT_FILTER_ERROR,\n            ]:\n                self.log_error(fl_ctx, \"Execution result is not a shareable. Validation results will be ignored.\")\n            else:\n                self.log_error(\n                    fl_ctx,\n                    f\"Client {client_name} sent results for validating {model_owner} model with return code set.\"\n                    \" Logging empty results.\",\n                )\n\n            self._val_results[client_name][model_owner] = {}\n        else:\n            save_file_name = client_name + \"_\" + model_owner\n\n            try:\n                dxo = from_shareable(result)\n                self._save_validation_content(save_file_name, self._cross_val_results_dir, dxo, fl_ctx)\n                self._val_results[client_name][model_owner] = os.path.join(self._cross_val_results_dir, save_file_name)\n\n                self.log_info(fl_ctx, f\"Client {client_name} sent results for validating {model_owner} model.\")\n            except ValueError as v_e:\n                reason = (\n                    f\"Unable to save validation result from {client_name} of {model_owner}'s model. \"\n                    f\"Exception: {str(v_e)}\"\n                )\n                self.log_exception(fl_ctx, reason)",
  "def _save_validation_content(self, name: str, save_dir: str, dxo: DXO, fl_ctx: FLContext) -> str:\n        \"\"\"Saves shareable to given directory within the app_dir.\n\n        Args:\n            name (str): Name of shareable\n            save_dir (str): Relative path to directory in which to save\n            shareable (Shareable): Shareable object\n            fl_ctx (FLContext): FLContext object\n\n        Returns:\n            str: Path to the file saved.\n        \"\"\"\n        # Save the model with name as the filename to shareable directory\n        data_filename = os.path.join(save_dir, name)\n\n        try:\n            bytes_to_save = dxo.to_bytes()\n        except Exception as e:\n            raise ValueError(f\"Unable to extract shareable contents. Exception: {(e.__str__())}\") from e\n\n        # Save contents to path\n        try:\n            with open(data_filename, \"wb\") as f:\n                f.write(bytes_to_save)\n        except Exception as e:\n            raise ValueError(f\"Unable to save shareable contents: {str(e)}\") from e\n\n        self.log_debug(fl_ctx, f\"Saved cross validation model with name: {name}.\")\n\n        return data_filename",
  "def _load_validation_content(self, name: str, load_dir: str, fl_ctx: FLContext) -> Union[DXO, None]:\n        # Load shareable from disk\n        shareable_filename = os.path.join(load_dir, name)\n        dxo: DXO = None\n\n        # load shareable\n        try:\n            with open(shareable_filename, \"rb\") as f:\n                data = f.read()\n\n            dxo: DXO = from_bytes(data)\n\n            self.log_debug(fl_ctx, f\"Loading cross validation shareable content with name: {name}.\")\n        except Exception as e:\n            raise ValueError(f\"Exception in loading shareable content for {name}: {str(e)}\")\n\n        return dxo",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        super().handle_event(event_type=event_type, fl_ctx=fl_ctx)\n        if event_type == InfoCollector.EVENT_TYPE_GET_STATS:\n            if self._formatter:\n                collector = fl_ctx.get_prop(InfoCollector.CTX_KEY_STATS_COLLECTOR, None)\n                if collector:\n                    if not isinstance(collector, GroupInfoCollector):\n                        raise TypeError(\"collector must be GroupInfoCollector but got {}\".format(type(collector)))\n\n                    fl_ctx.set_prop(AppConstants.VALIDATION_RESULT, self._val_results, private=True, sticky=False)\n                    val_info = self._formatter.format(fl_ctx)\n\n                    collector.add_info(\n                        group_name=self._name,\n                        info={\"val_results\": val_info},\n                    )\n            else:\n                self.log_warning(fl_ctx, \"No formatter provided. Validation results can't be printed.\")",
  "def process_result_of_unknown_task(\n        self, client: Client, task_name: str, client_task_id: str, result: Shareable, fl_ctx: FLContext\n    ):\n        if task_name == self._submit_model_task_name:\n            self._accept_local_model(client_name=client.name, result=result, fl_ctx=fl_ctx)\n        elif task_name == self._validation_task_name:\n            self._accept_val_result(client_name=client.name, result=result, fl_ctx=fl_ctx)\n        else:\n            self.log_error(fl_ctx, \"Ignoring result from unknown task.\")",
  "class ScatterAndGather(Controller):\n    def __init__(\n        self,\n        min_clients: int = 1,\n        num_rounds: int = 5,\n        start_round: int = 0,\n        wait_time_after_min_received: int = 10,\n        aggregator_id=AppConstants.DEFAULT_AGGREGATOR_ID,\n        persistor_id=AppConstants.DEFAULT_PERSISTOR_ID,\n        shareable_generator_id=AppConstants.DEFAULT_SHAREABLE_GENERATOR_ID,\n        train_task_name=AppConstants.TASK_TRAIN,\n        train_timeout: int = 0,\n        ignore_result_error: bool = False,\n    ):\n        \"\"\"The controller for ScatterAndGather Workflow.\n\n        The ScatterAndGather workflow defines FederatedAveraging on all clients.\n        The model persistor (persistor_id) is used to load the initial global model which is sent to all clients.\n        Each client sends it's updated weights after local training which is aggregated (aggregator_id). The\n        shareable generator is used to convert the aggregated weights to shareable and shareable back to weight.\n        The model_persistor also saves the model after training.\n\n        Args:\n            min_clients (int, optional): Min number of clients in training. Defaults to 1.\n            num_rounds (int, optional): The total number of training rounds. Defaults to 5.\n            start_round (int, optional): Start round for training. Defaults to 0.\n            wait_time_after_min_received (int, optional): Time to wait before beginning aggregation after\n                contributions received. Defaults to 10.\n            aggregator_id (str, optional): ID of the aggregator component. Defaults to \"aggregator\".\n            persistor_id (str, optional): ID of the persistor component. Defaults to \"persistor\".\n            shareable_generator_id (str, optional): ID of the shareable generator. Defaults to \"shareable_generator\".\n            train_task_name (str, optional): Name of the train task. Defaults to \"train\".\n            train_timeout (int, optional): Time to wait for clients to do local training.\n            ignore_result_error (bool, optional): whether this controller can proceed if client result has errors.\n                Defaults to False.\n\n        Raises:\n            TypeError: when any of input arguments does not have correct type\n            ValueError: when any of input arguments is out of range\n        \"\"\"\n        Controller.__init__(self)\n\n        # Check arguments\n        if not isinstance(min_clients, int):\n            raise TypeError(\"min_clients must be int but got {}\".format(type(min_clients)))\n        if not isinstance(num_rounds, int):\n            raise TypeError(\"num_rounds must be int but got {}\".format(type(num_rounds)))\n        if not isinstance(start_round, int):\n            raise TypeError(\"start_round must be int but got {}\".format(type(start_round)))\n        if not isinstance(wait_time_after_min_received, int):\n            raise TypeError(\n                \"wait_time_after_min_received must be int but got {}\".format(type(wait_time_after_min_received))\n            )\n        if not isinstance(train_timeout, int):\n            raise TypeError(\"train_timeout must be int but got {}\".format(type(train_timeout)))\n        if not isinstance(aggregator_id, str):\n            raise TypeError(\"aggregator_id must be a string but got {}\".format(type(aggregator_id)))\n        if not isinstance(persistor_id, str):\n            raise TypeError(\"persistor_id must be a string but got {}\".format(type(persistor_id)))\n        if not isinstance(shareable_generator_id, str):\n            raise TypeError(\"shareable_generator_id must be a string but got {}\".format(type(shareable_generator_id)))\n        if not isinstance(train_task_name, str):\n            raise TypeError(\"train_task_name must be a string but got {}\".format(type(train_task_name)))\n        if min_clients <= 0:\n            raise ValueError(\"min_clients must be greater than 0.\")\n        if num_rounds < 0:\n            raise ValueError(\"num_rounds must be greater than or equal to 0.\")\n        if start_round < 0:\n            raise ValueError(\"start_round must be greater than or equal to 0.\")\n        if wait_time_after_min_received < 0:\n            raise ValueError(\"wait_time_after_min_received must be greater than or equal to 0.\")\n\n        self.aggregator_id = aggregator_id\n        self.persistor_id = persistor_id\n        self.shareable_generator_id = shareable_generator_id\n        self.train_task_name = train_task_name\n        self.aggregator = None\n        self.persistor = None\n        self.shareable_gen = None\n\n        # config data\n        self._min_clients = min_clients\n        self._num_rounds = num_rounds\n        self._wait_time_after_min_received = wait_time_after_min_received  # 5 minutes\n        self._start_round = start_round\n        self._train_timeout = train_timeout\n        self.ignore_result_error = ignore_result_error\n\n        # workflow phases: init, train, validate\n        self._phase = AppConstants.PHASE_INIT\n        self._global_weights = None\n        self._current_round = None\n\n    def start_controller(self, fl_ctx: FLContext) -> None:\n        self.log_info(fl_ctx, \"Initializing ScatterAndGather workflow.\")\n        self._phase = AppConstants.PHASE_INIT\n        engine = fl_ctx.get_engine()\n        if not engine:\n            self.system_panic(\"Engine not found. ScatterAndGather exiting.\", fl_ctx)\n            return\n\n        self.aggregator = engine.get_component(self.aggregator_id)\n        if not isinstance(self.aggregator, Aggregator):\n            self.system_panic(\n                f\"aggregator {self.aggregator_id} must be an Aggregator type object but got {type(self.aggregator)}\",\n                fl_ctx,\n            )\n            return\n\n        self.shareable_gen = engine.get_component(self.shareable_generator_id)\n        if not isinstance(self.shareable_gen, ShareableGenerator):\n            self.system_panic(\n                f\"Shareable generator {self.shareable_generator_id} must be a ShareableGenerator type object, \"\n                f\"but got {type(self.shareable_gen)}\",\n                fl_ctx,\n            )\n            return\n\n        self.persistor = engine.get_component(self.persistor_id)\n        if not isinstance(self.persistor, LearnablePersistor):\n            self.system_panic(\n                f\"Model Persistor {self.persistor_id} must be a LearnablePersistor type object, \"\n                f\"but got {type(self.persistor)}\",\n                fl_ctx,\n            )\n            return\n\n        # initialize global model\n        fl_ctx.set_prop(AppConstants.START_ROUND, self._start_round, private=True, sticky=True)\n        fl_ctx.set_prop(AppConstants.NUM_ROUNDS, self._num_rounds, private=True, sticky=False)\n        self._global_weights = self.persistor.load(fl_ctx)\n        fl_ctx.set_prop(AppConstants.GLOBAL_MODEL, self._global_weights, private=True, sticky=True)\n        self.fire_event(AppEventType.INITIAL_MODEL_LOADED, fl_ctx)\n\n    def control_flow(self, abort_signal: Signal, fl_ctx: FLContext) -> None:\n        try:\n\n            self.log_info(fl_ctx, \"Beginning ScatterAndGather training phase.\")\n            self._phase = AppConstants.PHASE_TRAIN\n\n            fl_ctx.set_prop(AppConstants.PHASE, self._phase, private=True, sticky=False)\n            fl_ctx.set_prop(AppConstants.NUM_ROUNDS, self._num_rounds, private=True, sticky=False)\n            self.fire_event(AppEventType.TRAINING_STARTED, fl_ctx)\n\n            # for self._current_round in range(self._start_round, self._start_round + self._num_rounds):\n            if self._current_round is None:\n                self._current_round = self._start_round\n            while self._current_round < self._start_round + self._num_rounds:\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.log_info(fl_ctx, f\"Round {self._current_round} started.\")\n                fl_ctx.set_prop(AppConstants.GLOBAL_MODEL, self._global_weights, private=True, sticky=True)\n                fl_ctx.set_prop(AppConstants.CURRENT_ROUND, self._current_round, private=True, sticky=False)\n                self.fire_event(AppEventType.ROUND_STARTED, fl_ctx)\n\n                # Create train_task\n                data_shareable: Shareable = self.shareable_gen.learnable_to_shareable(self._global_weights, fl_ctx)\n                data_shareable.set_header(AppConstants.CURRENT_ROUND, self._current_round)\n                data_shareable.set_header(AppConstants.NUM_ROUNDS, self._num_rounds)\n                data_shareable.add_cookie(AppConstants.CONTRIBUTION_ROUND, self._current_round)\n\n                train_task = Task(\n                    name=self.train_task_name,\n                    data=data_shareable,\n                    props={},\n                    timeout=self._train_timeout,\n                    before_task_sent_cb=self._prepare_train_task_data,\n                    result_received_cb=self._process_train_result,\n                )\n\n                self.broadcast_and_wait(\n                    task=train_task,\n                    min_responses=self._min_clients,\n                    wait_time_after_min_received=self._wait_time_after_min_received,\n                    fl_ctx=fl_ctx,\n                    abort_signal=abort_signal,\n                )\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.fire_event(AppEventType.BEFORE_AGGREGATION, fl_ctx)\n                aggr_result = self.aggregator.aggregate(fl_ctx)\n                fl_ctx.set_prop(AppConstants.AGGREGATION_RESULT, aggr_result, private=True, sticky=False)\n                self.fire_event(AppEventType.AFTER_AGGREGATION, fl_ctx)\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.fire_event(AppEventType.BEFORE_SHAREABLE_TO_LEARNABLE, fl_ctx)\n                self._global_weights = self.shareable_gen.shareable_to_learnable(aggr_result, fl_ctx)\n                fl_ctx.set_prop(AppConstants.GLOBAL_MODEL, self._global_weights, private=True, sticky=True)\n                fl_ctx.sync_sticky()\n                self.fire_event(AppEventType.AFTER_SHAREABLE_TO_LEARNABLE, fl_ctx)\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.fire_event(AppEventType.BEFORE_LEARNABLE_PERSIST, fl_ctx)\n                self.persistor.save(self._global_weights, fl_ctx)\n                self.fire_event(AppEventType.AFTER_LEARNABLE_PERSIST, fl_ctx)\n\n                self.fire_event(AppEventType.ROUND_DONE, fl_ctx)\n                self.log_info(fl_ctx, f\"Round {self._current_round} finished.\")\n\n                self._current_round += 1\n\n                # Call the engine to persist the snapshot of all the FLComponents\n                engine = fl_ctx.get_engine()\n                engine.persist_components(fl_ctx, completed=False)\n\n            self._phase = AppConstants.PHASE_FINISHED\n            self.log_info(fl_ctx, \"Finished ScatterAndGather Training.\")\n        except BaseException as e:\n            traceback.print_exc()\n            error_msg = f\"Exception in ScatterAndGather control_flow: {e}\"\n            self.log_exception(fl_ctx, error_msg)\n            self.system_panic(str(e), fl_ctx)\n\n    def stop_controller(self, fl_ctx: FLContext) -> None:\n        self._phase = AppConstants.PHASE_FINISHED\n        self.cancel_all_tasks()\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        super().handle_event(event_type, fl_ctx)\n        if event_type == InfoCollector.EVENT_TYPE_GET_STATS:\n            collector = fl_ctx.get_prop(InfoCollector.CTX_KEY_STATS_COLLECTOR, None)\n            if collector:\n                if not isinstance(collector, GroupInfoCollector):\n                    raise TypeError(\"collector must be GroupInfoCollector but got {}\".format(type(collector)))\n\n                collector.add_info(\n                    group_name=self._name,\n                    info={\"phase\": self._phase, \"current_round\": self._current_round, \"num_rounds\": self._num_rounds},\n                )\n\n    def _prepare_train_task_data(self, client_task: ClientTask, fl_ctx: FLContext) -> None:\n        fl_ctx.set_prop(AppConstants.TRAIN_SHAREABLE, client_task.task.data, private=True, sticky=False)\n        self.fire_event(AppEventType.BEFORE_TRAIN_TASK, fl_ctx)\n\n    def _process_train_result(self, client_task: ClientTask, fl_ctx: FLContext) -> None:\n        result = client_task.result\n        client_name = client_task.client.name\n\n        self._accept_train_result(client_name=client_name, result=result, fl_ctx=fl_ctx)\n\n        # Cleanup task result\n        client_task.result = None\n\n    def process_result_of_unknown_task(\n        self, client: Client, task_name, client_task_id, result: Shareable, fl_ctx: FLContext\n    ) -> None:\n        if self._phase == AppConstants.PHASE_TRAIN and task_name == self.train_task_name:\n            self._accept_train_result(client_name=client.name, result=result, fl_ctx=fl_ctx)\n            self.log_info(fl_ctx, f\"Result of unknown task {task_name} sent to aggregator.\")\n        else:\n            self.log_error(fl_ctx, \"Ignoring result from unknown task.\")\n\n    def _accept_train_result(self, client_name: str, result: Shareable, fl_ctx: FLContext) -> bool:\n\n        rc = result.get_return_code()\n        contribution_round = result.get_cookie(AppConstants.CONTRIBUTION_ROUND)\n        result.set_header(AppConstants.CONTRIBUTION_ROUND, contribution_round)\n\n        # Raise errors if bad peer context or execution exception.\n        if rc and rc != ReturnCode.OK:\n            if self.ignore_result_error:\n                self.log_error(fl_ctx, f\"Ignore the client train result. Train result error code: {rc}\")\n                return False\n            else:\n                if rc in [ReturnCode.MISSING_PEER_CONTEXT, ReturnCode.BAD_PEER_CONTEXT]:\n                    self.system_panic(\"Peer context is bad or missing. ScatterAndGather exiting.\", fl_ctx=fl_ctx)\n                    return False\n                elif rc in [ReturnCode.EXECUTION_EXCEPTION, ReturnCode.TASK_UNKNOWN]:\n                    self.system_panic(\n                        \"Execution Exception in client training. ScatterAndGather exiting.\", fl_ctx=fl_ctx\n                    )\n                    return False\n                elif rc in [\n                    ReturnCode.EXECUTION_RESULT_ERROR,\n                    ReturnCode.TASK_DATA_FILTER_ERROR,\n                    ReturnCode.TASK_RESULT_FILTER_ERROR,\n                ]:\n                    self.system_panic(\"Execution result is not a shareable. ScatterAndGather exiting.\", fl_ctx=fl_ctx)\n                    return False\n\n        fl_ctx.set_prop(AppConstants.CURRENT_ROUND, self._current_round, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.TRAINING_RESULT, result, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.CONTRIBUTION_ROUND, contribution_round, private=True, sticky=False)\n        self.fire_event(AppEventType.BEFORE_CONTRIBUTION_ACCEPT, fl_ctx)\n\n        accepted = self.aggregator.accept(result, fl_ctx)\n        accepted_msg = \"ACCEPTED\" if accepted else \"REJECTED\"\n        self.log_info(fl_ctx, f\"Contribution from {client_name} {accepted_msg} by the aggregator.\")\n\n        fl_ctx.set_prop(AppConstants.AGGREGATION_ACCEPTED, accepted, private=True, sticky=False)\n        self.fire_event(AppEventType.AFTER_CONTRIBUTION_ACCEPT, fl_ctx)\n\n        return accepted\n\n    def _check_abort_signal(self, fl_ctx, abort_signal: Signal):\n        if abort_signal.triggered:\n            self._phase = AppConstants.PHASE_FINISHED\n            self.log_info(fl_ctx, f\"Abort signal received. Exiting at round {self._current_round}.\")\n            return True\n        return False\n\n    def get_persist_state(self, fl_ctx: FLContext) -> dict:\n        return {\n            \"current_round\": self._current_round,\n            \"start_round\": self._start_round,\n            \"num_rounds\": self._num_rounds,\n            \"global_weights\": self._global_weights,\n        }\n\n    def restore(self, state_data: dict, fl_ctx: FLContext):\n        try:\n            self._current_round = state_data.get(\"current_round\")\n            self._start_round = state_data.get(\"start_round\")\n            self._num_rounds = state_data.get(\"num_rounds\")\n            self._global_weights = state_data.get(\"global_weights\")\n        finally:\n            pass",
  "def __init__(\n        self,\n        min_clients: int = 1,\n        num_rounds: int = 5,\n        start_round: int = 0,\n        wait_time_after_min_received: int = 10,\n        aggregator_id=AppConstants.DEFAULT_AGGREGATOR_ID,\n        persistor_id=AppConstants.DEFAULT_PERSISTOR_ID,\n        shareable_generator_id=AppConstants.DEFAULT_SHAREABLE_GENERATOR_ID,\n        train_task_name=AppConstants.TASK_TRAIN,\n        train_timeout: int = 0,\n        ignore_result_error: bool = False,\n    ):\n        \"\"\"The controller for ScatterAndGather Workflow.\n\n        The ScatterAndGather workflow defines FederatedAveraging on all clients.\n        The model persistor (persistor_id) is used to load the initial global model which is sent to all clients.\n        Each client sends it's updated weights after local training which is aggregated (aggregator_id). The\n        shareable generator is used to convert the aggregated weights to shareable and shareable back to weight.\n        The model_persistor also saves the model after training.\n\n        Args:\n            min_clients (int, optional): Min number of clients in training. Defaults to 1.\n            num_rounds (int, optional): The total number of training rounds. Defaults to 5.\n            start_round (int, optional): Start round for training. Defaults to 0.\n            wait_time_after_min_received (int, optional): Time to wait before beginning aggregation after\n                contributions received. Defaults to 10.\n            aggregator_id (str, optional): ID of the aggregator component. Defaults to \"aggregator\".\n            persistor_id (str, optional): ID of the persistor component. Defaults to \"persistor\".\n            shareable_generator_id (str, optional): ID of the shareable generator. Defaults to \"shareable_generator\".\n            train_task_name (str, optional): Name of the train task. Defaults to \"train\".\n            train_timeout (int, optional): Time to wait for clients to do local training.\n            ignore_result_error (bool, optional): whether this controller can proceed if client result has errors.\n                Defaults to False.\n\n        Raises:\n            TypeError: when any of input arguments does not have correct type\n            ValueError: when any of input arguments is out of range\n        \"\"\"\n        Controller.__init__(self)\n\n        # Check arguments\n        if not isinstance(min_clients, int):\n            raise TypeError(\"min_clients must be int but got {}\".format(type(min_clients)))\n        if not isinstance(num_rounds, int):\n            raise TypeError(\"num_rounds must be int but got {}\".format(type(num_rounds)))\n        if not isinstance(start_round, int):\n            raise TypeError(\"start_round must be int but got {}\".format(type(start_round)))\n        if not isinstance(wait_time_after_min_received, int):\n            raise TypeError(\n                \"wait_time_after_min_received must be int but got {}\".format(type(wait_time_after_min_received))\n            )\n        if not isinstance(train_timeout, int):\n            raise TypeError(\"train_timeout must be int but got {}\".format(type(train_timeout)))\n        if not isinstance(aggregator_id, str):\n            raise TypeError(\"aggregator_id must be a string but got {}\".format(type(aggregator_id)))\n        if not isinstance(persistor_id, str):\n            raise TypeError(\"persistor_id must be a string but got {}\".format(type(persistor_id)))\n        if not isinstance(shareable_generator_id, str):\n            raise TypeError(\"shareable_generator_id must be a string but got {}\".format(type(shareable_generator_id)))\n        if not isinstance(train_task_name, str):\n            raise TypeError(\"train_task_name must be a string but got {}\".format(type(train_task_name)))\n        if min_clients <= 0:\n            raise ValueError(\"min_clients must be greater than 0.\")\n        if num_rounds < 0:\n            raise ValueError(\"num_rounds must be greater than or equal to 0.\")\n        if start_round < 0:\n            raise ValueError(\"start_round must be greater than or equal to 0.\")\n        if wait_time_after_min_received < 0:\n            raise ValueError(\"wait_time_after_min_received must be greater than or equal to 0.\")\n\n        self.aggregator_id = aggregator_id\n        self.persistor_id = persistor_id\n        self.shareable_generator_id = shareable_generator_id\n        self.train_task_name = train_task_name\n        self.aggregator = None\n        self.persistor = None\n        self.shareable_gen = None\n\n        # config data\n        self._min_clients = min_clients\n        self._num_rounds = num_rounds\n        self._wait_time_after_min_received = wait_time_after_min_received  # 5 minutes\n        self._start_round = start_round\n        self._train_timeout = train_timeout\n        self.ignore_result_error = ignore_result_error\n\n        # workflow phases: init, train, validate\n        self._phase = AppConstants.PHASE_INIT\n        self._global_weights = None\n        self._current_round = None",
  "def start_controller(self, fl_ctx: FLContext) -> None:\n        self.log_info(fl_ctx, \"Initializing ScatterAndGather workflow.\")\n        self._phase = AppConstants.PHASE_INIT\n        engine = fl_ctx.get_engine()\n        if not engine:\n            self.system_panic(\"Engine not found. ScatterAndGather exiting.\", fl_ctx)\n            return\n\n        self.aggregator = engine.get_component(self.aggregator_id)\n        if not isinstance(self.aggregator, Aggregator):\n            self.system_panic(\n                f\"aggregator {self.aggregator_id} must be an Aggregator type object but got {type(self.aggregator)}\",\n                fl_ctx,\n            )\n            return\n\n        self.shareable_gen = engine.get_component(self.shareable_generator_id)\n        if not isinstance(self.shareable_gen, ShareableGenerator):\n            self.system_panic(\n                f\"Shareable generator {self.shareable_generator_id} must be a ShareableGenerator type object, \"\n                f\"but got {type(self.shareable_gen)}\",\n                fl_ctx,\n            )\n            return\n\n        self.persistor = engine.get_component(self.persistor_id)\n        if not isinstance(self.persistor, LearnablePersistor):\n            self.system_panic(\n                f\"Model Persistor {self.persistor_id} must be a LearnablePersistor type object, \"\n                f\"but got {type(self.persistor)}\",\n                fl_ctx,\n            )\n            return\n\n        # initialize global model\n        fl_ctx.set_prop(AppConstants.START_ROUND, self._start_round, private=True, sticky=True)\n        fl_ctx.set_prop(AppConstants.NUM_ROUNDS, self._num_rounds, private=True, sticky=False)\n        self._global_weights = self.persistor.load(fl_ctx)\n        fl_ctx.set_prop(AppConstants.GLOBAL_MODEL, self._global_weights, private=True, sticky=True)\n        self.fire_event(AppEventType.INITIAL_MODEL_LOADED, fl_ctx)",
  "def control_flow(self, abort_signal: Signal, fl_ctx: FLContext) -> None:\n        try:\n\n            self.log_info(fl_ctx, \"Beginning ScatterAndGather training phase.\")\n            self._phase = AppConstants.PHASE_TRAIN\n\n            fl_ctx.set_prop(AppConstants.PHASE, self._phase, private=True, sticky=False)\n            fl_ctx.set_prop(AppConstants.NUM_ROUNDS, self._num_rounds, private=True, sticky=False)\n            self.fire_event(AppEventType.TRAINING_STARTED, fl_ctx)\n\n            # for self._current_round in range(self._start_round, self._start_round + self._num_rounds):\n            if self._current_round is None:\n                self._current_round = self._start_round\n            while self._current_round < self._start_round + self._num_rounds:\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.log_info(fl_ctx, f\"Round {self._current_round} started.\")\n                fl_ctx.set_prop(AppConstants.GLOBAL_MODEL, self._global_weights, private=True, sticky=True)\n                fl_ctx.set_prop(AppConstants.CURRENT_ROUND, self._current_round, private=True, sticky=False)\n                self.fire_event(AppEventType.ROUND_STARTED, fl_ctx)\n\n                # Create train_task\n                data_shareable: Shareable = self.shareable_gen.learnable_to_shareable(self._global_weights, fl_ctx)\n                data_shareable.set_header(AppConstants.CURRENT_ROUND, self._current_round)\n                data_shareable.set_header(AppConstants.NUM_ROUNDS, self._num_rounds)\n                data_shareable.add_cookie(AppConstants.CONTRIBUTION_ROUND, self._current_round)\n\n                train_task = Task(\n                    name=self.train_task_name,\n                    data=data_shareable,\n                    props={},\n                    timeout=self._train_timeout,\n                    before_task_sent_cb=self._prepare_train_task_data,\n                    result_received_cb=self._process_train_result,\n                )\n\n                self.broadcast_and_wait(\n                    task=train_task,\n                    min_responses=self._min_clients,\n                    wait_time_after_min_received=self._wait_time_after_min_received,\n                    fl_ctx=fl_ctx,\n                    abort_signal=abort_signal,\n                )\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.fire_event(AppEventType.BEFORE_AGGREGATION, fl_ctx)\n                aggr_result = self.aggregator.aggregate(fl_ctx)\n                fl_ctx.set_prop(AppConstants.AGGREGATION_RESULT, aggr_result, private=True, sticky=False)\n                self.fire_event(AppEventType.AFTER_AGGREGATION, fl_ctx)\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.fire_event(AppEventType.BEFORE_SHAREABLE_TO_LEARNABLE, fl_ctx)\n                self._global_weights = self.shareable_gen.shareable_to_learnable(aggr_result, fl_ctx)\n                fl_ctx.set_prop(AppConstants.GLOBAL_MODEL, self._global_weights, private=True, sticky=True)\n                fl_ctx.sync_sticky()\n                self.fire_event(AppEventType.AFTER_SHAREABLE_TO_LEARNABLE, fl_ctx)\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.fire_event(AppEventType.BEFORE_LEARNABLE_PERSIST, fl_ctx)\n                self.persistor.save(self._global_weights, fl_ctx)\n                self.fire_event(AppEventType.AFTER_LEARNABLE_PERSIST, fl_ctx)\n\n                self.fire_event(AppEventType.ROUND_DONE, fl_ctx)\n                self.log_info(fl_ctx, f\"Round {self._current_round} finished.\")\n\n                self._current_round += 1\n\n                # Call the engine to persist the snapshot of all the FLComponents\n                engine = fl_ctx.get_engine()\n                engine.persist_components(fl_ctx, completed=False)\n\n            self._phase = AppConstants.PHASE_FINISHED\n            self.log_info(fl_ctx, \"Finished ScatterAndGather Training.\")\n        except BaseException as e:\n            traceback.print_exc()\n            error_msg = f\"Exception in ScatterAndGather control_flow: {e}\"\n            self.log_exception(fl_ctx, error_msg)\n            self.system_panic(str(e), fl_ctx)",
  "def stop_controller(self, fl_ctx: FLContext) -> None:\n        self._phase = AppConstants.PHASE_FINISHED\n        self.cancel_all_tasks()",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        super().handle_event(event_type, fl_ctx)\n        if event_type == InfoCollector.EVENT_TYPE_GET_STATS:\n            collector = fl_ctx.get_prop(InfoCollector.CTX_KEY_STATS_COLLECTOR, None)\n            if collector:\n                if not isinstance(collector, GroupInfoCollector):\n                    raise TypeError(\"collector must be GroupInfoCollector but got {}\".format(type(collector)))\n\n                collector.add_info(\n                    group_name=self._name,\n                    info={\"phase\": self._phase, \"current_round\": self._current_round, \"num_rounds\": self._num_rounds},\n                )",
  "def _prepare_train_task_data(self, client_task: ClientTask, fl_ctx: FLContext) -> None:\n        fl_ctx.set_prop(AppConstants.TRAIN_SHAREABLE, client_task.task.data, private=True, sticky=False)\n        self.fire_event(AppEventType.BEFORE_TRAIN_TASK, fl_ctx)",
  "def _process_train_result(self, client_task: ClientTask, fl_ctx: FLContext) -> None:\n        result = client_task.result\n        client_name = client_task.client.name\n\n        self._accept_train_result(client_name=client_name, result=result, fl_ctx=fl_ctx)\n\n        # Cleanup task result\n        client_task.result = None",
  "def process_result_of_unknown_task(\n        self, client: Client, task_name, client_task_id, result: Shareable, fl_ctx: FLContext\n    ) -> None:\n        if self._phase == AppConstants.PHASE_TRAIN and task_name == self.train_task_name:\n            self._accept_train_result(client_name=client.name, result=result, fl_ctx=fl_ctx)\n            self.log_info(fl_ctx, f\"Result of unknown task {task_name} sent to aggregator.\")\n        else:\n            self.log_error(fl_ctx, \"Ignoring result from unknown task.\")",
  "def _accept_train_result(self, client_name: str, result: Shareable, fl_ctx: FLContext) -> bool:\n\n        rc = result.get_return_code()\n        contribution_round = result.get_cookie(AppConstants.CONTRIBUTION_ROUND)\n        result.set_header(AppConstants.CONTRIBUTION_ROUND, contribution_round)\n\n        # Raise errors if bad peer context or execution exception.\n        if rc and rc != ReturnCode.OK:\n            if self.ignore_result_error:\n                self.log_error(fl_ctx, f\"Ignore the client train result. Train result error code: {rc}\")\n                return False\n            else:\n                if rc in [ReturnCode.MISSING_PEER_CONTEXT, ReturnCode.BAD_PEER_CONTEXT]:\n                    self.system_panic(\"Peer context is bad or missing. ScatterAndGather exiting.\", fl_ctx=fl_ctx)\n                    return False\n                elif rc in [ReturnCode.EXECUTION_EXCEPTION, ReturnCode.TASK_UNKNOWN]:\n                    self.system_panic(\n                        \"Execution Exception in client training. ScatterAndGather exiting.\", fl_ctx=fl_ctx\n                    )\n                    return False\n                elif rc in [\n                    ReturnCode.EXECUTION_RESULT_ERROR,\n                    ReturnCode.TASK_DATA_FILTER_ERROR,\n                    ReturnCode.TASK_RESULT_FILTER_ERROR,\n                ]:\n                    self.system_panic(\"Execution result is not a shareable. ScatterAndGather exiting.\", fl_ctx=fl_ctx)\n                    return False\n\n        fl_ctx.set_prop(AppConstants.CURRENT_ROUND, self._current_round, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.TRAINING_RESULT, result, private=True, sticky=False)\n        fl_ctx.set_prop(AppConstants.CONTRIBUTION_ROUND, contribution_round, private=True, sticky=False)\n        self.fire_event(AppEventType.BEFORE_CONTRIBUTION_ACCEPT, fl_ctx)\n\n        accepted = self.aggregator.accept(result, fl_ctx)\n        accepted_msg = \"ACCEPTED\" if accepted else \"REJECTED\"\n        self.log_info(fl_ctx, f\"Contribution from {client_name} {accepted_msg} by the aggregator.\")\n\n        fl_ctx.set_prop(AppConstants.AGGREGATION_ACCEPTED, accepted, private=True, sticky=False)\n        self.fire_event(AppEventType.AFTER_CONTRIBUTION_ACCEPT, fl_ctx)\n\n        return accepted",
  "def _check_abort_signal(self, fl_ctx, abort_signal: Signal):\n        if abort_signal.triggered:\n            self._phase = AppConstants.PHASE_FINISHED\n            self.log_info(fl_ctx, f\"Abort signal received. Exiting at round {self._current_round}.\")\n            return True\n        return False",
  "def get_persist_state(self, fl_ctx: FLContext) -> dict:\n        return {\n            \"current_round\": self._current_round,\n            \"start_round\": self._start_round,\n            \"num_rounds\": self._num_rounds,\n            \"global_weights\": self._global_weights,\n        }",
  "def restore(self, state_data: dict, fl_ctx: FLContext):\n        try:\n            self._current_round = state_data.get(\"current_round\")\n            self._start_round = state_data.get(\"start_round\")\n            self._num_rounds = state_data.get(\"num_rounds\")\n            self._global_weights = state_data.get(\"global_weights\")\n        finally:\n            pass",
  "class GlobalModelEval(CrossSiteModelEval):\n    def __init__(\n        self,\n        task_check_period=0.5,\n        cross_val_dir=AppConstants.CROSS_VAL_DIR,\n        validation_timeout: int = 6000,\n        model_locator_id=\"\",\n        formatter_id=\"\",\n        validation_task_name=AppConstants.TASK_VALIDATION,\n        cleanup_models=False,\n        participating_clients=None,\n        wait_for_clients_timeout=300,\n    ):\n        \"\"\"Cross Site Model Validation workflow.\n\n        Args:\n            task_check_period (float, optional): How often to check for new tasks or tasks being finished.\n                Defaults to 0.5.\n            cross_val_dir (str, optional): Path to cross site validation directory relative to run directory.\n                Defaults to \"cross_site_val\".\n            validation_timeout (int, optional): Timeout for validate_model task. Defaults to 6000.\n            model_locator_id (str, optional): ID for model_locator component. Defaults to None.\n            formatter_id (str, optional): ID for formatter component. Defaults to None.\n            validation_task_name (str, optional): Name of validate_model task. Defaults to \"validate\".\n            cleanup_models (bool, optional): Whether or not models should be deleted after run. Defaults to False.\n            participating_clients (list, optional): List of participating client names. If not provided, defaults\n                to all clients connected at start of controller.\n            wait_for_clients_timeout (int, optional): Timeout for clients to appear. Defaults to 300 secs\n        \"\"\"\n        if not model_locator_id:\n            raise ValueError(\"missing required model_locator_id\")\n\n        CrossSiteModelEval.__init__(\n            self,\n            task_check_period=task_check_period,\n            cross_val_dir=cross_val_dir,\n            validation_timeout=validation_timeout,\n            model_locator_id=model_locator_id,\n            formatter_id=formatter_id,\n            validation_task_name=validation_task_name,\n            submit_model_task_name=\"\",\n            cleanup_models=cleanup_models,\n            participating_clients=participating_clients,\n            wait_for_clients_timeout=wait_for_clients_timeout,\n        )",
  "def __init__(\n        self,\n        task_check_period=0.5,\n        cross_val_dir=AppConstants.CROSS_VAL_DIR,\n        validation_timeout: int = 6000,\n        model_locator_id=\"\",\n        formatter_id=\"\",\n        validation_task_name=AppConstants.TASK_VALIDATION,\n        cleanup_models=False,\n        participating_clients=None,\n        wait_for_clients_timeout=300,\n    ):\n        \"\"\"Cross Site Model Validation workflow.\n\n        Args:\n            task_check_period (float, optional): How often to check for new tasks or tasks being finished.\n                Defaults to 0.5.\n            cross_val_dir (str, optional): Path to cross site validation directory relative to run directory.\n                Defaults to \"cross_site_val\".\n            validation_timeout (int, optional): Timeout for validate_model task. Defaults to 6000.\n            model_locator_id (str, optional): ID for model_locator component. Defaults to None.\n            formatter_id (str, optional): ID for formatter component. Defaults to None.\n            validation_task_name (str, optional): Name of validate_model task. Defaults to \"validate\".\n            cleanup_models (bool, optional): Whether or not models should be deleted after run. Defaults to False.\n            participating_clients (list, optional): List of participating client names. If not provided, defaults\n                to all clients connected at start of controller.\n            wait_for_clients_timeout (int, optional): Timeout for clients to appear. Defaults to 300 secs\n        \"\"\"\n        if not model_locator_id:\n            raise ValueError(\"missing required model_locator_id\")\n\n        CrossSiteModelEval.__init__(\n            self,\n            task_check_period=task_check_period,\n            cross_val_dir=cross_val_dir,\n            validation_timeout=validation_timeout,\n            model_locator_id=model_locator_id,\n            formatter_id=formatter_id,\n            validation_task_name=validation_task_name,\n            submit_model_task_name=\"\",\n            cleanup_models=cleanup_models,\n            participating_clients=participating_clients,\n            wait_for_clients_timeout=wait_for_clients_timeout,\n        )",
  "class ScatterAndGatherScaffold(ScatterAndGather):\n    def __init__(\n        self,\n        min_clients: int = 1,\n        num_rounds: int = 5,\n        start_round: int = 0,\n        wait_time_after_min_received: int = 10,\n        aggregator_id=AppConstants.DEFAULT_AGGREGATOR_ID,\n        persistor_id=AppConstants.DEFAULT_PERSISTOR_ID,\n        shareable_generator_id=AppConstants.DEFAULT_SHAREABLE_GENERATOR_ID,\n        train_task_name=AppConstants.TASK_TRAIN,\n        train_timeout: int = 0,\n        ignore_result_error: bool = False,\n    ):\n        \"\"\"The controller for ScatterAndGatherScaffold workflow.\n\n        The model persistor (persistor_id) is used to load the initial global model which is sent to all clients.\n        Each client sends it's updated weights after local training which is aggregated (aggregator_id). The\n        shareable generator is used to convert the aggregated weights to shareable and shareable back to weight.\n        The model_persistor also saves the model after training.\n\n        Args:\n            min_clients (int, optional): Min number of clients in training. Defaults to 1.\n            num_rounds (int, optional): The total number of training rounds. Defaults to 5.\n            start_round (int, optional): Start round for training. Defaults to 0.\n            wait_time_after_min_received (int, optional): Time to wait before beginning aggregation after\n                contributions received. Defaults to 10.\n            train_timeout (int, optional): Time to wait for clients to do local training.\n            aggregator_id (str, optional): ID of the aggregator component. Defaults to \"aggregator\".\n            persistor_id (str, optional): ID of the persistor component. Defaults to \"persistor\".\n            shareable_generator_id (str, optional): ID of the shareable generator. Defaults to \"shareable_generator\".\n            train_task_name (str, optional): Name of the train task. Defaults to \"train\".\n        \"\"\"\n\n        super().__init__(\n            min_clients=min_clients,\n            num_rounds=num_rounds,\n            start_round=start_round,\n            wait_time_after_min_received=wait_time_after_min_received,\n            aggregator_id=aggregator_id,\n            persistor_id=persistor_id,\n            shareable_generator_id=shareable_generator_id,\n            train_task_name=train_task_name,\n            train_timeout=train_timeout,\n            ignore_result_error=ignore_result_error,\n        )\n\n        # for SCAFFOLD\n        self.aggregator_ctrl = None\n        self._global_ctrl_weights = None\n\n    def start_controller(self, fl_ctx: FLContext) -> None:\n        super().start_controller(fl_ctx=fl_ctx)\n        self.log_info(fl_ctx, \"Initializing ScatterAndGatherScaffold workflow.\")\n\n        # for SCAFFOLD\n        if not self._global_weights:\n            self.system_panic(\"Global weights not available!\", fl_ctx)\n            return\n\n        self._global_ctrl_weights = copy.deepcopy(self._global_weights[\"weights\"])\n        # Initialize correction term with zeros\n        for k in self._global_ctrl_weights.keys():\n            self._global_ctrl_weights[k] = np.zeros_like(self._global_ctrl_weights[k])\n        # TODO: Print some stats of the correction magnitudes\n\n    def control_flow(self, abort_signal: Signal, fl_ctx: FLContext) -> None:\n        try:\n\n            self.log_info(fl_ctx, \"Beginning ScatterAndGatherScaffold training phase.\")\n            self._phase = AppConstants.PHASE_TRAIN\n\n            fl_ctx.set_prop(AppConstants.PHASE, self._phase, private=True, sticky=False)\n            fl_ctx.set_prop(AppConstants.NUM_ROUNDS, self._num_rounds, private=True, sticky=False)\n            self.fire_event(AppEventType.TRAINING_STARTED, fl_ctx)\n\n            for self._current_round in range(self._start_round, self._start_round + self._num_rounds):\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.log_info(fl_ctx, f\"Round {self._current_round} started.\")\n                fl_ctx.set_prop(AppConstants.GLOBAL_MODEL, self._global_weights, private=True, sticky=True)\n                fl_ctx.set_prop(AppConstants.CURRENT_ROUND, self._current_round, private=True, sticky=False)\n                self.fire_event(AppEventType.ROUND_STARTED, fl_ctx)\n\n                # Create train_task\n                # get DXO with global model weights\n                dxo_global_weights = model_learnable_to_dxo(self._global_weights)\n\n                # add global SCAFFOLD controls using a DXO collection\n                dxo_global_ctrl = DXO(data_kind=DataKind.WEIGHT_DIFF, data=self._global_ctrl_weights)\n                dxo_dict = {\n                    AppConstants.MODEL_WEIGHTS: dxo_global_weights,\n                    AlgorithmConstants.SCAFFOLD_CTRL_GLOBAL: dxo_global_ctrl,\n                }\n                dxo_collection = DXO(data_kind=DataKind.COLLECTION, data=dxo_dict)\n                data_shareable = dxo_collection.to_shareable()\n\n                # add meta information\n                data_shareable.set_header(AppConstants.CURRENT_ROUND, self._current_round)\n                data_shareable.set_header(AppConstants.NUM_ROUNDS, self._num_rounds)\n                data_shareable.add_cookie(AppConstants.CONTRIBUTION_ROUND, self._current_round)\n\n                train_task = Task(\n                    name=self.train_task_name,\n                    data=data_shareable,\n                    props={},\n                    timeout=self._train_timeout,\n                    before_task_sent_cb=self._prepare_train_task_data,\n                    result_received_cb=self._process_train_result,\n                )\n\n                self.broadcast_and_wait(\n                    task=train_task,\n                    min_responses=self._min_clients,\n                    wait_time_after_min_received=self._wait_time_after_min_received,\n                    fl_ctx=fl_ctx,\n                    abort_signal=abort_signal,\n                )\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.fire_event(AppEventType.BEFORE_AGGREGATION, fl_ctx)\n                aggr_result = self.aggregator.aggregate(fl_ctx)\n\n                # extract aggregated weights and controls\n                collection_dxo = from_shareable(aggr_result)\n                dxo_aggr_result = collection_dxo.data.get(AppConstants.MODEL_WEIGHTS)\n                if not dxo_aggr_result:\n                    self.log_error(fl_ctx, \"Aggregated model weights are missing!\")\n                    return\n                dxo_ctrl_aggr_result = collection_dxo.data.get(AlgorithmConstants.SCAFFOLD_CTRL_DIFF)\n                if not dxo_ctrl_aggr_result:\n                    self.log_error(fl_ctx, \"Aggregated model weight controls are missing!\")\n                    return\n\n                fl_ctx.set_prop(AppConstants.AGGREGATION_RESULT, aggr_result, private=True, sticky=False)\n                self.fire_event(AppEventType.AFTER_AGGREGATION, fl_ctx)\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                # update global model using shareable generator\n                self.fire_event(AppEventType.BEFORE_SHAREABLE_TO_LEARNABLE, fl_ctx)\n                self._global_weights = self.shareable_gen.shareable_to_learnable(dxo_aggr_result.to_shareable(), fl_ctx)\n\n                # update SCAFFOLD global controls\n                ctr_diff = dxo_ctrl_aggr_result.data\n                for v_name, v_value in ctr_diff.items():\n                    self._global_ctrl_weights[v_name] += v_value\n                fl_ctx.set_prop(\n                    AlgorithmConstants.SCAFFOLD_CTRL_GLOBAL, self._global_ctrl_weights, private=True, sticky=True\n                )\n\n                fl_ctx.set_prop(AppConstants.GLOBAL_MODEL, self._global_weights, private=True, sticky=True)\n                fl_ctx.sync_sticky()\n                self.fire_event(AppEventType.AFTER_SHAREABLE_TO_LEARNABLE, fl_ctx)\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.fire_event(AppEventType.BEFORE_LEARNABLE_PERSIST, fl_ctx)\n                self.persistor.save(self._global_weights, fl_ctx)\n                self.fire_event(AppEventType.AFTER_LEARNABLE_PERSIST, fl_ctx)\n\n                self.fire_event(AppEventType.ROUND_DONE, fl_ctx)\n                self.log_info(fl_ctx, f\"Round {self._current_round} finished.\")\n\n            self._phase = AppConstants.PHASE_FINISHED\n            self.log_info(fl_ctx, \"Finished ScatterAndGatherScaffold Training.\")\n        except BaseException as e:\n            traceback.print_exc()\n            error_msg = f\"Exception in ScatterAndGatherScaffold control_flow: {e}\"\n            self.log_exception(fl_ctx, error_msg)\n            self.system_panic(str(e), fl_ctx)",
  "def __init__(\n        self,\n        min_clients: int = 1,\n        num_rounds: int = 5,\n        start_round: int = 0,\n        wait_time_after_min_received: int = 10,\n        aggregator_id=AppConstants.DEFAULT_AGGREGATOR_ID,\n        persistor_id=AppConstants.DEFAULT_PERSISTOR_ID,\n        shareable_generator_id=AppConstants.DEFAULT_SHAREABLE_GENERATOR_ID,\n        train_task_name=AppConstants.TASK_TRAIN,\n        train_timeout: int = 0,\n        ignore_result_error: bool = False,\n    ):\n        \"\"\"The controller for ScatterAndGatherScaffold workflow.\n\n        The model persistor (persistor_id) is used to load the initial global model which is sent to all clients.\n        Each client sends it's updated weights after local training which is aggregated (aggregator_id). The\n        shareable generator is used to convert the aggregated weights to shareable and shareable back to weight.\n        The model_persistor also saves the model after training.\n\n        Args:\n            min_clients (int, optional): Min number of clients in training. Defaults to 1.\n            num_rounds (int, optional): The total number of training rounds. Defaults to 5.\n            start_round (int, optional): Start round for training. Defaults to 0.\n            wait_time_after_min_received (int, optional): Time to wait before beginning aggregation after\n                contributions received. Defaults to 10.\n            train_timeout (int, optional): Time to wait for clients to do local training.\n            aggregator_id (str, optional): ID of the aggregator component. Defaults to \"aggregator\".\n            persistor_id (str, optional): ID of the persistor component. Defaults to \"persistor\".\n            shareable_generator_id (str, optional): ID of the shareable generator. Defaults to \"shareable_generator\".\n            train_task_name (str, optional): Name of the train task. Defaults to \"train\".\n        \"\"\"\n\n        super().__init__(\n            min_clients=min_clients,\n            num_rounds=num_rounds,\n            start_round=start_round,\n            wait_time_after_min_received=wait_time_after_min_received,\n            aggregator_id=aggregator_id,\n            persistor_id=persistor_id,\n            shareable_generator_id=shareable_generator_id,\n            train_task_name=train_task_name,\n            train_timeout=train_timeout,\n            ignore_result_error=ignore_result_error,\n        )\n\n        # for SCAFFOLD\n        self.aggregator_ctrl = None\n        self._global_ctrl_weights = None",
  "def start_controller(self, fl_ctx: FLContext) -> None:\n        super().start_controller(fl_ctx=fl_ctx)\n        self.log_info(fl_ctx, \"Initializing ScatterAndGatherScaffold workflow.\")\n\n        # for SCAFFOLD\n        if not self._global_weights:\n            self.system_panic(\"Global weights not available!\", fl_ctx)\n            return\n\n        self._global_ctrl_weights = copy.deepcopy(self._global_weights[\"weights\"])\n        # Initialize correction term with zeros\n        for k in self._global_ctrl_weights.keys():\n            self._global_ctrl_weights[k] = np.zeros_like(self._global_ctrl_weights[k])",
  "def control_flow(self, abort_signal: Signal, fl_ctx: FLContext) -> None:\n        try:\n\n            self.log_info(fl_ctx, \"Beginning ScatterAndGatherScaffold training phase.\")\n            self._phase = AppConstants.PHASE_TRAIN\n\n            fl_ctx.set_prop(AppConstants.PHASE, self._phase, private=True, sticky=False)\n            fl_ctx.set_prop(AppConstants.NUM_ROUNDS, self._num_rounds, private=True, sticky=False)\n            self.fire_event(AppEventType.TRAINING_STARTED, fl_ctx)\n\n            for self._current_round in range(self._start_round, self._start_round + self._num_rounds):\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.log_info(fl_ctx, f\"Round {self._current_round} started.\")\n                fl_ctx.set_prop(AppConstants.GLOBAL_MODEL, self._global_weights, private=True, sticky=True)\n                fl_ctx.set_prop(AppConstants.CURRENT_ROUND, self._current_round, private=True, sticky=False)\n                self.fire_event(AppEventType.ROUND_STARTED, fl_ctx)\n\n                # Create train_task\n                # get DXO with global model weights\n                dxo_global_weights = model_learnable_to_dxo(self._global_weights)\n\n                # add global SCAFFOLD controls using a DXO collection\n                dxo_global_ctrl = DXO(data_kind=DataKind.WEIGHT_DIFF, data=self._global_ctrl_weights)\n                dxo_dict = {\n                    AppConstants.MODEL_WEIGHTS: dxo_global_weights,\n                    AlgorithmConstants.SCAFFOLD_CTRL_GLOBAL: dxo_global_ctrl,\n                }\n                dxo_collection = DXO(data_kind=DataKind.COLLECTION, data=dxo_dict)\n                data_shareable = dxo_collection.to_shareable()\n\n                # add meta information\n                data_shareable.set_header(AppConstants.CURRENT_ROUND, self._current_round)\n                data_shareable.set_header(AppConstants.NUM_ROUNDS, self._num_rounds)\n                data_shareable.add_cookie(AppConstants.CONTRIBUTION_ROUND, self._current_round)\n\n                train_task = Task(\n                    name=self.train_task_name,\n                    data=data_shareable,\n                    props={},\n                    timeout=self._train_timeout,\n                    before_task_sent_cb=self._prepare_train_task_data,\n                    result_received_cb=self._process_train_result,\n                )\n\n                self.broadcast_and_wait(\n                    task=train_task,\n                    min_responses=self._min_clients,\n                    wait_time_after_min_received=self._wait_time_after_min_received,\n                    fl_ctx=fl_ctx,\n                    abort_signal=abort_signal,\n                )\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.fire_event(AppEventType.BEFORE_AGGREGATION, fl_ctx)\n                aggr_result = self.aggregator.aggregate(fl_ctx)\n\n                # extract aggregated weights and controls\n                collection_dxo = from_shareable(aggr_result)\n                dxo_aggr_result = collection_dxo.data.get(AppConstants.MODEL_WEIGHTS)\n                if not dxo_aggr_result:\n                    self.log_error(fl_ctx, \"Aggregated model weights are missing!\")\n                    return\n                dxo_ctrl_aggr_result = collection_dxo.data.get(AlgorithmConstants.SCAFFOLD_CTRL_DIFF)\n                if not dxo_ctrl_aggr_result:\n                    self.log_error(fl_ctx, \"Aggregated model weight controls are missing!\")\n                    return\n\n                fl_ctx.set_prop(AppConstants.AGGREGATION_RESULT, aggr_result, private=True, sticky=False)\n                self.fire_event(AppEventType.AFTER_AGGREGATION, fl_ctx)\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                # update global model using shareable generator\n                self.fire_event(AppEventType.BEFORE_SHAREABLE_TO_LEARNABLE, fl_ctx)\n                self._global_weights = self.shareable_gen.shareable_to_learnable(dxo_aggr_result.to_shareable(), fl_ctx)\n\n                # update SCAFFOLD global controls\n                ctr_diff = dxo_ctrl_aggr_result.data\n                for v_name, v_value in ctr_diff.items():\n                    self._global_ctrl_weights[v_name] += v_value\n                fl_ctx.set_prop(\n                    AlgorithmConstants.SCAFFOLD_CTRL_GLOBAL, self._global_ctrl_weights, private=True, sticky=True\n                )\n\n                fl_ctx.set_prop(AppConstants.GLOBAL_MODEL, self._global_weights, private=True, sticky=True)\n                fl_ctx.sync_sticky()\n                self.fire_event(AppEventType.AFTER_SHAREABLE_TO_LEARNABLE, fl_ctx)\n\n                if self._check_abort_signal(fl_ctx, abort_signal):\n                    return\n\n                self.fire_event(AppEventType.BEFORE_LEARNABLE_PERSIST, fl_ctx)\n                self.persistor.save(self._global_weights, fl_ctx)\n                self.fire_event(AppEventType.AFTER_LEARNABLE_PERSIST, fl_ctx)\n\n                self.fire_event(AppEventType.ROUND_DONE, fl_ctx)\n                self.log_info(fl_ctx, f\"Round {self._current_round} finished.\")\n\n            self._phase = AppConstants.PHASE_FINISHED\n            self.log_info(fl_ctx, \"Finished ScatterAndGatherScaffold Training.\")\n        except BaseException as e:\n            traceback.print_exc()\n            error_msg = f\"Exception in ScatterAndGatherScaffold control_flow: {e}\"\n            self.log_exception(fl_ctx, error_msg)\n            self.system_panic(str(e), fl_ctx)",
  "class ListResourceManager(ResourceManagerSpec, FLComponent):\n    \"\"\"Manage a list of resource units.\n\n    For example:\n\n        - require 2, current resources is [0, 1, 2, 3, 4, 5] => return [0,1]\n          after allocation the current resources become [2, 3, 4, 5]\n        - require 3, current resources [2, 3, 4, 5] => return [2, 3, 4]\n\n    \"\"\"\n\n    def __init__(self, resources: Dict[str, List], expiration_period: int = 30):\n        \"\"\"Constructor\n\n        Args:\n            resources (dict): Specify the list of resources unit\n            expiration_period (int): Number of seconds to hold the resources reserved.\n                If check_resources is called but after \"expiration_period\" no allocate resource is called,\n                then the reserved resources will be released.\n        \"\"\"\n        super().__init__()\n        if not isinstance(resources, dict):\n            raise TypeError(f\"resources should be of type dict, but got {type(resources)}.\")\n        if not isinstance(expiration_period, int):\n            raise TypeError(f\"expiration_period should be of type int, but got {type(expiration_period)}.\")\n        if expiration_period < 0:\n            raise ValueError(\"expiration_period should be greater than 0.\")\n\n        self.resources = {}\n        for k in resources:\n            if not isinstance(resources[k], list):\n                raise TypeError(f\"item in resources should be of type list, but got {type(resources[k])}.\")\n            self.resources[k] = deque(resources[k])\n\n        self.expiration_period = expiration_period\n        self.reserved_resources = {}\n        self.lock = Lock()\n        self.stop_event = Event()\n        self.cleanup_thread = Thread(target=self._check_expired)\n\n    def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.SYSTEM_START:\n            self.cleanup_thread.start()\n        elif event_type == EventType.SYSTEM_END:\n            self.stop_event.set()\n            if self.cleanup_thread:\n                self.cleanup_thread.join()\n                self.cleanup_thread = None\n\n    def _check_expired(self):\n        while not self.stop_event.is_set():\n            time.sleep(1)\n            with self.lock:\n                tokens_to_remove = []\n                for k in self.reserved_resources:\n                    r, t = self.reserved_resources[k]\n                    t -= 1\n                    if t == 0:\n                        tokens_to_remove.append(k)\n                    else:\n                        self.reserved_resources[k] = r, t\n                for token in tokens_to_remove:\n                    reserved_resources, _ = self.reserved_resources.pop(token)\n                    for k in reserved_resources:\n                        for i in reserved_resources[k]:\n                            self.resources[k].append(i)\n                self.logger.debug(f\"current resources: {self.resources}, reserved_resources {self.reserved_resources}.\")\n\n    def _check_all_required_resource_available(self, resource_requirement: dict, fl_ctx: FLContext) -> bool:\n        check_result = True\n        with self.lock:\n            for k in resource_requirement:\n                if k in self.resources:\n                    if len(self.resources[k]) < resource_requirement[k]:\n                        check_result = False\n                        self.log_debug(fl_ctx, f\"Resource {k} is not enough.\")\n                        break\n                else:\n                    check_result = False\n                    self.log_debug(fl_ctx, f\"Missing {k} in resources.\")\n                    break\n        return check_result\n\n    def check_resources(self, resource_requirement: dict, fl_ctx: FLContext) -> (bool, Optional[str]):\n        if not isinstance(resource_requirement, dict):\n            raise TypeError(f\"resource_requirement should be of type dict, but got {type(resource_requirement)}.\")\n\n        check_result = self._check_all_required_resource_available(resource_requirement, fl_ctx)\n        token = None\n\n        # reserve resource only when check is True\n        if check_result:\n            token = str(uuid.uuid4())\n            reserved_resources = {}\n            with self.lock:\n                for k in resource_requirement:\n                    reserved_resource_units = []\n                    for i in range(resource_requirement[k]):\n                        reserved_resource_units.append(self.resources[k].popleft())\n                    reserved_resources[k] = reserved_resource_units\n                self.reserved_resources[token] = (reserved_resources, self.expiration_period)\n                self.log_debug(\n                    fl_ctx, f\"reserving resources: {reserved_resources} for requirements {resource_requirement}.\"\n                )\n                self.log_debug(\n                    fl_ctx, f\"current resources: {self.resources}, reserved_resources {self.reserved_resources}.\"\n                )\n        return check_result, token\n\n    def cancel_resources(self, resource_requirement: dict, token: str, fl_ctx: FLContext):\n        with self.lock:\n            if token and token in self.reserved_resources:\n                reserved_resources, _ = self.reserved_resources.pop(token)\n                for k in reserved_resources:\n                    for i in reserved_resources[k]:\n                        self.resources[k].appendleft(i)\n                self.log_debug(fl_ctx, f\"cancelling resources: {reserved_resources}.\")\n                self.log_debug(\n                    fl_ctx, f\"current resources: {self.resources}, reserved_resources {self.reserved_resources}.\"\n                )\n            else:\n                self.log_debug(fl_ctx, f\"Token {token} is not related to any reserved resources.\")\n        return None\n\n    def allocate_resources(self, resource_requirement: dict, token: str, fl_ctx: FLContext) -> dict:\n        result = {}\n        with self.lock:\n            if token and token in self.reserved_resources:\n                result, _ = self.reserved_resources.pop(token)\n                self.log_debug(fl_ctx, f\"allocating resources: {result} for requirements: {resource_requirement}.\")\n                self.log_debug(\n                    fl_ctx, f\"current resources: {self.resources}, reserved_resources {self.reserved_resources}.\"\n                )\n            else:\n                raise RuntimeError(f\"allocate_resources: No reserved resources for token {token}.\")\n        return result\n\n    def free_resources(self, resources: dict, token: str, fl_ctx: FLContext):\n        with self.lock:\n            self.log_debug(fl_ctx, f\"freeing resources: {resources}.\")\n            self.log_debug(\n                fl_ctx, f\"current resources: {self.resources}, reserved_resources {self.reserved_resources}.\"\n            )\n            for k in resources:\n                for i in resources[k]:\n                    self.resources[k].append(i)",
  "def __init__(self, resources: Dict[str, List], expiration_period: int = 30):\n        \"\"\"Constructor\n\n        Args:\n            resources (dict): Specify the list of resources unit\n            expiration_period (int): Number of seconds to hold the resources reserved.\n                If check_resources is called but after \"expiration_period\" no allocate resource is called,\n                then the reserved resources will be released.\n        \"\"\"\n        super().__init__()\n        if not isinstance(resources, dict):\n            raise TypeError(f\"resources should be of type dict, but got {type(resources)}.\")\n        if not isinstance(expiration_period, int):\n            raise TypeError(f\"expiration_period should be of type int, but got {type(expiration_period)}.\")\n        if expiration_period < 0:\n            raise ValueError(\"expiration_period should be greater than 0.\")\n\n        self.resources = {}\n        for k in resources:\n            if not isinstance(resources[k], list):\n                raise TypeError(f\"item in resources should be of type list, but got {type(resources[k])}.\")\n            self.resources[k] = deque(resources[k])\n\n        self.expiration_period = expiration_period\n        self.reserved_resources = {}\n        self.lock = Lock()\n        self.stop_event = Event()\n        self.cleanup_thread = Thread(target=self._check_expired)",
  "def handle_event(self, event_type: str, fl_ctx: FLContext):\n        if event_type == EventType.SYSTEM_START:\n            self.cleanup_thread.start()\n        elif event_type == EventType.SYSTEM_END:\n            self.stop_event.set()\n            if self.cleanup_thread:\n                self.cleanup_thread.join()\n                self.cleanup_thread = None",
  "def _check_expired(self):\n        while not self.stop_event.is_set():\n            time.sleep(1)\n            with self.lock:\n                tokens_to_remove = []\n                for k in self.reserved_resources:\n                    r, t = self.reserved_resources[k]\n                    t -= 1\n                    if t == 0:\n                        tokens_to_remove.append(k)\n                    else:\n                        self.reserved_resources[k] = r, t\n                for token in tokens_to_remove:\n                    reserved_resources, _ = self.reserved_resources.pop(token)\n                    for k in reserved_resources:\n                        for i in reserved_resources[k]:\n                            self.resources[k].append(i)\n                self.logger.debug(f\"current resources: {self.resources}, reserved_resources {self.reserved_resources}.\")",
  "def _check_all_required_resource_available(self, resource_requirement: dict, fl_ctx: FLContext) -> bool:\n        check_result = True\n        with self.lock:\n            for k in resource_requirement:\n                if k in self.resources:\n                    if len(self.resources[k]) < resource_requirement[k]:\n                        check_result = False\n                        self.log_debug(fl_ctx, f\"Resource {k} is not enough.\")\n                        break\n                else:\n                    check_result = False\n                    self.log_debug(fl_ctx, f\"Missing {k} in resources.\")\n                    break\n        return check_result",
  "def check_resources(self, resource_requirement: dict, fl_ctx: FLContext) -> (bool, Optional[str]):\n        if not isinstance(resource_requirement, dict):\n            raise TypeError(f\"resource_requirement should be of type dict, but got {type(resource_requirement)}.\")\n\n        check_result = self._check_all_required_resource_available(resource_requirement, fl_ctx)\n        token = None\n\n        # reserve resource only when check is True\n        if check_result:\n            token = str(uuid.uuid4())\n            reserved_resources = {}\n            with self.lock:\n                for k in resource_requirement:\n                    reserved_resource_units = []\n                    for i in range(resource_requirement[k]):\n                        reserved_resource_units.append(self.resources[k].popleft())\n                    reserved_resources[k] = reserved_resource_units\n                self.reserved_resources[token] = (reserved_resources, self.expiration_period)\n                self.log_debug(\n                    fl_ctx, f\"reserving resources: {reserved_resources} for requirements {resource_requirement}.\"\n                )\n                self.log_debug(\n                    fl_ctx, f\"current resources: {self.resources}, reserved_resources {self.reserved_resources}.\"\n                )\n        return check_result, token",
  "def cancel_resources(self, resource_requirement: dict, token: str, fl_ctx: FLContext):\n        with self.lock:\n            if token and token in self.reserved_resources:\n                reserved_resources, _ = self.reserved_resources.pop(token)\n                for k in reserved_resources:\n                    for i in reserved_resources[k]:\n                        self.resources[k].appendleft(i)\n                self.log_debug(fl_ctx, f\"cancelling resources: {reserved_resources}.\")\n                self.log_debug(\n                    fl_ctx, f\"current resources: {self.resources}, reserved_resources {self.reserved_resources}.\"\n                )\n            else:\n                self.log_debug(fl_ctx, f\"Token {token} is not related to any reserved resources.\")\n        return None",
  "def allocate_resources(self, resource_requirement: dict, token: str, fl_ctx: FLContext) -> dict:\n        result = {}\n        with self.lock:\n            if token and token in self.reserved_resources:\n                result, _ = self.reserved_resources.pop(token)\n                self.log_debug(fl_ctx, f\"allocating resources: {result} for requirements: {resource_requirement}.\")\n                self.log_debug(\n                    fl_ctx, f\"current resources: {self.resources}, reserved_resources {self.reserved_resources}.\"\n                )\n            else:\n                raise RuntimeError(f\"allocate_resources: No reserved resources for token {token}.\")\n        return result",
  "def free_resources(self, resources: dict, token: str, fl_ctx: FLContext):\n        with self.lock:\n            self.log_debug(fl_ctx, f\"freeing resources: {resources}.\")\n            self.log_debug(\n                fl_ctx, f\"current resources: {self.resources}, reserved_resources {self.reserved_resources}.\"\n            )\n            for k in resources:\n                for i in resources[k]:\n                    self.resources[k].append(i)",
  "class S3Storage(StorageSpec):\n    def __init__(self, endpoint, access_key, secret_key, secure, bucket_name):\n        \"\"\"Init S3Storage.\n\n        Uses S3 bucket to persist objects, with absolute paths as object URIs.\n\n        Args:\n            endpoint: hostname of S3 service\n            access_key: access key (username) of S3 service account\n            secret_key: secret key (password) of S3 service account\n            secure: flag for secure (TLS) mode\n            bucket_name: name of S3 bucket\n\n        Raises:\n            RuntimeError: error creating minio S3 client and bucket\n\n        \"\"\"\n        try:\n            self.s3_client = Minio(endpoint=endpoint, access_key=access_key, secret_key=secret_key, secure=secure)\n            if not self.s3_client.bucket_exists(bucket_name):\n                self.s3_client.make_bucket(bucket_name)\n        except MinioException as e:\n            raise StorageException(\"Error creating minio s3 client: {}\".format(str(e)))\n        self.bucket_name = bucket_name\n\n    def _object_exists(self, uri: str):\n        try:\n            self.s3_client.stat_object(self.bucket_name, uri)\n        except MinioException:\n            return False\n        return True\n\n    def create_object(self, uri: str, data: bytes, meta: dict, overwrite_existing: bool = False):\n        \"\"\"Creates an object.\n\n        Args:\n            uri: URI of the object\n            data: content of the object\n            meta: meta info of the object\n            overwrite_existing: whether to overwrite the object if already exists\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError:\n                - if error creating the object\n                - if object already exists and overwrite_existing is False\n                - if object will be inside pre-existing object\n                - if object will be at a non-empty directory\n\n        Examples of URI:\n\n        /state/engine/...\n        /runs/approved/covid_exam.3\n        /runs/pending/spleen_seg.1\n\n        \"\"\"\n        if self._object_exists(uri) and not overwrite_existing:\n            raise StorageException(\"object {} already exists and overwrite_existing is False\".format(uri))\n\n        if not self._object_exists(uri):\n            try:\n                dir_is_nonempty = list(\n                    self.s3_client.list_objects(self.bucket_name, prefix=uri, include_user_meta=True)\n                )\n            except MinioException as e:\n                raise StorageException(\n                    \"cannot create object: checking if uri has any objects failed: {}\".format(str(e))\n                )\n            if dir_is_nonempty:\n                raise StorageException(\"cannot create object {} at nonempty directory\".format(uri))\n\n        try:\n            self.s3_client.put_object(\n                self.bucket_name,\n                uri,\n                data=io.BytesIO(data),\n                length=-1,\n                metadata={_USER_META_KEY: meta},\n                part_size=_AWS_PART_SIZE,\n            )\n        except MinioException as e:\n            raise StorageException(\"error putting object into bucket: {}\".format(str(e)))\n\n    def update_meta(self, uri: str, meta: dict, replace: bool):\n        \"\"\"Updates the meta info of the specified object.\n\n        Args:\n            uri: URI of the object\n            meta: value of new meta info\n            replace: whether to replace the current meta completely or partial update\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError:\n                - if object does not exist\n                - if error copying object\n\n        \"\"\"\n        if not self._object_exists(uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        if not replace:\n            prev_meta = self.get_meta(uri)\n            prev_meta.update(meta)\n            meta = prev_meta\n\n        try:\n            self.s3_client.copy_object(\n                self.bucket_name,\n                uri,\n                CopySource(self.bucket_name, uri),\n                metadata={_USER_META_KEY: meta},\n                metadata_directive=REPLACE,\n            )\n        except MinioException as e:\n            raise StorageException(\"error copying object: {}\".format(str(e)))\n\n    def update_data(self, uri: str, data: bytes):\n        \"\"\"Updates the data info of the specified object.\n\n        Args:\n            uri: URI of the object\n            data: value of new data\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError:\n                - if object does not exist\n                - if error putting object into bucket\n\n        \"\"\"\n        if not self._object_exists(uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        try:\n            self.s3_client.put_object(\n                self.bucket_name,\n                uri,\n                data=io.BytesIO(data),\n                length=-1,\n                metadata={_USER_META_KEY: self.get_meta(uri)},\n                part_size=_AWS_PART_SIZE,\n            )\n        except MinioException as e:\n            raise StorageException(\"error putting object into bucket: {}\".format(str(e)))\n\n    def list_objects(self, path: str) -> List[str]:\n        \"\"\"List all objects in the specified path.\n\n        Args:\n            path: the path to the objects\n\n        Returns:\n            list of URIs of objects\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError: if error listing objects\n\n        \"\"\"\n        dir_path = path.rstrip(os.sep) + os.sep\n        try:\n            return [\n                URI_ROOT + obj._object_name\n                for obj in list(self.s3_client.list_objects(self.bucket_name, prefix=dir_path, include_user_meta=True))\n                if obj._metadata\n            ]\n        except MinioException as e:\n            raise StorageException(f\"error listing objects at {path}: {str(e)}.\")\n\n    def get_meta(self, uri: str) -> dict:\n        \"\"\"Gets user defined meta info of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            meta info of the object.\n            if object does not exist, return empty dict {}\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError:\n                - if error accessing object\n\n        \"\"\"\n        if not self._object_exists(uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        try:\n            return ast.literal_eval(\n                self.s3_client.stat_object(self.bucket_name, uri)._metadata[\"x-amz-meta-{}\".format(_USER_META_KEY)]\n            )\n        except MinioException as e:\n            raise StorageException(f\"error accessing object ({uri}): {str(e)}.\")\n\n    def get_data(self, uri: str) -> bytes:\n        \"\"\"Gets data of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            data of the object.\n            if object does not exist, return None\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError:\n                - if error accessing object\n\n        \"\"\"\n        if not self._object_exists(uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        try:\n            return self.s3_client.get_object(self.bucket_name, uri).data\n        except MinioException as e:\n            raise StorageException(f\"error accessing object ({uri}): {str(e)}.\")\n\n    def get_detail(self, uri: str) -> Tuple[dict, bytes]:\n        \"\"\"Gets both data and meta of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            meta info and data of the object.\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError: if object does not exist\n\n        \"\"\"\n        if not self._object_exists(uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        return self.get_meta(uri), self.get_data(uri)\n\n    def delete_object(self, uri: str):\n        \"\"\"Deletes the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError:\n                - if object does not exist\n                - if error removing object\n\n        \"\"\"\n        if not self._object_exists(uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        try:\n            self.s3_client.remove_object(self.bucket_name, uri)\n        except MinioException as e:\n            raise StorageException(f\"error removing object ({uri}): {str(e)}.\")",
  "def __init__(self, endpoint, access_key, secret_key, secure, bucket_name):\n        \"\"\"Init S3Storage.\n\n        Uses S3 bucket to persist objects, with absolute paths as object URIs.\n\n        Args:\n            endpoint: hostname of S3 service\n            access_key: access key (username) of S3 service account\n            secret_key: secret key (password) of S3 service account\n            secure: flag for secure (TLS) mode\n            bucket_name: name of S3 bucket\n\n        Raises:\n            RuntimeError: error creating minio S3 client and bucket\n\n        \"\"\"\n        try:\n            self.s3_client = Minio(endpoint=endpoint, access_key=access_key, secret_key=secret_key, secure=secure)\n            if not self.s3_client.bucket_exists(bucket_name):\n                self.s3_client.make_bucket(bucket_name)\n        except MinioException as e:\n            raise StorageException(\"Error creating minio s3 client: {}\".format(str(e)))\n        self.bucket_name = bucket_name",
  "def _object_exists(self, uri: str):\n        try:\n            self.s3_client.stat_object(self.bucket_name, uri)\n        except MinioException:\n            return False\n        return True",
  "def create_object(self, uri: str, data: bytes, meta: dict, overwrite_existing: bool = False):\n        \"\"\"Creates an object.\n\n        Args:\n            uri: URI of the object\n            data: content of the object\n            meta: meta info of the object\n            overwrite_existing: whether to overwrite the object if already exists\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError:\n                - if error creating the object\n                - if object already exists and overwrite_existing is False\n                - if object will be inside pre-existing object\n                - if object will be at a non-empty directory\n\n        Examples of URI:\n\n        /state/engine/...\n        /runs/approved/covid_exam.3\n        /runs/pending/spleen_seg.1\n\n        \"\"\"\n        if self._object_exists(uri) and not overwrite_existing:\n            raise StorageException(\"object {} already exists and overwrite_existing is False\".format(uri))\n\n        if not self._object_exists(uri):\n            try:\n                dir_is_nonempty = list(\n                    self.s3_client.list_objects(self.bucket_name, prefix=uri, include_user_meta=True)\n                )\n            except MinioException as e:\n                raise StorageException(\n                    \"cannot create object: checking if uri has any objects failed: {}\".format(str(e))\n                )\n            if dir_is_nonempty:\n                raise StorageException(\"cannot create object {} at nonempty directory\".format(uri))\n\n        try:\n            self.s3_client.put_object(\n                self.bucket_name,\n                uri,\n                data=io.BytesIO(data),\n                length=-1,\n                metadata={_USER_META_KEY: meta},\n                part_size=_AWS_PART_SIZE,\n            )\n        except MinioException as e:\n            raise StorageException(\"error putting object into bucket: {}\".format(str(e)))",
  "def update_meta(self, uri: str, meta: dict, replace: bool):\n        \"\"\"Updates the meta info of the specified object.\n\n        Args:\n            uri: URI of the object\n            meta: value of new meta info\n            replace: whether to replace the current meta completely or partial update\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError:\n                - if object does not exist\n                - if error copying object\n\n        \"\"\"\n        if not self._object_exists(uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        if not replace:\n            prev_meta = self.get_meta(uri)\n            prev_meta.update(meta)\n            meta = prev_meta\n\n        try:\n            self.s3_client.copy_object(\n                self.bucket_name,\n                uri,\n                CopySource(self.bucket_name, uri),\n                metadata={_USER_META_KEY: meta},\n                metadata_directive=REPLACE,\n            )\n        except MinioException as e:\n            raise StorageException(\"error copying object: {}\".format(str(e)))",
  "def update_data(self, uri: str, data: bytes):\n        \"\"\"Updates the data info of the specified object.\n\n        Args:\n            uri: URI of the object\n            data: value of new data\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError:\n                - if object does not exist\n                - if error putting object into bucket\n\n        \"\"\"\n        if not self._object_exists(uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        try:\n            self.s3_client.put_object(\n                self.bucket_name,\n                uri,\n                data=io.BytesIO(data),\n                length=-1,\n                metadata={_USER_META_KEY: self.get_meta(uri)},\n                part_size=_AWS_PART_SIZE,\n            )\n        except MinioException as e:\n            raise StorageException(\"error putting object into bucket: {}\".format(str(e)))",
  "def list_objects(self, path: str) -> List[str]:\n        \"\"\"List all objects in the specified path.\n\n        Args:\n            path: the path to the objects\n\n        Returns:\n            list of URIs of objects\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError: if error listing objects\n\n        \"\"\"\n        dir_path = path.rstrip(os.sep) + os.sep\n        try:\n            return [\n                URI_ROOT + obj._object_name\n                for obj in list(self.s3_client.list_objects(self.bucket_name, prefix=dir_path, include_user_meta=True))\n                if obj._metadata\n            ]\n        except MinioException as e:\n            raise StorageException(f\"error listing objects at {path}: {str(e)}.\")",
  "def get_meta(self, uri: str) -> dict:\n        \"\"\"Gets user defined meta info of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            meta info of the object.\n            if object does not exist, return empty dict {}\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError:\n                - if error accessing object\n\n        \"\"\"\n        if not self._object_exists(uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        try:\n            return ast.literal_eval(\n                self.s3_client.stat_object(self.bucket_name, uri)._metadata[\"x-amz-meta-{}\".format(_USER_META_KEY)]\n            )\n        except MinioException as e:\n            raise StorageException(f\"error accessing object ({uri}): {str(e)}.\")",
  "def get_data(self, uri: str) -> bytes:\n        \"\"\"Gets data of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            data of the object.\n            if object does not exist, return None\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError:\n                - if error accessing object\n\n        \"\"\"\n        if not self._object_exists(uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        try:\n            return self.s3_client.get_object(self.bucket_name, uri).data\n        except MinioException as e:\n            raise StorageException(f\"error accessing object ({uri}): {str(e)}.\")",
  "def get_detail(self, uri: str) -> Tuple[dict, bytes]:\n        \"\"\"Gets both data and meta of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            meta info and data of the object.\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError: if object does not exist\n\n        \"\"\"\n        if not self._object_exists(uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        return self.get_meta(uri), self.get_data(uri)",
  "def delete_object(self, uri: str):\n        \"\"\"Deletes the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Raises:\n            TypeError: if invalid argument types\n            RuntimeError:\n                - if object does not exist\n                - if error removing object\n\n        \"\"\"\n        if not self._object_exists(uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        try:\n            self.s3_client.remove_object(self.bucket_name, uri)\n        except MinioException as e:\n            raise StorageException(f\"error removing object ({uri}): {str(e)}.\")",
  "def _write(path: str, content):\n    tmp_path = path + \"_\" + str(uuid.uuid4())\n    try:\n        Path(os.path.dirname(path)).mkdir(parents=True, exist_ok=True)\n        with open(tmp_path, \"wb\") as f:\n            f.write(content)\n            f.flush()\n            os.fsync(f.fileno())\n    except Exception as e:\n        if os.path.isfile(tmp_path):\n            os.remove(tmp_path)\n        raise StorageException(\"failed to write content: {}\".format(e))\n\n    if os.path.exists(tmp_path):\n        os.rename(tmp_path, path)",
  "def _read(path: str) -> bytes:\n    try:\n        with open(path, \"rb\") as f:\n            content = f.read()\n    except Exception as e:\n        raise StorageException(\"failed to read content: {}\".format(e))\n\n    return content",
  "def _object_exists(uri: str):\n    \"\"\"Checks whether an object exists at specified directory.\"\"\"\n    data_exists = os.path.isfile(os.path.join(uri, \"data\"))\n    meta_exists = os.path.isfile(os.path.join(uri, \"meta\"))\n    return all((os.path.isabs(uri), os.path.isdir(uri), data_exists, meta_exists))",
  "class FilesystemStorage(StorageSpec):\n    def __init__(self, root_dir=os.path.abspath(os.sep), uri_root=\"/\"):\n        \"\"\"Init FileSystemStorage.\n\n        Uses local filesystem to persist objects, with absolute paths as object URIs.\n\n        Args:\n            root_dir: the absolute path on the filesystem to store things\n            uri_root: serving as the root of the storage. All URIs are rooted at this uri_root.\n        \"\"\"\n        if not os.path.isabs(root_dir):\n            raise ValueError(f\"root_dir {root_dir} must be an absolute path.\")\n        if os.path.exists(root_dir) and not os.path.isdir(root_dir):\n            raise ValueError(f\"root_dir {root_dir} exists but is not a directory.\")\n        if not os.path.exists(root_dir):\n            os.makedirs(root_dir, exist_ok=False)\n        self.root_dir = root_dir\n        self.uri_root = uri_root\n\n    def create_object(self, uri: str, data: bytes, meta: dict, overwrite_existing: bool = False):\n        \"\"\"Creates an object.\n\n        Args:\n            uri: URI of the object\n            data: content of the object\n            meta: meta of the object\n            overwrite_existing: whether to overwrite the object if already exists\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException:\n                - if error creating the object\n                - if object already exists and overwrite_existing is False\n                - if object will be at a non-empty directory\n            IOError: if error writing the object\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if _object_exists(full_uri) and not overwrite_existing:\n            raise StorageException(\"object {} already exists and overwrite_existing is False\".format(uri))\n\n        if not _object_exists(full_uri) and os.path.isdir(full_uri) and os.listdir(full_uri):\n            raise StorageException(\"cannot create object {} at nonempty directory\".format(uri))\n\n        data_path = os.path.join(full_uri, \"data\")\n        meta_path = os.path.join(full_uri, \"meta\")\n\n        tmp_data_path = data_path + \"_\" + str(uuid.uuid4())\n        _write(tmp_data_path, data)\n        try:\n            _write(meta_path, json.dumps(str(meta)).encode(\"utf-8\"))\n        except Exception as e:\n            os.remove(tmp_data_path)\n            raise e\n        os.rename(tmp_data_path, data_path)\n\n        return full_uri\n\n    def update_meta(self, uri: str, meta: dict, replace: bool):\n        \"\"\"Updates the meta of the specified object.\n\n        Args:\n            uri: URI of the object\n            meta: value of new meta\n            replace: whether to replace the current meta completely or partial update\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if object does not exist\n            IOError: if error writing the object\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if not _object_exists(full_uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        if replace:\n            _write(os.path.join(full_uri, \"meta\"), json.dumps(str(meta)).encode(\"utf-8\"))\n        else:\n            prev_meta = self.get_meta(uri)\n            prev_meta.update(meta)\n            _write(os.path.join(full_uri, \"meta\"), json.dumps(str(prev_meta)).encode(\"utf-8\"))\n\n    def update_data(self, uri: str, data: bytes):\n        \"\"\"Updates the data of the specified object.\n\n        Args:\n            uri: URI of the object\n            data: value of new data\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if object does not exist\n            IOError: if error writing the object\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if not _object_exists(full_uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        _write(os.path.join(full_uri, \"data\"), data)\n\n    def list_objects(self, path: str) -> List[str]:\n        \"\"\"List all objects in the specified path.\n\n        Args:\n            path: the path uri to the objects\n\n        Returns:\n            list of URIs of objects\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if path does not exist or is not a valid directory.\n\n        \"\"\"\n        full_dir_path = os.path.join(self.root_dir, path.lstrip(self.uri_root))\n        if not os.path.isdir(full_dir_path):\n            raise StorageException(f\"path {full_dir_path} is not a valid directory.\")\n\n        return [\n            os.path.join(path, f) for f in os.listdir(full_dir_path) if _object_exists(os.path.join(full_dir_path, f))\n        ]\n\n    def get_meta(self, uri: str) -> dict:\n        \"\"\"Gets meta of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            meta of the object.\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if object does not exist\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if not _object_exists(full_uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        return ast.literal_eval(json.loads(_read(os.path.join(full_uri, \"meta\")).decode(\"utf-8\")))\n\n    def get_data(self, uri: str) -> bytes:\n        \"\"\"Gets data of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            data of the object.\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if object does not exist\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if not _object_exists(full_uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        return _read(os.path.join(full_uri, \"data\"))\n\n    def get_detail(self, uri: str) -> Tuple[dict, bytes]:\n        \"\"\"Gets both data and meta of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            meta and data of the object.\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if object does not exist\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if not _object_exists(full_uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        return self.get_meta(uri), self.get_data(uri)\n\n    def delete_object(self, uri: str):\n        \"\"\"Deletes the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if object does not exist\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if not _object_exists(full_uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        shutil.rmtree(full_uri)\n\n        return full_uri",
  "def __init__(self, root_dir=os.path.abspath(os.sep), uri_root=\"/\"):\n        \"\"\"Init FileSystemStorage.\n\n        Uses local filesystem to persist objects, with absolute paths as object URIs.\n\n        Args:\n            root_dir: the absolute path on the filesystem to store things\n            uri_root: serving as the root of the storage. All URIs are rooted at this uri_root.\n        \"\"\"\n        if not os.path.isabs(root_dir):\n            raise ValueError(f\"root_dir {root_dir} must be an absolute path.\")\n        if os.path.exists(root_dir) and not os.path.isdir(root_dir):\n            raise ValueError(f\"root_dir {root_dir} exists but is not a directory.\")\n        if not os.path.exists(root_dir):\n            os.makedirs(root_dir, exist_ok=False)\n        self.root_dir = root_dir\n        self.uri_root = uri_root",
  "def create_object(self, uri: str, data: bytes, meta: dict, overwrite_existing: bool = False):\n        \"\"\"Creates an object.\n\n        Args:\n            uri: URI of the object\n            data: content of the object\n            meta: meta of the object\n            overwrite_existing: whether to overwrite the object if already exists\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException:\n                - if error creating the object\n                - if object already exists and overwrite_existing is False\n                - if object will be at a non-empty directory\n            IOError: if error writing the object\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if _object_exists(full_uri) and not overwrite_existing:\n            raise StorageException(\"object {} already exists and overwrite_existing is False\".format(uri))\n\n        if not _object_exists(full_uri) and os.path.isdir(full_uri) and os.listdir(full_uri):\n            raise StorageException(\"cannot create object {} at nonempty directory\".format(uri))\n\n        data_path = os.path.join(full_uri, \"data\")\n        meta_path = os.path.join(full_uri, \"meta\")\n\n        tmp_data_path = data_path + \"_\" + str(uuid.uuid4())\n        _write(tmp_data_path, data)\n        try:\n            _write(meta_path, json.dumps(str(meta)).encode(\"utf-8\"))\n        except Exception as e:\n            os.remove(tmp_data_path)\n            raise e\n        os.rename(tmp_data_path, data_path)\n\n        return full_uri",
  "def update_meta(self, uri: str, meta: dict, replace: bool):\n        \"\"\"Updates the meta of the specified object.\n\n        Args:\n            uri: URI of the object\n            meta: value of new meta\n            replace: whether to replace the current meta completely or partial update\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if object does not exist\n            IOError: if error writing the object\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if not _object_exists(full_uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        if replace:\n            _write(os.path.join(full_uri, \"meta\"), json.dumps(str(meta)).encode(\"utf-8\"))\n        else:\n            prev_meta = self.get_meta(uri)\n            prev_meta.update(meta)\n            _write(os.path.join(full_uri, \"meta\"), json.dumps(str(prev_meta)).encode(\"utf-8\"))",
  "def update_data(self, uri: str, data: bytes):\n        \"\"\"Updates the data of the specified object.\n\n        Args:\n            uri: URI of the object\n            data: value of new data\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if object does not exist\n            IOError: if error writing the object\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if not _object_exists(full_uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        _write(os.path.join(full_uri, \"data\"), data)",
  "def list_objects(self, path: str) -> List[str]:\n        \"\"\"List all objects in the specified path.\n\n        Args:\n            path: the path uri to the objects\n\n        Returns:\n            list of URIs of objects\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if path does not exist or is not a valid directory.\n\n        \"\"\"\n        full_dir_path = os.path.join(self.root_dir, path.lstrip(self.uri_root))\n        if not os.path.isdir(full_dir_path):\n            raise StorageException(f\"path {full_dir_path} is not a valid directory.\")\n\n        return [\n            os.path.join(path, f) for f in os.listdir(full_dir_path) if _object_exists(os.path.join(full_dir_path, f))\n        ]",
  "def get_meta(self, uri: str) -> dict:\n        \"\"\"Gets meta of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            meta of the object.\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if object does not exist\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if not _object_exists(full_uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        return ast.literal_eval(json.loads(_read(os.path.join(full_uri, \"meta\")).decode(\"utf-8\")))",
  "def get_data(self, uri: str) -> bytes:\n        \"\"\"Gets data of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            data of the object.\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if object does not exist\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if not _object_exists(full_uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        return _read(os.path.join(full_uri, \"data\"))",
  "def get_detail(self, uri: str) -> Tuple[dict, bytes]:\n        \"\"\"Gets both data and meta of the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Returns:\n            meta and data of the object.\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if object does not exist\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if not _object_exists(full_uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        return self.get_meta(uri), self.get_data(uri)",
  "def delete_object(self, uri: str):\n        \"\"\"Deletes the specified object.\n\n        Args:\n            uri: URI of the object\n\n        Raises:\n            TypeError: if invalid argument types\n            StorageException: if object does not exist\n\n        \"\"\"\n        full_uri = os.path.join(self.root_dir, uri.lstrip(self.uri_root))\n\n        if not _object_exists(full_uri):\n            raise StorageException(\"object {} does not exist\".format(uri))\n\n        shutil.rmtree(full_uri)\n\n        return full_uri",
  "class Right(object):\n\n    UPLOAD_APP = \"upload_app\"\n    DEPLOY_ALL = \"deploy_all\"\n    DEPLOY_SELF = \"deploy_self\"\n    OPERATE_ALL = \"operate_all\"\n    OPERATE_SELF = \"operate_self\"\n    VIEW_ALL = \"view_all\"\n    VIEW_SELF = \"view_self\"\n    TRAIN_ALL = \"train_all\"\n    TRAIN_SELF = \"train_self\"",
  "class Rule(object):\n\n    ALLOW_BYOC = \"allow_byoc\"\n    ALLOW_CUSTOM_DATALIST = \"allow_custom_datalist\"",
  "class Action(object):\n\n    UPLOAD = \"upload\"\n    DEPLOY = \"deploy\"\n    OPERATE = \"operate\"\n    VIEW = \"view\"\n    TRAIN = \"train\"\n    BYOC = \"byoc\"\n    CUSTOM_DATALIST = \"custom_datalist\"",
  "class FLAuthzContext(AuthzContext):\n    def __init__(self, user_name: str, site_names: List[str], actions: List[str]):\n        \"\"\"System-wide authorization context.\n\n        Information about the authorization, such as roles, users, sites and actions\n\n        Args:\n            user_name (str): user name\n            site_names (List[str]): all the sites to be checked\n            actions (List[str]): associated actions\n        \"\"\"\n        AuthzContext.__init__(self, user_name=user_name, site_names=site_names)\n        self.actions = actions\n\n    @staticmethod\n    def new_authz_context(site_names: List[str], actions: List[str]):\n        assert len(actions) > 0, \"actions must be specified\"\n        for a in actions:\n            assert a in [\n                Action.UPLOAD,\n                Action.DEPLOY,\n                Action.OPERATE,\n                Action.VIEW,\n                Action.TRAIN,\n                Action.BYOC,\n                Action.CUSTOM_DATALIST,\n            ], \"invalid action {}\".format(a)\n\n        return FLAuthzContext(user_name=\"\", site_names=site_names, actions=actions)",
  "def action_checker_signature(user_name, site_name):\n    return True, \"\"",
  "class FLAuthorizer(Authorizer):\n    def __init__(self):\n        \"\"\"System-wide authorization class.\n\n        Examine if a user has certain rights on a specific site\n        based on authorization.json file.\n\n        \"\"\"\n        Authorizer.__init__(self)\n        self.action_checkers = {\n            Action.UPLOAD: self._user_can_upload,\n            Action.DEPLOY: self._user_can_deploy,\n            Action.OPERATE: self._user_can_operate,\n            Action.VIEW: self._user_can_view,\n            Action.TRAIN: self._user_can_train,\n            Action.BYOC: self._site_allows_byoc,\n            Action.CUSTOM_DATALIST: self._site_allows_custom_datalist,\n        }\n\n    def evaluate_user_right_on_site(self, right_name: str, user_name: str, site_name: str):\n        \"\"\"Check whether a user has a right in an org.\n\n        Superuser has all rights in all orgs.\n\n        Args:\n            right_name: right to be evaluated\n            user_name: user to be evaluated against\n            site_name: the org\n\n        Returns:\n            A tuple of (result, error).\n\n            result: True/False for bool type right; Int number for int rule; None if error occurred during evaluation\n\n            error: Error occurred during evaluation\n        \"\"\"\n        right_type = self.policy.get_right_type(right_name)\n        if right_type == \"bool\":\n            user = self.policy.get_user(user_name)\n            if not user:\n                return None, 'unknown user \"{}\"'.format(user_name)\n            roles = user[\"roles\"]\n            if \"super\" in roles:\n                # superuser has all rights!\n                return True, \"\"\n\n        return super(FLAuthorizer, self).evaluate_user_right_on_site(right_name, user_name, site_name)\n\n    def _any_bool_rights(self, right_names: List[str], user_name: str, site_name: str):\n        if not self.policy:\n            return None, \"policy not defined\"\n\n        user = self.policy.get_user(user_name)\n        if not user:\n            return None, 'unknown user \"{}\"'.format(user_name)\n\n        roles = user[\"roles\"]\n        if \"super\" in roles:\n            # superuser has all rights!\n            return True, \"\"\n\n        for right_name in right_names:\n            value, err = self.evaluate_user_right_on_site(right_name, user_name, site_name)\n            if err:\n                return None, err\n\n            if value:\n                return True, \"\"\n        return False, \"\"\n\n    def _any_bool_rules(self, rule_names: List[str], site_name: str):\n        if not self.policy:\n            return None, \"policy not defined\"\n\n        for rule_name in rule_names:\n            value, err = self.evaluate_rule_on_site(rule_name, site_name)\n            if err:\n                return None, err\n            if value:\n                return True, \"\"\n        return False, \"\"\n\n    def _user_can_upload(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rights(user_name=user_name, site_name=site_name, right_names=[Right.UPLOAD_APP])\n\n    def _user_can_deploy(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rights(\n            user_name=user_name, site_name=site_name, right_names=[Right.DEPLOY_ALL, Right.DEPLOY_SELF]\n        )\n\n    def _user_can_train(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rights(\n            user_name=user_name, site_name=site_name, right_names=[Right.TRAIN_ALL, Right.TRAIN_SELF]\n        )\n\n    def _user_can_operate(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rights(\n            user_name=user_name, site_name=site_name, right_names=[Right.OPERATE_ALL, Right.OPERATE_SELF]\n        )\n\n    def _user_can_view(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rights(\n            user_name=user_name, site_name=site_name, right_names=[Right.VIEW_ALL, Right.VIEW_SELF]\n        )\n\n    def _site_allows_byoc(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rules(site_name=site_name, rule_names=[Rule.ALLOW_BYOC])\n\n    def _site_allows_custom_datalist(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rules(site_name=site_name, rule_names=[Rule.ALLOW_CUSTOM_DATALIST])\n\n    def authorize(self, ctx: FLAuthzContext):\n        if not ctx:\n            return True, \"\"\n\n        assert isinstance(ctx, FLAuthzContext), \"authz_ctx must be FLAuthzContext but got {}\".format(type(ctx))\n\n        if not ctx.actions:\n            return True, \"\"\n\n        assert isinstance(ctx.user_name, str) and len(ctx.user_name) > 0, \"program error: no user name in ctx!\"\n\n        if not ctx.site_names:\n            return True, \"\"\n\n        for action in ctx.actions:\n            checker = self.action_checkers.get(action, None)\n            if not checker:\n                return False, \"program error: invalid action name {}\".format(action)\n\n            for site_name in ctx.site_names:\n                authorized, err = checker(user_name=ctx.user_name, site_name=site_name)\n                if err:\n                    return False, err\n\n                if not authorized:\n                    text_vars = {\"site\": site_name, \"user\": ctx.user_name}\n                    return False, ACTION_EXPLANATION[action].format(**text_vars)\n\n        return True, \"\"",
  "class EmptyAuthorizer(Authorizer):\n    def authorize(self, ctx: AuthzContext) -> (object, str):\n        return True, \"\"\n\n    def evaluate_user_right_on_site(self, right_name: str, user_name: str, site_name: str):\n        return True, \"\"",
  "def __init__(self, user_name: str, site_names: List[str], actions: List[str]):\n        \"\"\"System-wide authorization context.\n\n        Information about the authorization, such as roles, users, sites and actions\n\n        Args:\n            user_name (str): user name\n            site_names (List[str]): all the sites to be checked\n            actions (List[str]): associated actions\n        \"\"\"\n        AuthzContext.__init__(self, user_name=user_name, site_names=site_names)\n        self.actions = actions",
  "def new_authz_context(site_names: List[str], actions: List[str]):\n        assert len(actions) > 0, \"actions must be specified\"\n        for a in actions:\n            assert a in [\n                Action.UPLOAD,\n                Action.DEPLOY,\n                Action.OPERATE,\n                Action.VIEW,\n                Action.TRAIN,\n                Action.BYOC,\n                Action.CUSTOM_DATALIST,\n            ], \"invalid action {}\".format(a)\n\n        return FLAuthzContext(user_name=\"\", site_names=site_names, actions=actions)",
  "def __init__(self):\n        \"\"\"System-wide authorization class.\n\n        Examine if a user has certain rights on a specific site\n        based on authorization.json file.\n\n        \"\"\"\n        Authorizer.__init__(self)\n        self.action_checkers = {\n            Action.UPLOAD: self._user_can_upload,\n            Action.DEPLOY: self._user_can_deploy,\n            Action.OPERATE: self._user_can_operate,\n            Action.VIEW: self._user_can_view,\n            Action.TRAIN: self._user_can_train,\n            Action.BYOC: self._site_allows_byoc,\n            Action.CUSTOM_DATALIST: self._site_allows_custom_datalist,\n        }",
  "def evaluate_user_right_on_site(self, right_name: str, user_name: str, site_name: str):\n        \"\"\"Check whether a user has a right in an org.\n\n        Superuser has all rights in all orgs.\n\n        Args:\n            right_name: right to be evaluated\n            user_name: user to be evaluated against\n            site_name: the org\n\n        Returns:\n            A tuple of (result, error).\n\n            result: True/False for bool type right; Int number for int rule; None if error occurred during evaluation\n\n            error: Error occurred during evaluation\n        \"\"\"\n        right_type = self.policy.get_right_type(right_name)\n        if right_type == \"bool\":\n            user = self.policy.get_user(user_name)\n            if not user:\n                return None, 'unknown user \"{}\"'.format(user_name)\n            roles = user[\"roles\"]\n            if \"super\" in roles:\n                # superuser has all rights!\n                return True, \"\"\n\n        return super(FLAuthorizer, self).evaluate_user_right_on_site(right_name, user_name, site_name)",
  "def _any_bool_rights(self, right_names: List[str], user_name: str, site_name: str):\n        if not self.policy:\n            return None, \"policy not defined\"\n\n        user = self.policy.get_user(user_name)\n        if not user:\n            return None, 'unknown user \"{}\"'.format(user_name)\n\n        roles = user[\"roles\"]\n        if \"super\" in roles:\n            # superuser has all rights!\n            return True, \"\"\n\n        for right_name in right_names:\n            value, err = self.evaluate_user_right_on_site(right_name, user_name, site_name)\n            if err:\n                return None, err\n\n            if value:\n                return True, \"\"\n        return False, \"\"",
  "def _any_bool_rules(self, rule_names: List[str], site_name: str):\n        if not self.policy:\n            return None, \"policy not defined\"\n\n        for rule_name in rule_names:\n            value, err = self.evaluate_rule_on_site(rule_name, site_name)\n            if err:\n                return None, err\n            if value:\n                return True, \"\"\n        return False, \"\"",
  "def _user_can_upload(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rights(user_name=user_name, site_name=site_name, right_names=[Right.UPLOAD_APP])",
  "def _user_can_deploy(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rights(\n            user_name=user_name, site_name=site_name, right_names=[Right.DEPLOY_ALL, Right.DEPLOY_SELF]\n        )",
  "def _user_can_train(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rights(\n            user_name=user_name, site_name=site_name, right_names=[Right.TRAIN_ALL, Right.TRAIN_SELF]\n        )",
  "def _user_can_operate(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rights(\n            user_name=user_name, site_name=site_name, right_names=[Right.OPERATE_ALL, Right.OPERATE_SELF]\n        )",
  "def _user_can_view(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rights(\n            user_name=user_name, site_name=site_name, right_names=[Right.VIEW_ALL, Right.VIEW_SELF]\n        )",
  "def _site_allows_byoc(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rules(site_name=site_name, rule_names=[Rule.ALLOW_BYOC])",
  "def _site_allows_custom_datalist(self, user_name, site_name):\n        # must follow action_checker_signature\n        return self._any_bool_rules(site_name=site_name, rule_names=[Rule.ALLOW_CUSTOM_DATALIST])",
  "def authorize(self, ctx: FLAuthzContext):\n        if not ctx:\n            return True, \"\"\n\n        assert isinstance(ctx, FLAuthzContext), \"authz_ctx must be FLAuthzContext but got {}\".format(type(ctx))\n\n        if not ctx.actions:\n            return True, \"\"\n\n        assert isinstance(ctx.user_name, str) and len(ctx.user_name) > 0, \"program error: no user name in ctx!\"\n\n        if not ctx.site_names:\n            return True, \"\"\n\n        for action in ctx.actions:\n            checker = self.action_checkers.get(action, None)\n            if not checker:\n                return False, \"program error: invalid action name {}\".format(action)\n\n            for site_name in ctx.site_names:\n                authorized, err = checker(user_name=ctx.user_name, site_name=site_name)\n                if err:\n                    return False, err\n\n                if not authorized:\n                    text_vars = {\"site\": site_name, \"user\": ctx.user_name}\n                    return False, ACTION_EXPLANATION[action].format(**text_vars)\n\n        return True, \"\"",
  "def authorize(self, ctx: AuthzContext) -> (object, str):\n        return True, \"\"",
  "def evaluate_user_right_on_site(self, right_name: str, user_name: str, site_name: str):\n        return True, \"\"",
  "def repeat_to_length(string_to_expand, length):\n    \"\"\"Repeats string_to_expand to fill up a string of the provided length.\n\n    Args:\n        string_to_expand: string to repeat\n        length: length of string to return\n\n    Returns: generated string of provided length\n\n    \"\"\"\n    return (string_to_expand * (int(length / len(string_to_expand)) + 1))[:length]",
  "class Table(object):\n    \"\"\"\n    Table structure to write to. The headers are set in the init and the data is input to rows before write\n    writes the table.\n\n    Args:\n            headers: headers of the table\n    \"\"\"\n\n    def __init__(self, headers: Optional[List[str]] = None):\n        self.rows = []\n        if headers and len(headers) > 0:\n            new_headers = []\n            for h in headers:\n                new_headers.append(h.upper())\n            self.rows.append(new_headers)\n\n    def set_rows(self, rows):\n        self.rows = rows\n\n    def add_row(self, row: List[str]):\n        self.rows.append(row)\n\n    def write(self, writer):\n        # compute the number of cols\n        num_cols = 0\n        for row in self.rows:\n            if num_cols < len(row):\n                num_cols = len(row)\n\n        # compute max col size\n        col_len = [0 for _ in range(num_cols)]\n        for row in self.rows:\n            for i in range(len(row)):\n                if col_len[i] < len(row[i]):\n                    col_len[i] = len(row[i])\n\n        col_fmt = [\"\" for _ in range(num_cols)]\n        for i in range(num_cols):\n            if i == 0:\n                extra = \"\"\n            else:\n                extra = \" \"\n\n            col_fmt[i] = extra + \"| {:\" + \"{}\".format(col_len[i]) + \"}\"\n            if i == num_cols - 1:\n                col_fmt[i] = col_fmt[i] + \" |\"\n\n        total_col_size = 0\n        for i in range(num_cols):\n            total_col_size += col_len[i] + 2\n\n        table_width = total_col_size + num_cols + 1\n        border_line = repeat_to_length(\"-\", table_width)\n        writer.write(border_line + \"\\n\")\n\n        for r in range(len(self.rows)):\n            row = self.rows[r]\n            line = \"\"\n            for i in range(num_cols):\n                if i < len(row):\n                    data = row[i]\n                else:\n                    data = \" \"\n\n                line += col_fmt[i].format(data)\n\n            writer.write(line + \"\\n\")\n\n            if r == 0:\n                writer.write(border_line + \"\\n\")\n\n        writer.write(border_line + \"\\n\")",
  "def __init__(self, headers: Optional[List[str]] = None):\n        self.rows = []\n        if headers and len(headers) > 0:\n            new_headers = []\n            for h in headers:\n                new_headers.append(h.upper())\n            self.rows.append(new_headers)",
  "def set_rows(self, rows):\n        self.rows = rows",
  "def add_row(self, row: List[str]):\n        self.rows.append(row)",
  "def write(self, writer):\n        # compute the number of cols\n        num_cols = 0\n        for row in self.rows:\n            if num_cols < len(row):\n                num_cols = len(row)\n\n        # compute max col size\n        col_len = [0 for _ in range(num_cols)]\n        for row in self.rows:\n            for i in range(len(row)):\n                if col_len[i] < len(row[i]):\n                    col_len[i] = len(row[i])\n\n        col_fmt = [\"\" for _ in range(num_cols)]\n        for i in range(num_cols):\n            if i == 0:\n                extra = \"\"\n            else:\n                extra = \" \"\n\n            col_fmt[i] = extra + \"| {:\" + \"{}\".format(col_len[i]) + \"}\"\n            if i == num_cols - 1:\n                col_fmt[i] = col_fmt[i] + \" |\"\n\n        total_col_size = 0\n        for i in range(num_cols):\n            total_col_size += col_len[i] + 2\n\n        table_width = total_col_size + num_cols + 1\n        border_line = repeat_to_length(\"-\", table_width)\n        writer.write(border_line + \"\\n\")\n\n        for r in range(len(self.rows)):\n            row = self.rows[r]\n            line = \"\"\n            for i in range(num_cols):\n                if i < len(row):\n                    data = row[i]\n                else:\n                    data = \" \"\n\n                line += col_fmt[i].format(data)\n\n            writer.write(line + \"\\n\")\n\n            if r == 0:\n                writer.write(border_line + \"\\n\")\n\n        writer.write(border_line + \"\\n\")",
  "def _get_default_meta(job_folder_name: str) -> str:\n    # A format string for the dummy meta.json\n    meta = f\"\"\"{{\n                 \"{JobMetaKey.JOB_NAME.value}\": \"{job_folder_name}\",\n                 \"{JobMetaKey.JOB_FOLDER_NAME.value}\": \"{job_folder_name}\",\n                 \"{JobMetaKey.RESOURCE_SPEC.value}\": {{ }},\n                 \"{JobMetaKey.DEPLOY_MAP.value}\": {{ \"{job_folder_name}\": [\"{ALL_SITES}\"] }},\n                 \"{JobMetaKey.MIN_CLIENTS.value}\": 1\n               }}\n            \"\"\"\n    return meta",
  "def normpath_for_zip(path):\n    \"\"\"Normalizes the path for zip file.\n\n    Args:\n        path (str): the path to be normalized\n    \"\"\"\n    path = os.path.normpath(path)\n    path = os.path.splitdrive(path)[1]\n    # ZIP spec requires forward slashes\n    return path.replace(\"\\\\\", \"/\")",
  "def remove_leading_dotdot(path: str) -> str:\n    path = str(Path(path))\n    while path.startswith(f\"..{os.path.sep}\"):\n        path = path[3:]\n    return path",
  "def split_path(path: str) -> (str, str):\n    \"\"\"Splits a path into a pair of head and tail.\n\n    It removes trailing `os.path.sep` and call `os.path.split`\n\n    Args:\n        path: Path to split\n\n    Returns:\n        A tuple of `(head, tail)`\n    \"\"\"\n    path = str(Path(path))\n    if path.endswith(os.path.sep):\n        full_path = path[:-1]\n    else:\n        full_path = path\n\n    return os.path.split(full_path)",
  "def get_all_file_paths(directory):\n    \"\"\"Gets all file paths in the directory.\n\n    Args:\n        directory: directory to get all paths for\n\n    Returns:\n        A list of paths of all the files in the provided directory\n    \"\"\"\n    file_paths = []\n\n    # crawling through directory and subdirectories\n    for root, directories, files in os.walk(directory):\n        for filename in files:\n            file_paths.append(normpath_for_zip(os.path.join(root, filename)))\n        for dir_name in directories:\n            file_paths.append(normpath_for_zip(os.path.join(root, dir_name)))\n\n    return file_paths",
  "def _zip_directory(root_dir: str, folder_name: str, output_file):\n    \"\"\"Creates a zip archive file for the specified directory.\n\n    Args:\n        root_dir: root path that contains the folder to be zipped\n        folder_name: path to the folder to be zipped, relative to root_dir\n        output_file: file to write to\n    \"\"\"\n    dir_name = normpath_for_zip(os.path.join(root_dir, folder_name))\n    if not os.path.exists(dir_name):\n        raise FileNotFoundError(f'output directory \"{dir_name}\" does not exist')\n\n    if not os.path.isdir(dir_name):\n        raise NotADirectoryError(f'\"{dir_name}\" is not a valid directory')\n\n    file_paths = get_all_file_paths(dir_name)\n    if folder_name:\n        prefix_len = len(split_path(dir_name)[0]) + 1\n    else:\n        prefix_len = len(dir_name) + 1\n\n    # writing files to a zipfile\n    with ZipFile(output_file, \"w\") as z:\n        # writing each file one by one\n        for full_path in file_paths:\n            rel_path = full_path[prefix_len:]\n            z.write(full_path, arcname=rel_path)",
  "def zip_directory_to_bytes(root_dir: str, folder_name: str) -> bytes:\n    \"\"\"Compresses a directory and return the bytes value of it.\n\n    Args:\n        root_dir: root path that contains the folder to be zipped\n        folder_name: path to the folder to be zipped, relative to root_dir\n    \"\"\"\n    bio = io.BytesIO()\n    _zip_directory(root_dir, folder_name, bio)\n    return bio.getvalue()",
  "def unzip_all_from_bytes(zip_data: bytes, output_dir_name: str):\n    \"\"\"Decompresses a zip and extracts all files to the specified output directory.\n\n    Args:\n        zip_data: the input zip data\n        output_dir_name: the output directory for extracted content\n    \"\"\"\n    if not os.path.exists(output_dir_name):\n        raise FileNotFoundError(f'output directory \"{output_dir_name}\" does not exist')\n\n    if not os.path.isdir(output_dir_name):\n        raise NotADirectoryError(f'\"{output_dir_name}\" is not a valid directory')\n\n    with ZipFile(io.BytesIO(zip_data), \"r\") as z:\n        z.extractall(output_dir_name)",
  "def convert_legacy_zip(zip_data: bytes) -> bytes:\n    \"\"\"Convert a legacy app in zip into job layout in memory.\n\n    Args:\n        zip_data: The input zip data\n\n    Returns:\n        The converted zip data\n    \"\"\"\n\n    meta: Optional[dict] = None\n    reader = io.BytesIO(zip_data)\n    with ZipFile(reader, \"r\") as in_zip:\n        info_list = in_zip.infolist()\n        folder_name = info_list[0].filename.split(\"/\")[0]\n        meta_path = normpath_for_zip(os.path.join(folder_name, META_NAME))\n        if next((info for info in info_list if info.filename == meta_path), None):\n            # Already in job layout\n            meta_data = in_zip.read(meta_path)\n            meta = json.loads(meta_data)\n            if JobMetaKey.JOB_FOLDER_NAME.value not in meta:\n                meta[JobMetaKey.JOB_FOLDER_NAME.value] = folder_name\n            else:\n                return zip_data\n\n        writer = io.BytesIO()\n        with ZipFile(writer, \"w\") as out_zip:\n            if meta:\n                out_zip.writestr(meta_path, json.dumps(meta))\n                out_zip.comment = in_zip.comment  # preserve the comment\n                for info in info_list:\n                    if info.filename != meta_path:\n                        out_zip.writestr(info, in_zip.read(info.filename))\n            else:\n                out_zip.writestr(meta_path, _get_default_meta(folder_name))\n                # Push everything else to a sub folder with the same name:\n                # hello-pt/README.md -> hello-pt/hello-pt/README.md\n                for info in info_list:\n                    name = info.filename\n                    content = in_zip.read(name)\n                    path = folder_name + \"/\" + name\n                    info.filename = path\n                    out_zip.writestr(info, content)\n\n        return writer.getvalue()",
  "def receive_til_end(sock, end=ALL_END):\n    total_data = []\n    data_size = 0\n    sock.settimeout(MAX_IDLE_TIME)\n    while True:\n        data = str(sock.recv(1024), \"utf-8\")\n        data_size += len(data)\n        if data_size > MAX_DATA_SIZE:\n            raise BufferError(f\"Data size exceeds limit ({MAX_DATA_SIZE} bytes)\")\n        if end in data:\n            total_data.append(data[: data.find(end)])\n            break\n\n        total_data.append(data)\n\n    result = \"\".join(total_data)\n    return result.replace(LINE_END, \"\")",
  "def _split_data(data: str):\n    # first determine whether the data contains ALL_END\n    # anything after ALL_END is dropped\n    all_done = False\n    idx = data.find(ALL_END)\n    if idx >= 0:\n        data = data[:idx]\n        all_done = True\n\n    # find lines separated by LINE_END\n    parts = data.split(LINE_END)\n    return parts, all_done",
  "def _process_one_line(line: str, process_json_func):\n    \"\"\"Validate and process one line, which should be a str containing a JSON document.\"\"\"\n    json_data = validate_proto(line)\n    process_json_func(json_data)",
  "def receive_and_process(sock, process_json_func):\n    \"\"\"Receives and sends lines to process with process_json_func.\"\"\"\n    leftover = \"\"\n    while True:\n        data = str(sock.recv(MAX_MSG_SIZE), \"utf-8\")\n        if len(data) <= 0:\n            return False\n\n        segs, all_done = _split_data(data)\n        if all_done:\n            for seg in segs:\n                line = leftover + seg\n                if len(line) > 0:\n                    _process_one_line(line, process_json_func)\n                leftover = \"\"\n            return True\n\n        for i in range(len(segs) - 1):\n            line = leftover + segs[i]\n            if len(line) > 0:\n                _process_one_line(line, process_json_func)\n            leftover = \"\"\n\n        leftover += segs[len(segs) - 1]",
  "class Connection(BaseContext):\n    def __init__(self, sock, server):\n        \"\"\"Object containing connection information and buffer to build and send a line with socket passed in at init.\n\n        Args:\n            sock: sock for the connection\n            server: server for the connection\n        \"\"\"\n        BaseContext.__init__(self)\n        self.sock = sock\n        self.server = server\n        self.app_ctx = None\n        self.ended = False\n        self.request = None\n        self.command = None\n        self.args = None\n        self.buffer = Buffer()\n\n    def _send_line(self, line: str, all_end=False):\n        \"\"\"If not ``self.ended``, send line with sock.\"\"\"\n        if self.ended:\n            return\n\n        if all_end:\n            end = ALL_END\n            self.ended = True\n        else:\n            end = LINE_END\n\n        self.sock.sendall(bytes(line + end, \"utf-8\"))\n\n    def append_table(self, headers: List[str]) -> Table:\n        return self.buffer.append_table(headers)\n\n    def append_string(self, data: str, flush=False):\n        self.buffer.append_string(data)\n        if flush:\n            self.flush()\n\n    def append_success(self, data: str, flush=False):\n        self.buffer.append_success(data)\n        if flush:\n            self.flush()\n\n    def append_dict(self, data: dict, flush=False):\n        self.buffer.append_dict(data)\n        if flush:\n            self.flush()\n\n    def append_error(self, data: str, flush=False):\n        self.buffer.append_error(data)\n        if flush:\n            self.flush()\n\n    def append_command(self, cmd: str, flush=False):\n        self.buffer.append_command(cmd)\n        if flush:\n            self.flush()\n\n    def append_token(self, token: str, flush=False):\n        self.buffer.append_token(token)\n        if flush:\n            self.flush()\n\n    def append_shutdown(self, msg: str, flush=False):\n        self.buffer.append_shutdown(msg)\n        if flush:\n            self.flush()\n\n    def append_any(self, data, flush=False):\n        if data is None:\n            return\n\n        if isinstance(data, str):\n            self.append_string(data, flush)\n        elif isinstance(data, dict):\n            self.append_dict(data, flush)\n        else:\n            self.append_error(\"unsupported data type {}\".format(type(data)))\n\n    def flush(self):\n        line = self.buffer.encode()\n        if line is None or len(line) <= 0:\n            return\n\n        self.buffer.reset()\n        self._send_line(line, all_end=False)\n\n    def close(self):\n        self.flush()\n        self._send_line(\"\", all_end=True)",
  "def __init__(self, sock, server):\n        \"\"\"Object containing connection information and buffer to build and send a line with socket passed in at init.\n\n        Args:\n            sock: sock for the connection\n            server: server for the connection\n        \"\"\"\n        BaseContext.__init__(self)\n        self.sock = sock\n        self.server = server\n        self.app_ctx = None\n        self.ended = False\n        self.request = None\n        self.command = None\n        self.args = None\n        self.buffer = Buffer()",
  "def _send_line(self, line: str, all_end=False):\n        \"\"\"If not ``self.ended``, send line with sock.\"\"\"\n        if self.ended:\n            return\n\n        if all_end:\n            end = ALL_END\n            self.ended = True\n        else:\n            end = LINE_END\n\n        self.sock.sendall(bytes(line + end, \"utf-8\"))",
  "def append_table(self, headers: List[str]) -> Table:\n        return self.buffer.append_table(headers)",
  "def append_string(self, data: str, flush=False):\n        self.buffer.append_string(data)\n        if flush:\n            self.flush()",
  "def append_success(self, data: str, flush=False):\n        self.buffer.append_success(data)\n        if flush:\n            self.flush()",
  "def append_dict(self, data: dict, flush=False):\n        self.buffer.append_dict(data)\n        if flush:\n            self.flush()",
  "def append_error(self, data: str, flush=False):\n        self.buffer.append_error(data)\n        if flush:\n            self.flush()",
  "def append_command(self, cmd: str, flush=False):\n        self.buffer.append_command(cmd)\n        if flush:\n            self.flush()",
  "def append_token(self, token: str, flush=False):\n        self.buffer.append_token(token)\n        if flush:\n            self.flush()",
  "def append_shutdown(self, msg: str, flush=False):\n        self.buffer.append_shutdown(msg)\n        if flush:\n            self.flush()",
  "def append_any(self, data, flush=False):\n        if data is None:\n            return\n\n        if isinstance(data, str):\n            self.append_string(data, flush)\n        elif isinstance(data, dict):\n            self.append_dict(data, flush)\n        else:\n            self.append_error(\"unsupported data type {}\".format(type(data)))",
  "def flush(self):\n        line = self.buffer.encode()\n        if line is None or len(line) <= 0:\n            return\n\n        self.buffer.reset()\n        self._send_line(line, all_end=False)",
  "def close(self):\n        self.flush()\n        self._send_line(\"\", all_end=True)",
  "class CommandSpec(object):\n\n    valid_confirms = [\"none\", \"yesno\", \"auth\"]\n\n    def __init__(\n        self, name: str, description: str, usage: str, handler_func, authz_func=None, visible=True, confirm=None\n    ):\n        \"\"\"Specification of a command within a CommandModuleSpec to register into CommandRegister as a CommandEntry.\n\n        Args:\n            name: command name\n            description: command description text\n            usage: string to show usage of the command\n            handler_func: function to call for executing the command\n            authz_func: authorization function to run to get a tuple of (valid, authz_ctx) in AuthzFilter\n            visible: whether the command is visible or not\n            confirm: whether the command needs confirmation to execute\n        \"\"\"\n        self.name = name\n        self.description = description\n        self.usage = usage\n        self.handler_func = handler_func\n        self.authz_func = authz_func\n        self.visible = visible\n        self.confirm = confirm\n        if not confirm:\n            self.confirm = \"none\"\n        else:\n            assert confirm in CommandSpec.valid_confirms",
  "class CommandModuleSpec(object):\n    def __init__(self, name: str, cmd_specs: List[CommandSpec]):\n        \"\"\"Specification for a command module containing a list of commands in the form of CommandSpec.\n\n        Args:\n            name: becomes the scope name of the commands in cmd_specs when registered in CommandRegister\n            cmd_specs: list of CommandSpec objects with\n        \"\"\"\n        self.name = name\n        self.cmd_specs = cmd_specs",
  "class CommandModule(object):\n    \"\"\"Base class containing CommandModuleSpec.\"\"\"\n\n    def get_spec(self) -> CommandModuleSpec:\n        pass\n\n    def close(self):\n        pass",
  "class CommandEntry(object):\n    def __init__(self, scope, name, desc, usage, handler, authz_func, visible, confirm):\n        \"\"\"Contains information about a command. This is registered in Scope within CommandRegister.\n\n        Args:\n            scope: scope for this command\n            name: command name\n            desc: command description text\n            usage: string to show usage of the command\n            handler: function to call for executing the command\n            authz_func: authorization function to run to get a tuple of (valid, authz_ctx) in AuthzFilter\n            visible: whether the command is visible or not\n            confirm: whether the command needs confirmation to execute\n        \"\"\"\n        self.scope = scope\n        self.name = name\n        self.desc = desc\n        self.usage = usage\n        self.handler = handler\n        self.authz_func = authz_func\n        self.visible = visible\n        self.confirm = confirm",
  "class _Scope(object):\n    def __init__(self, name: str):\n        \"\"\"A container grouping CommandEntry objects inside CommandRegister.\n\n        Args:\n            name: name of scope grouping commands\n        \"\"\"\n        self.name = name\n        self.entries = {}\n\n    def register_command(\n        self, cmd_name: str, cmd_desc: str, cmd_usage: str, handler_func, authz_func, visible, confirm\n    ):\n        self.entries[cmd_name] = CommandEntry(\n            self, cmd_name, cmd_desc, cmd_usage, handler_func, authz_func, visible, confirm\n        )",
  "class CommandRegister(object):\n    def __init__(self, app_ctx):\n        \"\"\"Object containing the commands in scopes once they have been registered.\n\n        ServerCommandRegister is derived from this class and calls the handler of the command through\n        ``process_command`` and ``_do_command``. This is also used to register commands for the admin client.\n\n        Args:\n            app_ctx: app context\n        \"\"\"\n        self.app_ctx = app_ctx\n        self.scopes = {}\n        self.cmd_map = {}\n        self.modules = []\n\n    def _get_scope(self, name: str):\n        scope = self.scopes.get(name, None)\n        if scope is None:\n            scope = _Scope(name)\n            self.scopes[name] = scope\n        return scope\n\n    def get_command_entries(self, cmd_name: str):\n        return self.cmd_map.get(cmd_name, [])\n\n    def register_module(self, module: CommandModule, include_invisible=True):\n        self.modules.append(module)\n        module_spec = module.get_spec()\n        for cmd_spec in module_spec.cmd_specs:\n            assert isinstance(cmd_spec, CommandSpec)\n            if cmd_spec.visible or include_invisible:\n                self.add_command(\n                    scope_name=module_spec.name,\n                    cmd_name=cmd_spec.name,\n                    desc=cmd_spec.description,\n                    usage=cmd_spec.usage,\n                    handler=cmd_spec.handler_func,\n                    authz_func=cmd_spec.authz_func,\n                    visible=cmd_spec.visible,\n                    confirm=cmd_spec.confirm,\n                )\n\n    def add_command(self, scope_name, cmd_name, desc, usage, handler, authz_func, visible, confirm):\n        scope = self._get_scope(scope_name)\n        scope.register_command(\n            cmd_name=cmd_name,\n            cmd_desc=desc,\n            cmd_usage=usage,\n            handler_func=handler,\n            authz_func=authz_func,\n            visible=visible,\n            confirm=confirm,\n        )\n\n    def _add_cmd_entry(self, cmd_name, entry):\n        entry_list = self.cmd_map.get(cmd_name, None)\n        if entry_list is None:\n            entry_list = []\n            self.cmd_map[cmd_name] = entry_list\n        entry_list.append(entry)\n\n    def finalize(self, add_cmd_func=None):\n        if len(self.cmd_map) > 0:\n            # already finalized\n            return\n\n        for scope_name, scope in self.scopes.items():\n            for cmd_name, entry in scope.entries.items():\n                self._add_cmd_entry(cmd_name, entry)\n                full_cmd_name = \"{}.{}\".format(scope_name, cmd_name)\n                self._add_cmd_entry(full_cmd_name, entry)\n                if add_cmd_func:\n                    add_cmd_func(entry)",
  "def __init__(\n        self, name: str, description: str, usage: str, handler_func, authz_func=None, visible=True, confirm=None\n    ):\n        \"\"\"Specification of a command within a CommandModuleSpec to register into CommandRegister as a CommandEntry.\n\n        Args:\n            name: command name\n            description: command description text\n            usage: string to show usage of the command\n            handler_func: function to call for executing the command\n            authz_func: authorization function to run to get a tuple of (valid, authz_ctx) in AuthzFilter\n            visible: whether the command is visible or not\n            confirm: whether the command needs confirmation to execute\n        \"\"\"\n        self.name = name\n        self.description = description\n        self.usage = usage\n        self.handler_func = handler_func\n        self.authz_func = authz_func\n        self.visible = visible\n        self.confirm = confirm\n        if not confirm:\n            self.confirm = \"none\"\n        else:\n            assert confirm in CommandSpec.valid_confirms",
  "def __init__(self, name: str, cmd_specs: List[CommandSpec]):\n        \"\"\"Specification for a command module containing a list of commands in the form of CommandSpec.\n\n        Args:\n            name: becomes the scope name of the commands in cmd_specs when registered in CommandRegister\n            cmd_specs: list of CommandSpec objects with\n        \"\"\"\n        self.name = name\n        self.cmd_specs = cmd_specs",
  "def get_spec(self) -> CommandModuleSpec:\n        pass",
  "def close(self):\n        pass",
  "def __init__(self, scope, name, desc, usage, handler, authz_func, visible, confirm):\n        \"\"\"Contains information about a command. This is registered in Scope within CommandRegister.\n\n        Args:\n            scope: scope for this command\n            name: command name\n            desc: command description text\n            usage: string to show usage of the command\n            handler: function to call for executing the command\n            authz_func: authorization function to run to get a tuple of (valid, authz_ctx) in AuthzFilter\n            visible: whether the command is visible or not\n            confirm: whether the command needs confirmation to execute\n        \"\"\"\n        self.scope = scope\n        self.name = name\n        self.desc = desc\n        self.usage = usage\n        self.handler = handler\n        self.authz_func = authz_func\n        self.visible = visible\n        self.confirm = confirm",
  "def __init__(self, name: str):\n        \"\"\"A container grouping CommandEntry objects inside CommandRegister.\n\n        Args:\n            name: name of scope grouping commands\n        \"\"\"\n        self.name = name\n        self.entries = {}",
  "def register_command(\n        self, cmd_name: str, cmd_desc: str, cmd_usage: str, handler_func, authz_func, visible, confirm\n    ):\n        self.entries[cmd_name] = CommandEntry(\n            self, cmd_name, cmd_desc, cmd_usage, handler_func, authz_func, visible, confirm\n        )",
  "def __init__(self, app_ctx):\n        \"\"\"Object containing the commands in scopes once they have been registered.\n\n        ServerCommandRegister is derived from this class and calls the handler of the command through\n        ``process_command`` and ``_do_command``. This is also used to register commands for the admin client.\n\n        Args:\n            app_ctx: app context\n        \"\"\"\n        self.app_ctx = app_ctx\n        self.scopes = {}\n        self.cmd_map = {}\n        self.modules = []",
  "def _get_scope(self, name: str):\n        scope = self.scopes.get(name, None)\n        if scope is None:\n            scope = _Scope(name)\n            self.scopes[name] = scope\n        return scope",
  "def get_command_entries(self, cmd_name: str):\n        return self.cmd_map.get(cmd_name, [])",
  "def register_module(self, module: CommandModule, include_invisible=True):\n        self.modules.append(module)\n        module_spec = module.get_spec()\n        for cmd_spec in module_spec.cmd_specs:\n            assert isinstance(cmd_spec, CommandSpec)\n            if cmd_spec.visible or include_invisible:\n                self.add_command(\n                    scope_name=module_spec.name,\n                    cmd_name=cmd_spec.name,\n                    desc=cmd_spec.description,\n                    usage=cmd_spec.usage,\n                    handler=cmd_spec.handler_func,\n                    authz_func=cmd_spec.authz_func,\n                    visible=cmd_spec.visible,\n                    confirm=cmd_spec.confirm,\n                )",
  "def add_command(self, scope_name, cmd_name, desc, usage, handler, authz_func, visible, confirm):\n        scope = self._get_scope(scope_name)\n        scope.register_command(\n            cmd_name=cmd_name,\n            cmd_desc=desc,\n            cmd_usage=usage,\n            handler_func=handler,\n            authz_func=authz_func,\n            visible=visible,\n            confirm=confirm,\n        )",
  "def _add_cmd_entry(self, cmd_name, entry):\n        entry_list = self.cmd_map.get(cmd_name, None)\n        if entry_list is None:\n            entry_list = []\n            self.cmd_map[cmd_name] = entry_list\n        entry_list.append(entry)",
  "def finalize(self, add_cmd_func=None):\n        if len(self.cmd_map) > 0:\n            # already finalized\n            return\n\n        for scope_name, scope in self.scopes.items():\n            for cmd_name, entry in scope.entries.items():\n                self._add_cmd_entry(cmd_name, entry)\n                full_cmd_name = \"{}.{}\".format(scope_name, cmd_name)\n                self._add_cmd_entry(full_cmd_name, entry)\n                if add_cmd_func:\n                    add_cmd_func(entry)",
  "def hash_password(password):\n    \"\"\"Hash a password for storing.\n\n    Args:\n        password: password to hash\n\n    Returns: hashed password\n\n    \"\"\"\n    salt = hashlib.sha256(os.urandom(60)).hexdigest().encode(\"ascii\")\n    pwd_hash = hashlib.pbkdf2_hmac(hash_name=\"sha512\", password=password.encode(\"utf-8\"), salt=salt, iterations=100000)\n\n    pwd_hash = binascii.hexlify(pwd_hash)\n    return (salt + pwd_hash).decode(\"ascii\")",
  "def verify_password(stored_password, provided_password):\n    \"\"\"Verify a stored password against one provided by user.\n\n    Args:\n        stored_password: stored password\n        provided_password: password provided by user\n\n    Returns: True if the stored password equals the provided password, otherwise False\n\n    \"\"\"\n    salt = stored_password[:64]\n    stored_password = stored_password[64:]\n    pwd_hash = hashlib.pbkdf2_hmac(\n        hash_name=\"sha512\", password=provided_password.encode(\"utf-8\"), salt=salt.encode(\"ascii\"), iterations=100000\n    )\n\n    pwd_hash = binascii.hexlify(pwd_hash).decode(\"ascii\")\n    return pwd_hash == stored_password",
  "def make_session_token():\n    \"\"\"Makes a new session token.\n\n    Returns: created session token\n\n    \"\"\"\n    t = uuid.uuid1()\n    return str(t)",
  "def get_certificate_common_name(cert: dict):\n    \"\"\"Gets the common name of the provided certificate.\n\n    Args:\n        cert: certificate\n\n    Returns: common name of provided cert\n\n    \"\"\"\n    if cert is None:\n        return None\n\n    for sub in cert.get(\"subject\", ()):\n        for key, value in sub:\n            if key == \"commonName\":\n                return value",
  "class Buffer(object):\n    def __init__(self):\n        \"\"\"Buffer to append to for :class:`nvflare.fuel.hci.conn.Connection`.\"\"\"\n        self.output = {\"time\": \"{}\".format(datetime.now()), \"data\": []}\n\n    def append_table(self, headers: List[str]) -> Table:\n        t = Table(headers)\n        self.output[\"data\"].append({\"type\": \"table\", \"rows\": t.rows})\n        return t\n\n    def append_string(self, data: str):\n        self.output[\"data\"].append({\"type\": \"string\", \"data\": data})\n\n    def append_dict(self, data: dict):\n        self.output[\"data\"].append({\"type\": \"dict\", \"data\": data})\n\n    def append_success(self, data: str):\n        self.output[\"data\"].append({\"type\": \"success\", \"data\": data})\n\n    def append_error(self, data: str):\n        self.output[\"data\"].append({\"type\": \"error\", \"data\": data})\n\n    def append_command(self, cmd: str):\n        self.output[\"data\"].append({\"type\": \"command\", \"data\": cmd})\n\n    def append_token(self, token: str):\n        self.output[\"data\"].append({\"type\": \"token\", \"data\": token})\n\n    def append_shutdown(self, msg: str):\n        self.output[\"data\"].append({\"type\": \"shutdown\", \"data\": msg})\n\n    def encode(self):\n        if len(self.output[\"data\"]) <= 0:\n            return None\n\n        return json.dumps(self.output)\n\n    def reset(self):\n        self.output = {\"time\": \"{}\".format(datetime.now()), \"data\": []}",
  "def make_error(data: str):\n    buf = Buffer()\n    buf.append_error(data)\n    return buf.output",
  "def validate_proto(line: str):\n    \"\"\"Validate that the line being received is of the expected format.\n\n    Args:\n        line: str containing a JSON document\n\n    Returns: deserialized JSON document\n    \"\"\"\n    all_types = [\"string\", \"success\", \"error\", \"table\", \"command\", \"token\", \"shutdown\", \"dict\"]\n    types_with_data = [\"string\", \"success\", \"error\", \"command\", \"token\", \"shutdown\"]\n    try:\n        json_data = json.loads(line)\n        assert isinstance(json_data, dict)\n        assert \"data\" in json_data\n        data = json_data[\"data\"]\n        assert isinstance(data, list)\n        for item in data:\n            assert isinstance(item, dict)\n            assert \"type\" in item\n            it = item[\"type\"]\n            assert it in all_types\n\n            if it in types_with_data:\n                assert \"data\" in item\n                assert isinstance(item[\"data\"], str)\n            elif it == \"table\":\n                assert \"rows\" in item\n                rows = item[\"rows\"]\n                assert isinstance(rows, list)\n                for row in rows:\n                    assert isinstance(row, list)\n\n        return json_data\n    except BaseException:\n        return None",
  "def __init__(self):\n        \"\"\"Buffer to append to for :class:`nvflare.fuel.hci.conn.Connection`.\"\"\"\n        self.output = {\"time\": \"{}\".format(datetime.now()), \"data\": []}",
  "def append_table(self, headers: List[str]) -> Table:\n        t = Table(headers)\n        self.output[\"data\"].append({\"type\": \"table\", \"rows\": t.rows})\n        return t",
  "def append_string(self, data: str):\n        self.output[\"data\"].append({\"type\": \"string\", \"data\": data})",
  "def append_dict(self, data: dict):\n        self.output[\"data\"].append({\"type\": \"dict\", \"data\": data})",
  "def append_success(self, data: str):\n        self.output[\"data\"].append({\"type\": \"success\", \"data\": data})",
  "def append_error(self, data: str):\n        self.output[\"data\"].append({\"type\": \"error\", \"data\": data})",
  "def append_command(self, cmd: str):\n        self.output[\"data\"].append({\"type\": \"command\", \"data\": cmd})",
  "def append_token(self, token: str):\n        self.output[\"data\"].append({\"type\": \"token\", \"data\": token})",
  "def append_shutdown(self, msg: str):\n        self.output[\"data\"].append({\"type\": \"shutdown\", \"data\": msg})",
  "def encode(self):\n        if len(self.output[\"data\"]) <= 0:\n            return None\n\n        return json.dumps(self.output)",
  "def reset(self):\n        self.output = {\"time\": \"{}\".format(datetime.now()), \"data\": []}",
  "def bytes_to_b64str(data_bytes) -> str:\n    \"\"\"Convert binary to base64-encoded string.\"\"\"\n    encoded_bytes = base64.b64encode(data_bytes)\n    return encoded_bytes.decode(\"ascii\")",
  "def b64str_to_bytes(b64str: str) -> bytes:\n    \"\"\"Convert base64-encoded string to binary.\"\"\"\n    encoded_bytes = b64str.encode(\"ascii\")\n    return base64.b64decode(encoded_bytes)",
  "def binary_file_to_b64str(file_name) -> str:\n    \"\"\"Encode content of a binary file to a Base64-encoded ASCII string.\n\n    Args:\n        file_name: the binary file to be processed\n\n    Returns: base64-encoded ASCII string\n\n    \"\"\"\n    data_bytes = open(file_name, \"rb\").read()\n    return bytes_to_b64str(data_bytes)",
  "def b64str_to_binary_file(b64str: str, file_name):\n    \"\"\"Decode a base64-encoded string and write it into a binary file.\n\n    Args:\n        b64str: the base64-encoded ASCII string\n        file_name: the file to write to\n\n    Returns: number of bytes written\n\n    \"\"\"\n    data_bytes = b64str_to_bytes(b64str)\n    with open(file_name, \"wb\") as f:\n        f.write(data_bytes)\n    return len(data_bytes)",
  "def text_file_to_b64str(file_name) -> str:\n    \"\"\"Encode content of a text file to a Base64-encoded ASCII string.\n\n    Args:\n        file_name: name of the text file\n\n    Returns: base64-encoded string\n\n    \"\"\"\n    data_string = open(file_name, \"r\").read()\n    data_bytes = data_string.encode(\"utf-8\")\n    return bytes_to_b64str(data_bytes)",
  "def b64str_to_text_file(b64str: str, file_name):\n    \"\"\"Decode a base64-encoded string and write result into a text file.\n\n    Args:\n        b64str: base64-encoded string\n        file_name: file to be created\n\n    Returns: number of data types written (may not be the same as number of characters)\n\n    \"\"\"\n    data_bytes = b64str_to_bytes(b64str)\n    data_string = data_bytes.decode(\"utf-8\")\n    with open(file_name, \"w\") as f:\n        f.write(data_string)\n    return len(data_bytes)",
  "class ShellCommandValidator(object):\n    def __init__(self, arg_validator: ArgValidator):\n        \"\"\"Base class for validators to be called by command executors for shell commands.\n\n        Args:\n            arg_validator: instance of ArgValidator\n        \"\"\"\n        self.arg_validator = arg_validator\n\n    def validate(self, args: List[str]):\n        self.arg_validator.err = \"\"\n        return self.arg_validator.validate(args)\n\n    def get_usage(self):\n        return self.arg_validator.get_usage()",
  "class TailValidator(ShellCommandValidator):\n    def __init__(self):\n        \"\"\"Validator for the tail command.\"\"\"\n        val = ArgValidator(\"tail\")\n        val.add_argument(\"-c\", type=int, help=\"output the last C bytes\")\n        val.add_argument(\"-n\", type=int, help=\"output the last N lines\")\n        val.add_argument(\"files\", metavar=\"file\", type=str, nargs=\"+\")\n        ShellCommandValidator.__init__(self, val)",
  "class HeadValidator(ShellCommandValidator):\n    def __init__(self):\n        \"\"\"Validator for the head command.\"\"\"\n        val = ArgValidator(\"head\")\n        val.add_argument(\"-c\", type=int, help=\"print the first C bytes of each file\")\n        val.add_argument(\"-n\", type=int, help=\"print the first N lines instead of the first 10\")\n        val.add_argument(\"files\", metavar=\"file\", type=str, nargs=\"+\")\n        ShellCommandValidator.__init__(self, val)",
  "class GrepValidator(ShellCommandValidator):\n    def __init__(self):\n        \"\"\"Validator for the grep command.\"\"\"\n        val = ArgValidator(\"grep\")\n        val.add_argument(\"-n\", action=\"store_true\", help=\"print line number with output lines\")\n        val.add_argument(\"-i\", action=\"store_true\", help=\"ignore case distinctions\")\n        val.add_argument(\"-b\", action=\"store_true\", help=\"print the byte offset with output lines\")\n        val.add_argument(\"pattern\", metavar=\"pattern\", type=str)\n        val.add_argument(\"files\", metavar=\"file\", type=str, nargs=\"+\")\n        ShellCommandValidator.__init__(self, val)",
  "class CatValidator(ShellCommandValidator):\n    def __init__(self):\n        \"\"\"Validator for the cat command.\"\"\"\n        val = ArgValidator(\"cat\")\n        val.add_argument(\"-n\", action=\"store_true\", help=\"number all output lines\")\n        val.add_argument(\"-b\", action=\"store_true\", help=\"number nonempty output lines, overrides -n\")\n        val.add_argument(\"-s\", action=\"store_true\", help=\"suppress repeated empty output lines\")\n        val.add_argument(\"-T\", action=\"store_true\", help=\"display TAB characters as ^I\")\n        val.add_argument(\"files\", metavar=\"file\", type=str, nargs=\"+\")\n        ShellCommandValidator.__init__(self, val)",
  "class LsValidator(ShellCommandValidator):\n    def __init__(self):\n        \"\"\"Validator for the ls command.\"\"\"\n        val = ArgValidator(\"ls\")\n        val.add_argument(\"-a\", action=\"store_true\")\n        val.add_argument(\"-l\", action=\"store_true\", help=\"use a long listing format\")\n        val.add_argument(\"-t\", action=\"store_true\", help=\"sort by modification time, newest first\")\n        val.add_argument(\"-S\", action=\"store_true\", help=\"sort by file size, largest first\")\n        val.add_argument(\"-R\", action=\"store_true\", help=\"list subdirectories recursively\")\n        val.add_argument(\"-u\", action=\"store_true\", help=\"with -l: show access time, otherwise: sort by access time\")\n        val.add_argument(\"files\", metavar=\"file\", type=str, nargs=\"?\")\n        ShellCommandValidator.__init__(self, val)",
  "def __init__(self, arg_validator: ArgValidator):\n        \"\"\"Base class for validators to be called by command executors for shell commands.\n\n        Args:\n            arg_validator: instance of ArgValidator\n        \"\"\"\n        self.arg_validator = arg_validator",
  "def validate(self, args: List[str]):\n        self.arg_validator.err = \"\"\n        return self.arg_validator.validate(args)",
  "def get_usage(self):\n        return self.arg_validator.get_usage()",
  "def __init__(self):\n        \"\"\"Validator for the tail command.\"\"\"\n        val = ArgValidator(\"tail\")\n        val.add_argument(\"-c\", type=int, help=\"output the last C bytes\")\n        val.add_argument(\"-n\", type=int, help=\"output the last N lines\")\n        val.add_argument(\"files\", metavar=\"file\", type=str, nargs=\"+\")\n        ShellCommandValidator.__init__(self, val)",
  "def __init__(self):\n        \"\"\"Validator for the head command.\"\"\"\n        val = ArgValidator(\"head\")\n        val.add_argument(\"-c\", type=int, help=\"print the first C bytes of each file\")\n        val.add_argument(\"-n\", type=int, help=\"print the first N lines instead of the first 10\")\n        val.add_argument(\"files\", metavar=\"file\", type=str, nargs=\"+\")\n        ShellCommandValidator.__init__(self, val)",
  "def __init__(self):\n        \"\"\"Validator for the grep command.\"\"\"\n        val = ArgValidator(\"grep\")\n        val.add_argument(\"-n\", action=\"store_true\", help=\"print line number with output lines\")\n        val.add_argument(\"-i\", action=\"store_true\", help=\"ignore case distinctions\")\n        val.add_argument(\"-b\", action=\"store_true\", help=\"print the byte offset with output lines\")\n        val.add_argument(\"pattern\", metavar=\"pattern\", type=str)\n        val.add_argument(\"files\", metavar=\"file\", type=str, nargs=\"+\")\n        ShellCommandValidator.__init__(self, val)",
  "def __init__(self):\n        \"\"\"Validator for the cat command.\"\"\"\n        val = ArgValidator(\"cat\")\n        val.add_argument(\"-n\", action=\"store_true\", help=\"number all output lines\")\n        val.add_argument(\"-b\", action=\"store_true\", help=\"number nonempty output lines, overrides -n\")\n        val.add_argument(\"-s\", action=\"store_true\", help=\"suppress repeated empty output lines\")\n        val.add_argument(\"-T\", action=\"store_true\", help=\"display TAB characters as ^I\")\n        val.add_argument(\"files\", metavar=\"file\", type=str, nargs=\"+\")\n        ShellCommandValidator.__init__(self, val)",
  "def __init__(self):\n        \"\"\"Validator for the ls command.\"\"\"\n        val = ArgValidator(\"ls\")\n        val.add_argument(\"-a\", action=\"store_true\")\n        val.add_argument(\"-l\", action=\"store_true\", help=\"use a long listing format\")\n        val.add_argument(\"-t\", action=\"store_true\", help=\"sort by modification time, newest first\")\n        val.add_argument(\"-S\", action=\"store_true\", help=\"sort by file size, largest first\")\n        val.add_argument(\"-R\", action=\"store_true\", help=\"list subdirectories recursively\")\n        val.add_argument(\"-u\", action=\"store_true\", help=\"with -l: show access time, otherwise: sort by access time\")\n        val.add_argument(\"files\", metavar=\"file\", type=str, nargs=\"?\")\n        ShellCommandValidator.__init__(self, val)",
  "def split_to_args(line: str) -> List[str]:\n    if '\"' in line:\n        return shlex.split(line)\n    else:\n        line = re.sub(\" +\", \" \", line)\n        return line.split(\" \")",
  "def join_args(segs: List[str]) -> str:\n    result = \"\"\n    sep = \"\"\n    for a in segs:\n        parts = a.split()\n        if len(parts) < 2:\n            p = parts[0]\n        else:\n            p = '\"' + a + '\"'\n        result = result + sep + p\n        sep = \" \"\n\n    return result",
  "class ArgValidator(argparse.ArgumentParser):\n    def __init__(self, name):\n        \"\"\"Validator for admin shell commands that uses argparse to check arguments and get usage through print_help.\n\n        Args:\n            name: name of the program to pass to ArgumentParser\n        \"\"\"\n        argparse.ArgumentParser.__init__(self, prog=name, add_help=False)\n        self.err = \"\"\n\n    def error(self, message):\n        self.err = message\n\n    def validate(self, args):\n        try:\n            result = self.parse_args(args)\n            return self.err, result\n        except BaseException:\n            return 'argument error; try \"? cmdName to show supported usage for a command\"', None\n\n    def get_usage(self) -> str:\n        buffer = io.StringIO()\n        self.print_help(buffer)\n        usage_output = buffer.getvalue().split(\"\\n\", 1)[1]\n        buffer.close()\n        return usage_output",
  "def __init__(self, name):\n        \"\"\"Validator for admin shell commands that uses argparse to check arguments and get usage through print_help.\n\n        Args:\n            name: name of the program to pass to ArgumentParser\n        \"\"\"\n        argparse.ArgumentParser.__init__(self, prog=name, add_help=False)\n        self.err = \"\"",
  "def error(self, message):\n        self.err = message",
  "def validate(self, args):\n        try:\n            result = self.parse_args(args)\n            return self.err, result\n        except BaseException:\n            return 'argument error; try \"? cmdName to show supported usage for a command\"', None",
  "def get_usage(self) -> str:\n        buffer = io.StringIO()\n        self.print_help(buffer)\n        usage_output = buffer.getvalue().split(\"\\n\", 1)[1]\n        buffer.close()\n        return usage_output",
  "class Authenticator(ABC):\n    \"\"\"Base class for authenticating credentials.\"\"\"\n\n    @abstractmethod\n    def authenticate(self, user_name: str, credential: str, credential_type: str) -> bool:\n        \"\"\"Authenticate a specified user with the provided credential.\n\n        Args:\n            user_name: user login name\n            credential: provided credential\n            credential_type: type of credential\n\n        Returns: True if successful, False otherwise\n\n        \"\"\"\n        pass",
  "class SimpleAuthenticator(Authenticator):\n    def __init__(self, users):\n        \"\"\"Authenticator to use in the LoginModule for authenticating admin clients for login.\n\n        Args:\n            users: user information\n        \"\"\"\n        self.users = users\n\n    def authenticate_password(self, user_name: str, pwd: str):\n        pwd_hash = self.users.get(user_name)\n        if pwd_hash is None:\n            return False\n\n        return verify_password(pwd_hash, pwd)\n\n    def authenticate_cn(self, user_name: str, cn):\n        return user_name == cn\n\n    def authenticate(self, user_name: str, credential, credential_type):\n        if credential_type == \"password\":\n            return self.authenticate_password(user_name, credential)\n        elif credential_type == \"cn\":\n            return self.authenticate_cn(user_name, credential)\n        else:\n            return False",
  "class LoginModule(CommandModule, CommandFilter):\n    def __init__(self, authenticator: Authenticator, sess_mgr: SessionManager):\n        \"\"\"Login module.\n\n        CommandModule containing the login commands to handle login and logout of admin clients, as well as the\n        CommandFilter pre_command to check that a client is logged in with a valid session.\n\n        Args:\n            authenticator: Authenticator\n            sess_mgr: SessionManager\n        \"\"\"\n        if authenticator:\n            if not isinstance(authenticator, Authenticator):\n                raise TypeError(\"authenticator must be Authenticator but got {}.\".format(type(authenticator)))\n\n        if not isinstance(sess_mgr, SessionManager):\n            raise TypeError(\"sess_mgr must be SessionManager but got {}.\".format(type(sess_mgr)))\n\n        self.authenticator = authenticator\n        self.session_mgr = sess_mgr\n\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=\"login\",\n            cmd_specs=[\n                CommandSpec(\n                    name=LOGIN_CMD_NAME,\n                    description=\"login to server\",\n                    usage=\"login userName password\",\n                    handler_func=self.handle_login,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=CERT_LOGIN_CMD_NAME,\n                    description=\"login to server with SSL cert\",\n                    usage=\"login userName\",\n                    handler_func=self.handle_cert_login,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=\"_logout\",\n                    description=\"logout from server\",\n                    usage=\"logout\",\n                    handler_func=self.handle_logout,\n                    visible=False,\n                ),\n            ],\n        )\n\n    def handle_login(self, conn: Connection, args: List[str]):\n        if not self.authenticator:\n            conn.append_string(\"OK\")\n            return\n\n        if len(args) != 3:\n            conn.append_string(\"REJECT\")\n            return\n\n        user_name = args[1]\n        pwd = args[2]\n\n        ok = self.authenticator.authenticate(user_name, pwd, \"password\")\n        if not ok:\n            conn.append_string(\"REJECT\")\n            return\n\n        session = self.session_mgr.create_session(user_name)\n        conn.append_string(\"OK\")\n        conn.append_token(session.token)\n\n    def handle_cert_login(self, conn: Connection, args: List[str]):\n        if not self.authenticator:\n            conn.append_string(\"OK\")\n            return\n\n        if len(args) != 2:\n            conn.append_string(\"REJECT\")\n            return\n\n        cn = conn.get_prop(\"_client_cn\", None)\n        if cn is None:\n            conn.append_string(\"REJECT\")\n            return\n\n        user_name = args[1]\n\n        ok = self.authenticator.authenticate(user_name, cn, \"cn\")\n        if not ok:\n            conn.append_string(\"REJECT\")\n            return\n\n        session = self.session_mgr.create_session(user_name)\n        conn.append_string(\"OK\")\n        conn.append_token(session.token)\n\n    def handle_logout(self, conn: Connection, args: List[str]):\n        if self.authenticator and self.session_mgr:\n            token = conn.get_prop(ConnProps.TOKEN)\n            if token:\n                self.session_mgr.end_session(token)\n        conn.append_string(\"OK\")\n\n    def pre_command(self, conn: Connection, args: List[str]):\n        if args[0] in [LOGIN_CMD_NAME, CERT_LOGIN_CMD_NAME, CHECK_SESSION_CMD_NAME]:\n            # skip login and check session commands\n            return True\n\n        # validate token\n        req_json = conn.request\n        token = None\n        data = req_json[\"data\"]\n        for item in data:\n            it = item[\"type\"]\n            if it == \"token\":\n                token = item[\"data\"]\n                break\n\n        if token is None:\n            conn.append_error(\"not authenticated - no token\")\n            return False\n\n        sess = self.session_mgr.get_session(token)\n        if sess:\n            sess.mark_active()\n            conn.set_prop(ConnProps.SESSION, sess)\n            conn.set_prop(ConnProps.USER_NAME, sess.user_name)\n            conn.set_prop(ConnProps.TOKEN, token)\n            return True\n        else:\n            conn.append_error(\"session_inactive\")\n            conn.append_string(\n                \"user not authenticated or session timed out after {} seconds of inactivity - logged out\".format(\n                    self.session_mgr.idle_timeout\n                )\n            )\n            return False",
  "def authenticate(self, user_name: str, credential: str, credential_type: str) -> bool:\n        \"\"\"Authenticate a specified user with the provided credential.\n\n        Args:\n            user_name: user login name\n            credential: provided credential\n            credential_type: type of credential\n\n        Returns: True if successful, False otherwise\n\n        \"\"\"\n        pass",
  "def __init__(self, users):\n        \"\"\"Authenticator to use in the LoginModule for authenticating admin clients for login.\n\n        Args:\n            users: user information\n        \"\"\"\n        self.users = users",
  "def authenticate_password(self, user_name: str, pwd: str):\n        pwd_hash = self.users.get(user_name)\n        if pwd_hash is None:\n            return False\n\n        return verify_password(pwd_hash, pwd)",
  "def authenticate_cn(self, user_name: str, cn):\n        return user_name == cn",
  "def authenticate(self, user_name: str, credential, credential_type):\n        if credential_type == \"password\":\n            return self.authenticate_password(user_name, credential)\n        elif credential_type == \"cn\":\n            return self.authenticate_cn(user_name, credential)\n        else:\n            return False",
  "def __init__(self, authenticator: Authenticator, sess_mgr: SessionManager):\n        \"\"\"Login module.\n\n        CommandModule containing the login commands to handle login and logout of admin clients, as well as the\n        CommandFilter pre_command to check that a client is logged in with a valid session.\n\n        Args:\n            authenticator: Authenticator\n            sess_mgr: SessionManager\n        \"\"\"\n        if authenticator:\n            if not isinstance(authenticator, Authenticator):\n                raise TypeError(\"authenticator must be Authenticator but got {}.\".format(type(authenticator)))\n\n        if not isinstance(sess_mgr, SessionManager):\n            raise TypeError(\"sess_mgr must be SessionManager but got {}.\".format(type(sess_mgr)))\n\n        self.authenticator = authenticator\n        self.session_mgr = sess_mgr",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=\"login\",\n            cmd_specs=[\n                CommandSpec(\n                    name=LOGIN_CMD_NAME,\n                    description=\"login to server\",\n                    usage=\"login userName password\",\n                    handler_func=self.handle_login,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=CERT_LOGIN_CMD_NAME,\n                    description=\"login to server with SSL cert\",\n                    usage=\"login userName\",\n                    handler_func=self.handle_cert_login,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=\"_logout\",\n                    description=\"logout from server\",\n                    usage=\"logout\",\n                    handler_func=self.handle_logout,\n                    visible=False,\n                ),\n            ],\n        )",
  "def handle_login(self, conn: Connection, args: List[str]):\n        if not self.authenticator:\n            conn.append_string(\"OK\")\n            return\n\n        if len(args) != 3:\n            conn.append_string(\"REJECT\")\n            return\n\n        user_name = args[1]\n        pwd = args[2]\n\n        ok = self.authenticator.authenticate(user_name, pwd, \"password\")\n        if not ok:\n            conn.append_string(\"REJECT\")\n            return\n\n        session = self.session_mgr.create_session(user_name)\n        conn.append_string(\"OK\")\n        conn.append_token(session.token)",
  "def handle_cert_login(self, conn: Connection, args: List[str]):\n        if not self.authenticator:\n            conn.append_string(\"OK\")\n            return\n\n        if len(args) != 2:\n            conn.append_string(\"REJECT\")\n            return\n\n        cn = conn.get_prop(\"_client_cn\", None)\n        if cn is None:\n            conn.append_string(\"REJECT\")\n            return\n\n        user_name = args[1]\n\n        ok = self.authenticator.authenticate(user_name, cn, \"cn\")\n        if not ok:\n            conn.append_string(\"REJECT\")\n            return\n\n        session = self.session_mgr.create_session(user_name)\n        conn.append_string(\"OK\")\n        conn.append_token(session.token)",
  "def handle_logout(self, conn: Connection, args: List[str]):\n        if self.authenticator and self.session_mgr:\n            token = conn.get_prop(ConnProps.TOKEN)\n            if token:\n                self.session_mgr.end_session(token)\n        conn.append_string(\"OK\")",
  "def pre_command(self, conn: Connection, args: List[str]):\n        if args[0] in [LOGIN_CMD_NAME, CERT_LOGIN_CMD_NAME, CHECK_SESSION_CMD_NAME]:\n            # skip login and check session commands\n            return True\n\n        # validate token\n        req_json = conn.request\n        token = None\n        data = req_json[\"data\"]\n        for item in data:\n            it = item[\"type\"]\n            if it == \"token\":\n                token = item[\"data\"]\n                break\n\n        if token is None:\n            conn.append_error(\"not authenticated - no token\")\n            return False\n\n        sess = self.session_mgr.get_session(token)\n        if sess:\n            sess.mark_active()\n            conn.set_prop(ConnProps.SESSION, sess)\n            conn.set_prop(ConnProps.USER_NAME, sess.user_name)\n            conn.set_prop(ConnProps.TOKEN, token)\n            return True\n        else:\n            conn.append_error(\"session_inactive\")\n            conn.append_string(\n                \"user not authenticated or session timed out after {} seconds of inactivity - logged out\".format(\n                    self.session_mgr.idle_timeout\n                )\n            )\n            return False",
  "class AuthorizationService(object):\n\n    the_authorizer = None\n\n    @staticmethod\n    def initialize(authorizer: Authorizer, policy_file: str = AUTHORIZATION_POLICY_FILE) -> (Authorizer, str):\n        assert isinstance(authorizer, Authorizer), \"authorizer must be Authorizer but got {}\".format(type(authorizer))\n\n        if not AuthorizationService.the_authorizer:\n            # get secure content of the policy file\n            policy_conf, result = SecurityContentService.load_json(policy_file)\n            if result == LoadResult.NOT_MANAGED or result == LoadResult.NO_SUCH_CONTENT:\n                # no authorization needed\n                AuthorizationService.the_authorizer = authorizer\n            elif result == LoadResult.OK:\n                err = authorizer.load_policy(policy_conf)\n                if err:\n                    return None, err\n                AuthorizationService.the_authorizer = authorizer\n            else:\n                return None, \"invalid policy file {}: {}\".format(policy_file, result)\n\n        return AuthorizationService.the_authorizer, \"\"\n\n    @staticmethod\n    def initialize_with_policy(authorizer: Authorizer, policy_file_path: str) -> (Authorizer, str):\n        assert isinstance(authorizer, Authorizer), \"authorizer must be Authorizer but got {}\".format(type(authorizer))\n\n        if AuthorizationService.the_authorizer:\n            return AuthorizationService.the_authorizer\n\n        if not os.path.exists(policy_file_path):\n            return None, 'policy file \"{}\" does not exist'.format(policy_file_path)\n\n        with open(policy_file_path) as file:\n            try:\n                policy_conf = json.load(file)\n            except json.JSONDecodeError:\n                return None, 'policy file \"{}\" is invalid'.format(policy_file_path)\n\n        err = authorizer.load_policy(policy_conf)\n        if err:\n            return None, err\n\n        AuthorizationService.the_authorizer = authorizer\n        return AuthorizationService.the_authorizer, \"\"\n\n    @staticmethod\n    def get_authorizer():\n        return AuthorizationService.the_authorizer\n\n    @staticmethod\n    def authorize(ctx: AuthzContext):\n        if not AuthorizationService.the_authorizer:\n            return None, \"no authorizer defined\"\n        return AuthorizationService.the_authorizer.authorize(ctx)",
  "class AuthzFilter(CommandFilter):\n    def __init__(self, authorizer: Authorizer):\n        \"\"\"Filter for authorization of admin commands.\n\n        Args:\n            authorizer: instance of Authorizer\n        \"\"\"\n        CommandFilter.__init__(self)\n        assert isinstance(authorizer, Authorizer), \"authorizer must be Authorizer but got {}\".format(type(authorizer))\n        self.authorizer = authorizer\n\n    def pre_command(self, conn: Connection, args: List[str]):\n        cmd_entry = conn.get_prop(ConnProps.CMD_ENTRY, None)\n        if not cmd_entry:\n            return True\n\n        assert isinstance(cmd_entry, CommandEntry)\n        authz_func = cmd_entry.authz_func\n        if not authz_func:\n            return True\n\n        valid, authz_ctx = authz_func(conn, args)\n\n        if not valid:\n            return False\n\n        if not authz_ctx or (isinstance(authz_ctx, tuple) and not any(authz_ctx)):\n            # no authz needed\n            return True\n\n        if isinstance(authz_ctx, tuple):\n            for authz in authz_ctx:\n                result = self.check_authz(authz, conn)\n                if not result:\n                    return False\n            return True\n        else:\n            return self.check_authz(authz_ctx, conn)\n\n    def check_authz(self, authz_ctx, conn: Connection):\n        assert isinstance(authz_ctx, AuthzContext), \"authz_ctx must be AuthzContext but got {}\".format(type(authz_ctx))\n\n        authz_ctx.user_name = conn.get_prop(ConnProps.USER_NAME, \"\")\n        conn.set_prop(ConnProps.AUTHZ_CTX, authz_ctx)\n        authorized, err = self.authorizer.authorize(ctx=authz_ctx)\n        if err:\n            conn.append_error(\"Authorization Error: {}\".format(err))\n            return False\n\n        if not authorized:\n            conn.append_error(\"This action is not authorized\")\n            return False\n        return True",
  "class AuthzCommandModule(CommandModule):\n    def __init__(self, authorizer: Authorizer):\n        \"\"\"Authorization command module.\n\n        Args:\n            authorizer: instance of Authorizer\n        \"\"\"\n        assert isinstance(authorizer, Authorizer), \"authorizer must be Authorizer but got {}\".format(type(authorizer))\n        self.authorizer = authorizer\n\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=\"authz\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"show_info\",\n                    description=\"show general info of authorization policy\",\n                    usage=\"show_info\",\n                    handler_func=self.show_info,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"show_users\",\n                    description=\"show users configured for authorization\",\n                    usage=\"show_users\",\n                    handler_func=self.show_users,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"show_sites\",\n                    description=\"show sites configured for authorization\",\n                    usage=\"show_sites\",\n                    handler_func=self.show_sites,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"show_rules\",\n                    description=\"show rules configured for authorization\",\n                    usage=\"show_rules\",\n                    handler_func=self.show_rules,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"show_rights\",\n                    description=\"show rights configured for authorization\",\n                    usage=\"show_rights\",\n                    handler_func=self.show_rights,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"show_config\",\n                    description=\"show authorization config\",\n                    usage=\"show_config\",\n                    handler_func=self.show_config,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"eval_right\",\n                    description=\"check if a user has a right on a site\",\n                    usage=\"eval_right user_name right_name [site_name...]\",\n                    handler_func=self.eval_right,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"eval_rule\",\n                    description=\"evaluate a site against a rule\",\n                    usage=\"eval_rule site_name rule_name\",\n                    handler_func=self.eval_rule,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n            ],\n        )\n\n    def _authorize_cmd(self, conn: Connection, args: List[str]):\n        # Use this method to pre-process the command,\n        # mainly to get authorizer and policy and store them in conn\n        # so the command handler can get them from the conn.\n        # This way, command handlers don't need to know how to get authorizer or policy.\n        # In case we use different way to get authorizer, this is the only place to change!\n        policy = self.authorizer.get_policy()\n        if not policy:\n            conn.append_error(\"no authorization policy defined\")\n            return False, None\n\n        conn.set_prop(\"authorizer\", self.authorizer)\n        conn.set_prop(\"policy\", policy)\n\n        # return a None authz_ctx because the command does not need to be authorized!\n        return True, None\n\n    def show_info(self, conn: Connection, args: List[str]):\n        authorizer = conn.get_prop(\"authorizer\")\n        conn.append_string(\"Last Loaded: {}\".format(time_to_string(authorizer.last_load_time)))\n\n    def show_users(self, conn: Connection, args: List[str]):\n        policy = conn.get_prop(\"policy\")\n        users = policy.get_users()\n        table = conn.append_table([\"user\", \"org\", \"roles\"])\n        for user_name, user_def in users.items():\n            table.add_row([user_name, user_def[\"org\"], \",\".join(user_def[\"roles\"])])\n\n    def show_sites(self, conn: Connection, args: List[str]):\n        policy = conn.get_prop(\"policy\")\n        if not policy:\n            conn.append_error(\"no authorization policy\")\n            return\n\n        sites = policy.get_sites()\n        table = conn.append_table([\"site\", \"org\"])\n        for site_name, org in sites.items():\n            table.add_row([site_name, org])\n\n    def show_rights(self, conn: Connection, args: List[str]):\n        policy = conn.get_prop(\"policy\")\n        if not policy:\n            conn.append_error(\"no authorization policy\")\n            return\n\n        rights = policy.get_rights()\n        table = conn.append_table([\"name\", \"description\", \"default\"])\n        for name, right_def in rights.items():\n            desc = right_def.get(\"desc\", \"\")\n            default = right_def.get(\"default\", \"\")\n            table.add_row([name, desc, \"{}\".format(default)])\n\n    def show_rules(self, conn: Connection, args: List[str]):\n        policy = conn.get_prop(\"policy\")\n        if not policy:\n            conn.append_error(\"no authorization policy\")\n            return\n\n        rules = policy.get_rules()\n        table = conn.append_table([\"name\", \"description\", \"default\"])\n        for name, rule_def in rules.items():\n            desc = rule_def.get(\"desc\", \"\")\n            default = rule_def.get(\"default\", \"\")\n            table.add_row([name, desc, \"{}\".format(default)])\n\n    def show_config(self, conn: Connection, args: List[str]):\n        policy = conn.get_prop(\"policy\")\n        config = policy.get_config()\n        conn.append_string(json.dumps(config, indent=1))\n\n    def eval_right(self, conn: Connection, args: List[str]):\n        if len(args) < 3:\n            conn.append_error(\"Usage: {} user_name right_name [site_name...]\".format(args[0]))\n            return\n\n        authorizer = conn.get_prop(\"authorizer\")\n        user_name = args[1]\n        right_name = args[2]\n        site_names = args[3:]\n        if not site_names:\n            # all sites\n            policy = conn.get_prop(\"policy\")\n            if not policy:\n                conn.append_error(\"no authorization policy\")\n                return\n\n            sites = policy.get_sites()\n            for s, _ in sites.items():\n                site_names.append(s)\n\n        table = conn.append_table([\"Site\", \"Result\"])\n        for s in site_names:\n            result, err = authorizer.evaluate_user_right_on_site(\n                user_name=user_name, site_name=s, right_name=right_name\n            )\n            if err:\n                result = err\n            else:\n                result = str(result)\n            table.add_row([s, result])\n\n    def eval_rule(self, conn: Connection, args: List[str]):\n        if len(args) != 3:\n            conn.append_error(\"Usage: {} site_name rule_name\".format(args[0]))\n            return\n\n        authorizer = conn.get_prop(\"authorizer\")\n        site_name = args[1]\n        rule_name = args[2]\n        result, err = authorizer.evaluate_rule_on_site(site_name=site_name, rule_name=rule_name)\n        if err:\n            conn.append_error(err)\n        else:\n            conn.append_string(\"{}\".format(result))",
  "def initialize(authorizer: Authorizer, policy_file: str = AUTHORIZATION_POLICY_FILE) -> (Authorizer, str):\n        assert isinstance(authorizer, Authorizer), \"authorizer must be Authorizer but got {}\".format(type(authorizer))\n\n        if not AuthorizationService.the_authorizer:\n            # get secure content of the policy file\n            policy_conf, result = SecurityContentService.load_json(policy_file)\n            if result == LoadResult.NOT_MANAGED or result == LoadResult.NO_SUCH_CONTENT:\n                # no authorization needed\n                AuthorizationService.the_authorizer = authorizer\n            elif result == LoadResult.OK:\n                err = authorizer.load_policy(policy_conf)\n                if err:\n                    return None, err\n                AuthorizationService.the_authorizer = authorizer\n            else:\n                return None, \"invalid policy file {}: {}\".format(policy_file, result)\n\n        return AuthorizationService.the_authorizer, \"\"",
  "def initialize_with_policy(authorizer: Authorizer, policy_file_path: str) -> (Authorizer, str):\n        assert isinstance(authorizer, Authorizer), \"authorizer must be Authorizer but got {}\".format(type(authorizer))\n\n        if AuthorizationService.the_authorizer:\n            return AuthorizationService.the_authorizer\n\n        if not os.path.exists(policy_file_path):\n            return None, 'policy file \"{}\" does not exist'.format(policy_file_path)\n\n        with open(policy_file_path) as file:\n            try:\n                policy_conf = json.load(file)\n            except json.JSONDecodeError:\n                return None, 'policy file \"{}\" is invalid'.format(policy_file_path)\n\n        err = authorizer.load_policy(policy_conf)\n        if err:\n            return None, err\n\n        AuthorizationService.the_authorizer = authorizer\n        return AuthorizationService.the_authorizer, \"\"",
  "def get_authorizer():\n        return AuthorizationService.the_authorizer",
  "def authorize(ctx: AuthzContext):\n        if not AuthorizationService.the_authorizer:\n            return None, \"no authorizer defined\"\n        return AuthorizationService.the_authorizer.authorize(ctx)",
  "def __init__(self, authorizer: Authorizer):\n        \"\"\"Filter for authorization of admin commands.\n\n        Args:\n            authorizer: instance of Authorizer\n        \"\"\"\n        CommandFilter.__init__(self)\n        assert isinstance(authorizer, Authorizer), \"authorizer must be Authorizer but got {}\".format(type(authorizer))\n        self.authorizer = authorizer",
  "def pre_command(self, conn: Connection, args: List[str]):\n        cmd_entry = conn.get_prop(ConnProps.CMD_ENTRY, None)\n        if not cmd_entry:\n            return True\n\n        assert isinstance(cmd_entry, CommandEntry)\n        authz_func = cmd_entry.authz_func\n        if not authz_func:\n            return True\n\n        valid, authz_ctx = authz_func(conn, args)\n\n        if not valid:\n            return False\n\n        if not authz_ctx or (isinstance(authz_ctx, tuple) and not any(authz_ctx)):\n            # no authz needed\n            return True\n\n        if isinstance(authz_ctx, tuple):\n            for authz in authz_ctx:\n                result = self.check_authz(authz, conn)\n                if not result:\n                    return False\n            return True\n        else:\n            return self.check_authz(authz_ctx, conn)",
  "def check_authz(self, authz_ctx, conn: Connection):\n        assert isinstance(authz_ctx, AuthzContext), \"authz_ctx must be AuthzContext but got {}\".format(type(authz_ctx))\n\n        authz_ctx.user_name = conn.get_prop(ConnProps.USER_NAME, \"\")\n        conn.set_prop(ConnProps.AUTHZ_CTX, authz_ctx)\n        authorized, err = self.authorizer.authorize(ctx=authz_ctx)\n        if err:\n            conn.append_error(\"Authorization Error: {}\".format(err))\n            return False\n\n        if not authorized:\n            conn.append_error(\"This action is not authorized\")\n            return False\n        return True",
  "def __init__(self, authorizer: Authorizer):\n        \"\"\"Authorization command module.\n\n        Args:\n            authorizer: instance of Authorizer\n        \"\"\"\n        assert isinstance(authorizer, Authorizer), \"authorizer must be Authorizer but got {}\".format(type(authorizer))\n        self.authorizer = authorizer",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=\"authz\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"show_info\",\n                    description=\"show general info of authorization policy\",\n                    usage=\"show_info\",\n                    handler_func=self.show_info,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"show_users\",\n                    description=\"show users configured for authorization\",\n                    usage=\"show_users\",\n                    handler_func=self.show_users,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"show_sites\",\n                    description=\"show sites configured for authorization\",\n                    usage=\"show_sites\",\n                    handler_func=self.show_sites,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"show_rules\",\n                    description=\"show rules configured for authorization\",\n                    usage=\"show_rules\",\n                    handler_func=self.show_rules,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"show_rights\",\n                    description=\"show rights configured for authorization\",\n                    usage=\"show_rights\",\n                    handler_func=self.show_rights,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"show_config\",\n                    description=\"show authorization config\",\n                    usage=\"show_config\",\n                    handler_func=self.show_config,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"eval_right\",\n                    description=\"check if a user has a right on a site\",\n                    usage=\"eval_right user_name right_name [site_name...]\",\n                    handler_func=self.eval_right,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=\"eval_rule\",\n                    description=\"evaluate a site against a rule\",\n                    usage=\"eval_rule site_name rule_name\",\n                    handler_func=self.eval_rule,\n                    authz_func=self._authorize_cmd,\n                    visible=True,\n                ),\n            ],\n        )",
  "def _authorize_cmd(self, conn: Connection, args: List[str]):\n        # Use this method to pre-process the command,\n        # mainly to get authorizer and policy and store them in conn\n        # so the command handler can get them from the conn.\n        # This way, command handlers don't need to know how to get authorizer or policy.\n        # In case we use different way to get authorizer, this is the only place to change!\n        policy = self.authorizer.get_policy()\n        if not policy:\n            conn.append_error(\"no authorization policy defined\")\n            return False, None\n\n        conn.set_prop(\"authorizer\", self.authorizer)\n        conn.set_prop(\"policy\", policy)\n\n        # return a None authz_ctx because the command does not need to be authorized!\n        return True, None",
  "def show_info(self, conn: Connection, args: List[str]):\n        authorizer = conn.get_prop(\"authorizer\")\n        conn.append_string(\"Last Loaded: {}\".format(time_to_string(authorizer.last_load_time)))",
  "def show_users(self, conn: Connection, args: List[str]):\n        policy = conn.get_prop(\"policy\")\n        users = policy.get_users()\n        table = conn.append_table([\"user\", \"org\", \"roles\"])\n        for user_name, user_def in users.items():\n            table.add_row([user_name, user_def[\"org\"], \",\".join(user_def[\"roles\"])])",
  "def show_sites(self, conn: Connection, args: List[str]):\n        policy = conn.get_prop(\"policy\")\n        if not policy:\n            conn.append_error(\"no authorization policy\")\n            return\n\n        sites = policy.get_sites()\n        table = conn.append_table([\"site\", \"org\"])\n        for site_name, org in sites.items():\n            table.add_row([site_name, org])",
  "def show_rights(self, conn: Connection, args: List[str]):\n        policy = conn.get_prop(\"policy\")\n        if not policy:\n            conn.append_error(\"no authorization policy\")\n            return\n\n        rights = policy.get_rights()\n        table = conn.append_table([\"name\", \"description\", \"default\"])\n        for name, right_def in rights.items():\n            desc = right_def.get(\"desc\", \"\")\n            default = right_def.get(\"default\", \"\")\n            table.add_row([name, desc, \"{}\".format(default)])",
  "def show_rules(self, conn: Connection, args: List[str]):\n        policy = conn.get_prop(\"policy\")\n        if not policy:\n            conn.append_error(\"no authorization policy\")\n            return\n\n        rules = policy.get_rules()\n        table = conn.append_table([\"name\", \"description\", \"default\"])\n        for name, rule_def in rules.items():\n            desc = rule_def.get(\"desc\", \"\")\n            default = rule_def.get(\"default\", \"\")\n            table.add_row([name, desc, \"{}\".format(default)])",
  "def show_config(self, conn: Connection, args: List[str]):\n        policy = conn.get_prop(\"policy\")\n        config = policy.get_config()\n        conn.append_string(json.dumps(config, indent=1))",
  "def eval_right(self, conn: Connection, args: List[str]):\n        if len(args) < 3:\n            conn.append_error(\"Usage: {} user_name right_name [site_name...]\".format(args[0]))\n            return\n\n        authorizer = conn.get_prop(\"authorizer\")\n        user_name = args[1]\n        right_name = args[2]\n        site_names = args[3:]\n        if not site_names:\n            # all sites\n            policy = conn.get_prop(\"policy\")\n            if not policy:\n                conn.append_error(\"no authorization policy\")\n                return\n\n            sites = policy.get_sites()\n            for s, _ in sites.items():\n                site_names.append(s)\n\n        table = conn.append_table([\"Site\", \"Result\"])\n        for s in site_names:\n            result, err = authorizer.evaluate_user_right_on_site(\n                user_name=user_name, site_name=s, right_name=right_name\n            )\n            if err:\n                result = err\n            else:\n                result = str(result)\n            table.add_row([s, result])",
  "def eval_rule(self, conn: Connection, args: List[str]):\n        if len(args) != 3:\n            conn.append_error(\"Usage: {} site_name rule_name\".format(args[0]))\n            return\n\n        authorizer = conn.get_prop(\"authorizer\")\n        site_name = args[1]\n        rule_name = args[2]\n        result, err = authorizer.evaluate_rule_on_site(site_name=site_name, rule_name=rule_name)\n        if err:\n            conn.append_error(err)\n        else:\n            conn.append_string(\"{}\".format(result))",
  "class ConnProps(object):\n    \"\"\"Constants for connection properties.\"\"\"\n\n    EVENT_ID = \"_eventId\"\n    USER_NAME = \"_userName\"\n    TOKEN = \"_sessionToken\"\n    SESSION = \"_session\"\n    CMD_ENTRY = \"_cmdEntry\"\n    AUTHZ_CTX = \"_authztx\"\n    JOB_DATA = \"_jobData\"\n    JOB_META = \"_jobMeta\"\n    DOWNLOAD_JOB_URL = \"Download Job URL:\"",
  "class FileTransferModule(CommandModule, CommandUtil):\n    def __init__(self, upload_dir: str, download_dir: str, upload_folder_authz_func=None, download_job_url=None):\n        \"\"\"Command module for file transfers.\n\n        Args:\n            upload_dir:\n            download_dir:\n            upload_folder_authz_func:\n        \"\"\"\n        if not os.path.isdir(upload_dir):\n            raise ValueError(\"upload_dir {} is not a valid dir\".format(upload_dir))\n\n        if not os.path.isdir(download_dir):\n            raise ValueError(\"download_dir {} is not a valid dir\".format(download_dir))\n\n        self.upload_dir = upload_dir\n        self.download_dir = download_dir\n        self.upload_folder_authz_func = upload_folder_authz_func\n        self.download_url = download_job_url\n\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=ftd.SERVER_MODULE_NAME,\n            cmd_specs=[\n                CommandSpec(\n                    name=ftd.SERVER_CMD_UPLOAD_TEXT,\n                    description=\"upload one or more text files\",\n                    usage=\"_upload name1 data1 name2 data2 ...\",\n                    handler_func=self.upload_text_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_DOWNLOAD_TEXT,\n                    description=\"download one or more text files\",\n                    usage=\"download file_name ...\",\n                    handler_func=self.download_text_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_UPLOAD_BINARY,\n                    description=\"upload one or more binary files\",\n                    usage=\"upload name1 data1 name2 data2 ...\",\n                    handler_func=self.upload_binary_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_DOWNLOAD_BINARY,\n                    description=\"download one or more binary files\",\n                    usage=\"download file_name ...\",\n                    handler_func=self.download_binary_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_UPLOAD_FOLDER,\n                    description=\"upload a folder from client\",\n                    usage=\"upload_folder folder_name\",\n                    handler_func=self.upload_folder,\n                    authz_func=self._authorize_upload_folder,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_SUBMIT_JOB,\n                    description=\"Submit a job\",\n                    usage=\"submit_job job_folder\",\n                    handler_func=self.submit_job,\n                    authz_func=self._authorize_submission,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_DOWNLOAD_JOB,\n                    description=\"download a job\",\n                    usage=\"download_job job_id\",\n                    handler_func=self.download_job,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_INFO,\n                    description=\"show info\",\n                    usage=\"info\",\n                    handler_func=self.info,\n                    visible=False,\n                ),\n            ],\n        )\n\n    def upload_file(self, conn: Connection, args: List[str], str_to_file_func):\n        if len(args) < 3:\n            conn.append_error(\"syntax error: missing files\")\n            return\n\n        if len(args) % 2 != 1:\n            conn.append_error(\"syntax error: file name/data not paired\")\n            return\n\n        table = conn.append_table([\"file\", \"size\"])\n        i = 1\n        while i < len(args):\n            name = args[i]\n            data = args[i + 1]\n            i += 2\n\n            full_path = os.path.join(self.upload_dir, name)\n            num_bytes = str_to_file_func(b64str=data, file_name=full_path)\n            table.add_row([name, str(num_bytes)])\n\n    def upload_text_file(self, conn: Connection, args: List[str]):\n        self.upload_file(conn, args, b64str_to_text_file)\n\n    def upload_binary_file(self, conn: Connection, args: List[str]):\n        self.upload_file(conn, args, b64str_to_binary_file)\n\n    def download_file(self, conn: Connection, args: List[str], file_to_str_func):\n        if len(args) < 2:\n            conn.append_error(\"syntax error: missing file names\")\n            return\n\n        table = conn.append_table([\"name\", \"data\"])\n        for i in range(1, len(args)):\n            file_name = args[i]\n            full_path = os.path.join(self.download_dir, file_name)\n            if not os.path.exists(full_path):\n                conn.append_error(\"no such file: {}\".format(file_name))\n                continue\n\n            if not os.path.isfile(full_path):\n                conn.append_error(\"not a file: {}\".format(file_name))\n                continue\n\n            encoded_str = file_to_str_func(full_path)\n            table.add_row([file_name, encoded_str])\n\n    def download_text_file(self, conn: Connection, args: List[str]):\n        self.download_file(conn, args, text_file_to_b64str)\n\n    def download_binary_file(self, conn: Connection, args: List[str]):\n        self.download_file(conn, args, binary_file_to_b64str)\n\n    def _authorize_upload_folder(self, conn: Connection, args: List[str]):\n        if len(args) != 3:\n            conn.append_error(\"syntax error: require data\")\n            return False, None\n\n        folder_name = args[1]\n        zip_b64str = args[2]\n        tmp_dir = tempfile.mkdtemp()\n\n        try:\n            data_bytes = b64str_to_bytes(zip_b64str)\n            unzip_all_from_bytes(data_bytes, tmp_dir)\n            tmp_folder_path = os.path.join(tmp_dir, folder_name)\n\n            if not os.path.isdir(tmp_folder_path):\n                conn.append_error(\"logic error: unzip failed to create folder {}\".format(tmp_folder_path))\n                return False, None\n\n            if self.upload_folder_authz_func:\n                err, authz_ctx = self.upload_folder_authz_func(tmp_folder_path)\n                if err is None:\n                    err = \"\"\n                elif not isinstance(err, str):\n                    # the validator failed to follow signature\n                    # assuming things are bad\n                    err = \"folder validation failed\"\n\n                if len(err) > 0:\n                    conn.append_error(err)\n                    return False, None\n                else:\n                    return True, authz_ctx\n            else:\n                return True, None\n        except BaseException:\n            traceback.print_exc()\n            conn.append_error(\"exception occurred\")\n            return False, None\n        finally:\n            shutil.rmtree(tmp_dir)\n\n    def upload_folder(self, conn: Connection, args: List[str]):\n        folder_name = args[1]\n        zip_b64str = args[2]\n        folder_path = os.path.join(self.upload_dir, folder_name)\n        if os.path.exists(folder_path):\n            shutil.rmtree(folder_path)\n        data_bytes = b64str_to_bytes(zip_b64str)\n        unzip_all_from_bytes(data_bytes, self.upload_dir)\n        conn.set_prop(\"upload_folder_path\", folder_path)\n        conn.append_string(\"Created folder {}\".format(folder_path))\n\n    def submit_job(self, conn: Connection, args: List[str]):\n\n        folder_name = args[1]\n        data_bytes = conn.get_prop(ConnProps.JOB_DATA)\n        engine = conn.app_ctx\n\n        try:\n            with engine.new_context() as fl_ctx:\n                job_validator = JobMetaValidator()\n                valid, error, meta = job_validator.validate(folder_name, data_bytes)\n                if not valid:\n                    conn.append_error(error)\n                    return\n\n                job_def_manager = engine.job_def_manager\n                if not isinstance(job_def_manager, JobDefManagerSpec):\n                    raise TypeError(\n                        f\"job_def_manager in engine is not of type JobDefManagerSpec, but got {type(job_def_manager)}\"\n                    )\n\n                meta = job_def_manager.create(meta, data_bytes, fl_ctx)\n                conn.append_string(\"Submitted job: {}\".format(meta.get(JobMetaKey.JOB_ID)))\n        except Exception as e:\n            conn.append_error(\"Exception occurred trying to submit job: \" + str(e))\n            return\n\n        conn.append_success(\"\")\n\n    def download_job(self, conn: Connection, args: List[str]):\n        if len(args) != 2:\n            conn.append_error(\"syntax error: job ID required\")\n            return\n\n        job_id = args[1]\n\n        engine = conn.app_ctx\n        try:\n            job_def_manager = engine.job_def_manager\n            if not isinstance(job_def_manager, JobDefManagerSpec):\n                raise TypeError(\n                    f\"job_def_manager in engine is not of type JobDefManagerSpec, but got {type(job_def_manager)}\"\n                )\n            with engine.new_context() as fl_ctx:\n                job_data = job_def_manager.get_job_data(job_id, fl_ctx)\n                size = get_size(job_data, seen=None)\n                if size > MAX_DOWNLOAD_JOB__SIZE:\n                    conn.append_string(ConnProps.DOWNLOAD_JOB_URL + self.download_url + job_id)\n                    return\n\n                self._unzip_data(job_data, job_id)\n        except Exception as e:\n            conn.append_error(\"Exception occurred trying to get job from store: \" + str(e))\n            return\n        try:\n            data = zip_directory_to_bytes(self.download_dir, job_id)\n            b64str = bytes_to_b64str(data)\n            conn.append_string(b64str)\n        except BaseException:\n            traceback.print_exc()\n            conn.append_error(\"Exception occurred during attempt to zip data to send for job: {}\".format(job_id))\n\n    def _unzip_data(self, job_data, job_id):\n        job_id_dir = os.path.join(self.download_dir, job_id)\n        if os.path.exists(job_id_dir):\n            shutil.rmtree(job_id_dir)\n        os.mkdir(job_id_dir)\n\n        data_bytes = job_data[JobDataKey.JOB_DATA.value]\n        job_dir = os.path.join(job_id_dir, \"job\")\n        os.mkdir(job_dir)\n        unzip_all_from_bytes(data_bytes, job_dir)\n\n        workspace_bytes = job_data[JobDataKey.WORKSPACE_DATA.value]\n        workspace_dir = os.path.join(job_id_dir, \"workspace\")\n        os.mkdir(workspace_dir)\n        if workspace_bytes is not None:\n            unzip_all_from_bytes(workspace_bytes, workspace_dir)\n\n    def info(self, conn: Connection, args: List[str]):\n        conn.append_string(\"Server Upload Destination: {}\".format(self.upload_dir))\n        conn.append_string(\"Server Download Source: {}\".format(self.download_dir))\n\n    def _authorize_submission(self, conn: Connection, args: List[str]):\n\n        folder_name = args[1]\n        zip_b64str = args[2]\n        data_bytes = convert_legacy_zip(b64str_to_bytes(zip_b64str))\n        conn.set_prop(ConnProps.JOB_DATA, data_bytes)\n\n        meta_file = f\"{folder_name}/{META_FILE}\"\n        with ZipFile(BytesIO(data_bytes), \"r\") as zf:\n            meta_data = zf.read(meta_file)\n            meta = json.loads(meta_data)\n        conn.set_prop(ConnProps.JOB_META, meta)\n\n        return self.authorize_job_meta(conn, meta, [Action.TRAIN])",
  "def __init__(self, upload_dir: str, download_dir: str, upload_folder_authz_func=None, download_job_url=None):\n        \"\"\"Command module for file transfers.\n\n        Args:\n            upload_dir:\n            download_dir:\n            upload_folder_authz_func:\n        \"\"\"\n        if not os.path.isdir(upload_dir):\n            raise ValueError(\"upload_dir {} is not a valid dir\".format(upload_dir))\n\n        if not os.path.isdir(download_dir):\n            raise ValueError(\"download_dir {} is not a valid dir\".format(download_dir))\n\n        self.upload_dir = upload_dir\n        self.download_dir = download_dir\n        self.upload_folder_authz_func = upload_folder_authz_func\n        self.download_url = download_job_url",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=ftd.SERVER_MODULE_NAME,\n            cmd_specs=[\n                CommandSpec(\n                    name=ftd.SERVER_CMD_UPLOAD_TEXT,\n                    description=\"upload one or more text files\",\n                    usage=\"_upload name1 data1 name2 data2 ...\",\n                    handler_func=self.upload_text_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_DOWNLOAD_TEXT,\n                    description=\"download one or more text files\",\n                    usage=\"download file_name ...\",\n                    handler_func=self.download_text_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_UPLOAD_BINARY,\n                    description=\"upload one or more binary files\",\n                    usage=\"upload name1 data1 name2 data2 ...\",\n                    handler_func=self.upload_binary_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_DOWNLOAD_BINARY,\n                    description=\"download one or more binary files\",\n                    usage=\"download file_name ...\",\n                    handler_func=self.download_binary_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_UPLOAD_FOLDER,\n                    description=\"upload a folder from client\",\n                    usage=\"upload_folder folder_name\",\n                    handler_func=self.upload_folder,\n                    authz_func=self._authorize_upload_folder,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_SUBMIT_JOB,\n                    description=\"Submit a job\",\n                    usage=\"submit_job job_folder\",\n                    handler_func=self.submit_job,\n                    authz_func=self._authorize_submission,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_DOWNLOAD_JOB,\n                    description=\"download a job\",\n                    usage=\"download_job job_id\",\n                    handler_func=self.download_job,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=ftd.SERVER_CMD_INFO,\n                    description=\"show info\",\n                    usage=\"info\",\n                    handler_func=self.info,\n                    visible=False,\n                ),\n            ],\n        )",
  "def upload_file(self, conn: Connection, args: List[str], str_to_file_func):\n        if len(args) < 3:\n            conn.append_error(\"syntax error: missing files\")\n            return\n\n        if len(args) % 2 != 1:\n            conn.append_error(\"syntax error: file name/data not paired\")\n            return\n\n        table = conn.append_table([\"file\", \"size\"])\n        i = 1\n        while i < len(args):\n            name = args[i]\n            data = args[i + 1]\n            i += 2\n\n            full_path = os.path.join(self.upload_dir, name)\n            num_bytes = str_to_file_func(b64str=data, file_name=full_path)\n            table.add_row([name, str(num_bytes)])",
  "def upload_text_file(self, conn: Connection, args: List[str]):\n        self.upload_file(conn, args, b64str_to_text_file)",
  "def upload_binary_file(self, conn: Connection, args: List[str]):\n        self.upload_file(conn, args, b64str_to_binary_file)",
  "def download_file(self, conn: Connection, args: List[str], file_to_str_func):\n        if len(args) < 2:\n            conn.append_error(\"syntax error: missing file names\")\n            return\n\n        table = conn.append_table([\"name\", \"data\"])\n        for i in range(1, len(args)):\n            file_name = args[i]\n            full_path = os.path.join(self.download_dir, file_name)\n            if not os.path.exists(full_path):\n                conn.append_error(\"no such file: {}\".format(file_name))\n                continue\n\n            if not os.path.isfile(full_path):\n                conn.append_error(\"not a file: {}\".format(file_name))\n                continue\n\n            encoded_str = file_to_str_func(full_path)\n            table.add_row([file_name, encoded_str])",
  "def download_text_file(self, conn: Connection, args: List[str]):\n        self.download_file(conn, args, text_file_to_b64str)",
  "def download_binary_file(self, conn: Connection, args: List[str]):\n        self.download_file(conn, args, binary_file_to_b64str)",
  "def _authorize_upload_folder(self, conn: Connection, args: List[str]):\n        if len(args) != 3:\n            conn.append_error(\"syntax error: require data\")\n            return False, None\n\n        folder_name = args[1]\n        zip_b64str = args[2]\n        tmp_dir = tempfile.mkdtemp()\n\n        try:\n            data_bytes = b64str_to_bytes(zip_b64str)\n            unzip_all_from_bytes(data_bytes, tmp_dir)\n            tmp_folder_path = os.path.join(tmp_dir, folder_name)\n\n            if not os.path.isdir(tmp_folder_path):\n                conn.append_error(\"logic error: unzip failed to create folder {}\".format(tmp_folder_path))\n                return False, None\n\n            if self.upload_folder_authz_func:\n                err, authz_ctx = self.upload_folder_authz_func(tmp_folder_path)\n                if err is None:\n                    err = \"\"\n                elif not isinstance(err, str):\n                    # the validator failed to follow signature\n                    # assuming things are bad\n                    err = \"folder validation failed\"\n\n                if len(err) > 0:\n                    conn.append_error(err)\n                    return False, None\n                else:\n                    return True, authz_ctx\n            else:\n                return True, None\n        except BaseException:\n            traceback.print_exc()\n            conn.append_error(\"exception occurred\")\n            return False, None\n        finally:\n            shutil.rmtree(tmp_dir)",
  "def upload_folder(self, conn: Connection, args: List[str]):\n        folder_name = args[1]\n        zip_b64str = args[2]\n        folder_path = os.path.join(self.upload_dir, folder_name)\n        if os.path.exists(folder_path):\n            shutil.rmtree(folder_path)\n        data_bytes = b64str_to_bytes(zip_b64str)\n        unzip_all_from_bytes(data_bytes, self.upload_dir)\n        conn.set_prop(\"upload_folder_path\", folder_path)\n        conn.append_string(\"Created folder {}\".format(folder_path))",
  "def submit_job(self, conn: Connection, args: List[str]):\n\n        folder_name = args[1]\n        data_bytes = conn.get_prop(ConnProps.JOB_DATA)\n        engine = conn.app_ctx\n\n        try:\n            with engine.new_context() as fl_ctx:\n                job_validator = JobMetaValidator()\n                valid, error, meta = job_validator.validate(folder_name, data_bytes)\n                if not valid:\n                    conn.append_error(error)\n                    return\n\n                job_def_manager = engine.job_def_manager\n                if not isinstance(job_def_manager, JobDefManagerSpec):\n                    raise TypeError(\n                        f\"job_def_manager in engine is not of type JobDefManagerSpec, but got {type(job_def_manager)}\"\n                    )\n\n                meta = job_def_manager.create(meta, data_bytes, fl_ctx)\n                conn.append_string(\"Submitted job: {}\".format(meta.get(JobMetaKey.JOB_ID)))\n        except Exception as e:\n            conn.append_error(\"Exception occurred trying to submit job: \" + str(e))\n            return\n\n        conn.append_success(\"\")",
  "def download_job(self, conn: Connection, args: List[str]):\n        if len(args) != 2:\n            conn.append_error(\"syntax error: job ID required\")\n            return\n\n        job_id = args[1]\n\n        engine = conn.app_ctx\n        try:\n            job_def_manager = engine.job_def_manager\n            if not isinstance(job_def_manager, JobDefManagerSpec):\n                raise TypeError(\n                    f\"job_def_manager in engine is not of type JobDefManagerSpec, but got {type(job_def_manager)}\"\n                )\n            with engine.new_context() as fl_ctx:\n                job_data = job_def_manager.get_job_data(job_id, fl_ctx)\n                size = get_size(job_data, seen=None)\n                if size > MAX_DOWNLOAD_JOB__SIZE:\n                    conn.append_string(ConnProps.DOWNLOAD_JOB_URL + self.download_url + job_id)\n                    return\n\n                self._unzip_data(job_data, job_id)\n        except Exception as e:\n            conn.append_error(\"Exception occurred trying to get job from store: \" + str(e))\n            return\n        try:\n            data = zip_directory_to_bytes(self.download_dir, job_id)\n            b64str = bytes_to_b64str(data)\n            conn.append_string(b64str)\n        except BaseException:\n            traceback.print_exc()\n            conn.append_error(\"Exception occurred during attempt to zip data to send for job: {}\".format(job_id))",
  "def _unzip_data(self, job_data, job_id):\n        job_id_dir = os.path.join(self.download_dir, job_id)\n        if os.path.exists(job_id_dir):\n            shutil.rmtree(job_id_dir)\n        os.mkdir(job_id_dir)\n\n        data_bytes = job_data[JobDataKey.JOB_DATA.value]\n        job_dir = os.path.join(job_id_dir, \"job\")\n        os.mkdir(job_dir)\n        unzip_all_from_bytes(data_bytes, job_dir)\n\n        workspace_bytes = job_data[JobDataKey.WORKSPACE_DATA.value]\n        workspace_dir = os.path.join(job_id_dir, \"workspace\")\n        os.mkdir(workspace_dir)\n        if workspace_bytes is not None:\n            unzip_all_from_bytes(workspace_bytes, workspace_dir)",
  "def info(self, conn: Connection, args: List[str]):\n        conn.append_string(\"Server Upload Destination: {}\".format(self.upload_dir))\n        conn.append_string(\"Server Download Source: {}\".format(self.download_dir))",
  "def _authorize_submission(self, conn: Connection, args: List[str]):\n\n        folder_name = args[1]\n        zip_b64str = args[2]\n        data_bytes = convert_legacy_zip(b64str_to_bytes(zip_b64str))\n        conn.set_prop(ConnProps.JOB_DATA, data_bytes)\n\n        meta_file = f\"{folder_name}/{META_FILE}\"\n        with ZipFile(BytesIO(data_bytes), \"r\") as zf:\n            meta_data = zf.read(meta_file)\n            meta = json.loads(meta_data)\n        conn.set_prop(ConnProps.JOB_META, meta)\n\n        return self.authorize_job_meta(conn, meta, [Action.TRAIN])",
  "class Session(object):\n    def __init__(self):\n        \"\"\"Object keeping track of an admin client session with token and time data.\"\"\"\n        self.user_name = None\n        self.start_time = None\n        self.last_active_time = None\n        self.token = None\n\n    def mark_active(self):\n        self.last_active_time = time.time()",
  "class SessionManager(CommandModule):\n    def __init__(self, idle_timeout=3600, monitor_interval=5):\n        \"\"\"Session manager.\n\n        Args:\n            idle_timeout: session idle timeout\n            monitor_interval: interval for obtaining updates when monitoring\n        \"\"\"\n        if monitor_interval <= 0:\n            monitor_interval = 5\n\n        self.sess_update_lock = threading.Lock()\n        self.sessions = {}  # token => Session\n        self.idle_timeout = idle_timeout\n        self.monitor_interval = monitor_interval\n        self.asked_to_stop = False\n        self.monitor = threading.Thread(target=self.monitor_sessions)\n        self.monitor.start()\n\n    def monitor_sessions(self):\n        \"\"\"Runs loop in a thread to end sessions that time out.\"\"\"\n        while True:\n            # print('checking for dead sessions ...')\n            if self.asked_to_stop:\n                break\n\n            dead_sess = None\n            for _, sess in self.sessions.items():\n                time_passed = time.time() - sess.last_active_time\n                # print('time passed: {} secs'.format(time_passed))\n                if time_passed > self.idle_timeout:\n                    dead_sess = sess\n                    break\n\n            if dead_sess:\n                # print('ending dead session {}'.format(dead_sess.token))\n                self.end_session(dead_sess.token)\n            else:\n                # print('no dead sessions found')\n                pass\n\n            time.sleep(self.monitor_interval)\n\n    def shutdown(self):\n        self.asked_to_stop = True\n        self.monitor.join(timeout=10)\n\n    def create_session(self, user_name):\n        \"\"\"Creates new session with a new session token.\n\n        Args:\n            user_name: user name for session\n\n        Returns: Session\n\n        \"\"\"\n        token = make_session_token()\n        sess = Session()\n        sess.user_name = user_name\n        sess.start_time = time.time()\n        sess.last_active_time = sess.start_time\n        sess.token = token\n        with self.sess_update_lock:\n            self.sessions[token] = sess\n        return sess\n\n    def get_session(self, token: str):\n        with self.sess_update_lock:\n            return self.sessions.get(token)\n\n    def get_sessions(self):\n        result = []\n        with self.sess_update_lock:\n            for _, s in self.sessions.items():\n                result.append(s)\n        return result\n\n    def end_session(self, token):\n        with self.sess_update_lock:\n            self.sessions.pop(token, None)\n\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=\"sess\",\n            cmd_specs=[\n                CommandSpec(\n                    name=LIST_SESSIONS_CMD_NAME,\n                    description=\"list user sessions\",\n                    usage=\"list_sessions\",\n                    handler_func=self.handle_list_sessions,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=CHECK_SESSION_CMD_NAME,\n                    description=\"check if session is active\",\n                    usage=\"check_session\",\n                    handler_func=self.handle_check_session,\n                    visible=False,\n                ),\n            ],\n        )\n\n    def handle_list_sessions(self, conn: Connection, args: List[str]):\n        \"\"\"Lists sessions and the details in a table.\n\n        Registered in the FedAdminServer with ``cmd_reg.register_module(sess_mgr)``.\n        \"\"\"\n        with self.sess_update_lock:\n            sess_list = list(self.sessions.values())\n        sess_list.sort(key=lambda x: x.user_name, reverse=False)\n        table = conn.append_table([\"User\", \"Session ID\", \"Start\", \"Last Active\", \"Idle\"])\n        for s in sess_list:\n            table.add_row(\n                [\n                    s.user_name,\n                    \"{}\".format(s.token),\n                    time_to_string(s.start_time),\n                    time_to_string(s.last_active_time),\n                    \"{}\".format(time.time() - s.last_active_time),\n                ]\n            )\n\n    def handle_check_session(self, conn: Connection, args: List[str]):\n        token = None\n        data = conn.request[\"data\"]\n        for item in data:\n            it = item[\"type\"]\n            if it == \"token\":\n                token = item[\"data\"]\n                break\n\n        sess = self.get_session(token)\n        if sess:\n            conn.append_string(\"OK\")\n        else:\n            conn.append_error(\"session_inactive\")\n            conn.append_string(\n                \"admin client session timed out after {} seconds of inactivity - logging out\".format(self.idle_timeout)\n            )",
  "def __init__(self):\n        \"\"\"Object keeping track of an admin client session with token and time data.\"\"\"\n        self.user_name = None\n        self.start_time = None\n        self.last_active_time = None\n        self.token = None",
  "def mark_active(self):\n        self.last_active_time = time.time()",
  "def __init__(self, idle_timeout=3600, monitor_interval=5):\n        \"\"\"Session manager.\n\n        Args:\n            idle_timeout: session idle timeout\n            monitor_interval: interval for obtaining updates when monitoring\n        \"\"\"\n        if monitor_interval <= 0:\n            monitor_interval = 5\n\n        self.sess_update_lock = threading.Lock()\n        self.sessions = {}  # token => Session\n        self.idle_timeout = idle_timeout\n        self.monitor_interval = monitor_interval\n        self.asked_to_stop = False\n        self.monitor = threading.Thread(target=self.monitor_sessions)\n        self.monitor.start()",
  "def monitor_sessions(self):\n        \"\"\"Runs loop in a thread to end sessions that time out.\"\"\"\n        while True:\n            # print('checking for dead sessions ...')\n            if self.asked_to_stop:\n                break\n\n            dead_sess = None\n            for _, sess in self.sessions.items():\n                time_passed = time.time() - sess.last_active_time\n                # print('time passed: {} secs'.format(time_passed))\n                if time_passed > self.idle_timeout:\n                    dead_sess = sess\n                    break\n\n            if dead_sess:\n                # print('ending dead session {}'.format(dead_sess.token))\n                self.end_session(dead_sess.token)\n            else:\n                # print('no dead sessions found')\n                pass\n\n            time.sleep(self.monitor_interval)",
  "def shutdown(self):\n        self.asked_to_stop = True\n        self.monitor.join(timeout=10)",
  "def create_session(self, user_name):\n        \"\"\"Creates new session with a new session token.\n\n        Args:\n            user_name: user name for session\n\n        Returns: Session\n\n        \"\"\"\n        token = make_session_token()\n        sess = Session()\n        sess.user_name = user_name\n        sess.start_time = time.time()\n        sess.last_active_time = sess.start_time\n        sess.token = token\n        with self.sess_update_lock:\n            self.sessions[token] = sess\n        return sess",
  "def get_session(self, token: str):\n        with self.sess_update_lock:\n            return self.sessions.get(token)",
  "def get_sessions(self):\n        result = []\n        with self.sess_update_lock:\n            for _, s in self.sessions.items():\n                result.append(s)\n        return result",
  "def end_session(self, token):\n        with self.sess_update_lock:\n            self.sessions.pop(token, None)",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=\"sess\",\n            cmd_specs=[\n                CommandSpec(\n                    name=LIST_SESSIONS_CMD_NAME,\n                    description=\"list user sessions\",\n                    usage=\"list_sessions\",\n                    handler_func=self.handle_list_sessions,\n                    visible=True,\n                ),\n                CommandSpec(\n                    name=CHECK_SESSION_CMD_NAME,\n                    description=\"check if session is active\",\n                    usage=\"check_session\",\n                    handler_func=self.handle_check_session,\n                    visible=False,\n                ),\n            ],\n        )",
  "def handle_list_sessions(self, conn: Connection, args: List[str]):\n        \"\"\"Lists sessions and the details in a table.\n\n        Registered in the FedAdminServer with ``cmd_reg.register_module(sess_mgr)``.\n        \"\"\"\n        with self.sess_update_lock:\n            sess_list = list(self.sessions.values())\n        sess_list.sort(key=lambda x: x.user_name, reverse=False)\n        table = conn.append_table([\"User\", \"Session ID\", \"Start\", \"Last Active\", \"Idle\"])\n        for s in sess_list:\n            table.add_row(\n                [\n                    s.user_name,\n                    \"{}\".format(s.token),\n                    time_to_string(s.start_time),\n                    time_to_string(s.last_active_time),\n                    \"{}\".format(time.time() - s.last_active_time),\n                ]\n            )",
  "def handle_check_session(self, conn: Connection, args: List[str]):\n        token = None\n        data = conn.request[\"data\"]\n        for item in data:\n            it = item[\"type\"]\n            if it == \"token\":\n                token = item[\"data\"]\n                break\n\n        sess = self.get_session(token)\n        if sess:\n            conn.append_string(\"OK\")\n        else:\n            conn.append_error(\"session_inactive\")\n            conn.append_string(\n                \"admin client session timed out after {} seconds of inactivity - logging out\".format(self.idle_timeout)\n            )",
  "class CommandAudit(CommandFilter):\n    def __init__(self, auditor: Auditor):\n        \"\"\"Command filter for auditing by adding events.\n\n        This filter needs to be registered after the login filter because it needs the username established\n        by the login filter.\n\n        Args:\n            auditor: instance of Auditor\n        \"\"\"\n        CommandFilter.__init__(self)\n        assert isinstance(auditor, Auditor), \"auditor must be Auditor but got {}\".format(type(auditor))\n        self.auditor = auditor\n\n    def pre_command(self, conn: Connection, args: List[str]):\n        user_name = conn.get_prop(ConnProps.USER_NAME, \"?\")\n\n        event_id = self.auditor.add_event(\n            user=user_name,\n            action=conn.command[:100],  # at most 100 chars\n        )\n\n        conn.set_prop(ConnProps.EVENT_ID, event_id)\n        return True",
  "def __init__(self, auditor: Auditor):\n        \"\"\"Command filter for auditing by adding events.\n\n        This filter needs to be registered after the login filter because it needs the username established\n        by the login filter.\n\n        Args:\n            auditor: instance of Auditor\n        \"\"\"\n        CommandFilter.__init__(self)\n        assert isinstance(auditor, Auditor), \"auditor must be Auditor but got {}\".format(type(auditor))\n        self.auditor = auditor",
  "def pre_command(self, conn: Connection, args: List[str]):\n        user_name = conn.get_prop(ConnProps.USER_NAME, \"?\")\n\n        event_id = self.auditor.add_event(\n            user=user_name,\n            action=conn.command[:100],  # at most 100 chars\n        )\n\n        conn.set_prop(ConnProps.EVENT_ID, event_id)\n        return True",
  "class CommandFilter(object):\n    \"\"\"Base class for filters to run before or after commands.\"\"\"\n\n    def pre_command(self, conn: Connection, args: List[str]) -> bool:\n        \"\"\"Code to execute before executing a command.\n\n        Returns: True to continue filter chain or False to not\n        \"\"\"\n        return True\n\n    def post_command(self, conn: Connection, args: List[str]) -> bool:\n        \"\"\"Code to execute after executing a command.\"\"\"\n        pass\n\n    def close(self):\n        pass",
  "class ServerCommandRegister(CommandRegister):\n    def __init__(self, app_ctx):\n        \"\"\"Runs filters and executes commands by calling their handler function.\n\n        This is the main command register used by AdminServer.\n\n        Args:\n            app_ctx: app context\n        \"\"\"\n        CommandRegister.__init__(self, app_ctx)\n        self.filters = []\n        self.closed = False\n\n    def add_filter(self, cmd_filter: CommandFilter):\n        assert isinstance(cmd_filter, CommandFilter), \"cmd_filter must be CommandFilter but got {}.\".format(\n            type(cmd_filter)\n        )\n        self.filters.append(cmd_filter)\n\n    def _do_command(self, conn: Connection, command: str):\n        \"\"\"Executes command.\n\n        Getting the command from the command registry, invoke filters and call the handler function, passing along conn\n        and the args split from the command.\n        \"\"\"\n        conn.app_ctx = self.app_ctx\n        args = split_to_args(command)\n        conn.args = args\n        conn.command = command\n\n        cmd_name = args[0]\n        entries = self.get_command_entries(cmd_name)\n        if len(entries) <= 0:\n            conn.append_error('Unknown command \"{}\"'.format(cmd_name))\n            return\n        elif len(entries) == 1:\n            conn.set_prop(ConnProps.CMD_ENTRY, entries[0])\n            handler = entries[0].handler\n        else:\n            conn.append_error('Command \"{}\" exists in multiple scopes. Please use full command name'.format(cmd_name))\n            return\n\n        if handler is None:\n            conn.append_error('Unknown command \"{}\"'.format(cmd_name))\n            return\n\n        # invoke pre filters\n        if len(self.filters) > 0:\n            for f in self.filters:\n                ok = f.pre_command(conn, args)\n                if not ok:\n                    return\n\n        if handler is not None:\n            handler(conn, args)\n        else:\n            conn.append_error('Unknown command \"{}\"'.format(command))\n            return\n\n        # invoke post filters\n        if len(self.filters) > 0:\n            for f in self.filters:\n                f.post_command(conn, args)\n\n    def process_command(self, conn: Connection, command: str):\n        try:\n            self._do_command(conn, command)\n        except BaseException as e:\n            traceback.print_exc()\n            conn.append_error(f\"Exception Occurred: {e}\")\n\n    def close(self):\n        if self.closed:\n            return\n\n        for f in self.filters:\n            f.close()\n\n        for m in self.modules:\n            m.close()\n\n        self.closed = True",
  "def pre_command(self, conn: Connection, args: List[str]) -> bool:\n        \"\"\"Code to execute before executing a command.\n\n        Returns: True to continue filter chain or False to not\n        \"\"\"\n        return True",
  "def post_command(self, conn: Connection, args: List[str]) -> bool:\n        \"\"\"Code to execute after executing a command.\"\"\"\n        pass",
  "def close(self):\n        pass",
  "def __init__(self, app_ctx):\n        \"\"\"Runs filters and executes commands by calling their handler function.\n\n        This is the main command register used by AdminServer.\n\n        Args:\n            app_ctx: app context\n        \"\"\"\n        CommandRegister.__init__(self, app_ctx)\n        self.filters = []\n        self.closed = False",
  "def add_filter(self, cmd_filter: CommandFilter):\n        assert isinstance(cmd_filter, CommandFilter), \"cmd_filter must be CommandFilter but got {}.\".format(\n            type(cmd_filter)\n        )\n        self.filters.append(cmd_filter)",
  "def _do_command(self, conn: Connection, command: str):\n        \"\"\"Executes command.\n\n        Getting the command from the command registry, invoke filters and call the handler function, passing along conn\n        and the args split from the command.\n        \"\"\"\n        conn.app_ctx = self.app_ctx\n        args = split_to_args(command)\n        conn.args = args\n        conn.command = command\n\n        cmd_name = args[0]\n        entries = self.get_command_entries(cmd_name)\n        if len(entries) <= 0:\n            conn.append_error('Unknown command \"{}\"'.format(cmd_name))\n            return\n        elif len(entries) == 1:\n            conn.set_prop(ConnProps.CMD_ENTRY, entries[0])\n            handler = entries[0].handler\n        else:\n            conn.append_error('Command \"{}\" exists in multiple scopes. Please use full command name'.format(cmd_name))\n            return\n\n        if handler is None:\n            conn.append_error('Unknown command \"{}\"'.format(cmd_name))\n            return\n\n        # invoke pre filters\n        if len(self.filters) > 0:\n            for f in self.filters:\n                ok = f.pre_command(conn, args)\n                if not ok:\n                    return\n\n        if handler is not None:\n            handler(conn, args)\n        else:\n            conn.append_error('Unknown command \"{}\"'.format(command))\n            return\n\n        # invoke post filters\n        if len(self.filters) > 0:\n            for f in self.filters:\n                f.post_command(conn, args)",
  "def process_command(self, conn: Connection, command: str):\n        try:\n            self._do_command(conn, command)\n        except BaseException as e:\n            traceback.print_exc()\n            conn.append_error(f\"Exception Occurred: {e}\")",
  "def close(self):\n        if self.closed:\n            return\n\n        for f in self.filters:\n            f.close()\n\n        for m in self.modules:\n            m.close()\n\n        self.closed = True",
  "class _MsgHandler(socketserver.BaseRequestHandler):\n    \"\"\"Message handler.\n\n    Used by the AdminServer to receive admin commands, validate, then process and do command through the\n    ServerCommandRegister.\n    \"\"\"\n\n    connections = 0\n    lock = threading.Lock()\n\n    def __init__(self, request, client_address, server):\n        # handle() is called in the constructor so logger must be initialized first\n        self.logger = logging.getLogger(self.__class__.__name__)\n        super().__init__(request, client_address, server)\n\n    def handle(self):\n        try:\n            with _MsgHandler.lock:\n                _MsgHandler.connections += 1\n\n            self.logger.debug(f\"Concurrent admin connections: {_MsgHandler.connections}\")\n            if _MsgHandler.connections > MAX_ADMIN_CONNECTIONS:\n                raise ConnectionRefusedError(f\"Admin connection limit ({MAX_ADMIN_CONNECTIONS}) reached\")\n\n            conn = Connection(self.request, self.server)\n\n            if self.server.use_ssl:\n                cn = get_certificate_common_name(self.request.getpeercert())\n                conn.set_prop(\"_client_cn\", cn)\n                valid = self.server.validate_client_cn(cn)\n            else:\n                valid = True\n\n            if not valid:\n                conn.append_error(\"authentication error\")\n            else:\n                req = receive_til_end(self.request).strip()\n                command = None\n                req_json = validate_proto(req)\n                conn.request = req_json\n                if req_json is not None:\n                    data = req_json[\"data\"]\n                    for item in data:\n                        it = item[\"type\"]\n                        if it == \"command\":\n                            command = item[\"data\"]\n                            break\n\n                    if command is None:\n                        conn.append_error(\"protocol violation\")\n                    else:\n                        self.server.cmd_reg.process_command(conn, command)\n                else:\n                    # not json encoded\n                    conn.append_error(\"protocol violation\")\n\n            if not conn.ended:\n                conn.close()\n        except BaseException as exc:\n            self.logger.error(f\"Admin connection terminated due to exception: {str(exc)}\")\n            if self.logger.getEffectiveLevel() <= logging.DEBUG:\n                self.logger.exception(\"Admin connection error\")\n        finally:\n            with _MsgHandler.lock:\n                _MsgHandler.connections -= 1",
  "def initialize_hci():\n    socketserver.TCPServer.allow_reuse_address = True",
  "class AdminServer(socketserver.ThreadingTCPServer):\n    # faster re-binding\n    allow_reuse_address = True\n\n    # make this bigger than five\n    request_queue_size = 10\n\n    # kick connections when we exit\n    daemon_threads = True\n\n    def __init__(\n        self,\n        cmd_reg: ServerCommandRegister,\n        host,\n        port,\n        ca_cert=None,\n        server_cert=None,\n        server_key=None,\n        accepted_client_cns=None,\n    ):\n        \"\"\"Base class of FedAdminServer to create a server that can receive commands.\n\n        Args:\n            cmd_reg: CommandRegister\n            host: the IP address of the admin server\n            port: port number of admin server\n            ca_cert: the root CA's cert file name\n            server_cert: server's cert, signed by the CA\n            server_key: server's private key file\n            accepted_client_cns: list of accepted Common Names from client, if specified\n        \"\"\"\n        socketserver.TCPServer.__init__(self, (host, port), _MsgHandler, False)\n\n        self.use_ssl = False\n        if ca_cert and server_cert:\n            if accepted_client_cns:\n                assert isinstance(accepted_client_cns, list), \"accepted_client_cns must be list but got {}.\".format(\n                    accepted_client_cns\n                )\n\n            ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n            ctx.verify_mode = ssl.CERT_REQUIRED\n            ctx.load_verify_locations(ca_cert)\n            ctx.load_cert_chain(certfile=server_cert, keyfile=server_key)\n\n            # replace the socket with an SSL version of itself\n            self.socket = ctx.wrap_socket(self.socket, server_side=True)\n            self.use_ssl = True\n\n        # bind the socket and start the server\n        self.server_bind()\n        self.server_activate()\n\n        self._thread = None\n        self.host = host\n        self.port = port\n        self.accepted_client_cns = accepted_client_cns\n        self.cmd_reg = cmd_reg\n        cmd_reg.finalize()\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    def validate_client_cn(self, cn):\n        if self.accepted_client_cns:\n            return cn in self.accepted_client_cns\n        else:\n            return True\n\n    def stop(self):\n        self.shutdown()\n        self.cmd_reg.close()\n\n        if self._thread.is_alive():\n            self._thread.join()\n\n        self.logger.info(f\"Admin Server {self.host} on Port {self.port} shutdown!\")\n\n    def set_command_registry(self, cmd_reg: ServerCommandRegister):\n        if cmd_reg:\n            cmd_reg.finalize()\n\n            if self.cmd_reg:\n                self.cmd_reg.close()\n\n            self.cmd_reg = cmd_reg\n\n    def start(self):\n        if self._thread is None:\n            self._thread = threading.Thread(target=self._run, args=())\n\n        if not self._thread.is_alive():\n            self._thread.start()\n\n    def _run(self):\n        self.logger.info(f\"Starting Admin Server {self.host} on Port {self.port}\")\n        self.serve_forever()",
  "def __init__(self, request, client_address, server):\n        # handle() is called in the constructor so logger must be initialized first\n        self.logger = logging.getLogger(self.__class__.__name__)\n        super().__init__(request, client_address, server)",
  "def handle(self):\n        try:\n            with _MsgHandler.lock:\n                _MsgHandler.connections += 1\n\n            self.logger.debug(f\"Concurrent admin connections: {_MsgHandler.connections}\")\n            if _MsgHandler.connections > MAX_ADMIN_CONNECTIONS:\n                raise ConnectionRefusedError(f\"Admin connection limit ({MAX_ADMIN_CONNECTIONS}) reached\")\n\n            conn = Connection(self.request, self.server)\n\n            if self.server.use_ssl:\n                cn = get_certificate_common_name(self.request.getpeercert())\n                conn.set_prop(\"_client_cn\", cn)\n                valid = self.server.validate_client_cn(cn)\n            else:\n                valid = True\n\n            if not valid:\n                conn.append_error(\"authentication error\")\n            else:\n                req = receive_til_end(self.request).strip()\n                command = None\n                req_json = validate_proto(req)\n                conn.request = req_json\n                if req_json is not None:\n                    data = req_json[\"data\"]\n                    for item in data:\n                        it = item[\"type\"]\n                        if it == \"command\":\n                            command = item[\"data\"]\n                            break\n\n                    if command is None:\n                        conn.append_error(\"protocol violation\")\n                    else:\n                        self.server.cmd_reg.process_command(conn, command)\n                else:\n                    # not json encoded\n                    conn.append_error(\"protocol violation\")\n\n            if not conn.ended:\n                conn.close()\n        except BaseException as exc:\n            self.logger.error(f\"Admin connection terminated due to exception: {str(exc)}\")\n            if self.logger.getEffectiveLevel() <= logging.DEBUG:\n                self.logger.exception(\"Admin connection error\")\n        finally:\n            with _MsgHandler.lock:\n                _MsgHandler.connections -= 1",
  "def __init__(\n        self,\n        cmd_reg: ServerCommandRegister,\n        host,\n        port,\n        ca_cert=None,\n        server_cert=None,\n        server_key=None,\n        accepted_client_cns=None,\n    ):\n        \"\"\"Base class of FedAdminServer to create a server that can receive commands.\n\n        Args:\n            cmd_reg: CommandRegister\n            host: the IP address of the admin server\n            port: port number of admin server\n            ca_cert: the root CA's cert file name\n            server_cert: server's cert, signed by the CA\n            server_key: server's private key file\n            accepted_client_cns: list of accepted Common Names from client, if specified\n        \"\"\"\n        socketserver.TCPServer.__init__(self, (host, port), _MsgHandler, False)\n\n        self.use_ssl = False\n        if ca_cert and server_cert:\n            if accepted_client_cns:\n                assert isinstance(accepted_client_cns, list), \"accepted_client_cns must be list but got {}.\".format(\n                    accepted_client_cns\n                )\n\n            ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n            ctx.verify_mode = ssl.CERT_REQUIRED\n            ctx.load_verify_locations(ca_cert)\n            ctx.load_cert_chain(certfile=server_cert, keyfile=server_key)\n\n            # replace the socket with an SSL version of itself\n            self.socket = ctx.wrap_socket(self.socket, server_side=True)\n            self.use_ssl = True\n\n        # bind the socket and start the server\n        self.server_bind()\n        self.server_activate()\n\n        self._thread = None\n        self.host = host\n        self.port = port\n        self.accepted_client_cns = accepted_client_cns\n        self.cmd_reg = cmd_reg\n        cmd_reg.finalize()\n        self.logger = logging.getLogger(self.__class__.__name__)",
  "def validate_client_cn(self, cn):\n        if self.accepted_client_cns:\n            return cn in self.accepted_client_cns\n        else:\n            return True",
  "def stop(self):\n        self.shutdown()\n        self.cmd_reg.close()\n\n        if self._thread.is_alive():\n            self._thread.join()\n\n        self.logger.info(f\"Admin Server {self.host} on Port {self.port} shutdown!\")",
  "def set_command_registry(self, cmd_reg: ServerCommandRegister):\n        if cmd_reg:\n            cmd_reg.finalize()\n\n            if self.cmd_reg:\n                self.cmd_reg.close()\n\n            self.cmd_reg = cmd_reg",
  "def start(self):\n        if self._thread is None:\n            self._thread = threading.Thread(target=self._run, args=())\n\n        if not self._thread.is_alive():\n            self._thread.start()",
  "def _run(self):\n        self.logger.info(f\"Starting Admin Server {self.host} on Port {self.port}\")\n        self.serve_forever()",
  "class BuiltInCmdModule(CommandModule):\n    def __init__(self, reg: ServerCommandRegister):\n        \"\"\"Built in CommandModule with the ability to list commands.\n\n        Args:\n            reg: ServerCommandRegister\n        \"\"\"\n        self.reg = reg\n\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=\"\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"_commands\",\n                    description=\"list server commands\",\n                    usage=\"_commands\",\n                    handler_func=self.handle_list_commands,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=\"echo\",\n                    description=\"echo user input back to client\",\n                    usage=\"echo args ...\",\n                    handler_func=self.handle_echo,\n                    visible=False,\n                ),\n            ],\n        )\n\n    def _show_command(self, conn: Connection, cmd_name):\n        entries = self.reg.get_command_entries(cmd_name)\n        if len(entries) <= 0:\n            conn.append_error(\"undefined command {}\\n\".format(cmd_name))\n            return\n\n        for e in entries:\n            if not e.visible:\n                continue\n\n            if len(e.scope.name) > 0:\n                conn.append_string(\"Command: {}.{}\".format(e.scope.name, cmd_name))\n            else:\n                conn.append_string(\"Command: {}\".format(cmd_name))\n\n            conn.append_string(\"Description: {}\".format(e.desc))\n            conn.append_string(\"Usage: {}\\n\".format(e.usage))\n\n    def handle_list_commands(self, conn: Connection, args: List[str]):\n        if len(args) <= 1:\n            table = conn.append_table([\"Scope\", \"Command\", \"Description\", \"Usage\", \"Confirm\"])\n            for scope_name in sorted(self.reg.scopes):\n                scope = self.reg.scopes[scope_name]\n                for cmd_name in sorted(scope.entries):\n                    e = scope.entries[cmd_name]\n                    if e.visible:\n                        table.add_row([scope_name, cmd_name, e.desc, e.usage, e.confirm])\n        else:\n            for cmd_name in args[1:]:\n                self._show_command(conn, cmd_name)\n\n    def handle_echo(self, conn: Connection, args: List[str]):\n        for a in args:\n            conn.append_string(a)",
  "def new_command_register_with_builtin_module(app_ctx):\n    \"\"\"Creates ServerCommandRegister and registers builtin command module.\n\n    Args:\n        app_ctx: engine\n\n    Returns: ServerCommandRegister\n\n    \"\"\"\n    reg = ServerCommandRegister(app_ctx=app_ctx)\n    reg.register_module(BuiltInCmdModule(reg))\n    return reg",
  "def __init__(self, reg: ServerCommandRegister):\n        \"\"\"Built in CommandModule with the ability to list commands.\n\n        Args:\n            reg: ServerCommandRegister\n        \"\"\"\n        self.reg = reg",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=\"\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"_commands\",\n                    description=\"list server commands\",\n                    usage=\"_commands\",\n                    handler_func=self.handle_list_commands,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=\"echo\",\n                    description=\"echo user input back to client\",\n                    usage=\"echo args ...\",\n                    handler_func=self.handle_echo,\n                    visible=False,\n                ),\n            ],\n        )",
  "def _show_command(self, conn: Connection, cmd_name):\n        entries = self.reg.get_command_entries(cmd_name)\n        if len(entries) <= 0:\n            conn.append_error(\"undefined command {}\\n\".format(cmd_name))\n            return\n\n        for e in entries:\n            if not e.visible:\n                continue\n\n            if len(e.scope.name) > 0:\n                conn.append_string(\"Command: {}.{}\".format(e.scope.name, cmd_name))\n            else:\n                conn.append_string(\"Command: {}\".format(cmd_name))\n\n            conn.append_string(\"Description: {}\".format(e.desc))\n            conn.append_string(\"Usage: {}\\n\".format(e.usage))",
  "def handle_list_commands(self, conn: Connection, args: List[str]):\n        if len(args) <= 1:\n            table = conn.append_table([\"Scope\", \"Command\", \"Description\", \"Usage\", \"Confirm\"])\n            for scope_name in sorted(self.reg.scopes):\n                scope = self.reg.scopes[scope_name]\n                for cmd_name in sorted(scope.entries):\n                    e = scope.entries[cmd_name]\n                    if e.visible:\n                        table.add_row([scope_name, cmd_name, e.desc, e.usage, e.confirm])\n        else:\n            for cmd_name in args[1:]:\n                self._show_command(conn, cmd_name)",
  "def handle_echo(self, conn: Connection, args: List[str]):\n        for a in args:\n            conn.append_string(a)",
  "def main():\n    \"\"\"\n    Script to launch the admin client to issue admin commands to the server.\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--workspace\", \"-m\", type=str, help=\"WORKSPACE folder\", required=True)\n\n    parser.add_argument(\n        \"--fed_admin\", \"-s\", type=str, help=\"json file with configurations for launching admin client\", required=True\n    )\n    parser.add_argument(\"--cli_history_size\", type=int, default=1000)\n    parser.add_argument(\"--with_debug\", action=\"store_true\")\n\n    args = parser.parse_args()\n\n    try:\n        os.chdir(args.workspace)\n        workspace = os.path.join(args.workspace, \"startup\")\n        conf = FLAdminClientStarterConfigurator(app_root=workspace, admin_config_file_name=args.fed_admin)\n        conf.configure()\n    except ConfigError as ex:\n        print(\"ConfigError:\", str(ex))\n\n    try:\n        admin_config = conf.config_data[\"admin\"]\n    except KeyError:\n        print(\"Missing admin section in fed_admin configuration.\")\n\n    modules = []\n\n    if admin_config.get(\"with_file_transfer\"):\n        modules.append(\n            FileTransferModule(upload_dir=admin_config.get(\"upload_dir\"), download_dir=admin_config.get(\"download_dir\"))\n        )\n\n    ca_cert = admin_config.get(\"ca_cert\", \"\")\n    client_cert = admin_config.get(\"client_cert\", \"\")\n    client_key = admin_config.get(\"client_key\", \"\")\n\n    if admin_config.get(\"with_ssl\"):\n        if len(ca_cert) <= 0:\n            print(\"missing CA Cert file name field ca_cert in fed_admin configuration\")\n            return\n\n        if len(client_cert) <= 0:\n            print(\"missing Client Cert file name field client_cert in fed_admin configuration\")\n            return\n\n        if len(client_key) <= 0:\n            print(\"missing Client Key file name field client_key in fed_admin configuration\")\n            return\n    else:\n        ca_cert = None\n        client_key = None\n        client_cert = None\n\n    if args.with_debug:\n        print(\"SSL: {}\".format(admin_config.get(\"with_ssl\")))\n        print(\"File Transfer: {}\".format(admin_config.get(\"with_file_transfer\")))\n\n        if admin_config.get(\"with_file_transfer\"):\n            print(\"  Upload Dir: {}\".format(admin_config.get(\"upload_dir\")))\n            print(\"  Download Dir: {}\".format(admin_config.get(\"download_dir\")))\n\n    client = AdminClient(\n        prompt=admin_config.get(\"prompt\", \"> \"),\n        cmd_modules=modules,\n        ca_cert=ca_cert,\n        client_cert=client_cert,\n        client_key=client_key,\n        upload_dir=admin_config.get(\"upload_dir\"),\n        download_dir=admin_config.get(\"download_dir\"),\n        require_login=admin_config.get(\"with_login\", True),\n        credential_type=CredentialType.PASSWORD if admin_config.get(\"cred_type\") == \"password\" else CredentialType.CERT,\n        debug=args.with_debug,\n        overseer_agent=conf.overseer_agent,\n        # cli_history_size=args.cli_history_size,\n    )\n\n    client.run()",
  "class Commander(cmd.Cmd):\n    def __init__(self, policy: Policy):\n        \"\"\"Command line prompt helper tool for getting information for authorization configurations.\n\n        Args:\n            policy: authorization policy object\n        \"\"\"\n        cmd.Cmd.__init__(self)\n        self.policy = policy\n        self.intro = \"Type help or ? to list commands.\\n\"\n        self.prompt = \">\"\n\n    def do_bye(self, arg):\n        \"\"\"Exits from the client.\"\"\"\n        return True\n\n    def emptyline(self):\n        return\n\n    def do_show_users(self, arg):\n        users = self.policy.get_users()\n        table = Table([\"user\", \"org\", \"roles\"])\n        for user_name, user_def in users.items():\n            table.add_row([user_name, user_def[\"org\"], \",\".join(user_def[\"roles\"])])\n        self.write_table(table)\n\n    def _split_to_args(self, arg):\n        if len(arg) <= 0:\n            return []\n        else:\n            return split_to_args(arg)\n\n    def do_show_sites(self, arg):\n        sites = self.policy.get_sites()\n        table = Table([\"site\", \"org\"])\n        for site_name, org in sites.items():\n            table.add_row([site_name, org])\n        self.write_table(table)\n\n    def do_show_rights(self, arg):\n        rights = self.policy.get_rights()\n        table = Table([\"name\", \"description\", \"default\"])\n        for name, right_def in rights.items():\n            desc = right_def.get(\"desc\", \"\")\n            default = right_def.get(\"default\", \"\")\n            table.add_row([name, desc, \"{}\".format(default)])\n        self.write_table(table)\n\n    def do_show_rules(self, arg):\n        rules = self.policy.get_rules()\n        table = Table([\"name\", \"description\", \"default\"])\n        for name, rule_def in rules.items():\n            desc = rule_def.get(\"desc\", \"\")\n            default = rule_def.get(\"default\", \"\")\n            table.add_row([name, desc, \"{}\".format(default)])\n        self.write_table(table)\n\n    def do_show_config(self, arg):\n        config = self.policy.get_config()\n        self.write_string(json.dumps(config, indent=1))\n\n    def do_show_site_rules(self, arg):\n        args = [\"show_site_rules\"] + self._split_to_args(arg)\n        if len(args) != 2:\n            self.write_string(\"Usage: {} site_name\".format(args[0]))\n            return\n\n        site_name = args[1]\n        rules = self.policy.get_rules()\n        table = Table([\"Rule\", \"Result\"])\n        for rule_name, _ in rules.items():\n            result, err = self._eval_rule(site_name, rule_name)\n            if err:\n                self.write_error(err)\n                return\n            else:\n                table.add_row([rule_name, result])\n        self.write_table(table)\n\n    def _eval_right(self, user_name, right_name, site_name):\n        result, err = self.policy.evaluate_user_right_on_site(\n            user_name=user_name, site_name=site_name, right_name=right_name\n        )\n        if err:\n            return result, err\n        if result is None:\n            rights = self.policy.get_rights()\n            right_def = rights[right_name]\n            return \"({})\".format(right_def.get(\"default\", \"?\")), \"\"\n        else:\n            return \"{}\".format(result), \"\"\n\n    def do_eval_right(self, arg):\n        args = [\"eval_right\"] + self._split_to_args(arg)\n        if len(args) != 4:\n            self.write_string(\"Usage: {} user_name right_name site_name\".format(args[0]))\n            return\n\n        user_name = args[1]\n        right_name = args[2]\n        site_name = args[3]\n        result, err = self._eval_right(user_name=user_name, site_name=site_name, right_name=right_name)\n        if err:\n            self.write_error(err)\n        else:\n            self.write_string(result)\n\n    def do_eval_user(self, arg):\n        args = [\"eval_user\"] + self._split_to_args(arg)\n        if len(args) != 3:\n            self.write_string(\"Usage: {} user_name site_name\".format(args[0]))\n            return\n\n        user_name = args[1]\n        site_name = args[2]\n        table = Table([\"Right\", \"Result\"])\n        rights = self.policy.get_rights()\n        for right_name, right_def in rights.items():\n            result, err = self._eval_right(user_name=user_name, site_name=site_name, right_name=right_name)\n            if err:\n                self.write_error(err)\n                return\n            else:\n                table.add_row([right_name, result])\n        self.write_table(table)\n\n    def _eval_rule(self, site_name, rule_name):\n        result, err = self.policy.evaluate_rule_on_site(site_name=site_name, rule_name=rule_name)\n        if err:\n            return result, err\n\n        if result is None:\n            rules = self.policy.get_rules()\n            rule_def = rules[rule_name]\n            return \"({})\".format(rule_def.get(\"default\", \"?\")), \"\"\n        else:\n            return \"{}\".format(result), \"\"\n\n    def do_eval_rule(self, arg):\n        args = [\"eval_rule\"] + self._split_to_args(arg)\n        if len(args) != 3:\n            self.write_string(\"Usage: {} site_name rule_name\".format(args[0]))\n            return\n\n        site_name = args[1]\n        rule_name = args[2]\n        result, err = self._eval_rule(site_name=site_name, rule_name=rule_name)\n        if err:\n            self.write_error(err)\n        else:\n            self.write_string(result)\n\n    def write_string(self, data: str):\n        content = data + \"\\n\"\n        self.stdout.write(content)\n\n    def write_table(self, table: Table):\n        table.write(self.stdout)\n\n    def write_error(self, err: str):\n        content = \"Error: \" + err + \"\\n\"\n        self.stdout.write(content)",
  "def main():\n    \"\"\"Tool to help preview and see the details of an authorization policy with command line commands.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--policy\", \"-p\", type=str, help=\"authz policy file\", required=False, default=\"\")\n    parser.add_argument(\"--defs\", \"-d\", type=str, help=\"authz definition file\", required=False, default=\"\")\n    parser.add_argument(\"--config\", \"-c\", type=str, help=\"authz config file\", required=False, default=\"\")\n\n    args = parser.parse_args()\n\n    if args.policy:\n        with open(args.policy) as file:\n            config = json.load(file)\n            err = validate_policy_config(config)\n            if err:\n                print(\"Policy config error: {}\".format(err))\n                return\n    else:\n        assert args.defs, \"missing authz definition file\"\n        assert args.config, \"missing authz config file\"\n        with open(args.defs) as file:\n            defs = json.load(file)\n\n        with open(args.config) as file:\n            config = json.load(file)\n\n        config.update(defs)\n\n    commander = Commander(Policy(config))\n    commander.cmdloop(intro=\"Type help or ? to list commands.\")",
  "def __init__(self, policy: Policy):\n        \"\"\"Command line prompt helper tool for getting information for authorization configurations.\n\n        Args:\n            policy: authorization policy object\n        \"\"\"\n        cmd.Cmd.__init__(self)\n        self.policy = policy\n        self.intro = \"Type help or ? to list commands.\\n\"\n        self.prompt = \">\"",
  "def do_bye(self, arg):\n        \"\"\"Exits from the client.\"\"\"\n        return True",
  "def emptyline(self):\n        return",
  "def do_show_users(self, arg):\n        users = self.policy.get_users()\n        table = Table([\"user\", \"org\", \"roles\"])\n        for user_name, user_def in users.items():\n            table.add_row([user_name, user_def[\"org\"], \",\".join(user_def[\"roles\"])])\n        self.write_table(table)",
  "def _split_to_args(self, arg):\n        if len(arg) <= 0:\n            return []\n        else:\n            return split_to_args(arg)",
  "def do_show_sites(self, arg):\n        sites = self.policy.get_sites()\n        table = Table([\"site\", \"org\"])\n        for site_name, org in sites.items():\n            table.add_row([site_name, org])\n        self.write_table(table)",
  "def do_show_rights(self, arg):\n        rights = self.policy.get_rights()\n        table = Table([\"name\", \"description\", \"default\"])\n        for name, right_def in rights.items():\n            desc = right_def.get(\"desc\", \"\")\n            default = right_def.get(\"default\", \"\")\n            table.add_row([name, desc, \"{}\".format(default)])\n        self.write_table(table)",
  "def do_show_rules(self, arg):\n        rules = self.policy.get_rules()\n        table = Table([\"name\", \"description\", \"default\"])\n        for name, rule_def in rules.items():\n            desc = rule_def.get(\"desc\", \"\")\n            default = rule_def.get(\"default\", \"\")\n            table.add_row([name, desc, \"{}\".format(default)])\n        self.write_table(table)",
  "def do_show_config(self, arg):\n        config = self.policy.get_config()\n        self.write_string(json.dumps(config, indent=1))",
  "def do_show_site_rules(self, arg):\n        args = [\"show_site_rules\"] + self._split_to_args(arg)\n        if len(args) != 2:\n            self.write_string(\"Usage: {} site_name\".format(args[0]))\n            return\n\n        site_name = args[1]\n        rules = self.policy.get_rules()\n        table = Table([\"Rule\", \"Result\"])\n        for rule_name, _ in rules.items():\n            result, err = self._eval_rule(site_name, rule_name)\n            if err:\n                self.write_error(err)\n                return\n            else:\n                table.add_row([rule_name, result])\n        self.write_table(table)",
  "def _eval_right(self, user_name, right_name, site_name):\n        result, err = self.policy.evaluate_user_right_on_site(\n            user_name=user_name, site_name=site_name, right_name=right_name\n        )\n        if err:\n            return result, err\n        if result is None:\n            rights = self.policy.get_rights()\n            right_def = rights[right_name]\n            return \"({})\".format(right_def.get(\"default\", \"?\")), \"\"\n        else:\n            return \"{}\".format(result), \"\"",
  "def do_eval_right(self, arg):\n        args = [\"eval_right\"] + self._split_to_args(arg)\n        if len(args) != 4:\n            self.write_string(\"Usage: {} user_name right_name site_name\".format(args[0]))\n            return\n\n        user_name = args[1]\n        right_name = args[2]\n        site_name = args[3]\n        result, err = self._eval_right(user_name=user_name, site_name=site_name, right_name=right_name)\n        if err:\n            self.write_error(err)\n        else:\n            self.write_string(result)",
  "def do_eval_user(self, arg):\n        args = [\"eval_user\"] + self._split_to_args(arg)\n        if len(args) != 3:\n            self.write_string(\"Usage: {} user_name site_name\".format(args[0]))\n            return\n\n        user_name = args[1]\n        site_name = args[2]\n        table = Table([\"Right\", \"Result\"])\n        rights = self.policy.get_rights()\n        for right_name, right_def in rights.items():\n            result, err = self._eval_right(user_name=user_name, site_name=site_name, right_name=right_name)\n            if err:\n                self.write_error(err)\n                return\n            else:\n                table.add_row([right_name, result])\n        self.write_table(table)",
  "def _eval_rule(self, site_name, rule_name):\n        result, err = self.policy.evaluate_rule_on_site(site_name=site_name, rule_name=rule_name)\n        if err:\n            return result, err\n\n        if result is None:\n            rules = self.policy.get_rules()\n            rule_def = rules[rule_name]\n            return \"({})\".format(rule_def.get(\"default\", \"?\")), \"\"\n        else:\n            return \"{}\".format(result), \"\"",
  "def do_eval_rule(self, arg):\n        args = [\"eval_rule\"] + self._split_to_args(arg)\n        if len(args) != 3:\n            self.write_string(\"Usage: {} site_name rule_name\".format(args[0]))\n            return\n\n        site_name = args[1]\n        rule_name = args[2]\n        result, err = self._eval_rule(site_name=site_name, rule_name=rule_name)\n        if err:\n            self.write_error(err)\n        else:\n            self.write_string(result)",
  "def write_string(self, data: str):\n        content = data + \"\\n\"\n        self.stdout.write(content)",
  "def write_table(self, table: Table):\n        table.write(self.stdout)",
  "def write_error(self, err: str):\n        content = \"Error: \" + err + \"\\n\"\n        self.stdout.write(content)",
  "def main():\n    \"\"\"\n    TODO: should this file be removed?\n\n    \"\"\"\n    user_name = input(\"User Name: \")\n\n    pwd = getpass.getpass(\"Password (8 or more chars): \")\n\n    if len(pwd) < 8:\n        print(\"Invalid password - must have at least 8 chars\")\n        return\n\n    pwd2 = getpass.getpass(\"Confirm Password: \")\n\n    if pwd != pwd2:\n        print(\"Passwords mismatch\")\n        return\n\n    result = hash_password(user_name + pwd)\n    print(\"Password Hash: {}\".format(result))",
  "class _BuiltInCmdModule(CommandModule):\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=\"\",\n            cmd_specs=[\n                CommandSpec(name=\"bye\", description=\"exit from the client\", usage=\"bye\", handler_func=None),\n                CommandSpec(name=\"help\", description=\"get command help information\", usage=\"help\", handler_func=None),\n                CommandSpec(\n                    name=\"lpwd\", description=\"print local work dir of the admin client\", usage=\"lpwd\", handler_func=None\n                ),\n            ],\n        )",
  "class CredentialType(str, Enum):\n    PASSWORD = \"password\"\n    CERT = \"cert\"",
  "class AdminClient(cmd.Cmd):\n    \"\"\"Admin command prompt for submitting admin commands to the server through the CLI.\n\n    Args:\n        host: cn provisioned for the server, with this fully qualified domain name resolving to the IP of the FL server. This may be set by the OverseerAgent.\n        port: port provisioned as admin_port for FL admin communication, by default provisioned as 8003, must be int if provided. This may be set by the OverseerAgent.\n        prompt: prompt to use for the command prompt\n        ca_cert: path to CA Cert file, by default provisioned rootCA.pem\n        client_cert: path to admin client Cert file, by default provisioned as client.crt\n        client_key: path to admin client Key file, by default provisioned as client.key\n        server_cn: server cn\n        require_login: whether to require login\n        credential_type: what type of credential to use\n        cmd_modules: command modules to load and register\n        overseer_agent: initialized OverseerAgent to obtain the primary service provider to set the host and port of the active server\n        debug: whether to print debug messages. False by default.\n    \"\"\"\n\n    def __init__(\n        self,\n        host=None,\n        port: int = None,\n        prompt: str = \"> \",\n        ca_cert=None,\n        client_cert=None,\n        client_key=None,\n        upload_dir=\"\",\n        download_dir=\"\",\n        server_cn=None,\n        require_login: bool = False,\n        credential_type: str = CredentialType.PASSWORD,\n        cmd_modules: Optional[List] = None,\n        overseer_agent: OverseerAgent = None,\n        debug: bool = False,\n    ):\n        cmd.Cmd.__init__(self)\n        self.intro = \"Type help or ? to list commands.\\n\"\n        self.prompt = prompt\n        self.require_login = require_login\n        self.credential_type = credential_type\n        self.user_name = None\n        self.pwd = None\n\n        self.overseer_agent = overseer_agent\n        self.debug = debug\n        self.out_file = None\n        self.no_stdout = False\n\n        if not isinstance(overseer_agent, OverseerAgent):\n            raise TypeError(\"overseer_agent was not properly initialized.\")\n        if not isinstance(credential_type, CredentialType):\n            raise TypeError(\"invalid credential_type {}\".format(credential_type))\n\n        modules = [_BuiltInCmdModule()]\n        if cmd_modules:\n            if not isinstance(cmd_modules, list):\n                raise TypeError(\"cmd_modules must be a list.\")\n            for m in cmd_modules:\n                if not isinstance(m, CommandModule):\n                    raise TypeError(\"cmd_modules must be a list of CommandModule\")\n                modules.append(m)\n\n        poc = True if self.credential_type == CredentialType.PASSWORD else False\n\n        self._get_login_creds()\n\n        self.api = AdminAPI(\n            host=host,\n            port=port,\n            ca_cert=ca_cert,\n            client_cert=client_cert,\n            client_key=client_key,\n            upload_dir=upload_dir,\n            download_dir=download_dir,\n            server_cn=server_cn,\n            cmd_modules=modules,\n            overseer_agent=self.overseer_agent,\n            auto_login=True,\n            user_name=self.user_name,\n            debug=self.debug,\n            poc=poc,\n        )\n\n        signal.signal(signal.SIGUSR1, partial(self.session_signal_handler))\n\n    def session_ended(self, message):\n        self.write_error(message)\n        os.kill(os.getpid(), signal.SIGUSR1)\n\n    def session_signal_handler(self, signum, frame):\n        self.api.close_session_monitor()\n        raise ConnectionError\n\n    def _set_output_file(self, file, no_stdout):\n        self._close_output_file()\n        self.out_file = file\n        self.no_stdout = no_stdout\n\n    def _close_output_file(self):\n        if self.out_file:\n            self.out_file.close()\n            self.out_file = None\n        self.no_stdout = False\n\n    def do_bye(self, arg):\n        \"\"\"Exit from the client.\n\n        If the arg is not logout, in other words, the user is issuing the bye command to shut down the client, or it is\n        called by inputting the EOF character, a message will display that the admin client is shutting down.\"\"\"\n        if arg != \"logout\":\n            print(\"Shutting down admin client, please wait...\")\n        if self.require_login:\n            self.api.server_execute(\"_logout\")\n        return True\n\n    def do_lpwd(self, arg):\n        \"\"\"print local current work dir\"\"\"\n        self.write_string(os.getcwd())\n\n    def emptyline(self):\n        return\n\n    def _show_one_command(self, cmd_name, reg):\n        entries = reg.get_command_entries(cmd_name)\n        if len(entries) <= 0:\n            self.write_string(\"Undefined command {}\\n\".format(cmd_name))\n            return\n\n        for e in entries:\n            if not e.visible:\n                continue\n\n            if len(e.scope.name) > 0:\n                self.write_string(\"Command: {}.{}\".format(e.scope.name, cmd_name))\n            else:\n                self.write_string(\"Command: {}\".format(cmd_name))\n\n            self.write_string(\"Description: {}\".format(e.desc))\n            self.write_string(\"Usage: {}\\n\".format(e.usage))\n\n    def _show_commands(self, reg: CommandRegister):\n        table = Table([\"Command\", \"Description\"])\n        for scope_name in sorted(reg.scopes):\n            scope = reg.scopes[scope_name]\n            for cmd_name in sorted(scope.entries):\n                e = scope.entries[cmd_name]\n                if e.visible:\n                    table.add_row([cmd_name, e.desc])\n        self.write_table(table)\n\n    def do_help(self, arg):\n        if len(arg) <= 0:\n            self.write_string(\"Client Initiated / Overseer Commands\")\n            self._show_commands(self.api.client_cmd_reg)\n\n            self.write_string(\"\\nServer Commands\")\n            self._show_commands(self.api.server_cmd_reg)\n        else:\n            server_cmds = []\n            local_cmds = []\n            parts = arg.split()\n            for p in parts:\n                entries = self.api.client_cmd_reg.get_command_entries(p)\n                if len(entries) > 0:\n                    local_cmds.append(p)\n\n                entries = self.api.server_cmd_reg.get_command_entries(p)\n                if len(entries) > 0:\n                    server_cmds.append(p)\n\n            if len(local_cmds) > 0:\n                self.write_string(\"Client Commands\")\n                self.write_string(\"---------------\")\n                for cmd_name in local_cmds:\n                    self._show_one_command(cmd_name, self.api.client_cmd_reg)\n\n            if len(server_cmds) > 0:\n                self.write_string(\"Server Commands\")\n                self.write_string(\"---------------\")\n                for cmd_name in server_cmds:\n                    self._show_one_command(cmd_name, self.api.server_cmd_reg)\n\n    def complete(self, text, state):\n        results = [x + \" \" for x in self.api.all_cmds if x.startswith(text)] + [None]\n        return results[state]\n\n    def default(self, line):\n        self._close_output_file()\n        try:\n            return self._do_default(line)\n        except KeyboardInterrupt:\n            self.write_stdout(\"\\n\")\n        except BaseException as ex:\n            if self.debug:\n                traceback.print_exc()\n            self.write_stdout(\"exception occurred: {}\".format(ex))\n        self._close_output_file()\n\n    def _do_default(self, line):\n        args = split_to_args(line)\n        cmd_name = args[0]\n\n        # check for file output\n        out_file_name = None\n        no_stdout = False\n        out_arg_idx = 0\n        for i in range(len(args)):\n            arg = args[i]\n            if arg.startswith(\">\") and out_file_name is not None:\n                self.write_error(\"only one output file is supported\")\n                return\n\n            if arg.startswith(\">>\"):\n                # only output to file\n                out_file_name = arg[2:]\n                no_stdout = True\n                out_arg_idx = i\n            elif arg.startswith(\">\"):\n                # only output to file\n                out_file_name = arg[1:]\n                no_stdout = False\n                out_arg_idx = i\n\n        if out_file_name is not None:\n            if len(out_file_name) <= 0:\n                self.write_error(\"output file name must not be empty\")\n                return\n            args.pop(out_arg_idx)\n            line = join_args(args)\n            try:\n                out_file = open(out_file_name, \"w\")\n            except BaseException as ex:\n                self.write_error(\"cannot open file {}: {}\".format(out_file_name, ex))\n                return\n\n            self._set_output_file(out_file, no_stdout)\n\n        # check client command first\n        entries = self.api.client_cmd_reg.get_command_entries(cmd_name)\n        if len(entries) > 1:\n            self.write_string(\"Ambiguous client command {} - qualify with scope\".format(cmd_name))\n            return\n        elif len(entries) == 1:\n            ent = entries[0]\n            resp = ent.handler(args, self.api)\n            self.print_resp(resp)\n            if resp.get(\"status\") == APIStatus.ERROR_INACTIVE_SESSION:\n                return True\n            return\n\n        entries = self.api.server_cmd_reg.get_command_entries(cmd_name)\n        if len(entries) <= 0:\n            self.write_string(\"Undefined server command {}\".format(cmd_name))\n            return\n        elif len(entries) > 1:\n            self.write_string(\"Ambiguous server command {} - qualify with scope\".format(cmd_name))\n            return\n\n        ent = entries[0]\n        confirm_method = ent.confirm\n        if ent.confirm == \"auth\":\n            if self.credential_type == CredentialType.PASSWORD:\n                confirm_method = \"pwd\"\n            elif self.user_name:\n                confirm_method = \"username\"\n            else:\n                confirm_method = \"yesno\"\n\n        if confirm_method == \"yesno\":\n            answer = input(\"Are you sure (Y/N): \")\n            answer = answer.lower()\n            if answer != \"y\" and answer != \"yes\":\n                return\n        elif confirm_method == \"username\":\n            answer = input(\"Confirm with User Name: \")\n            if answer != self.user_name:\n                self.write_string(\"user name mismatch\")\n                return\n        elif confirm_method == \"pwd\":\n            pwd = getpass.getpass(\"Enter password to confirm: \")\n            if not verify_password(self.pwd, pwd):\n                self.write_string(\"Not authenticated\")\n                return\n\n        start = time.time()\n        resp = self.api.server_execute(line)\n        secs = time.time() - start\n        usecs = int(secs * 1000000)\n        done = \"Done [{} usecs] {}\".format(usecs, datetime.now())\n        self.print_resp(resp)\n        if resp[\"status\"] == APIStatus.ERROR_INACTIVE_SESSION:\n            return True\n        self.write_stdout(done)\n        if self.api.shutdown_received:\n            # exit the client\n            self.write_string(self.api.shutdown_msg)\n            return True\n\n    def cmdloop(self, intro=None):\n        \"\"\"Repeatedly issue a prompt, accept input, parse an initial prefix\n        off the received input, and dispatch to action methods, passing them\n        the remainder of the line as argument.\n\n        Overriding what is in cmd.Cmd to handle exiting client on Ctrl+D (EOF).\n        \"\"\"\n\n        self.preloop()\n        if self.use_rawinput and self.completekey:\n            try:\n                import readline\n\n                self.old_completer = readline.get_completer()\n                readline.set_completer(self.complete)\n                readline.parse_and_bind(self.completekey + \": complete\")\n            except ImportError:\n                pass\n        try:\n            if intro is not None:\n                self.intro = intro\n            if self.intro:\n                self.stdout.write(str(self.intro) + \"\\n\")\n            stop = None\n            while not stop:\n                if self.cmdqueue:\n                    line = self.cmdqueue.pop(0)\n                else:\n                    if self.use_rawinput:\n                        try:\n                            line = input(self.prompt)\n                        except (EOFError, ConnectionError):\n                            line = \"bye\"\n                        except KeyboardInterrupt:\n                            self.stdout.write(\"\\n\")\n                            line = \"\\n\"\n                    else:\n                        self.stdout.write(self.prompt)\n                        self.stdout.flush()\n                        line = self.stdin.readline()\n                        if not len(line):\n                            line = \"EOF\"\n                        else:\n                            line = line.rstrip(\"\\r\\n\")\n                line = self.precmd(line)\n                stop = self.onecmd(line)\n                stop = self.postcmd(stop, line)\n            self.postloop()\n        finally:\n            if self.use_rawinput and self.completekey:\n                try:\n                    import readline\n\n                    readline.set_completer(self.old_completer)\n                except ImportError:\n                    pass\n\n    def run(self):\n\n        try:\n            self.stdout.write(\"Waiting for token from successful login...\\n\")\n            while self.api.token is None:\n                time.sleep(1.0)\n                if self.api.shutdown_received:\n                    return False\n\n            # self.api.start_session_monitor(self.session_ended)\n            # above line was commented out, but if we want to use it, need to be logged in to call server_execute(\"_check_session\") and consider how SP changes impact this\n            self.cmdloop(intro='Type ? to list commands; type \"? cmdName\" to show usage of a command.')\n        finally:\n            self.overseer_agent.end()\n\n    def _get_login_creds(self):\n        if self.credential_type == CredentialType.PASSWORD:\n            self.user_name = \"admin\"\n            self.pwd = hash_password(\"admin\")\n        else:\n            self.user_name = input(\"User Name: \")\n\n    def print_resp(self, resp: dict):\n        \"\"\"Prints the server response\n\n        Args:\n            resp (dict): The server response.\n        \"\"\"\n        if \"details\" in resp:\n            if isinstance(resp[\"details\"], str):\n                self.write_string(resp[\"details\"])\n            if isinstance(resp[\"details\"], Table):\n                self.write_table(resp[\"details\"])\n\n        if \"data\" in resp:\n            for item in resp[\"data\"]:\n                if not isinstance(item, dict):\n                    continue\n                item_type = item.get(\"type\")\n                if item_type == \"string\":\n                    self.write_string(item[\"data\"])\n                elif item_type == \"table\":\n                    table = Table(None)\n                    table.set_rows(item[\"rows\"])\n                    self.write_table(table)\n                elif item_type == \"error\":\n                    self.write_error(item[\"data\"])\n                elif item_type == \"dict\":\n                    self.write_dict(item[\"data\"])\n\n        if \"details\" not in resp and \"data\" not in resp:\n            self.write_string(\"Response is not correct.\")\n\n    def write_stdout(self, data: str):\n        self.stdout.write(data + \"\\n\")\n\n    def _write(self, content: str):\n        if not self.no_stdout:\n            self.stdout.write(content)\n        if self.out_file:\n            self.out_file.write(content)\n\n    def write_string(self, data: str):\n        content = data + \"\\n\"\n        self._write(content)\n\n    def write_table(self, table: Table):\n        if not self.no_stdout:\n            table.write(self.stdout)\n        if self.out_file:\n            table.write(self.out_file)\n\n    def write_dict(self, data: dict):\n        content = json.dumps(data, indent=2) + \"\\n\"\n        self._write(content)\n\n    def write_error(self, err: str):\n        content = \"Error: \" + err + \"\\n\"\n        self._write(content)\n\n    def flush(self):\n        if not self.no_stdout:\n            self.stdout.flush()\n        if self.out_file:\n            self.out_file.flush()",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=\"\",\n            cmd_specs=[\n                CommandSpec(name=\"bye\", description=\"exit from the client\", usage=\"bye\", handler_func=None),\n                CommandSpec(name=\"help\", description=\"get command help information\", usage=\"help\", handler_func=None),\n                CommandSpec(\n                    name=\"lpwd\", description=\"print local work dir of the admin client\", usage=\"lpwd\", handler_func=None\n                ),\n            ],\n        )",
  "def __init__(\n        self,\n        host=None,\n        port: int = None,\n        prompt: str = \"> \",\n        ca_cert=None,\n        client_cert=None,\n        client_key=None,\n        upload_dir=\"\",\n        download_dir=\"\",\n        server_cn=None,\n        require_login: bool = False,\n        credential_type: str = CredentialType.PASSWORD,\n        cmd_modules: Optional[List] = None,\n        overseer_agent: OverseerAgent = None,\n        debug: bool = False,\n    ):\n        cmd.Cmd.__init__(self)\n        self.intro = \"Type help or ? to list commands.\\n\"\n        self.prompt = prompt\n        self.require_login = require_login\n        self.credential_type = credential_type\n        self.user_name = None\n        self.pwd = None\n\n        self.overseer_agent = overseer_agent\n        self.debug = debug\n        self.out_file = None\n        self.no_stdout = False\n\n        if not isinstance(overseer_agent, OverseerAgent):\n            raise TypeError(\"overseer_agent was not properly initialized.\")\n        if not isinstance(credential_type, CredentialType):\n            raise TypeError(\"invalid credential_type {}\".format(credential_type))\n\n        modules = [_BuiltInCmdModule()]\n        if cmd_modules:\n            if not isinstance(cmd_modules, list):\n                raise TypeError(\"cmd_modules must be a list.\")\n            for m in cmd_modules:\n                if not isinstance(m, CommandModule):\n                    raise TypeError(\"cmd_modules must be a list of CommandModule\")\n                modules.append(m)\n\n        poc = True if self.credential_type == CredentialType.PASSWORD else False\n\n        self._get_login_creds()\n\n        self.api = AdminAPI(\n            host=host,\n            port=port,\n            ca_cert=ca_cert,\n            client_cert=client_cert,\n            client_key=client_key,\n            upload_dir=upload_dir,\n            download_dir=download_dir,\n            server_cn=server_cn,\n            cmd_modules=modules,\n            overseer_agent=self.overseer_agent,\n            auto_login=True,\n            user_name=self.user_name,\n            debug=self.debug,\n            poc=poc,\n        )\n\n        signal.signal(signal.SIGUSR1, partial(self.session_signal_handler))",
  "def session_ended(self, message):\n        self.write_error(message)\n        os.kill(os.getpid(), signal.SIGUSR1)",
  "def session_signal_handler(self, signum, frame):\n        self.api.close_session_monitor()\n        raise ConnectionError",
  "def _set_output_file(self, file, no_stdout):\n        self._close_output_file()\n        self.out_file = file\n        self.no_stdout = no_stdout",
  "def _close_output_file(self):\n        if self.out_file:\n            self.out_file.close()\n            self.out_file = None\n        self.no_stdout = False",
  "def do_bye(self, arg):\n        \"\"\"Exit from the client.\n\n        If the arg is not logout, in other words, the user is issuing the bye command to shut down the client, or it is\n        called by inputting the EOF character, a message will display that the admin client is shutting down.\"\"\"\n        if arg != \"logout\":\n            print(\"Shutting down admin client, please wait...\")\n        if self.require_login:\n            self.api.server_execute(\"_logout\")\n        return True",
  "def do_lpwd(self, arg):\n        \"\"\"print local current work dir\"\"\"\n        self.write_string(os.getcwd())",
  "def emptyline(self):\n        return",
  "def _show_one_command(self, cmd_name, reg):\n        entries = reg.get_command_entries(cmd_name)\n        if len(entries) <= 0:\n            self.write_string(\"Undefined command {}\\n\".format(cmd_name))\n            return\n\n        for e in entries:\n            if not e.visible:\n                continue\n\n            if len(e.scope.name) > 0:\n                self.write_string(\"Command: {}.{}\".format(e.scope.name, cmd_name))\n            else:\n                self.write_string(\"Command: {}\".format(cmd_name))\n\n            self.write_string(\"Description: {}\".format(e.desc))\n            self.write_string(\"Usage: {}\\n\".format(e.usage))",
  "def _show_commands(self, reg: CommandRegister):\n        table = Table([\"Command\", \"Description\"])\n        for scope_name in sorted(reg.scopes):\n            scope = reg.scopes[scope_name]\n            for cmd_name in sorted(scope.entries):\n                e = scope.entries[cmd_name]\n                if e.visible:\n                    table.add_row([cmd_name, e.desc])\n        self.write_table(table)",
  "def do_help(self, arg):\n        if len(arg) <= 0:\n            self.write_string(\"Client Initiated / Overseer Commands\")\n            self._show_commands(self.api.client_cmd_reg)\n\n            self.write_string(\"\\nServer Commands\")\n            self._show_commands(self.api.server_cmd_reg)\n        else:\n            server_cmds = []\n            local_cmds = []\n            parts = arg.split()\n            for p in parts:\n                entries = self.api.client_cmd_reg.get_command_entries(p)\n                if len(entries) > 0:\n                    local_cmds.append(p)\n\n                entries = self.api.server_cmd_reg.get_command_entries(p)\n                if len(entries) > 0:\n                    server_cmds.append(p)\n\n            if len(local_cmds) > 0:\n                self.write_string(\"Client Commands\")\n                self.write_string(\"---------------\")\n                for cmd_name in local_cmds:\n                    self._show_one_command(cmd_name, self.api.client_cmd_reg)\n\n            if len(server_cmds) > 0:\n                self.write_string(\"Server Commands\")\n                self.write_string(\"---------------\")\n                for cmd_name in server_cmds:\n                    self._show_one_command(cmd_name, self.api.server_cmd_reg)",
  "def complete(self, text, state):\n        results = [x + \" \" for x in self.api.all_cmds if x.startswith(text)] + [None]\n        return results[state]",
  "def default(self, line):\n        self._close_output_file()\n        try:\n            return self._do_default(line)\n        except KeyboardInterrupt:\n            self.write_stdout(\"\\n\")\n        except BaseException as ex:\n            if self.debug:\n                traceback.print_exc()\n            self.write_stdout(\"exception occurred: {}\".format(ex))\n        self._close_output_file()",
  "def _do_default(self, line):\n        args = split_to_args(line)\n        cmd_name = args[0]\n\n        # check for file output\n        out_file_name = None\n        no_stdout = False\n        out_arg_idx = 0\n        for i in range(len(args)):\n            arg = args[i]\n            if arg.startswith(\">\") and out_file_name is not None:\n                self.write_error(\"only one output file is supported\")\n                return\n\n            if arg.startswith(\">>\"):\n                # only output to file\n                out_file_name = arg[2:]\n                no_stdout = True\n                out_arg_idx = i\n            elif arg.startswith(\">\"):\n                # only output to file\n                out_file_name = arg[1:]\n                no_stdout = False\n                out_arg_idx = i\n\n        if out_file_name is not None:\n            if len(out_file_name) <= 0:\n                self.write_error(\"output file name must not be empty\")\n                return\n            args.pop(out_arg_idx)\n            line = join_args(args)\n            try:\n                out_file = open(out_file_name, \"w\")\n            except BaseException as ex:\n                self.write_error(\"cannot open file {}: {}\".format(out_file_name, ex))\n                return\n\n            self._set_output_file(out_file, no_stdout)\n\n        # check client command first\n        entries = self.api.client_cmd_reg.get_command_entries(cmd_name)\n        if len(entries) > 1:\n            self.write_string(\"Ambiguous client command {} - qualify with scope\".format(cmd_name))\n            return\n        elif len(entries) == 1:\n            ent = entries[0]\n            resp = ent.handler(args, self.api)\n            self.print_resp(resp)\n            if resp.get(\"status\") == APIStatus.ERROR_INACTIVE_SESSION:\n                return True\n            return\n\n        entries = self.api.server_cmd_reg.get_command_entries(cmd_name)\n        if len(entries) <= 0:\n            self.write_string(\"Undefined server command {}\".format(cmd_name))\n            return\n        elif len(entries) > 1:\n            self.write_string(\"Ambiguous server command {} - qualify with scope\".format(cmd_name))\n            return\n\n        ent = entries[0]\n        confirm_method = ent.confirm\n        if ent.confirm == \"auth\":\n            if self.credential_type == CredentialType.PASSWORD:\n                confirm_method = \"pwd\"\n            elif self.user_name:\n                confirm_method = \"username\"\n            else:\n                confirm_method = \"yesno\"\n\n        if confirm_method == \"yesno\":\n            answer = input(\"Are you sure (Y/N): \")\n            answer = answer.lower()\n            if answer != \"y\" and answer != \"yes\":\n                return\n        elif confirm_method == \"username\":\n            answer = input(\"Confirm with User Name: \")\n            if answer != self.user_name:\n                self.write_string(\"user name mismatch\")\n                return\n        elif confirm_method == \"pwd\":\n            pwd = getpass.getpass(\"Enter password to confirm: \")\n            if not verify_password(self.pwd, pwd):\n                self.write_string(\"Not authenticated\")\n                return\n\n        start = time.time()\n        resp = self.api.server_execute(line)\n        secs = time.time() - start\n        usecs = int(secs * 1000000)\n        done = \"Done [{} usecs] {}\".format(usecs, datetime.now())\n        self.print_resp(resp)\n        if resp[\"status\"] == APIStatus.ERROR_INACTIVE_SESSION:\n            return True\n        self.write_stdout(done)\n        if self.api.shutdown_received:\n            # exit the client\n            self.write_string(self.api.shutdown_msg)\n            return True",
  "def cmdloop(self, intro=None):\n        \"\"\"Repeatedly issue a prompt, accept input, parse an initial prefix\n        off the received input, and dispatch to action methods, passing them\n        the remainder of the line as argument.\n\n        Overriding what is in cmd.Cmd to handle exiting client on Ctrl+D (EOF).\n        \"\"\"\n\n        self.preloop()\n        if self.use_rawinput and self.completekey:\n            try:\n                import readline\n\n                self.old_completer = readline.get_completer()\n                readline.set_completer(self.complete)\n                readline.parse_and_bind(self.completekey + \": complete\")\n            except ImportError:\n                pass\n        try:\n            if intro is not None:\n                self.intro = intro\n            if self.intro:\n                self.stdout.write(str(self.intro) + \"\\n\")\n            stop = None\n            while not stop:\n                if self.cmdqueue:\n                    line = self.cmdqueue.pop(0)\n                else:\n                    if self.use_rawinput:\n                        try:\n                            line = input(self.prompt)\n                        except (EOFError, ConnectionError):\n                            line = \"bye\"\n                        except KeyboardInterrupt:\n                            self.stdout.write(\"\\n\")\n                            line = \"\\n\"\n                    else:\n                        self.stdout.write(self.prompt)\n                        self.stdout.flush()\n                        line = self.stdin.readline()\n                        if not len(line):\n                            line = \"EOF\"\n                        else:\n                            line = line.rstrip(\"\\r\\n\")\n                line = self.precmd(line)\n                stop = self.onecmd(line)\n                stop = self.postcmd(stop, line)\n            self.postloop()\n        finally:\n            if self.use_rawinput and self.completekey:\n                try:\n                    import readline\n\n                    readline.set_completer(self.old_completer)\n                except ImportError:\n                    pass",
  "def run(self):\n\n        try:\n            self.stdout.write(\"Waiting for token from successful login...\\n\")\n            while self.api.token is None:\n                time.sleep(1.0)\n                if self.api.shutdown_received:\n                    return False\n\n            # self.api.start_session_monitor(self.session_ended)\n            # above line was commented out, but if we want to use it, need to be logged in to call server_execute(\"_check_session\") and consider how SP changes impact this\n            self.cmdloop(intro='Type ? to list commands; type \"? cmdName\" to show usage of a command.')\n        finally:\n            self.overseer_agent.end()",
  "def _get_login_creds(self):\n        if self.credential_type == CredentialType.PASSWORD:\n            self.user_name = \"admin\"\n            self.pwd = hash_password(\"admin\")\n        else:\n            self.user_name = input(\"User Name: \")",
  "def print_resp(self, resp: dict):\n        \"\"\"Prints the server response\n\n        Args:\n            resp (dict): The server response.\n        \"\"\"\n        if \"details\" in resp:\n            if isinstance(resp[\"details\"], str):\n                self.write_string(resp[\"details\"])\n            if isinstance(resp[\"details\"], Table):\n                self.write_table(resp[\"details\"])\n\n        if \"data\" in resp:\n            for item in resp[\"data\"]:\n                if not isinstance(item, dict):\n                    continue\n                item_type = item.get(\"type\")\n                if item_type == \"string\":\n                    self.write_string(item[\"data\"])\n                elif item_type == \"table\":\n                    table = Table(None)\n                    table.set_rows(item[\"rows\"])\n                    self.write_table(table)\n                elif item_type == \"error\":\n                    self.write_error(item[\"data\"])\n                elif item_type == \"dict\":\n                    self.write_dict(item[\"data\"])\n\n        if \"details\" not in resp and \"data\" not in resp:\n            self.write_string(\"Response is not correct.\")",
  "def write_stdout(self, data: str):\n        self.stdout.write(data + \"\\n\")",
  "def _write(self, content: str):\n        if not self.no_stdout:\n            self.stdout.write(content)\n        if self.out_file:\n            self.out_file.write(content)",
  "def write_string(self, data: str):\n        content = data + \"\\n\"\n        self._write(content)",
  "def write_table(self, table: Table):\n        if not self.no_stdout:\n            table.write(self.stdout)\n        if self.out_file:\n            table.write(self.out_file)",
  "def write_dict(self, data: dict):\n        content = json.dumps(data, indent=2) + \"\\n\"\n        self._write(content)",
  "def write_error(self, err: str):\n        content = \"Error: \" + err + \"\\n\"\n        self._write(content)",
  "def flush(self):\n        if not self.no_stdout:\n            self.stdout.flush()\n        if self.out_file:\n            self.out_file.flush()",
  "class _DefaultReplyProcessor(ReplyProcessor):\n    def process_shutdown(self, api: AdminAPI, msg: str):\n        api.shutdown_received = True\n        api.shutdown_msg = msg",
  "class _LoginReplyProcessor(ReplyProcessor):\n    \"\"\"Reply processor for handling login and setting the token for the admin client.\"\"\"\n\n    def process_string(self, api: AdminAPI, item: str):\n        api.login_result = item\n\n    def process_token(self, api: AdminAPI, token: str):\n        api.token = token",
  "class _CmdListReplyProcessor(ReplyProcessor):\n    \"\"\"Reply processor to register available commands after getting back a table of commands from the server.\"\"\"\n\n    def process_table(self, api: AdminAPI, table: Table):\n        for i in range(len(table.rows)):\n            if i == 0:\n                # this is header\n                continue\n\n            row = table.rows[i]\n            if len(row) < 5:\n                return\n\n            scope = row[0]\n            cmd_name = row[1]\n            desc = row[2]\n            usage = row[3]\n            confirm = row[4]\n\n            # if confirm == 'auth' and not client.require_login:\n            # the user is not authenticated - skip this command\n            # continue\n\n            api.server_cmd_reg.add_command(\n                scope_name=scope,\n                cmd_name=cmd_name,\n                desc=desc,\n                usage=usage,\n                handler=None,\n                authz_func=None,\n                visible=True,\n                confirm=confirm,\n            )\n\n        api.server_cmd_received = True",
  "class AdminAPI(AdminAPISpec):\n    def __init__(\n        self,\n        host=None,\n        port=None,\n        ca_cert: str = \"\",\n        client_cert: str = \"\",\n        client_key: str = \"\",\n        upload_dir: str = \"\",\n        download_dir: str = \"\",\n        server_cn=None,\n        cmd_modules: Optional[List] = None,\n        overseer_agent: OverseerAgent = None,\n        auto_login: bool = False,\n        user_name: str = None,\n        poc: bool = False,\n        debug: bool = False,\n    ):\n        \"\"\"Underlying API to keep certs, keys and connection information and to execute admin commands through do_command.\n\n        Args:\n            host: cn provisioned for the server, with this fully qualified domain name resolving to the IP of the FL server. This may be set by the OverseerAgent.\n            port: port provisioned as admin_port for FL admin communication, by default provisioned as 8003, must be int if provided. This may be set by the OverseerAgent.\n            ca_cert: path to CA Cert file, by default provisioned rootCA.pem\n            client_cert: path to admin client Cert file, by default provisioned as client.crt\n            client_key: path to admin client Key file, by default provisioned as client.key\n            upload_dir: File transfer upload directory. Folders uploaded to the server to be deployed must be here. Folder must already exist and be accessible.\n            download_dir: File transfer download directory. Can be same as upload_dir. Folder must already exist and be accessible.\n            server_cn: server cn (only used for validating server cn)\n            cmd_modules: command modules to load and register. Note that FileTransferModule is initialized here with upload_dir and download_dir if cmd_modules is None.\n            overseer_agent: initialized OverseerAgent to obtain the primary service provider to set the host and port of the active server\n            auto_login: Whether to use stored credentials to automatically log in (required to be True with OverseerAgent to provide high availability)\n            user_name: Username to authenticate with FL server\n            poc: Whether to enable poc mode for using the proof of concept example without secure communication.\n            debug: Whether to print debug messages, which can help with diagnosing problems. False by default.\n        \"\"\"\n        super().__init__()\n        if cmd_modules is None:\n            from .file_transfer import FileTransferModule\n\n            cmd_modules = [FileTransferModule(upload_dir=upload_dir, download_dir=download_dir)]\n        elif not isinstance(cmd_modules, list):\n            raise TypeError(\"cmd_modules must be a list, but got {}\".format(type(cmd_modules)))\n        else:\n            for m in cmd_modules:\n                if not isinstance(m, CommandModule):\n                    raise TypeError(\n                        \"cmd_modules must be a list of CommandModule, but got element of type {}\".format(type(m))\n                    )\n        cmd_modules.append(HACommandModule())\n\n        self.overseer_agent = overseer_agent\n        self.host = host\n        self.port = port\n        self.poc = poc\n        if self.poc:\n            self.poc_key = \"admin\"\n        else:\n            if len(ca_cert) <= 0:\n                raise Exception(\"missing CA Cert file name\")\n            self.ca_cert = ca_cert\n            if len(client_cert) <= 0:\n                raise Exception(\"missing Client Cert file name\")\n            self.client_cert = client_cert\n            if len(client_key) <= 0:\n                raise Exception(\"missing Client Key file name\")\n            self.client_key = client_key\n            if not isinstance(self.overseer_agent, OverseerAgent):\n                raise Exception(\"overseer_agent is missing but must be provided for secure context.\")\n            self.overseer_agent.set_secure_context(\n                ca_path=self.ca_cert, cert_path=self.client_cert, prv_key_path=self.client_key\n            )\n        if self.overseer_agent:\n            self.overseer_agent.start(self._overseer_callback)\n        self.server_cn = server_cn\n        self.debug = debug\n\n        # for overseer agent\n        self.ssid = None\n\n        # for login\n        self.token = None\n        self.login_result = None\n        if auto_login:\n            self.auto_login = True\n            if not user_name:\n                raise Exception(\"for auto_login, user_name is required.\")\n            self.user_name = user_name\n\n        self.server_cmd_reg = CommandRegister(app_ctx=self)\n        self.client_cmd_reg = CommandRegister(app_ctx=self)\n        self.server_cmd_received = False\n\n        self.all_cmds = []\n        self._load_client_cmds(cmd_modules)\n\n        # for shutdown\n        self.shutdown_received = False\n        self.shutdown_msg = None\n\n        self.server_sess_active = False\n\n        self.sess_monitor_thread = None\n        self.sess_monitor_active = False\n\n    def _overseer_callback(self, overseer_agent):\n        sp = overseer_agent.get_primary_sp()\n        self._set_primary_sp(sp)\n\n    def _set_primary_sp(self, sp: SP):\n        if sp and sp.primary is True:\n            if self.host != sp.name or self.port != int(sp.admin_port) or self.ssid != sp.service_session_id:\n                # if needing to log out of previous server, this may be where to issue server_execute(\"_logout\")\n                self.host = sp.name\n                self.port = int(sp.admin_port)\n                self.ssid = sp.service_session_id\n                print(\n                    f\"Got primary SP {self.host}:{sp.fl_port}:{self.port} from overseer. Host: {self.host} Admin_port: {self.port} SSID: {self.ssid}\"\n                )\n\n                thread = threading.Thread(target=self._login_sp)\n                thread.start()\n\n    def _login_sp(self):\n        if not self._auto_login():\n            print(\"cannot log in, shutting down...\")\n            self.shutdown_received = True\n\n    def _auto_login(self):\n        try_count = 0\n        while try_count < 5:\n            if self.poc:\n                self.login_with_poc(username=self.user_name, poc_key=self.poc_key)\n                print(f\"login_result: {self.login_result} token: {self.token}\")\n                if self.login_result == \"OK\":\n                    return True\n                elif self.login_result == \"REJECT\":\n                    print(\"Incorrect key for POC mode.\")\n                    return False\n                else:\n                    print(\"Communication Error - please try later\")\n                    try_count += 1\n            else:\n                self.login(username=self.user_name)\n                if self.login_result == \"OK\":\n                    return True\n                elif self.login_result == \"REJECT\":\n                    print(\"Incorrect user name or certificate.\")\n                    return False\n                else:\n                    print(\"Communication Error - please try later\")\n                    try_count += 1\n            time.sleep(1.0)\n        return False\n\n    def _load_client_cmds(self, cmd_modules):\n        if cmd_modules:\n            for m in cmd_modules:\n                self.client_cmd_reg.register_module(m, include_invisible=False)\n        self.client_cmd_reg.finalize(self.register_command)\n\n    def register_command(self, cmd_entry):\n        self.all_cmds.append(cmd_entry.name)\n\n    def start_session_monitor(self, session_ended_callback, interval=5):\n        if self.sess_monitor_thread and self.sess_monitor_thread.is_alive():\n            self.close_session_monitor()\n        self.sess_monitor_thread = threading.Thread(\n            target=self._check_session, args=(session_ended_callback, interval), daemon=True\n        )\n        self.sess_monitor_active = True\n        self.sess_monitor_thread.start()\n\n    def close_session_monitor(self):\n        self.sess_monitor_active = False\n        if self.sess_monitor_thread and self.sess_monitor_thread.is_alive():\n            self.sess_monitor_thread.join()\n            self.sess_monitor_thread = None\n\n    def _check_session(self, session_ended_callback, interval):\n        error_msg = \"\"\n        connection_error_counter = 0\n        while True:\n            time.sleep(interval)\n\n            if not self.sess_monitor_active:\n                return\n\n            if self.shutdown_received:\n                error_msg = self.shutdown_msg\n                break\n\n            resp = self.server_execute(\"_check_session\")\n            status = resp[\"status\"]\n\n            connection_error_counter += 1\n            if status != APIStatus.ERROR_SERVER_CONNECTION:\n                connection_error_counter = 0\n\n            if status in APIStatus.ERROR_INACTIVE_SESSION or (\n                status in APIStatus.ERROR_SERVER_CONNECTION and connection_error_counter > 60 // interval\n            ):\n                for item in resp[\"data\"]:\n                    if item[\"type\"] == \"error\":\n                        error_msg = item[\"data\"]\n                break\n\n        self.server_sess_active = False\n        session_ended_callback(error_msg)\n\n    def logout(self):\n        \"\"\"Send logout command to server.\"\"\"\n        resp = self.server_execute(\"_logout\")\n        self.server_sess_active = False\n        return resp\n\n    def login(self, username: str):\n        \"\"\"Login using certification files and retrieve server side commands.\n\n        Args:\n            username: Username\n\n        Returns:\n            A dict of status and details\n        \"\"\"\n        self.login_result = None\n        self._try_command(f\"_cert_login {username}\", _LoginReplyProcessor())\n        if self.login_result is None:\n            return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": \"Communication Error - please try later\"}\n        elif self.login_result == \"REJECT\":\n            return {\"status\": APIStatus.ERROR_CERT, \"details\": \"Incorrect user name or certificate\"}\n\n        # get command list from server\n        self.server_cmd_received = False\n        self._try_command(\"_commands\", _CmdListReplyProcessor())\n        self.server_cmd_reg.finalize(self.register_command)\n        if not self.server_cmd_received:\n            return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": \"Communication Error - please try later\"}\n\n        self.server_sess_active = True\n        return {\"status\": APIStatus.SUCCESS, \"details\": \"Login success\"}\n\n    def login_with_poc(self, username: str, poc_key: str):\n        \"\"\"Login using key for proof of concept example.\n\n        Args:\n            username: Username\n            poc_key: key used for proof of concept admin login\n\n        Returns:\n            A dict of login status and details\n        \"\"\"\n        self.login_result = None\n        self._try_command(f\"_login {username} {poc_key}\", _LoginReplyProcessor())\n        if self.login_result is None:\n            return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": \"Communication Error - please try later\"}\n        elif self.login_result == \"REJECT\":\n            return {\"status\": APIStatus.ERROR_CERT, \"details\": \"Incorrect user name or certificate\"}\n\n        # get command list from server\n        self.server_cmd_received = False\n        self._try_command(\"_commands\", _CmdListReplyProcessor())\n        self.server_cmd_reg.finalize(self.register_command)\n        if not self.server_cmd_received:\n            return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": \"Communication Error - please try later\"}\n\n        self.server_sess_active = True\n        return {\"status\": APIStatus.SUCCESS, \"details\": \"Login success\"}\n\n    def _send_to_sock(self, sock, command, process_json_func):\n        conn = Connection(sock, self)\n        conn.append_command(command)\n        if self.token:\n            conn.append_token(self.token)\n\n        conn.close()\n        ok = receive_and_process(sock, process_json_func)\n        if not ok:\n            process_json_func(\n                make_error(\"Failed to communicate with Admin Server {} on {}\".format(self.host, self.port))\n            )\n\n    def _process_server_reply(self, resp):\n        \"\"\"Process the server reply and store the status/details into API's `command_result`\n\n        Args:\n            resp: The raw response that returns by the server.\n        \"\"\"\n        if self.debug:\n            print(\"DEBUG: Server Reply: {}\".format(resp))\n        # this resp is what is usually directly used to return, straight from server\n        self.set_command_result(resp)\n        reply_processor = _DefaultReplyProcessor() if self.reply_processor is None else self.reply_processor\n\n        reply_processor.reply_start(self, resp)\n\n        if resp is not None:\n            data = resp[\"data\"]\n            for item in data:\n                it = item[\"type\"]\n                if it == \"string\":\n                    reply_processor.process_string(self, item[\"data\"])\n                elif it == \"success\":\n                    reply_processor.process_success(self, item[\"data\"])\n                elif it == \"error\":\n                    reply_processor.process_error(self, item[\"data\"])\n                    break\n                elif it == \"table\":\n                    table = Table(None)\n                    table.set_rows(item[\"rows\"])\n                    reply_processor.process_table(self, table)\n                elif it == \"dict\":\n                    reply_processor.process_dict(self, item[\"data\"])\n                elif it == \"token\":\n                    reply_processor.process_token(self, item[\"data\"])\n                elif it == \"shutdown\":\n                    reply_processor.process_shutdown(self, item[\"data\"])\n                    break\n                else:\n                    reply_processor.protocol_error(self, \"Invalid item type: \" + it)\n                    break\n        else:\n            reply_processor.protocol_error(self, \"Protocol Error\")\n\n        reply_processor.reply_done(self)\n\n    def _try_command(self, command, reply_processor):\n        \"\"\"Try to execute a command on server side.\n\n        Args:\n            command: The command to execute.\n            reply_processor: An instance of ReplyProcessor\n\n        \"\"\"\n        # process_json_func can't return data because how \"receive_and_process\" is written.\n        self.reply_processor = reply_processor\n        process_json_func = self._process_server_reply\n        try:\n            if not self.poc:\n                # SSL communication\n                ctx = ssl.create_default_context()\n                ctx.verify_mode = ssl.CERT_REQUIRED\n                ctx.check_hostname = False\n\n                ctx.load_verify_locations(self.ca_cert)\n                ctx.load_cert_chain(certfile=self.client_cert, keyfile=self.client_key)\n\n                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n                    with ctx.wrap_socket(sock) as ssock:\n                        ssock.connect((self.host, self.port))\n                        if self.server_cn:\n                            # validate server CN\n                            cn = get_certificate_common_name(ssock.getpeercert())\n                            if cn != self.server_cn:\n                                process_json_func(\n                                    make_error(\"wrong server: expecting {} but connected {}\".format(self.server_cn, cn))\n                                )\n                                return\n\n                        self._send_to_sock(ssock, command, process_json_func)\n            else:\n                # poc without certs\n                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n                    sock.connect((self.host, self.port))\n                    self._send_to_sock(sock, command, process_json_func)\n        except Exception as ex:\n            if self.debug:\n                traceback.print_exc()\n\n            process_json_func(\n                make_error(\"Failed to communicate with Admin Server {} on {}: {}\".format(self.host, self.port, ex))\n            )\n\n    def do_command(self, command):\n        \"\"\"A convenient method to call commands using string.\n\n        Args:\n          command (str): command\n\n        Returns:\n            Object containing status and details (or direct response from server, which originally was just time and data)\n        \"\"\"\n        args = split_to_args(command)\n        cmd_name = args[0]\n        self.set_command_result(None)\n\n        # check client side commands\n        entries = self.client_cmd_reg.get_command_entries(cmd_name)\n        if len(entries) > 1:\n            return {\n                \"status\": APIStatus.ERROR_SYNTAX,\n                \"details\": f\"Ambiguous client command {cmd_name} - qualify with scope\",\n            }\n        elif len(entries) == 1:\n            self.set_command_result(None)\n            ent = entries[0]\n            return_result = ent.handler(args, self)\n            result = self.get_command_result()\n            if return_result:\n                return return_result\n            if result is None:\n                return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": \"Client did not respond\"}\n            return result\n\n        # check server side commands\n        entries = self.server_cmd_reg.get_command_entries(cmd_name)\n        if len(entries) <= 0:\n            return {\n                \"status\": APIStatus.ERROR_SYNTAX,\n                \"details\": f\"Command {cmd_name} not found in server or client cmds\",\n            }\n        elif len(entries) > 1:\n            return {\n                \"status\": APIStatus.ERROR_SYNTAX,\n                \"details\": f\"Ambiguous server command {cmd_name} - qualify with scope\",\n            }\n        return self.server_execute(command)\n\n    def server_execute(self, command, reply_processor=None):\n        if not self.server_sess_active:\n            return {\"status\": APIStatus.ERROR_INACTIVE_SESSION, \"details\": \"API session is inactive\"}\n\n        self.set_command_result(None)\n        start = time.time()\n        self._try_command(command, reply_processor)\n        secs = time.time() - start\n        usecs = int(secs * 1000000)\n\n        if self.debug:\n            print(f\"DEBUG: server_execute Done [{usecs} usecs] {datetime.now()}\")\n\n        result = self.get_command_result()\n        if result is None:\n            return {\"status\": APIStatus.ERROR_SERVER_CONNECTION, \"details\": \"Server did not respond\"}\n        if \"data\" in result:\n            for item in result[\"data\"]:\n                if item[\"type\"] == \"error\":\n                    if \"session_inactive\" in item[\"data\"]:\n                        result.update({\"status\": APIStatus.ERROR_INACTIVE_SESSION})\n                    elif any(\n                        err in item[\"data\"] for err in (\"Failed to communicate with Admin Server\", \"wrong server\")\n                    ):\n                        result.update({\"status\": APIStatus.ERROR_SERVER_CONNECTION})\n        if \"status\" not in result:\n            result.update({\"status\": APIStatus.SUCCESS})\n        self.set_command_result(result)\n        return result",
  "def process_shutdown(self, api: AdminAPI, msg: str):\n        api.shutdown_received = True\n        api.shutdown_msg = msg",
  "def process_string(self, api: AdminAPI, item: str):\n        api.login_result = item",
  "def process_token(self, api: AdminAPI, token: str):\n        api.token = token",
  "def process_table(self, api: AdminAPI, table: Table):\n        for i in range(len(table.rows)):\n            if i == 0:\n                # this is header\n                continue\n\n            row = table.rows[i]\n            if len(row) < 5:\n                return\n\n            scope = row[0]\n            cmd_name = row[1]\n            desc = row[2]\n            usage = row[3]\n            confirm = row[4]\n\n            # if confirm == 'auth' and not client.require_login:\n            # the user is not authenticated - skip this command\n            # continue\n\n            api.server_cmd_reg.add_command(\n                scope_name=scope,\n                cmd_name=cmd_name,\n                desc=desc,\n                usage=usage,\n                handler=None,\n                authz_func=None,\n                visible=True,\n                confirm=confirm,\n            )\n\n        api.server_cmd_received = True",
  "def __init__(\n        self,\n        host=None,\n        port=None,\n        ca_cert: str = \"\",\n        client_cert: str = \"\",\n        client_key: str = \"\",\n        upload_dir: str = \"\",\n        download_dir: str = \"\",\n        server_cn=None,\n        cmd_modules: Optional[List] = None,\n        overseer_agent: OverseerAgent = None,\n        auto_login: bool = False,\n        user_name: str = None,\n        poc: bool = False,\n        debug: bool = False,\n    ):\n        \"\"\"Underlying API to keep certs, keys and connection information and to execute admin commands through do_command.\n\n        Args:\n            host: cn provisioned for the server, with this fully qualified domain name resolving to the IP of the FL server. This may be set by the OverseerAgent.\n            port: port provisioned as admin_port for FL admin communication, by default provisioned as 8003, must be int if provided. This may be set by the OverseerAgent.\n            ca_cert: path to CA Cert file, by default provisioned rootCA.pem\n            client_cert: path to admin client Cert file, by default provisioned as client.crt\n            client_key: path to admin client Key file, by default provisioned as client.key\n            upload_dir: File transfer upload directory. Folders uploaded to the server to be deployed must be here. Folder must already exist and be accessible.\n            download_dir: File transfer download directory. Can be same as upload_dir. Folder must already exist and be accessible.\n            server_cn: server cn (only used for validating server cn)\n            cmd_modules: command modules to load and register. Note that FileTransferModule is initialized here with upload_dir and download_dir if cmd_modules is None.\n            overseer_agent: initialized OverseerAgent to obtain the primary service provider to set the host and port of the active server\n            auto_login: Whether to use stored credentials to automatically log in (required to be True with OverseerAgent to provide high availability)\n            user_name: Username to authenticate with FL server\n            poc: Whether to enable poc mode for using the proof of concept example without secure communication.\n            debug: Whether to print debug messages, which can help with diagnosing problems. False by default.\n        \"\"\"\n        super().__init__()\n        if cmd_modules is None:\n            from .file_transfer import FileTransferModule\n\n            cmd_modules = [FileTransferModule(upload_dir=upload_dir, download_dir=download_dir)]\n        elif not isinstance(cmd_modules, list):\n            raise TypeError(\"cmd_modules must be a list, but got {}\".format(type(cmd_modules)))\n        else:\n            for m in cmd_modules:\n                if not isinstance(m, CommandModule):\n                    raise TypeError(\n                        \"cmd_modules must be a list of CommandModule, but got element of type {}\".format(type(m))\n                    )\n        cmd_modules.append(HACommandModule())\n\n        self.overseer_agent = overseer_agent\n        self.host = host\n        self.port = port\n        self.poc = poc\n        if self.poc:\n            self.poc_key = \"admin\"\n        else:\n            if len(ca_cert) <= 0:\n                raise Exception(\"missing CA Cert file name\")\n            self.ca_cert = ca_cert\n            if len(client_cert) <= 0:\n                raise Exception(\"missing Client Cert file name\")\n            self.client_cert = client_cert\n            if len(client_key) <= 0:\n                raise Exception(\"missing Client Key file name\")\n            self.client_key = client_key\n            if not isinstance(self.overseer_agent, OverseerAgent):\n                raise Exception(\"overseer_agent is missing but must be provided for secure context.\")\n            self.overseer_agent.set_secure_context(\n                ca_path=self.ca_cert, cert_path=self.client_cert, prv_key_path=self.client_key\n            )\n        if self.overseer_agent:\n            self.overseer_agent.start(self._overseer_callback)\n        self.server_cn = server_cn\n        self.debug = debug\n\n        # for overseer agent\n        self.ssid = None\n\n        # for login\n        self.token = None\n        self.login_result = None\n        if auto_login:\n            self.auto_login = True\n            if not user_name:\n                raise Exception(\"for auto_login, user_name is required.\")\n            self.user_name = user_name\n\n        self.server_cmd_reg = CommandRegister(app_ctx=self)\n        self.client_cmd_reg = CommandRegister(app_ctx=self)\n        self.server_cmd_received = False\n\n        self.all_cmds = []\n        self._load_client_cmds(cmd_modules)\n\n        # for shutdown\n        self.shutdown_received = False\n        self.shutdown_msg = None\n\n        self.server_sess_active = False\n\n        self.sess_monitor_thread = None\n        self.sess_monitor_active = False",
  "def _overseer_callback(self, overseer_agent):\n        sp = overseer_agent.get_primary_sp()\n        self._set_primary_sp(sp)",
  "def _set_primary_sp(self, sp: SP):\n        if sp and sp.primary is True:\n            if self.host != sp.name or self.port != int(sp.admin_port) or self.ssid != sp.service_session_id:\n                # if needing to log out of previous server, this may be where to issue server_execute(\"_logout\")\n                self.host = sp.name\n                self.port = int(sp.admin_port)\n                self.ssid = sp.service_session_id\n                print(\n                    f\"Got primary SP {self.host}:{sp.fl_port}:{self.port} from overseer. Host: {self.host} Admin_port: {self.port} SSID: {self.ssid}\"\n                )\n\n                thread = threading.Thread(target=self._login_sp)\n                thread.start()",
  "def _login_sp(self):\n        if not self._auto_login():\n            print(\"cannot log in, shutting down...\")\n            self.shutdown_received = True",
  "def _auto_login(self):\n        try_count = 0\n        while try_count < 5:\n            if self.poc:\n                self.login_with_poc(username=self.user_name, poc_key=self.poc_key)\n                print(f\"login_result: {self.login_result} token: {self.token}\")\n                if self.login_result == \"OK\":\n                    return True\n                elif self.login_result == \"REJECT\":\n                    print(\"Incorrect key for POC mode.\")\n                    return False\n                else:\n                    print(\"Communication Error - please try later\")\n                    try_count += 1\n            else:\n                self.login(username=self.user_name)\n                if self.login_result == \"OK\":\n                    return True\n                elif self.login_result == \"REJECT\":\n                    print(\"Incorrect user name or certificate.\")\n                    return False\n                else:\n                    print(\"Communication Error - please try later\")\n                    try_count += 1\n            time.sleep(1.0)\n        return False",
  "def _load_client_cmds(self, cmd_modules):\n        if cmd_modules:\n            for m in cmd_modules:\n                self.client_cmd_reg.register_module(m, include_invisible=False)\n        self.client_cmd_reg.finalize(self.register_command)",
  "def register_command(self, cmd_entry):\n        self.all_cmds.append(cmd_entry.name)",
  "def start_session_monitor(self, session_ended_callback, interval=5):\n        if self.sess_monitor_thread and self.sess_monitor_thread.is_alive():\n            self.close_session_monitor()\n        self.sess_monitor_thread = threading.Thread(\n            target=self._check_session, args=(session_ended_callback, interval), daemon=True\n        )\n        self.sess_monitor_active = True\n        self.sess_monitor_thread.start()",
  "def close_session_monitor(self):\n        self.sess_monitor_active = False\n        if self.sess_monitor_thread and self.sess_monitor_thread.is_alive():\n            self.sess_monitor_thread.join()\n            self.sess_monitor_thread = None",
  "def _check_session(self, session_ended_callback, interval):\n        error_msg = \"\"\n        connection_error_counter = 0\n        while True:\n            time.sleep(interval)\n\n            if not self.sess_monitor_active:\n                return\n\n            if self.shutdown_received:\n                error_msg = self.shutdown_msg\n                break\n\n            resp = self.server_execute(\"_check_session\")\n            status = resp[\"status\"]\n\n            connection_error_counter += 1\n            if status != APIStatus.ERROR_SERVER_CONNECTION:\n                connection_error_counter = 0\n\n            if status in APIStatus.ERROR_INACTIVE_SESSION or (\n                status in APIStatus.ERROR_SERVER_CONNECTION and connection_error_counter > 60 // interval\n            ):\n                for item in resp[\"data\"]:\n                    if item[\"type\"] == \"error\":\n                        error_msg = item[\"data\"]\n                break\n\n        self.server_sess_active = False\n        session_ended_callback(error_msg)",
  "def logout(self):\n        \"\"\"Send logout command to server.\"\"\"\n        resp = self.server_execute(\"_logout\")\n        self.server_sess_active = False\n        return resp",
  "def login(self, username: str):\n        \"\"\"Login using certification files and retrieve server side commands.\n\n        Args:\n            username: Username\n\n        Returns:\n            A dict of status and details\n        \"\"\"\n        self.login_result = None\n        self._try_command(f\"_cert_login {username}\", _LoginReplyProcessor())\n        if self.login_result is None:\n            return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": \"Communication Error - please try later\"}\n        elif self.login_result == \"REJECT\":\n            return {\"status\": APIStatus.ERROR_CERT, \"details\": \"Incorrect user name or certificate\"}\n\n        # get command list from server\n        self.server_cmd_received = False\n        self._try_command(\"_commands\", _CmdListReplyProcessor())\n        self.server_cmd_reg.finalize(self.register_command)\n        if not self.server_cmd_received:\n            return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": \"Communication Error - please try later\"}\n\n        self.server_sess_active = True\n        return {\"status\": APIStatus.SUCCESS, \"details\": \"Login success\"}",
  "def login_with_poc(self, username: str, poc_key: str):\n        \"\"\"Login using key for proof of concept example.\n\n        Args:\n            username: Username\n            poc_key: key used for proof of concept admin login\n\n        Returns:\n            A dict of login status and details\n        \"\"\"\n        self.login_result = None\n        self._try_command(f\"_login {username} {poc_key}\", _LoginReplyProcessor())\n        if self.login_result is None:\n            return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": \"Communication Error - please try later\"}\n        elif self.login_result == \"REJECT\":\n            return {\"status\": APIStatus.ERROR_CERT, \"details\": \"Incorrect user name or certificate\"}\n\n        # get command list from server\n        self.server_cmd_received = False\n        self._try_command(\"_commands\", _CmdListReplyProcessor())\n        self.server_cmd_reg.finalize(self.register_command)\n        if not self.server_cmd_received:\n            return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": \"Communication Error - please try later\"}\n\n        self.server_sess_active = True\n        return {\"status\": APIStatus.SUCCESS, \"details\": \"Login success\"}",
  "def _send_to_sock(self, sock, command, process_json_func):\n        conn = Connection(sock, self)\n        conn.append_command(command)\n        if self.token:\n            conn.append_token(self.token)\n\n        conn.close()\n        ok = receive_and_process(sock, process_json_func)\n        if not ok:\n            process_json_func(\n                make_error(\"Failed to communicate with Admin Server {} on {}\".format(self.host, self.port))\n            )",
  "def _process_server_reply(self, resp):\n        \"\"\"Process the server reply and store the status/details into API's `command_result`\n\n        Args:\n            resp: The raw response that returns by the server.\n        \"\"\"\n        if self.debug:\n            print(\"DEBUG: Server Reply: {}\".format(resp))\n        # this resp is what is usually directly used to return, straight from server\n        self.set_command_result(resp)\n        reply_processor = _DefaultReplyProcessor() if self.reply_processor is None else self.reply_processor\n\n        reply_processor.reply_start(self, resp)\n\n        if resp is not None:\n            data = resp[\"data\"]\n            for item in data:\n                it = item[\"type\"]\n                if it == \"string\":\n                    reply_processor.process_string(self, item[\"data\"])\n                elif it == \"success\":\n                    reply_processor.process_success(self, item[\"data\"])\n                elif it == \"error\":\n                    reply_processor.process_error(self, item[\"data\"])\n                    break\n                elif it == \"table\":\n                    table = Table(None)\n                    table.set_rows(item[\"rows\"])\n                    reply_processor.process_table(self, table)\n                elif it == \"dict\":\n                    reply_processor.process_dict(self, item[\"data\"])\n                elif it == \"token\":\n                    reply_processor.process_token(self, item[\"data\"])\n                elif it == \"shutdown\":\n                    reply_processor.process_shutdown(self, item[\"data\"])\n                    break\n                else:\n                    reply_processor.protocol_error(self, \"Invalid item type: \" + it)\n                    break\n        else:\n            reply_processor.protocol_error(self, \"Protocol Error\")\n\n        reply_processor.reply_done(self)",
  "def _try_command(self, command, reply_processor):\n        \"\"\"Try to execute a command on server side.\n\n        Args:\n            command: The command to execute.\n            reply_processor: An instance of ReplyProcessor\n\n        \"\"\"\n        # process_json_func can't return data because how \"receive_and_process\" is written.\n        self.reply_processor = reply_processor\n        process_json_func = self._process_server_reply\n        try:\n            if not self.poc:\n                # SSL communication\n                ctx = ssl.create_default_context()\n                ctx.verify_mode = ssl.CERT_REQUIRED\n                ctx.check_hostname = False\n\n                ctx.load_verify_locations(self.ca_cert)\n                ctx.load_cert_chain(certfile=self.client_cert, keyfile=self.client_key)\n\n                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n                    with ctx.wrap_socket(sock) as ssock:\n                        ssock.connect((self.host, self.port))\n                        if self.server_cn:\n                            # validate server CN\n                            cn = get_certificate_common_name(ssock.getpeercert())\n                            if cn != self.server_cn:\n                                process_json_func(\n                                    make_error(\"wrong server: expecting {} but connected {}\".format(self.server_cn, cn))\n                                )\n                                return\n\n                        self._send_to_sock(ssock, command, process_json_func)\n            else:\n                # poc without certs\n                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n                    sock.connect((self.host, self.port))\n                    self._send_to_sock(sock, command, process_json_func)\n        except Exception as ex:\n            if self.debug:\n                traceback.print_exc()\n\n            process_json_func(\n                make_error(\"Failed to communicate with Admin Server {} on {}: {}\".format(self.host, self.port, ex))\n            )",
  "def do_command(self, command):\n        \"\"\"A convenient method to call commands using string.\n\n        Args:\n          command (str): command\n\n        Returns:\n            Object containing status and details (or direct response from server, which originally was just time and data)\n        \"\"\"\n        args = split_to_args(command)\n        cmd_name = args[0]\n        self.set_command_result(None)\n\n        # check client side commands\n        entries = self.client_cmd_reg.get_command_entries(cmd_name)\n        if len(entries) > 1:\n            return {\n                \"status\": APIStatus.ERROR_SYNTAX,\n                \"details\": f\"Ambiguous client command {cmd_name} - qualify with scope\",\n            }\n        elif len(entries) == 1:\n            self.set_command_result(None)\n            ent = entries[0]\n            return_result = ent.handler(args, self)\n            result = self.get_command_result()\n            if return_result:\n                return return_result\n            if result is None:\n                return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": \"Client did not respond\"}\n            return result\n\n        # check server side commands\n        entries = self.server_cmd_reg.get_command_entries(cmd_name)\n        if len(entries) <= 0:\n            return {\n                \"status\": APIStatus.ERROR_SYNTAX,\n                \"details\": f\"Command {cmd_name} not found in server or client cmds\",\n            }\n        elif len(entries) > 1:\n            return {\n                \"status\": APIStatus.ERROR_SYNTAX,\n                \"details\": f\"Ambiguous server command {cmd_name} - qualify with scope\",\n            }\n        return self.server_execute(command)",
  "def server_execute(self, command, reply_processor=None):\n        if not self.server_sess_active:\n            return {\"status\": APIStatus.ERROR_INACTIVE_SESSION, \"details\": \"API session is inactive\"}\n\n        self.set_command_result(None)\n        start = time.time()\n        self._try_command(command, reply_processor)\n        secs = time.time() - start\n        usecs = int(secs * 1000000)\n\n        if self.debug:\n            print(f\"DEBUG: server_execute Done [{usecs} usecs] {datetime.now()}\")\n\n        result = self.get_command_result()\n        if result is None:\n            return {\"status\": APIStatus.ERROR_SERVER_CONNECTION, \"details\": \"Server did not respond\"}\n        if \"data\" in result:\n            for item in result[\"data\"]:\n                if item[\"type\"] == \"error\":\n                    if \"session_inactive\" in item[\"data\"]:\n                        result.update({\"status\": APIStatus.ERROR_INACTIVE_SESSION})\n                    elif any(\n                        err in item[\"data\"] for err in (\"Failed to communicate with Admin Server\", \"wrong server\")\n                    ):\n                        result.update({\"status\": APIStatus.ERROR_SERVER_CONNECTION})\n        if \"status\" not in result:\n            result.update({\"status\": APIStatus.SUCCESS})\n        self.set_command_result(result)\n        return result",
  "def api_command_wrapper(api_command_result):\n    \"\"\"Prints the result of the command and raises RuntimeError to interrupt command sequence if there is an error.\n\n    Args:\n        api_command_result: result of the api command\n\n    \"\"\"\n    print(api_command_result)\n    if not api_command_result[\"status\"] == \"SUCCESS\":\n        raise RuntimeError(\"command was not successful!\")\n\n    return api_command_result",
  "class FLAdminAPIRunner:\n    def __init__(\n        self,\n        username,\n        admin_dir,\n        poc=False,\n        debug=False,\n    ):\n        \"\"\"Initializes and logs into an FLAdminAPI instance.\n\n        The default locations for certs, keys, and directories are used.\n\n        Args:\n            username: string of username to log in with\n            admin_dir: string of root admin dir containing the startup dir\n            poc: whether to run in poc mode without SSL certs\n            debug: whether to turn on debug mode\n        \"\"\"\n        assert isinstance(username, str), \"username must be str\"\n        self.username = username\n        assert isinstance(admin_dir, str), \"admin_dir must be str\"\n        if poc:\n            self.poc = True\n        else:\n            self.poc = False\n        if debug:\n            debug = True\n\n        try:\n            os.chdir(admin_dir)\n            workspace = os.path.join(admin_dir, \"startup\")\n            conf = FLAdminClientStarterConfigurator(app_root=workspace, admin_config_file_name=\"fed_admin.json\")\n            conf.configure()\n        except ConfigError as ex:\n            print(\"ConfigError:\", str(ex))\n\n        try:\n            admin_config = conf.config_data[\"admin\"]\n        except KeyError:\n            print(\"Missing admin section in fed_admin configuration.\")\n\n        ca_cert = admin_config.get(\"ca_cert\", \"\")\n        client_cert = admin_config.get(\"client_cert\", \"\")\n        client_key = admin_config.get(\"client_key\", \"\")\n\n        if admin_config.get(\"with_ssl\"):\n            if len(ca_cert) <= 0:\n                print(\"missing CA Cert file name field ca_cert in fed_admin configuration\")\n                return\n\n            if len(client_cert) <= 0:\n                print(\"missing Client Cert file name field client_cert in fed_admin configuration\")\n                return\n\n            if len(client_key) <= 0:\n                print(\"missing Client Key file name field client_key in fed_admin configuration\")\n                return\n        else:\n            ca_cert = None\n            client_key = None\n            client_cert = None\n\n        upload_dir = admin_config.get(\"upload_dir\")\n        download_dir = admin_config.get(\"download_dir\")\n        if not os.path.isdir(download_dir):\n            os.makedirs(download_dir)\n\n        assert os.path.isdir(admin_dir), f\"admin directory does not exist at {admin_dir}\"\n        if not self.poc:\n            assert os.path.isfile(ca_cert), f\"rootCA.pem does not exist at {ca_cert}\"\n            assert os.path.isfile(client_cert), f\"client.crt does not exist at {client_cert}\"\n            assert os.path.isfile(client_key), f\"client.key does not exist at {client_key}\"\n\n        # Connect with admin client\n        self.api = FLAdminAPI(\n            ca_cert=ca_cert,\n            client_cert=client_cert,\n            client_key=client_key,\n            upload_dir=upload_dir,\n            download_dir=download_dir,\n            overseer_agent=conf.overseer_agent,\n            user_name=username,\n            poc=self.poc,\n            debug=debug,\n        )\n\n        # wait for admin to login\n        _t_warning_start = time.time()\n        while not self.api.server_sess_active:\n            time.sleep(0.5)\n            if time.time() - _t_warning_start > 10:\n                print(\"Admin is taking a long time to log in to the server...\")\n                print(\"Make sure the server is up and available, and all configurations are correct.\")\n                _t_warning_start = time.time()\n\n    def run(\n        self,\n        job_folder_name,\n    ):\n        \"\"\"An example script to upload, deploy, and start a specified app.\n\n        Note that the app folder must be in upload_dir already. Prints the command to be executed first so it is easy\n        to follow along as the commands run.\n\n        Args:\n            job_folder_name: name of job folder to submit, either relative to the upload_dir specified in the fed_admin.json config, or absolute path\n\n        \"\"\"\n        try:\n            print(\"api.check_status(TargetType.SERVER)\")\n            api_command_wrapper(self.api.check_status(TargetType.SERVER))\n            print(f'api.submit_job(\"{job_folder_name}\")')\n            api_command_wrapper(self.api.submit_job(job_folder_name))\n            time.sleep(1)\n            print(\"api.check_status(TargetType.SERVER)\")\n            api_command_wrapper(self.api.check_status(TargetType.SERVER))\n            # The following wait_until can be put into a loop that has other behavior other than waiting until clients\n            # are in a status of stopped. For this code, the app is expected to stop, or this may not end.\n            print(\"api.wait_until_client_status()\")\n            wait_result = api_command_wrapper(self.api.wait_until_client_status())\n            print(wait_result)\n            print(\"api.check_status(TargetType.SERVER)\")\n            api_command_wrapper(self.api.check_status(TargetType.SERVER))\n            # now server engine status should be stopped\n            time.sleep(10)  # wait for clients to stop in case they take longer than server to stop\n            print(\"api.check_status(TargetType.CLIENT)\")\n            api_command_wrapper(self.api.check_status(TargetType.CLIENT))\n        except RuntimeError as e:\n            print(f\"There was an exception: {e}\")",
  "def __init__(\n        self,\n        username,\n        admin_dir,\n        poc=False,\n        debug=False,\n    ):\n        \"\"\"Initializes and logs into an FLAdminAPI instance.\n\n        The default locations for certs, keys, and directories are used.\n\n        Args:\n            username: string of username to log in with\n            admin_dir: string of root admin dir containing the startup dir\n            poc: whether to run in poc mode without SSL certs\n            debug: whether to turn on debug mode\n        \"\"\"\n        assert isinstance(username, str), \"username must be str\"\n        self.username = username\n        assert isinstance(admin_dir, str), \"admin_dir must be str\"\n        if poc:\n            self.poc = True\n        else:\n            self.poc = False\n        if debug:\n            debug = True\n\n        try:\n            os.chdir(admin_dir)\n            workspace = os.path.join(admin_dir, \"startup\")\n            conf = FLAdminClientStarterConfigurator(app_root=workspace, admin_config_file_name=\"fed_admin.json\")\n            conf.configure()\n        except ConfigError as ex:\n            print(\"ConfigError:\", str(ex))\n\n        try:\n            admin_config = conf.config_data[\"admin\"]\n        except KeyError:\n            print(\"Missing admin section in fed_admin configuration.\")\n\n        ca_cert = admin_config.get(\"ca_cert\", \"\")\n        client_cert = admin_config.get(\"client_cert\", \"\")\n        client_key = admin_config.get(\"client_key\", \"\")\n\n        if admin_config.get(\"with_ssl\"):\n            if len(ca_cert) <= 0:\n                print(\"missing CA Cert file name field ca_cert in fed_admin configuration\")\n                return\n\n            if len(client_cert) <= 0:\n                print(\"missing Client Cert file name field client_cert in fed_admin configuration\")\n                return\n\n            if len(client_key) <= 0:\n                print(\"missing Client Key file name field client_key in fed_admin configuration\")\n                return\n        else:\n            ca_cert = None\n            client_key = None\n            client_cert = None\n\n        upload_dir = admin_config.get(\"upload_dir\")\n        download_dir = admin_config.get(\"download_dir\")\n        if not os.path.isdir(download_dir):\n            os.makedirs(download_dir)\n\n        assert os.path.isdir(admin_dir), f\"admin directory does not exist at {admin_dir}\"\n        if not self.poc:\n            assert os.path.isfile(ca_cert), f\"rootCA.pem does not exist at {ca_cert}\"\n            assert os.path.isfile(client_cert), f\"client.crt does not exist at {client_cert}\"\n            assert os.path.isfile(client_key), f\"client.key does not exist at {client_key}\"\n\n        # Connect with admin client\n        self.api = FLAdminAPI(\n            ca_cert=ca_cert,\n            client_cert=client_cert,\n            client_key=client_key,\n            upload_dir=upload_dir,\n            download_dir=download_dir,\n            overseer_agent=conf.overseer_agent,\n            user_name=username,\n            poc=self.poc,\n            debug=debug,\n        )\n\n        # wait for admin to login\n        _t_warning_start = time.time()\n        while not self.api.server_sess_active:\n            time.sleep(0.5)\n            if time.time() - _t_warning_start > 10:\n                print(\"Admin is taking a long time to log in to the server...\")\n                print(\"Make sure the server is up and available, and all configurations are correct.\")\n                _t_warning_start = time.time()",
  "def run(\n        self,\n        job_folder_name,\n    ):\n        \"\"\"An example script to upload, deploy, and start a specified app.\n\n        Note that the app folder must be in upload_dir already. Prints the command to be executed first so it is easy\n        to follow along as the commands run.\n\n        Args:\n            job_folder_name: name of job folder to submit, either relative to the upload_dir specified in the fed_admin.json config, or absolute path\n\n        \"\"\"\n        try:\n            print(\"api.check_status(TargetType.SERVER)\")\n            api_command_wrapper(self.api.check_status(TargetType.SERVER))\n            print(f'api.submit_job(\"{job_folder_name}\")')\n            api_command_wrapper(self.api.submit_job(job_folder_name))\n            time.sleep(1)\n            print(\"api.check_status(TargetType.SERVER)\")\n            api_command_wrapper(self.api.check_status(TargetType.SERVER))\n            # The following wait_until can be put into a loop that has other behavior other than waiting until clients\n            # are in a status of stopped. For this code, the app is expected to stop, or this may not end.\n            print(\"api.wait_until_client_status()\")\n            wait_result = api_command_wrapper(self.api.wait_until_client_status())\n            print(wait_result)\n            print(\"api.check_status(TargetType.SERVER)\")\n            api_command_wrapper(self.api.check_status(TargetType.SERVER))\n            # now server engine status should be stopped\n            time.sleep(10)  # wait for clients to stop in case they take longer than server to stop\n            print(\"api.check_status(TargetType.CLIENT)\")\n            api_command_wrapper(self.api.check_status(TargetType.CLIENT))\n        except RuntimeError as e:\n            print(f\"There was an exception: {e}\")",
  "class FLAdminAPIResponse(dict):\n    def __init__(self, status: APIStatus, details: dict = None, raw: dict = None):\n        \"\"\"Structure containing the response of calls to the api as key value pairs.\n\n        The status key is the primary indicator of the success of a call and can contain APIStatus.SUCCESS or another\n        APIStatus. Most calls will return additional information in the details key, which is also a dictionary of key\n        value pairs. The raw key can optionally have the underlying response from AdminAPI when relevant, particularly\n        when data is received from the server and the status of a call is APIStatus.ERROR_RUNTIME to provide additional\n        information.\n\n        Note that the status in this response primarily indicates that the command submitted successfully. Depending on\n        the command and especially for calls to multiple clients, the contents of details or the raw response should be\n        examined to determine if the execution of the command was successful for each specific client.\n\n        Args:\n            status: APIStatus for primary indicator of the success of a call\n            details: response details\n            raw: raw response from server\n        \"\"\"\n        super().__init__()\n        self[\"status\"] = status  # todo: status.value but it may break existing code\n        if details:\n            self[\"details\"] = details\n        if raw:\n            self[\"raw\"] = raw",
  "class APISyntaxError(Exception):\n    pass",
  "class TargetType(str, Enum):\n    ALL = \"all\"\n    SERVER = \"server\"\n    CLIENT = \"client\"",
  "class FLAdminAPISpec(ABC):\n    @abstractmethod\n    def check_status(self, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        \"\"\"Checks and returns the FL status.\n\n        If target_type is server, the call does not wait for the server to retrieve\n        information on the clients but returns the last information the server had at the time this call is made.\n\n        If target_type is client, specific clients can be specified in targets, and this call generally takes longer\n        than the function to just check the FL server status because this one waits for communication from the server to\n        client then back.\n\n        Note that this is still the previous training check_status, and there will be a new call to get status through\n        InfoCollector, which will be able to get information from components.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def submit_job(self, job_folder: str) -> FLAdminAPIResponse:\n        \"\"\"Submit a job.\n\n        Assumes job folder is in the upload_dir set in API init.\n\n        Args:\n            job_folder (str): name of the job folder in upload_dir to submit\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def clone_job(self, job_id: str) -> FLAdminAPIResponse:\n        \"\"\"Clone a job that exists by copying the job contents and providing a new job_id.\n\n        Args:\n            job_id (str): job id of the job to clone\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_jobs(self, options: str = None) -> FLAdminAPIResponse:\n        \"\"\"List the jobs in the system.\n\n        Args:\n            options (str): the options string as provided to the list_jobs command for admin client.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def download_job(self, job_id: str) -> FLAdminAPIResponse:\n        \"\"\"Download the specified job in the system.\n\n        Args:\n            job_id (str): Job id for the job to download\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def abort_job(self, job_id: str) -> FLAdminAPIResponse:\n        \"\"\"Abort a job that is running.\n\n        Args:\n            job_id (str): the job id to abort\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def delete_job(self, job_id: str) -> FLAdminAPIResponse:\n        \"\"\"Delete the specified job and workspace from the permanent store.\n\n        Args:\n            job_id (str): the job id to delete\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def abort(self, job_id: str, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        \"\"\"Issue a command to abort training.\n\n        Args:\n            job_id (str): job id\n            target_type: server | client\n            targets: if target_type is client, targets can optionally be a list of client names\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def restart(self, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        \"\"\"Issue a command to restart the specified target.\n\n        If the target is server, all FL clients will be restarted as well.\n\n        Args:\n            target_type: server | client\n            targets: if target_type is client, targets can optionally be a list of client names\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def shutdown(self, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        \"\"\"Issue a command to stop FL entirely for a specific FL client or specific FL clients.\n\n        Note that the targets will not be able to start with an API command after shutting down.\n\n        Args:\n            target_type: server | client\n            targets: if target_type is client, targets can optionally be a list of client names\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def remove_client(self, targets: List[str]) -> FLAdminAPIResponse:\n        \"\"\"Issue a command to remove a specific FL client or FL clients.\n\n        Note that the targets will not be able to start with an API command after shutting down. Also, you will not be\n        able to issue admin commands through the server to that client until the client is restarted (this includes\n        being able to issue the restart command through the API).\n\n        Args:\n            targets: a list of client names\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def set_timeout(self, timeout: float) -> FLAdminAPIResponse:\n        \"\"\"Sets the timeout for admin commands on the server in seconds.\n\n        This timeout is the maximum amount of time the server will wait for replies from clients. If the timeout is too\n        short, the server may not receive a response because clients may not have a chance to reply.\n\n        Args:\n            timeout: timeout in seconds of admin commands to set on the server\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_sp(self) -> FLAdminAPIResponse:\n        \"\"\"Gets the information on the available servers (service providers).\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_active_sp(self) -> FLAdminAPIResponse:\n        \"\"\"Gets the active server (service provider).\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def promote_sp(self, sp_end_point: str) -> FLAdminAPIResponse:\n        \"\"\"Sends command through overseer_agent to promote the specified sp_end_point to become the active server.\n\n        Args:\n            sp_end_point: service provider end point to promote to active in the form of server:fl_port:admin_port like example.com:8002:8003\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_available_apps_to_upload(self):\n        pass\n\n    @abstractmethod\n    def ls_target(self, target: str, options: str = None, path: str = None) -> FLAdminAPIResponse:\n        \"\"\"Issue ls command to retrieve the contents of the path.\n\n        Sends the shell command to get the directory listing of the target allowing for options that the ls command\n        of admin client allows. If no path is specified, the contents of the working directory are returned. The target\n        can be \"server\" or a specific client name for example \"site2\". The allowed options are: \"-a\" for all, \"-l\" to\n        use a long listing format, \"-t\" to sort by modification time newest first, \"-S\" to sort by file size largest\n        first, \"-R\" to list subdirectories recursively, \"-u\" with -l to show access time otherwise sort by access time.\n\n        Args:\n            target (str):  either server or single client's client name.\n            options (str): the options string as provided to the ls command for admin client.\n            path (str):    optionally, the path to specify (relative to the working directory of the specified target)\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def cat_target(self, target: str, options: str = None, file: str = None) -> FLAdminAPIResponse:\n        \"\"\"Issue cat command.\n\n        Sends the shell command to get the contents of the target's specified file allowing for options that the cat\n        command of admin client allows. The target can be \"server\" or a specific client name for example \"site2\". The\n        file is required and should contain the relative path to the file from the working directory of the target. The\n        allowed options are \"-n\" to number all output lines, \"-b\" to number nonempty output lines, \"-s\" to suppress\n        repeated empty output lines, and \"-T\" to display TAB characters as ^I.\n\n        Args:\n            target (str):  either server or single client's client name.\n            options (str): the options string as provided to the ls command for admin client.\n            file (str):    the path to the file to return the contents of\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def tail_target_log(self, target: str, options: str = None) -> FLAdminAPIResponse:\n        \"\"\"Returns the end of target's log allowing for options that the tail of admin client allows.\n\n        The option \"-n\" can be used to specify the number of lines for example \"-n 100\", or \"-c\" can specify the\n        number of bytes.\n\n        Args:\n            target (str):  either server or single client's client name.\n            options (str): the options string as provided to the tail command for admin client. For this command, \"-n\" can be\n                     used to specify the number of lines for example \"-n 100\", or \"-c\" can specify the number of bytes.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def env_target(self, target: str) -> FLAdminAPIResponse:\n        \"\"\"Get the environment variables of the specified target.\n\n        Args:\n            target (str):  either server or single client's client name.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_working_directory(self, target: str) -> FLAdminAPIResponse:\n        \"\"\"Gets the workspace root directory of the specified target.\n\n        Args:\n            target (str):  either server or single client's client name.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def grep_target(\n        self, target: str, options: str = None, pattern: str = None, file: str = None\n    ) -> FLAdminAPIResponse:\n        \"\"\"Issue grep command.\n\n        Sends the shell command to grep the contents of the target's specified file allowing for options that the grep\n        command of admin client allows. The target can be \"server\" or a specific client name for example \"site2\". The\n        file is required and should contain the relative path to the file from the working directory of the target. The\n        pattern is also required. The allowed options are \"-n\" to print line number with output lines, \"-i\" to ignore\n        case distinctions, and \"-b\" to print the byte offset with output lines.\n\n        Args:\n            target (str):  either server or single client's client name.\n            options (str): the options string as provided to the grep command for admin client.\n            pattern (str): the pattern to search for\n            file (str):    the path to the file to grep\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def show_stats(\n        self, job_id: str, target_type: TargetType, targets: Optional[List[str]] = None\n    ) -> FLAdminAPIResponse:\n        \"\"\"Gets and shows stats from the Info Collector.\n\n        Args:\n            job_id (str): job id\n            target_type: server | client\n            targets: if target_type is client, targets can optionally be a list of client names\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n\n    @abstractmethod\n    def show_errors(\n        self, job_id: str, target_type: TargetType, targets: Optional[List[str]] = None\n    ) -> FLAdminAPIResponse:\n        \"\"\"Gets and shows errors from the Info Collector.\n\n        Args:\n            job_id (str): job id\n            target_type: server | client\n            targets: if target_type is client, targets can optionally be a list of client names\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n\n    @abstractmethod\n    def reset_errors(self, job_id: str) -> FLAdminAPIResponse:\n        \"\"\"Resets the collector errors.\n\n        Args:\n            job_id (str): job id\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n\n    @abstractmethod\n    def get_connected_client_list(self) -> FLAdminAPIResponse:\n        \"\"\"A convenience function to get a list of the clients currently connected to the FL server.\n\n        Operates through the check status server call. Note that this returns the client list based on the last known\n        statuses on the server, so it can be possible for a client to be disconnected and not yet removed from the list\n        of connected clients.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def wait_until_server_status(\n        self,\n        interval: int = 20,\n        timeout: int = None,\n        callback: Callable[[FLAdminAPIResponse], bool] = None,\n        fail_attempts: int = 3,\n    ) -> FLAdminAPIResponse:\n        \"\"\"Wait until provided callback returns True.\n\n        There is the option to specify a timeout and interval to check the server status. If no callback function is\n        provided, the default callback returns True when the server\n        status is \"training stopped\". A custom callback can be provided to add logic to handle checking for other\n        conditions. A timeout should be set in case there are any error conditions that result in the system being stuck\n        in a state where the callback never returns True.\n\n        Args:\n            interval (int): in seconds, the time between consecutive checks of the server\n            timeout (int): if set, the amount of time this function will run until before returning a response message\n            callback: the reply from check_status_server() will be passed to the callback, along with any additional kwargs\n            which can go on to perform additional logic.\n            fail_attempts (int): number of consecutive failed attempts of getting the server status before returning with ERROR_RUNTIME.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def __init__(self, status: APIStatus, details: dict = None, raw: dict = None):\n        \"\"\"Structure containing the response of calls to the api as key value pairs.\n\n        The status key is the primary indicator of the success of a call and can contain APIStatus.SUCCESS or another\n        APIStatus. Most calls will return additional information in the details key, which is also a dictionary of key\n        value pairs. The raw key can optionally have the underlying response from AdminAPI when relevant, particularly\n        when data is received from the server and the status of a call is APIStatus.ERROR_RUNTIME to provide additional\n        information.\n\n        Note that the status in this response primarily indicates that the command submitted successfully. Depending on\n        the command and especially for calls to multiple clients, the contents of details or the raw response should be\n        examined to determine if the execution of the command was successful for each specific client.\n\n        Args:\n            status: APIStatus for primary indicator of the success of a call\n            details: response details\n            raw: raw response from server\n        \"\"\"\n        super().__init__()\n        self[\"status\"] = status  # todo: status.value but it may break existing code\n        if details:\n            self[\"details\"] = details\n        if raw:\n            self[\"raw\"] = raw",
  "def check_status(self, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        \"\"\"Checks and returns the FL status.\n\n        If target_type is server, the call does not wait for the server to retrieve\n        information on the clients but returns the last information the server had at the time this call is made.\n\n        If target_type is client, specific clients can be specified in targets, and this call generally takes longer\n        than the function to just check the FL server status because this one waits for communication from the server to\n        client then back.\n\n        Note that this is still the previous training check_status, and there will be a new call to get status through\n        InfoCollector, which will be able to get information from components.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def submit_job(self, job_folder: str) -> FLAdminAPIResponse:\n        \"\"\"Submit a job.\n\n        Assumes job folder is in the upload_dir set in API init.\n\n        Args:\n            job_folder (str): name of the job folder in upload_dir to submit\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def clone_job(self, job_id: str) -> FLAdminAPIResponse:\n        \"\"\"Clone a job that exists by copying the job contents and providing a new job_id.\n\n        Args:\n            job_id (str): job id of the job to clone\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def list_jobs(self, options: str = None) -> FLAdminAPIResponse:\n        \"\"\"List the jobs in the system.\n\n        Args:\n            options (str): the options string as provided to the list_jobs command for admin client.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def download_job(self, job_id: str) -> FLAdminAPIResponse:\n        \"\"\"Download the specified job in the system.\n\n        Args:\n            job_id (str): Job id for the job to download\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def abort_job(self, job_id: str) -> FLAdminAPIResponse:\n        \"\"\"Abort a job that is running.\n\n        Args:\n            job_id (str): the job id to abort\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def delete_job(self, job_id: str) -> FLAdminAPIResponse:\n        \"\"\"Delete the specified job and workspace from the permanent store.\n\n        Args:\n            job_id (str): the job id to delete\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def abort(self, job_id: str, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        \"\"\"Issue a command to abort training.\n\n        Args:\n            job_id (str): job id\n            target_type: server | client\n            targets: if target_type is client, targets can optionally be a list of client names\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def restart(self, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        \"\"\"Issue a command to restart the specified target.\n\n        If the target is server, all FL clients will be restarted as well.\n\n        Args:\n            target_type: server | client\n            targets: if target_type is client, targets can optionally be a list of client names\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def shutdown(self, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        \"\"\"Issue a command to stop FL entirely for a specific FL client or specific FL clients.\n\n        Note that the targets will not be able to start with an API command after shutting down.\n\n        Args:\n            target_type: server | client\n            targets: if target_type is client, targets can optionally be a list of client names\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def remove_client(self, targets: List[str]) -> FLAdminAPIResponse:\n        \"\"\"Issue a command to remove a specific FL client or FL clients.\n\n        Note that the targets will not be able to start with an API command after shutting down. Also, you will not be\n        able to issue admin commands through the server to that client until the client is restarted (this includes\n        being able to issue the restart command through the API).\n\n        Args:\n            targets: a list of client names\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def set_timeout(self, timeout: float) -> FLAdminAPIResponse:\n        \"\"\"Sets the timeout for admin commands on the server in seconds.\n\n        This timeout is the maximum amount of time the server will wait for replies from clients. If the timeout is too\n        short, the server may not receive a response because clients may not have a chance to reply.\n\n        Args:\n            timeout: timeout in seconds of admin commands to set on the server\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def list_sp(self) -> FLAdminAPIResponse:\n        \"\"\"Gets the information on the available servers (service providers).\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def get_active_sp(self) -> FLAdminAPIResponse:\n        \"\"\"Gets the active server (service provider).\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def promote_sp(self, sp_end_point: str) -> FLAdminAPIResponse:\n        \"\"\"Sends command through overseer_agent to promote the specified sp_end_point to become the active server.\n\n        Args:\n            sp_end_point: service provider end point to promote to active in the form of server:fl_port:admin_port like example.com:8002:8003\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def get_available_apps_to_upload(self):\n        pass",
  "def ls_target(self, target: str, options: str = None, path: str = None) -> FLAdminAPIResponse:\n        \"\"\"Issue ls command to retrieve the contents of the path.\n\n        Sends the shell command to get the directory listing of the target allowing for options that the ls command\n        of admin client allows. If no path is specified, the contents of the working directory are returned. The target\n        can be \"server\" or a specific client name for example \"site2\". The allowed options are: \"-a\" for all, \"-l\" to\n        use a long listing format, \"-t\" to sort by modification time newest first, \"-S\" to sort by file size largest\n        first, \"-R\" to list subdirectories recursively, \"-u\" with -l to show access time otherwise sort by access time.\n\n        Args:\n            target (str):  either server or single client's client name.\n            options (str): the options string as provided to the ls command for admin client.\n            path (str):    optionally, the path to specify (relative to the working directory of the specified target)\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def cat_target(self, target: str, options: str = None, file: str = None) -> FLAdminAPIResponse:\n        \"\"\"Issue cat command.\n\n        Sends the shell command to get the contents of the target's specified file allowing for options that the cat\n        command of admin client allows. The target can be \"server\" or a specific client name for example \"site2\". The\n        file is required and should contain the relative path to the file from the working directory of the target. The\n        allowed options are \"-n\" to number all output lines, \"-b\" to number nonempty output lines, \"-s\" to suppress\n        repeated empty output lines, and \"-T\" to display TAB characters as ^I.\n\n        Args:\n            target (str):  either server or single client's client name.\n            options (str): the options string as provided to the ls command for admin client.\n            file (str):    the path to the file to return the contents of\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def tail_target_log(self, target: str, options: str = None) -> FLAdminAPIResponse:\n        \"\"\"Returns the end of target's log allowing for options that the tail of admin client allows.\n\n        The option \"-n\" can be used to specify the number of lines for example \"-n 100\", or \"-c\" can specify the\n        number of bytes.\n\n        Args:\n            target (str):  either server or single client's client name.\n            options (str): the options string as provided to the tail command for admin client. For this command, \"-n\" can be\n                     used to specify the number of lines for example \"-n 100\", or \"-c\" can specify the number of bytes.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def env_target(self, target: str) -> FLAdminAPIResponse:\n        \"\"\"Get the environment variables of the specified target.\n\n        Args:\n            target (str):  either server or single client's client name.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def get_working_directory(self, target: str) -> FLAdminAPIResponse:\n        \"\"\"Gets the workspace root directory of the specified target.\n\n        Args:\n            target (str):  either server or single client's client name.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def grep_target(\n        self, target: str, options: str = None, pattern: str = None, file: str = None\n    ) -> FLAdminAPIResponse:\n        \"\"\"Issue grep command.\n\n        Sends the shell command to grep the contents of the target's specified file allowing for options that the grep\n        command of admin client allows. The target can be \"server\" or a specific client name for example \"site2\". The\n        file is required and should contain the relative path to the file from the working directory of the target. The\n        pattern is also required. The allowed options are \"-n\" to print line number with output lines, \"-i\" to ignore\n        case distinctions, and \"-b\" to print the byte offset with output lines.\n\n        Args:\n            target (str):  either server or single client's client name.\n            options (str): the options string as provided to the grep command for admin client.\n            pattern (str): the pattern to search for\n            file (str):    the path to the file to grep\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def show_stats(\n        self, job_id: str, target_type: TargetType, targets: Optional[List[str]] = None\n    ) -> FLAdminAPIResponse:\n        \"\"\"Gets and shows stats from the Info Collector.\n\n        Args:\n            job_id (str): job id\n            target_type: server | client\n            targets: if target_type is client, targets can optionally be a list of client names\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"",
  "def show_errors(\n        self, job_id: str, target_type: TargetType, targets: Optional[List[str]] = None\n    ) -> FLAdminAPIResponse:\n        \"\"\"Gets and shows errors from the Info Collector.\n\n        Args:\n            job_id (str): job id\n            target_type: server | client\n            targets: if target_type is client, targets can optionally be a list of client names\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"",
  "def reset_errors(self, job_id: str) -> FLAdminAPIResponse:\n        \"\"\"Resets the collector errors.\n\n        Args:\n            job_id (str): job id\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"",
  "def get_connected_client_list(self) -> FLAdminAPIResponse:\n        \"\"\"A convenience function to get a list of the clients currently connected to the FL server.\n\n        Operates through the check status server call. Note that this returns the client list based on the last known\n        statuses on the server, so it can be possible for a client to be disconnected and not yet removed from the list\n        of connected clients.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def wait_until_server_status(\n        self,\n        interval: int = 20,\n        timeout: int = None,\n        callback: Callable[[FLAdminAPIResponse], bool] = None,\n        fail_attempts: int = 3,\n    ) -> FLAdminAPIResponse:\n        \"\"\"Wait until provided callback returns True.\n\n        There is the option to specify a timeout and interval to check the server status. If no callback function is\n        provided, the default callback returns True when the server\n        status is \"training stopped\". A custom callback can be provided to add logic to handle checking for other\n        conditions. A timeout should be set in case there are any error conditions that result in the system being stuck\n        in a state where the callback never returns True.\n\n        Args:\n            interval (int): in seconds, the time between consecutive checks of the server\n            timeout (int): if set, the amount of time this function will run until before returning a response message\n            callback: the reply from check_status_server() will be passed to the callback, along with any additional kwargs\n            which can go on to perform additional logic.\n            fail_attempts (int): number of consecutive failed attempts of getting the server status before returning with ERROR_RUNTIME.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        pass",
  "def wrap_with_return_exception_responses(func):\n    \"\"\"Decorator on all FLAdminAPI calls to handle any raised exceptions and return the fitting error status.\"\"\"\n\n    @wraps(func)\n    def wrapper(self, *args, **kwargs):\n        try:\n            reply = func(self, *args, **kwargs)\n            if reply:\n                return reply\n            else:\n                return FLAdminAPIResponse(\n                    APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not generate reply.\"}\n                )\n        except ConnectionRefusedError as e:\n            return FLAdminAPIResponse(APIStatus.ERROR_AUTHENTICATION, {\"message\": \"Error: \" + str(e)})\n        except PermissionError as e:\n            return FLAdminAPIResponse(APIStatus.ERROR_AUTHORIZATION, {\"message\": \"Error: \" + str(e)})\n        except LookupError as e:\n            return FLAdminAPIResponse(APIStatus.ERROR_INVALID_CLIENT, {\"message\": \"Error: \" + str(e)})\n        except APISyntaxError as e:\n            return FLAdminAPIResponse(APIStatus.ERROR_SYNTAX, {\"message\": \"Error: \" + str(e)})\n        except TimeoutError as e:\n            return FLAdminAPIResponse(\n                APIStatus.ERROR_RUNTIME,\n                {\"message\": \"TimeoutError: possibly unable to communicate with server. \" + str(e)},\n            )\n        except Exception as e:\n            return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": \"Exception: \" + str(e)})\n\n    return wrapper",
  "def default_server_status_handling_cb(reply: FLAdminAPIResponse, **kwargs) -> bool:\n    if reply[\"details\"][FLDetailKey.SERVER_ENGINE_STATUS] == \"stopped\":\n        return True\n    else:\n        return False",
  "def default_client_status_handling_cb(reply: FLAdminAPIResponse) -> bool:\n    client_statuses = reply.get(\"details\").get(\"client_statuses\")\n    stopped_client_count = 0\n    for i in range(1, len(client_statuses)):\n        if client_statuses[i][3] == \"No Jobs\":\n            stopped_client_count = stopped_client_count + 1\n    if stopped_client_count == len(client_statuses) - 1:\n        return True\n    else:\n        return False",
  "def default_stats_handling_cb(reply: FLAdminAPIResponse) -> bool:\n    if reply.get(\"details\").get(\"message\").get(\"ServerRunner\").get(\"status\") == \"done\":\n        return True\n    else:\n        return False",
  "class FLAdminAPI(AdminAPI, FLAdminAPISpec):\n    def __init__(\n        self,\n        ca_cert: str = \"\",\n        client_cert: str = \"\",\n        client_key: str = \"\",\n        upload_dir: str = \"\",\n        download_dir: str = \"\",\n        server_cn=None,\n        cmd_modules: Optional[List] = None,\n        overseer_agent: OverseerAgent = None,\n        user_name: str = None,\n        poc=False,\n        debug=False,\n    ):\n        \"\"\"FLAdminAPI serves as foundation for communications to FL server through the AdminAPI.\n\n        Upon initialization, FLAdminAPI will start the overseer agent to get the active server and then try to log in.\n        This happens in a thread, so code that executes after should check that the FLAdminAPI is successfully logged in.\n\n        Args:\n            ca_cert: path to CA Cert file, by default provisioned rootCA.pem\n            client_cert: path to admin client Cert file, by default provisioned as client.crt\n            client_key: path to admin client Key file, by default provisioned as client.key\n            upload_dir: File transfer upload directory. Folders uploaded to the server to be deployed must be here. Folder must already exist and be accessible.\n            download_dir: File transfer download directory. Can be same as upload_dir. Folder must already exist and be accessible.\n            server_cn: server cn (only used for validating server cn)\n            cmd_modules: command modules to load and register. Note that FileTransferModule is initialized here with upload_dir and download_dir if cmd_modules is None.\n            overseer_agent: initialized OverseerAgent to obtain the primary service provider to set the host and port of the active server\n            user_name: Username to authenticate with FL server\n            poc: Whether to enable poc mode for using the proof of concept example without secure communication.\n            debug: Whether to print debug messages. False by default.\n        \"\"\"\n        super().__init__(\n            ca_cert=ca_cert,\n            client_cert=client_cert,\n            client_key=client_key,\n            upload_dir=upload_dir,\n            download_dir=download_dir,\n            server_cn=server_cn,\n            cmd_modules=cmd_modules,\n            overseer_agent=overseer_agent,\n            auto_login=True,\n            user_name=user_name,\n            poc=poc,\n            debug=debug,\n        )\n        self.upload_dir = upload_dir\n        self.download_dir = download_dir\n        self._error_buffer = None\n\n    def _process_targets_into_str(self, targets: List[str]) -> str:\n        if not isinstance(targets, list):\n            raise APISyntaxError(\"targets is not a list.\")\n        if not all(isinstance(t, str) for t in targets):\n            raise APISyntaxError(\"all targets in the list of targets must be strings.\")\n        for t in targets:\n            try:\n                self._validate_required_target_string(t)\n            except APISyntaxError:\n                raise APISyntaxError(\"each target in targets must be a string of only valid characters and no spaces.\")\n        return \" \".join(targets)\n\n    def _validate_required_target_string(self, target: str) -> str:\n        \"\"\"Returns the target string if it exists and is valid.\"\"\"\n        if not target:\n            raise APISyntaxError(\"target is required but not specified.\")\n        if not isinstance(target, str):\n            raise APISyntaxError(\"target is not str.\")\n        if not re.match(\"^[A-Za-z0-9._-]*$\", target):\n            raise APISyntaxError(\"target must be a string of only valid characters and no spaces.\")\n        return target\n\n    def _validate_options_string(self, options: str) -> str:\n        \"\"\"Returns the options string if it is valid.\"\"\"\n        if not isinstance(options, str):\n            raise APISyntaxError(\"options is not str.\")\n        if not re.match(\"^[A-Za-z0-9- ]*$\", options):\n            raise APISyntaxError(\"options must be a string of only valid characters.\")\n        return options\n\n    def _validate_path_string(self, path: str) -> str:\n        \"\"\"Returns the path string if it is valid.\"\"\"\n        if not isinstance(path, str):\n            raise APISyntaxError(\"path is not str.\")\n        if not re.match(\"^[A-Za-z0-9-._/]*$\", path):\n            raise APISyntaxError(\"unsupported characters in path {}\".format(path))\n        if path.startswith(\"/\"):\n            raise APISyntaxError(\"absolute path is not allowed\")\n        paths = path.split(\"/\")\n        for p in paths:\n            if p == \"..\":\n                raise APISyntaxError(\".. in path name is not allowed\")\n        return path\n\n    def _validate_file_string(self, file: str) -> str:\n        \"\"\"Returns the file string if it is valid.\"\"\"\n        if not isinstance(file, str):\n            raise APISyntaxError(\"file is not str.\")\n        if not re.match(\"^[A-Za-z0-9-._/]*$\", file):\n            raise APISyntaxError(\"unsupported characters in file {}\".format(file))\n        if file.startswith(\"/\"):\n            raise APISyntaxError(\"absolute path for file is not allowed\")\n        paths = file.split(\"/\")\n        for p in paths:\n            if p == \"..\":\n                raise APISyntaxError(\".. in file path is not allowed\")\n        basename, file_extension = os.path.splitext(file)\n        if file_extension not in [\".txt\", \".log\", \".json\", \".csv\", \".sh\", \".config\", \".py\"]:\n            raise APISyntaxError(\n                \"this command cannot be applied to file {}. Only files with the following extensions are \"\n                \"permitted: .txt, .log, .json, .csv, .sh, .config, .py\".format(file)\n            )\n        return file\n\n    def _validate_sp_string(self, sp_string) -> str:\n        if re.match(\n            type_pattern_mapping.get(\"sp_end_point\"),\n            sp_string,\n        ):\n            return sp_string\n        else:\n            raise APISyntaxError(\"sp_string must be of the format example.com:8002:8003\")\n\n    def _get_processed_cmd_reply_data(self, command) -> Tuple[bool, str, Dict[str, Any]]:\n        \"\"\"Executes the specified command through the underlying AdminAPI's do_command() and checks the response to\n        raise common errors.\n\n        Returns:\n            Tuple of bool to indicate if success is in reply data, str with full response of the reply data, and the raw\n            reply.\n        \"\"\"\n        success_in_data = False\n        reply = self.do_command(command)\n        # handle errors from write_error (these can be from FileTransferModule)\n        if self._error_buffer:\n            err = self._error_buffer\n            self._error_buffer = None\n            raise RuntimeError(err)\n        if reply.get(\"status\") == APIStatus.SUCCESS:\n            success_in_data = True\n        reply_data_list = []\n        reply_data_full_response = \"\"\n        if reply.get(\"data\"):\n            for data in reply[\"data\"]:\n                if isinstance(data, dict):\n                    if data.get(\"type\") == \"success\":\n                        success_in_data = True\n                    if data.get(\"type\") == \"string\" or data.get(\"type\") == \"error\":\n                        reply_data_list.append(data[\"data\"])\n            reply_data_full_response = \"\\n\".join(reply_data_list)\n            if \"session_inactive\" in reply_data_full_response:\n                raise ConnectionRefusedError(reply_data_full_response)\n            if \"Failed to communicate\" in reply_data_full_response:\n                raise ConnectionError(reply_data_full_response)\n            if \"invalid client\" in reply_data_full_response:\n                raise LookupError(reply_data_full_response)\n            if \"unknown site\" in reply_data_full_response:\n                raise LookupError(reply_data_full_response)\n            if \"Authorization Error\" in reply_data_full_response:\n                raise PermissionError(reply_data_full_response)\n        if reply.get(\"status\") != APIStatus.SUCCESS:\n            raise RuntimeError(reply.get(\"details\"))\n        return success_in_data, reply_data_full_response, reply\n\n    def _parse_section_of_response_text(\n        self, data, start_string: str, offset: int = None, end_string: str = None, end_index=None\n    ) -> str:\n        \"\"\"Convenience method to get portion of string based on parameters.\"\"\"\n        if not offset:\n            offset = len(start_string) + 1\n        if end_string:\n            return data[data.find(start_string) + offset : data.find(end_string)]\n        if end_index:\n            return data[data.find(start_string) + offset : end_index]\n        return data[data.find(start_string) + offset :]\n\n    def _parse_section_of_response_text_as_int(\n        self, data, start_string: str, offset: int = None, end_string: str = None, end_index=None\n    ) -> int:\n        try:\n            return int(\n                self._parse_section_of_response_text(\n                    data=data, start_string=start_string, offset=offset, end_string=end_string, end_index=end_index\n                )\n            )\n        except ValueError:\n            return -1\n\n    def write_error(self, error: str) -> None:\n        \"\"\"Internally used to handle errors from FileTransferModule\"\"\"\n        self._error_buffer = error\n\n    @wrap_with_return_exception_responses\n    def check_status(self, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        if target_type == TargetType.SERVER:\n            return self._check_status_server()\n        elif target_type == TargetType.CLIENT:\n            return self._check_status_client(targets)\n        else:\n            raise APISyntaxError(\"target_type must be server or client.\")\n\n    def _check_status_server(self) -> FLAdminAPIResponse:\n        \"\"\"\n        Checks the server status and returns the details. This call does not wait for the server to retrieve information\n        on the clients but returns the last information the server had at the time this call is made.\n\n        \"\"\"\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.CHECK_STATUS + \" server\"\n        )\n        details = {}\n        if reply.get(\"data\"):\n            for data in reply[\"data\"]:\n                if data[\"type\"] == \"string\":\n                    if data[\"data\"].find(\"Engine status:\") != -1:\n                        details[FLDetailKey.SERVER_ENGINE_STATUS] = self._parse_section_of_response_text(\n                            data=data[\"data\"], start_string=\"Engine status:\"\n                        )\n                    if data[\"data\"].find(\"Registered clients:\") != -1:\n                        details[FLDetailKey.REGISTERED_CLIENTS] = self._parse_section_of_response_text_as_int(\n                            data=data[\"data\"], start_string=\"Registered clients:\"\n                        )\n                if data[\"type\"] == \"table\":\n                    details[FLDetailKey.STATUS_TABLE] = data[\"rows\"]\n            return FLAdminAPIResponse(APIStatus.SUCCESS, details, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    def _check_status_client(self, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        if targets:\n            processed_targets_str = self._process_targets_into_str(targets)\n            command = AdminCommandNames.CHECK_STATUS + \" client \" + processed_targets_str\n        else:\n            command = AdminCommandNames.CHECK_STATUS + \" client\"\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        details = {}\n        if reply.get(\"data\"):\n            for data in reply[\"data\"]:\n                if data[\"type\"] == \"table\":\n                    details[\"client_statuses\"] = data[\"rows\"]\n            return FLAdminAPIResponse(APIStatus.SUCCESS, details, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def submit_job(self, job_folder: str) -> FLAdminAPIResponse:\n        if not job_folder:\n            raise APISyntaxError(\"job_folder is required but not specified.\")\n        if not isinstance(job_folder, str):\n            raise APISyntaxError(\"job_folder must be str but got {}.\".format(type(job_folder)))\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.SUBMIT_JOB + \" \" + job_folder\n        )\n        if reply_data_full_response:\n            if \"Submitted job\" in reply_data_full_response:\n                # TODO:: this is a hack to get job id\n                return FLAdminAPIResponse(\n                    APIStatus.SUCCESS,\n                    {\"message\": reply_data_full_response, \"job_id\": reply_data_full_response.split(\":\")[-1].strip()},\n                    reply,\n                )\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def clone_job(self, job_id: str) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_folder is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_folder must be str but got {}.\".format(type(job_id)))\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.CLONE_JOB + \" \" + job_id\n        )\n        if reply_data_full_response:\n            if \"Cloned job\" in reply_data_full_response:\n                return FLAdminAPIResponse(\n                    APIStatus.SUCCESS,\n                    {\"message\": reply_data_full_response, \"job_id\": reply_data_full_response.split(\":\")[-1].strip()},\n                    reply,\n                )\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def list_jobs(self, options: str = None) -> FLAdminAPIResponse:\n        command = AdminCommandNames.LIST_JOBS\n        if options:\n            options = self._validate_options_string(options)\n            command = command + \" \" + options\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def download_job(self, job_id: str) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_id is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.DOWNLOAD_JOB + \" \" + job_id\n        )\n        if success:\n            return FLAdminAPIResponse(\n                APIStatus.SUCCESS,\n                {\"message\": reply.get(\"details\")},\n                reply,\n            )\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def abort_job(self, job_id: str) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_id is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.ABORT_JOB + \" \" + job_id\n        )\n        if reply_data_full_response:\n            if \"Abort signal has been sent\" in reply_data_full_response:\n                return FLAdminAPIResponse(\n                    APIStatus.SUCCESS,\n                    {\"message\": reply_data_full_response},\n                    reply,\n                )\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def delete_job(self, job_id: str) -> FLAdminAPIResponse:\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.DELETE_JOB + \" \" + str(job_id)\n        )\n        if reply_data_full_response:\n            if \"can not be deleted\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response})\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def abort(self, job_id: str, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_id is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        if target_type == TargetType.ALL:\n            command = AdminCommandNames.ABORT + \" \" + job_id + \" all\"\n        elif target_type == TargetType.SERVER:\n            command = AdminCommandNames.ABORT + \" \" + job_id + \" server\"\n        elif target_type == TargetType.CLIENT:\n            if targets:\n                processed_targets_str = self._process_targets_into_str(targets)\n                command = AdminCommandNames.ABORT + \" \" + job_id + \" client \" + processed_targets_str\n            else:\n                command = AdminCommandNames.ABORT + \" \" + job_id + \" client\"\n        else:\n            raise APISyntaxError(\"target_type must be server, client, or all.\")\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            if \"Server app has not started\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response}, reply)\n            if \"No clients to abort\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response}, reply)\n            if \"please wait for started before abort\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response}, reply)\n        if success:\n            return_details = {}\n            if reply_data_full_response:\n                return_details[\"message\"] = reply_data_full_response\n            if reply.get(\"data\"):\n                for data in reply[\"data\"]:\n                    if data[\"type\"] == \"table\":\n                        return_details[FLDetailKey.RESPONSES] = data[\"rows\"]\n            return FLAdminAPIResponse(APIStatus.SUCCESS, return_details, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def restart(self, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        if target_type == TargetType.ALL:\n            command = AdminCommandNames.RESTART + \" \" + \"all\"\n        elif target_type == TargetType.SERVER:\n            command = AdminCommandNames.RESTART + \" \" + \"server\"\n        elif target_type == TargetType.CLIENT:\n            if targets:\n                processed_targets_str = self._process_targets_into_str(targets)\n                command = AdminCommandNames.RESTART + \" client \" + processed_targets_str\n            else:\n                command = AdminCommandNames.RESTART + \" \" + \"client\"\n        else:\n            raise APISyntaxError(\"target_type must be server, client, or all.\")\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            if \"no clients available\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response})\n            if \"Server is starting, please wait for started before restart\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response})\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def shutdown(self, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        if target_type == TargetType.ALL:\n            command = AdminCommandNames.SHUTDOWN + \" \" + \"all\"\n        elif target_type == TargetType.SERVER:\n            command = AdminCommandNames.SHUTDOWN + \" \" + \"server\"\n        elif target_type == TargetType.CLIENT:\n            if targets:\n                processed_targets_str = self._process_targets_into_str(targets)\n                command = AdminCommandNames.SHUTDOWN + \" client \" + processed_targets_str\n            else:\n                command = AdminCommandNames.SHUTDOWN + \" \" + \"client\"\n        else:\n            raise APISyntaxError(\"target_type must be server, client, or all.\")\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            if \"There are still active clients. Shutdown all clients first.\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response})\n            if \"no clients to shutdown\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response})\n            if \"Server is starting, please wait for started before shutdown\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response})\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def remove_client(self, targets: List[str]) -> FLAdminAPIResponse:\n        if not targets:\n            raise APISyntaxError(\"targets needs to be provided as a list of client names.\")\n        processed_targets_str = self._process_targets_into_str(targets)\n        command = AdminCommandNames.REMOVE_CLIENT + \" \" + processed_targets_str\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def set_timeout(self, timeout: float) -> FLAdminAPIResponse:\n        if not isinstance(timeout, (float, int)):\n            raise APISyntaxError(\"timeout is not float.\")\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\"set_timeout \" + str(timeout))\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def list_sp(self) -> FLAdminAPIResponse:\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\"list_sp\")\n        if reply.get(\"data\"):\n            return FLAdminAPIResponse(APIStatus.SUCCESS, reply.get(\"data\"), reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def get_active_sp(self) -> FLAdminAPIResponse:\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\"get_active_sp\")\n        if reply.get(\"details\"):\n            return FLAdminAPIResponse(APIStatus.SUCCESS, reply.get(\"details\"), reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def promote_sp(self, sp_end_point: str) -> FLAdminAPIResponse:\n        sp_end_point = self._validate_sp_string(sp_end_point)\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\"promote_sp \" + sp_end_point)\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply.get(\"details\")}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def shutdown_system(self) -> FLAdminAPIResponse:\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\"shutdown_system\")\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply.get(\"details\")}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def get_available_apps_to_upload(self):\n        dir_list = []\n        for item in os.listdir(self.upload_dir):\n            if os.path.isdir(os.path.join(self.upload_dir, item)):\n                dir_list.append(item)\n        return FLAdminAPIResponse(APIStatus.SUCCESS, {\"app_list\": dir_list})\n\n    @wrap_with_return_exception_responses\n    def ls_target(self, target: str, options: str = None, path: str = None) -> FLAdminAPIResponse:\n        target = self._validate_required_target_string(target)\n        command = \"ls \" + target\n        if options:\n            options = self._validate_options_string(options)\n            command = command + \" \" + options\n        if path:\n            path = self._validate_path_string(path)\n            command = command + \" \" + path\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response})\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def cat_target(self, target: str, options: str = None, file: str = None) -> FLAdminAPIResponse:\n        if not file:\n            raise APISyntaxError(\"file is required but not specified.\")\n        file = self._validate_file_string(file)\n        target = self._validate_required_target_string(target)\n        command = \"cat \" + target\n        if options:\n            options = self._validate_options_string(options)\n            command = command + \" \" + options\n        if file:\n            command = command + \" \" + file\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response})\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def tail_target_log(self, target: str, options: str = None) -> FLAdminAPIResponse:\n        target = self._validate_required_target_string(target)\n        command = \"tail \" + target\n        if options:\n            options = self._validate_options_string(options)\n            command = command + \" \" + options\n        command = command + \" log.txt\"\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response})\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def env_target(self, target: str) -> FLAdminAPIResponse:\n        target = self._validate_required_target_string(target)\n        command = \"env \" + target\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            details = {}\n            environment = reply_data_full_response.split(\"\\n\")\n            for e in environment:\n                # set key and value to contents of each line with first = as separator\n                details[e[0 : e.find(\"=\")]] = e[e.find(\"=\") + 1 :]\n            return FLAdminAPIResponse(APIStatus.SUCCESS, details)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def get_working_directory(self, target: str) -> FLAdminAPIResponse:\n        target = self._validate_required_target_string(target)\n        command = \"pwd \" + target\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response})\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def grep_target(\n        self, target: str, options: str = None, pattern: str = None, file: str = None\n    ) -> FLAdminAPIResponse:\n        if not file:\n            raise APISyntaxError(\"file is required but not specified.\")\n        file = self._validate_file_string(file)\n        if not pattern:\n            raise APISyntaxError(\"pattern is required but not specified.\")\n        if not isinstance(pattern, str):\n            raise APISyntaxError(\"pattern is not str.\")\n        target = self._validate_required_target_string(target)\n        command = \"grep \" + target\n        if options:\n            options = self._validate_options_string(options)\n            command = command + \" \" + options\n        command = command + ' \"' + pattern + '\" ' + file\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response})\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def show_stats(\n        self, job_id: str, target_type: TargetType, targets: Optional[List[str]] = None\n    ) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_id is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        if target_type == TargetType.SERVER:\n            command = AdminCommandNames.SHOW_STATS + \" \" + job_id + \" server\"\n        elif target_type == TargetType.CLIENT:\n            if targets:\n                processed_targets_str = self._process_targets_into_str(targets)\n                command = AdminCommandNames.SHOW_STATS + \" \" + job_id + \" client \" + processed_targets_str\n            else:\n                command = AdminCommandNames.SHOW_STATS + \" \" + job_id + \" client\"\n        else:\n            raise APISyntaxError(\"target_type must be server or client.\")\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply.get(\"data\"):\n            for data in reply[\"data\"]:\n                if data[\"type\"] == \"dict\":\n                    stats_result = data[\"data\"]\n                    return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": stats_result}, reply)\n        if reply_data_full_response:\n            if \"App is not running\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def show_errors(\n        self, job_id: str, target_type: TargetType, targets: Optional[List[str]] = None\n    ) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_id is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        if target_type == TargetType.SERVER:\n            command = AdminCommandNames.SHOW_ERRORS + \" \" + job_id + \" server\"\n        elif target_type == TargetType.CLIENT:\n            if targets:\n                processed_targets_str = self._process_targets_into_str(targets)\n                command = AdminCommandNames.SHOW_ERRORS + \" \" + job_id + \" client \" + processed_targets_str\n            else:\n                command = AdminCommandNames.SHOW_ERRORS + \" \" + job_id + \" client\"\n        else:\n            raise APISyntaxError(\"target_type must be server or client.\")\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply.get(\"data\"):\n            for data in reply[\"data\"]:\n                if data[\"type\"] == \"dict\":\n                    errors_result = data[\"data\"]\n                    return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": errors_result}, reply)\n        if reply_data_full_response:\n            if \"App is not running\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": \"No errors.\"}, reply)\n\n    @wrap_with_return_exception_responses\n    def reset_errors(self, job_id: str) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_id is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.RESET_ERRORS + \" \" + job_id\n        )\n        if reply_data_full_response:\n            if \"App is not running\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response}, reply)\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )\n\n    @wrap_with_return_exception_responses\n    def get_connected_client_list(self) -> FLAdminAPIResponse:\n        reply = self._check_status_server()\n        if reply[\"status\"] == APIStatus.SUCCESS:\n            status_table = reply[\"details\"][FLDetailKey.STATUS_TABLE]\n            list_of_connected_clients = []\n            for row in status_table:\n                if row[0] != \"CLIENT NAME\":\n                    list_of_connected_clients.append(row[0])\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {FLDetailKey.CONNECTED_CLIENTS: list_of_connected_clients})\n        else:\n            return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": \"runtime error\"}, reply)\n\n    @wrap_with_return_exception_responses\n    def wait_until_server_status(\n        self,\n        interval: int = 20,\n        timeout: int = None,\n        callback: Callable[[FLAdminAPIResponse, Optional[List]], bool] = default_server_status_handling_cb,\n        fail_attempts: int = 3,\n        **kwargs,\n    ) -> FLAdminAPIResponse:\n        failed_attempts = 0\n        start = time.time()\n        while True:\n            reply = self._check_status_server()\n            if reply[\"details\"].get(FLDetailKey.SERVER_ENGINE_STATUS):\n                met = callback(reply, **kwargs)\n                if met:\n                    return FLAdminAPIResponse(APIStatus.SUCCESS, {}, None)\n                fail_attempts = 0\n            else:\n                print(\"Could not get reply from check status server, trying again later\")\n                failed_attempts += 1\n\n            now = time.time()\n            if timeout is not None:\n                if now - start >= timeout:\n                    return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": \"Waited until timeout.\"}, None)\n            if failed_attempts > fail_attempts:\n                return FLAdminAPIResponse(\n                    APIStatus.ERROR_RUNTIME,\n                    {\n                        \"message\": \"FL server status was not obtainable for more than the specified number of \"\n                        \"fail_attempts. \"\n                    },\n                    None,\n                )\n            time.sleep(interval)\n\n    @wrap_with_return_exception_responses\n    def wait_until_client_status(\n        self,\n        interval: int = 10,\n        timeout: int = None,\n        callback: Callable[[FLAdminAPIResponse, Optional[List]], bool] = default_client_status_handling_cb,\n        fail_attempts: int = 6,\n        **kwargs,\n    ) -> FLAdminAPIResponse:\n        \"\"\"This is similar to wait_until_server_status() and is an example for using other information from a repeated\n        call, in this case check_status(TargetType.CLIENT). Custom code can be written to use any data available from\n        any call to make decisions for how to proceed. Take caution that the conditions will be met at some point, or\n        timeout should be set with logic outside this function to handle checks for potential errors or this may loop\n        indefinitely.\n\n        Args:\n            interval: in seconds, the time between consecutive checks of the server\n            timeout: if set, the amount of time this function will run until before returning a response message\n            callback: the reply from show_stats(TargetType.SERVER) will be passed to the callback, along with any additional kwargs\n            which can go on to perform additional logic.\n            fail_attempts: number of consecutive failed attempts of getting the server status before returning with ERROR_RUNTIME.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        failed_attempts = 0\n        start = time.time()\n        while True:\n            try:\n                reply = self.check_status(TargetType.CLIENT)\n                if reply:\n                    met = callback(reply, **kwargs)\n                    if met:\n                        return FLAdminAPIResponse(APIStatus.SUCCESS, {}, None)\n                    fail_attempts = 0\n                else:\n                    print(\"Could not get reply from check status client, trying again later\")\n                    failed_attempts += 1\n            except BaseException as e:\n                print(\"Could not get clients stats, trying again later. Exception: \", e)\n                failed_attempts += 1\n\n            now = time.time()\n            if timeout is not None:\n                if now - start >= timeout:\n                    return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": \"Waited until timeout.\"}, None)\n            if failed_attempts > fail_attempts:\n                return FLAdminAPIResponse(\n                    APIStatus.ERROR_RUNTIME,\n                    {\n                        \"message\": \"FL client status was not obtainable for more than the specified number of \"\n                        \"fail_attempts. \"\n                    },\n                    None,\n                )\n            time.sleep(interval)\n\n    @wrap_with_return_exception_responses\n    def wait_until_server_stats(\n        self,\n        interval: int = 10,\n        timeout: int = None,\n        callback: Callable[[FLAdminAPIResponse, Optional[List]], bool] = default_stats_handling_cb,\n        fail_attempts: int = 6,\n        **kwargs,\n    ) -> FLAdminAPIResponse:\n        \"\"\"This is similar to wait_until_server_status() and is an example for using other information from a repeated\n        call, in this case show_stats(TargetType.SERVER). Custom code can be written to use any data available from any\n        call to make decisions for how to proceed. Take caution that the conditions will be met at some point, or\n        timeout should be set with logic outside this function to handle checks for potential errors or this may loop\n        indefinitely.\n\n        Args:\n            interval: in seconds, the time between consecutive checks of the server\n            timeout: if set, the amount of time this function will run until before returning a response message\n            callback: the reply from show_stats(TargetType.SERVER) will be passed to the callback, along with any additional kwargs\n            which can go on to perform additional logic.\n            fail_attempts: number of consecutive failed attempts of getting the server status before returning with ERROR_RUNTIME.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        failed_attempts = 0\n        start = time.time()\n        while True:\n            try:\n                reply = self.show_stats(TargetType.SERVER)\n                try:\n                    if reply:\n                        met = callback(reply, **kwargs)\n                        if met:\n                            return FLAdminAPIResponse(APIStatus.SUCCESS, {}, None)\n                        fail_attempts = 0\n                    else:\n                        print(\"Could not get reply from show stats server, trying again later\")\n                        failed_attempts += 1\n                except AttributeError:\n                    # if attribute cannot be found, check if app is no longer running to return APIStatus.SUCCESS\n                    if reply.get(\"details\").get(\"message\") == \"App is not running\":\n                        return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": \"Waited until app not running.\"}, None)\n            except BaseException as e:\n                print(\"Could not get server stats, trying again later. Exception: \", e)\n                failed_attempts += 1\n\n            now = time.time()\n            if timeout is not None:\n                if now - start >= timeout:\n                    return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": \"Waited until timeout.\"}, None)\n            if failed_attempts > fail_attempts:\n                return FLAdminAPIResponse(\n                    APIStatus.ERROR_RUNTIME,\n                    {\n                        \"message\": \"FL server stats was not obtainable for more than the specified number of \"\n                        \"fail_attempts. \"\n                    },\n                    None,\n                )\n            time.sleep(interval)\n\n    def login(self, username: str):\n        result = super().login(username=username)\n        return FLAdminAPIResponse(status=result[\"status\"], details=result[\"details\"])\n\n    def login_with_poc(self, username: str, poc_key: str):\n        result = super().login_with_poc(username=username, poc_key=poc_key)\n        return FLAdminAPIResponse(status=result[\"status\"], details=result[\"details\"])",
  "def wrapper(self, *args, **kwargs):\n        try:\n            reply = func(self, *args, **kwargs)\n            if reply:\n                return reply\n            else:\n                return FLAdminAPIResponse(\n                    APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not generate reply.\"}\n                )\n        except ConnectionRefusedError as e:\n            return FLAdminAPIResponse(APIStatus.ERROR_AUTHENTICATION, {\"message\": \"Error: \" + str(e)})\n        except PermissionError as e:\n            return FLAdminAPIResponse(APIStatus.ERROR_AUTHORIZATION, {\"message\": \"Error: \" + str(e)})\n        except LookupError as e:\n            return FLAdminAPIResponse(APIStatus.ERROR_INVALID_CLIENT, {\"message\": \"Error: \" + str(e)})\n        except APISyntaxError as e:\n            return FLAdminAPIResponse(APIStatus.ERROR_SYNTAX, {\"message\": \"Error: \" + str(e)})\n        except TimeoutError as e:\n            return FLAdminAPIResponse(\n                APIStatus.ERROR_RUNTIME,\n                {\"message\": \"TimeoutError: possibly unable to communicate with server. \" + str(e)},\n            )\n        except Exception as e:\n            return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": \"Exception: \" + str(e)})",
  "def __init__(\n        self,\n        ca_cert: str = \"\",\n        client_cert: str = \"\",\n        client_key: str = \"\",\n        upload_dir: str = \"\",\n        download_dir: str = \"\",\n        server_cn=None,\n        cmd_modules: Optional[List] = None,\n        overseer_agent: OverseerAgent = None,\n        user_name: str = None,\n        poc=False,\n        debug=False,\n    ):\n        \"\"\"FLAdminAPI serves as foundation for communications to FL server through the AdminAPI.\n\n        Upon initialization, FLAdminAPI will start the overseer agent to get the active server and then try to log in.\n        This happens in a thread, so code that executes after should check that the FLAdminAPI is successfully logged in.\n\n        Args:\n            ca_cert: path to CA Cert file, by default provisioned rootCA.pem\n            client_cert: path to admin client Cert file, by default provisioned as client.crt\n            client_key: path to admin client Key file, by default provisioned as client.key\n            upload_dir: File transfer upload directory. Folders uploaded to the server to be deployed must be here. Folder must already exist and be accessible.\n            download_dir: File transfer download directory. Can be same as upload_dir. Folder must already exist and be accessible.\n            server_cn: server cn (only used for validating server cn)\n            cmd_modules: command modules to load and register. Note that FileTransferModule is initialized here with upload_dir and download_dir if cmd_modules is None.\n            overseer_agent: initialized OverseerAgent to obtain the primary service provider to set the host and port of the active server\n            user_name: Username to authenticate with FL server\n            poc: Whether to enable poc mode for using the proof of concept example without secure communication.\n            debug: Whether to print debug messages. False by default.\n        \"\"\"\n        super().__init__(\n            ca_cert=ca_cert,\n            client_cert=client_cert,\n            client_key=client_key,\n            upload_dir=upload_dir,\n            download_dir=download_dir,\n            server_cn=server_cn,\n            cmd_modules=cmd_modules,\n            overseer_agent=overseer_agent,\n            auto_login=True,\n            user_name=user_name,\n            poc=poc,\n            debug=debug,\n        )\n        self.upload_dir = upload_dir\n        self.download_dir = download_dir\n        self._error_buffer = None",
  "def _process_targets_into_str(self, targets: List[str]) -> str:\n        if not isinstance(targets, list):\n            raise APISyntaxError(\"targets is not a list.\")\n        if not all(isinstance(t, str) for t in targets):\n            raise APISyntaxError(\"all targets in the list of targets must be strings.\")\n        for t in targets:\n            try:\n                self._validate_required_target_string(t)\n            except APISyntaxError:\n                raise APISyntaxError(\"each target in targets must be a string of only valid characters and no spaces.\")\n        return \" \".join(targets)",
  "def _validate_required_target_string(self, target: str) -> str:\n        \"\"\"Returns the target string if it exists and is valid.\"\"\"\n        if not target:\n            raise APISyntaxError(\"target is required but not specified.\")\n        if not isinstance(target, str):\n            raise APISyntaxError(\"target is not str.\")\n        if not re.match(\"^[A-Za-z0-9._-]*$\", target):\n            raise APISyntaxError(\"target must be a string of only valid characters and no spaces.\")\n        return target",
  "def _validate_options_string(self, options: str) -> str:\n        \"\"\"Returns the options string if it is valid.\"\"\"\n        if not isinstance(options, str):\n            raise APISyntaxError(\"options is not str.\")\n        if not re.match(\"^[A-Za-z0-9- ]*$\", options):\n            raise APISyntaxError(\"options must be a string of only valid characters.\")\n        return options",
  "def _validate_path_string(self, path: str) -> str:\n        \"\"\"Returns the path string if it is valid.\"\"\"\n        if not isinstance(path, str):\n            raise APISyntaxError(\"path is not str.\")\n        if not re.match(\"^[A-Za-z0-9-._/]*$\", path):\n            raise APISyntaxError(\"unsupported characters in path {}\".format(path))\n        if path.startswith(\"/\"):\n            raise APISyntaxError(\"absolute path is not allowed\")\n        paths = path.split(\"/\")\n        for p in paths:\n            if p == \"..\":\n                raise APISyntaxError(\".. in path name is not allowed\")\n        return path",
  "def _validate_file_string(self, file: str) -> str:\n        \"\"\"Returns the file string if it is valid.\"\"\"\n        if not isinstance(file, str):\n            raise APISyntaxError(\"file is not str.\")\n        if not re.match(\"^[A-Za-z0-9-._/]*$\", file):\n            raise APISyntaxError(\"unsupported characters in file {}\".format(file))\n        if file.startswith(\"/\"):\n            raise APISyntaxError(\"absolute path for file is not allowed\")\n        paths = file.split(\"/\")\n        for p in paths:\n            if p == \"..\":\n                raise APISyntaxError(\".. in file path is not allowed\")\n        basename, file_extension = os.path.splitext(file)\n        if file_extension not in [\".txt\", \".log\", \".json\", \".csv\", \".sh\", \".config\", \".py\"]:\n            raise APISyntaxError(\n                \"this command cannot be applied to file {}. Only files with the following extensions are \"\n                \"permitted: .txt, .log, .json, .csv, .sh, .config, .py\".format(file)\n            )\n        return file",
  "def _validate_sp_string(self, sp_string) -> str:\n        if re.match(\n            type_pattern_mapping.get(\"sp_end_point\"),\n            sp_string,\n        ):\n            return sp_string\n        else:\n            raise APISyntaxError(\"sp_string must be of the format example.com:8002:8003\")",
  "def _get_processed_cmd_reply_data(self, command) -> Tuple[bool, str, Dict[str, Any]]:\n        \"\"\"Executes the specified command through the underlying AdminAPI's do_command() and checks the response to\n        raise common errors.\n\n        Returns:\n            Tuple of bool to indicate if success is in reply data, str with full response of the reply data, and the raw\n            reply.\n        \"\"\"\n        success_in_data = False\n        reply = self.do_command(command)\n        # handle errors from write_error (these can be from FileTransferModule)\n        if self._error_buffer:\n            err = self._error_buffer\n            self._error_buffer = None\n            raise RuntimeError(err)\n        if reply.get(\"status\") == APIStatus.SUCCESS:\n            success_in_data = True\n        reply_data_list = []\n        reply_data_full_response = \"\"\n        if reply.get(\"data\"):\n            for data in reply[\"data\"]:\n                if isinstance(data, dict):\n                    if data.get(\"type\") == \"success\":\n                        success_in_data = True\n                    if data.get(\"type\") == \"string\" or data.get(\"type\") == \"error\":\n                        reply_data_list.append(data[\"data\"])\n            reply_data_full_response = \"\\n\".join(reply_data_list)\n            if \"session_inactive\" in reply_data_full_response:\n                raise ConnectionRefusedError(reply_data_full_response)\n            if \"Failed to communicate\" in reply_data_full_response:\n                raise ConnectionError(reply_data_full_response)\n            if \"invalid client\" in reply_data_full_response:\n                raise LookupError(reply_data_full_response)\n            if \"unknown site\" in reply_data_full_response:\n                raise LookupError(reply_data_full_response)\n            if \"Authorization Error\" in reply_data_full_response:\n                raise PermissionError(reply_data_full_response)\n        if reply.get(\"status\") != APIStatus.SUCCESS:\n            raise RuntimeError(reply.get(\"details\"))\n        return success_in_data, reply_data_full_response, reply",
  "def _parse_section_of_response_text(\n        self, data, start_string: str, offset: int = None, end_string: str = None, end_index=None\n    ) -> str:\n        \"\"\"Convenience method to get portion of string based on parameters.\"\"\"\n        if not offset:\n            offset = len(start_string) + 1\n        if end_string:\n            return data[data.find(start_string) + offset : data.find(end_string)]\n        if end_index:\n            return data[data.find(start_string) + offset : end_index]\n        return data[data.find(start_string) + offset :]",
  "def _parse_section_of_response_text_as_int(\n        self, data, start_string: str, offset: int = None, end_string: str = None, end_index=None\n    ) -> int:\n        try:\n            return int(\n                self._parse_section_of_response_text(\n                    data=data, start_string=start_string, offset=offset, end_string=end_string, end_index=end_index\n                )\n            )\n        except ValueError:\n            return -1",
  "def write_error(self, error: str) -> None:\n        \"\"\"Internally used to handle errors from FileTransferModule\"\"\"\n        self._error_buffer = error",
  "def check_status(self, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        if target_type == TargetType.SERVER:\n            return self._check_status_server()\n        elif target_type == TargetType.CLIENT:\n            return self._check_status_client(targets)\n        else:\n            raise APISyntaxError(\"target_type must be server or client.\")",
  "def _check_status_server(self) -> FLAdminAPIResponse:\n        \"\"\"\n        Checks the server status and returns the details. This call does not wait for the server to retrieve information\n        on the clients but returns the last information the server had at the time this call is made.\n\n        \"\"\"\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.CHECK_STATUS + \" server\"\n        )\n        details = {}\n        if reply.get(\"data\"):\n            for data in reply[\"data\"]:\n                if data[\"type\"] == \"string\":\n                    if data[\"data\"].find(\"Engine status:\") != -1:\n                        details[FLDetailKey.SERVER_ENGINE_STATUS] = self._parse_section_of_response_text(\n                            data=data[\"data\"], start_string=\"Engine status:\"\n                        )\n                    if data[\"data\"].find(\"Registered clients:\") != -1:\n                        details[FLDetailKey.REGISTERED_CLIENTS] = self._parse_section_of_response_text_as_int(\n                            data=data[\"data\"], start_string=\"Registered clients:\"\n                        )\n                if data[\"type\"] == \"table\":\n                    details[FLDetailKey.STATUS_TABLE] = data[\"rows\"]\n            return FLAdminAPIResponse(APIStatus.SUCCESS, details, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def _check_status_client(self, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        if targets:\n            processed_targets_str = self._process_targets_into_str(targets)\n            command = AdminCommandNames.CHECK_STATUS + \" client \" + processed_targets_str\n        else:\n            command = AdminCommandNames.CHECK_STATUS + \" client\"\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        details = {}\n        if reply.get(\"data\"):\n            for data in reply[\"data\"]:\n                if data[\"type\"] == \"table\":\n                    details[\"client_statuses\"] = data[\"rows\"]\n            return FLAdminAPIResponse(APIStatus.SUCCESS, details, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def submit_job(self, job_folder: str) -> FLAdminAPIResponse:\n        if not job_folder:\n            raise APISyntaxError(\"job_folder is required but not specified.\")\n        if not isinstance(job_folder, str):\n            raise APISyntaxError(\"job_folder must be str but got {}.\".format(type(job_folder)))\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.SUBMIT_JOB + \" \" + job_folder\n        )\n        if reply_data_full_response:\n            if \"Submitted job\" in reply_data_full_response:\n                # TODO:: this is a hack to get job id\n                return FLAdminAPIResponse(\n                    APIStatus.SUCCESS,\n                    {\"message\": reply_data_full_response, \"job_id\": reply_data_full_response.split(\":\")[-1].strip()},\n                    reply,\n                )\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def clone_job(self, job_id: str) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_folder is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_folder must be str but got {}.\".format(type(job_id)))\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.CLONE_JOB + \" \" + job_id\n        )\n        if reply_data_full_response:\n            if \"Cloned job\" in reply_data_full_response:\n                return FLAdminAPIResponse(\n                    APIStatus.SUCCESS,\n                    {\"message\": reply_data_full_response, \"job_id\": reply_data_full_response.split(\":\")[-1].strip()},\n                    reply,\n                )\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def list_jobs(self, options: str = None) -> FLAdminAPIResponse:\n        command = AdminCommandNames.LIST_JOBS\n        if options:\n            options = self._validate_options_string(options)\n            command = command + \" \" + options\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def download_job(self, job_id: str) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_id is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.DOWNLOAD_JOB + \" \" + job_id\n        )\n        if success:\n            return FLAdminAPIResponse(\n                APIStatus.SUCCESS,\n                {\"message\": reply.get(\"details\")},\n                reply,\n            )\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def abort_job(self, job_id: str) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_id is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.ABORT_JOB + \" \" + job_id\n        )\n        if reply_data_full_response:\n            if \"Abort signal has been sent\" in reply_data_full_response:\n                return FLAdminAPIResponse(\n                    APIStatus.SUCCESS,\n                    {\"message\": reply_data_full_response},\n                    reply,\n                )\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def delete_job(self, job_id: str) -> FLAdminAPIResponse:\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.DELETE_JOB + \" \" + str(job_id)\n        )\n        if reply_data_full_response:\n            if \"can not be deleted\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response})\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def abort(self, job_id: str, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_id is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        if target_type == TargetType.ALL:\n            command = AdminCommandNames.ABORT + \" \" + job_id + \" all\"\n        elif target_type == TargetType.SERVER:\n            command = AdminCommandNames.ABORT + \" \" + job_id + \" server\"\n        elif target_type == TargetType.CLIENT:\n            if targets:\n                processed_targets_str = self._process_targets_into_str(targets)\n                command = AdminCommandNames.ABORT + \" \" + job_id + \" client \" + processed_targets_str\n            else:\n                command = AdminCommandNames.ABORT + \" \" + job_id + \" client\"\n        else:\n            raise APISyntaxError(\"target_type must be server, client, or all.\")\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            if \"Server app has not started\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response}, reply)\n            if \"No clients to abort\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response}, reply)\n            if \"please wait for started before abort\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response}, reply)\n        if success:\n            return_details = {}\n            if reply_data_full_response:\n                return_details[\"message\"] = reply_data_full_response\n            if reply.get(\"data\"):\n                for data in reply[\"data\"]:\n                    if data[\"type\"] == \"table\":\n                        return_details[FLDetailKey.RESPONSES] = data[\"rows\"]\n            return FLAdminAPIResponse(APIStatus.SUCCESS, return_details, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def restart(self, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        if target_type == TargetType.ALL:\n            command = AdminCommandNames.RESTART + \" \" + \"all\"\n        elif target_type == TargetType.SERVER:\n            command = AdminCommandNames.RESTART + \" \" + \"server\"\n        elif target_type == TargetType.CLIENT:\n            if targets:\n                processed_targets_str = self._process_targets_into_str(targets)\n                command = AdminCommandNames.RESTART + \" client \" + processed_targets_str\n            else:\n                command = AdminCommandNames.RESTART + \" \" + \"client\"\n        else:\n            raise APISyntaxError(\"target_type must be server, client, or all.\")\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            if \"no clients available\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response})\n            if \"Server is starting, please wait for started before restart\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response})\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def shutdown(self, target_type: TargetType, targets: Optional[List[str]] = None) -> FLAdminAPIResponse:\n        if target_type == TargetType.ALL:\n            command = AdminCommandNames.SHUTDOWN + \" \" + \"all\"\n        elif target_type == TargetType.SERVER:\n            command = AdminCommandNames.SHUTDOWN + \" \" + \"server\"\n        elif target_type == TargetType.CLIENT:\n            if targets:\n                processed_targets_str = self._process_targets_into_str(targets)\n                command = AdminCommandNames.SHUTDOWN + \" client \" + processed_targets_str\n            else:\n                command = AdminCommandNames.SHUTDOWN + \" \" + \"client\"\n        else:\n            raise APISyntaxError(\"target_type must be server, client, or all.\")\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            if \"There are still active clients. Shutdown all clients first.\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response})\n            if \"no clients to shutdown\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response})\n            if \"Server is starting, please wait for started before shutdown\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response})\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def remove_client(self, targets: List[str]) -> FLAdminAPIResponse:\n        if not targets:\n            raise APISyntaxError(\"targets needs to be provided as a list of client names.\")\n        processed_targets_str = self._process_targets_into_str(targets)\n        command = AdminCommandNames.REMOVE_CLIENT + \" \" + processed_targets_str\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def set_timeout(self, timeout: float) -> FLAdminAPIResponse:\n        if not isinstance(timeout, (float, int)):\n            raise APISyntaxError(\"timeout is not float.\")\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\"set_timeout \" + str(timeout))\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def list_sp(self) -> FLAdminAPIResponse:\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\"list_sp\")\n        if reply.get(\"data\"):\n            return FLAdminAPIResponse(APIStatus.SUCCESS, reply.get(\"data\"), reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def get_active_sp(self) -> FLAdminAPIResponse:\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\"get_active_sp\")\n        if reply.get(\"details\"):\n            return FLAdminAPIResponse(APIStatus.SUCCESS, reply.get(\"details\"), reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def promote_sp(self, sp_end_point: str) -> FLAdminAPIResponse:\n        sp_end_point = self._validate_sp_string(sp_end_point)\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\"promote_sp \" + sp_end_point)\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply.get(\"details\")}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def shutdown_system(self) -> FLAdminAPIResponse:\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\"shutdown_system\")\n        if success:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply.get(\"details\")}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def get_available_apps_to_upload(self):\n        dir_list = []\n        for item in os.listdir(self.upload_dir):\n            if os.path.isdir(os.path.join(self.upload_dir, item)):\n                dir_list.append(item)\n        return FLAdminAPIResponse(APIStatus.SUCCESS, {\"app_list\": dir_list})",
  "def ls_target(self, target: str, options: str = None, path: str = None) -> FLAdminAPIResponse:\n        target = self._validate_required_target_string(target)\n        command = \"ls \" + target\n        if options:\n            options = self._validate_options_string(options)\n            command = command + \" \" + options\n        if path:\n            path = self._validate_path_string(path)\n            command = command + \" \" + path\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response})\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def cat_target(self, target: str, options: str = None, file: str = None) -> FLAdminAPIResponse:\n        if not file:\n            raise APISyntaxError(\"file is required but not specified.\")\n        file = self._validate_file_string(file)\n        target = self._validate_required_target_string(target)\n        command = \"cat \" + target\n        if options:\n            options = self._validate_options_string(options)\n            command = command + \" \" + options\n        if file:\n            command = command + \" \" + file\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response})\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def tail_target_log(self, target: str, options: str = None) -> FLAdminAPIResponse:\n        target = self._validate_required_target_string(target)\n        command = \"tail \" + target\n        if options:\n            options = self._validate_options_string(options)\n            command = command + \" \" + options\n        command = command + \" log.txt\"\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response})\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def env_target(self, target: str) -> FLAdminAPIResponse:\n        target = self._validate_required_target_string(target)\n        command = \"env \" + target\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            details = {}\n            environment = reply_data_full_response.split(\"\\n\")\n            for e in environment:\n                # set key and value to contents of each line with first = as separator\n                details[e[0 : e.find(\"=\")]] = e[e.find(\"=\") + 1 :]\n            return FLAdminAPIResponse(APIStatus.SUCCESS, details)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def get_working_directory(self, target: str) -> FLAdminAPIResponse:\n        target = self._validate_required_target_string(target)\n        command = \"pwd \" + target\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response})\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def grep_target(\n        self, target: str, options: str = None, pattern: str = None, file: str = None\n    ) -> FLAdminAPIResponse:\n        if not file:\n            raise APISyntaxError(\"file is required but not specified.\")\n        file = self._validate_file_string(file)\n        if not pattern:\n            raise APISyntaxError(\"pattern is required but not specified.\")\n        if not isinstance(pattern, str):\n            raise APISyntaxError(\"pattern is not str.\")\n        target = self._validate_required_target_string(target)\n        command = \"grep \" + target\n        if options:\n            options = self._validate_options_string(options)\n            command = command + \" \" + options\n        command = command + ' \"' + pattern + '\" ' + file\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply_data_full_response:\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response})\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def show_stats(\n        self, job_id: str, target_type: TargetType, targets: Optional[List[str]] = None\n    ) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_id is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        if target_type == TargetType.SERVER:\n            command = AdminCommandNames.SHOW_STATS + \" \" + job_id + \" server\"\n        elif target_type == TargetType.CLIENT:\n            if targets:\n                processed_targets_str = self._process_targets_into_str(targets)\n                command = AdminCommandNames.SHOW_STATS + \" \" + job_id + \" client \" + processed_targets_str\n            else:\n                command = AdminCommandNames.SHOW_STATS + \" \" + job_id + \" client\"\n        else:\n            raise APISyntaxError(\"target_type must be server or client.\")\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply.get(\"data\"):\n            for data in reply[\"data\"]:\n                if data[\"type\"] == \"dict\":\n                    stats_result = data[\"data\"]\n                    return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": stats_result}, reply)\n        if reply_data_full_response:\n            if \"App is not running\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def show_errors(\n        self, job_id: str, target_type: TargetType, targets: Optional[List[str]] = None\n    ) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_id is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        if target_type == TargetType.SERVER:\n            command = AdminCommandNames.SHOW_ERRORS + \" \" + job_id + \" server\"\n        elif target_type == TargetType.CLIENT:\n            if targets:\n                processed_targets_str = self._process_targets_into_str(targets)\n                command = AdminCommandNames.SHOW_ERRORS + \" \" + job_id + \" client \" + processed_targets_str\n            else:\n                command = AdminCommandNames.SHOW_ERRORS + \" \" + job_id + \" client\"\n        else:\n            raise APISyntaxError(\"target_type must be server or client.\")\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(command)\n        if reply.get(\"data\"):\n            for data in reply[\"data\"]:\n                if data[\"type\"] == \"dict\":\n                    errors_result = data[\"data\"]\n                    return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": errors_result}, reply)\n        if reply_data_full_response:\n            if \"App is not running\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": \"No errors.\"}, reply)",
  "def reset_errors(self, job_id: str) -> FLAdminAPIResponse:\n        if not job_id:\n            raise APISyntaxError(\"job_id is required but not specified.\")\n        if not isinstance(job_id, str):\n            raise APISyntaxError(\"job_id must be str but got {}.\".format(type(job_id)))\n        success, reply_data_full_response, reply = self._get_processed_cmd_reply_data(\n            AdminCommandNames.RESET_ERRORS + \" \" + job_id\n        )\n        if reply_data_full_response:\n            if \"App is not running\" in reply_data_full_response:\n                return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": reply_data_full_response}, reply)\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": reply_data_full_response}, reply)\n        return FLAdminAPIResponse(\n            APIStatus.ERROR_RUNTIME, {\"message\": \"Runtime error: could not handle server reply.\"}, reply\n        )",
  "def get_connected_client_list(self) -> FLAdminAPIResponse:\n        reply = self._check_status_server()\n        if reply[\"status\"] == APIStatus.SUCCESS:\n            status_table = reply[\"details\"][FLDetailKey.STATUS_TABLE]\n            list_of_connected_clients = []\n            for row in status_table:\n                if row[0] != \"CLIENT NAME\":\n                    list_of_connected_clients.append(row[0])\n            return FLAdminAPIResponse(APIStatus.SUCCESS, {FLDetailKey.CONNECTED_CLIENTS: list_of_connected_clients})\n        else:\n            return FLAdminAPIResponse(APIStatus.ERROR_RUNTIME, {\"message\": \"runtime error\"}, reply)",
  "def wait_until_server_status(\n        self,\n        interval: int = 20,\n        timeout: int = None,\n        callback: Callable[[FLAdminAPIResponse, Optional[List]], bool] = default_server_status_handling_cb,\n        fail_attempts: int = 3,\n        **kwargs,\n    ) -> FLAdminAPIResponse:\n        failed_attempts = 0\n        start = time.time()\n        while True:\n            reply = self._check_status_server()\n            if reply[\"details\"].get(FLDetailKey.SERVER_ENGINE_STATUS):\n                met = callback(reply, **kwargs)\n                if met:\n                    return FLAdminAPIResponse(APIStatus.SUCCESS, {}, None)\n                fail_attempts = 0\n            else:\n                print(\"Could not get reply from check status server, trying again later\")\n                failed_attempts += 1\n\n            now = time.time()\n            if timeout is not None:\n                if now - start >= timeout:\n                    return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": \"Waited until timeout.\"}, None)\n            if failed_attempts > fail_attempts:\n                return FLAdminAPIResponse(\n                    APIStatus.ERROR_RUNTIME,\n                    {\n                        \"message\": \"FL server status was not obtainable for more than the specified number of \"\n                        \"fail_attempts. \"\n                    },\n                    None,\n                )\n            time.sleep(interval)",
  "def wait_until_client_status(\n        self,\n        interval: int = 10,\n        timeout: int = None,\n        callback: Callable[[FLAdminAPIResponse, Optional[List]], bool] = default_client_status_handling_cb,\n        fail_attempts: int = 6,\n        **kwargs,\n    ) -> FLAdminAPIResponse:\n        \"\"\"This is similar to wait_until_server_status() and is an example for using other information from a repeated\n        call, in this case check_status(TargetType.CLIENT). Custom code can be written to use any data available from\n        any call to make decisions for how to proceed. Take caution that the conditions will be met at some point, or\n        timeout should be set with logic outside this function to handle checks for potential errors or this may loop\n        indefinitely.\n\n        Args:\n            interval: in seconds, the time between consecutive checks of the server\n            timeout: if set, the amount of time this function will run until before returning a response message\n            callback: the reply from show_stats(TargetType.SERVER) will be passed to the callback, along with any additional kwargs\n            which can go on to perform additional logic.\n            fail_attempts: number of consecutive failed attempts of getting the server status before returning with ERROR_RUNTIME.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        failed_attempts = 0\n        start = time.time()\n        while True:\n            try:\n                reply = self.check_status(TargetType.CLIENT)\n                if reply:\n                    met = callback(reply, **kwargs)\n                    if met:\n                        return FLAdminAPIResponse(APIStatus.SUCCESS, {}, None)\n                    fail_attempts = 0\n                else:\n                    print(\"Could not get reply from check status client, trying again later\")\n                    failed_attempts += 1\n            except BaseException as e:\n                print(\"Could not get clients stats, trying again later. Exception: \", e)\n                failed_attempts += 1\n\n            now = time.time()\n            if timeout is not None:\n                if now - start >= timeout:\n                    return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": \"Waited until timeout.\"}, None)\n            if failed_attempts > fail_attempts:\n                return FLAdminAPIResponse(\n                    APIStatus.ERROR_RUNTIME,\n                    {\n                        \"message\": \"FL client status was not obtainable for more than the specified number of \"\n                        \"fail_attempts. \"\n                    },\n                    None,\n                )\n            time.sleep(interval)",
  "def wait_until_server_stats(\n        self,\n        interval: int = 10,\n        timeout: int = None,\n        callback: Callable[[FLAdminAPIResponse, Optional[List]], bool] = default_stats_handling_cb,\n        fail_attempts: int = 6,\n        **kwargs,\n    ) -> FLAdminAPIResponse:\n        \"\"\"This is similar to wait_until_server_status() and is an example for using other information from a repeated\n        call, in this case show_stats(TargetType.SERVER). Custom code can be written to use any data available from any\n        call to make decisions for how to proceed. Take caution that the conditions will be met at some point, or\n        timeout should be set with logic outside this function to handle checks for potential errors or this may loop\n        indefinitely.\n\n        Args:\n            interval: in seconds, the time between consecutive checks of the server\n            timeout: if set, the amount of time this function will run until before returning a response message\n            callback: the reply from show_stats(TargetType.SERVER) will be passed to the callback, along with any additional kwargs\n            which can go on to perform additional logic.\n            fail_attempts: number of consecutive failed attempts of getting the server status before returning with ERROR_RUNTIME.\n\n        Returns: FLAdminAPIResponse\n\n        \"\"\"\n        failed_attempts = 0\n        start = time.time()\n        while True:\n            try:\n                reply = self.show_stats(TargetType.SERVER)\n                try:\n                    if reply:\n                        met = callback(reply, **kwargs)\n                        if met:\n                            return FLAdminAPIResponse(APIStatus.SUCCESS, {}, None)\n                        fail_attempts = 0\n                    else:\n                        print(\"Could not get reply from show stats server, trying again later\")\n                        failed_attempts += 1\n                except AttributeError:\n                    # if attribute cannot be found, check if app is no longer running to return APIStatus.SUCCESS\n                    if reply.get(\"details\").get(\"message\") == \"App is not running\":\n                        return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": \"Waited until app not running.\"}, None)\n            except BaseException as e:\n                print(\"Could not get server stats, trying again later. Exception: \", e)\n                failed_attempts += 1\n\n            now = time.time()\n            if timeout is not None:\n                if now - start >= timeout:\n                    return FLAdminAPIResponse(APIStatus.SUCCESS, {\"message\": \"Waited until timeout.\"}, None)\n            if failed_attempts > fail_attempts:\n                return FLAdminAPIResponse(\n                    APIStatus.ERROR_RUNTIME,\n                    {\n                        \"message\": \"FL server stats was not obtainable for more than the specified number of \"\n                        \"fail_attempts. \"\n                    },\n                    None,\n                )\n            time.sleep(interval)",
  "def login(self, username: str):\n        result = super().login(username=username)\n        return FLAdminAPIResponse(status=result[\"status\"], details=result[\"details\"])",
  "def login_with_poc(self, username: str, poc_key: str):\n        result = super().login_with_poc(username=username, poc_key=poc_key)\n        return FLAdminAPIResponse(status=result[\"status\"], details=result[\"details\"])",
  "class ReplyProcessor:\n    \"\"\"A base class for parsing server's response.\"\"\"\n\n    def reply_start(self, api: AdminAPISpec, reply_json):\n        pass\n\n    def process_string(self, api: AdminAPISpec, item: str):\n        pass\n\n    def process_success(self, api: AdminAPISpec, item: str):\n        pass\n\n    def process_error(self, api: AdminAPISpec, err: str):\n        pass\n\n    def process_table(self, api: AdminAPISpec, table: Table):\n        pass\n\n    def process_dict(self, api: AdminAPISpec, data: dict):\n        pass\n\n    def process_shutdown(self, api: AdminAPISpec, msg: str):\n        pass\n\n    def process_token(self, api: AdminAPISpec, token: str):\n        pass\n\n    def protocol_error(self, api: AdminAPISpec, err: str):\n        pass\n\n    def reply_done(self, api: AdminAPISpec):\n        pass",
  "class AdminAPISpec(ABC):\n    def __init__(self):\n        self.reply_processor = None\n        self.command_result = None\n\n    @abstractmethod\n    def server_execute(self, command: str, reply_processor: Optional[ReplyProcessor] = None):\n        \"\"\"Executes a command on server side.\n\n        Args:\n            command: The command to be executed.\n            reply_processor: Reply callback to use.\n        \"\"\"\n        pass\n\n    def set_command_result(self, result):\n        \"\"\"Sets the result returning from executing the command.\"\"\"\n        self.command_result = result\n\n    def get_command_result(self):\n        \"\"\"Gets the result returning from executing the command.\"\"\"\n        return self.command_result",
  "def reply_start(self, api: AdminAPISpec, reply_json):\n        pass",
  "def process_string(self, api: AdminAPISpec, item: str):\n        pass",
  "def process_success(self, api: AdminAPISpec, item: str):\n        pass",
  "def process_error(self, api: AdminAPISpec, err: str):\n        pass",
  "def process_table(self, api: AdminAPISpec, table: Table):\n        pass",
  "def process_dict(self, api: AdminAPISpec, data: dict):\n        pass",
  "def process_shutdown(self, api: AdminAPISpec, msg: str):\n        pass",
  "def process_token(self, api: AdminAPISpec, token: str):\n        pass",
  "def protocol_error(self, api: AdminAPISpec, err: str):\n        pass",
  "def reply_done(self, api: AdminAPISpec):\n        pass",
  "def __init__(self):\n        self.reply_processor = None\n        self.command_result = None",
  "def server_execute(self, command: str, reply_processor: Optional[ReplyProcessor] = None):\n        \"\"\"Executes a command on server side.\n\n        Args:\n            command: The command to be executed.\n            reply_processor: Reply callback to use.\n        \"\"\"\n        pass",
  "def set_command_result(self, result):\n        \"\"\"Sets the result returning from executing the command.\"\"\"\n        self.command_result = result",
  "def get_command_result(self):\n        \"\"\"Gets the result returning from executing the command.\"\"\"\n        return self.command_result",
  "def _server_cmd_name(name: str):\n    return ftd.SERVER_MODULE_NAME + \".\" + name",
  "class _DownloadProcessor(ReplyProcessor):\n    \"\"\"Reply processor to handle downloads.\"\"\"\n\n    def __init__(self, download_dir: str, str_to_file_func):\n        self.download_dir = download_dir\n        self.str_to_file_func = str_to_file_func\n        self.data_received = False\n        self.table = None\n\n    def reply_start(self, api, reply_json):\n        self.data_received = False\n        self.table = Table([\"file\", \"size\"])\n\n    def reply_done(self, api):\n        if not self.data_received:\n            api.set_command_result({\"status\": APIStatus.ERROR_PROTOCOL, \"details\": \"protocol error - no data received\"})\n        else:\n            command_result = api.get_command_result()\n            if command_result is None:\n                command_result = {}\n            command_result[\"status\"] = APIStatus.SUCCESS\n            command_result[\"details\"] = self.table\n            api.set_command_result(command_result)\n\n    def process_table(self, api, table: Table):\n        try:\n            rows = table.rows\n            if len(rows) < 1:\n                # no data\n                api.set_command_result({\"status\": APIStatus.ERROR_PROTOCOL, \"details\": \"protocol error - no file data\"})\n                return\n\n            for i in range(len(rows)):\n                if i == 0:\n                    # this is header\n                    continue\n\n                row = rows[i]\n                if len(row) < 1:\n                    api.set_command_result(\n                        {\n                            \"status\": APIStatus.ERROR_PROTOCOL,\n                            \"details\": \"protocol error - missing file name\",\n                        }\n                    )\n                    return\n\n                if len(row) < 2:\n                    api.set_command_result(\n                        {\n                            \"status\": APIStatus.ERROR_PROTOCOL,\n                            \"details\": \"protocol error - missing file data\",\n                        }\n                    )\n                    return\n\n                file_name = row[0]\n                encoded_str = row[1]\n                full_path = os.path.join(self.download_dir, file_name)\n                num_bytes = self.str_to_file_func(encoded_str, full_path)\n                self.table.add_row([file_name, str(num_bytes)])\n                self.data_received = True\n        except Exception as ex:\n            traceback.print_exc()\n            api.set_command_result({\"status\": APIStatus.ERROR_RUNTIME, \"details\": f\"exception processing file: {ex}\"})",
  "class _DownloadFolderProcessor(ReplyProcessor):\n    \"\"\"Reply processor for handling downloading directories.\"\"\"\n\n    def __init__(self, download_dir: str):\n        self.download_dir = download_dir\n        self.data_received = False\n\n    def reply_start(self, api, reply_json):\n        self.data_received = False\n\n    def reply_done(self, api):\n        if not self.data_received:\n            api.set_command_result({\"status\": APIStatus.ERROR_RUNTIME, \"details\": \"protocol error - no data received\"})\n\n    def process_error(self, api: AdminAPISpec, err: str):\n        self.data_received = True\n        api.set_command_result({\"status\": APIStatus.ERROR_RUNTIME, \"details\": err})\n\n    def process_string(self, api, item: str):\n        try:\n            self.data_received = True\n            if item.startswith(ConnProps.DOWNLOAD_JOB_URL):\n                api.set_command_result(\n                    {\n                        \"status\": APIStatus.SUCCESS,\n                        \"details\": item,\n                    }\n                )\n            else:\n                data_bytes = b64str_to_bytes(item)\n                unzip_all_from_bytes(data_bytes, self.download_dir)\n                api.set_command_result(\n                    {\n                        \"status\": APIStatus.SUCCESS,\n                        \"details\": \"Download to dir {}\".format(self.download_dir),\n                    }\n                )\n        except Exception as ex:\n            traceback.print_exc()\n            api.set_command_result(\n                {\n                    \"status\": APIStatus.ERROR_RUNTIME,\n                    \"details\": \"exception processing reply: {}\".format(ex),\n                }\n            )",
  "class FileTransferModule(CommandModule):\n    \"\"\"Command module with commands relevant to file transfer.\"\"\"\n\n    def __init__(self, upload_dir: str, download_dir: str):\n        if not os.path.isdir(upload_dir):\n            raise ValueError(\"upload_dir {} is not a valid dir\".format(upload_dir))\n\n        if not os.path.isdir(download_dir):\n            raise ValueError(\"download_dir {} is not a valid dir\".format(download_dir))\n\n        self.upload_dir = upload_dir\n        self.download_dir = download_dir\n\n    def get_spec(self):\n        return CommandModuleSpec(\n            name=\"file_transfer\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"upload_text\",\n                    description=\"upload one or more text files in the upload_dir\",\n                    usage=\"upload_text file_name ...\",\n                    handler_func=self.upload_text_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=\"download_text\",\n                    description=\"download one or more text files in the download_dir\",\n                    usage=\"download_text file_name ...\",\n                    handler_func=self.download_text_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=\"upload_binary\",\n                    description=\"upload one or more binary files in the upload_dir\",\n                    usage=\"upload_binary file_name ...\",\n                    handler_func=self.upload_binary_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=\"download_binary\",\n                    description=\"download one or more binary files in the download_dir\",\n                    usage=\"download_binary file_name ...\",\n                    handler_func=self.download_binary_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=\"submit_job\",\n                    description=\"Submit application to the server\",\n                    usage=\"submit_job job_folder\",\n                    handler_func=self.submit_job,\n                ),\n                CommandSpec(\n                    name=\"download_job\",\n                    description=\"download job contents from the server\",\n                    usage=\"download_job job_id\",\n                    handler_func=self.download_job,\n                ),\n                CommandSpec(\n                    name=\"info\",\n                    description=\"show folder setup info\",\n                    usage=\"info\",\n                    handler_func=self.info,\n                ),\n            ],\n        )\n\n    def upload_file(self, args, api: AdminAPISpec, cmd_name, file_to_str_func):\n        full_cmd_name = _server_cmd_name(cmd_name)\n        if len(args) < 2:\n            return {\"status\": APIStatus.ERROR_SYNTAX, \"details\": \"syntax error: missing file names\"}\n\n        parts = [full_cmd_name]\n        for i in range(1, len(args)):\n            file_name = args[i]\n            full_path = os.path.join(self.upload_dir, file_name)\n            if not os.path.isfile(full_path):\n                return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": f\"no such file: {full_path}\"}\n\n            encoded_string = file_to_str_func(full_path)\n            parts.append(file_name)\n            parts.append(encoded_string)\n\n        command = join_args(parts)\n        return api.server_execute(command)\n\n    def upload_text_file(self, args, api: AdminAPISpec):\n        return self.upload_file(args, api, ftd.SERVER_CMD_UPLOAD_TEXT, text_file_to_b64str)\n\n    def upload_binary_file(self, args, api: AdminAPISpec):\n        return self.upload_file(args, api, ftd.SERVER_CMD_UPLOAD_BINARY, binary_file_to_b64str)\n\n    def download_file(self, args, api: AdminAPISpec, cmd_name, str_to_file_func):\n        full_cmd_name = _server_cmd_name(cmd_name)\n        if len(args) < 2:\n            return {\"status\": APIStatus.ERROR_SYNTAX, \"details\": \"syntax error: missing file names\"}\n\n        parts = [full_cmd_name]\n        for i in range(1, len(args)):\n            file_name = args[i]\n            parts.append(file_name)\n\n        command = join_args(parts)\n        reply_processor = _DownloadProcessor(self.download_dir, str_to_file_func)\n        return api.server_execute(command, reply_processor)\n\n    def download_text_file(self, args, api: AdminAPISpec):\n        return self.download_file(args, api, ftd.SERVER_CMD_DOWNLOAD_TEXT, b64str_to_text_file)\n\n    def download_binary_file(self, args, api: AdminAPISpec):\n        return self.download_file(args, api, ftd.SERVER_CMD_DOWNLOAD_BINARY, b64str_to_binary_file)\n\n    def upload_folder(self, args, api: AdminAPISpec):\n        if len(args) != 2:\n            return {\"status\": APIStatus.ERROR_SYNTAX, \"details\": \"usage: upload_folder folder_name\"}\n\n        folder_name = args[1]\n        if folder_name.endswith(\"/\"):\n            folder_name = folder_name.rstrip(\"/\")\n\n        full_path = os.path.join(self.upload_dir, folder_name)\n        if not os.path.isdir(full_path):\n            return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": f\"'{full_path}' is not a valid folder.\"}\n\n        # zip the data\n        data = zip_directory_to_bytes(self.upload_dir, folder_name)\n\n        # prepare for upload\n        rel_path = os.path.relpath(full_path, self.upload_dir)\n        folder_name = remove_leading_dotdot(rel_path)\n\n        b64str = bytes_to_b64str(data)\n        parts = [_server_cmd_name(ftd.SERVER_CMD_UPLOAD_FOLDER), folder_name, b64str]\n        command = join_args(parts)\n        return api.server_execute(command)\n\n    def submit_job(self, args, api: AdminAPISpec):\n        if len(args) != 2:\n            return {\"status\": APIStatus.ERROR_SYNTAX, \"details\": \"usage: submit_job job_folder\"}\n\n        folder_name = args[1]\n        if folder_name.endswith(\"/\"):\n            folder_name = folder_name.rstrip(\"/\")\n\n        full_path = os.path.join(self.upload_dir, folder_name)\n        if not os.path.isdir(full_path):\n            return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": f\"'{full_path}' is not a valid folder.\"}\n\n        # zip the data\n        data = zip_directory_to_bytes(self.upload_dir, folder_name)\n\n        folder_name = split_path(full_path)[1]\n        b64str = bytes_to_b64str(data)\n        parts = [_server_cmd_name(ftd.SERVER_CMD_SUBMIT_JOB), folder_name, b64str]\n        command = join_args(parts)\n        return api.server_execute(command)\n\n    def download_job(self, args, api: AdminAPISpec):\n        if len(args) != 2:\n            return {\"status\": APIStatus.ERROR_SYNTAX, \"details\": \"usage: download_job job_id\"}\n        job_id = args[1]\n        parts = [_server_cmd_name(ftd.SERVER_CMD_DOWNLOAD_JOB), job_id]\n        command = join_args(parts)\n        reply_processor = _DownloadFolderProcessor(self.download_dir)\n        return api.server_execute(command, reply_processor)\n\n    def info(self, args, api: AdminAPISpec):\n        msg = f\"Local Upload Source: {self.upload_dir}\\n\"\n        msg += f\"Local Download Destination: {self.download_dir}\\n\"\n        resp = api.server_execute(_server_cmd_name(ftd.SERVER_CMD_INFO))\n        if \"details\" not in resp:\n            resp[\"details\"] = msg\n        else:\n            resp[\"details\"] = msg + resp[\"details\"]\n        api.set_command_result(resp)\n        return resp",
  "def __init__(self, download_dir: str, str_to_file_func):\n        self.download_dir = download_dir\n        self.str_to_file_func = str_to_file_func\n        self.data_received = False\n        self.table = None",
  "def reply_start(self, api, reply_json):\n        self.data_received = False\n        self.table = Table([\"file\", \"size\"])",
  "def reply_done(self, api):\n        if not self.data_received:\n            api.set_command_result({\"status\": APIStatus.ERROR_PROTOCOL, \"details\": \"protocol error - no data received\"})\n        else:\n            command_result = api.get_command_result()\n            if command_result is None:\n                command_result = {}\n            command_result[\"status\"] = APIStatus.SUCCESS\n            command_result[\"details\"] = self.table\n            api.set_command_result(command_result)",
  "def process_table(self, api, table: Table):\n        try:\n            rows = table.rows\n            if len(rows) < 1:\n                # no data\n                api.set_command_result({\"status\": APIStatus.ERROR_PROTOCOL, \"details\": \"protocol error - no file data\"})\n                return\n\n            for i in range(len(rows)):\n                if i == 0:\n                    # this is header\n                    continue\n\n                row = rows[i]\n                if len(row) < 1:\n                    api.set_command_result(\n                        {\n                            \"status\": APIStatus.ERROR_PROTOCOL,\n                            \"details\": \"protocol error - missing file name\",\n                        }\n                    )\n                    return\n\n                if len(row) < 2:\n                    api.set_command_result(\n                        {\n                            \"status\": APIStatus.ERROR_PROTOCOL,\n                            \"details\": \"protocol error - missing file data\",\n                        }\n                    )\n                    return\n\n                file_name = row[0]\n                encoded_str = row[1]\n                full_path = os.path.join(self.download_dir, file_name)\n                num_bytes = self.str_to_file_func(encoded_str, full_path)\n                self.table.add_row([file_name, str(num_bytes)])\n                self.data_received = True\n        except Exception as ex:\n            traceback.print_exc()\n            api.set_command_result({\"status\": APIStatus.ERROR_RUNTIME, \"details\": f\"exception processing file: {ex}\"})",
  "def __init__(self, download_dir: str):\n        self.download_dir = download_dir\n        self.data_received = False",
  "def reply_start(self, api, reply_json):\n        self.data_received = False",
  "def reply_done(self, api):\n        if not self.data_received:\n            api.set_command_result({\"status\": APIStatus.ERROR_RUNTIME, \"details\": \"protocol error - no data received\"})",
  "def process_error(self, api: AdminAPISpec, err: str):\n        self.data_received = True\n        api.set_command_result({\"status\": APIStatus.ERROR_RUNTIME, \"details\": err})",
  "def process_string(self, api, item: str):\n        try:\n            self.data_received = True\n            if item.startswith(ConnProps.DOWNLOAD_JOB_URL):\n                api.set_command_result(\n                    {\n                        \"status\": APIStatus.SUCCESS,\n                        \"details\": item,\n                    }\n                )\n            else:\n                data_bytes = b64str_to_bytes(item)\n                unzip_all_from_bytes(data_bytes, self.download_dir)\n                api.set_command_result(\n                    {\n                        \"status\": APIStatus.SUCCESS,\n                        \"details\": \"Download to dir {}\".format(self.download_dir),\n                    }\n                )\n        except Exception as ex:\n            traceback.print_exc()\n            api.set_command_result(\n                {\n                    \"status\": APIStatus.ERROR_RUNTIME,\n                    \"details\": \"exception processing reply: {}\".format(ex),\n                }\n            )",
  "def __init__(self, upload_dir: str, download_dir: str):\n        if not os.path.isdir(upload_dir):\n            raise ValueError(\"upload_dir {} is not a valid dir\".format(upload_dir))\n\n        if not os.path.isdir(download_dir):\n            raise ValueError(\"download_dir {} is not a valid dir\".format(download_dir))\n\n        self.upload_dir = upload_dir\n        self.download_dir = download_dir",
  "def get_spec(self):\n        return CommandModuleSpec(\n            name=\"file_transfer\",\n            cmd_specs=[\n                CommandSpec(\n                    name=\"upload_text\",\n                    description=\"upload one or more text files in the upload_dir\",\n                    usage=\"upload_text file_name ...\",\n                    handler_func=self.upload_text_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=\"download_text\",\n                    description=\"download one or more text files in the download_dir\",\n                    usage=\"download_text file_name ...\",\n                    handler_func=self.download_text_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=\"upload_binary\",\n                    description=\"upload one or more binary files in the upload_dir\",\n                    usage=\"upload_binary file_name ...\",\n                    handler_func=self.upload_binary_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=\"download_binary\",\n                    description=\"download one or more binary files in the download_dir\",\n                    usage=\"download_binary file_name ...\",\n                    handler_func=self.download_binary_file,\n                    visible=False,\n                ),\n                CommandSpec(\n                    name=\"submit_job\",\n                    description=\"Submit application to the server\",\n                    usage=\"submit_job job_folder\",\n                    handler_func=self.submit_job,\n                ),\n                CommandSpec(\n                    name=\"download_job\",\n                    description=\"download job contents from the server\",\n                    usage=\"download_job job_id\",\n                    handler_func=self.download_job,\n                ),\n                CommandSpec(\n                    name=\"info\",\n                    description=\"show folder setup info\",\n                    usage=\"info\",\n                    handler_func=self.info,\n                ),\n            ],\n        )",
  "def upload_file(self, args, api: AdminAPISpec, cmd_name, file_to_str_func):\n        full_cmd_name = _server_cmd_name(cmd_name)\n        if len(args) < 2:\n            return {\"status\": APIStatus.ERROR_SYNTAX, \"details\": \"syntax error: missing file names\"}\n\n        parts = [full_cmd_name]\n        for i in range(1, len(args)):\n            file_name = args[i]\n            full_path = os.path.join(self.upload_dir, file_name)\n            if not os.path.isfile(full_path):\n                return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": f\"no such file: {full_path}\"}\n\n            encoded_string = file_to_str_func(full_path)\n            parts.append(file_name)\n            parts.append(encoded_string)\n\n        command = join_args(parts)\n        return api.server_execute(command)",
  "def upload_text_file(self, args, api: AdminAPISpec):\n        return self.upload_file(args, api, ftd.SERVER_CMD_UPLOAD_TEXT, text_file_to_b64str)",
  "def upload_binary_file(self, args, api: AdminAPISpec):\n        return self.upload_file(args, api, ftd.SERVER_CMD_UPLOAD_BINARY, binary_file_to_b64str)",
  "def download_file(self, args, api: AdminAPISpec, cmd_name, str_to_file_func):\n        full_cmd_name = _server_cmd_name(cmd_name)\n        if len(args) < 2:\n            return {\"status\": APIStatus.ERROR_SYNTAX, \"details\": \"syntax error: missing file names\"}\n\n        parts = [full_cmd_name]\n        for i in range(1, len(args)):\n            file_name = args[i]\n            parts.append(file_name)\n\n        command = join_args(parts)\n        reply_processor = _DownloadProcessor(self.download_dir, str_to_file_func)\n        return api.server_execute(command, reply_processor)",
  "def download_text_file(self, args, api: AdminAPISpec):\n        return self.download_file(args, api, ftd.SERVER_CMD_DOWNLOAD_TEXT, b64str_to_text_file)",
  "def download_binary_file(self, args, api: AdminAPISpec):\n        return self.download_file(args, api, ftd.SERVER_CMD_DOWNLOAD_BINARY, b64str_to_binary_file)",
  "def upload_folder(self, args, api: AdminAPISpec):\n        if len(args) != 2:\n            return {\"status\": APIStatus.ERROR_SYNTAX, \"details\": \"usage: upload_folder folder_name\"}\n\n        folder_name = args[1]\n        if folder_name.endswith(\"/\"):\n            folder_name = folder_name.rstrip(\"/\")\n\n        full_path = os.path.join(self.upload_dir, folder_name)\n        if not os.path.isdir(full_path):\n            return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": f\"'{full_path}' is not a valid folder.\"}\n\n        # zip the data\n        data = zip_directory_to_bytes(self.upload_dir, folder_name)\n\n        # prepare for upload\n        rel_path = os.path.relpath(full_path, self.upload_dir)\n        folder_name = remove_leading_dotdot(rel_path)\n\n        b64str = bytes_to_b64str(data)\n        parts = [_server_cmd_name(ftd.SERVER_CMD_UPLOAD_FOLDER), folder_name, b64str]\n        command = join_args(parts)\n        return api.server_execute(command)",
  "def submit_job(self, args, api: AdminAPISpec):\n        if len(args) != 2:\n            return {\"status\": APIStatus.ERROR_SYNTAX, \"details\": \"usage: submit_job job_folder\"}\n\n        folder_name = args[1]\n        if folder_name.endswith(\"/\"):\n            folder_name = folder_name.rstrip(\"/\")\n\n        full_path = os.path.join(self.upload_dir, folder_name)\n        if not os.path.isdir(full_path):\n            return {\"status\": APIStatus.ERROR_RUNTIME, \"details\": f\"'{full_path}' is not a valid folder.\"}\n\n        # zip the data\n        data = zip_directory_to_bytes(self.upload_dir, folder_name)\n\n        folder_name = split_path(full_path)[1]\n        b64str = bytes_to_b64str(data)\n        parts = [_server_cmd_name(ftd.SERVER_CMD_SUBMIT_JOB), folder_name, b64str]\n        command = join_args(parts)\n        return api.server_execute(command)",
  "def download_job(self, args, api: AdminAPISpec):\n        if len(args) != 2:\n            return {\"status\": APIStatus.ERROR_SYNTAX, \"details\": \"usage: download_job job_id\"}\n        job_id = args[1]\n        parts = [_server_cmd_name(ftd.SERVER_CMD_DOWNLOAD_JOB), job_id]\n        command = join_args(parts)\n        reply_processor = _DownloadFolderProcessor(self.download_dir)\n        return api.server_execute(command, reply_processor)",
  "def info(self, args, api: AdminAPISpec):\n        msg = f\"Local Upload Source: {self.upload_dir}\\n\"\n        msg += f\"Local Download Destination: {self.download_dir}\\n\"\n        resp = api.server_execute(_server_cmd_name(ftd.SERVER_CMD_INFO))\n        if \"details\" not in resp:\n            resp[\"details\"] = msg\n        else:\n            resp[\"details\"] = msg + resp[\"details\"]\n        api.set_command_result(resp)\n        return resp",
  "class FLDetailKey(str, Enum):\n    \"\"\"Constants for FL details that can be returned in the FLAdminAPI.\"\"\"\n\n    APP_NAME = \"app_name\"\n    REGISTERED_CLIENTS = \"registered_clients\"\n    CONNECTED_CLIENTS = \"connected_clients\"\n    SERVER_ENGINE_STATUS = \"server_engine_status\"\n    SERVER_LOG = \"server_log\"\n    CLIENT_LOG = \"client_log\"\n    STATUS_TABLE = \"status_table\"\n    RESPONSES = \"responses\"\n    SUBMITTED_MODELS = \"submitted_models\"",
  "class APIStatus(str, Enum):\n    \"\"\"Constants for the valid status options for the status of FLAdminAPIResponse.\"\"\"\n\n    SUCCESS = \"SUCCESS\"  # command issues successfully\n    ERROR_PROTOCOL = (\n        \"ERROR_PROTOCOL\"  # the payload/data is not following the correct format/protocol expected by the server\n    )\n    ERROR_CERT = \"ERROR_CERT\"  # key or certs are incorrect\n    ERROR_AUTHENTICATION = \"ERROR_AUTHENTICATION\"  # authentication failed, need to log in\n    ERROR_AUTHORIZATION = \"ERROR_AUTHORIZATION\"  # authorization failed, permissions\n    ERROR_SYNTAX = \"ERROR_SYNTAX\"  # command syntax incorrect\n    ERROR_RUNTIME = \"ERROR_RUNTIME\"  # various errors at runtime depending on the command\n    ERROR_INVALID_CLIENT = \"ERROR_INVALID_CLIENT\"  # wrong/invalid client names exists in command\n    ERROR_INACTIVE_SESSION = \"ERROR_INACTIVE_SESSION\"  # admin client session is inactive\n    ERROR_SERVER_CONNECTION = \"ERROR_SERVER_CONNECTION\"",
  "class CommunicationMetaData(object):\n    COMMAND = \"command\"\n    TASK_NAME = \"task_name\"\n    FL_CTX = \"fl_ctx\"\n    EVENT_TYPE = \"event_type\"\n    HANDLE_CONN = \"handle_conn\"\n    EXE_CONN = \"exe_conn\"\n    COMPONENTS = \"MPExecutor_components\"\n    HANDLERS = \"MPExecutor_handlers\"\n    LOCAL_EXECUTOR = \"local_executor\"\n    RANK_NUMBER = \"rank_number\"\n    SHAREABLE = \"shareable\"\n    RELAYER = \"relayer\"\n    RANK_PROCESS_STARTED = \"rank_process_started\"\n    PARENT_PASSWORD = \"parent process secret password\"\n    CHILD_PASSWORD = \"client process secret password\"",
  "class CommunicateData(object):\n    EXECUTE = \"execute\"\n    HANDLE_EVENT = \"handle_event\"\n    CLOSE = \"close\"\n    SUB_WORKER_PROCESS = \"sub_worker_process\"\n    MULTI_PROCESS_EXECUTOR = \"multi_process_executor\"",
  "class SimpleContext(object):\n    def __init__(self):\n        \"\"\"A simple context containing a props dictionary of key value pairs and convenience methods.\"\"\"\n        self.props = {}\n\n    def set_prop(self, key, value):\n        self.props[key] = value\n\n    def set_props(self, props: dict):\n        if props:\n            self.props.update(props)\n\n    def len(self):\n        return len(self.props)\n\n    def get_prop(self, key, default=None):\n        return self.props.get(key, default)\n\n    def clear_props(self):\n        self.props = {}",
  "class BaseContext(SimpleContext):\n    def __init__(self):\n        \"\"\"A SimpleContext with threading locks.\n\n        This context class enables thread-safe set/get on top of SimpleContext.\"\"\"\n        SimpleContext.__init__(self)\n        self._update_lock = threading.Lock()\n\n    def set_prop(self, key, value):\n        with self._update_lock:\n            SimpleContext.set_prop(self, key, value)\n\n    def set_props(self, props: dict):\n        if not props:\n            return\n\n        with self._update_lock:\n            SimpleContext.set_props(self, props)\n\n    def len(self):\n        with self._update_lock:\n            return SimpleContext.len(self)\n\n    def get_prop(self, key, default=None):\n        with self._update_lock:\n            return SimpleContext.get_prop(self, key, default)\n\n    def clear_props(self):\n        with self._update_lock:\n            SimpleContext.clear_props(self)",
  "def __init__(self):\n        \"\"\"A simple context containing a props dictionary of key value pairs and convenience methods.\"\"\"\n        self.props = {}",
  "def set_prop(self, key, value):\n        self.props[key] = value",
  "def set_props(self, props: dict):\n        if props:\n            self.props.update(props)",
  "def len(self):\n        return len(self.props)",
  "def get_prop(self, key, default=None):\n        return self.props.get(key, default)",
  "def clear_props(self):\n        self.props = {}",
  "def __init__(self):\n        \"\"\"A SimpleContext with threading locks.\n\n        This context class enables thread-safe set/get on top of SimpleContext.\"\"\"\n        SimpleContext.__init__(self)\n        self._update_lock = threading.Lock()",
  "def set_prop(self, key, value):\n        with self._update_lock:\n            SimpleContext.set_prop(self, key, value)",
  "def set_props(self, props: dict):\n        if not props:\n            return\n\n        with self._update_lock:\n            SimpleContext.set_props(self, props)",
  "def len(self):\n        with self._update_lock:\n            return SimpleContext.len(self)",
  "def get_prop(self, key, default=None):\n        with self._update_lock:\n            return SimpleContext.get_prop(self, key, default)",
  "def clear_props(self):\n        with self._update_lock:\n            SimpleContext.clear_props(self)",
  "class ConfigError(Exception):\n    \"\"\"Raised when configuration parsing error happens.\"\"\"\n\n    pass",
  "def _validate_value(type_def: dict, value):\n    value_type = type_def.get(\"type\", \"bool\")\n    if value_type == \"bool\":\n        if value not in [True, False]:\n            return False\n    elif not isinstance(value, (int, float)):\n        return False\n    return True",
  "def validate_policy_config(config: dict) -> str:\n    \"\"\"Validates that an authorization policy configuration has the right syntax.\n\n    Args:\n        config: configuration dictionary to validate\n\n    Returns: empty string if there are no errors, else a string describing the error encountered\n\n    \"\"\"\n    if not isinstance(config, dict):\n        return \"policy definition must be a dict\"\n\n    # validate rules\n    policy_rules = config.get(\"rules\", None)\n    if not policy_rules:\n        return \"missing rules in policy\"\n    if not isinstance(policy_rules, dict):\n        return \"rules must be dict\"\n    for rule_name, rule_def in policy_rules.items():\n        if not isinstance(rule_def, dict):\n            return 'bad rule \"{}\": must be a dict'.format(rule_name)\n\n        default_value = rule_def.get(\"default\", None)\n        if default_value is None:\n            return 'bad rule \"{}\": missing default value'.format(rule_name)\n\n        rule_type = rule_def.get(\"type\", \"bool\")\n        if rule_type not in [\"bool\", \"int\"]:\n            return 'bad rule \"{}\": invalid type \"{}\"'.format(rule_name, rule_type)\n\n        if not _validate_value(rule_def, default_value):\n            return 'bad rule \"{}\": invalid default \"{}\"'.format(rule_name, default_value)\n\n    # validate rights\n    policy_rights = config.get(\"rights\", None)\n    if not policy_rights:\n        return \"missing rights in policy\"\n    if not isinstance(policy_rights, dict):\n        return \"rights must be dict\"\n    for right_name, right_def in policy_rights.items():\n        if not isinstance(right_def, dict):\n            return 'bad right \"{}\": must be a dict'.format(right_name)\n\n        precond = right_def.get(\"precond\", None)\n        if precond is not None and precond not in [\"selfOrg\"]:\n            return 'bad right \"{}\": unknown precond \"{}\"'.format(right_name, precond)\n\n        default_value = right_def.get(\"default\", None)\n        if default_value is None:\n            return 'bad right \"{}\": missing default value'.format(right_name)\n\n        right_type = right_def.get(\"type\", \"bool\")\n        if right_type not in [\"bool\", \"int\"]:\n            return 'bad right \"{}\": invalid type \"{}\"'.format(right_name, right_type)\n\n        if not _validate_value(right_def, default_value):\n            return 'bad right \"{}\": invalid default \"{}\"'.format(right_name, default_value)\n\n    # validate roles\n    policy_roles = config.get(\"roles\", {})\n    if policy_roles:\n        if not isinstance(policy_roles, dict):\n            return \"roles must be dict\"\n\n        for role_name, role_desc in policy_roles.items():\n            if not isinstance(role_name, str):\n                return 'bad role name \"{}\": must be str'.format(role_name)\n            if not isinstance(role_desc, str):\n                return 'bad role desc \"{}\": must be str'.format(role_desc)\n\n    # validate groups\n    policy_groups = config.get(\"groups\", {})\n    if policy_groups:\n        if not isinstance(policy_groups, dict):\n            return \"groups must be dict\"\n\n        for grp_name, grp_def in policy_groups.items():\n            if not isinstance(grp_def, dict):\n                return 'bad group \"{}\": group def must be dict'.format(grp_name)\n            rules = grp_def.get(\"rules\", None)\n            if rules:\n                if not isinstance(rules, dict):\n                    return 'bad group \"{}\": rules must be dict'.format(grp_name)\n                for rule_name, rule_value in rules.items():\n                    rule_def = policy_rules.get(rule_name, None)\n                    if not rule_def:\n                        return 'bad group \"{}\": unknown rule \"{}\"'.format(grp_name, rule_name)\n                    if not _validate_value(rule_def, rule_value):\n                        return 'bad group \"{}\": invalid value \"{}\" for rule \"{}\"'.format(\n                            grp_name, rule_value, rule_name\n                        )\n\n            role_rights = grp_def.get(\"role_rights\", None)\n            if role_rights:\n                if not isinstance(role_rights, dict):\n                    return 'bad group \"{}\": role_rights must be dict'.format(grp_name)\n                for role_name, rights in role_rights.items():\n                    if not isinstance(rights, dict):\n                        return 'bad group \"{}\": rights of role \"{}\" must be dict'.format(grp_name, role_name)\n                    for right_name, right_value in rights.items():\n                        right_def = policy_rights.get(right_name, None)\n                        if not right_def:\n                            return 'bad group \"{}\": unknown right \"{}\" in role \"{}\" must be dict'.format(\n                                grp_name, right_name, role_name\n                            )\n                        if not _validate_value(right_def, right_value):\n                            return 'bad group \"{}\": invalid value \"{}\" for right \"{}\" in role \"{}\" must be dict'.format(\n                                grp_name, right_value, right_name, role_name\n                            )\n\n    # validate orgs\n    policy_orgs = config.get(\"orgs\", None)\n    if not policy_orgs:\n        return \"missing orgs in policy\"\n\n    if not isinstance(policy_orgs, dict):\n        return \"orgs must be a dict\"\n\n    for org_name, groups in policy_orgs.items():\n        if not isinstance(groups, list):\n            return 'bad org \"{}\": groups must be a list'.format(org_name)\n        if len(groups) <= 0:\n            return 'bad org \"{}\": groups not defined'.format(org_name)\n        for grp_name in groups:\n            if not isinstance(grp_name, str):\n                return 'bad org \"{}\": group name must be str'.format(org_name)\n            grp_def = policy_groups.get(grp_name, None)\n            if not grp_def:\n                return 'bad org \"{}\": undefined group \"{}\"'.format(org_name, grp_name)\n\n    # validate users\n    policy_users = config.get(\"users\", None)\n    if not policy_users:\n        return \"missing users in policy\"\n\n    if not isinstance(policy_users, dict):\n        return \"users must be dict\"\n\n    for user_name, user_def in policy_users.items():\n        if not isinstance(user_def, dict):\n            return 'bad user \"{}\": definition must be dict'.format(user_name)\n        org_name = user_def.get(\"org\", None)\n        if not org_name:\n            return 'bad user \"{}\": missing org'.format(user_name)\n\n        org_def = policy_orgs.get(org_name)\n        if not org_def:\n            return 'bad user \"{}\": undefined org \"{}\"'.format(user_name, org_name)\n\n        roles = user_def.get(\"roles\", None)\n        if not roles:\n            return 'bad user \"{}\": missing roles'.format(user_name)\n        if not isinstance(roles, list):\n            return 'bad user \"{}\": roles must be list'.format(user_name)\n        if len(roles) <= 0:\n            return 'bad user \"{}\": no roles defined'.format(user_name)\n        for role_name in roles:\n            if not isinstance(role_name, str):\n                return 'bad user \"{}\": role name must be str'.format(user_name)\n            role_def = policy_roles.get(role_name, None)\n            if not role_def:\n                return 'bad user \"{}\": undefined role \"{}\" must be str'.format(user_name, role_name)\n\n    # validate sites\n    sites = config.get(\"sites\", None)\n    if not sites:\n        return \"missing sites in policy\"\n\n    if not isinstance(sites, dict):\n        return \"sites must be dict\"\n\n    for site_name, org_name in sites.items():\n        if org_name not in policy_orgs:\n            return 'bad site \"{}\": undefined org \"{}\"'.format(site_name, org_name)\n\n    return \"\"",
  "def _group_rule_key(grp_name: str, rule_name: str):\n    return grp_name + \":\" + rule_name",
  "def _group_role_right_key(grp_name: str, role_name: str, right_name: str):\n    return grp_name + \":\" + role_name + \":\" + right_name",
  "def _eval_bool(space: dict, keys: [str]):\n    exit_value = None\n    for k in keys:\n        value = space.get(k, None)\n        if value:\n            return True\n        if value is not None:\n            exit_value = False\n    return exit_value",
  "def _eval_int(space: dict, keys: [str]):\n    exit_value = None\n    for k in keys:\n        value = space.get(k, None)\n        if value is not None:\n            if exit_value is None or exit_value < value:\n                exit_value = value\n    return exit_value",
  "class Policy(object):\n    def __init__(self, conf: dict):\n        \"\"\"The authorization policy definition.\n\n        Authorization policy definition with methods to access information about the policy. Init creates the internal\n        representation of the policy from a config dictionary.\n\n        Policy evaluation result:\n\n        For bool type of rules or rights:\n\n            True - the rule is satisfied or the right is granted\n            False - the rule is not satisfied; the right iis not granted\n            None - the rule or right is not applicable (precondition not met)\n\n        For int type or rules or rights:\n\n            Number - the value of the evaluation\n            None - the rule or right is not applicable (precondition not met)\n\n        Args:\n            conf (dict): the configuration dictionary with keys=groups, users, rights, rules, sites, orgs\n        \"\"\"\n        self.config = conf\n        self.preconf_valuators = {\"selfOrg\": self._eval_precond_self_org}\n\n        # compute the rule and right spaces\n        self.rule_space = {}\n        self.right_space = {}\n        groups = conf[\"groups\"]\n        for grp_name, grp_def in groups.items():\n            rules = grp_def.get(\"rules\", None)\n            if rules:\n                for rule_name, rule_value in rules.items():\n                    key = _group_rule_key(grp_name, rule_name)\n                    self.rule_space[key] = rule_value\n\n            role_rights = grp_def.get(\"role_rights\", None)\n            if role_rights:\n                for role_name, rights in role_rights.items():\n                    for right_name, right_value in rights.items():\n                        key = _group_role_right_key(grp_name, role_name, right_name)\n                        self.right_space[key] = right_value\n\n    def get_config(self):\n        return self.config\n\n    def _eval_precond(self, precond: str, user_name: str, org_name: str):\n        evaluator = self.preconf_valuators.get(precond, None)\n        if not evaluator:\n            return None\n        else:\n            return evaluator(user_name, org_name)\n\n    def _eval_precond_self_org(self, user_name: str, org_name: str):\n        users = self.config[\"users\"]\n        user = users[user_name]\n        return user[\"org\"] == org_name\n\n    def _get_org_groups(self, org_name: str):\n        orgs = self.config[\"orgs\"]\n        return orgs.get(org_name, None)\n\n    def evaluate_rule_on_org(self, rule_name: str, org_name: str):\n        rules = self.config[\"rules\"]\n        rule_def = rules.get(rule_name, None)\n        if not rule_def:\n            return None, 'undefined rule \"{}\"'.format(rule_name)\n\n        rule_type = rule_def.get(\"type\", \"bool\")\n        groups = self._get_org_groups(org_name)\n        if not groups:\n            return None, 'unknown org \"{}\"'.format(org_name)\n\n        keys = []\n        for grp_name in groups:\n            keys.append(_group_rule_key(grp_name, rule_name))\n\n        if rule_type == \"bool\":\n            result = _eval_bool(space=self.rule_space, keys=keys)\n        else:\n            result = _eval_bool(space=self.rule_space, keys=keys)\n\n        if result is None:\n            result = rule_def[\"default\"]\n        return result, \"\"\n\n    def _get_org_of_site(self, site_name):\n        sites = self.config[\"sites\"]\n        return sites.get(site_name, None)\n\n    def evaluate_rule_on_site(self, rule_name: str, site_name: str):\n        org_name = self._get_org_of_site(site_name)\n        if not org_name:\n            return None, 'unknown site \"{}\"'.format(site_name)\n        return self.evaluate_rule_on_org(rule_name, org_name)\n\n    def evaluate_user_right_on_org(self, right_name: str, user_name: str, org_name: str):\n        rights = self.config[\"rights\"]\n        right_def = rights.get(right_name, None)\n        if not right_def:\n            return None, 'undefined right \"{}\"'.format(right_name)\n\n        right_type = right_def.get(\"type\", \"bool\")\n        groups = self._get_org_groups(org_name)\n        if not groups:\n            return None, 'unknown org \"{}\"'.format(org_name)\n\n        users = self.config[\"users\"]\n        user = users.get(user_name, None)\n        if not user:\n            return None, 'unknown user \"{}\"'.format(user_name)\n\n        precond = right_def.get(\"precond\", None)\n        if precond:\n            matched = self._eval_precond(precond, user_name, org_name)\n            if not matched:\n                if right_type == \"bool\":\n                    return False, \"\"\n                else:\n                    return 0, \"\"\n\n        roles = user[\"roles\"]\n        keys = []\n        for grp_name in groups:\n            for role_name in roles:\n                keys.append(_group_role_right_key(grp_name, role_name, right_name))\n\n        if right_type == \"bool\":\n            result = _eval_bool(self.right_space, keys)\n        else:\n            result = _eval_int(self.right_space, keys)\n\n        if result is None:\n            result = right_def[\"default\"]\n        return result, \"\"\n\n    def evaluate_user_right_on_site(self, right_name: str, user_name: str, site_name: str):\n        org_name = self._get_org_of_site(site_name)\n        if not org_name:\n            return None, 'unknown site \"{}\"'.format(site_name)\n        return self.evaluate_user_right_on_org(right_name, user_name, org_name)\n\n    def get_user(self, user_name: str):\n        users = self.config[\"users\"]\n        return users.get(user_name, None)\n\n    def get_users(self):\n        return self.config[\"users\"]\n\n    def get_sites(self):\n        return self.config[\"sites\"]\n\n    def get_rights(self):\n        return self.config[\"rights\"]\n\n    def get_rules(self):\n        return self.config[\"rules\"]\n\n    def get_right_type(self, right_name: str):\n        rights = self.config[\"rights\"]\n        right_def = rights.get(right_name, None)\n        if not right_def:\n            return None\n        return right_def.get(\"type\", \"bool\")",
  "class AuthzContext(object):\n    def __init__(self, user_name: str, site_names: List[str]):\n        \"\"\"Base class to contain context data for authorization.\n\n        Args:\n            user_name (str): user name to be checked\n            site_names (List[str]): site names to be checked against\n        \"\"\"\n        self.user_name = user_name\n        self.site_names = site_names\n        self.attrs = {}\n\n    def set_attr(self, key: str, value):\n        self.attrs[key] = value\n\n    def get_attr(self, key: str, default=None):\n        return self.attrs.get(key, default)",
  "class Authorizer(object):\n    def __init__(self):\n        \"\"\"Base class containing the authorization policy.\"\"\"\n        self.policy = None\n        self.last_load_time = None\n\n    def get_policy(self) -> Policy:\n        return self.policy\n\n    def authorize(self, ctx: AuthzContext) -> (object, str):\n        return True, \"\"\n\n    def evaluate_user_right_on_site(self, right_name: str, user_name: str, site_name: str):\n        if not self.policy:\n            return None, \"policy not defined\"\n        return self.policy.evaluate_user_right_on_site(right_name=right_name, user_name=user_name, site_name=site_name)\n\n    def evaluate_rule_on_site(self, rule_name: str, site_name: str):\n        if not self.policy:\n            return None, \"policy not defined\"\n\n        return self.policy.evaluate_rule_on_site(rule_name=rule_name, site_name=site_name)\n\n    def load_policy(self, policy_config: dict) -> str:\n        err = validate_policy_config(policy_config)\n        if err:\n            return err\n\n        self.policy = Policy(policy_config)\n        self.last_load_time = time.time()\n        return \"\"",
  "def __init__(self, conf: dict):\n        \"\"\"The authorization policy definition.\n\n        Authorization policy definition with methods to access information about the policy. Init creates the internal\n        representation of the policy from a config dictionary.\n\n        Policy evaluation result:\n\n        For bool type of rules or rights:\n\n            True - the rule is satisfied or the right is granted\n            False - the rule is not satisfied; the right iis not granted\n            None - the rule or right is not applicable (precondition not met)\n\n        For int type or rules or rights:\n\n            Number - the value of the evaluation\n            None - the rule or right is not applicable (precondition not met)\n\n        Args:\n            conf (dict): the configuration dictionary with keys=groups, users, rights, rules, sites, orgs\n        \"\"\"\n        self.config = conf\n        self.preconf_valuators = {\"selfOrg\": self._eval_precond_self_org}\n\n        # compute the rule and right spaces\n        self.rule_space = {}\n        self.right_space = {}\n        groups = conf[\"groups\"]\n        for grp_name, grp_def in groups.items():\n            rules = grp_def.get(\"rules\", None)\n            if rules:\n                for rule_name, rule_value in rules.items():\n                    key = _group_rule_key(grp_name, rule_name)\n                    self.rule_space[key] = rule_value\n\n            role_rights = grp_def.get(\"role_rights\", None)\n            if role_rights:\n                for role_name, rights in role_rights.items():\n                    for right_name, right_value in rights.items():\n                        key = _group_role_right_key(grp_name, role_name, right_name)\n                        self.right_space[key] = right_value",
  "def get_config(self):\n        return self.config",
  "def _eval_precond(self, precond: str, user_name: str, org_name: str):\n        evaluator = self.preconf_valuators.get(precond, None)\n        if not evaluator:\n            return None\n        else:\n            return evaluator(user_name, org_name)",
  "def _eval_precond_self_org(self, user_name: str, org_name: str):\n        users = self.config[\"users\"]\n        user = users[user_name]\n        return user[\"org\"] == org_name",
  "def _get_org_groups(self, org_name: str):\n        orgs = self.config[\"orgs\"]\n        return orgs.get(org_name, None)",
  "def evaluate_rule_on_org(self, rule_name: str, org_name: str):\n        rules = self.config[\"rules\"]\n        rule_def = rules.get(rule_name, None)\n        if not rule_def:\n            return None, 'undefined rule \"{}\"'.format(rule_name)\n\n        rule_type = rule_def.get(\"type\", \"bool\")\n        groups = self._get_org_groups(org_name)\n        if not groups:\n            return None, 'unknown org \"{}\"'.format(org_name)\n\n        keys = []\n        for grp_name in groups:\n            keys.append(_group_rule_key(grp_name, rule_name))\n\n        if rule_type == \"bool\":\n            result = _eval_bool(space=self.rule_space, keys=keys)\n        else:\n            result = _eval_bool(space=self.rule_space, keys=keys)\n\n        if result is None:\n            result = rule_def[\"default\"]\n        return result, \"\"",
  "def _get_org_of_site(self, site_name):\n        sites = self.config[\"sites\"]\n        return sites.get(site_name, None)",
  "def evaluate_rule_on_site(self, rule_name: str, site_name: str):\n        org_name = self._get_org_of_site(site_name)\n        if not org_name:\n            return None, 'unknown site \"{}\"'.format(site_name)\n        return self.evaluate_rule_on_org(rule_name, org_name)",
  "def evaluate_user_right_on_org(self, right_name: str, user_name: str, org_name: str):\n        rights = self.config[\"rights\"]\n        right_def = rights.get(right_name, None)\n        if not right_def:\n            return None, 'undefined right \"{}\"'.format(right_name)\n\n        right_type = right_def.get(\"type\", \"bool\")\n        groups = self._get_org_groups(org_name)\n        if not groups:\n            return None, 'unknown org \"{}\"'.format(org_name)\n\n        users = self.config[\"users\"]\n        user = users.get(user_name, None)\n        if not user:\n            return None, 'unknown user \"{}\"'.format(user_name)\n\n        precond = right_def.get(\"precond\", None)\n        if precond:\n            matched = self._eval_precond(precond, user_name, org_name)\n            if not matched:\n                if right_type == \"bool\":\n                    return False, \"\"\n                else:\n                    return 0, \"\"\n\n        roles = user[\"roles\"]\n        keys = []\n        for grp_name in groups:\n            for role_name in roles:\n                keys.append(_group_role_right_key(grp_name, role_name, right_name))\n\n        if right_type == \"bool\":\n            result = _eval_bool(self.right_space, keys)\n        else:\n            result = _eval_int(self.right_space, keys)\n\n        if result is None:\n            result = right_def[\"default\"]\n        return result, \"\"",
  "def evaluate_user_right_on_site(self, right_name: str, user_name: str, site_name: str):\n        org_name = self._get_org_of_site(site_name)\n        if not org_name:\n            return None, 'unknown site \"{}\"'.format(site_name)\n        return self.evaluate_user_right_on_org(right_name, user_name, org_name)",
  "def get_user(self, user_name: str):\n        users = self.config[\"users\"]\n        return users.get(user_name, None)",
  "def get_users(self):\n        return self.config[\"users\"]",
  "def get_sites(self):\n        return self.config[\"sites\"]",
  "def get_rights(self):\n        return self.config[\"rights\"]",
  "def get_rules(self):\n        return self.config[\"rules\"]",
  "def get_right_type(self, right_name: str):\n        rights = self.config[\"rights\"]\n        right_def = rights.get(right_name, None)\n        if not right_def:\n            return None\n        return right_def.get(\"type\", \"bool\")",
  "def __init__(self, user_name: str, site_names: List[str]):\n        \"\"\"Base class to contain context data for authorization.\n\n        Args:\n            user_name (str): user name to be checked\n            site_names (List[str]): site names to be checked against\n        \"\"\"\n        self.user_name = user_name\n        self.site_names = site_names\n        self.attrs = {}",
  "def set_attr(self, key: str, value):\n        self.attrs[key] = value",
  "def get_attr(self, key: str, default=None):\n        return self.attrs.get(key, default)",
  "def __init__(self):\n        \"\"\"Base class containing the authorization policy.\"\"\"\n        self.policy = None\n        self.last_load_time = None",
  "def get_policy(self) -> Policy:\n        return self.policy",
  "def authorize(self, ctx: AuthzContext) -> (object, str):\n        return True, \"\"",
  "def evaluate_user_right_on_site(self, right_name: str, user_name: str, site_name: str):\n        if not self.policy:\n            return None, \"policy not defined\"\n        return self.policy.evaluate_user_right_on_site(right_name=right_name, user_name=user_name, site_name=site_name)",
  "def evaluate_rule_on_site(self, rule_name: str, site_name: str):\n        if not self.policy:\n            return None, \"policy not defined\"\n\n        return self.policy.evaluate_rule_on_site(rule_name=rule_name, site_name=site_name)",
  "def load_policy(self, policy_config: dict) -> str:\n        err = validate_policy_config(policy_config)\n        if err:\n            return err\n\n        self.policy = Policy(policy_config)\n        self.last_load_time = time.time()\n        return \"\"",
  "class Auditor(object):\n    def __init__(self, audit_file_name: str):\n        \"\"\"Manages the audit file to log events.\n\n        Args:\n            audit_file_name (str): the location to save audit log file\n        \"\"\"\n        assert isinstance(audit_file_name, str), \"audit_file_name must be str\"\n        if os.path.exists(audit_file_name):\n            assert os.path.isfile(audit_file_name), \"audit_file_name is not a valid file\"\n\n        # create/open the file\n        self.audit_file = open(audit_file_name, \"a\")\n\n    def add_event(self, user: str, action: str, ref: str = \"\", msg: str = \"\") -> str:\n        event_id = uuid.uuid4()\n        event_id_str = \"{}\".format(event_id)\n\n        if len(ref) > 0:\n            ref = \" [R:{}] \".format(ref)\n        else:\n            ref = \" \"\n\n        if len(msg) > 0:\n            msg = \" [M:{}]\".format(msg)\n\n        line = \"[E:{}]{}[T:{}] [U:{}] [A:{}]{}\\n\".format(event_id, ref, datetime.now(), user, action, msg)\n        self.audit_file.write(line)\n        self.audit_file.flush()\n        return event_id_str\n\n    def close(self):\n        if self.audit_file is not None:\n            self.audit_file.close()\n            self.audit_file = None",
  "class AuditService(object):\n    \"\"\"Service for interacting with Auditor to add events to log.\"\"\"\n\n    the_auditor = None\n\n    @staticmethod\n    def initialize(audit_file_name: str):\n        if not AuditService.the_auditor:\n            AuditService.the_auditor = Auditor(audit_file_name)\n        return AuditService.the_auditor\n\n    @staticmethod\n    def get_auditor():\n        return AuditService.the_auditor\n\n    @staticmethod\n    def add_event(user: str, action: str, ref: str = \"\", msg: str = \"\") -> str:\n        if not AuditService.the_auditor:\n            return \"\"\n        return AuditService.the_auditor.add_event(user, action, ref, msg)\n\n    @staticmethod\n    def close():\n        if AuditService.the_auditor:\n            AuditService.the_auditor.close()",
  "def __init__(self, audit_file_name: str):\n        \"\"\"Manages the audit file to log events.\n\n        Args:\n            audit_file_name (str): the location to save audit log file\n        \"\"\"\n        assert isinstance(audit_file_name, str), \"audit_file_name must be str\"\n        if os.path.exists(audit_file_name):\n            assert os.path.isfile(audit_file_name), \"audit_file_name is not a valid file\"\n\n        # create/open the file\n        self.audit_file = open(audit_file_name, \"a\")",
  "def add_event(self, user: str, action: str, ref: str = \"\", msg: str = \"\") -> str:\n        event_id = uuid.uuid4()\n        event_id_str = \"{}\".format(event_id)\n\n        if len(ref) > 0:\n            ref = \" [R:{}] \".format(ref)\n        else:\n            ref = \" \"\n\n        if len(msg) > 0:\n            msg = \" [M:{}]\".format(msg)\n\n        line = \"[E:{}]{}[T:{}] [U:{}] [A:{}]{}\\n\".format(event_id, ref, datetime.now(), user, action, msg)\n        self.audit_file.write(line)\n        self.audit_file.flush()\n        return event_id_str",
  "def close(self):\n        if self.audit_file is not None:\n            self.audit_file.close()\n            self.audit_file = None",
  "def initialize(audit_file_name: str):\n        if not AuditService.the_auditor:\n            AuditService.the_auditor = Auditor(audit_file_name)\n        return AuditService.the_auditor",
  "def get_auditor():\n        return AuditService.the_auditor",
  "def add_event(user: str, action: str, ref: str = \"\", msg: str = \"\") -> str:\n        if not AuditService.the_auditor:\n            return \"\"\n        return AuditService.the_auditor.add_event(user, action, ref, msg)",
  "def close():\n        if AuditService.the_auditor:\n            AuditService.the_auditor.close()",
  "class LoadResult(Enum):\n    \"\"\"Constants for different results when loading secure content.\"\"\"\n\n    OK = \"ok\"\n    NOT_MANAGED = \"notManaged\"\n    NO_SUCH_CONTENT = \"noSuchContent\"\n    NOT_SIGNED = \"notSigned\"\n    INVALID_SIGNATURE = \"invalidSignature\"\n    INVALID_CONTENT = \"invalidContent\"",
  "class SecurityContentManager(object):\n    def __init__(self, content_folder, signature_filename=\"signature.json\", root_cert=\"rootCA.pem\"):\n        \"\"\"Content manager used by SecurityContentService to load secure content.\n\n        Args:\n            content_folder (str): the folder path that includes signature file\n            signature_filename (str, optional): the signature file (signed dictionary). Defaults to \"signature.json\".\n            root_cert (str, optional): root CA certificate filename. Defaults to \"rootCA.pem\".\n        \"\"\"\n        self.content_folder = content_folder\n        signature_path = os.path.join(self.content_folder, signature_filename)\n        rootCA_cert_path = os.path.join(self.content_folder, root_cert)\n        if os.path.exists(signature_path) and os.path.exists(rootCA_cert_path):\n            self.signature = json.load(open(signature_path, \"rt\"))\n            for k in self.signature:\n                self.signature[k] = b64decode(self.signature[k].encode(\"utf-8\"))\n            cert = x509.load_pem_x509_certificate(open(rootCA_cert_path, \"rb\").read(), default_backend())\n            self.public_key = cert.public_key()\n            self.valid_config = True\n        else:\n            self.signature = dict()\n            self.valid_config = False\n\n    def load_content(self, file_under_verification):\n        \"\"\"Loads the data of the file under verification and verifies that the signature is valid.\n\n        Args:\n            file_under_verification: file to load and verify\n\n        Returns:\n            A tuple of the file data and the LoadResult. File data may be None if the data cannot be loaded.\n        \"\"\"\n        full_path = os.path.join(self.content_folder, file_under_verification)\n        data = None\n        if not os.path.exists(full_path):\n            return data, LoadResult.NO_SUCH_CONTENT\n\n        with open(full_path, \"rb\") as f:\n            data = f.read()\n        if not data:\n            return data, LoadResult.NO_SUCH_CONTENT\n\n        if self.valid_config and file_under_verification in self.signature:\n            signature = self.signature[file_under_verification]\n            try:\n                self.public_key.verify(\n                    signature=signature,\n                    data=data,\n                    padding=padding.PSS(mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH),\n                    algorithm=hashes.SHA256(),\n                )\n                result = LoadResult.OK\n            except InvalidSignature:\n                result = LoadResult.INVALID_SIGNATURE\n        else:\n            result = LoadResult.NOT_SIGNED\n        return data, result",
  "class SecurityContentService(object):\n    \"\"\"Uses SecurityContentManager to load secure content.\"\"\"\n\n    security_content_manager = None\n\n    @staticmethod\n    def initialize(content_folder: str, signature_filename=\"signature.json\", root_cert=\"rootCA.pem\"):\n        if SecurityContentService.security_content_manager is None:\n            SecurityContentService.security_content_manager = SecurityContentManager(\n                content_folder, signature_filename, root_cert\n            )\n\n    @staticmethod\n    def load_content(file_under_verification):\n        if not SecurityContentService.security_content_manager:\n            return None, LoadResult.NOT_MANAGED\n\n        return SecurityContentService.security_content_manager.load_content(file_under_verification)\n\n    @staticmethod\n    def load_json(file_under_verification):\n        if not SecurityContentService.security_content_manager:\n            return None, LoadResult.NOT_MANAGED\n\n        json_data = None\n\n        data_bytes, result = SecurityContentService.security_content_manager.load_content(file_under_verification)\n\n        if data_bytes:\n            try:\n                data_text = data_bytes.decode(\"ascii\")\n                json_data = json.loads(data_text)\n            except json.JSONDecodeError:\n                return None, LoadResult.INVALID_CONTENT\n\n        return json_data, result",
  "def __init__(self, content_folder, signature_filename=\"signature.json\", root_cert=\"rootCA.pem\"):\n        \"\"\"Content manager used by SecurityContentService to load secure content.\n\n        Args:\n            content_folder (str): the folder path that includes signature file\n            signature_filename (str, optional): the signature file (signed dictionary). Defaults to \"signature.json\".\n            root_cert (str, optional): root CA certificate filename. Defaults to \"rootCA.pem\".\n        \"\"\"\n        self.content_folder = content_folder\n        signature_path = os.path.join(self.content_folder, signature_filename)\n        rootCA_cert_path = os.path.join(self.content_folder, root_cert)\n        if os.path.exists(signature_path) and os.path.exists(rootCA_cert_path):\n            self.signature = json.load(open(signature_path, \"rt\"))\n            for k in self.signature:\n                self.signature[k] = b64decode(self.signature[k].encode(\"utf-8\"))\n            cert = x509.load_pem_x509_certificate(open(rootCA_cert_path, \"rb\").read(), default_backend())\n            self.public_key = cert.public_key()\n            self.valid_config = True\n        else:\n            self.signature = dict()\n            self.valid_config = False",
  "def load_content(self, file_under_verification):\n        \"\"\"Loads the data of the file under verification and verifies that the signature is valid.\n\n        Args:\n            file_under_verification: file to load and verify\n\n        Returns:\n            A tuple of the file data and the LoadResult. File data may be None if the data cannot be loaded.\n        \"\"\"\n        full_path = os.path.join(self.content_folder, file_under_verification)\n        data = None\n        if not os.path.exists(full_path):\n            return data, LoadResult.NO_SUCH_CONTENT\n\n        with open(full_path, \"rb\") as f:\n            data = f.read()\n        if not data:\n            return data, LoadResult.NO_SUCH_CONTENT\n\n        if self.valid_config and file_under_verification in self.signature:\n            signature = self.signature[file_under_verification]\n            try:\n                self.public_key.verify(\n                    signature=signature,\n                    data=data,\n                    padding=padding.PSS(mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH),\n                    algorithm=hashes.SHA256(),\n                )\n                result = LoadResult.OK\n            except InvalidSignature:\n                result = LoadResult.INVALID_SIGNATURE\n        else:\n            result = LoadResult.NOT_SIGNED\n        return data, result",
  "def initialize(content_folder: str, signature_filename=\"signature.json\", root_cert=\"rootCA.pem\"):\n        if SecurityContentService.security_content_manager is None:\n            SecurityContentService.security_content_manager = SecurityContentManager(\n                content_folder, signature_filename, root_cert\n            )",
  "def load_content(file_under_verification):\n        if not SecurityContentService.security_content_manager:\n            return None, LoadResult.NOT_MANAGED\n\n        return SecurityContentService.security_content_manager.load_content(file_under_verification)",
  "def load_json(file_under_verification):\n        if not SecurityContentService.security_content_manager:\n            return None, LoadResult.NOT_MANAGED\n\n        json_data = None\n\n        data_bytes, result = SecurityContentService.security_content_manager.load_content(file_under_verification)\n\n        if data_bytes:\n            try:\n                data_text = data_bytes.decode(\"ascii\")\n                json_data = json.loads(data_text)\n            except json.JSONDecodeError:\n                return None, LoadResult.INVALID_CONTENT\n\n        return json_data, result",
  "def update(d, u):\n    for k, v in u.items():\n        if isinstance(v, collections.Mapping):\n            d[k] = update(d.get(k, {}), v)\n        else:\n            d[k] = v\n    return d",
  "def update_configs_with_envs(configs, env):\n    for k, v in configs.items():\n        if isinstance(v, list):\n            length = len(v)\n            for i in range(length):\n                if isinstance(v[i], dict):\n                    configs[k][i] = update_configs_with_envs(v[i], env)\n        elif isinstance(v, dict):\n            configs[k] = update_configs_with_envs(v, env)\n        elif isinstance(v, str):\n            configs[k] = v.format(**env)\n    return configs",
  "def merge_dict(dict1, dict2):\n    return {**dict1, **dict2}",
  "def extract_first_level_primitive(d):\n    result = {}\n    for k, v in d.items():\n        if type(v) in (int, float, bool, str):\n            result[k] = v\n    return result",
  "def save_to_json(data, path, sort_keys=False, indent=None):\n    with open(path, \"w\") as f:\n        json.dump(data, f, sort_keys=sort_keys, indent=indent)",
  "def time_to_string(t):\n    \"\"\"Convert time into a formatted string.\n\n    Args:\n        t: input time string in seconds since the Epoch\n\n    Returns: formatted time string\n\n    \"\"\"\n    if t is None:\n        return \"N/A\"\n\n    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(t))",
  "def parse_var(s):\n    \"\"\"Parse string variable into key-value tuple.\n\n    Returns (key, value) tuple from string with equals sign with the portion before the first equals sign as the key\n    and the rest as the value.\n\n    Args:\n        s: string to parse\n\n    Returns: Tuple of key and value\n    \"\"\"\n    items = s.split(\"=\")\n    key = items[0].strip()  # we remove blanks around keys, as is logical\n    value = \"\"\n    if len(items) > 1:\n        # rejoin the rest:\n        value = \"=\".join(items[1:])\n    return key, value",
  "def parse_vars(items):\n    \"\"\"Converts a list of key value pairs into a dictionary.\n\n    Args:\n        items: list like ['a=1', 'b=2', 'c=3']\n\n    Returns: dictionary like {'a': '1', 'b': '2', 'c': '3'}\n\n    \"\"\"\n    d = {}\n    if items:\n        for item in items:\n            key, value = parse_var(item)\n\n            # d[key] = value\n            try:\n                d[key] = int(value)\n            except ValueError:\n                pass\n                try:\n                    d[key] = float(value)\n                except ValueError:\n                    pass\n                    try:\n                        d[key] = bool(strtobool(str(value)))\n                    except ValueError:\n                        pass\n                        d[key] = value\n    return d",
  "class SafeArgumentParser(argparse.ArgumentParser):\n    \"\"\"Safe version of ArgumentParser which doesn't exit on error\"\"\"\n\n    def __init__(self, **kwargs):\n        kwargs[\"add_help\"] = False\n        super().__init__(**kwargs)\n\n    def error(self, message):\n        writer = io.StringIO()\n        self.print_help(writer)\n        raise ValueError(message + \"\\n\" + writer.getvalue())",
  "def __init__(self, **kwargs):\n        kwargs[\"add_help\"] = False\n        super().__init__(**kwargs)",
  "def error(self, message):\n        writer = io.StringIO()\n        self.print_help(writer)\n        raise ValueError(message + \"\\n\" + writer.getvalue())",
  "class ConfigContext(object):\n    def __init__(self):\n        \"\"\"Object containing configuration context.\"\"\"\n        self.app_root = \"\"\n        self.vars = None\n        self.config_json = None\n        self.pass_num = 0",
  "class _EnvUpdater(JsonObjectProcessor):\n    def __init__(self, vs, element_filter=None):\n        JsonObjectProcessor.__init__(self)\n        self.vars = vs\n        if element_filter is not None and not callable(element_filter):\n            raise ValueError(\"element_filter must be a callable function but got {}.\".format(type(element_filter)))\n        self.element_filter = element_filter\n\n    def process_element(self, node: Node):\n        element = node.element\n        if isinstance(element, str):\n            if self.element_filter is not None and not self.element_filter(element):\n                return\n            element = self.substitute(element)\n            parent_element = node.parent_element()\n            if node.position > 0:\n                # parent is a list\n                parent_element[node.position - 1] = element\n            else:\n                # parent is a dict\n                parent_element[node.key] = element\n\n    def substitute(self, element: str):\n        a = re.split(\"{|}\", element)\n        if len(a) == 3 and a[0] == \"\" and a[2] == \"\":\n            element = self.vars.get(a[1], None)\n        else:\n            element = element.format(**self.vars)\n        return element",
  "class Configurator(JsonObjectProcessor):\n    def __init__(\n        self,\n        app_root: str,\n        cmd_vars: dict,\n        env_config: dict,\n        wf_config_file_name: str,\n        base_pkgs: List[str],\n        module_names: List[str],\n        exclude_libs=True,\n        default_vars=None,\n        num_passes=1,\n        element_filter=None,\n        var_processor=None,\n    ):\n        \"\"\"Base class of Configurator to parse JSON configuration.\n\n        Args:\n            app_root: app root\n            cmd_vars: command vars\n            env_config: environment configuration\n            wf_config_file_name: config file name\n            base_pkgs: base packages\n            module_names: module names\n            exclude_libs: whether to exclude libs\n            default_vars: default vars\n            num_passes: number of passes\n            element_filter: element filter\n            var_processor: variable processor\n        \"\"\"\n        JsonObjectProcessor.__init__(self)\n\n        assert isinstance(app_root, str), \"app_root must be str but got {}.\".format(type(app_root))\n\n        assert isinstance(num_passes, int), \"num_passes must be int but got {}.\".format(type(num_passes))\n        assert num_passes > 0, \"num_passes must > 0\"\n\n        if cmd_vars:\n            assert isinstance(cmd_vars, dict), \"cmd_vars must be dict but got {}.\".format(type(cmd_vars))\n\n        if env_config:\n            assert isinstance(env_config, dict), \"env_config must be dict but got {}.\".format(type(env_config))\n\n        assert isinstance(wf_config_file_name, str), \"wf_config_file_name must be str but got {}.\".format(\n            type(wf_config_file_name)\n        )\n        assert os.path.isfile(wf_config_file_name), \"wf_config_file_name {} is not a valid file\".format(\n            wf_config_file_name\n        )\n        assert os.path.exists(wf_config_file_name), \"wf_config_file_name {} does not exist\".format(wf_config_file_name)\n\n        if default_vars is not None:\n            assert isinstance(default_vars, dict), \"default_vars must be dict but got {}.\".format(type(default_vars))\n        else:\n            default_vars = {}\n\n        self.cmd_vars = cmd_vars\n        self.default_vars = default_vars\n        self.app_root = app_root\n        self.env_config = env_config\n        self.wf_config_file_name = wf_config_file_name\n        self.num_passes = num_passes\n        self.element_filter = element_filter\n\n        self.module_scanner = ModuleScanner(base_pkgs, module_names, exclude_libs)\n        self.all_vars = None\n        self.vars_from_cmd = None\n        self.vars_from_env_config = None\n        self.vars_from_wf_config = None\n        self.config_ctx = None\n        self.var_processor = var_processor\n\n        with open(wf_config_file_name) as file:\n            self.wf_config_data = json.load(file)\n\n        self.json_scanner = JsonScanner(self.wf_config_data, wf_config_file_name)\n\n    def _do_configure(self):\n        vars_from_cmd = {}\n        if self.cmd_vars:\n            vars_from_cmd = copy.copy(self.cmd_vars)\n            for key, value in vars_from_cmd.items():\n                if key.startswith(\"APP_\") and value != \"\":\n                    vars_from_cmd[key] = os.path.join(self.app_root, value)\n\n        vars_from_env_config = {}\n        if self.env_config:\n            vars_from_env_config = copy.copy(self.env_config)\n            for key, value in vars_from_env_config.items():\n                if key.startswith(\"APP_\") and value != \"\":\n                    vars_from_env_config[key] = os.path.join(self.app_root, value)\n\n        vars_from_wf_conf = extract_first_level_primitive(self.wf_config_data)\n\n        if \"determinism\" in self.wf_config_data:\n            vars_from_wf_conf[\"determinism\"] = self.wf_config_data[\"determinism\"]\n\n        # precedence of vars (high to low):\n        #   vars_from_cmd, vars_from_config, vars_from_wf_conf\n        # func merge_dict(d1, d2) gives d2 higher precedence for the same key\n        all_vars = merge_dict(self.default_vars, vars_from_wf_conf)\n        all_vars = merge_dict(all_vars, vars_from_env_config)\n        all_vars = merge_dict(all_vars, vars_from_cmd)\n\n        # update the wf_config with vars\n        self.all_vars = all_vars\n        self.vars_from_cmd = vars_from_cmd\n        self.vars_from_env_config = vars_from_env_config\n        self.vars_from_wf_config = vars_from_wf_conf\n\n        if self.var_processor:\n            self.var_processor.process(self.all_vars, app_root=self.app_root)\n\n        self.json_scanner.scan(_EnvUpdater(all_vars, self.element_filter))\n\n        config_ctx = ConfigContext()\n        config_ctx.vars = self.all_vars\n        config_ctx.app_root = self.app_root\n        config_ctx.config_json = self.wf_config_data\n        self.config_ctx = config_ctx\n\n        self.start_config(self.config_ctx)\n\n        # scan the wf_config again to create components\n        for i in range(self.num_passes):\n            self.config_ctx.pass_num = i + 1\n            self.json_scanner.scan(self)\n\n        # finalize configuration\n        self.finalize_config(self.config_ctx)\n\n    def configure(self):\n        try:\n            self._do_configure()\n        except ConfigError as ex:\n            raise ConfigError(\"Config error in {}: {}\".format(self.wf_config_file_name, ex))\n        except Exception as ex:\n            print(\"Error processing config {}: {}\".format(self.wf_config_file_name, ex))\n            raise ex\n\n    def process_element(self, node: Node):\n        self.process_config_element(self.config_ctx, node)\n\n    def process_args(self, args: dict):\n        return args\n\n    def build_component(self, config_dict):\n        if not config_dict:\n            return None\n\n        if not isinstance(config_dict, dict):\n            raise ConfigError(\"component config must be dict but got {}.\".format(type(config_dict)))\n\n        if config_dict.get(\"disabled\") is True:\n            return None\n\n        class_args = config_dict.get(\"args\", dict())\n        class_args = self.process_args(class_args)\n\n        class_path = self.get_class_path(config_dict)\n\n        # Handle the special case, if config pass in the class_attributes, use the user defined class attributes\n        # parameters directly.\n        if \"class_attributes\" in class_args:\n            class_args = class_args[\"class_attributes\"]\n\n        return instantiate_class(class_path, class_args)\n\n    def get_class_path(self, config_dict):\n        if \"path\" in config_dict.keys():\n            path_spec = config_dict[\"path\"]\n            if not isinstance(path_spec, str):\n                raise ConfigError(\"path spec must be str but got {}.\".format(type(path_spec)))\n\n            if len(path_spec) <= 0:\n                raise ConfigError(\"path spec must not be empty\")\n\n            class_path = format(path_spec)\n            parts = class_path.split(\".\")\n            if len(parts) < 2:\n                raise ConfigError(\"invalid class path '{}': missing module name\".format(class_path))\n        else:\n            if \"name\" not in config_dict:\n                raise ConfigError(\"class name or path must be specified\")\n\n            class_name = config_dict[\"name\"]\n\n            if not isinstance(class_name, str):\n                raise ConfigError(\"class name must be str\")\n\n            if len(class_name) <= 0:\n                raise ConfigError(\"class name must not be empty\")\n            module_name = self.module_scanner.get_module_name(class_name)\n            if module_name is None:\n                raise ConfigError('Cannot find component class \"{}\"'.format(class_name))\n            class_path = module_name + \".{}\".format(class_name)\n\n        return class_path\n\n    def is_configured_subclass(self, config_dict, base_class):\n        return issubclass(get_class(self.get_class_path(config_dict)), base_class)\n\n    def start_config(self, config_ctx: ConfigContext):\n        pass\n\n    def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        pass\n\n    def finalize_config(self, config_ctx: ConfigContext):\n        pass",
  "def get_component_refs(component):\n    \"\"\"Get component reference.\n\n    Args:\n        component: string for component\n\n    Returns: list of component and reference\n\n    \"\"\"\n    if \"name\" in component:\n        name = component[\"name\"]\n        key = \"name\"\n    elif \"path\" in component:\n        name = component[\"path\"]\n        key = \"path\"\n    else:\n        raise ConfigError('component has no \"name\" or \"path')\n\n    parts = name.split(\"#\")\n    component[key] = parts[0]\n    return parts",
  "def __init__(self):\n        \"\"\"Object containing configuration context.\"\"\"\n        self.app_root = \"\"\n        self.vars = None\n        self.config_json = None\n        self.pass_num = 0",
  "def __init__(self, vs, element_filter=None):\n        JsonObjectProcessor.__init__(self)\n        self.vars = vs\n        if element_filter is not None and not callable(element_filter):\n            raise ValueError(\"element_filter must be a callable function but got {}.\".format(type(element_filter)))\n        self.element_filter = element_filter",
  "def process_element(self, node: Node):\n        element = node.element\n        if isinstance(element, str):\n            if self.element_filter is not None and not self.element_filter(element):\n                return\n            element = self.substitute(element)\n            parent_element = node.parent_element()\n            if node.position > 0:\n                # parent is a list\n                parent_element[node.position - 1] = element\n            else:\n                # parent is a dict\n                parent_element[node.key] = element",
  "def substitute(self, element: str):\n        a = re.split(\"{|}\", element)\n        if len(a) == 3 and a[0] == \"\" and a[2] == \"\":\n            element = self.vars.get(a[1], None)\n        else:\n            element = element.format(**self.vars)\n        return element",
  "def __init__(\n        self,\n        app_root: str,\n        cmd_vars: dict,\n        env_config: dict,\n        wf_config_file_name: str,\n        base_pkgs: List[str],\n        module_names: List[str],\n        exclude_libs=True,\n        default_vars=None,\n        num_passes=1,\n        element_filter=None,\n        var_processor=None,\n    ):\n        \"\"\"Base class of Configurator to parse JSON configuration.\n\n        Args:\n            app_root: app root\n            cmd_vars: command vars\n            env_config: environment configuration\n            wf_config_file_name: config file name\n            base_pkgs: base packages\n            module_names: module names\n            exclude_libs: whether to exclude libs\n            default_vars: default vars\n            num_passes: number of passes\n            element_filter: element filter\n            var_processor: variable processor\n        \"\"\"\n        JsonObjectProcessor.__init__(self)\n\n        assert isinstance(app_root, str), \"app_root must be str but got {}.\".format(type(app_root))\n\n        assert isinstance(num_passes, int), \"num_passes must be int but got {}.\".format(type(num_passes))\n        assert num_passes > 0, \"num_passes must > 0\"\n\n        if cmd_vars:\n            assert isinstance(cmd_vars, dict), \"cmd_vars must be dict but got {}.\".format(type(cmd_vars))\n\n        if env_config:\n            assert isinstance(env_config, dict), \"env_config must be dict but got {}.\".format(type(env_config))\n\n        assert isinstance(wf_config_file_name, str), \"wf_config_file_name must be str but got {}.\".format(\n            type(wf_config_file_name)\n        )\n        assert os.path.isfile(wf_config_file_name), \"wf_config_file_name {} is not a valid file\".format(\n            wf_config_file_name\n        )\n        assert os.path.exists(wf_config_file_name), \"wf_config_file_name {} does not exist\".format(wf_config_file_name)\n\n        if default_vars is not None:\n            assert isinstance(default_vars, dict), \"default_vars must be dict but got {}.\".format(type(default_vars))\n        else:\n            default_vars = {}\n\n        self.cmd_vars = cmd_vars\n        self.default_vars = default_vars\n        self.app_root = app_root\n        self.env_config = env_config\n        self.wf_config_file_name = wf_config_file_name\n        self.num_passes = num_passes\n        self.element_filter = element_filter\n\n        self.module_scanner = ModuleScanner(base_pkgs, module_names, exclude_libs)\n        self.all_vars = None\n        self.vars_from_cmd = None\n        self.vars_from_env_config = None\n        self.vars_from_wf_config = None\n        self.config_ctx = None\n        self.var_processor = var_processor\n\n        with open(wf_config_file_name) as file:\n            self.wf_config_data = json.load(file)\n\n        self.json_scanner = JsonScanner(self.wf_config_data, wf_config_file_name)",
  "def _do_configure(self):\n        vars_from_cmd = {}\n        if self.cmd_vars:\n            vars_from_cmd = copy.copy(self.cmd_vars)\n            for key, value in vars_from_cmd.items():\n                if key.startswith(\"APP_\") and value != \"\":\n                    vars_from_cmd[key] = os.path.join(self.app_root, value)\n\n        vars_from_env_config = {}\n        if self.env_config:\n            vars_from_env_config = copy.copy(self.env_config)\n            for key, value in vars_from_env_config.items():\n                if key.startswith(\"APP_\") and value != \"\":\n                    vars_from_env_config[key] = os.path.join(self.app_root, value)\n\n        vars_from_wf_conf = extract_first_level_primitive(self.wf_config_data)\n\n        if \"determinism\" in self.wf_config_data:\n            vars_from_wf_conf[\"determinism\"] = self.wf_config_data[\"determinism\"]\n\n        # precedence of vars (high to low):\n        #   vars_from_cmd, vars_from_config, vars_from_wf_conf\n        # func merge_dict(d1, d2) gives d2 higher precedence for the same key\n        all_vars = merge_dict(self.default_vars, vars_from_wf_conf)\n        all_vars = merge_dict(all_vars, vars_from_env_config)\n        all_vars = merge_dict(all_vars, vars_from_cmd)\n\n        # update the wf_config with vars\n        self.all_vars = all_vars\n        self.vars_from_cmd = vars_from_cmd\n        self.vars_from_env_config = vars_from_env_config\n        self.vars_from_wf_config = vars_from_wf_conf\n\n        if self.var_processor:\n            self.var_processor.process(self.all_vars, app_root=self.app_root)\n\n        self.json_scanner.scan(_EnvUpdater(all_vars, self.element_filter))\n\n        config_ctx = ConfigContext()\n        config_ctx.vars = self.all_vars\n        config_ctx.app_root = self.app_root\n        config_ctx.config_json = self.wf_config_data\n        self.config_ctx = config_ctx\n\n        self.start_config(self.config_ctx)\n\n        # scan the wf_config again to create components\n        for i in range(self.num_passes):\n            self.config_ctx.pass_num = i + 1\n            self.json_scanner.scan(self)\n\n        # finalize configuration\n        self.finalize_config(self.config_ctx)",
  "def configure(self):\n        try:\n            self._do_configure()\n        except ConfigError as ex:\n            raise ConfigError(\"Config error in {}: {}\".format(self.wf_config_file_name, ex))\n        except Exception as ex:\n            print(\"Error processing config {}: {}\".format(self.wf_config_file_name, ex))\n            raise ex",
  "def process_element(self, node: Node):\n        self.process_config_element(self.config_ctx, node)",
  "def process_args(self, args: dict):\n        return args",
  "def build_component(self, config_dict):\n        if not config_dict:\n            return None\n\n        if not isinstance(config_dict, dict):\n            raise ConfigError(\"component config must be dict but got {}.\".format(type(config_dict)))\n\n        if config_dict.get(\"disabled\") is True:\n            return None\n\n        class_args = config_dict.get(\"args\", dict())\n        class_args = self.process_args(class_args)\n\n        class_path = self.get_class_path(config_dict)\n\n        # Handle the special case, if config pass in the class_attributes, use the user defined class attributes\n        # parameters directly.\n        if \"class_attributes\" in class_args:\n            class_args = class_args[\"class_attributes\"]\n\n        return instantiate_class(class_path, class_args)",
  "def get_class_path(self, config_dict):\n        if \"path\" in config_dict.keys():\n            path_spec = config_dict[\"path\"]\n            if not isinstance(path_spec, str):\n                raise ConfigError(\"path spec must be str but got {}.\".format(type(path_spec)))\n\n            if len(path_spec) <= 0:\n                raise ConfigError(\"path spec must not be empty\")\n\n            class_path = format(path_spec)\n            parts = class_path.split(\".\")\n            if len(parts) < 2:\n                raise ConfigError(\"invalid class path '{}': missing module name\".format(class_path))\n        else:\n            if \"name\" not in config_dict:\n                raise ConfigError(\"class name or path must be specified\")\n\n            class_name = config_dict[\"name\"]\n\n            if not isinstance(class_name, str):\n                raise ConfigError(\"class name must be str\")\n\n            if len(class_name) <= 0:\n                raise ConfigError(\"class name must not be empty\")\n            module_name = self.module_scanner.get_module_name(class_name)\n            if module_name is None:\n                raise ConfigError('Cannot find component class \"{}\"'.format(class_name))\n            class_path = module_name + \".{}\".format(class_name)\n\n        return class_path",
  "def is_configured_subclass(self, config_dict, base_class):\n        return issubclass(get_class(self.get_class_path(config_dict)), base_class)",
  "def start_config(self, config_ctx: ConfigContext):\n        pass",
  "def process_config_element(self, config_ctx: ConfigContext, node: Node):\n        pass",
  "def finalize_config(self, config_ctx: ConfigContext):\n        pass",
  "class ComponentBuilder:\n    @abstractmethod\n    def get_module_scanner(self):\n        \"\"\"Provide the package module scanner.\n\n        Returns: module_scanner\n\n        \"\"\"\n        pass\n\n    def build_component(self, config_dict):\n        if not config_dict:\n            return None\n\n        if not isinstance(config_dict, dict):\n            raise ConfigError(\"component config must be dict but got {}.\".format(type(config_dict)))\n\n        if config_dict.get(\"disabled\") is True:\n            return None\n\n        class_args = config_dict.get(\"args\", dict())\n        for k, v in class_args.items():\n            if isinstance(v, dict):\n                # try to replace the arg with a component\n                try:\n                    t = self.build_component(v)\n                    class_args[k] = t\n                except BaseException:\n                    pass\n        class_path = self.get_class_path(config_dict)\n\n        # Handle the special case, if config pass in the class_attributes, use the user defined class attributes\n        # parameters directly.\n        if \"class_attributes\" in class_args:\n            class_args = class_args[\"class_attributes\"]\n\n        return instantiate_class(class_path, class_args)\n\n    def get_class_path(self, config_dict):\n        if \"path\" in config_dict.keys():\n            path_spec = config_dict[\"path\"]\n            if not isinstance(path_spec, str):\n                raise ConfigError(\"path spec must be str but got {}.\".format(type(path_spec)))\n\n            if len(path_spec) <= 0:\n                raise ConfigError(\"path spec must not be empty\")\n\n            class_path = format(path_spec)\n            parts = class_path.split(\".\")\n            if len(parts) < 2:\n                raise ConfigError(\"invalid class path '{}': missing module name\".format(class_path))\n        else:\n            if \"name\" not in config_dict:\n                raise ConfigError(\"class name or path must be specified\")\n\n            class_name = config_dict[\"name\"]\n\n            if not isinstance(class_name, str):\n                raise ConfigError(\"class name must be str but got {}.\".format(type(class_name)))\n\n            if len(class_name) <= 0:\n                raise ConfigError(\"class name must not be empty\")\n            module_name = self.get_module_scanner().get_module_name(class_name)\n            if module_name is None:\n                raise ConfigError('Cannot find component class \"{}\"'.format(class_name))\n            class_path = module_name + \".{}\".format(class_name)\n\n        return class_path",
  "def get_module_scanner(self):\n        \"\"\"Provide the package module scanner.\n\n        Returns: module_scanner\n\n        \"\"\"\n        pass",
  "def build_component(self, config_dict):\n        if not config_dict:\n            return None\n\n        if not isinstance(config_dict, dict):\n            raise ConfigError(\"component config must be dict but got {}.\".format(type(config_dict)))\n\n        if config_dict.get(\"disabled\") is True:\n            return None\n\n        class_args = config_dict.get(\"args\", dict())\n        for k, v in class_args.items():\n            if isinstance(v, dict):\n                # try to replace the arg with a component\n                try:\n                    t = self.build_component(v)\n                    class_args[k] = t\n                except BaseException:\n                    pass\n        class_path = self.get_class_path(config_dict)\n\n        # Handle the special case, if config pass in the class_attributes, use the user defined class attributes\n        # parameters directly.\n        if \"class_attributes\" in class_args:\n            class_args = class_args[\"class_attributes\"]\n\n        return instantiate_class(class_path, class_args)",
  "def get_class_path(self, config_dict):\n        if \"path\" in config_dict.keys():\n            path_spec = config_dict[\"path\"]\n            if not isinstance(path_spec, str):\n                raise ConfigError(\"path spec must be str but got {}.\".format(type(path_spec)))\n\n            if len(path_spec) <= 0:\n                raise ConfigError(\"path spec must not be empty\")\n\n            class_path = format(path_spec)\n            parts = class_path.split(\".\")\n            if len(parts) < 2:\n                raise ConfigError(\"invalid class path '{}': missing module name\".format(class_path))\n        else:\n            if \"name\" not in config_dict:\n                raise ConfigError(\"class name or path must be specified\")\n\n            class_name = config_dict[\"name\"]\n\n            if not isinstance(class_name, str):\n                raise ConfigError(\"class name must be str but got {}.\".format(type(class_name)))\n\n            if len(class_name) <= 0:\n                raise ConfigError(\"class name must not be empty\")\n            module_name = self.get_module_scanner().get_module_name(class_name)\n            if module_name is None:\n                raise ConfigError('Cannot find component class \"{}\"'.format(class_name))\n            class_path = module_name + \".{}\".format(class_name)\n\n        return class_path",
  "def get_class(class_path):\n    module_name, class_name = class_path.rsplit(\".\", 1)\n\n    try:\n        module_ = importlib.import_module(module_name)\n\n        try:\n            class_ = getattr(module_, class_name)\n        except AttributeError:\n            raise ValueError(\"Class {} does not exist\".format(class_path))\n    except AttributeError:\n        raise ValueError(\"Module {} does not exist\".format(class_path))\n\n    return class_",
  "def instantiate_class(class_path, init_params):\n    \"\"\"Method for creating an instance for the class.\n\n    Args:\n        class_path: full path of the class\n        init_params: A dictionary that contains the name of the transform and constructor input\n        arguments. The transform name will be appended to `medical.common.transforms` to make a\n        full name of the transform to be built.\n    \"\"\"\n    c = get_class(class_path)\n    try:\n        if init_params:\n            instance = c(**init_params)\n        else:\n            instance = c()\n    except TypeError as e:\n        raise ValueError(\"Class {} has parameters error.\".format(class_path), str(e))\n\n    return instance",
  "def get_object_method(obj, method_name):\n    op = getattr(obj, method_name, None)\n    if op is None or not callable(op):\n        return None\n    return op",
  "def get_instance_method(instance, method_name):\n    return get_object_method(instance, method_name)",
  "def get_config_classname(config_dict: dict):\n    class_name = config_dict.get(\"name\", None)\n    if not class_name:\n        class_name = config_dict.get(\"path\", \"\")\n    return class_name",
  "class ModuleScanner:\n    def __init__(self, base_pkgs: List[str], module_names: List[str], exclude_libs=True):\n        \"\"\"Scanner to look for and load specified module names.\n\n        Args:\n            base_pkgs: base packages to look for modules in\n            module_names: module names to load\n            exclude_libs: excludes modules containing .libs if True. Defaults to True.\n        \"\"\"\n        self.base_pkgs = base_pkgs\n        self.module_names = module_names\n        self.exclude_libs = exclude_libs\n        self._class_table = {}\n        self._create_classes_table()\n\n    def _create_classes_table(self):\n        for base in self.base_pkgs:\n            package = __import__(base)\n\n            for importer, modname, ispkg in pkgutil.walk_packages(path=package.__path__, prefix=package.__name__ + \".\"):\n\n                if modname.startswith(base):\n                    if not self.exclude_libs or (\".libs\" not in modname):\n                        if any(name in modname for name in self.module_names):\n                            try:\n                                module = importlib.import_module(modname)\n                                for name, obj in inspect.getmembers(module):\n                                    if inspect.isclass(obj) and obj.__module__ == modname:\n                                        self._class_table[name] = modname\n                            except ModuleNotFoundError as ex:\n                                pass\n\n    def get_module_name(self, class_name):\n        return self._class_table.get(class_name, None)",
  "def __init__(self, base_pkgs: List[str], module_names: List[str], exclude_libs=True):\n        \"\"\"Scanner to look for and load specified module names.\n\n        Args:\n            base_pkgs: base packages to look for modules in\n            module_names: module names to load\n            exclude_libs: excludes modules containing .libs if True. Defaults to True.\n        \"\"\"\n        self.base_pkgs = base_pkgs\n        self.module_names = module_names\n        self.exclude_libs = exclude_libs\n        self._class_table = {}\n        self._create_classes_table()",
  "def _create_classes_table(self):\n        for base in self.base_pkgs:\n            package = __import__(base)\n\n            for importer, modname, ispkg in pkgutil.walk_packages(path=package.__path__, prefix=package.__name__ + \".\"):\n\n                if modname.startswith(base):\n                    if not self.exclude_libs or (\".libs\" not in modname):\n                        if any(name in modname for name in self.module_names):\n                            try:\n                                module = importlib.import_module(modname)\n                                for name, obj in inspect.getmembers(module):\n                                    if inspect.isclass(obj) and obj.__module__ == modname:\n                                        self._class_table[name] = modname\n                            except ModuleNotFoundError as ex:\n                                pass",
  "def get_module_name(self, class_name):\n        return self._class_table.get(class_name, None)",
  "class Node(object):\n    def __init__(self, element):\n        \"\"\"A JSON element with additional data.\n\n        Args:\n            element: element to create Node object for\n        \"\"\"\n        self.parent = None\n        self.element = element\n        self.level = 0\n        self.key = \"\"\n        self.position = 0\n        self.paths = []\n        self.processor = None\n        self.exit_cb = None  # node_exit_cb_signature(node: Node)\n        self.props = {}\n\n    def path(self):\n        if len(self.paths) <= 0:\n            return \"\"\n\n        return \".\".join(self.paths)\n\n    def parent_element(self):\n        if self.parent:\n            return self.parent.element\n        else:\n            return None",
  "def _child_node(node: Node, key, pos, element) -> Node:\n    child = Node(element)\n    child.processor = node.processor\n    child.level = node.level + 1\n    child.position = pos\n    child.parent = node\n    child.paths = copy.copy(node.paths)\n\n    child.key = key\n    if pos > 0:\n        child.key = \"#{}\".format(pos)\n\n    child.paths.append(child.key)\n    return child",
  "class JsonObjectProcessor(object):\n    \"\"\"JsonObjectProcessor is used to process JSON elements by the scan_json() function.\"\"\"\n\n    def process_element(self, node: Node):\n        \"\"\"This method is called by the scan() function for each JSON element scanned.\n\n        Args:\n            node: the node representing the JSON element\n        \"\"\"\n        pass",
  "class JsonScanner(object):\n    def __init__(self, json_data: dict, location=None):\n        \"\"\"Scanner for processing JSON data.\n\n        Args:\n            json_data: dictionary containing json data to scan\n            location: location to provide in error messages\n        \"\"\"\n        assert isinstance(json_data, dict), \"json_data must be dict\"\n        self.location = location\n        self.data = json_data\n\n    def _do_scan(self, node: Node):\n        try:\n            node.processor.process_element(node)\n        except BaseException as ex:\n            if self.location:\n                raise ConfigError(\"Error processing {} in JSON element {}: {}\".format(self.location, node.path(), ex))\n            else:\n                raise ConfigError(\"Error in JSON element {}: {}\".format(node.path(), ex))\n\n        element = node.element\n\n        if isinstance(element, dict):\n            # need to make a copy of the element dict in case the processor modifies the dict\n            iter_dict = copy.copy(element)\n            for k, v in iter_dict.items():\n                self._do_scan(_child_node(node, k, 0, v))\n        elif isinstance(element, list):\n            for i in range(len(element)):\n                self._do_scan(_child_node(node, node.key, i + 1, element[i]))\n\n        if node.exit_cb is not None:\n            try:\n                node.exit_cb(node)\n            except BaseException as ex:\n                if self.location:\n                    raise ConfigError(\n                        \"Error post-processing {} in JSON element {}: {}\".format(self.location, node.path(), ex)\n                    )\n                else:\n                    raise ConfigError(\"Error post-processing JSON element {}: {}\".format(node.path(), ex))\n\n    def scan(self, processor: JsonObjectProcessor):\n        assert isinstance(processor, JsonObjectProcessor), \"processor must be JsonObjectProcessor\"\n        node = Node(self.data)\n        node.processor = processor\n        self._do_scan(node)",
  "def __init__(self, element):\n        \"\"\"A JSON element with additional data.\n\n        Args:\n            element: element to create Node object for\n        \"\"\"\n        self.parent = None\n        self.element = element\n        self.level = 0\n        self.key = \"\"\n        self.position = 0\n        self.paths = []\n        self.processor = None\n        self.exit_cb = None  # node_exit_cb_signature(node: Node)\n        self.props = {}",
  "def path(self):\n        if len(self.paths) <= 0:\n            return \"\"\n\n        return \".\".join(self.paths)",
  "def parent_element(self):\n        if self.parent:\n            return self.parent.element\n        else:\n            return None",
  "def process_element(self, node: Node):\n        \"\"\"This method is called by the scan() function for each JSON element scanned.\n\n        Args:\n            node: the node representing the JSON element\n        \"\"\"\n        pass",
  "def __init__(self, json_data: dict, location=None):\n        \"\"\"Scanner for processing JSON data.\n\n        Args:\n            json_data: dictionary containing json data to scan\n            location: location to provide in error messages\n        \"\"\"\n        assert isinstance(json_data, dict), \"json_data must be dict\"\n        self.location = location\n        self.data = json_data",
  "def _do_scan(self, node: Node):\n        try:\n            node.processor.process_element(node)\n        except BaseException as ex:\n            if self.location:\n                raise ConfigError(\"Error processing {} in JSON element {}: {}\".format(self.location, node.path(), ex))\n            else:\n                raise ConfigError(\"Error in JSON element {}: {}\".format(node.path(), ex))\n\n        element = node.element\n\n        if isinstance(element, dict):\n            # need to make a copy of the element dict in case the processor modifies the dict\n            iter_dict = copy.copy(element)\n            for k, v in iter_dict.items():\n                self._do_scan(_child_node(node, k, 0, v))\n        elif isinstance(element, list):\n            for i in range(len(element)):\n                self._do_scan(_child_node(node, node.key, i + 1, element[i]))\n\n        if node.exit_cb is not None:\n            try:\n                node.exit_cb(node)\n            except BaseException as ex:\n                if self.location:\n                    raise ConfigError(\n                        \"Error post-processing {} in JSON element {}: {}\".format(self.location, node.path(), ex)\n                    )\n                else:\n                    raise ConfigError(\"Error post-processing JSON element {}: {}\".format(node.path(), ex))",
  "def scan(self, processor: JsonObjectProcessor):\n        assert isinstance(processor, JsonObjectProcessor), \"processor must be JsonObjectProcessor\"\n        node = Node(self.data)\n        node.processor = processor\n        self._do_scan(node)",
  "class Queue(object):\n    def __init__(self, name):\n        \"\"\"Queue object with basic functions.\n\n        Args:\n            name: name of queue\n        \"\"\"\n        self.name = name\n        self.items = []\n        self._update_lock = threading.Lock()\n        self.next_seq_no = 1\n\n    def append(self, item):\n        with self._update_lock:\n            self.items.append(item)\n            seq_no = self.next_seq_no\n            self.next_seq_no += 1\n            return seq_no\n\n    def len(self):\n        with self._update_lock:\n            return len(self.items)\n\n    def get(self, default=None):\n        with self._update_lock:\n            if len(self.items) > 0:\n                result = self.items[0]\n            else:\n                result = default\n        return result\n\n    def pop(self, default=None):\n        with self._update_lock:\n            if len(self.items) > 0:\n                result = self.items.pop(0)\n            else:\n                result = default\n        return result\n\n    def fill(self, data, limit):\n        with self._update_lock:\n            count = limit - len(self.items)\n            if count > 0:\n                for _ in range(count):\n                    self.items.append(data)\n\n    def clear(self):\n        with self._update_lock:\n            self.items = []",
  "class Channel(object):\n    def __init__(self, src, dest):\n        \"\"\"Channel object.\n\n        Args:\n            src: source\n            dest: destination\n        \"\"\"\n        self.src = src\n        self.dest = dest\n        self.req = Queue(\"req\")\n        self.reply = Queue(\"reply\")\n\n    def send(self, src, data):\n        if src == self.src:\n            self.req.append(data)\n        elif src == self.dest:\n            self.reply.append(data)\n\n    def receive(self, src, default=None):\n        if src == self.src:\n            return self.reply.pop(default=default)\n        elif src == self.dest:\n            return self.req.pop(default=default)\n        else:\n            return default\n\n    def __str__(self):\n        return \"Channel({}<=>{})\".format(self.src.name, self.dest.name)",
  "def __init__(self, name):\n        \"\"\"Queue object with basic functions.\n\n        Args:\n            name: name of queue\n        \"\"\"\n        self.name = name\n        self.items = []\n        self._update_lock = threading.Lock()\n        self.next_seq_no = 1",
  "def append(self, item):\n        with self._update_lock:\n            self.items.append(item)\n            seq_no = self.next_seq_no\n            self.next_seq_no += 1\n            return seq_no",
  "def len(self):\n        with self._update_lock:\n            return len(self.items)",
  "def get(self, default=None):\n        with self._update_lock:\n            if len(self.items) > 0:\n                result = self.items[0]\n            else:\n                result = default\n        return result",
  "def pop(self, default=None):\n        with self._update_lock:\n            if len(self.items) > 0:\n                result = self.items.pop(0)\n            else:\n                result = default\n        return result",
  "def fill(self, data, limit):\n        with self._update_lock:\n            count = limit - len(self.items)\n            if count > 0:\n                for _ in range(count):\n                    self.items.append(data)",
  "def clear(self):\n        with self._update_lock:\n            self.items = []",
  "def __init__(self, src, dest):\n        \"\"\"Channel object.\n\n        Args:\n            src: source\n            dest: destination\n        \"\"\"\n        self.src = src\n        self.dest = dest\n        self.req = Queue(\"req\")\n        self.reply = Queue(\"reply\")",
  "def send(self, src, data):\n        if src == self.src:\n            self.req.append(data)\n        elif src == self.dest:\n            self.reply.append(data)",
  "def receive(self, src, default=None):\n        if src == self.src:\n            return self.reply.pop(default=default)\n        elif src == self.dest:\n            return self.req.pop(default=default)\n        else:\n            return default",
  "def __str__(self):\n        return \"Channel({}<=>{})\".format(self.src.name, self.dest.name)",
  "class FilePipe(Pipe):\n    def __init__(self, root_path: str, name: str):\n        \"\"\"Implementation of communication through the file system.\n\n        Args:\n            root_path: root path\n            name: name of pipe\n        \"\"\"\n        assert os.path.exists(root_path), 'root path \"{}\" does not exist'.format(root_path)\n        pipe_path = os.path.join(root_path, name)\n\n        if not os.path.exists(pipe_path):\n            os.mkdir(pipe_path)\n\n        x_path = os.path.join(pipe_path, \"x\")\n        if not os.path.exists(x_path):\n            os.mkdir(x_path)\n            print(\"created {}\".format(x_path))\n\n        y_path = os.path.join(pipe_path, \"y\")\n        if not os.path.exists(y_path):\n            os.mkdir(y_path)\n            print(\"created {}\".format(y_path))\n\n        t_path = os.path.join(pipe_path, \"t\")\n        if not os.path.exists(t_path):\n            os.mkdir(t_path)\n            print(\"created {}\".format(t_path))\n\n        Pipe.__init__(self, name)\n        self.pipe_path = pipe_path\n        self.x_path = x_path\n        self.y_path = y_path\n        self.t_path = t_path\n\n    def _clear_dir(self, p: str):\n        file_list = os.listdir(p)\n        if file_list:\n            for f in file_list:\n                os.remove(os.path.join(p, f))\n\n    def _topic_to_file_name(self, topic: str):\n        return \"{}.{}\".format(topic, uuid.uuid4())\n\n    def _file_name_to_topic(self, file_name: str):\n        parts = file_name.split(\".\")\n        return \".\".join(parts[0 : len(parts) - 1])\n\n    def _create_file(self, dir: str, topic: str, data_bytes):\n        file_name = self._topic_to_file_name(topic)\n        file_path = os.path.join(dir, file_name)\n\n        tmp_name = file_name + \".tmp\"\n        tmp_path = os.path.join(self.t_path, tmp_name)\n        with open(tmp_path, \"wb\") as f:\n            f.write(data_bytes)\n        os.rename(tmp_path, file_path)\n\n    def clear(self):\n        self._clear_dir(self.x_path)\n        self._clear_dir(self.y_path)\n        self._clear_dir(self.t_path)\n\n    def x_put(self, topic: str, data_bytes):\n        # put it in Y's queue\n        self._create_file(self.y_path, topic, data_bytes)\n\n    def _get_next(self, from_dir: str):\n        # print('get from dir: {}'.format(from_dir))\n        files = os.listdir(from_dir)\n        if files:\n            files = [os.path.join(from_dir, f) for f in files]\n            files.sort(key=os.path.getmtime, reverse=False)\n            next = files[0]\n            # print('got file {}'.format(next))\n\n            topic = self._file_name_to_topic(os.path.basename(next))\n            with open(next, mode=\"rb\") as file:  # b is important -> binary\n                data = file.read()\n            os.remove(next)  # remove this file\n            return topic, data\n        else:\n            return None, None\n\n    def _get_from_dir(self, from_dir: str, timeout=None):\n        if not timeout or timeout <= 0:\n            return self._get_next(from_dir)\n\n        start = time.time()\n        while True:\n            topic, data = self._get_next(from_dir)\n            if topic is not None:\n                return topic, data\n\n            if time.time() - start >= timeout:\n                break\n            time.sleep(2)\n\n        return None, None\n\n    def x_get(self, timeout=None) -> (str, bytes):\n        # read from X's queue\n        return self._get_from_dir(self.x_path, timeout)\n\n    def y_put(self, topic: str, data_bytes):\n        # put it in X's queue\n        self._create_file(self.x_path, topic, data_bytes)\n\n    def y_get(self, timeout=None):\n        # read from Y's queue\n        return self._get_from_dir(self.y_path, timeout)",
  "def __init__(self, root_path: str, name: str):\n        \"\"\"Implementation of communication through the file system.\n\n        Args:\n            root_path: root path\n            name: name of pipe\n        \"\"\"\n        assert os.path.exists(root_path), 'root path \"{}\" does not exist'.format(root_path)\n        pipe_path = os.path.join(root_path, name)\n\n        if not os.path.exists(pipe_path):\n            os.mkdir(pipe_path)\n\n        x_path = os.path.join(pipe_path, \"x\")\n        if not os.path.exists(x_path):\n            os.mkdir(x_path)\n            print(\"created {}\".format(x_path))\n\n        y_path = os.path.join(pipe_path, \"y\")\n        if not os.path.exists(y_path):\n            os.mkdir(y_path)\n            print(\"created {}\".format(y_path))\n\n        t_path = os.path.join(pipe_path, \"t\")\n        if not os.path.exists(t_path):\n            os.mkdir(t_path)\n            print(\"created {}\".format(t_path))\n\n        Pipe.__init__(self, name)\n        self.pipe_path = pipe_path\n        self.x_path = x_path\n        self.y_path = y_path\n        self.t_path = t_path",
  "def _clear_dir(self, p: str):\n        file_list = os.listdir(p)\n        if file_list:\n            for f in file_list:\n                os.remove(os.path.join(p, f))",
  "def _topic_to_file_name(self, topic: str):\n        return \"{}.{}\".format(topic, uuid.uuid4())",
  "def _file_name_to_topic(self, file_name: str):\n        parts = file_name.split(\".\")\n        return \".\".join(parts[0 : len(parts) - 1])",
  "def _create_file(self, dir: str, topic: str, data_bytes):\n        file_name = self._topic_to_file_name(topic)\n        file_path = os.path.join(dir, file_name)\n\n        tmp_name = file_name + \".tmp\"\n        tmp_path = os.path.join(self.t_path, tmp_name)\n        with open(tmp_path, \"wb\") as f:\n            f.write(data_bytes)\n        os.rename(tmp_path, file_path)",
  "def clear(self):\n        self._clear_dir(self.x_path)\n        self._clear_dir(self.y_path)\n        self._clear_dir(self.t_path)",
  "def x_put(self, topic: str, data_bytes):\n        # put it in Y's queue\n        self._create_file(self.y_path, topic, data_bytes)",
  "def _get_next(self, from_dir: str):\n        # print('get from dir: {}'.format(from_dir))\n        files = os.listdir(from_dir)\n        if files:\n            files = [os.path.join(from_dir, f) for f in files]\n            files.sort(key=os.path.getmtime, reverse=False)\n            next = files[0]\n            # print('got file {}'.format(next))\n\n            topic = self._file_name_to_topic(os.path.basename(next))\n            with open(next, mode=\"rb\") as file:  # b is important -> binary\n                data = file.read()\n            os.remove(next)  # remove this file\n            return topic, data\n        else:\n            return None, None",
  "def _get_from_dir(self, from_dir: str, timeout=None):\n        if not timeout or timeout <= 0:\n            return self._get_next(from_dir)\n\n        start = time.time()\n        while True:\n            topic, data = self._get_next(from_dir)\n            if topic is not None:\n                return topic, data\n\n            if time.time() - start >= timeout:\n                break\n            time.sleep(2)\n\n        return None, None",
  "def x_get(self, timeout=None) -> (str, bytes):\n        # read from X's queue\n        return self._get_from_dir(self.x_path, timeout)",
  "def y_put(self, topic: str, data_bytes):\n        # put it in X's queue\n        self._create_file(self.x_path, topic, data_bytes)",
  "def y_get(self, timeout=None):\n        # read from Y's queue\n        return self._get_from_dir(self.y_path, timeout)",
  "class EndPoint(object):\n    def __init__(self, get_func, put_func):\n        \"\"\"Object with put and get functions.\n\n        Args:\n            get_func: get function\n            put_func: put function\n        \"\"\"\n        self.get_func = get_func\n        self.put_func = put_func\n\n    def put(self, topic: str, data_bytes):\n        self.put_func(topic=topic, data_bytes=data_bytes)\n\n    def get(self, timeout=None):\n        return self.get_func(timeout=timeout)",
  "class Pipe(object):\n    def __init__(self, name):\n        \"\"\"Base class for communication.\n\n        Args:\n            name: name of pipe\n        \"\"\"\n        self.name = name\n        self.x = EndPoint(self.x_get, self.x_put)\n        self.y = EndPoint(self.y_get, self.y_put)\n\n    def clear(self):\n        pass\n\n    def x_put(self, topic: str, data_bytes):\n        pass\n\n    def x_get(self, timeout=None):\n        pass\n\n    def y_put(self, topic: str, data_bytes):\n        pass\n\n    def y_get(self, timeout=None):\n        pass",
  "def __init__(self, get_func, put_func):\n        \"\"\"Object with put and get functions.\n\n        Args:\n            get_func: get function\n            put_func: put function\n        \"\"\"\n        self.get_func = get_func\n        self.put_func = put_func",
  "def put(self, topic: str, data_bytes):\n        self.put_func(topic=topic, data_bytes=data_bytes)",
  "def get(self, timeout=None):\n        return self.get_func(timeout=timeout)",
  "def __init__(self, name):\n        \"\"\"Base class for communication.\n\n        Args:\n            name: name of pipe\n        \"\"\"\n        self.name = name\n        self.x = EndPoint(self.x_get, self.x_put)\n        self.y = EndPoint(self.y_get, self.y_put)",
  "def clear(self):\n        pass",
  "def x_put(self, topic: str, data_bytes):\n        pass",
  "def x_get(self, timeout=None):\n        pass",
  "def y_put(self, topic: str, data_bytes):\n        pass",
  "def y_get(self, timeout=None):\n        pass"
]