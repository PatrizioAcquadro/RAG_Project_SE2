[
  "def pytest_addoption(parser):\n    \"\"\"\n    Adds a custom command line option to pytest to control plotting and longrun.\n    \"\"\"\n    parser.addoption(\n        \"--plotting-on\",\n        action=\"store_true\",\n        default=False,\n        help=\"switch on interactive plotting in tests\",\n    )\n    parser.addoption(\n        \"--longrun\",\n        action=\"store_true\",\n        dest=\"longrun\",\n        default=False,\n        help=\"enable longrundecorated tests\",\n    )\n    parser.addoption(\n        \"--reactor\",\n        action=\"store_true\",\n        dest=\"reactor\",\n        default=False,\n        help=\"enable reactor end-to-end test\",\n    )\n\n    parser.addoption(\n        \"--private\",\n        action=\"store_true\",\n        dest=\"private\",\n        default=False,\n        help=\"run tests that use private data\",\n    )",
  "def pytest_configure(config):\n    \"\"\"\n    Configures pytest with the plotting and longrun command line options.\n    \"\"\"\n    if not config.getoption(\"--plotting-on\"):\n        # We're not displaying plots so use a display-less backend\n        mpl.use(\"Agg\")\n        # Disable CAD viewer by mocking out FreeCAD API's displayer.\n        # Note that if we use a new CAD backend, this must be changed.\n        with suppress(ImportError):\n            mock.patch(\"bluemira.codes._polyscope.ps\").start()\n        mock.patch(\"bluemira.codes._freecadapi.show_cad\").start()\n\n    options = {\n        \"longrun\": config.option.longrun,\n        \"reactor\": config.option.reactor,\n        \"private\": config.option.private,\n    }\n    if options[\"private\"] and try_get_bluemira_private_data_root() is None:\n        raise ValueError(\"You cannot run private tests. Data directory not found\")\n\n    strings = []\n    for name, value in options.items():\n        if not value:\n            strings.append(f\"not {name}\")\n\n    logic_string = \" and \".join(strings)\n\n    setattr(config.option, \"markexpr\", logic_string)",
  "class EUDEMO(Reactor):\n    \"\"\"EUDEMO reactor definition.\"\"\"\n\n    # Components\n    plasma: Plasma\n    vacuum_vessel: VacuumVessel\n    thermal_shield: ThermalShield\n    divertor: Divertor\n    blanket: Blanket\n    tf_coils: TFCoil\n    pf_coils: PFCoil\n    coil_structures: CoilStructures\n    cryostat: Cryostat\n    radiation_shield: RadiationShield\n\n    # Models\n    equilibria: EquilibriumManager",
  "def build_reference_equilibrium(\n    params: Union[Dict, ParameterFrame],\n    build_config: Dict,\n    equilibrium_manager: EquilibriumManager,\n    lcfs_coords: Optional[Coordinates],\n    profiles: Optional[Profile],\n) -> Equilibrium:\n    \"\"\"\n    Build the reference equilibrium for the tokamak and store in\n    the equilibrium manager\n    \"\"\"\n    designer = ReferenceFreeBoundaryEquilibriumDesigner(\n        params,\n        build_config,\n        lcfs_coords,\n        profiles,\n    )\n    reference_eq = designer.execute()\n    constraints = None\n    result = None\n    if designer.opt_problem is not None:\n        constraints = designer.opt_problem.targets\n        result = designer._result\n    ref_snapshot = Snapshot(\n        reference_eq,\n        reference_eq.coilset,\n        constraints,\n        reference_eq.profiles,\n        result,\n        reference_eq.limiter,\n    )\n    equilibrium_manager.add_state(equilibrium_manager.REFERENCE, ref_snapshot)\n    return reference_eq",
  "def build_plasma(params, build_config: Dict, eq: Equilibrium) -> Plasma:\n    \"\"\"Build EUDEMO plasma from an equilibrium.\"\"\"\n    lcfs_loop = eq.get_LCFS()\n    lcfs_wire = interpolate_bspline({\"x\": lcfs_loop.x, \"z\": lcfs_loop.z}, closed=True)\n    builder = PlasmaBuilder(params, build_config, lcfs_wire)\n    return Plasma(builder.build())",
  "def build_vacuum_vessel(params, build_config, ivc_koz) -> VacuumVessel:\n    \"\"\"Build the vacuum vessel around the given IVC keep-out zone.\"\"\"\n    vv_builder = VacuumVesselBuilder(params, build_config, ivc_koz)\n    return VacuumVessel(vv_builder.build())",
  "def build_vacuum_vessel_thermal_shield(\n    params, build_config, vv_koz\n) -> VacuumVesselThermalShield:\n    \"\"\"Build the vacuum vessel thermal shield around the given  VV keep-out zone\"\"\"\n    vvts_builder = VVTSBuilder(params, build_config, vv_koz)\n    return VacuumVesselThermalShield(vvts_builder.build())",
  "def build_cryots(params, build_config, pf_kozs, tf_koz) -> CryostatThermalShield:\n    \"\"\"\n    Build the Cryostat thermal shield for the reactor.\n    \"\"\"\n    cts_builder = CryostatTSBuilder(\n        params,\n        build_config,\n        pf_kozs,\n        tf_koz,\n    )\n    return CryostatThermalShield(cts_builder.build())",
  "def assemble_thermal_shield(vv_thermal_shield, cryostat_thermal_shield):\n    \"\"\"\n    Assemble the thermal shield component for the reactor.\n    \"\"\"\n    component = Component(\n        name=\"Thermal Shield\",\n        children=[vv_thermal_shield.component(), cryostat_thermal_shield.component()],\n    )\n    return ThermalShield(component)",
  "def build_divertor(params, build_config, div_silhouette) -> Divertor:\n    \"\"\"Build the divertor given a silhouette of a sector.\"\"\"\n    builder = DivertorBuilder(params, build_config, div_silhouette)\n    return Divertor(builder.build())",
  "def build_blanket(\n    params,\n    build_config: Dict,\n    blanket_boundary,\n    blanket_face,\n    r_inner_cut: float,\n    cut_angle: float,\n) -> Blanket:\n    \"\"\"Build the blanket given a silhouette of a sector.\"\"\"\n    designer = BlanketDesigner(\n        params, blanket_boundary, blanket_face, r_inner_cut, cut_angle\n    )\n    ib_silhouette, ob_silhouette = designer.execute()\n    builder = BlanketBuilder(params, build_config, ib_silhouette, ob_silhouette)\n    return Blanket(builder.build())",
  "def build_tf_coils(params, build_config, separatrix, vvts_cross_section) -> TFCoil:\n    \"\"\"Design and build the TF coils for the reactor.\"\"\"\n    centreline, wp_cross_section = run_designer(\n        TFCoilDesigner,\n        params,\n        build_config,\n        separatrix=separatrix,\n        keep_out_zone=vvts_cross_section,\n    )\n    builder = TFCoilBuilder(\n        params, build_config, centreline.create_shape(), wp_cross_section\n    )\n    return TFCoil(builder.build(), builder._make_field_solver())",
  "def build_pf_coils(\n    params,\n    build_config,\n    equilibrium_manager,\n    tf_coil_boundary,\n    pf_coil_keep_out_zones=(),\n) -> PFCoil:\n    \"\"\"\n    Design and build the PF coils for the reactor.\n    \"\"\"\n    pf_coil_keep_out_zones_new = []\n    # This is a very crude way of forcing PF coil centrepoints away from the KOZs\n    # to stop clashes between ports and PF coil corners\n    # TODO: Implement adjustable current bounds on sub-opt problems\n    offset_value = np.sqrt(\n        params.global_params.I_p.value / params.global_params.PF_jmax.value\n    )\n    for koz in pf_coil_keep_out_zones:\n        new_wire = offset_wire(koz.boundary[0], offset_value, open_wire=False)\n        new_face = BluemiraFace(new_wire)\n        pf_coil_keep_out_zones_new.append(new_face)\n\n    pf_designer = PFCoilsDesigner(\n        params,\n        build_config,\n        equilibrium_manager,\n        tf_coil_boundary,\n        pf_coil_keep_out_zones_new,\n    )\n\n    coilset = pf_designer.execute()\n    component = build_pf_coils_component(params, build_config, coilset)\n    return PFCoil(component, coilset)",
  "def build_coil_structures(\n    params,\n    build_config,\n    tf_coil_xz_face,\n    pf_coil_xz_wires,\n    pf_coil_keep_out_zones,\n) -> CoilStructures:\n    \"\"\"\n    Design and build the coil structures for the reactor.\n    \"\"\"\n    component = build_coil_structures_component(\n        params, build_config, tf_coil_xz_face, pf_coil_xz_wires, pf_coil_keep_out_zones\n    )\n    return CoilStructures(component)",
  "def build_upper_port(\n    params,\n    build_config,\n    upper_port_koz: BluemiraFace,\n    pf_coils,\n    cryostat_ts_xz_boundary: BluemiraFace,\n):\n    \"\"\"\n    Build the upper port for the reactor.\n    \"\"\"\n    ts_builder = TSUpperPortDuctBuilder(params, upper_port_koz, cryostat_ts_xz_boundary)\n    ts_upper_port = ts_builder.build()\n    vv_builder = VVUpperPortDuctBuilder(params, upper_port_koz, cryostat_ts_xz_boundary)\n    vv_upper_port = vv_builder.build()\n    return ts_upper_port, vv_upper_port",
  "def build_equatorial_port(params, build_config, cryostat_ts_xz_boundary):\n    \"\"\"\n    Build the equatorial port for the reactor.\n    \"\"\"\n    builder = VVEquatorialPortDuctBuilder(params, cryostat_ts_xz_boundary)\n    vv_eq_port = builder.build()\n    builder = TSEquatorialPortDuctBuilder(params, cryostat_ts_xz_boundary)\n    ts_eq_port = builder.build()\n    return ts_eq_port, vv_eq_port",
  "def build_lower_port(\n    params,\n    build_config,\n    lp_duct_angled_nowall_extrude_boundary,\n    lp_duct_straight_nowall_extrude_boundary,\n    cryostat_xz_boundary,\n):\n    \"\"\"Builder for the Lower Port and Duct\"\"\"\n    offset = params.global_params.tk_cr_vv.value + params.global_params.g_cr_ts.value\n    x_straight_end = cryostat_xz_boundary.bounding_box.x_max - offset\n    builder = TSLowerPortDuctBuilder(\n        params,\n        build_config,\n        lp_duct_angled_nowall_extrude_boundary,\n        lp_duct_straight_nowall_extrude_boundary,\n        x_straight_end,\n    )\n    ts_lower_port = builder.build()\n\n    builder = VVLowerPortDuctBuilder(\n        params,\n        build_config,\n        lp_duct_angled_nowall_extrude_boundary,\n        lp_duct_straight_nowall_extrude_boundary,\n        x_straight_end,\n    )\n    vv_lower_port = builder.build()\n    return ts_lower_port, vv_lower_port",
  "def build_cryostat(params, build_config, cryostat_thermal_koz) -> Cryostat:\n    \"\"\"\n    Design and build the Cryostat for the reactor.\n    \"\"\"\n    cryod = CryostatDesigner(params, cryostat_thermal_koz)\n    return Cryostat(CryostatBuilder(params, build_config, *cryod.execute()).build())",
  "def build_radiation_shield(params, build_config, cryostat_koz) -> RadiationShield:\n    \"\"\"\n    Design and build the Radiation shield for the reactor.\n    \"\"\"\n    return RadiationShield(\n        RadiationShieldBuilder(params, build_config, BluemiraFace(cryostat_koz)).build()\n    )",
  "def build_cryostat_plugs(\n    params, build_config, ts_ports, cryostat_xz_boundary: BluemiraFace\n):\n    \"\"\"\n    Build the port plugs for the cryostat.\n    \"\"\"\n    closest_faces = []\n    for port in ts_ports:\n        xyz = port.get_component(\"xyz\")\n        for child in xyz.children:\n            if \"voidspace\" not in child.name:\n                port_xyz = child.shape.deepcopy()\n                port_xyz.rotate(degree=-180 / params.global_params.n_TF.value)\n        faces = port_xyz.faces\n        distances = [\n            distance_to(f.center_of_mass, cryostat_xz_boundary)[0] for f in faces\n        ]\n        closest_face = faces[np.argmin(distances)]\n        closest_faces.append(closest_face)\n\n    outer_wires = [cf.boundary[0].deepcopy() for cf in closest_faces]\n\n    builder = CryostatPortPlugBuilder(\n        params, build_config, outer_wires, cryostat_xz_boundary\n    )\n    return builder.build()",
  "def build_radiation_plugs(params, build_config, cr_ports, radiation_xz_boundary):\n    \"\"\"\n    Build the port plugs for the radiation shield.\n    \"\"\"\n    closest_faces = []\n    xyz = cr_ports.get_component(\"xyz\")\n    for child in xyz.children:\n        if \"voidspace\" not in child.name:\n            port_xyz = child.shape.deepcopy()\n            port_xyz.rotate(degree=-180 / params.global_params.n_TF.value)\n            faces = port_xyz.faces\n            distances = [\n                distance_to(f.center_of_mass, radiation_xz_boundary)[0] for f in faces\n            ]\n            closest_face = faces[np.argmin(distances)]\n            closest_faces.append(closest_face)\n    outer_wires = [cf.boundary[0].deepcopy() for cf in closest_faces]\n\n    builder = RadiationPortPlugBuilder(\n        params, build_config, outer_wires, radiation_xz_boundary\n    )\n    return builder.build()",
  "class SteadyStatePowerCycleParams(ParameterFrame):\n    \"\"\"\n    Steady-state power cycle solver parameter frame\n    \"\"\"\n\n    P_fus_DT: Parameter[float]\n    P_fus_DD: Parameter[float]\n    P_rad: Parameter[float]\n    P_hcd_ss: Parameter[float]\n    P_hcd_ss_el: Parameter[float]\n    vvpfrac: Parameter[float]\n    e_mult: Parameter[float]\n    e_decay_mult: Parameter[float]\n    f_core_rad_fw: Parameter[float]\n    f_sol_rad: Parameter[float]\n    f_sol_rad_fw: Parameter[float]\n    f_sol_ch_fw: Parameter[float]\n    f_fw_aux: Parameter[float]\n    blanket_type: Parameter[str]\n    bb_p_inlet: Parameter[float]\n    bb_p_outlet: Parameter[float]\n    bb_t_inlet: Parameter[float]\n    bb_t_outlet: Parameter[float]\n    bb_pump_eta_isen: Parameter[float]\n    bb_pump_eta_el: Parameter[float]\n    div_pump_eta_isen: Parameter[float]\n    div_pump_eta_el: Parameter[float]",
  "class EUDEMOReferenceParasiticLoadStrategy(ParasiticLoadStrategy):\n    \"\"\"\n    S. Ciattaglia reference point from the mid-2010's\n    \"\"\"\n\n    def __init__(self):\n        self.p_fusion_ref = 2037e6\n        self.p_cryo = 44e6\n        self.p_mag = 44e6\n        self.p_t_plant = 15.5e6\n        self.p_other = 31e6\n\n    def calculate(self, p_fusion):\n        \"\"\"\n        Because we were told to do this. Nobody trusts models.\n        \"\"\"\n        f_norm = p_fusion / self.p_fusion_ref\n        p_mag = f_norm * self.p_mag\n        p_cryo = f_norm * self.p_cryo\n        p_t_plant = f_norm * self.p_t_plant\n        p_other = f_norm * self.p_other\n        return p_mag, p_cryo, p_t_plant, p_other",
  "class SteadyStatePowerCycleRunMode(BaseRunMode):\n    \"\"\"Enumeration of the run modes for the steady state power cycle solver\"\"\"\n\n    RUN = enum.auto()",
  "class SteadyStatePowerCycleSetup(Task):\n    \"\"\"\n    Setup task for the steady-state power cycle model.\n    \"\"\"\n\n    def run(self):\n        \"\"\"\n        Run the setup task.\n        \"\"\"\n        self.params = make_parameter_frame(self.params, SteadyStatePowerCycleParams)\n        params = self.params  # avoid constant 'self' lookup\n        # TODO: Get remaining hard-coded values hooked up\n        neutron_power_strat = NeutronPowerStrategy(\n            f_blanket=0.9,\n            f_divertor=0.05,\n            f_vessel=params.vvpfrac.value,  # TODO: Change this parameter name\n            f_other=0.01,\n            energy_multiplication=params.e_mult.value,\n            decay_multiplication=params.e_decay_mult.value,\n        )\n        rad_sep_strat = RadChargedPowerStrategy(\n            f_core_rad_fw=params.f_core_rad_fw.value,\n            f_sol_rad=params.f_sol_rad.value,\n            f_sol_rad_fw=params.f_sol_rad_fw.value,\n            f_sol_ch_fw=params.f_sol_ch_fw.value,\n            f_fw_aux=params.f_fw_aux.value,\n        )\n\n        if params.blanket_type.value == \"HCPB\":\n            blanket_pump_strat = HePumping(\n                params.bb_p_inlet.value,\n                params.bb_p_outlet.value,\n                params.bb_t_inlet.value,\n                params.bb_t_outlet.value,\n                eta_isentropic=params.bb_pump_eta_isen.value,\n                eta_electric=params.bb_pump_eta_el.value,\n            )\n            bop_cycle = SuperheatedRankine(\n                bb_t_out=params.bb_t_outlet.value, delta_t_turbine=20\n            )\n        elif params.blanket_type.value == \"WCLL\":\n            blanket_pump_strat = H2OPumping(\n                0.005,\n                eta_isentropic=params.bb_pump_eta_isen.value,\n                eta_electric=params.bb_pump_eta_el.value,\n            )\n            bop_cycle = PredeterminedEfficiency(0.33)\n        else:\n            raise ValueError(f\"Unrecognised blanket type {params.blanket_type.value}\")\n\n        divertor_pump_strat = H2OPumping(\n            f_pump=0.05,\n            eta_isentropic=params.div_pump_eta_isen.value,\n            eta_electric=params.div_pump_eta_el.value,\n        )\n        parasitic_load_strat = EUDEMOReferenceParasiticLoadStrategy()\n        return (\n            rad_sep_strat,\n            neutron_power_strat,\n            blanket_pump_strat,\n            divertor_pump_strat,\n            bop_cycle,\n            parasitic_load_strat,\n        )",
  "class SteadyStatePowerCycleRun(Task):\n    \"\"\"\n    Run task for the steady-state power cycle model.\n    \"\"\"\n\n    def run(self, setup_result):\n        \"\"\"\n        Run the run task. (o.O)\n        \"\"\"\n        params = make_parameter_frame(self.params, BoPModelParams)\n        bop = BalanceOfPlantModel(params, *setup_result)\n        bop.build()\n        return bop",
  "class SteadyStatePowerCycleTeardown(Task):\n    \"\"\"\n    Teardown task for the steady-state power cycle model.\n    \"\"\"\n\n    def run(self, run_result):\n        \"\"\"\n        Run the teardown task.\n        \"\"\"\n        power_cycle = run_result\n        flow_dict = power_cycle.flow_dict\n        electricity = flow_dict[\"Electricity\"]\n        p_el_net = abs(electricity[-1])\n        f_recirc = sum(np.abs(electricity[1:-1])) / abs(electricity[0])\n        eta_ss = p_el_net / (flow_dict[\"Plasma\"][0] + flow_dict[\"Neutrons\"][1])\n        return power_cycle, {\n            \"P_el_net\": p_el_net,\n            \"eta_ss\": eta_ss,\n            \"f_recirc\": f_recirc,\n        }",
  "class SteadyStatePowerCycleSolver(CodesSolver):\n    \"\"\"\n    Solver for the steady-state power cycle of an EU-DEMO reactor.\n    \"\"\"\n\n    name = \"SteadyStatePowerCycle\"\n    setup_cls = SteadyStatePowerCycleSetup\n    run_cls = SteadyStatePowerCycleRun\n    teardown_cls = SteadyStatePowerCycleTeardown\n    run_mode_cls = SteadyStatePowerCycleRunMode\n\n    def execute(self):\n        \"\"\"\n        Execute the solver.\n        \"\"\"\n        power_cycle, result = super().execute(SteadyStatePowerCycleRunMode.RUN)\n        self.model = power_cycle\n        return result",
  "def __init__(self):\n        self.p_fusion_ref = 2037e6\n        self.p_cryo = 44e6\n        self.p_mag = 44e6\n        self.p_t_plant = 15.5e6\n        self.p_other = 31e6",
  "def calculate(self, p_fusion):\n        \"\"\"\n        Because we were told to do this. Nobody trusts models.\n        \"\"\"\n        f_norm = p_fusion / self.p_fusion_ref\n        p_mag = f_norm * self.p_mag\n        p_cryo = f_norm * self.p_cryo\n        p_t_plant = f_norm * self.p_t_plant\n        p_other = f_norm * self.p_other\n        return p_mag, p_cryo, p_t_plant, p_other",
  "def run(self):\n        \"\"\"\n        Run the setup task.\n        \"\"\"\n        self.params = make_parameter_frame(self.params, SteadyStatePowerCycleParams)\n        params = self.params  # avoid constant 'self' lookup\n        # TODO: Get remaining hard-coded values hooked up\n        neutron_power_strat = NeutronPowerStrategy(\n            f_blanket=0.9,\n            f_divertor=0.05,\n            f_vessel=params.vvpfrac.value,  # TODO: Change this parameter name\n            f_other=0.01,\n            energy_multiplication=params.e_mult.value,\n            decay_multiplication=params.e_decay_mult.value,\n        )\n        rad_sep_strat = RadChargedPowerStrategy(\n            f_core_rad_fw=params.f_core_rad_fw.value,\n            f_sol_rad=params.f_sol_rad.value,\n            f_sol_rad_fw=params.f_sol_rad_fw.value,\n            f_sol_ch_fw=params.f_sol_ch_fw.value,\n            f_fw_aux=params.f_fw_aux.value,\n        )\n\n        if params.blanket_type.value == \"HCPB\":\n            blanket_pump_strat = HePumping(\n                params.bb_p_inlet.value,\n                params.bb_p_outlet.value,\n                params.bb_t_inlet.value,\n                params.bb_t_outlet.value,\n                eta_isentropic=params.bb_pump_eta_isen.value,\n                eta_electric=params.bb_pump_eta_el.value,\n            )\n            bop_cycle = SuperheatedRankine(\n                bb_t_out=params.bb_t_outlet.value, delta_t_turbine=20\n            )\n        elif params.blanket_type.value == \"WCLL\":\n            blanket_pump_strat = H2OPumping(\n                0.005,\n                eta_isentropic=params.bb_pump_eta_isen.value,\n                eta_electric=params.bb_pump_eta_el.value,\n            )\n            bop_cycle = PredeterminedEfficiency(0.33)\n        else:\n            raise ValueError(f\"Unrecognised blanket type {params.blanket_type.value}\")\n\n        divertor_pump_strat = H2OPumping(\n            f_pump=0.05,\n            eta_isentropic=params.div_pump_eta_isen.value,\n            eta_electric=params.div_pump_eta_el.value,\n        )\n        parasitic_load_strat = EUDEMOReferenceParasiticLoadStrategy()\n        return (\n            rad_sep_strat,\n            neutron_power_strat,\n            blanket_pump_strat,\n            divertor_pump_strat,\n            bop_cycle,\n            parasitic_load_strat,\n        )",
  "def run(self, setup_result):\n        \"\"\"\n        Run the run task. (o.O)\n        \"\"\"\n        params = make_parameter_frame(self.params, BoPModelParams)\n        bop = BalanceOfPlantModel(params, *setup_result)\n        bop.build()\n        return bop",
  "def run(self, run_result):\n        \"\"\"\n        Run the teardown task.\n        \"\"\"\n        power_cycle = run_result\n        flow_dict = power_cycle.flow_dict\n        electricity = flow_dict[\"Electricity\"]\n        p_el_net = abs(electricity[-1])\n        f_recirc = sum(np.abs(electricity[1:-1])) / abs(electricity[0])\n        eta_ss = p_el_net / (flow_dict[\"Plasma\"][0] + flow_dict[\"Neutrons\"][1])\n        return power_cycle, {\n            \"P_el_net\": p_el_net,\n            \"eta_ss\": eta_ss,\n            \"f_recirc\": f_recirc,\n        }",
  "def execute(self):\n        \"\"\"\n        Execute the solver.\n        \"\"\"\n        power_cycle, result = super().execute(SteadyStatePowerCycleRunMode.RUN)\n        self.model = power_cycle\n        return result",
  "class CoilStructuresParameters(ParameterFrame):\n    \"\"\"\n    Parameters for the coil structures\n    \"\"\"\n\n    n_TF: Parameter[int]\n    tf_wp_depth: Parameter[float]\n    tk_tf_side: Parameter[float]\n    tf_wp_width: Parameter[float]\n\n    # OIS\n    tk_ois: Parameter[float]\n    g_ois_tf_edge: Parameter[float]\n    min_OIS_length: Parameter[float]\n\n    # PF\n    pf_s_tk_plate: Parameter[float]\n    pf_s_n_plate: Parameter[int]\n    pf_s_g: Parameter[float]\n\n    # GS\n    x_g_support: Parameter[float]\n    z_gs: Parameter[float]\n    tf_gs_tk_plate: Parameter[float]\n    tf_gs_g_plate: Parameter[float]\n    tf_gs_base_depth: Parameter[float]",
  "def build_coil_structures_component(\n    params, build_config, tf_coil_xz_face, pf_coil_xz_wires, pf_coil_keep_out_zones\n):\n    \"\"\"\n    Build the coil structures super-component.\n    \"\"\"\n    params = make_parameter_frame(params, CoilStructuresParameters)\n    ois_designer = StraightOISDesigner(\n        params, build_config, tf_coil_xz_face, pf_coil_keep_out_zones\n    )\n    ois_xz_profiles = ois_designer.run()\n    ois_builder = OISBuilder(params, build_config, ois_xz_profiles)\n    ois_component = ois_builder.build()\n\n    tf_koz = tf_coil_xz_face.boundary[0]\n    support_components = []\n    for i, pf_coil in enumerate(pf_coil_xz_wires):\n        bc = {**build_config, \"support_number\": str(i)}\n        pf_support_builder = PFCoilSupportBuilder(params, bc, tf_koz, pf_coil)\n        support_components.append(pf_support_builder.build())\n\n    pf_support_component = Component(\"PF supports\", children=support_components)\n\n    gs_builder = ITERGravitySupportBuilder(params, build_config, tf_koz)\n    gs_component = gs_builder.build()\n\n    component = Component(\n        \"Coil Structures\", children=[ois_component, pf_support_component, gs_component]\n    )\n    return component",
  "class VacuumVessel(PortManagerMixin, ComponentManager):\n    \"\"\"\n    Wrapper around a Vacuum Vessel component tree.\n    \"\"\"\n\n    def xz_boundary(self) -> BluemiraWire:\n        \"\"\"Return a wire giving the vessel's boundary in the xz plane.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(VacuumVesselBuilder.BODY)\n            .shape.boundary[0]\n        )\n\n    def add_ports(self, ports: Union[Component, List[Component]], n_TF: int):\n        \"\"\"\n        Add a series of ports to the vacuum vessel component tree.\n        \"\"\"\n        component = self.component()\n        xyz = component.get_component(\"xyz\")\n        vv_xyz = xyz.get_component(\"Sector 1\")\n        target_void = vv_xyz.get_component(\"Vessel voidspace 1\").shape\n        target_shape = vv_xyz.get_component(\"Body 1\").shape\n\n        if isinstance(ports, Component):\n            ports = [ports]\n\n        tool_voids = []\n        new_shape_pieces = []\n        for i, port in enumerate(ports):\n            if i > 0:\n                target_shape = boolean_fuse(new_shape_pieces)\n\n            port_xyz = port.get_component(\"xyz\")\n            tool_shape = port_xyz.get_component(port.name).shape\n            tool_void = port_xyz.get_component(port.name + \" voidspace\").shape\n            tool_voids.append(tool_void)\n            new_shape_pieces = pipe_pipe_join(\n                target_shape, target_void, tool_shape, tool_void\n            )\n\n        final_shape = boolean_fuse(new_shape_pieces)\n        final_void = boolean_fuse([target_void] + tool_voids)\n\n        sector_body = PhysicalComponent(VacuumVesselBuilder.BODY, final_shape)\n        sector_void = PhysicalComponent(\n            VacuumVesselBuilder.VOID, final_void, material=Void(\"vacuum\")\n        )\n\n        self._orphan_old_components(component)\n        self._create_new_components(sector_body, sector_void, n_TF)\n\n    def _create_new_components(self, sector_body, sector_void, n_TF: int):\n        angle = 180 / n_TF\n        component = self.component()\n        apply_component_display_options(sector_body, color=BLUE_PALETTE[\"VV\"][0])\n        apply_component_display_options(sector_void, color=(0, 0, 0))\n        Component(\n            \"xyz\",\n            children=[Component(\"Sector 1\", children=[sector_body, sector_void])],\n            parent=component,\n        )\n\n        self._make_2d_views(\n            component,\n            sector_body,\n            sector_void,\n            angle,\n            BLUE_PALETTE[\"TS\"][0],\n            void_color=(0, 0, 0),\n        )",
  "class VacuumVesselBuilderParams(ParameterFrame):\n    \"\"\"\n    Vacuum Vessel builder parameters\n    \"\"\"\n\n    n_TF: Parameter[int]\n    r_vv_ib_in: Parameter[float]\n    r_vv_ob_in: Parameter[float]\n    tk_vv_in: Parameter[float]\n    tk_vv_out: Parameter[float]\n    g_vv_bb: Parameter[float]\n    vv_in_off_deg: Parameter[float]\n    vv_out_off_deg: Parameter[float]",
  "class VacuumVesselBuilder(Builder):\n    \"\"\"\n    Vacuum Vessel builder\n    \"\"\"\n\n    VV = \"VV\"\n    BODY = \"Body\"\n    VOID = \"Vessel voidspace\"\n    param_cls: Type[VacuumVesselBuilderParams] = VacuumVesselBuilderParams\n\n    def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        ivc_koz: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.ivc_koz = ivc_koz\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the vacuum vessel component.\n        \"\"\"\n        xz_vv, xz_vacuum = self.build_xz()\n        vv_face = xz_vv.get_component_properties(\"shape\")\n        vacuum_face = xz_vacuum.get_component_properties(\"shape\")\n\n        return self.component_tree(\n            xz=[xz_vv, xz_vacuum],\n            xy=self.build_xy(vv_face),\n            xyz=self.build_xyz(vv_face, vacuum_face, degree=0),\n        )\n\n    def build_xz(\n        self,\n    ) -> PhysicalComponent:\n        \"\"\"\n        Build the x-z components of the vacuum vessel.\n        \"\"\"\n        inner_vv = _offset_wire_discretised(\n            self.ivc_koz,\n            self.params.g_vv_bb.value,\n            join=\"arc\",\n            open_wire=False,\n            ndiscr=600,\n        )\n\n        outer_vv = varied_offset(\n            inner_vv,\n            self.params.tk_vv_in.value,\n            self.params.tk_vv_out.value,\n            self.params.vv_in_off_deg.value,\n            self.params.vv_out_off_deg.value,\n            num_points=300,\n        )\n        inner_vv = force_wire_to_spline(inner_vv, n_edges_max=100)\n        outer_vv = force_wire_to_spline(outer_vv, n_edges_max=100)\n        face = BluemiraFace([outer_vv, inner_vv])\n\n        body = PhysicalComponent(self.BODY, face)\n        vacuum = PhysicalComponent(\n            self.VOID, BluemiraFace(inner_vv), material=Void(\"vacuum\")\n        )\n        apply_component_display_options(body, color=BLUE_PALETTE[self.VV][0])\n        apply_component_display_options(vacuum, color=(0, 0, 0))\n\n        return body, vacuum\n\n    def build_xy(self, vv_face: BluemiraFace) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y components of the vacuum vessel.\n        \"\"\"\n        return build_sectioned_xy(vv_face, BLUE_PALETTE[self.VV][0])\n\n    def build_xyz(\n        self, vv_face: BluemiraFace, vacuum_face: BluemiraFace, degree: float = 360.0\n    ) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y-z components of the vacuum vessel.\n        \"\"\"\n        return build_sectioned_xyz(\n            [vv_face, vacuum_face],\n            [self.BODY, self.VOID],\n            self.params.n_TF.value,\n            [BLUE_PALETTE[self.VV][0], (0, 0, 0)],\n            degree,\n            material=[None, Void(\"vacuum\")],\n        )",
  "def xz_boundary(self) -> BluemiraWire:\n        \"\"\"Return a wire giving the vessel's boundary in the xz plane.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(VacuumVesselBuilder.BODY)\n            .shape.boundary[0]\n        )",
  "def add_ports(self, ports: Union[Component, List[Component]], n_TF: int):\n        \"\"\"\n        Add a series of ports to the vacuum vessel component tree.\n        \"\"\"\n        component = self.component()\n        xyz = component.get_component(\"xyz\")\n        vv_xyz = xyz.get_component(\"Sector 1\")\n        target_void = vv_xyz.get_component(\"Vessel voidspace 1\").shape\n        target_shape = vv_xyz.get_component(\"Body 1\").shape\n\n        if isinstance(ports, Component):\n            ports = [ports]\n\n        tool_voids = []\n        new_shape_pieces = []\n        for i, port in enumerate(ports):\n            if i > 0:\n                target_shape = boolean_fuse(new_shape_pieces)\n\n            port_xyz = port.get_component(\"xyz\")\n            tool_shape = port_xyz.get_component(port.name).shape\n            tool_void = port_xyz.get_component(port.name + \" voidspace\").shape\n            tool_voids.append(tool_void)\n            new_shape_pieces = pipe_pipe_join(\n                target_shape, target_void, tool_shape, tool_void\n            )\n\n        final_shape = boolean_fuse(new_shape_pieces)\n        final_void = boolean_fuse([target_void] + tool_voids)\n\n        sector_body = PhysicalComponent(VacuumVesselBuilder.BODY, final_shape)\n        sector_void = PhysicalComponent(\n            VacuumVesselBuilder.VOID, final_void, material=Void(\"vacuum\")\n        )\n\n        self._orphan_old_components(component)\n        self._create_new_components(sector_body, sector_void, n_TF)",
  "def _create_new_components(self, sector_body, sector_void, n_TF: int):\n        angle = 180 / n_TF\n        component = self.component()\n        apply_component_display_options(sector_body, color=BLUE_PALETTE[\"VV\"][0])\n        apply_component_display_options(sector_void, color=(0, 0, 0))\n        Component(\n            \"xyz\",\n            children=[Component(\"Sector 1\", children=[sector_body, sector_void])],\n            parent=component,\n        )\n\n        self._make_2d_views(\n            component,\n            sector_body,\n            sector_void,\n            angle,\n            BLUE_PALETTE[\"TS\"][0],\n            void_color=(0, 0, 0),\n        )",
  "def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        ivc_koz: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.ivc_koz = ivc_koz",
  "def build(self) -> Component:\n        \"\"\"\n        Build the vacuum vessel component.\n        \"\"\"\n        xz_vv, xz_vacuum = self.build_xz()\n        vv_face = xz_vv.get_component_properties(\"shape\")\n        vacuum_face = xz_vacuum.get_component_properties(\"shape\")\n\n        return self.component_tree(\n            xz=[xz_vv, xz_vacuum],\n            xy=self.build_xy(vv_face),\n            xyz=self.build_xyz(vv_face, vacuum_face, degree=0),\n        )",
  "def build_xz(\n        self,\n    ) -> PhysicalComponent:\n        \"\"\"\n        Build the x-z components of the vacuum vessel.\n        \"\"\"\n        inner_vv = _offset_wire_discretised(\n            self.ivc_koz,\n            self.params.g_vv_bb.value,\n            join=\"arc\",\n            open_wire=False,\n            ndiscr=600,\n        )\n\n        outer_vv = varied_offset(\n            inner_vv,\n            self.params.tk_vv_in.value,\n            self.params.tk_vv_out.value,\n            self.params.vv_in_off_deg.value,\n            self.params.vv_out_off_deg.value,\n            num_points=300,\n        )\n        inner_vv = force_wire_to_spline(inner_vv, n_edges_max=100)\n        outer_vv = force_wire_to_spline(outer_vv, n_edges_max=100)\n        face = BluemiraFace([outer_vv, inner_vv])\n\n        body = PhysicalComponent(self.BODY, face)\n        vacuum = PhysicalComponent(\n            self.VOID, BluemiraFace(inner_vv), material=Void(\"vacuum\")\n        )\n        apply_component_display_options(body, color=BLUE_PALETTE[self.VV][0])\n        apply_component_display_options(vacuum, color=(0, 0, 0))\n\n        return body, vacuum",
  "def build_xy(self, vv_face: BluemiraFace) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y components of the vacuum vessel.\n        \"\"\"\n        return build_sectioned_xy(vv_face, BLUE_PALETTE[self.VV][0])",
  "def build_xyz(\n        self, vv_face: BluemiraFace, vacuum_face: BluemiraFace, degree: float = 360.0\n    ) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y-z components of the vacuum vessel.\n        \"\"\"\n        return build_sectioned_xyz(\n            [vv_face, vacuum_face],\n            [self.BODY, self.VOID],\n            self.params.n_TF.value,\n            [BLUE_PALETTE[self.VV][0], (0, 0, 0)],\n            degree,\n            material=[None, Void(\"vacuum\")],\n        )",
  "class EquilibriumManager:\n    \"\"\"\n    Manager for free-boundary equilibria\n    \"\"\"\n\n    REFERENCE = \"Reference\"\n    BREAKDOWN = \"Breakdown\"\n    SOF = \"SOF\"  # Start of flat-top\n    EOF = \"EOF\"  # End of flat-top\n\n    def __init__(self):\n        self.states = {\n            self.REFERENCE: None,\n            self.BREAKDOWN: None,\n            self.SOF: None,\n            self.EOF: None,\n        }\n\n    def add_state(self, name: str, snapshot: Snapshot):\n        \"\"\"\n        Add an equilibrium state to the Equilibrium manager.\n        \"\"\"\n        if self.states.get(name, None) is not None:\n            bluemira_warn(f\"Over-writing equilibrium state: {name}!\")\n        self.states[name] = snapshot\n\n    def get_state(self, name: str) -> Union[None, Snapshot]:\n        \"\"\"\n        Get an equilibrium state from the Equilibrium manager.\n        \"\"\"\n        return self.states.get(name, None)",
  "def __init__(self):\n        self.states = {\n            self.REFERENCE: None,\n            self.BREAKDOWN: None,\n            self.SOF: None,\n            self.EOF: None,\n        }",
  "def add_state(self, name: str, snapshot: Snapshot):\n        \"\"\"\n        Add an equilibrium state to the Equilibrium manager.\n        \"\"\"\n        if self.states.get(name, None) is not None:\n            bluemira_warn(f\"Over-writing equilibrium state: {name}!\")\n        self.states[name] = snapshot",
  "def get_state(self, name: str) -> Union[None, Snapshot]:\n        \"\"\"\n        Get an equilibrium state from the Equilibrium manager.\n        \"\"\"\n        return self.states.get(name, None)",
  "def radial_build(params: _PfT, build_config: Dict) -> _PfT:\n    \"\"\"\n    Update parameters after a radial build is run/read/mocked using PROCESS.\n\n    Parameters\n    ----------\n    params:\n        Parameters on which to perform the solve (updated)\n    build_config:\n        Build configuration\n\n    Returns\n    -------\n    Updated parameters following the solve.\n    \"\"\"\n    run_mode = build_config.pop(\"run_mode\", \"mock\")\n    plot = build_config.pop(\"plot\", False)\n    solver = systems_code_solver(params, build_config)\n    new_params = solver.execute(run_mode)\n\n    if plot:\n        plot_radial_build(solver.read_directory)\n    params.update_from_frame(new_params)\n    return params",
  "class VacuumVesselThermalShield(ComponentManager):\n    \"\"\"\n    Wrapper around a VVTS component tree.\n    \"\"\"\n\n    def xz_boundary(self) -> BluemiraWire:\n        \"\"\"Return a wire representing the VVTS poloidal silhouette.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(VVTSBuilder.VVTS)\n            .shape.boundary[0]\n        )",
  "class CryostatThermalShield(ComponentManager):\n    \"\"\"\n    Wrapper around a VVTS component tree.\n    \"\"\"\n\n    def xz_boundary(self) -> BluemiraWire:\n        \"\"\"Return a wire representing the VVTS poloidal silhouette.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(CryostatTSBuilder.CRYO_TS)\n            .shape.boundary[0]\n        )",
  "class OrphanerMixin:\n    \"\"\"\n    Component orphanage mixin class\n    \"\"\"\n\n    @staticmethod\n    def _orphan_old_components(components):\n        \"\"\"\n        Orphan and delete previous components\n        \"\"\"\n        if not isinstance(components, Iterable):\n            components = [components]\n        for comp in components:\n            for view in [\"xyz\", \"xz\", \"xy\"]:\n                comp_view = comp.get_component(view)\n                comp_view.parent = None\n                del comp_view",
  "class PlugManagerMixin(OrphanerMixin):\n    \"\"\"\n    Mixin class for miscellaneous plug component integration utilities.\n    \"\"\"\n\n    @staticmethod\n    def _make_2d_views(parent, solid_comp, plug_comps, angle, color, plug_color):\n        for view in [\"xz\", \"xy\"]:\n            solid_comps = make_2d_view_components(\n                view, azimuthal_angle=angle, components=[solid_comp]\n            )[0]\n            for solid in solid_comps:\n                apply_component_display_options(solid, color=color)\n\n            view_plug_comps = make_2d_view_components(\n                view, azimuthal_angle=angle, components=plug_comps\n            )\n            view_plug_comps = [item for row in view_plug_comps for item in row]\n\n            for plug in view_plug_comps:\n                apply_component_display_options(plug, plug_color)\n\n            view_comps = solid_comps + view_plug_comps\n\n            Component(view, children=view_comps, parent=parent)\n\n    def _add_plugs(\n        self,\n        plug_component: Component,\n        n_TF: int,\n        name: str,\n        color_list: List[Tuple[float, float, float]],\n    ):\n        comp = plug_component.get_component(\"xyz\")\n        void_shapes = []\n        plugs = []\n        for child in comp.children:\n            if \"voidspace\" in child.name:\n                void_shapes.append(child.shape)\n            else:\n                plugs.append(child)\n\n        component = self.component()\n        xyz_shape = (\n            component.get_component(\"xyz\")\n            .get_component(\"Sector 1\")\n            .get_component(name)\n            .shape\n        )\n\n        xyz_shape = boolean_cut(xyz_shape, void_shapes)[0]\n        xyz_comp = PhysicalComponent(name, xyz_shape)\n        apply_component_display_options(xyz_comp, color=color_list[0])\n        self._orphan_old_components(component)\n\n        new_components = [xyz_comp] + plugs\n\n        Component(\n            \"xyz\",\n            parent=component,\n            children=[Component(\"Sector 1\", children=new_components)],\n        )\n\n        angle = 180 / n_TF\n        self._make_2d_views(\n            component,\n            xyz_comp,\n            plugs,\n            angle,\n            color_list[0],\n            color_list[1],\n        )",
  "class PortManagerMixin(OrphanerMixin, abc.ABC):\n    \"\"\"\n    Mixin class for miscellaneous port component integration utilities.\n    \"\"\"\n\n    def __init__(self, *args, verbose: bool = True, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.add_ports = _timing(\n            self.add_ports,\n            \"Built in\",\n            f\"Adding ports to {type(self).__name__}\",\n            debug_info_str=not verbose,\n        )\n\n    @staticmethod\n    def _make_2d_views(\n        parent, solid_comp, void_comp, angle, color, void_color=(0, 0, 0)\n    ):\n        for view in [\"xz\", \"xy\"]:\n            solid_comps, void_comps = make_2d_view_components(\n                view, azimuthal_angle=angle, components=[solid_comp, void_comp]\n            )\n            for solid in solid_comps:\n                apply_component_display_options(solid, color=color)\n            for void in void_comps:\n                apply_component_display_options(void, color=void_color)\n            view_comps = solid_comps + void_comps\n\n            Component(view, children=view_comps, parent=parent)\n\n    @abc.abstractmethod\n    def add_ports(self, ports: List[Component], n_TF: int):\n        \"\"\"Add ports to Component\"\"\"",
  "class ThermalShield(PortManagerMixin, ComponentManager):\n    \"\"\"\n    Wrapper around a Thermal Shield component tree.\n    \"\"\"\n\n    def vacuum_vessel_thermal_shield(self) -> Component:\n        \"\"\"\n        Get the vacuum vessel thermal shield component\n        \"\"\"\n        return self.component().get_component(\"VVTS\")\n\n    def cryostat_thermal_shield(self) -> Component:\n        \"\"\"\n        Get the cryostat thermal shield component\n        \"\"\"\n        return self.component().get_component(\"CryostatTS\")\n\n    @staticmethod\n    def _join_ports_to_vvts(\n        ports: List[Component],\n        vvts_target_shape: BluemiraSolid,\n        vvts_target_void: BluemiraSolid,\n    ) -> Tuple[BluemiraSolid, BluemiraSolid, List[BluemiraSolid]]:\n        if isinstance(ports, Component):\n            ports = [ports]\n\n        tool_voids = []\n        new_shape_pieces = []\n        for port in ports:\n            port_xyz = port.get_component(\"xyz\")\n            tool_shape = port_xyz.get_component(port.name).shape\n            tool_void = port_xyz.get_component(port.name + \" voidspace\").shape\n            tool_voids.append(tool_void)\n            result_pieces = pipe_pipe_join(\n                vvts_target_shape, vvts_target_void, tool_shape, tool_void\n            )\n            # Assume the body is the biggest piece\n            result_pieces.sort(key=lambda solid: -solid.volume)\n            vvts_target_shape = result_pieces[0]\n            new_shape_pieces.extend(result_pieces[1:])\n\n        final_shape = boolean_fuse([vvts_target_shape] + new_shape_pieces)\n        final_void = boolean_fuse([vvts_target_void] + tool_voids)\n        return final_shape, final_void, tool_voids\n\n    def add_ports(self, ports: List[Component], n_TF: int):\n        \"\"\"\n        Add ports to the thermal shield\n        \"\"\"\n        vvts = self.vacuum_vessel_thermal_shield()\n        cts = self.cryostat_thermal_shield()\n\n        vvts_xyz = vvts.get_component(\"xyz\")\n        vv_xyz = vvts_xyz.get_component(\"Sector 1\")\n        vvts_target_name = f\"{VVTSBuilder.VVTS} 1\"\n        vvts_void_name = f\"{VVTSBuilder.VOID} 1\"\n        vvts_target_shape = vv_xyz.get_component(vvts_target_name).shape\n        vvts_target_void = vv_xyz.get_component(vvts_void_name).shape\n\n        cts_xyz = cts.get_component(\"xyz\")\n        cr_xyz = cts_xyz.get_component(\"Sector 1\")\n        cts_target_name = f\"{CryostatTSBuilder.CRYO_TS} 1\"\n        cts_void_name = f\"{CryostatTSBuilder.VOID} 1\"\n        cts_target_shape = cr_xyz.get_component(cts_target_name).shape\n        cts_target_void = cr_xyz.get_component(cts_void_name).shape\n\n        final_shape, final_void, tool_voids = self._join_ports_to_vvts(\n            ports, vvts_target_shape, vvts_target_void\n        )\n\n        temp = boolean_cut(final_shape, cts_target_shape)\n        temp.sort(key=lambda solid: -solid.volume)\n        final_shape = temp[0]\n\n        cts_target_shape = boolean_cut(cts_target_shape, tool_voids)[0]\n\n        vvts_sector_body = PhysicalComponent(vvts_target_name, final_shape)\n        vvts_sector_void = PhysicalComponent(\n            vvts_void_name, final_void, material=Void(\"vacuum\")\n        )\n\n        cts_sector_body = PhysicalComponent(cts_target_name, cts_target_shape)\n        cts_sector_void = PhysicalComponent(\n            cts_void_name, cts_target_void, material=Void(\"vacuum\")\n        )\n\n        self._orphan_old_components([vvts, cts])\n        self._create_new_components(\n            vvts_sector_body, vvts_sector_void, cts_sector_body, cts_sector_void, n_TF\n        )\n\n    def _create_new_components(\n        self,\n        vvts_sector_body,\n        vvts_sector_void,\n        cts_sector_body,\n        cts_sector_void,\n        n_TF: int,\n    ):\n        vvts = self.vacuum_vessel_thermal_shield()\n        cts = self.cryostat_thermal_shield()\n        angle = 180 / n_TF\n        apply_component_display_options(vvts_sector_body, color=BLUE_PALETTE[\"TS\"][0])\n        apply_component_display_options(vvts_sector_void, color=(0, 0, 0))\n        apply_component_display_options(cts_sector_body, color=BLUE_PALETTE[\"TS\"][0])\n        apply_component_display_options(cts_sector_void, color=(0, 0, 0))\n        Component(\n            \"xyz\",\n            children=[\n                Component(\"Sector 1\", children=[vvts_sector_body, vvts_sector_void])\n            ],\n            parent=vvts,\n        )\n        Component(\n            \"xyz\",\n            children=[\n                Component(\"Sector 1\", children=[cts_sector_body, cts_sector_void])\n            ],\n            parent=cts,\n        )\n\n        self._make_2d_views(\n            vvts,\n            vvts_sector_body,\n            vvts_sector_void,\n            angle,\n            BLUE_PALETTE[\"TS\"][0],\n            void_color=(0, 0, 0),\n        )\n\n        self._make_2d_views(\n            cts,\n            cts_sector_body,\n            cts_sector_void,\n            angle,\n            BLUE_PALETTE[\"TS\"][0],\n            void_color=(0, 0, 0),\n        )",
  "class Cryostat(PlugManagerMixin, ComponentManager):\n    \"\"\"\n    Wrapper around a Cryostat component tree.\n    \"\"\"\n\n    def xz_boundary(self) -> BluemiraWire:\n        \"\"\"Return a wire representing the Cryostat poloidal silhouette.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(CryostatBuilder.CRYO)\n            .shape.boundary[0]\n        )\n\n    def add_plugs(self, plug_component: Component, n_TF: int):\n        \"\"\"\n        Add plugs to the cryostat component.\n        \"\"\"\n        self._add_plugs(\n            plug_component, n_TF, f\"{CryostatBuilder.CRYO} 1\", BLUE_PALETTE[\"CR\"]\n        )",
  "class RadiationShield(PlugManagerMixin, ComponentManager):\n    \"\"\"\n    Wrapper around a RadiationShield component tree.\n    \"\"\"\n\n    def xz_boundary(self) -> BluemiraWire:\n        \"\"\"Return a wire representing the RadiationShield poloidal silhouette.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(RadiationShieldBuilder.BODY)\n            .shape.boundary[0]\n        )\n\n    def add_plugs(self, plug_component: Component, n_TF: int):\n        \"\"\"\n        Add plugs to the radiation shield component.\n        \"\"\"\n        self._add_plugs(\n            plug_component, n_TF, f\"{RadiationShieldBuilder.BODY} 1\", BLUE_PALETTE[\"RS\"]\n        )",
  "class CoilStructures(ComponentManager):\n    \"\"\"\n    Wrapper around the coil structures component tree\n    \"\"\"\n\n    pass",
  "def xz_boundary(self) -> BluemiraWire:\n        \"\"\"Return a wire representing the VVTS poloidal silhouette.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(VVTSBuilder.VVTS)\n            .shape.boundary[0]\n        )",
  "def xz_boundary(self) -> BluemiraWire:\n        \"\"\"Return a wire representing the VVTS poloidal silhouette.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(CryostatTSBuilder.CRYO_TS)\n            .shape.boundary[0]\n        )",
  "def _orphan_old_components(components):\n        \"\"\"\n        Orphan and delete previous components\n        \"\"\"\n        if not isinstance(components, Iterable):\n            components = [components]\n        for comp in components:\n            for view in [\"xyz\", \"xz\", \"xy\"]:\n                comp_view = comp.get_component(view)\n                comp_view.parent = None\n                del comp_view",
  "def _make_2d_views(parent, solid_comp, plug_comps, angle, color, plug_color):\n        for view in [\"xz\", \"xy\"]:\n            solid_comps = make_2d_view_components(\n                view, azimuthal_angle=angle, components=[solid_comp]\n            )[0]\n            for solid in solid_comps:\n                apply_component_display_options(solid, color=color)\n\n            view_plug_comps = make_2d_view_components(\n                view, azimuthal_angle=angle, components=plug_comps\n            )\n            view_plug_comps = [item for row in view_plug_comps for item in row]\n\n            for plug in view_plug_comps:\n                apply_component_display_options(plug, plug_color)\n\n            view_comps = solid_comps + view_plug_comps\n\n            Component(view, children=view_comps, parent=parent)",
  "def _add_plugs(\n        self,\n        plug_component: Component,\n        n_TF: int,\n        name: str,\n        color_list: List[Tuple[float, float, float]],\n    ):\n        comp = plug_component.get_component(\"xyz\")\n        void_shapes = []\n        plugs = []\n        for child in comp.children:\n            if \"voidspace\" in child.name:\n                void_shapes.append(child.shape)\n            else:\n                plugs.append(child)\n\n        component = self.component()\n        xyz_shape = (\n            component.get_component(\"xyz\")\n            .get_component(\"Sector 1\")\n            .get_component(name)\n            .shape\n        )\n\n        xyz_shape = boolean_cut(xyz_shape, void_shapes)[0]\n        xyz_comp = PhysicalComponent(name, xyz_shape)\n        apply_component_display_options(xyz_comp, color=color_list[0])\n        self._orphan_old_components(component)\n\n        new_components = [xyz_comp] + plugs\n\n        Component(\n            \"xyz\",\n            parent=component,\n            children=[Component(\"Sector 1\", children=new_components)],\n        )\n\n        angle = 180 / n_TF\n        self._make_2d_views(\n            component,\n            xyz_comp,\n            plugs,\n            angle,\n            color_list[0],\n            color_list[1],\n        )",
  "def __init__(self, *args, verbose: bool = True, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.add_ports = _timing(\n            self.add_ports,\n            \"Built in\",\n            f\"Adding ports to {type(self).__name__}\",\n            debug_info_str=not verbose,\n        )",
  "def _make_2d_views(\n        parent, solid_comp, void_comp, angle, color, void_color=(0, 0, 0)\n    ):\n        for view in [\"xz\", \"xy\"]:\n            solid_comps, void_comps = make_2d_view_components(\n                view, azimuthal_angle=angle, components=[solid_comp, void_comp]\n            )\n            for solid in solid_comps:\n                apply_component_display_options(solid, color=color)\n            for void in void_comps:\n                apply_component_display_options(void, color=void_color)\n            view_comps = solid_comps + void_comps\n\n            Component(view, children=view_comps, parent=parent)",
  "def add_ports(self, ports: List[Component], n_TF: int):\n        \"\"\"Add ports to Component\"\"\"",
  "def vacuum_vessel_thermal_shield(self) -> Component:\n        \"\"\"\n        Get the vacuum vessel thermal shield component\n        \"\"\"\n        return self.component().get_component(\"VVTS\")",
  "def cryostat_thermal_shield(self) -> Component:\n        \"\"\"\n        Get the cryostat thermal shield component\n        \"\"\"\n        return self.component().get_component(\"CryostatTS\")",
  "def _join_ports_to_vvts(\n        ports: List[Component],\n        vvts_target_shape: BluemiraSolid,\n        vvts_target_void: BluemiraSolid,\n    ) -> Tuple[BluemiraSolid, BluemiraSolid, List[BluemiraSolid]]:\n        if isinstance(ports, Component):\n            ports = [ports]\n\n        tool_voids = []\n        new_shape_pieces = []\n        for port in ports:\n            port_xyz = port.get_component(\"xyz\")\n            tool_shape = port_xyz.get_component(port.name).shape\n            tool_void = port_xyz.get_component(port.name + \" voidspace\").shape\n            tool_voids.append(tool_void)\n            result_pieces = pipe_pipe_join(\n                vvts_target_shape, vvts_target_void, tool_shape, tool_void\n            )\n            # Assume the body is the biggest piece\n            result_pieces.sort(key=lambda solid: -solid.volume)\n            vvts_target_shape = result_pieces[0]\n            new_shape_pieces.extend(result_pieces[1:])\n\n        final_shape = boolean_fuse([vvts_target_shape] + new_shape_pieces)\n        final_void = boolean_fuse([vvts_target_void] + tool_voids)\n        return final_shape, final_void, tool_voids",
  "def add_ports(self, ports: List[Component], n_TF: int):\n        \"\"\"\n        Add ports to the thermal shield\n        \"\"\"\n        vvts = self.vacuum_vessel_thermal_shield()\n        cts = self.cryostat_thermal_shield()\n\n        vvts_xyz = vvts.get_component(\"xyz\")\n        vv_xyz = vvts_xyz.get_component(\"Sector 1\")\n        vvts_target_name = f\"{VVTSBuilder.VVTS} 1\"\n        vvts_void_name = f\"{VVTSBuilder.VOID} 1\"\n        vvts_target_shape = vv_xyz.get_component(vvts_target_name).shape\n        vvts_target_void = vv_xyz.get_component(vvts_void_name).shape\n\n        cts_xyz = cts.get_component(\"xyz\")\n        cr_xyz = cts_xyz.get_component(\"Sector 1\")\n        cts_target_name = f\"{CryostatTSBuilder.CRYO_TS} 1\"\n        cts_void_name = f\"{CryostatTSBuilder.VOID} 1\"\n        cts_target_shape = cr_xyz.get_component(cts_target_name).shape\n        cts_target_void = cr_xyz.get_component(cts_void_name).shape\n\n        final_shape, final_void, tool_voids = self._join_ports_to_vvts(\n            ports, vvts_target_shape, vvts_target_void\n        )\n\n        temp = boolean_cut(final_shape, cts_target_shape)\n        temp.sort(key=lambda solid: -solid.volume)\n        final_shape = temp[0]\n\n        cts_target_shape = boolean_cut(cts_target_shape, tool_voids)[0]\n\n        vvts_sector_body = PhysicalComponent(vvts_target_name, final_shape)\n        vvts_sector_void = PhysicalComponent(\n            vvts_void_name, final_void, material=Void(\"vacuum\")\n        )\n\n        cts_sector_body = PhysicalComponent(cts_target_name, cts_target_shape)\n        cts_sector_void = PhysicalComponent(\n            cts_void_name, cts_target_void, material=Void(\"vacuum\")\n        )\n\n        self._orphan_old_components([vvts, cts])\n        self._create_new_components(\n            vvts_sector_body, vvts_sector_void, cts_sector_body, cts_sector_void, n_TF\n        )",
  "def _create_new_components(\n        self,\n        vvts_sector_body,\n        vvts_sector_void,\n        cts_sector_body,\n        cts_sector_void,\n        n_TF: int,\n    ):\n        vvts = self.vacuum_vessel_thermal_shield()\n        cts = self.cryostat_thermal_shield()\n        angle = 180 / n_TF\n        apply_component_display_options(vvts_sector_body, color=BLUE_PALETTE[\"TS\"][0])\n        apply_component_display_options(vvts_sector_void, color=(0, 0, 0))\n        apply_component_display_options(cts_sector_body, color=BLUE_PALETTE[\"TS\"][0])\n        apply_component_display_options(cts_sector_void, color=(0, 0, 0))\n        Component(\n            \"xyz\",\n            children=[\n                Component(\"Sector 1\", children=[vvts_sector_body, vvts_sector_void])\n            ],\n            parent=vvts,\n        )\n        Component(\n            \"xyz\",\n            children=[\n                Component(\"Sector 1\", children=[cts_sector_body, cts_sector_void])\n            ],\n            parent=cts,\n        )\n\n        self._make_2d_views(\n            vvts,\n            vvts_sector_body,\n            vvts_sector_void,\n            angle,\n            BLUE_PALETTE[\"TS\"][0],\n            void_color=(0, 0, 0),\n        )\n\n        self._make_2d_views(\n            cts,\n            cts_sector_body,\n            cts_sector_void,\n            angle,\n            BLUE_PALETTE[\"TS\"][0],\n            void_color=(0, 0, 0),\n        )",
  "def xz_boundary(self) -> BluemiraWire:\n        \"\"\"Return a wire representing the Cryostat poloidal silhouette.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(CryostatBuilder.CRYO)\n            .shape.boundary[0]\n        )",
  "def add_plugs(self, plug_component: Component, n_TF: int):\n        \"\"\"\n        Add plugs to the cryostat component.\n        \"\"\"\n        self._add_plugs(\n            plug_component, n_TF, f\"{CryostatBuilder.CRYO} 1\", BLUE_PALETTE[\"CR\"]\n        )",
  "def xz_boundary(self) -> BluemiraWire:\n        \"\"\"Return a wire representing the RadiationShield poloidal silhouette.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(RadiationShieldBuilder.BODY)\n            .shape.boundary[0]\n        )",
  "def add_plugs(self, plug_component: Component, n_TF: int):\n        \"\"\"\n        Add plugs to the radiation shield component.\n        \"\"\"\n        self._add_plugs(\n            plug_component, n_TF, f\"{RadiationShieldBuilder.BODY} 1\", BLUE_PALETTE[\"RS\"]\n        )",
  "def get_inner_cut_point(breeding_blanket_xz, r_inner_cut):\n    \"\"\"\n    Get the inner cut point of the breeding blanket geometry.\n    \"\"\"\n    cut_plane = BluemiraPlane.from_3_points(\n        [r_inner_cut, 0, 0], [r_inner_cut, 0, 1], [r_inner_cut, 1, 1]\n    )\n    # Get the first intersection with the vertical inner cut plane\n    intersections = slice_shape(breeding_blanket_xz.boundary[0], cut_plane)\n    intersections = intersections[intersections[:, -1] > 0.0]\n    intersection = sorted(intersections, key=lambda x: x[-1])[0]\n    return intersection",
  "def make_2d_view_components(\n    view: str, azimuthal_angle: float, components: List[PhysicalComponent]\n) -> List[PhysicalComponent]:\n    \"\"\"\n    Make a 2-D slice of a list of 3-D components\n\n    Parameters\n    ----------\n    view:\n        View to make the components for. From ['xz', 'xy']\n    azimuthal_angle:\n        Angle at which to cut the x-z plane [degree]. Has no effect for the\n        x-y plane\n    components:\n        List of PhysicalComponents to take slices from\n\n    Returns\n    -------\n    List of PhysicalComponents in the desired view plane\n    \"\"\"\n    azimuthal_angle = np.deg2rad(azimuthal_angle)\n    if view == \"xz\":\n        plane = BluemiraPlane.from_3_points(\n            [0, 0, 0], [0, 0, 1], [np.cos(azimuthal_angle), np.sin(azimuthal_angle), 0]\n        )\n    elif view == \"xy\":\n        plane = BluemiraPlane.from_3_points([0, 0, 0], [0, 1, 0], [1, 0, 0])\n    else:\n        raise ValueError(f\"Unrecognised view: {view}, please choose from ['xz', 'xy']\")\n\n    view_comps = []\n    for comp in components:\n        comp_slices = []\n        pieces = slice_shape(comp.shape, plane)\n        # TODO: slice_shape is unreliable for complex shapes...\n\n        if pieces:\n            for i, piece in enumerate(pieces):\n                face = BluemiraFace(piece)\n                if azimuthal_angle != 0:\n                    face.rotate(degree=-np.rad2deg(azimuthal_angle))\n                new_comp = PhysicalComponent(\n                    f\"{comp.name} {i}\", face, material=comp.material\n                )\n                comp_slices.append(new_comp)\n            view_comps.append(comp_slices)\n    return view_comps",
  "class EUDEMOReactorParams(ParameterFrame):\n    \"\"\"All parameters for the EUDEMO reactor.\"\"\"\n\n    # Common parameters\n    A: Parameter[float]\n    B_0: Parameter[float]\n    B_premag_stray_max: Parameter[float]\n    B_tf_peak: Parameter[float]\n    beta_p: Parameter[float]\n    beta: Parameter[float]\n    bb_min_angle: Parameter[float]\n    C_Ejima: Parameter[float]\n    condrad_cryo_heat: Parameter[float]\n    CS_bmax: Parameter[float]\n    CS_jmax: Parameter[float]\n    delta_95: Parameter[float]\n    delta: Parameter[float]\n    e_mult: Parameter[float]\n    e_nbi: Parameter[float]\n    eta_nb: Parameter[float]\n    f_bs: Parameter[float]\n    f_ni: Parameter[float]\n    g_cr_rs: Parameter[float]\n    g_cr_ts: Parameter[float]\n    g_cs_mod: Parameter[float]\n    g_cs_tf: Parameter[float]\n    g_ts_pf: Parameter[float]\n    g_ts_tf: Parameter[float]\n    g_vv_bb: Parameter[float]\n    g_vv_ts: Parameter[float]\n    h_cp_top: Parameter[float]\n    H_star: Parameter[float]\n    h_tf_max_in: Parameter[float]\n    I_p: Parameter[float]\n    ib_offset_angle: Parameter[float]\n    kappa_95: Parameter[float]\n    kappa: Parameter[float]\n    l_i: Parameter[float]\n    n_CS: Parameter[int]\n    n_PF: Parameter[int]\n    n_TF: Parameter[int]\n    ob_offset_angle: Parameter[float]\n    P_bd_in: Parameter[float]\n    P_brehms: Parameter[float]\n    P_el_net_process: Parameter[float]\n    P_el_net: Parameter[float]\n    P_fus_DD: Parameter[float]\n    P_fus_DT: Parameter[float]\n    P_fus: Parameter[float]\n    P_hcd_ss: Parameter[float]\n    P_line: Parameter[float]\n    P_rad_core: Parameter[float]\n    P_rad_edge: Parameter[float]\n    P_rad: Parameter[float]\n    P_sep: Parameter[float]\n    P_sync: Parameter[float]\n    PF_bmax: Parameter[float]\n    PF_jmax: Parameter[float]\n    q_95: Parameter[float]\n    R_0: Parameter[float]\n    r_cs_corner: Parameter[float]\n    r_pf_corner: Parameter[float]\n    r_cp_top: Parameter[float]\n    r_cs_in: Parameter[float]\n    r_fw_ib_in: Parameter[float]\n    r_fw_ob_in: Parameter[float]\n    r_tf_in_centre: Parameter[float]\n    r_tf_in: Parameter[float]\n    r_tf_inboard_out: Parameter[float]\n    r_tf_out_centre: Parameter[float]\n    r_ts_ib_in: Parameter[float]\n    r_vv_ib_in: Parameter[float]\n    r_vv_ob_in: Parameter[float]\n    sigma_tf_case_max: Parameter[float]\n    sigma_tf_wp_max: Parameter[float]\n    T_e: Parameter[float]\n    tau_e: Parameter[float]\n    tau_flattop: Parameter[float]\n    TF_currpt_ob: Parameter[float]\n    TF_E_stored: Parameter[float]\n    TF_res_bus: Parameter[float]\n    TF_res_tot: Parameter[float]\n    TF_respc_ob: Parameter[float]\n    TF_ripple_limit: Parameter[float]\n    tf_wp_depth: Parameter[float]\n    tf_wp_width: Parameter[float]\n    tk_bb_ib: Parameter[float]\n    tk_bb_ob: Parameter[float]\n    tk_cr_vv: Parameter[float]\n    tk_cs_casing: Parameter[float]\n    tk_cs_insulation: Parameter[float]\n    tk_cs: Parameter[float]\n    tk_pf_casing: Parameter[float]\n    tk_pf_insulation: Parameter[float]\n    tk_fw_in: Parameter[float]\n    tk_fw_out: Parameter[float]\n    tk_rs: Parameter[float]\n    tk_sh_bot: Parameter[float]\n    tk_sh_in: Parameter[float]\n    tk_sh_out: Parameter[float]\n    tk_sh_top: Parameter[float]\n    tk_sol_ib: Parameter[float]\n    tk_sol_ob: Parameter[float]\n    tk_tf_front_ib: Parameter[float]\n    tk_tf_inboard: Parameter[float]\n    tk_tf_ins: Parameter[float]\n    tk_tf_insgap: Parameter[float]\n    tk_tf_nose: Parameter[float]\n    tk_tf_outboard: Parameter[float]\n    tk_tf_side: Parameter[float]\n    tk_ts: Parameter[float]\n    tk_vv_bot: Parameter[float]\n    tk_vv_in: Parameter[float]\n    tk_vv_out: Parameter[float]\n    tk_vv_top: Parameter[float]\n    v_burn: Parameter[float]\n    V_p: Parameter[float]\n    well_depth: Parameter[float]\n    Z_eff: Parameter[float]\n\n    # PLASMOD\n    T_e_ped: Parameter[float]\n    q_control: Parameter[float]\n\n    # Equilibrium\n    div_L2D_ib: Parameter[float]\n    div_L2D_ob: Parameter[float]\n    n_CS: Parameter[int]\n    n_PF: Parameter[int]\n    shaf_shift: Parameter[float]\n\n    # Wall designer\n    fw_psi_n: Parameter[float]\n\n    # Divertor silhouette\n    div_type: Parameter[str]\n    div_Ltarg: Parameter[float]  # noqa: N815\n    div_open: Parameter[bool]\n\n    # Plasma face\n    c_rm: Parameter[float]\n\n    # Vacuum vessel\n    vv_in_off_deg: Parameter[float]\n    vv_out_off_deg: Parameter[float]\n\n    # Divertor\n    n_div_cassettes: Parameter[int]\n\n    # Blanket\n    n_bb_inboard: Parameter[int]\n    n_bb_outboard: Parameter[int]\n\n    # TF Coils\n    r_tf_current_ib: Parameter[float]\n    tk_tf_wp_y: Parameter[float]\n    tk_tf_wp: Parameter[float]\n    z_0: Parameter[float]\n\n    # OIS\n    tk_ois: Parameter[float]\n    g_ois_tf_edge: Parameter[float]\n    min_OIS_length: Parameter[float]\n\n    # PF Coils\n    F_cs_sepmax: Parameter[float]\n    F_cs_ztotmax: Parameter[float]\n    F_pf_zmax: Parameter[float]\n\n    # PF supports\n    pf_s_tk_plate: Parameter[float]\n    pf_s_n_plate: Parameter[int]\n    pf_s_g: Parameter[float]\n\n    # Gravity supports\n    x_g_support: Parameter[float]\n    x_gs_kink_diff: Parameter[float]\n    z_gs: Parameter[float]\n    tf_gs_tk_plate: Parameter[float]\n    tf_gs_g_plate: Parameter[float]\n    tf_gs_base_depth: Parameter[float]\n\n    # Ports\n    tk_vv_single_wall: Parameter[float]\n    tk_vv_double_wall: Parameter[float]\n    lower_port_angle: Parameter[float]\n\n    # Powercycle\n    bb_p_inlet: Parameter[float]\n    bb_p_outlet: Parameter[float]\n    bb_pump_eta_el: Parameter[float]\n    bb_pump_eta_isen: Parameter[float]\n    bb_t_inlet: Parameter[float]\n    bb_t_outlet: Parameter[float]\n    blanket_type: Parameter[str]\n    div_pump_eta_el: Parameter[float]\n    div_pump_eta_isen: Parameter[float]\n    e_decay_mult: Parameter[float]\n    f_core_rad_fw: Parameter[float]\n    f_fw_aux: Parameter[float]\n    f_sol_ch_fw: Parameter[float]\n    f_sol_rad: Parameter[float]\n    f_sol_rad_fw: Parameter[float]\n    vvpfrac: Parameter[float]\n    P_hcd_ss_el: Parameter[float]\n\n    # First wall panelling\n    fw_a_max: Parameter[float]\n    fw_dL_min: Parameter[float]",
  "class EquilibriumDesignerParams(ParameterFrame):\n    \"\"\"Parameters for running the `UnconstrainedTikhonovSolver`.\"\"\"\n\n    A: Parameter[float]\n    B_0: Parameter[float]\n    beta_p: Parameter[float]\n    CS_bmax: Parameter[float]\n    CS_jmax: Parameter[float]\n    delta: Parameter[float]\n    delta_95: Parameter[float]\n    div_L2D_ib: Parameter[float]\n    div_L2D_ob: Parameter[float]\n    g_cs_mod: Parameter[float]\n    I_p: Parameter[float]\n    kappa: Parameter[float]\n    kappa_95: Parameter[float]\n    l_i: Parameter[float]\n    n_CS: Parameter[int]\n    n_PF: Parameter[int]\n    PF_bmax: Parameter[float]\n    PF_jmax: Parameter[float]\n    q_95: Parameter[float]\n    R_0: Parameter[float]\n    r_cs_in: Parameter[float]\n    r_tf_in_centre: Parameter[float]\n    r_tf_out_centre: Parameter[float]\n    shaf_shift: Parameter[float]\n    tk_cs_casing: Parameter[float]\n    tk_cs_insulation: Parameter[float]\n    tk_cs: Parameter[float]",
  "class EquilibriumDesigner(Designer[Equilibrium]):\n    \"\"\"\n    Solves an unconstrained Tikhnov current gradient coil-set\n    optimisation problem, outputting an `Equilibrium`.\n\n    Parameters\n    ----------\n    params:\n        The parameters for the solver, the dictionary or frame must\n        contain all the parameters present in\n        `UnconstrainedTikhonovSolverParams`.\n    build_config:\n        The config for the solver. Optional keys:\n        - `read_file_path`: str\n            the path to an eqdsk file to read the equilibrium from,\n            required in `read` mode.\n        - `plot_optimisation`: bool\n            set to `True` to plot the iterations in the optimisation,\n            only used in `run` mode\n    \"\"\"\n\n    params: EquilibriumDesignerParams\n    param_cls = EquilibriumDesignerParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Optional[Dict] = None,\n    ):\n        super().__init__(params, build_config)\n        self.file_path = self.build_config.get(\"file_path\", None)\n        self.plot_optimisation = self.build_config.get(\"plot_optimisation\", False)\n        if self.run_mode == \"read\" and self.file_path is None:\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'read' mode: \"\n                \"'file_path' missing from build config.\"\n            )\n\n    def run(self) -> Equilibrium:\n        \"\"\"Run the designer's optimisation problem.\"\"\"\n        eq = self._make_equilibrium()\n        opt_problem = self._make_opt_problem(eq)\n        iterator_program = PicardIterator(\n            eq,\n            opt_problem,\n            convergence=DudsonConvergence(),\n            relaxation=0.2,\n            fixed_coils=True,\n            plot=self.plot_optimisation,\n        )\n        self._result = iterator_program()\n        self._update_params_from_eq(eq)\n        return eq\n\n    def read(self) -> Equilibrium:\n        \"\"\"Load an equilibrium from a file.\"\"\"\n        eq = Equilibrium.from_eqdsk(self.file_path)\n        self._update_params_from_eq(eq)\n        return eq\n\n    def _update_params_from_eq(self, eq: Equilibrium):\n        plasma_dict = eq.analyse_plasma()\n        new_values = {\n            \"beta_p\": plasma_dict[\"beta_p\"],\n            \"delta_95\": plasma_dict[\"delta_95\"],\n            \"delta\": plasma_dict[\"delta\"],\n            \"I_p\": plasma_dict[\"Ip\"],\n            \"kappa_95\": plasma_dict[\"kappa_95\"],\n            \"kappa\": plasma_dict[\"kappa\"],\n            \"l_i\": plasma_dict[\"li\"],\n            \"q_95\": plasma_dict[\"q_95\"],\n            \"shaf_shift\": np.hypot(plasma_dict[\"dx_shaf\"], plasma_dict[\"dz_shaf\"]),\n        }\n        self.params.update_values(new_values, source=type(self).__name__)\n\n    def _make_equilibrium(self) -> Equilibrium:\n        \"\"\"\n        Make a reference MHD equilibrium for the plasma.\n        \"\"\"\n        return make_equilibrium(\n            EquilibriumParams.from_frame(self.params),\n            _make_tf_boundary(\n                self.params.r_tf_in_centre.value,\n                self.params.r_tf_out_centre.value,\n                self.params.delta_95.value,\n            ),\n            self.build_config.get(\"grid_settings\", {}),\n        )\n\n    def _make_opt_problem(self, eq: Equilibrium):\n        \"\"\"\n        Create the `UnconstrainedTikhonovCurrentGradientCOP` optimisation problem.\n        \"\"\"\n        kappa = 1.12 * self.params.kappa_95.value\n        kappa_ul_tweak = 0.05\n        kappa_u = (1 - kappa_ul_tweak) * kappa\n        kappa_l = (1 + kappa_ul_tweak) * kappa\n\n        eq_targets = EUDEMOSingleNullConstraints(\n            R_0=self.params.R_0.value,\n            Z_0=0.0,\n            A=self.params.A.value,\n            kappa_u=kappa_u,\n            kappa_l=kappa_l,\n            delta_u=self.params.delta_95.value,\n            delta_l=self.params.delta_95.value,\n            psi_u_neg=0.0,\n            psi_u_pos=0.0,\n            psi_l_neg=60.0,\n            psi_l_pos=30.0,\n            div_l_ib=self.params.div_L2D_ib.value,\n            div_l_ob=self.params.div_L2D_ob.value,\n            psibval=0.0,\n            psibtol=1.0e-3,\n            lower=True,\n            n=100,\n        )\n        return UnconstrainedTikhonovCurrentGradientCOP(\n            eq.coilset, eq, eq_targets, gamma=1e-8\n        )",
  "def _make_tf_boundary(\n    r_tf_in_centre: float, r_tf_out_centre: float, delta_95: float\n) -> BluemiraWire:\n    \"\"\"\n    Make an initial TF coil shape to guide an equilibrium calculation.\n    \"\"\"\n    rin, rout = r_tf_in_centre, r_tf_out_centre\n    # TODO: Handle other TF coil parameterisations?\n    shape = PrincetonD({\"x1\": {\"value\": rin}, \"x2\": {\"value\": rout}, \"dz\": {\"value\": 0}})\n    tf_boundary = shape.create_shape()\n    if delta_95 < 0:  # Negative triangularity\n        tf_boundary.rotate(tf_boundary.center_of_mass, direction=(0, 1, 0), degree=180)\n    tf_boundary = offset_wire(tf_boundary, -0.5)\n    x, z = _flatten_shape(*tf_boundary.discretize(200, byedges=True).xz)\n    return make_polygon({\"x\": x, \"z\": z})",
  "def _flatten_shape(x, z):\n    \"\"\"\n    Flattens a shape by dragging the lowest and highest point to the minimum\n    radius point.\n    \"\"\"\n    amin, amax = np.argmin(z), np.argmax(z)\n    num_elements = amax - amin + 2\n\n    xx = np.empty(num_elements)\n    xx[0] = np.min(x)\n    xx[1:-1] = x[amin:amax]\n    xx[-1] = xx[0]\n\n    zmin, zmax = z[amin], z[amax]\n    zz = np.empty(num_elements)\n    zz[0] = zmin\n    zz[1:-1] = z[amin:amax]\n    zz[-1] = zmax\n\n    return xx, zz",
  "def get_plasmod_binary_path():\n    \"\"\"\n    Get the path to the PLASMOD binary.\n    \"\"\"\n    if plasmod_binary := shutil.which(\"plasmod\"):\n        PLASMOD_PATH = os.path.dirname(plasmod_binary)\n    else:\n        PLASMOD_PATH = os.path.join(os.path.dirname(get_bluemira_root()), \"plasmod/bin\")\n    binary = os.path.join(PLASMOD_PATH, \"plasmod\")\n    return binary",
  "class FixedEquilibriumDesignerParams(ParameterFrame):\n    \"\"\"Parameters for running the fixed boundary equilibrium solver.\"\"\"\n\n    A: Parameter[float]\n    B_0: Parameter[float]\n    delta: Parameter[float]\n    delta_95: Parameter[float]\n    I_p: Parameter[float]\n    kappa: Parameter[float]\n    kappa_95: Parameter[float]\n    q_95: Parameter[float]\n    R_0: Parameter[float]\n    r_cs_in: Parameter[float]\n    tk_cs: Parameter[float]\n    v_burn: Parameter[float]\n    P_fus: Parameter[float]\n\n    # PLASMOD parameters\n    q_control: Parameter[float]\n    e_nbi: Parameter[float]\n    f_ni: Parameter[float]\n    T_e_ped: Parameter[float]",
  "class FixedEquilibriumDesigner(Designer[Tuple[Coordinates, CustomProfile]]):\n    \"\"\"\n    Solves a transport <-> fixed boundary equilibrium problem to convergence,\n    returning a `FixedBoundaryEquilibrium`.\n\n    Parameters\n    ----------\n    params:\n        The parameters for the solver\n    build_config:\n        The config for the solver.\n    \"\"\"\n\n    params: FixedEquilibriumDesignerParams\n    param_cls = FixedEquilibriumDesignerParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Optional[Dict] = None,\n    ):\n        super().__init__(params, build_config)\n        self.file_path = self.build_config.get(\"file_path\", None)\n        if self.run_mode == \"read\" and self.file_path is None:\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'read' mode: \"\n                \"'file_path' missing from build config.\"\n            )\n\n    def run(self) -> Tuple[Coordinates, CustomProfile]:\n        \"\"\"\n        Run the FixedEquilibriumDesigner.\n        \"\"\"\n        # Get geometry parameterisation\n        geom_parameterisation = self._get_geometry_parameterisation()\n\n        # Get PLASMOD solver\n        transport_solver = self._get_transport_solver()\n\n        # Get fixed boundary equilibrium solver\n        fem_fixed_be_solver = self._get_fixed_equilibrium_solver()\n\n        # Solve converged transport - fixed boundary equilibrium\n        defaults = {\n            \"lcar_mesh\": 0.3,\n            \"max_iter\": 15,\n            \"iter_err_max\": 1e-3,\n            \"relaxation\": 0.0,\n            \"plot\": False,\n        }\n        settings = self.build_config.get(\"transport_eq_settings\", {})\n        settings = {**defaults, **settings}\n        fixed_equilibrium: FixedBoundaryEquilibrium = solve_transport_fixed_boundary(\n            geom_parameterisation,\n            transport_solver,\n            fem_fixed_be_solver,\n            kappa95_t=self.params.kappa_95.value,  # Target kappa_95\n            delta95_t=self.params.delta_95.value,  # Target delta_95\n            **settings,\n        )\n        if self.file_path is not None:\n            save_fixed_boundary_to_file(\n                self.file_path,\n                f\"Transport-fixed-boundary-solve {fem_fixed_be_solver.iter_err_max:.3e}\",\n                fixed_equilibrium,\n                65,\n                127,\n            )\n\n        xbdry, zbdry = get_mesh_boundary(fixed_equilibrium.mesh)\n        lcfs_coords = Coordinates({\"x\": xbdry, \"y\": 0, \"z\": zbdry})\n        lcfs_coords.close()\n        profiles = CustomProfile(\n            fixed_equilibrium.pprime,\n            fixed_equilibrium.ffprime,\n            R_0=fixed_equilibrium.R_0,\n            B_0=fixed_equilibrium.B_0,\n            I_p=fixed_equilibrium.I_p,\n        )\n        return lcfs_coords, profiles\n\n    def read(self) -> Tuple[Coordinates, CustomProfile]:\n        \"\"\"\n        Read in a fixed boundary equilibrium\n        \"\"\"\n        data = EQDSKInterface.from_file(self.file_path)\n        lcfs_coords = Coordinates({\"x\": data.xbdry, \"y\": 0, \"z\": data.zbdry})\n        lcfs_coords.close()\n\n        profiles = CustomProfile(\n            data.pprime,\n            data.ffprime,\n            R_0=data.xcentre,\n            B_0=data.bcentre,\n            I_p=data.cplasma,\n        )\n        return lcfs_coords, profiles\n\n    def _get_geometry_parameterisation(self):\n        param_cls: Type[GeometryParameterisation] = get_class_from_module(\n            self.build_config[\"param_class\"], default_module=\"bluemira.equilibria.shapes\"\n        )\n        shape_config = self.build_config.get(\"shape_config\", {})\n        input_dict = handle_lcfs_shape_input(param_cls, self.params, shape_config)\n        return param_cls(input_dict)\n\n    def _get_transport_solver(self):\n        defaults = {\n            \"i_impmodel\": \"PED_FIXED\",\n            \"i_modeltype\": \"GYROBOHM_2\",\n            \"i_equiltype\": \"q95_sawtooth\",\n            \"i_pedestal\": \"SAARELMA\",\n            \"isawt\": \"FULLY_RELAXED\",\n        }\n        problem_settings = self.build_config.get(\"plasmod_settings\", defaults)\n        problem_settings[\"amin\"] = self.params.R_0.value / self.params.A.value\n        problem_settings[\"pfus_req\"] = (\n            self.params.P_fus.value / 1e6\n        )  # TODO: Move into PLASMOD params\n        problem_settings[\"q_control\"] = (\n            self.params.q_control.value / 1e6\n        )  # TODO: Move into PLASMOD params\n        problem_settings[\"volume_in\"] = -2500.0\n        problem_settings[\"v_loop\"] = -1.0e-6\n\n        plasmod_build_config = {\n            \"problem_settings\": problem_settings,\n            \"mode\": \"run\",\n            \"binary\": get_plasmod_binary_path(),\n            \"directory\": get_bluemira_path(\"\", subfolder=\"generated_data\"),\n        }\n\n        return transport_code_solver(\n            params=self.params, build_config=plasmod_build_config, module=\"PLASMOD\"\n        )\n\n    def _get_fixed_equilibrium_solver(self):\n        eq_settings = self.build_config.get(\"fixed_equilibrium_settings\", {})\n        defaults = {\n            \"p_order\": 2,\n            \"max_iter\": 30,\n            \"iter_err_max\": 1e-4,\n            \"relaxation\": 0.05,\n        }\n        eq_settings = {**defaults, **eq_settings}\n        return FemGradShafranovFixedBoundary(**eq_settings)",
  "class DummyFixedEquilibriumDesignerParams(ParameterFrame):\n    \"\"\"\n    Parameter frame for the dummy equilibrium designer\n    \"\"\"\n\n    R_0: Parameter[float]\n    B_0: Parameter[float]\n    I_p: Parameter[float]\n    l_i: Parameter[float]\n    beta_p: Parameter[float]\n    A: Parameter[float]\n    delta: Parameter[float]\n    delta_95: Parameter[float]\n    kappa: Parameter[float]\n    kappa_95: Parameter[float]",
  "class DummyFixedEquilibriumDesigner(Designer[Tuple[Coordinates, Profile]]):\n    \"\"\"\n    Dummy equilibrium designer that produces a LCFS shape and a profile\n    object to be used in later reference free boundary equilibrium\n    designers.\n    \"\"\"\n\n    params: DummyFixedEquilibriumDesignerParams\n    param_cls = DummyFixedEquilibriumDesignerParams\n\n    def __init__(self, params, build_config):\n        super().__init__(params, build_config)\n        if self.build_config[\"run_mode\"] != \"run\":\n            bluemira_warn(\n                f\"This designer {type(self).__name__} can only be run in run mode.\"\n            )\n            self.build_config[\"run_mode\"] = \"run\"\n\n    def run(self) -> Tuple[Coordinates, Profile]:\n        \"\"\"\n        Run the DummyFixedEquilibriumDesigner.\n        \"\"\"\n        param_cls = self.build_config.get(\n            \"param_class\", \"bluemira.equilibria.shapes.JohnerLCFS\"\n        )\n        param_cls = get_class_from_module(param_cls)\n        shape_config = self.build_config.get(\"shape_config\", {})\n        input_dict = handle_lcfs_shape_input(param_cls, self.params, shape_config)\n        lcfs_parameterisation = param_cls(input_dict)\n\n        default_settings = {\n            \"n_points\": 200,\n            \"li_rel_tol\": 0.01,\n            \"li_min_iter\": 2,\n        }\n        settings = self.build_config.get(\"settings\", {})\n        settings = {**default_settings, **settings}\n        lcfs_coords = lcfs_parameterisation.create_shape().discretize(\n            byedges=True, ndiscr=settings[\"n_points\"]\n        )\n\n        profiles = BetaLiIpProfile(\n            self.params.beta_p.value,\n            self.params.l_i.value,\n            self.params.I_p.value,\n            R_0=self.params.R_0.value,\n            B_0=self.params.B_0.value,\n            li_rel_tol=settings[\"li_rel_tol\"],\n            li_min_iter=settings[\"li_min_iter\"],\n        )\n        return lcfs_coords, profiles",
  "class ReferenceFreeBoundaryEquilibriumDesignerParams(ParameterFrame):\n    \"\"\"Parameters for running the fixed boundary equilibrium solver.\"\"\"\n\n    A: Parameter[float]\n    B_0: Parameter[float]\n    I_p: Parameter[float]\n    kappa: Parameter[float]\n    R_0: Parameter[float]\n    r_cs_in: Parameter[float]\n    g_cs_mod: Parameter[float]\n    tk_cs_casing: Parameter[float]\n    tk_cs_insulation: Parameter[float]\n\n    tk_cs: Parameter[float]\n    tk_bb_ob: Parameter[float]\n    tk_vv_out: Parameter[float]\n\n    n_CS: Parameter[int]\n    n_PF: Parameter[int]\n\n    # Updated parameters\n    delta_95: Parameter[float]\n    delta: Parameter[float]\n    kappa_95: Parameter[float]\n    q_95: Parameter[float]\n    beta_p: Parameter[float]\n    l_i: Parameter[float]\n    shaf_shift: Parameter[float]",
  "class ReferenceFreeBoundaryEquilibriumDesigner(Designer[Equilibrium]):\n    \"\"\"\n    Solves a free boundary equilibrium from a LCFS shape and profiles.\n\n    Some coils are positioned at sensible locations to try and get an initial\n    free boundary equilibrium in order to be able to draw an initial first wall\n    shape.\n\n    Parameters\n    ----------\n    params:\n        The parameters for the solver\n    build_config:\n        The config for the solver.\n    lcfs_coords:\n        Coordinates for the desired LCFS shape\n    profiles:\n        Profile object describing the equilibrium profiles\n    \"\"\"\n\n    params: ReferenceFreeBoundaryEquilibriumDesignerParams\n    param_cls = ReferenceFreeBoundaryEquilibriumDesignerParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Optional[Dict] = None,\n        lcfs_coords: Optional[Coordinates] = None,\n        profiles: Optional[Profile] = None,\n    ):\n        super().__init__(params, build_config)\n        self.file_path = self.build_config.get(\"file_path\", None)\n        self.lcfs_coords = lcfs_coords\n        self.profiles = profiles\n\n        if self.run_mode == \"read\" and self.file_path is None:\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'read' mode: \"\n                \"'file_path' missing from build config.\"\n            )\n        self.opt_problem = None\n\n        if self.run_mode == \"run\" and (\n            (self.lcfs_coords is None) or (self.profiles is None)\n        ):\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'run' mode without \"\n                \"input LCFS shape or profiles.\"\n            )\n\n    def run(self) -> Equilibrium:\n        \"\"\"\n        Run the FreeBoundaryEquilibriumFromFixedDesigner.\n        \"\"\"\n        lcfs_shape = make_polygon(self.lcfs_coords, closed=True)\n\n        # Make dummy tf coil boundary\n        tf_coil_boundary = self._make_tf_boundary(lcfs_shape)\n\n        defaults = {\n            \"relaxation\": 0.02,\n            \"coil_discretisation\": 0.3,\n            \"gamma\": 1e-8,\n            \"iter_err_max\": 1e-2,\n            \"max_iter\": 30,\n        }\n        settings = self.build_config.get(\"settings\", {})\n        settings = {**defaults, **settings}\n\n        eq = make_reference_equilibrium(\n            ReferenceEquilibriumParams.from_frame(self.params),\n            tf_coil_boundary,\n            lcfs_shape,\n            self.profiles,\n            self.build_config.get(\"grid_settings\", {}),\n        )\n        # TODO: Check coil discretisation is sensible when size not set...\n        discretisation = settings.pop(\"coil_discretisation\")\n        # eq.coilset.discretisation = settings.pop(\"coil_discretisation\")\n        eq.coilset.get_coiltype(\"CS\").discretisation = discretisation\n\n        self.opt_problem = self._make_fbe_opt_problem(\n            eq, lcfs_shape, len(self.lcfs_coords.x), settings.pop(\"gamma\")\n        )\n\n        iter_err_max = settings.pop(\"iter_err_max\")\n        max_iter = settings.pop(\"max_iter\")\n        settings[\"maxiter\"] = max_iter  # TODO: Standardise name in PicardIterator\n        iterator_program = PicardIterator(\n            eq,\n            self.opt_problem,\n            convergence=DudsonConvergence(iter_err_max),\n            plot=self.build_config.get(\"plot\", False),\n            fixed_coils=True,\n            **settings,\n        )\n        self._result = iterator_program()\n\n        if self.build_config.get(\"plot\", False):\n            _, ax = plt.subplots()\n            eq.plot(ax=ax)\n            eq.coilset.plot(ax=ax, label=True)\n            ax.plot(self.lcfs_coords.x, self.lcfs_coords.z, \"\", marker=\"o\")\n            self.opt_problem.targets.plot(ax=ax)\n            plt.show()\n\n        self._update_params_from_eq(eq)\n\n        return eq\n\n    def read(self) -> Equilibrium:\n        \"\"\"Load an equilibrium from a file.\"\"\"\n        eq = Equilibrium.from_eqdsk(self.file_path)\n        self._update_params_from_eq(eq)\n        return eq\n\n    def _make_tf_boundary(\n        self,\n        lcfs_shape: BluemiraWire,\n    ) -> BluemiraWire:\n        coords = lcfs_shape.discretize(byedges=True, ndiscr=200)\n        xu_arg = np.argmax(coords.z)\n        xl_arg = np.argmin(coords.z)\n        xz_min, z_min = coords.x[xl_arg], coords.z[xl_arg]\n        xz_max, z_max = coords.x[xu_arg], coords.z[xu_arg]\n        x_circ = min(xz_min, xz_max)\n        z_circ = z_max - abs(z_min)\n        r_circ = 0.5 * (z_max + abs(z_min))\n\n        offset_value = self.params.tk_bb_ob.value + self.params.tk_vv_out.value + 2.5\n        semi_circle = make_circle(\n            r_circ + offset_value,\n            center=(x_circ, 0, z_circ),\n            start_angle=-90,\n            end_angle=90,\n            axis=(0, 1, 0),\n        )\n\n        xs, zs = semi_circle.start_point().xz.T[0]\n        xe, ze = semi_circle.end_point().xz.T[0]\n        r_cs_out = self.params.r_cs_in.value + self.params.tk_cs.value\n\n        lower_wire = make_polygon({\"x\": [r_cs_out, xs], \"y\": [0, 0], \"z\": [zs, zs]})\n        upper_wire = make_polygon({\"x\": [xe, r_cs_out], \"y\": [0, 0], \"z\": [ze, ze]})\n\n        return BluemiraWire([lower_wire, semi_circle, upper_wire])\n\n    def _make_fbe_opt_problem(\n        self, eq: Equilibrium, lcfs_shape: BluemiraWire, n_points: int, gamma: float\n    ):\n        \"\"\"\n        Create the `UnconstrainedTikhonovCurrentGradientCOP` optimisation problem.\n        \"\"\"\n        eq_targets = ReferenceConstraints(lcfs_shape, n_points)\n        return UnconstrainedTikhonovCurrentGradientCOP(\n            eq.coilset, eq, eq_targets, gamma=gamma\n        )\n\n    def _update_params_from_eq(self, eq: Equilibrium):\n        plasma_dict = eq.analyse_plasma()\n        new_values = {\n            \"beta_p\": plasma_dict[\"beta_p\"],\n            \"delta_95\": plasma_dict[\"delta_95\"],\n            \"delta\": plasma_dict[\"delta\"],\n            \"I_p\": plasma_dict[\"Ip\"],\n            \"kappa_95\": plasma_dict[\"kappa_95\"],\n            \"kappa\": plasma_dict[\"kappa\"],\n            \"l_i\": plasma_dict[\"li\"],\n            \"q_95\": plasma_dict[\"q_95\"],\n            \"shaf_shift\": np.hypot(plasma_dict[\"dx_shaf\"], plasma_dict[\"dz_shaf\"]),\n        }\n        self.params.update_values(new_values, source=type(self).__name__)",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Optional[Dict] = None,\n    ):\n        super().__init__(params, build_config)\n        self.file_path = self.build_config.get(\"file_path\", None)\n        self.plot_optimisation = self.build_config.get(\"plot_optimisation\", False)\n        if self.run_mode == \"read\" and self.file_path is None:\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'read' mode: \"\n                \"'file_path' missing from build config.\"\n            )",
  "def run(self) -> Equilibrium:\n        \"\"\"Run the designer's optimisation problem.\"\"\"\n        eq = self._make_equilibrium()\n        opt_problem = self._make_opt_problem(eq)\n        iterator_program = PicardIterator(\n            eq,\n            opt_problem,\n            convergence=DudsonConvergence(),\n            relaxation=0.2,\n            fixed_coils=True,\n            plot=self.plot_optimisation,\n        )\n        self._result = iterator_program()\n        self._update_params_from_eq(eq)\n        return eq",
  "def read(self) -> Equilibrium:\n        \"\"\"Load an equilibrium from a file.\"\"\"\n        eq = Equilibrium.from_eqdsk(self.file_path)\n        self._update_params_from_eq(eq)\n        return eq",
  "def _update_params_from_eq(self, eq: Equilibrium):\n        plasma_dict = eq.analyse_plasma()\n        new_values = {\n            \"beta_p\": plasma_dict[\"beta_p\"],\n            \"delta_95\": plasma_dict[\"delta_95\"],\n            \"delta\": plasma_dict[\"delta\"],\n            \"I_p\": plasma_dict[\"Ip\"],\n            \"kappa_95\": plasma_dict[\"kappa_95\"],\n            \"kappa\": plasma_dict[\"kappa\"],\n            \"l_i\": plasma_dict[\"li\"],\n            \"q_95\": plasma_dict[\"q_95\"],\n            \"shaf_shift\": np.hypot(plasma_dict[\"dx_shaf\"], plasma_dict[\"dz_shaf\"]),\n        }\n        self.params.update_values(new_values, source=type(self).__name__)",
  "def _make_equilibrium(self) -> Equilibrium:\n        \"\"\"\n        Make a reference MHD equilibrium for the plasma.\n        \"\"\"\n        return make_equilibrium(\n            EquilibriumParams.from_frame(self.params),\n            _make_tf_boundary(\n                self.params.r_tf_in_centre.value,\n                self.params.r_tf_out_centre.value,\n                self.params.delta_95.value,\n            ),\n            self.build_config.get(\"grid_settings\", {}),\n        )",
  "def _make_opt_problem(self, eq: Equilibrium):\n        \"\"\"\n        Create the `UnconstrainedTikhonovCurrentGradientCOP` optimisation problem.\n        \"\"\"\n        kappa = 1.12 * self.params.kappa_95.value\n        kappa_ul_tweak = 0.05\n        kappa_u = (1 - kappa_ul_tweak) * kappa\n        kappa_l = (1 + kappa_ul_tweak) * kappa\n\n        eq_targets = EUDEMOSingleNullConstraints(\n            R_0=self.params.R_0.value,\n            Z_0=0.0,\n            A=self.params.A.value,\n            kappa_u=kappa_u,\n            kappa_l=kappa_l,\n            delta_u=self.params.delta_95.value,\n            delta_l=self.params.delta_95.value,\n            psi_u_neg=0.0,\n            psi_u_pos=0.0,\n            psi_l_neg=60.0,\n            psi_l_pos=30.0,\n            div_l_ib=self.params.div_L2D_ib.value,\n            div_l_ob=self.params.div_L2D_ob.value,\n            psibval=0.0,\n            psibtol=1.0e-3,\n            lower=True,\n            n=100,\n        )\n        return UnconstrainedTikhonovCurrentGradientCOP(\n            eq.coilset, eq, eq_targets, gamma=1e-8\n        )",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Optional[Dict] = None,\n    ):\n        super().__init__(params, build_config)\n        self.file_path = self.build_config.get(\"file_path\", None)\n        if self.run_mode == \"read\" and self.file_path is None:\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'read' mode: \"\n                \"'file_path' missing from build config.\"\n            )",
  "def run(self) -> Tuple[Coordinates, CustomProfile]:\n        \"\"\"\n        Run the FixedEquilibriumDesigner.\n        \"\"\"\n        # Get geometry parameterisation\n        geom_parameterisation = self._get_geometry_parameterisation()\n\n        # Get PLASMOD solver\n        transport_solver = self._get_transport_solver()\n\n        # Get fixed boundary equilibrium solver\n        fem_fixed_be_solver = self._get_fixed_equilibrium_solver()\n\n        # Solve converged transport - fixed boundary equilibrium\n        defaults = {\n            \"lcar_mesh\": 0.3,\n            \"max_iter\": 15,\n            \"iter_err_max\": 1e-3,\n            \"relaxation\": 0.0,\n            \"plot\": False,\n        }\n        settings = self.build_config.get(\"transport_eq_settings\", {})\n        settings = {**defaults, **settings}\n        fixed_equilibrium: FixedBoundaryEquilibrium = solve_transport_fixed_boundary(\n            geom_parameterisation,\n            transport_solver,\n            fem_fixed_be_solver,\n            kappa95_t=self.params.kappa_95.value,  # Target kappa_95\n            delta95_t=self.params.delta_95.value,  # Target delta_95\n            **settings,\n        )\n        if self.file_path is not None:\n            save_fixed_boundary_to_file(\n                self.file_path,\n                f\"Transport-fixed-boundary-solve {fem_fixed_be_solver.iter_err_max:.3e}\",\n                fixed_equilibrium,\n                65,\n                127,\n            )\n\n        xbdry, zbdry = get_mesh_boundary(fixed_equilibrium.mesh)\n        lcfs_coords = Coordinates({\"x\": xbdry, \"y\": 0, \"z\": zbdry})\n        lcfs_coords.close()\n        profiles = CustomProfile(\n            fixed_equilibrium.pprime,\n            fixed_equilibrium.ffprime,\n            R_0=fixed_equilibrium.R_0,\n            B_0=fixed_equilibrium.B_0,\n            I_p=fixed_equilibrium.I_p,\n        )\n        return lcfs_coords, profiles",
  "def read(self) -> Tuple[Coordinates, CustomProfile]:\n        \"\"\"\n        Read in a fixed boundary equilibrium\n        \"\"\"\n        data = EQDSKInterface.from_file(self.file_path)\n        lcfs_coords = Coordinates({\"x\": data.xbdry, \"y\": 0, \"z\": data.zbdry})\n        lcfs_coords.close()\n\n        profiles = CustomProfile(\n            data.pprime,\n            data.ffprime,\n            R_0=data.xcentre,\n            B_0=data.bcentre,\n            I_p=data.cplasma,\n        )\n        return lcfs_coords, profiles",
  "def _get_geometry_parameterisation(self):\n        param_cls: Type[GeometryParameterisation] = get_class_from_module(\n            self.build_config[\"param_class\"], default_module=\"bluemira.equilibria.shapes\"\n        )\n        shape_config = self.build_config.get(\"shape_config\", {})\n        input_dict = handle_lcfs_shape_input(param_cls, self.params, shape_config)\n        return param_cls(input_dict)",
  "def _get_transport_solver(self):\n        defaults = {\n            \"i_impmodel\": \"PED_FIXED\",\n            \"i_modeltype\": \"GYROBOHM_2\",\n            \"i_equiltype\": \"q95_sawtooth\",\n            \"i_pedestal\": \"SAARELMA\",\n            \"isawt\": \"FULLY_RELAXED\",\n        }\n        problem_settings = self.build_config.get(\"plasmod_settings\", defaults)\n        problem_settings[\"amin\"] = self.params.R_0.value / self.params.A.value\n        problem_settings[\"pfus_req\"] = (\n            self.params.P_fus.value / 1e6\n        )  # TODO: Move into PLASMOD params\n        problem_settings[\"q_control\"] = (\n            self.params.q_control.value / 1e6\n        )  # TODO: Move into PLASMOD params\n        problem_settings[\"volume_in\"] = -2500.0\n        problem_settings[\"v_loop\"] = -1.0e-6\n\n        plasmod_build_config = {\n            \"problem_settings\": problem_settings,\n            \"mode\": \"run\",\n            \"binary\": get_plasmod_binary_path(),\n            \"directory\": get_bluemira_path(\"\", subfolder=\"generated_data\"),\n        }\n\n        return transport_code_solver(\n            params=self.params, build_config=plasmod_build_config, module=\"PLASMOD\"\n        )",
  "def _get_fixed_equilibrium_solver(self):\n        eq_settings = self.build_config.get(\"fixed_equilibrium_settings\", {})\n        defaults = {\n            \"p_order\": 2,\n            \"max_iter\": 30,\n            \"iter_err_max\": 1e-4,\n            \"relaxation\": 0.05,\n        }\n        eq_settings = {**defaults, **eq_settings}\n        return FemGradShafranovFixedBoundary(**eq_settings)",
  "def __init__(self, params, build_config):\n        super().__init__(params, build_config)\n        if self.build_config[\"run_mode\"] != \"run\":\n            bluemira_warn(\n                f\"This designer {type(self).__name__} can only be run in run mode.\"\n            )\n            self.build_config[\"run_mode\"] = \"run\"",
  "def run(self) -> Tuple[Coordinates, Profile]:\n        \"\"\"\n        Run the DummyFixedEquilibriumDesigner.\n        \"\"\"\n        param_cls = self.build_config.get(\n            \"param_class\", \"bluemira.equilibria.shapes.JohnerLCFS\"\n        )\n        param_cls = get_class_from_module(param_cls)\n        shape_config = self.build_config.get(\"shape_config\", {})\n        input_dict = handle_lcfs_shape_input(param_cls, self.params, shape_config)\n        lcfs_parameterisation = param_cls(input_dict)\n\n        default_settings = {\n            \"n_points\": 200,\n            \"li_rel_tol\": 0.01,\n            \"li_min_iter\": 2,\n        }\n        settings = self.build_config.get(\"settings\", {})\n        settings = {**default_settings, **settings}\n        lcfs_coords = lcfs_parameterisation.create_shape().discretize(\n            byedges=True, ndiscr=settings[\"n_points\"]\n        )\n\n        profiles = BetaLiIpProfile(\n            self.params.beta_p.value,\n            self.params.l_i.value,\n            self.params.I_p.value,\n            R_0=self.params.R_0.value,\n            B_0=self.params.B_0.value,\n            li_rel_tol=settings[\"li_rel_tol\"],\n            li_min_iter=settings[\"li_min_iter\"],\n        )\n        return lcfs_coords, profiles",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Optional[Dict] = None,\n        lcfs_coords: Optional[Coordinates] = None,\n        profiles: Optional[Profile] = None,\n    ):\n        super().__init__(params, build_config)\n        self.file_path = self.build_config.get(\"file_path\", None)\n        self.lcfs_coords = lcfs_coords\n        self.profiles = profiles\n\n        if self.run_mode == \"read\" and self.file_path is None:\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'read' mode: \"\n                \"'file_path' missing from build config.\"\n            )\n        self.opt_problem = None\n\n        if self.run_mode == \"run\" and (\n            (self.lcfs_coords is None) or (self.profiles is None)\n        ):\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'run' mode without \"\n                \"input LCFS shape or profiles.\"\n            )",
  "def run(self) -> Equilibrium:\n        \"\"\"\n        Run the FreeBoundaryEquilibriumFromFixedDesigner.\n        \"\"\"\n        lcfs_shape = make_polygon(self.lcfs_coords, closed=True)\n\n        # Make dummy tf coil boundary\n        tf_coil_boundary = self._make_tf_boundary(lcfs_shape)\n\n        defaults = {\n            \"relaxation\": 0.02,\n            \"coil_discretisation\": 0.3,\n            \"gamma\": 1e-8,\n            \"iter_err_max\": 1e-2,\n            \"max_iter\": 30,\n        }\n        settings = self.build_config.get(\"settings\", {})\n        settings = {**defaults, **settings}\n\n        eq = make_reference_equilibrium(\n            ReferenceEquilibriumParams.from_frame(self.params),\n            tf_coil_boundary,\n            lcfs_shape,\n            self.profiles,\n            self.build_config.get(\"grid_settings\", {}),\n        )\n        # TODO: Check coil discretisation is sensible when size not set...\n        discretisation = settings.pop(\"coil_discretisation\")\n        # eq.coilset.discretisation = settings.pop(\"coil_discretisation\")\n        eq.coilset.get_coiltype(\"CS\").discretisation = discretisation\n\n        self.opt_problem = self._make_fbe_opt_problem(\n            eq, lcfs_shape, len(self.lcfs_coords.x), settings.pop(\"gamma\")\n        )\n\n        iter_err_max = settings.pop(\"iter_err_max\")\n        max_iter = settings.pop(\"max_iter\")\n        settings[\"maxiter\"] = max_iter  # TODO: Standardise name in PicardIterator\n        iterator_program = PicardIterator(\n            eq,\n            self.opt_problem,\n            convergence=DudsonConvergence(iter_err_max),\n            plot=self.build_config.get(\"plot\", False),\n            fixed_coils=True,\n            **settings,\n        )\n        self._result = iterator_program()\n\n        if self.build_config.get(\"plot\", False):\n            _, ax = plt.subplots()\n            eq.plot(ax=ax)\n            eq.coilset.plot(ax=ax, label=True)\n            ax.plot(self.lcfs_coords.x, self.lcfs_coords.z, \"\", marker=\"o\")\n            self.opt_problem.targets.plot(ax=ax)\n            plt.show()\n\n        self._update_params_from_eq(eq)\n\n        return eq",
  "def read(self) -> Equilibrium:\n        \"\"\"Load an equilibrium from a file.\"\"\"\n        eq = Equilibrium.from_eqdsk(self.file_path)\n        self._update_params_from_eq(eq)\n        return eq",
  "def _make_tf_boundary(\n        self,\n        lcfs_shape: BluemiraWire,\n    ) -> BluemiraWire:\n        coords = lcfs_shape.discretize(byedges=True, ndiscr=200)\n        xu_arg = np.argmax(coords.z)\n        xl_arg = np.argmin(coords.z)\n        xz_min, z_min = coords.x[xl_arg], coords.z[xl_arg]\n        xz_max, z_max = coords.x[xu_arg], coords.z[xu_arg]\n        x_circ = min(xz_min, xz_max)\n        z_circ = z_max - abs(z_min)\n        r_circ = 0.5 * (z_max + abs(z_min))\n\n        offset_value = self.params.tk_bb_ob.value + self.params.tk_vv_out.value + 2.5\n        semi_circle = make_circle(\n            r_circ + offset_value,\n            center=(x_circ, 0, z_circ),\n            start_angle=-90,\n            end_angle=90,\n            axis=(0, 1, 0),\n        )\n\n        xs, zs = semi_circle.start_point().xz.T[0]\n        xe, ze = semi_circle.end_point().xz.T[0]\n        r_cs_out = self.params.r_cs_in.value + self.params.tk_cs.value\n\n        lower_wire = make_polygon({\"x\": [r_cs_out, xs], \"y\": [0, 0], \"z\": [zs, zs]})\n        upper_wire = make_polygon({\"x\": [xe, r_cs_out], \"y\": [0, 0], \"z\": [ze, ze]})\n\n        return BluemiraWire([lower_wire, semi_circle, upper_wire])",
  "def _make_fbe_opt_problem(\n        self, eq: Equilibrium, lcfs_shape: BluemiraWire, n_points: int, gamma: float\n    ):\n        \"\"\"\n        Create the `UnconstrainedTikhonovCurrentGradientCOP` optimisation problem.\n        \"\"\"\n        eq_targets = ReferenceConstraints(lcfs_shape, n_points)\n        return UnconstrainedTikhonovCurrentGradientCOP(\n            eq.coilset, eq, eq_targets, gamma=gamma\n        )",
  "def _update_params_from_eq(self, eq: Equilibrium):\n        plasma_dict = eq.analyse_plasma()\n        new_values = {\n            \"beta_p\": plasma_dict[\"beta_p\"],\n            \"delta_95\": plasma_dict[\"delta_95\"],\n            \"delta\": plasma_dict[\"delta\"],\n            \"I_p\": plasma_dict[\"Ip\"],\n            \"kappa_95\": plasma_dict[\"kappa_95\"],\n            \"kappa\": plasma_dict[\"kappa\"],\n            \"l_i\": plasma_dict[\"li\"],\n            \"q_95\": plasma_dict[\"q_95\"],\n            \"shaf_shift\": np.hypot(plasma_dict[\"dx_shaf\"], plasma_dict[\"dz_shaf\"]),\n        }\n        self.params.update_values(new_values, source=type(self).__name__)",
  "class EquilibriumParams(ParameterFrame):\n    \"\"\"Parameters required to make a new equilibrium.\"\"\"\n\n    A: Parameter[float]\n    B_0: Parameter[float]\n    beta_p: Parameter[float]\n    CS_bmax: Parameter[float]\n    CS_jmax: Parameter[float]\n    delta_95: Parameter[float]\n    g_cs_mod: Parameter[float]\n    I_p: Parameter[float]\n    kappa_95: Parameter[float]\n    n_CS: Parameter[int]\n    n_PF: Parameter[int]\n    PF_bmax: Parameter[float]\n    PF_jmax: Parameter[float]\n    R_0: Parameter[float]\n    r_cs_in: Parameter[float]\n    tk_cs_casing: Parameter[float]\n    tk_cs_insulation: Parameter[float]\n    tk_cs: Parameter[float]",
  "def make_equilibrium(\n    _params: Union[EquilibriumParams, Dict],\n    tf_coil_boundary: BluemiraWire,\n    grid_settings: dict,\n):\n    \"\"\"\n    Build an equilibrium using a coilset and a `BetaIpProfile` profile.\n    \"\"\"\n    if isinstance(_params, dict):\n        params = EquilibriumParams.from_dict(_params)\n    else:\n        params = _params\n\n    kappa = KAPPA_95_TO_100 * params.kappa_95.value\n    coilset = make_coilset(\n        tf_coil_boundary,\n        R_0=params.R_0.value,\n        kappa=kappa,\n        delta=params.delta_95.value,\n        r_cs=params.r_cs_in.value + params.tk_cs.value / 2,\n        tk_cs=params.tk_cs.value / 2,\n        g_cs=params.g_cs_mod.value,\n        tk_cs_ins=params.tk_cs_insulation.value,\n        tk_cs_cas=params.tk_cs_casing.value,\n        n_CS=params.n_CS.value,\n        n_PF=params.n_PF.value,\n        CS_jmax=params.CS_jmax.value,\n        CS_bmax=params.CS_bmax.value,\n        PF_jmax=params.PF_jmax.value,\n        PF_bmax=params.PF_bmax.value,\n    )\n    profiles = BetaIpProfile(\n        params.beta_p.value,\n        params.I_p.value,\n        params.R_0.value,\n        params.B_0.value,\n    )\n    grid = make_grid(params.R_0.value, params.A.value, kappa, grid_settings)\n\n    return Equilibrium(coilset, grid, profiles)",
  "class ReferenceEquilibriumParams(ParameterFrame):\n    \"\"\"Parameters required to make a new reference equilibrium.\"\"\"\n\n    A: Parameter[float]\n    B_0: Parameter[float]\n    I_p: Parameter[float]\n    kappa: Parameter[float]\n    R_0: Parameter[float]\n    r_cs_in: Parameter[float]\n    g_cs_mod: Parameter[float]\n    tk_cs_casing: Parameter[float]\n    tk_cs_insulation: Parameter[float]\n    tk_cs: Parameter[float]\n    beta_p: Parameter[float]\n    l_i: Parameter[float]\n    n_CS: Parameter[int]\n    n_PF: Parameter[int]",
  "def make_reference_equilibrium(\n    _params: Union[ReferenceEquilibriumParams, Dict],\n    tf_track: BluemiraWire,\n    lcfs_shape: BluemiraWire,\n    profiles: Profile,\n    grid_settings: dict,\n):\n    \"\"\"\n    Make a crude reference equilibrium, scaling coils and grid for a first pass\n    solve.\n    \"\"\"\n    if isinstance(_params, dict):\n        params = ReferenceEquilibriumParams.from_dict(_params)\n    else:\n        params = _params\n\n    coilset = make_reference_coilset(\n        tf_track,\n        lcfs_shape,\n        r_cs=params.r_cs_in.value + 0.5 * params.tk_cs.value,\n        tk_cs=0.5 * params.tk_cs.value,\n        g_cs_mod=params.g_cs_mod.value,\n        tk_cs_casing=params.tk_cs_casing.value,\n        tk_cs_insulation=params.tk_cs_insulation.value,\n        n_CS=params.n_CS.value,\n        n_PF=params.n_PF.value,\n    )\n\n    grid = make_grid(\n        params.R_0.value,\n        params.A.value,\n        params.kappa.value,\n        grid_settings,\n    )\n\n    return Equilibrium(coilset, grid, profiles)",
  "def estimate_kappa95(A: float, m_s_limit: float) -> float:\n    \"\"\"\n    Estimate the maximum kappa_95 for a given aspect ratio and margin to\n    stability. It is always better to have as high a kappa_95 as possible, so\n    we maximise it here, for a specified margin to stability value.\n\n    Parameters\n    ----------\n    A:\n        The aspect ratio of the plasma\n    m_s_limit:\n        The margin to stability (typically ~0.3)\n\n    Returns\n    -------\n    The maximum elongation for the specified input values\n\n    Notes\n    -----\n    The model used here is a 2nd order polynomial surface fit, generated using\n    data from CREATE. A quadratic equation is then solved for kappa_95, based\n    on the polynomial surface fit.\n    The data are stored in: data/equilibria/vertical_stability_data.json\n    For the A=2.6, m_s=0 case (a bit of an outlier), there is a fudging to cap the\n    kappa_95 to ~1.8 (which is the recommended value). The fit otherwise overestimates\n    kappa_95 in this corner of the space (kappa_95 ~ 1.81)\n    This is only a crude model, and is only relevant for EU-DEMO-like machines.\n    Furthermore, this is only for flat-top..! Ramp-up and ramp-down may be\n    design driving. Exercise caution.\n    \\t:math:`m_{s} = a\\\\kappa_{95}^{2}+bA^{2}+c\\\\kappa A+d\\\\kappa+eA+f`\\n\n    \\t:math:`\\\\kappa_{95}(A, m_{s}) = \\\\dfrac{-d-cA-\\\\sqrt{(c^{2}-4ab)A^{2}+(2dc-4ae)A+d^{2}-4af+4am_{s})}}{2a}`\n    \"\"\"  # noqa :W505\n    if not 2.6 <= A <= 3.6:\n        bluemira_warn(f\"Kappa 95 estimate only valid for 2.6 <= A <= 3.6, not A = {A}\")\n    if not 0.0 <= m_s_limit <= 0.8655172413793104:\n        bluemira_warn(\n            f\"Kappa 95 estimate only valid for 0.0 <= m_s <= 0.865, not m_s = {m_s_limit}\"\n        )\n\n    a = 3.68436807\n    b = -0.27706527\n    c = 0.87040251\n    d = -18.83740952\n    e = -0.27267618\n    f = 20.5141261\n\n    kappa_95 = (\n        -d\n        - c * A\n        - np.sqrt(\n            (c**2 - 4 * a * b) * A**2\n            + (2 * d * c - 4 * a * e) * A\n            + d**2\n            - 4 * a * f\n            + 4 * a * m_s_limit\n        )\n    ) / (2 * a)\n\n    # We're going to trim kappa_95 to 1.8, which is the maximum of the data, keeping\n    # the function smooth\n    if kappa_95 > 1.77:\n        ratio = 1.77 / kappa_95\n        corner_fudge = 0.3 * (kappa_95 - 1.77) / ratio\n        kappa_95 = kappa_95 ** (ratio) + corner_fudge\n\n    return kappa_95",
  "def handle_lcfs_shape_input(\n    param_cls: GeometryParameterisation,\n    params: ParameterFrame,\n    shape_config: Dict[str, float],\n) -> Dict[str, float]:\n    \"\"\"\n    Process the LCFS shape parameterisation inputs based on a parameterisation\n    and a shape configuration.\n\n    Parameters\n    ----------\n    param_cls:\n        LCFS geometry parameterisation\n    params:\n        Parameters of the reactor\n    shape_config:\n        Dictionary with the various shape configuration keys, which can be specific\n        to the geometry parameterisation\n\n    Returns\n    -------\n    Input dictionary for the initialisation of the specified GeometryParameterisation\n    \"\"\"\n    defaults = {\n        \"f_kappa_l\": 1.0,\n        \"f_delta_l\": 1.0,\n    }\n    shape_config = {**defaults, **shape_config}\n    kappa_95 = params.kappa_95.value\n    delta_95 = params.delta_95.value\n\n    kappa_factor = shape_config.pop(\"f_kappa_l\")\n    delta_factor = shape_config.pop(\"f_delta_l\")\n    if \"kappa_l\" not in shape_config:\n        shape_config[\"kappa_l\"] = kappa_factor * kappa_95\n    if \"kappa_u\" not in shape_config:\n        shape_config[\"kappa_u\"] = kappa_factor**0.5 * kappa_95\n    if \"delta_l\" not in shape_config:\n        shape_config[\"delta_l\"] = delta_factor * delta_95\n    if \"delta_u\" not in shape_config:\n        shape_config[\"delta_u\"] = delta_95\n\n    input_dict = {\n        \"r_0\": {\"value\": params.R_0.value},\n        \"a\": {\"value\": params.R_0.value / params.A.value},\n    }\n\n    param_cls_instance = param_cls()\n\n    for k, v in shape_config.items():\n        if k in param_cls_instance.variables.names:\n            input_dict[k] = {\"value\": v}\n        else:\n            bluemira_warn(\n                f\"Unknown shape parameter {k} for GeometryParameterisation: {param_cls_instance.name}\"\n            )\n    return input_dict",
  "def make_grid(\n    R_0: float, A: float, kappa: float, grid_settings: Dict[str, float]\n) -> Grid:\n    \"\"\"\n    Make a finite difference Grid for an Equilibrium.\n\n    Parameters\n    ----------\n    R_0:\n        Major radius\n    A:\n        Aspect ratio\n    kappa:\n        Elongation\n    grid_settings:\n        Dictionary of grid settings\n\n    Returns\n    -------\n    Finite difference grid for an Equilibrium\n    \"\"\"\n    defaults = {\n        \"grid_scale_x\": 2.0,\n        \"grid_scale_z\": 2.0,\n        \"nx\": 65,\n        \"nz\": 65,\n    }\n    grid_settings = {**defaults, **grid_settings}\n    scale_x = grid_settings[\"grid_scale_x\"]\n    scale_z = grid_settings[\"grid_scale_z\"]\n    nx = grid_settings[\"nx\"]\n    nz = grid_settings[\"nz\"]\n\n    x_min, x_max = R_0 - scale_x * (R_0 / A), R_0 + scale_x * (R_0 / A)\n    z_min, z_max = -scale_z * (kappa * R_0 / A), scale_z * (kappa * R_0 / A)\n    return Grid(x_min, x_max, z_min, z_max, nx, nz)",
  "class DivertorLegCalculator:\n    \"\"\"\n    Straight line divertor leg mixin calculator.\n    \"\"\"\n\n    @staticmethod\n    def calc_line(p1, p2, n):\n        \"\"\"\n        Calculate a linearly spaced series of points on a line between p1 and p2.\n        \"\"\"\n        xn = np.linspace(p1[0], p2[0], int(n))\n        zn = np.linspace(p1[1], p2[1], int(n))\n        return xn, zn\n\n    def calc_divertor_leg(self, x_point, angle, length, n, loc=\"lower\", pos=\"outer\"):\n        \"\"\"\n        Calculate the position of a straight line divertor leg.\n        \"\"\"\n        if loc not in [\"upper\", \"lower\"]:\n            raise ValueError(\n                f\"Please specify loc: 'upper' or 'lower' X-point, not: {loc}\"\n            )\n        if pos not in [\"inner\", \"outer\"]:\n            raise ValueError(f\"Please specify pos: 'inner' or 'outer' X leg, not: {pos}\")\n\n        loc_sign = 1 if loc == \"upper\" else -1\n        pos_sign = 1 if pos == \"outer\" else -1\n\n        angle = np.deg2rad(angle)\n        x = x_point[0] + pos_sign * length * np.cos(angle)\n        z = x_point[1] + loc_sign * length * np.sin(angle)\n\n        return self.calc_line(x_point, (x, z), n)",
  "class EUDEMOSingleNullConstraints(DivertorLegCalculator, MagneticConstraintSet):\n    \"\"\"\n    Parameterised family of magnetic constraints for a typical EU-DEMO-like single\n    null equilibrium.\n    \"\"\"\n\n    def __init__(\n        self,\n        R_0: float,\n        Z_0: float,\n        A: float,\n        kappa_u: float,\n        kappa_l: float,\n        delta_u: float,\n        delta_l: float,\n        psi_u_neg: float,\n        psi_u_pos: float,\n        psi_l_neg: float,\n        psi_l_pos: float,\n        div_l_ib: float,\n        div_l_ob: float,\n        psibval: float,\n        psibtol: float = 1e-3,\n        lower: float = True,\n        n: int = 100,\n    ):\n        constraints = []\n        f_s = flux_surface_johner(\n            R_0,\n            Z_0,\n            R_0 / A,\n            kappa_u,\n            kappa_l,\n            delta_u,\n            delta_l,\n            psi_u_neg,\n            psi_u_pos,\n            psi_l_neg,\n            psi_l_pos,\n            n=200,\n        )\n\n        if lower:\n            arg_x = np.argmin(f_s.z)\n        else:\n            arg_x = np.argmax(f_s.z)\n\n        x_point = [f_s.x[arg_x], f_s.z[arg_x]]\n\n        constraints = [FieldNullConstraint(*x_point)]\n\n        f_s = Coordinates(interpolate_points(*f_s.xyz, n))\n\n        x_s, z_s = f_s.x, f_s.z\n\n        constraints.append(PsiBoundaryConstraint(x_s, z_s, psibval, tolerance=psibtol))\n\n        x_leg1, z_leg1 = self.calc_divertor_leg(\n            x_point, 50, div_l_ob, int(n / 10), loc=\"lower\", pos=\"outer\"\n        )\n\n        x_leg2, z_leg2 = self.calc_divertor_leg(\n            x_point, 40, div_l_ib, int(n / 10), loc=\"lower\", pos=\"inner\"\n        )\n\n        x_legs = np.append(x_leg1, x_leg2)\n        z_legs = np.append(z_leg1, z_leg2)\n        constraints.append(\n            PsiBoundaryConstraint(x_legs, z_legs, psibval, tolerance=psibtol)\n        )\n\n        super().__init__(constraints)",
  "class EUDEMODoubleNullConstraints(DivertorLegCalculator, MagneticConstraintSet):\n    \"\"\"\n    Parameterised family of magnetic constraints for a typical EU-DEMO-like double\n    null equilibrium.\n    \"\"\"\n\n    def __init__(\n        self,\n        R_0: float,\n        Z_0: float,\n        A: float,\n        kappa: float,\n        delta: float,\n        psi_neg: float,\n        psi_pos: float,\n        div_l_ib: float,\n        div_l_ob: float,\n        psibval: float,\n        n: int = 400,\n    ):\n        super().__init__()\n        f_s = flux_surface_johner(\n            R_0,\n            Z_0,\n            R_0 / A,\n            kappa,\n            kappa,\n            delta,\n            delta,\n            psi_neg,\n            psi_pos,\n            psi_neg,\n            psi_pos,\n            n=200,\n        )\n\n        arg_xl = np.argmin(f_s.z)\n        arg_xu = np.argmax(f_s.z)\n        constraints = [\n            FieldNullConstraint(f_s.x[arg_xl], f_s.z[arg_xl]),\n            FieldNullConstraint(f_s.x[arg_xu], f_s.z[arg_xu]),\n        ]\n        f_s = Coordinates(interpolate_points(*f_s.xyz, n))\n        x_s, z_s = f_s.x, f_s.z\n\n        constraints.append(PsiBoundaryConstraint(x_s, z_s, psibval))\n\n        super().__init__(constraints)",
  "class ReferenceConstraints(MagneticConstraintSet):\n    \"\"\"\n    Parameters\n    ----------\n    shape:\n        Geometry from which to build the reference constraints for the equilibrium\n    n_points:\n        Number of points to use when creating the constraints\n    \"\"\"\n\n    def __init__(self, shape: BluemiraWire, n_points: int):\n        coords = shape.discretize(byedges=True, ndiscr=n_points)\n        z_min = np.min(coords.z)\n        z_max = np.max(coords.z)\n        arg_xl = np.argmin(coords.z)\n        arg_xu = np.argmax(coords.z)\n        arg_xin = np.argmin(coords.x)\n\n        if np.isclose(abs(z_min), z_max):\n            # Double null\n            constraints = [\n                FieldNullConstraint(coords.x[arg_xl], coords.z[arg_xl]),\n                FieldNullConstraint(coords.x[arg_xu], coords.z[arg_xu]),\n            ]\n\n        elif abs(z_min) > z_max:\n            # Lower single null\n            constraints = [\n                FieldNullConstraint(\n                    coords.x[arg_xl], coords.z[arg_xl], weights=n_points // 5\n                ),\n                # TODO: This is a hack so I can move on with my life. I'm not even sorry.\n                FieldNullConstraint(\n                    0.85 * coords.x[arg_xu],\n                    1.35 * coords.z[arg_xu],\n                    weights=n_points // 5,\n                ),\n            ]\n\n        else:\n            # Upper single null\n            constraints = [\n                FieldNullConstraint(coords.x[arg_xu], coords.z[arg_xu]),\n            ]\n\n        constraints.append(\n            IsofluxConstraint(\n                coords.x, coords.z, coords.x[arg_xin], coords.z[arg_xin], tolerance=1e-6\n            )\n        )\n\n        super().__init__(constraints)",
  "def calc_line(p1, p2, n):\n        \"\"\"\n        Calculate a linearly spaced series of points on a line between p1 and p2.\n        \"\"\"\n        xn = np.linspace(p1[0], p2[0], int(n))\n        zn = np.linspace(p1[1], p2[1], int(n))\n        return xn, zn",
  "def calc_divertor_leg(self, x_point, angle, length, n, loc=\"lower\", pos=\"outer\"):\n        \"\"\"\n        Calculate the position of a straight line divertor leg.\n        \"\"\"\n        if loc not in [\"upper\", \"lower\"]:\n            raise ValueError(\n                f\"Please specify loc: 'upper' or 'lower' X-point, not: {loc}\"\n            )\n        if pos not in [\"inner\", \"outer\"]:\n            raise ValueError(f\"Please specify pos: 'inner' or 'outer' X leg, not: {pos}\")\n\n        loc_sign = 1 if loc == \"upper\" else -1\n        pos_sign = 1 if pos == \"outer\" else -1\n\n        angle = np.deg2rad(angle)\n        x = x_point[0] + pos_sign * length * np.cos(angle)\n        z = x_point[1] + loc_sign * length * np.sin(angle)\n\n        return self.calc_line(x_point, (x, z), n)",
  "def __init__(\n        self,\n        R_0: float,\n        Z_0: float,\n        A: float,\n        kappa_u: float,\n        kappa_l: float,\n        delta_u: float,\n        delta_l: float,\n        psi_u_neg: float,\n        psi_u_pos: float,\n        psi_l_neg: float,\n        psi_l_pos: float,\n        div_l_ib: float,\n        div_l_ob: float,\n        psibval: float,\n        psibtol: float = 1e-3,\n        lower: float = True,\n        n: int = 100,\n    ):\n        constraints = []\n        f_s = flux_surface_johner(\n            R_0,\n            Z_0,\n            R_0 / A,\n            kappa_u,\n            kappa_l,\n            delta_u,\n            delta_l,\n            psi_u_neg,\n            psi_u_pos,\n            psi_l_neg,\n            psi_l_pos,\n            n=200,\n        )\n\n        if lower:\n            arg_x = np.argmin(f_s.z)\n        else:\n            arg_x = np.argmax(f_s.z)\n\n        x_point = [f_s.x[arg_x], f_s.z[arg_x]]\n\n        constraints = [FieldNullConstraint(*x_point)]\n\n        f_s = Coordinates(interpolate_points(*f_s.xyz, n))\n\n        x_s, z_s = f_s.x, f_s.z\n\n        constraints.append(PsiBoundaryConstraint(x_s, z_s, psibval, tolerance=psibtol))\n\n        x_leg1, z_leg1 = self.calc_divertor_leg(\n            x_point, 50, div_l_ob, int(n / 10), loc=\"lower\", pos=\"outer\"\n        )\n\n        x_leg2, z_leg2 = self.calc_divertor_leg(\n            x_point, 40, div_l_ib, int(n / 10), loc=\"lower\", pos=\"inner\"\n        )\n\n        x_legs = np.append(x_leg1, x_leg2)\n        z_legs = np.append(z_leg1, z_leg2)\n        constraints.append(\n            PsiBoundaryConstraint(x_legs, z_legs, psibval, tolerance=psibtol)\n        )\n\n        super().__init__(constraints)",
  "def __init__(\n        self,\n        R_0: float,\n        Z_0: float,\n        A: float,\n        kappa: float,\n        delta: float,\n        psi_neg: float,\n        psi_pos: float,\n        div_l_ib: float,\n        div_l_ob: float,\n        psibval: float,\n        n: int = 400,\n    ):\n        super().__init__()\n        f_s = flux_surface_johner(\n            R_0,\n            Z_0,\n            R_0 / A,\n            kappa,\n            kappa,\n            delta,\n            delta,\n            psi_neg,\n            psi_pos,\n            psi_neg,\n            psi_pos,\n            n=200,\n        )\n\n        arg_xl = np.argmin(f_s.z)\n        arg_xu = np.argmax(f_s.z)\n        constraints = [\n            FieldNullConstraint(f_s.x[arg_xl], f_s.z[arg_xl]),\n            FieldNullConstraint(f_s.x[arg_xu], f_s.z[arg_xu]),\n        ]\n        f_s = Coordinates(interpolate_points(*f_s.xyz, n))\n        x_s, z_s = f_s.x, f_s.z\n\n        constraints.append(PsiBoundaryConstraint(x_s, z_s, psibval))\n\n        super().__init__(constraints)",
  "def __init__(self, shape: BluemiraWire, n_points: int):\n        coords = shape.discretize(byedges=True, ndiscr=n_points)\n        z_min = np.min(coords.z)\n        z_max = np.max(coords.z)\n        arg_xl = np.argmin(coords.z)\n        arg_xu = np.argmax(coords.z)\n        arg_xin = np.argmin(coords.x)\n\n        if np.isclose(abs(z_min), z_max):\n            # Double null\n            constraints = [\n                FieldNullConstraint(coords.x[arg_xl], coords.z[arg_xl]),\n                FieldNullConstraint(coords.x[arg_xu], coords.z[arg_xu]),\n            ]\n\n        elif abs(z_min) > z_max:\n            # Lower single null\n            constraints = [\n                FieldNullConstraint(\n                    coords.x[arg_xl], coords.z[arg_xl], weights=n_points // 5\n                ),\n                # TODO: This is a hack so I can move on with my life. I'm not even sorry.\n                FieldNullConstraint(\n                    0.85 * coords.x[arg_xu],\n                    1.35 * coords.z[arg_xu],\n                    weights=n_points // 5,\n                ),\n            ]\n\n        else:\n            # Upper single null\n            constraints = [\n                FieldNullConstraint(coords.x[arg_xu], coords.z[arg_xu]),\n            ]\n\n        constraints.append(\n            IsofluxConstraint(\n                coords.x, coords.z, coords.x[arg_xin], coords.z[arg_xin], tolerance=1e-6\n            )\n        )\n\n        super().__init__(constraints)",
  "class TSUpperPortDuctBuilderParams(ParameterFrame):\n    \"\"\"Thermal shield upper port duct builder Parameter Frame\"\"\"\n\n    n_TF: Parameter[int]\n    tf_wp_depth: Parameter[float]\n    g_ts_tf: Parameter[float]\n    tk_ts: Parameter[float]\n    g_cr_ts: Parameter[float]",
  "class TSUpperPortDuctBuilder(Builder):\n    \"\"\"Thermal shield upper port duct builder\"\"\"\n\n    params: TSUpperPortDuctBuilderParams\n    param_cls = TSUpperPortDuctBuilderParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, ConfigParams, None],\n        port_koz: BluemiraFace,\n        cryostat_ts_xz: BluemiraWire,\n    ):\n        super().__init__(params, None)\n        self.x_min = port_koz.bounding_box.x_min\n        self.x_max = port_koz.bounding_box.x_max\n        self.z_max = cryostat_ts_xz.bounding_box.z_max + 0.5 * self.params.g_cr_ts.value\n\n        if self.params.tk_ts.value <= 0:\n            raise ValueError(\"Port wall thickness must be > 0\")\n\n        self.y_offset = self.params.tf_wp_depth.value + self.params.g_ts_tf.value\n\n    def build(self) -> Component:\n        \"\"\"Build upper port\"\"\"\n        xy_face = make_upper_port_xy_face(\n            self.params.n_TF.value,\n            self.x_min,\n            self.x_max,\n            self.params.tk_ts.value,\n            self.params.tk_ts.value,\n            self.y_offset,\n        )\n\n        return self.component_tree(\n            None, [self.build_xy(xy_face)], self.build_xyz(xy_face)\n        )\n\n    def build_xyz(self, xy_face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"Build upper port xyz\"\"\"\n        xy_voidface = BluemiraFace(xy_face.boundary[1])\n        xy_outface = BluemiraFace(xy_face.boundary[0])\n        port = extrude_shape(xy_face, (0, 0, self.z_max))\n        # Add start-cap for future boolean fragmentation help\n        cap = extrude_shape(xy_outface, vec=(0, 0, 0.1))\n        port = boolean_fuse([port, cap])\n        comp = PhysicalComponent(self.name, port)\n        apply_component_display_options(comp, BLUE_PALETTE[\"TS\"][0])\n        void = PhysicalComponent(\n            self.name + \" voidspace\",\n            extrude_shape(xy_voidface, (0, 0, self.z_max)),\n            material=Void(\"vacuum\"),\n        )\n        apply_component_display_options(void, color=(0, 0, 0))\n        return [comp, void]\n\n    def build_xy(self, face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"Build upport port xy face\"\"\"\n        comp = PhysicalComponent(self.name, face)\n        apply_component_display_options(comp, BLUE_PALETTE[\"TS\"][0])\n        return comp",
  "class TSEquatorialPortDuctBuilderParams(ParameterFrame):\n    \"\"\"Thermal shield upper port duct builder Parameter Frame\"\"\"\n\n    n_TF: Parameter[int]\n    R_0: Parameter[float]\n    tf_wp_depth: Parameter[float]\n    g_ts_tf: Parameter[float]\n    g_vv_ts: Parameter[float]\n    tk_ts: Parameter[float]\n    g_cr_ts: Parameter[float]\n    tk_vv_single_wall: Parameter[float]\n    ep_width: Parameter[float]\n    ep_height: Parameter[float]\n    ep_z_position: Parameter[float]",
  "class TSEquatorialPortDuctBuilder(Builder):\n    \"\"\"Thermal shield upper port duct builder\"\"\"\n\n    params: TSEquatorialPortDuctBuilderParams\n    param_cls = TSEquatorialPortDuctBuilderParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, ConfigParams, None],\n        cryostat_xz: BluemiraWire,\n    ):\n        super().__init__(params, None)\n        # Put the end of the equatorial port half-way between cryostat ts and\n        # cryostat\n        self.x_max = cryostat_xz.bounding_box.x_max + 0.5 * self.params.g_cr_ts.value\n\n    def build(self) -> Component:\n        \"\"\"Build equatorial port\"\"\"\n        offset = (\n            self.params.tk_vv_single_wall.value\n            + self.params.g_vv_ts.value\n            + self.params.tk_ts.value\n        )\n        y_val = 0.5 * self.params.ep_width.value + offset\n        z_ref = self.params.ep_z_position.value\n        z_val = 0.5 * self.params.ep_height.value + offset\n        yz_face = make_equatorial_port_yz_face(\n            self.x_max,\n            -y_val,\n            y_val,\n            z_ref - z_val,\n            z_ref + z_val,\n            self.params.tk_ts.value,\n        )\n\n        return self.component_tree(None, None, self.build_xyz(yz_face))\n\n    def build_xyz(self, yz_face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"Build equatorial port xyz\"\"\"\n        yz_voidface = BluemiraFace(yz_face.boundary[1])\n        degree = 180 / self.params.n_TF.value\n        vec = (self.params.R_0.value - self.x_max, 0, 0)\n        port = extrude_shape(yz_face, vec)\n        port.rotate(degree=degree)\n        comp = PhysicalComponent(self.name, port)\n\n        void = extrude_shape(yz_voidface, vec)\n        void.rotate(degree=degree)\n        void = PhysicalComponent(self.name + \" voidspace\", void, material=Void(\"vacuum\"))\n\n        apply_component_display_options(comp, BLUE_PALETTE[\"VV\"][0])\n        apply_component_display_options(void, color=(0, 0, 0))\n        return [comp, void]",
  "class VVUpperPortDuctBuilderParams(ParameterFrame):\n    \"\"\"Vacuum vessel upper port duct builder Parameter Frame\"\"\"\n\n    n_TF: Parameter[int]\n    tf_wp_depth: Parameter[float]\n    g_ts_tf: Parameter[float]\n    tk_ts: Parameter[float]\n    g_vv_ts: Parameter[float]\n    g_cr_ts: Parameter[float]\n    tk_vv_double_wall: Parameter[float]\n    tk_vv_single_wall: Parameter[float]",
  "class VVUpperPortDuctBuilder(Builder):\n    \"\"\"Vacuum vessel upper port duct builder\"\"\"\n\n    params: VVUpperPortDuctBuilderParams\n    param_cls = VVUpperPortDuctBuilderParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, ConfigParams, None],\n        port_koz: BluemiraFace,\n        cryostat_ts_xz: BluemiraWire,\n    ):\n        super().__init__(params, None)\n        koz_offset = self.params.tk_ts.value + self.params.g_vv_ts.value\n        self.x_min = port_koz.bounding_box.x_min + koz_offset\n        self.x_max = port_koz.bounding_box.x_max - koz_offset\n        self.z_max = cryostat_ts_xz.bounding_box.z_max + 0.5 * self.params.g_cr_ts.value\n\n        if (\n            self.params.tk_vv_double_wall.value <= 0\n            or self.params.tk_vv_single_wall.value <= 0\n        ):\n            raise ValueError(\"Port wall thickness must be > 0\")\n\n        self.y_offset = (\n            self.params.tf_wp_depth.value\n            + self.params.g_ts_tf.value\n            + self.params.tk_ts.value\n            + self.params.g_vv_ts.value\n        )\n\n    def build(self) -> Component:\n        \"\"\"Build upper port\"\"\"\n        xy_face = make_upper_port_xy_face(\n            self.params.n_TF.value,\n            self.x_min,\n            self.x_max,\n            self.params.tk_vv_double_wall.value,\n            self.params.tk_vv_single_wall.value,\n            self.y_offset,\n        )\n\n        return self.component_tree(\n            None,\n            self.build_xy(xy_face),\n            self.build_xyz(xy_face),\n        )\n\n    def build_xyz(self, xy_face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"Build upper port xyz\"\"\"\n        xy_voidface = BluemiraFace(xy_face.boundary[1])\n        xy_outface = BluemiraFace(xy_face.boundary[0])\n        port = extrude_shape(xy_face, (0, 0, self.z_max))\n        # Add start-cap for future boolean fragmentation help\n        cap = extrude_shape(xy_outface, vec=(0, 0, 0.1))\n        port = boolean_fuse([port, cap])\n\n        comp = PhysicalComponent(self.name, port)\n        apply_component_display_options(comp, BLUE_PALETTE[\"VV\"][0])\n        void = PhysicalComponent(\n            self.name + \" voidspace\",\n            extrude_shape(xy_voidface, (0, 0, self.z_max)),\n            material=Void(\"vacuum\"),\n        )\n        apply_component_display_options(void, color=(0, 0, 0))\n        return [comp, void]\n\n    def build_xy(self, xy_face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"Build upper port xy face\"\"\"\n        xy_voidface = BluemiraFace(xy_face.boundary[1])\n        comp = PhysicalComponent(self.name, xy_face)\n        apply_component_display_options(comp, BLUE_PALETTE[\"VV\"][0])\n        void = PhysicalComponent(\n            self.name + \" voidspace\", xy_voidface, material=Void(\"vacuum\")\n        )\n        apply_component_display_options(void, color=(0, 0, 0))\n        return [comp, void]",
  "class VVEquatorialPortDuctBuilderParams(ParameterFrame):\n    \"\"\"Vacuum vessel equatorial port duct builder Parameter Frame\"\"\"\n\n    R_0: Parameter[float]\n    n_TF: Parameter[int]\n    g_cr_ts: Parameter[float]\n    ep_z_position: Parameter[float]\n    ep_width: Parameter[float]\n    ep_height: Parameter[float]\n    tk_vv_single_wall: Parameter[float]",
  "class VVEquatorialPortDuctBuilder(Builder):\n    \"\"\"Vacuum vessel upper port duct builder\"\"\"\n\n    params: VVEquatorialPortDuctBuilderParams\n    param_cls = VVEquatorialPortDuctBuilderParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, ConfigParams, None],\n        cryostat_xz: BluemiraWire,\n    ):\n        super().__init__(params, None)\n        # Put the end of the equatorial port half-way between cryostat ts and\n        # cryostat\n        self.x_max = cryostat_xz.bounding_box.x_max + 0.5 * self.params.g_cr_ts.value\n\n    def build(self) -> Component:\n        \"\"\"Build equatorial port\"\"\"\n        y_val = 0.5 * self.params.ep_width.value\n        z_ref = self.params.ep_z_position.value\n        z_val = 0.5 * self.params.ep_height.value\n        yz_face = make_equatorial_port_yz_face(\n            self.x_max,\n            -y_val,\n            y_val,\n            z_ref - z_val,\n            z_ref + z_val,\n            self.params.tk_vv_single_wall.value,\n        )\n\n        return self.component_tree(\n            None,\n            None,\n            self.build_xyz(yz_face),\n        )\n\n    def build_xyz(self, yz_face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"Build equatorial port xyz\"\"\"\n        yz_voidface = BluemiraFace(yz_face.boundary[1])\n        degree = 180 / self.params.n_TF.value\n        vec = (self.params.R_0.value - self.x_max, 0, 0)\n        port = extrude_shape(yz_face, vec)\n        port.rotate(degree=degree)\n        comp = PhysicalComponent(self.name, port)\n\n        void = extrude_shape(yz_voidface, vec)\n        void.rotate(degree=degree)\n        void = PhysicalComponent(self.name + \" voidspace\", void, material=Void(\"vacuum\"))\n\n        apply_component_display_options(comp, BLUE_PALETTE[\"VV\"][0])\n        apply_component_display_options(void, color=(0, 0, 0))\n        return [comp, void]",
  "def make_upper_port_xy_face(\n    n_TF: int,\n    x_min: float,\n    x_max: float,\n    wall_end_tk: float,\n    wall_side_tk: float,\n    y_offset: float,\n) -> BluemiraFace:\n    \"\"\"\n    Creates a xy cross section of the upper port\n\n    translates the port koz to the origin,\n    builds the port at the origin and moves it back\n\n    Parameters\n    ----------\n    n_TF:\n        Number of TF coils\n    x_min:\n        Inner radius of the port keep-out zone\n    x_max:\n        Outer radius of the port keep-out zone\n    wall_end_tk:\n        Port wall end thickness\n    wall_size_tk:\n        Port wall side thickness\n    y_offset:\n        Offset value from the x-z plane at which to start building the port\n        (excluding port side wall thickness)\n\n    Returns\n    -------\n    xy_face:\n        x-y face of the upper port\n\n    Notes\n    -----\n    the port koz is slightly trimmed to allow for square ends to the port\n    \"\"\"\n    half_beta = np.pi / n_TF\n    cos_hb = np.cos(half_beta)\n    tan_hb = np.tan(half_beta)\n\n    y_tf_out = y_offset / cos_hb\n    y_tf_in = y_tf_out + wall_side_tk / cos_hb\n\n    x1 = x_min\n\n    # This is the correct way to retrieve the outer radius of the port, accounting\n    # for the TF thickness\n    # It's just the intersection of a line and a circle in the positive quadrant.\n    a1 = 1 + tan_hb**2\n    b1 = -2 * y_tf_out * tan_hb\n    c1 = y_tf_out**2 - x_max**2\n    discriminant = b1**2 - 4 * a1 * c1\n    x4 = 0.5 * (-b1 + np.sqrt(discriminant)) / a1\n\n    x2, x3 = x1 + wall_end_tk, x4 - wall_end_tk\n\n    if x2 >= x3:\n        raise BuilderError(\"Port dimensions too small\")\n\n    y1 = x1 * tan_hb - y_tf_out\n\n    if y1 < 0:\n        # Triangular outer port wall\n        y1 = 0\n        x1 = y_tf_out / tan_hb\n        x2 = x1 + wall_end_tk\n\n    y2, y3 = x2 * tan_hb - y_tf_in, x3 * tan_hb - y_tf_in\n\n    if y3 <= 0:\n        raise BuilderError(\"Port dimensions too small\")\n\n    if y2 < 0:\n        # Triangular inner port wall\n        y2 = 0\n        c = y3 - tan_hb * x3\n        x2 = -c / tan_hb\n        x1 = x2 - wall_end_tk\n\n    y1, y4 = x1 * tan_hb - y_tf_out, x4 * tan_hb - y_tf_out\n\n    inner_wire = make_polygon(\n        {\"x\": [x2, x3, x3, x2], \"y\": [-y2, -y3, y3, y2]}, closed=True\n    )\n    outer_wire = make_polygon(\n        {\"x\": [x1, x4, x4, x1], \"y\": [-y1, -y4, y4, y1]}, closed=True\n    )\n\n    xy_face = BluemiraFace((outer_wire, inner_wire))\n    xy_face.rotate(degree=np.rad2deg(half_beta))\n\n    return xy_face",
  "def make_equatorial_port_yz_face(\n    x_ref: float,\n    y_min: float,\n    y_max: float,\n    z_min: float,\n    z_max: float,\n    wall_side_tk: float,\n) -> BluemiraFace:\n    \"\"\"\n    Creates a yz cross section of the equatorial port\n\n    builds the port at the origin\n\n    Parameters\n    ----------\n    x_ref:\n        Reference x coordinate of the y-z plane\n    y_min:\n        Minimum y coordinate of the port void\n    y_max:\n        Maximum y coordinate of the port void\n    z_min:\n        Minimum z coordinate of the port void\n    z_max:\n        Maximum z coordinate of the port void\n    wall_side_tk:\n        Thickness of the port walss\n\n    Returns\n    -------\n    yz_face:\n        y-z face of the equatorial port\n    \"\"\"\n    y = np.array([y_min, y_min, y_max, y_max])\n    z = np.array([z_min, z_max, z_max, z_min])\n    inner = make_polygon({\"x\": x_ref, \"y\": y, \"z\": z}, closed=True)\n    outer = offset_wire(inner, wall_side_tk, open_wire=False)\n    return BluemiraFace([outer, inner])",
  "def pipe_pipe_join(\n    target_shape: BluemiraSolid,\n    target_void: BluemiraSolid,\n    tool_shape: BluemiraSolid,\n    tool_void: BluemiraSolid,\n) -> List[BluemiraSolid]:\n    \"\"\"\n    Join two hollow, intersecting pipes.\n\n    Parameters\n    ----------\n    target_shape:\n        Solid of the target shape\n    target_void:\n        Solid of the target void\n    tool_shape:\n        Solid of the tool shape\n    tool_void:\n        Solid of the tool void\n\n    Returns\n    -------\n    shape:\n        Solid of the joined pipe-pipe shape\n    void:\n        Solid of the joined pipe-pipe void\n\n    Notes\n    -----\n    This approach is more brittle than a classic fuse, fuse, cut operation, but is\n    substantially faster. If the parts do not fully intersect, undesired results\n    are to be expected.\n    \"\"\"\n    _, (target_fragments, tool_fragments) = boolean_fragments([target_shape, tool_shape])\n\n    # Keep the largest piece of the target by volume (opinionated)\n    # This is in case its COG is inside the tool void\n    target_fragments.sort(key=lambda solid: -solid.volume)\n    new_shape_pieces = [target_fragments[0]]\n    target_fragments = target_fragments[1:]\n    for targ_frag in target_fragments:\n        # Find the target piece(s) that are inside the tool\n        com = targ_frag.center_of_mass\n        if not point_inside_shape(com, tool_void):\n            new_shape_pieces.append(targ_frag)\n\n    for tool_frag in tool_fragments:\n        # Find the tool piece(s) that are inside the target\n        com = tool_frag.center_of_mass\n        if not point_inside_shape(com, target_void):\n            new_shape_pieces.append(tool_frag)\n        else:\n            for targ_frag in target_fragments:\n                # Find the union piece(s)\n                if tool_frag.is_same(targ_frag):\n                    new_shape_pieces.append(tool_frag)\n\n    return new_shape_pieces",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, ConfigParams, None],\n        port_koz: BluemiraFace,\n        cryostat_ts_xz: BluemiraWire,\n    ):\n        super().__init__(params, None)\n        self.x_min = port_koz.bounding_box.x_min\n        self.x_max = port_koz.bounding_box.x_max\n        self.z_max = cryostat_ts_xz.bounding_box.z_max + 0.5 * self.params.g_cr_ts.value\n\n        if self.params.tk_ts.value <= 0:\n            raise ValueError(\"Port wall thickness must be > 0\")\n\n        self.y_offset = self.params.tf_wp_depth.value + self.params.g_ts_tf.value",
  "def build(self) -> Component:\n        \"\"\"Build upper port\"\"\"\n        xy_face = make_upper_port_xy_face(\n            self.params.n_TF.value,\n            self.x_min,\n            self.x_max,\n            self.params.tk_ts.value,\n            self.params.tk_ts.value,\n            self.y_offset,\n        )\n\n        return self.component_tree(\n            None, [self.build_xy(xy_face)], self.build_xyz(xy_face)\n        )",
  "def build_xyz(self, xy_face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"Build upper port xyz\"\"\"\n        xy_voidface = BluemiraFace(xy_face.boundary[1])\n        xy_outface = BluemiraFace(xy_face.boundary[0])\n        port = extrude_shape(xy_face, (0, 0, self.z_max))\n        # Add start-cap for future boolean fragmentation help\n        cap = extrude_shape(xy_outface, vec=(0, 0, 0.1))\n        port = boolean_fuse([port, cap])\n        comp = PhysicalComponent(self.name, port)\n        apply_component_display_options(comp, BLUE_PALETTE[\"TS\"][0])\n        void = PhysicalComponent(\n            self.name + \" voidspace\",\n            extrude_shape(xy_voidface, (0, 0, self.z_max)),\n            material=Void(\"vacuum\"),\n        )\n        apply_component_display_options(void, color=(0, 0, 0))\n        return [comp, void]",
  "def build_xy(self, face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"Build upport port xy face\"\"\"\n        comp = PhysicalComponent(self.name, face)\n        apply_component_display_options(comp, BLUE_PALETTE[\"TS\"][0])\n        return comp",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, ConfigParams, None],\n        cryostat_xz: BluemiraWire,\n    ):\n        super().__init__(params, None)\n        # Put the end of the equatorial port half-way between cryostat ts and\n        # cryostat\n        self.x_max = cryostat_xz.bounding_box.x_max + 0.5 * self.params.g_cr_ts.value",
  "def build(self) -> Component:\n        \"\"\"Build equatorial port\"\"\"\n        offset = (\n            self.params.tk_vv_single_wall.value\n            + self.params.g_vv_ts.value\n            + self.params.tk_ts.value\n        )\n        y_val = 0.5 * self.params.ep_width.value + offset\n        z_ref = self.params.ep_z_position.value\n        z_val = 0.5 * self.params.ep_height.value + offset\n        yz_face = make_equatorial_port_yz_face(\n            self.x_max,\n            -y_val,\n            y_val,\n            z_ref - z_val,\n            z_ref + z_val,\n            self.params.tk_ts.value,\n        )\n\n        return self.component_tree(None, None, self.build_xyz(yz_face))",
  "def build_xyz(self, yz_face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"Build equatorial port xyz\"\"\"\n        yz_voidface = BluemiraFace(yz_face.boundary[1])\n        degree = 180 / self.params.n_TF.value\n        vec = (self.params.R_0.value - self.x_max, 0, 0)\n        port = extrude_shape(yz_face, vec)\n        port.rotate(degree=degree)\n        comp = PhysicalComponent(self.name, port)\n\n        void = extrude_shape(yz_voidface, vec)\n        void.rotate(degree=degree)\n        void = PhysicalComponent(self.name + \" voidspace\", void, material=Void(\"vacuum\"))\n\n        apply_component_display_options(comp, BLUE_PALETTE[\"VV\"][0])\n        apply_component_display_options(void, color=(0, 0, 0))\n        return [comp, void]",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, ConfigParams, None],\n        port_koz: BluemiraFace,\n        cryostat_ts_xz: BluemiraWire,\n    ):\n        super().__init__(params, None)\n        koz_offset = self.params.tk_ts.value + self.params.g_vv_ts.value\n        self.x_min = port_koz.bounding_box.x_min + koz_offset\n        self.x_max = port_koz.bounding_box.x_max - koz_offset\n        self.z_max = cryostat_ts_xz.bounding_box.z_max + 0.5 * self.params.g_cr_ts.value\n\n        if (\n            self.params.tk_vv_double_wall.value <= 0\n            or self.params.tk_vv_single_wall.value <= 0\n        ):\n            raise ValueError(\"Port wall thickness must be > 0\")\n\n        self.y_offset = (\n            self.params.tf_wp_depth.value\n            + self.params.g_ts_tf.value\n            + self.params.tk_ts.value\n            + self.params.g_vv_ts.value\n        )",
  "def build(self) -> Component:\n        \"\"\"Build upper port\"\"\"\n        xy_face = make_upper_port_xy_face(\n            self.params.n_TF.value,\n            self.x_min,\n            self.x_max,\n            self.params.tk_vv_double_wall.value,\n            self.params.tk_vv_single_wall.value,\n            self.y_offset,\n        )\n\n        return self.component_tree(\n            None,\n            self.build_xy(xy_face),\n            self.build_xyz(xy_face),\n        )",
  "def build_xyz(self, xy_face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"Build upper port xyz\"\"\"\n        xy_voidface = BluemiraFace(xy_face.boundary[1])\n        xy_outface = BluemiraFace(xy_face.boundary[0])\n        port = extrude_shape(xy_face, (0, 0, self.z_max))\n        # Add start-cap for future boolean fragmentation help\n        cap = extrude_shape(xy_outface, vec=(0, 0, 0.1))\n        port = boolean_fuse([port, cap])\n\n        comp = PhysicalComponent(self.name, port)\n        apply_component_display_options(comp, BLUE_PALETTE[\"VV\"][0])\n        void = PhysicalComponent(\n            self.name + \" voidspace\",\n            extrude_shape(xy_voidface, (0, 0, self.z_max)),\n            material=Void(\"vacuum\"),\n        )\n        apply_component_display_options(void, color=(0, 0, 0))\n        return [comp, void]",
  "def build_xy(self, xy_face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"Build upper port xy face\"\"\"\n        xy_voidface = BluemiraFace(xy_face.boundary[1])\n        comp = PhysicalComponent(self.name, xy_face)\n        apply_component_display_options(comp, BLUE_PALETTE[\"VV\"][0])\n        void = PhysicalComponent(\n            self.name + \" voidspace\", xy_voidface, material=Void(\"vacuum\")\n        )\n        apply_component_display_options(void, color=(0, 0, 0))\n        return [comp, void]",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, ConfigParams, None],\n        cryostat_xz: BluemiraWire,\n    ):\n        super().__init__(params, None)\n        # Put the end of the equatorial port half-way between cryostat ts and\n        # cryostat\n        self.x_max = cryostat_xz.bounding_box.x_max + 0.5 * self.params.g_cr_ts.value",
  "def build(self) -> Component:\n        \"\"\"Build equatorial port\"\"\"\n        y_val = 0.5 * self.params.ep_width.value\n        z_ref = self.params.ep_z_position.value\n        z_val = 0.5 * self.params.ep_height.value\n        yz_face = make_equatorial_port_yz_face(\n            self.x_max,\n            -y_val,\n            y_val,\n            z_ref - z_val,\n            z_ref + z_val,\n            self.params.tk_vv_single_wall.value,\n        )\n\n        return self.component_tree(\n            None,\n            None,\n            self.build_xyz(yz_face),\n        )",
  "def build_xyz(self, yz_face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"Build equatorial port xyz\"\"\"\n        yz_voidface = BluemiraFace(yz_face.boundary[1])\n        degree = 180 / self.params.n_TF.value\n        vec = (self.params.R_0.value - self.x_max, 0, 0)\n        port = extrude_shape(yz_face, vec)\n        port.rotate(degree=degree)\n        comp = PhysicalComponent(self.name, port)\n\n        void = extrude_shape(yz_voidface, vec)\n        void.rotate(degree=degree)\n        void = PhysicalComponent(self.name + \" voidspace\", void, material=Void(\"vacuum\"))\n\n        apply_component_display_options(comp, BLUE_PALETTE[\"VV\"][0])\n        apply_component_display_options(void, color=(0, 0, 0))\n        return [comp, void]",
  "def make_castellated_plug(\n    face: BluemiraFace,\n    vec: Tuple[float, float, float],\n    length: float,\n    offsets: Union[float, Iterable],\n    distances: Optional[Iterable] = None,\n    n_castellations: Optional[int] = None,\n) -> BluemiraSolid:\n    \"\"\"\n    Make a castellated port plug.\n\n    Parameters\n    ----------\n    face:\n        starting profile to be castellated\n    vec:\n        unit vector along which to extrude\n    length:\n        total length of castellated BluemiraSolid in vec direction\n    offsets:\n        castellations offset(s) for each position\n    distances:\n        (optional) parameter for manually spaced castellations\n    n_castellations:\n        (optional) parameter for equally spaced castellations\n\n    Returns\n    -------\n    BluemiraSolid of a castellated port plug\n    \"\"\"\n    # Normalise vec\n    vec = np.array(vec) / np.linalg.norm(vec)\n\n    # Check/Set-up distances iterable\n    if not ((n_castellations is None) or (n_castellations == 0)):\n        interval = length / (n_castellations + 1)\n        dist_iter = [interval * i for i in range(1, n_castellations + 1)]\n    else:\n        if distances is not None:\n            dist_iter = distances\n        else:\n            raise ValueError(\"Both distance and n_castellations parameters are None\")\n\n    # Check/Set-up offsets iterable\n    if type(offsets) is float:\n        off_iter = [offsets] * len(dist_iter)\n    else:\n        if len(offsets) == len(dist_iter):\n            off_iter = offsets\n        else:\n            raise ValueError(\"Length of offsets doesn't match distances/n_cast\")\n\n    parameter_array = list(zip(dist_iter, off_iter))\n    parameter_array.append((length, 0.0))\n\n    base = face\n    sections = []\n    _prev_dist = 0\n    for dist, off in parameter_array:\n        ext_vec = vec * (dist - _prev_dist)\n        sections.append(extrude_shape(base, ext_vec))\n        base.translate(ext_vec)\n        base = BluemiraFace(offset_wire(BluemiraWire(base.wires), off))\n        _prev_dist = dist\n\n    return boolean_fuse(sections)",
  "def make_onion_layer_plug_void(\n    outer_profiles: Iterable[BluemiraWire],\n    target_profile: BluemiraFace,\n    thickness: float,\n    offset: float,\n    gap: float,\n    tk_castellation: float,\n    n_castellations: int,\n    n_TF: int,\n) -> Tuple[List[BluemiraSolid], List[BluemiraSolid]]:\n    \"\"\"\n    Make geometries for castellated port plugs and voids for all ports.\n\n    Parameters\n    ----------\n    outer_profiles:\n        Outer profiles of the inner port plug imprint\n    target_profile:\n        Face onto which to project the port\n    thickness:\n        Thickness of the part through which the port opening must go through\n    offset:\n        Offset value from the outer profile\n    tk_castellation:\n        Thickness of the castellation offsets\n    n_castellations:\n        Number of castellations in the port plugs\n    n_TF:\n        Number of TF coils\n\n    Returns\n    -------\n    plugs:\n        BluemiraSolids of the port plugs\n    voids:\n        BluemiraSolids of the voids to cut away from the target\n    \"\"\"\n    degree = 180 / n_TF\n    x_max = target_profile.bounding_box.x_max\n    z_max = target_profile.bounding_box.z_max\n    plugs = []\n    voids = []\n    for wire in outer_profiles:\n        bb = wire.bounding_box\n        dx = abs(bb.x_max - x_max)\n        dz = abs(bb.z_max - z_max)\n        if dx < dz:\n            # Horizontal connection\n            dy = 0.5 * abs(bb.y_max - bb.y_min) + offset\n            radius = np.sqrt((x_max - thickness) ** 2 - dy**2)\n            length = x_max - radius\n            vector = (radius - bb.x_max, 0, 0)\n\n        else:\n            # Vertical connection\n            length = thickness\n            vector = (0, 0, dz - thickness)\n\n        wire.translate(vector)\n        void_wire = offset_wire(wire, gap)\n\n        plug = make_castellated_plug(\n            BluemiraFace(wire),\n            vector,\n            length,\n            offsets=tk_castellation,\n            n_castellations=n_castellations,\n        )\n        void = make_castellated_plug(\n            BluemiraFace(void_wire),\n            vector,\n            length,\n            offsets=tk_castellation,\n            n_castellations=n_castellations,\n        )\n\n        plug.rotate(degree=degree)\n        void.rotate(degree=degree)\n        plugs.append(plug)\n        voids.append(void)\n    return plugs, voids",
  "class CryostatPortPlugBuilderParams(ParameterFrame):\n    \"\"\"\n    Cryostat port plug builder parameters\n    \"\"\"\n\n    # Global\n    n_TF: Parameter[int]\n    tk_cr_vv: Parameter[float]\n    g_cr_ts: Parameter[float]\n\n    # Local\n    g_plug: Parameter[float]\n    tk_castellation: Parameter[float]\n    n_plug_castellations: Parameter[int]",
  "class CryostatPortPlugBuilder(Builder):\n    \"\"\"\n    Cryostat port plug builder.\n    \"\"\"\n\n    param_cls: Type[CryostatPortPlugBuilderParams] = CryostatPortPlugBuilderParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, CryostatPortPlugBuilderParams],\n        build_config: Optional[Dict],\n        outer_profiles: Iterable[BluemiraWire],\n        cryostat_xz_boundary: BluemiraFace,\n    ):\n        super().__init__(params, build_config)\n        self.outer_profiles = outer_profiles\n        self.cryostat_xz_boundary = cryostat_xz_boundary\n\n    def build(self) -> Component:\n        \"\"\"Build the Cryostat port plugs\"\"\"\n        return self.component_tree(\n            xz=None,\n            xy=None,\n            xyz=self.build_xyz(),\n        )\n\n    def build_xyz(self) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the 3D representation of the Cryostat port plugs\n        \"\"\"\n        plugs, voids = make_onion_layer_plug_void(\n            self.outer_profiles,\n            self.cryostat_xz_boundary,\n            self.params.tk_cr_vv.value,\n            self.params.g_cr_ts.value,\n            self.params.g_plug.value,\n            self.params.tk_castellation.value,\n            self.params.n_plug_castellations.value,\n            self.params.n_TF.value,\n        )\n\n        plug_comps, void_comps = [], []\n        for i, (plug, void) in enumerate(zip(plugs, voids)):\n            plug = PhysicalComponent(f\"{self.name} {i}\", plug)\n            void = PhysicalComponent(\n                f\"{self.name} {i} voidspace\", void, material=Void(\"air\")\n            )\n            apply_component_display_options(plug, BLUE_PALETTE[\"CR\"][1])\n            apply_component_display_options(void, (0, 0, 0))\n            plug_comps.append(plug)\n            void_comps.append(void)\n\n        return plug_comps + void_comps",
  "class RadiationPortPlugBuilderParams(ParameterFrame):\n    \"\"\"\n    Radiation shield port plug builder parameters\n    \"\"\"\n\n    # Global\n    n_TF: Parameter[int]\n    tk_rs: Parameter[float]\n    g_cr_rs: Parameter[float]\n\n    # Local\n    g_plug: Parameter[float]\n    tk_castellation: Parameter[float]\n    n_plug_castellations: Parameter[int]",
  "class RadiationPortPlugBuilder(Builder):\n    \"\"\"\n    Radiation shield port plug builder.\n    \"\"\"\n\n    param_cls: Type[RadiationPortPlugBuilderParams] = RadiationPortPlugBuilderParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, RadiationPortPlugBuilderParams],\n        build_config: Optional[Dict],\n        outer_profiles: Iterable[BluemiraWire],\n        radiation_xz_boundary: BluemiraFace,\n    ):\n        super().__init__(params, build_config)\n        self.outer_profiles = outer_profiles\n        self.radiation_xz_boundary = radiation_xz_boundary\n\n    def build(self) -> Component:\n        \"\"\"Build the radiation shield port plugs\"\"\"\n        return self.component_tree(\n            xz=None,\n            xy=None,\n            xyz=self.build_xyz(),\n        )\n\n    def build_xyz(self) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the 3D representation of the radiation shield port plugs\n        \"\"\"\n        plugs, voids = make_onion_layer_plug_void(\n            self.outer_profiles,\n            self.radiation_xz_boundary,\n            self.params.tk_rs.value,\n            self.params.g_cr_rs.value,\n            self.params.g_plug.value,\n            self.params.tk_castellation.value,\n            self.params.n_plug_castellations.value,\n            self.params.n_TF.value,\n        )\n        plug_comps, void_comps = [], []\n        for i, (plug, void) in enumerate(zip(plugs, voids)):\n            plug = PhysicalComponent(f\"{self.name} {i}\", plug)\n            void = PhysicalComponent(\n                f\"{self.name} {i} voidspace\", void, material=Void(\"air\")\n            )\n            apply_component_display_options(plug, BLUE_PALETTE[\"RS\"][1])\n            apply_component_display_options(void, (0, 0, 0))\n            plug_comps.append(plug)\n            void_comps.append(void)\n\n        return plug_comps + void_comps",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, CryostatPortPlugBuilderParams],\n        build_config: Optional[Dict],\n        outer_profiles: Iterable[BluemiraWire],\n        cryostat_xz_boundary: BluemiraFace,\n    ):\n        super().__init__(params, build_config)\n        self.outer_profiles = outer_profiles\n        self.cryostat_xz_boundary = cryostat_xz_boundary",
  "def build(self) -> Component:\n        \"\"\"Build the Cryostat port plugs\"\"\"\n        return self.component_tree(\n            xz=None,\n            xy=None,\n            xyz=self.build_xyz(),\n        )",
  "def build_xyz(self) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the 3D representation of the Cryostat port plugs\n        \"\"\"\n        plugs, voids = make_onion_layer_plug_void(\n            self.outer_profiles,\n            self.cryostat_xz_boundary,\n            self.params.tk_cr_vv.value,\n            self.params.g_cr_ts.value,\n            self.params.g_plug.value,\n            self.params.tk_castellation.value,\n            self.params.n_plug_castellations.value,\n            self.params.n_TF.value,\n        )\n\n        plug_comps, void_comps = [], []\n        for i, (plug, void) in enumerate(zip(plugs, voids)):\n            plug = PhysicalComponent(f\"{self.name} {i}\", plug)\n            void = PhysicalComponent(\n                f\"{self.name} {i} voidspace\", void, material=Void(\"air\")\n            )\n            apply_component_display_options(plug, BLUE_PALETTE[\"CR\"][1])\n            apply_component_display_options(void, (0, 0, 0))\n            plug_comps.append(plug)\n            void_comps.append(void)\n\n        return plug_comps + void_comps",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, RadiationPortPlugBuilderParams],\n        build_config: Optional[Dict],\n        outer_profiles: Iterable[BluemiraWire],\n        radiation_xz_boundary: BluemiraFace,\n    ):\n        super().__init__(params, build_config)\n        self.outer_profiles = outer_profiles\n        self.radiation_xz_boundary = radiation_xz_boundary",
  "def build(self) -> Component:\n        \"\"\"Build the radiation shield port plugs\"\"\"\n        return self.component_tree(\n            xz=None,\n            xy=None,\n            xyz=self.build_xyz(),\n        )",
  "def build_xyz(self) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the 3D representation of the radiation shield port plugs\n        \"\"\"\n        plugs, voids = make_onion_layer_plug_void(\n            self.outer_profiles,\n            self.radiation_xz_boundary,\n            self.params.tk_rs.value,\n            self.params.g_cr_rs.value,\n            self.params.g_plug.value,\n            self.params.tk_castellation.value,\n            self.params.n_plug_castellations.value,\n            self.params.n_TF.value,\n        )\n        plug_comps, void_comps = [], []\n        for i, (plug, void) in enumerate(zip(plugs, voids)):\n            plug = PhysicalComponent(f\"{self.name} {i}\", plug)\n            void = PhysicalComponent(\n                f\"{self.name} {i} voidspace\", void, material=Void(\"air\")\n            )\n            apply_component_display_options(plug, BLUE_PALETTE[\"RS\"][1])\n            apply_component_display_options(void, (0, 0, 0))\n            plug_comps.append(plug)\n            void_comps.append(void)\n\n        return plug_comps + void_comps",
  "class EquatorialPort(ComponentManager):\n    \"\"\"\n    Wrapper around a Equatorial Port component tree\n    \"\"\"\n\n    def xz_boundary(self) -> BluemiraWire:\n        \"\"\"Returns a wire defining the x-z boundary of the Equatorial Port\"\"\"\n        return (\n            self.component.get_component(\"xz\")\n            .get_component(EquatorialPortDuctBuilder.NAME)\n            .shape.boundary[0]\n        )",
  "class EquatorialPortKOZDesignerParams(ParameterFrame):\n    \"\"\"\n    Equatorial Port Designer parameters\n    \"\"\"\n\n    R_0: Parameter[float]\n    \"\"\"Gap between VV and TS\"\"\"\n    g_vv_ts: Parameter[float]\n    \"\"\"TS thickness\"\"\"\n    tk_ts: Parameter[float]\n    \"\"\"Gap between TS and TF (used for short gap to PF)\"\"\"\n    g_ts_tf: Parameter[float]\n    \"\"\"Gap between PF coil and support\"\"\"\n    pf_s_g: Parameter[float]\n    \"\"\"PF coil support thickness\"\"\"\n    pf_s_tk_plate: Parameter[float]\n    tk_vv_single_wall: Parameter[float]\n\n    ep_z_position: Parameter[float]\n    ep_height: Parameter[float]",
  "class EquatorialPortKOZDesigner(Designer):\n    \"\"\"\n    Equatorial Port Keep-out Zone Designer\n    - Builds a rectangular horizontal keep-out zone\n    offset out from the equatorial port x-z profile\n    \"\"\"\n\n    param_cls: Type[EquatorialPortKOZDesignerParams] = EquatorialPortKOZDesignerParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, EquatorialPortKOZDesignerParams],\n        build_config: Union[Dict, None],\n        x_ob: float,\n    ):\n        \"\"\"\n        Parameters:\n        -----------\n        params:\n            Parameters for the equatorial port designer\n        build_config:\n            Build config for the equatorial port designer\n        x_ob:\n            out-board x-position of the KOZ\n        \"\"\"\n        super().__init__(params, build_config)\n        self.koz_offset = (\n            self.params.tk_vv_single_wall.value\n            + self.params.g_vv_ts.value\n            + self.params.tk_ts.value\n            + self.params.g_ts_tf.value\n            + self.params.pf_s_tk_plate.value\n            + self.params.pf_s_g.value\n        )\n        self.x_ib = self.params.R_0.value\n        self.x_ob = x_ob\n        self.z_pos = self.params.ep_z_position.value\n\n    def run(self) -> BluemiraWire:\n        \"\"\"\n        Design the xz keep-out zone profile of the equatorial port\n        \"\"\"\n        z_h = 0.5 * self.params.ep_height.value + self.koz_offset\n        z_o = self.z_pos\n\n        x = (self.x_ib, self.x_ob, self.x_ob, self.x_ib)\n        z = (z_o - z_h, z_o - z_h, z_o + z_h, z_o + z_h)\n\n        ep_boundary = BluemiraFace(\n            make_polygon({\"x\": x, \"y\": 0, \"z\": z}, closed=True),\n            label=\"equatorial_port_koz\",\n        )\n        return ep_boundary",
  "class EquatorialPortDuctBuilderParams(ParameterFrame):\n    \"\"\"\n    Castellation Builder parameters\n    \"\"\"\n\n    ep_height: Parameter[float]\n    cst_r_corner: Parameter[float]",
  "class EquatorialPortDuctBuilder(Builder):\n    \"\"\"\n    Equatorial Port Duct Builder\n    \"\"\"\n\n    NAME = \"Equatorial Port Duct\"\n    param_cls: Type[EquatorialPortDuctBuilderParams] = EquatorialPortDuctBuilderParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, EquatorialPortDuctBuilderParams],\n        build_config: Union[Dict, None],\n        outer_profile: BluemiraWire,\n        length: float,\n        equatorial_port_wall_thickness: float,\n    ):\n        super().__init__(params, build_config)\n        self.outer = outer_profile\n        self.length = length\n        self.offset = equatorial_port_wall_thickness\n\n    def build(self) -> Component:\n        \"\"\"Build the Equatorial Port\"\"\"\n        self.z_h = self.params.ep_height.value\n        self.r_rad = self.params.cst_r_corner.value\n        hole = offset_wire(self.outer, -self.offset)\n        self.profile = BluemiraFace([self.outer, hole])\n        self.port = extrude_shape(self.profile, (self.length, 0, 0))\n\n        return self.component_tree(\n            xz=[self.build_xz()],\n            xy=[self.build_xy()],\n            xyz=[self.build_xyz()],\n        )\n\n    def build_xz(self) -> PhysicalComponent:\n        \"\"\"\n        Build the xy representation of the Equatorial Port\n        \"\"\"\n        port = slice_shape(\n            extrude_shape(BluemiraFace(self.outer), (self.length, 0, 0)),\n            BluemiraPlane(axis=(0, 1, 0)),\n        )\n        body = PhysicalComponent(self.NAME, BluemiraFace(port))\n        apply_component_display_options(body, BLUE_PALETTE[\"VV\"][0])\n        return body\n\n    def build_xy(self) -> PhysicalComponent:\n        \"\"\"\n        Build the cross-sectional representation of the Equatorial Port\n        \"\"\"\n        body = PhysicalComponent(self.NAME, self.profile)\n        apply_component_display_options(body, BLUE_PALETTE[\"VV\"][0])\n        return body\n\n    def build_xyz(self) -> PhysicalComponent:\n        \"\"\"\n        Build the 3D representation of the Equatorial Port\n        \"\"\"\n        body = PhysicalComponent(self.NAME, self.port)\n        apply_component_display_options(body, BLUE_PALETTE[\"VV\"][0])\n        return body",
  "def xz_boundary(self) -> BluemiraWire:\n        \"\"\"Returns a wire defining the x-z boundary of the Equatorial Port\"\"\"\n        return (\n            self.component.get_component(\"xz\")\n            .get_component(EquatorialPortDuctBuilder.NAME)\n            .shape.boundary[0]\n        )",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, EquatorialPortKOZDesignerParams],\n        build_config: Union[Dict, None],\n        x_ob: float,\n    ):\n        \"\"\"\n        Parameters:\n        -----------\n        params:\n            Parameters for the equatorial port designer\n        build_config:\n            Build config for the equatorial port designer\n        x_ob:\n            out-board x-position of the KOZ\n        \"\"\"\n        super().__init__(params, build_config)\n        self.koz_offset = (\n            self.params.tk_vv_single_wall.value\n            + self.params.g_vv_ts.value\n            + self.params.tk_ts.value\n            + self.params.g_ts_tf.value\n            + self.params.pf_s_tk_plate.value\n            + self.params.pf_s_g.value\n        )\n        self.x_ib = self.params.R_0.value\n        self.x_ob = x_ob\n        self.z_pos = self.params.ep_z_position.value",
  "def run(self) -> BluemiraWire:\n        \"\"\"\n        Design the xz keep-out zone profile of the equatorial port\n        \"\"\"\n        z_h = 0.5 * self.params.ep_height.value + self.koz_offset\n        z_o = self.z_pos\n\n        x = (self.x_ib, self.x_ob, self.x_ob, self.x_ib)\n        z = (z_o - z_h, z_o - z_h, z_o + z_h, z_o + z_h)\n\n        ep_boundary = BluemiraFace(\n            make_polygon({\"x\": x, \"y\": 0, \"z\": z}, closed=True),\n            label=\"equatorial_port_koz\",\n        )\n        return ep_boundary",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, EquatorialPortDuctBuilderParams],\n        build_config: Union[Dict, None],\n        outer_profile: BluemiraWire,\n        length: float,\n        equatorial_port_wall_thickness: float,\n    ):\n        super().__init__(params, build_config)\n        self.outer = outer_profile\n        self.length = length\n        self.offset = equatorial_port_wall_thickness",
  "def build(self) -> Component:\n        \"\"\"Build the Equatorial Port\"\"\"\n        self.z_h = self.params.ep_height.value\n        self.r_rad = self.params.cst_r_corner.value\n        hole = offset_wire(self.outer, -self.offset)\n        self.profile = BluemiraFace([self.outer, hole])\n        self.port = extrude_shape(self.profile, (self.length, 0, 0))\n\n        return self.component_tree(\n            xz=[self.build_xz()],\n            xy=[self.build_xy()],\n            xyz=[self.build_xyz()],\n        )",
  "def build_xz(self) -> PhysicalComponent:\n        \"\"\"\n        Build the xy representation of the Equatorial Port\n        \"\"\"\n        port = slice_shape(\n            extrude_shape(BluemiraFace(self.outer), (self.length, 0, 0)),\n            BluemiraPlane(axis=(0, 1, 0)),\n        )\n        body = PhysicalComponent(self.NAME, BluemiraFace(port))\n        apply_component_display_options(body, BLUE_PALETTE[\"VV\"][0])\n        return body",
  "def build_xy(self) -> PhysicalComponent:\n        \"\"\"\n        Build the cross-sectional representation of the Equatorial Port\n        \"\"\"\n        body = PhysicalComponent(self.NAME, self.profile)\n        apply_component_display_options(body, BLUE_PALETTE[\"VV\"][0])\n        return body",
  "def build_xyz(self) -> PhysicalComponent:\n        \"\"\"\n        Build the 3D representation of the Equatorial Port\n        \"\"\"\n        body = PhysicalComponent(self.NAME, self.port)\n        apply_component_display_options(body, BLUE_PALETTE[\"VV\"][0])\n        return body",
  "class UpperPortOP(OptimisationProblem):\n    \"\"\"\n    Collection of functions to use to minimise the upper port size.\n\n    Parameters\n    ----------\n    bb:\n        The xz-silhouette of the breeding blanket [m].\n    c_rm:\n        The required remote maintenance clearance [m].\n    R_0:\n        The tokamak major radius [m].\n    tk_bb_ib:\n        Blanket inboard thickness [m].\n    tk_bb_ob:\n        Blanket outboard thickness [m].\n    bb_min_angle:\n        Minimum blanket module angle [degrees].\n    \"\"\"\n\n    def __init__(\n        self,\n        bb: BluemiraFace,\n        c_rm: float,\n        R_0: float,\n        tk_bb_ib: float,\n        tk_bb_ob: float,\n        bb_min_angle: float,\n    ):\n        self.bb = bb\n        self.c_rm = c_rm\n        self.R_0 = R_0\n        self.tk_bb_ib = tk_bb_ib\n        self.bb_min_angle = bb_min_angle\n        self.tk_bb_ob = tk_bb_ob\n        self.r_ib_min = self.bb.bounding_box.x_min\n        self.r_ob_max = self.bb.bounding_box.x_max\n        self.gradient = np.array([-1, 1, 0, 1], dtype=float)\n\n    def objective(self, x: np.ndarray) -> float:\n        \"\"\"The objective function of the optimisation.\"\"\"\n        return self.port_size(x)\n\n    def df_objective(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"The gradient of the objective function.\"\"\"\n        return self.df_port_size(x)\n\n    def ineq_constraints(self) -> List[ConstraintT]:\n        \"\"\"Inequality constraints for the problem.\"\"\"\n        return [\n            {\"f_constraint\": self.constrain_blanket_cut, \"tolerance\": np.full(3, 1e-6)}\n        ]\n\n    def bounds(self) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"The bounds for the optimisation parameters.\"\"\"\n        lower = [self.r_ib_min - self.c_rm, self.R_0, self.r_ib_min + self.tk_bb_ib, 0]\n        upper = [\n            self.R_0,\n            self.r_ob_max + self.c_rm,\n            self.r_ob_max - self.tk_bb_ob,\n            self.bb_min_angle,\n        ]\n        return np.array(lower), np.array(upper)\n\n    def port_size(self, x: np.ndarray) -> float:\n        \"\"\"Return the port size given parameterisation ``x``.\"\"\"\n        ri, ro, _, gamma = x\n        return ro - ri + gamma\n\n    def df_port_size(self, _: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Return the gradient of the port size.\n\n        Parameters\n        ----------\n        _:\n            The parameterisation of the port size. This is unused as the\n            gradient is constant.\n\n        Returns\n        -------\n        The gradient of the port size parameterisation, with shape (3,).\n        \"\"\"\n        return self.gradient\n\n    def constrain_blanket_cut(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Constrain the upper port size.\n\n        This enforces 3 constraints:\n\n        c1. The outboard blanket must fit through the port.\n        c2. The inboard blanket must squeeze past the other blanket\n            segment and out the port. Hence, this also enforces that\n            the inboard blanket fits through the port.\n        c3. There should be enough vertically accessible space on the\n            inboard blanket to connect pipes and a remote attachment\n            point.\n        \"\"\"\n        ri, ro, ci, gamma = x\n        co = self.get_outer_cut_point(ci, gamma)[0]\n        c1 = (self.r_ob_max - co + self.c_rm) - (ro - co)\n        c2 = (ci - self.r_ib_min) - (ro - ci + self.c_rm)\n        c3 = (ri + 0.5 * abs(ci - self.r_ib_min)) - ci\n        return np.array([c1, c2, c3])\n\n    def get_outer_cut_point(self, ci: float, gamma: float):\n        \"\"\"\n        Get the coordinate of the outer blanket cut point.\n\n        The outer cut point radius of the cutting plane with the\n        breeding blanket geometry.\n        \"\"\"\n        intersection = get_inner_cut_point(self.bb, ci)\n        x, y, z = intersection\n        x2 = x - np.sin(np.deg2rad(gamma))\n        y2 = y\n        z2 = z + np.cos(np.deg2rad(gamma))\n        angled_cut_plane = BluemiraPlane.from_3_points(\n            intersection, [x2, y2, z2], [x, y + 1, z]\n        )\n        # Get the last intersection with the angled cut plane and the outer\n        intersections = slice_shape(self.bb.boundary[0], angled_cut_plane)\n        intersections = intersections[intersections[:, -1] > z + EPS]\n        intersection = min(intersections, key=lambda x: x[-1])\n        return intersection",
  "class UpperPortKOZDesignerParams(ParameterFrame):\n    \"\"\"Parameters required to run :class:`UpperPortKOZDesigner`.\"\"\"\n\n    tk_vv_double_wall: Parameter[float]\n    \"\"\"VV upper port wall thickness at radial ends [m].\"\"\"\n    g_vv_ts: Parameter[float]\n    \"\"\"Gap between VV and TS [m].\"\"\"\n    tk_ts: Parameter[float]\n    \"\"\"TS thickness [m].\"\"\"\n    g_ts_tf: Parameter[float]\n    \"\"\"Gap between TS and TF (used for short gap to PF) [m].\"\"\"\n    pf_s_g: Parameter[float]\n    \"\"\"Gap between PF coil and support [m].\"\"\"\n    pf_s_tk_plate: Parameter[float]\n    \"\"\"PF coil support thickness [m].\"\"\"\n    c_rm: Parameter[float]\n    \"\"\"Remote maintenance clearance [m].\"\"\"\n    R_0: Parameter[float]\n    \"\"\"Major radius [m].\"\"\"\n    bb_min_angle: Parameter[float]\n    \"\"\"Minimum blanket module angle [degrees].\"\"\"\n    tk_bb_ib: Parameter[float]\n    \"\"\"Blanket inboard thickness [m].\"\"\"\n    tk_bb_ob: Parameter[float]\n    \"\"\"Blanket outboard thickness [m].\"\"\"",
  "class UpperPortKOZDesigner(Designer[Tuple[BluemiraFace, float, float]]):\n    \"\"\"Upper Port keep-out zone designer.\"\"\"\n\n    param_cls = UpperPortKOZDesignerParams\n    params: UpperPortKOZDesignerParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Dict,\n        blanket_face: BluemiraFace,\n        upper_port_extrema=10,\n    ):\n        super().__init__(params, build_config)\n        self.blanket_face = blanket_face\n        self.opt_algorithm = self.build_config.get(\"opt_algorithm\", \"SLSQP\")\n        self.opt_conditions = {\n            **{\"max_eval\": 1000, \"ftol_rel\": 1e-8},\n            **self.build_config.get(\"opt_conditions\", {}),\n        }\n        self.upper_port_extrema = upper_port_extrema\n\n    def run(self):\n        \"\"\"Run the design problem to minimise the port size.\"\"\"\n        opt_problem = UpperPortOP(\n            bb=self.blanket_face,\n            c_rm=self.params.c_rm.value,\n            R_0=self.params.R_0.value,\n            tk_bb_ib=self.params.tk_bb_ib.value,\n            tk_bb_ob=self.params.tk_bb_ob.value,\n            bb_min_angle=(90 - self.params.bb_min_angle.value),\n        )\n        opt_result = opt_problem.optimise(\n            # Initial guess at center of bounds\n            x0=np.vstack(opt_problem.bounds()).mean(axis=0),\n            algorithm=self.opt_algorithm,\n            opt_conditions=self.opt_conditions,\n        )\n        r_up_inner, r_up_outer, r_cut, cut_angle = opt_result.x\n\n        offset = (\n            self.params.tk_vv_double_wall.value\n            + self.params.g_vv_ts.value\n            + self.params.tk_ts.value\n            + self.params.g_ts_tf.value\n            + self.params.pf_s_tk_plate.value\n            + self.params.pf_s_g.value\n        )\n        r_up_inner -= offset\n        r_up_outer += offset\n\n        return (\n            build_upper_port_zone(r_up_inner, r_up_outer, z_max=self.upper_port_extrema),\n            r_cut,\n            cut_angle,\n        )",
  "def build_upper_port_zone(\n    r_up_inner: float, r_up_outer: float, z_max: float = 10, z_min: float = 0\n) -> BluemiraFace:\n    \"\"\"\n    Make the void geometry for the upper port in the poloidal plane.\n\n    Parameters\n    ----------\n    r_up_inner:\n        Inner radius of the upper port void space\n    r_up_outer:\n        Outer radius of the upper port void space\n    z_max:\n        Maximum vertical height of the upper port void space\n    z_min:\n        Minimum vertical height of the upper port void space\n\n    Returns\n    -------\n    Face representing the upper port void space in the x-z plane\n    \"\"\"\n    x = [r_up_inner, r_up_outer, r_up_outer, r_up_inner]\n    z = [z_min, z_min, z_max, z_max]\n    return BluemiraFace(make_polygon({\"x\": x, \"y\": 0, \"z\": z}, closed=True))",
  "def __init__(\n        self,\n        bb: BluemiraFace,\n        c_rm: float,\n        R_0: float,\n        tk_bb_ib: float,\n        tk_bb_ob: float,\n        bb_min_angle: float,\n    ):\n        self.bb = bb\n        self.c_rm = c_rm\n        self.R_0 = R_0\n        self.tk_bb_ib = tk_bb_ib\n        self.bb_min_angle = bb_min_angle\n        self.tk_bb_ob = tk_bb_ob\n        self.r_ib_min = self.bb.bounding_box.x_min\n        self.r_ob_max = self.bb.bounding_box.x_max\n        self.gradient = np.array([-1, 1, 0, 1], dtype=float)",
  "def objective(self, x: np.ndarray) -> float:\n        \"\"\"The objective function of the optimisation.\"\"\"\n        return self.port_size(x)",
  "def df_objective(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"The gradient of the objective function.\"\"\"\n        return self.df_port_size(x)",
  "def ineq_constraints(self) -> List[ConstraintT]:\n        \"\"\"Inequality constraints for the problem.\"\"\"\n        return [\n            {\"f_constraint\": self.constrain_blanket_cut, \"tolerance\": np.full(3, 1e-6)}\n        ]",
  "def bounds(self) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"The bounds for the optimisation parameters.\"\"\"\n        lower = [self.r_ib_min - self.c_rm, self.R_0, self.r_ib_min + self.tk_bb_ib, 0]\n        upper = [\n            self.R_0,\n            self.r_ob_max + self.c_rm,\n            self.r_ob_max - self.tk_bb_ob,\n            self.bb_min_angle,\n        ]\n        return np.array(lower), np.array(upper)",
  "def port_size(self, x: np.ndarray) -> float:\n        \"\"\"Return the port size given parameterisation ``x``.\"\"\"\n        ri, ro, _, gamma = x\n        return ro - ri + gamma",
  "def df_port_size(self, _: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Return the gradient of the port size.\n\n        Parameters\n        ----------\n        _:\n            The parameterisation of the port size. This is unused as the\n            gradient is constant.\n\n        Returns\n        -------\n        The gradient of the port size parameterisation, with shape (3,).\n        \"\"\"\n        return self.gradient",
  "def constrain_blanket_cut(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Constrain the upper port size.\n\n        This enforces 3 constraints:\n\n        c1. The outboard blanket must fit through the port.\n        c2. The inboard blanket must squeeze past the other blanket\n            segment and out the port. Hence, this also enforces that\n            the inboard blanket fits through the port.\n        c3. There should be enough vertically accessible space on the\n            inboard blanket to connect pipes and a remote attachment\n            point.\n        \"\"\"\n        ri, ro, ci, gamma = x\n        co = self.get_outer_cut_point(ci, gamma)[0]\n        c1 = (self.r_ob_max - co + self.c_rm) - (ro - co)\n        c2 = (ci - self.r_ib_min) - (ro - ci + self.c_rm)\n        c3 = (ri + 0.5 * abs(ci - self.r_ib_min)) - ci\n        return np.array([c1, c2, c3])",
  "def get_outer_cut_point(self, ci: float, gamma: float):\n        \"\"\"\n        Get the coordinate of the outer blanket cut point.\n\n        The outer cut point radius of the cutting plane with the\n        breeding blanket geometry.\n        \"\"\"\n        intersection = get_inner_cut_point(self.bb, ci)\n        x, y, z = intersection\n        x2 = x - np.sin(np.deg2rad(gamma))\n        y2 = y\n        z2 = z + np.cos(np.deg2rad(gamma))\n        angled_cut_plane = BluemiraPlane.from_3_points(\n            intersection, [x2, y2, z2], [x, y + 1, z]\n        )\n        # Get the last intersection with the angled cut plane and the outer\n        intersections = slice_shape(self.bb.boundary[0], angled_cut_plane)\n        intersections = intersections[intersections[:, -1] > z + EPS]\n        intersection = min(intersections, key=lambda x: x[-1])\n        return intersection",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Dict,\n        blanket_face: BluemiraFace,\n        upper_port_extrema=10,\n    ):\n        super().__init__(params, build_config)\n        self.blanket_face = blanket_face\n        self.opt_algorithm = self.build_config.get(\"opt_algorithm\", \"SLSQP\")\n        self.opt_conditions = {\n            **{\"max_eval\": 1000, \"ftol_rel\": 1e-8},\n            **self.build_config.get(\"opt_conditions\", {}),\n        }\n        self.upper_port_extrema = upper_port_extrema",
  "def run(self):\n        \"\"\"Run the design problem to minimise the port size.\"\"\"\n        opt_problem = UpperPortOP(\n            bb=self.blanket_face,\n            c_rm=self.params.c_rm.value,\n            R_0=self.params.R_0.value,\n            tk_bb_ib=self.params.tk_bb_ib.value,\n            tk_bb_ob=self.params.tk_bb_ob.value,\n            bb_min_angle=(90 - self.params.bb_min_angle.value),\n        )\n        opt_result = opt_problem.optimise(\n            # Initial guess at center of bounds\n            x0=np.vstack(opt_problem.bounds()).mean(axis=0),\n            algorithm=self.opt_algorithm,\n            opt_conditions=self.opt_conditions,\n        )\n        r_up_inner, r_up_outer, r_cut, cut_angle = opt_result.x\n\n        offset = (\n            self.params.tk_vv_double_wall.value\n            + self.params.g_vv_ts.value\n            + self.params.tk_ts.value\n            + self.params.g_ts_tf.value\n            + self.params.pf_s_tk_plate.value\n            + self.params.pf_s_g.value\n        )\n        r_up_inner -= offset\n        r_up_outer += offset\n\n        return (\n            build_upper_port_zone(r_up_inner, r_up_outer, z_max=self.upper_port_extrema),\n            r_cut,\n            cut_angle,\n        )",
  "class LowerPortKOZDesignerParams(ParameterFrame):\n    \"\"\"Lower Port KOZ Designer ParameterFrame\"\"\"\n\n    n_TF: Parameter[int]\n    n_div_cassettes: Parameter[int]\n    lower_port_angle: Parameter[float]\n    g_ts_tf: Parameter[float]\n    tk_ts: Parameter[float]\n    g_vv_ts: Parameter[float]\n    tk_vv_single_wall: Parameter[float]\n    tf_wp_depth: Parameter[float]\n\n    # Pseudo - local\n    lp_height: Parameter[float]\n    lp_width: Parameter[float]\n    # Local (varying)\n\n    lp_duct_div_pad_ob: Parameter[float]\n    lp_duct_div_pad_ib: Parameter[float]",
  "class LowerPortKOZDesigner(Designer):\n    \"\"\"\n    Lower Port keep-out-zone designer\n\n    Notes\n    -----\n    Retractions on the lower_duct_angle are between [-90, 0] degrees.\n    \"\"\"\n\n    params: LowerPortKOZDesignerParams\n    param_cls: Type[ParameterFrame] = LowerPortKOZDesignerParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Dict,\n        divertor_xz: BluemiraFace,\n        tf_coil_xz_boundary: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.divertor_face = divertor_xz\n        self.tf_coil_xz_boundary = tf_coil_xz_boundary\n\n        # TODO: Cross-check with upper port handling and add casing\n        # sidewall thickness + gaps?\n        self.tf_coil_thickness = 0.5 * self.params.tf_wp_depth.value\n\n        self.tf_offset = (\n            self.params.g_ts_tf.value\n            + self.params.tk_ts.value\n            + self.params.g_vv_ts.value\n        )\n\n        self.div_pad_ob = self.params.lp_duct_div_pad_ob.value\n        self.div_pad_ib = self.params.lp_duct_div_pad_ib.value\n        self.wall_tk = self.params.tk_vv_single_wall.value\n        self.port_height = self.params.lp_height.value\n        self.port_width = self.params.lp_width.value\n\n    def run(self) -> Tuple[BluemiraFace, BluemiraFace, BluemiraWire, BluemiraWire]:\n        \"\"\"Run method of Designer\"\"\"\n        # ib -> inboard\n        # ob -> outboard\n        # inner -> closer to the center (or without the duct wall)\n        # outer -> further from the center\n        # pt -> point\n\n        ib_div_pt, ob_div_pt = self._get_div_pts_at_angle()\n        ib_div_pt_padded, ob_div_pt_padded = self._pad_points(ib_div_pt, ob_div_pt)\n\n        (\n            duct_inner_xz,\n            duct_outer_xz,\n            straight_top_inner_pt,\n            straight_bot_inner_pt,\n        ) = self._duct_xz_shapes(ib_div_pt_padded, ob_div_pt_padded)\n\n        duct_angled_inner_extrude_boundary = self._angled_duct_inner_xy_boundary(\n            ib_div_pt_padded, ob_div_pt_padded\n        )\n\n        duct_straight_inner_extrude_boundary = self._straight_duct_inner_yz_boundary(\n            straight_top_inner_pt, straight_bot_inner_pt\n        )\n\n        return (\n            duct_inner_xz,\n            duct_outer_xz,\n            duct_angled_inner_extrude_boundary,\n            duct_straight_inner_extrude_boundary,\n        )\n\n    @property\n    def _duct_angle_gradient(self) -> float:\n        return np.tan(np.deg2rad(self.params.lower_port_angle.value))\n\n    @property\n    def _half_beta(self) -> float:\n        return np.pi / self.params.n_TF.value\n\n    def _get_div_pts_at_angle(self) -> Tuple[Tuple, Tuple]:\n        div_z_top = self.divertor_face.bounding_box.z_max\n        div_z_bot = self.divertor_face.bounding_box.z_min\n\n        div_x_ib = self.divertor_face.bounding_box.x_min\n        div_x_ob = self.divertor_face.bounding_box.x_max\n\n        div_diag_len, _ = distance_to([div_x_ob, 0, div_z_top], [div_x_ib, 0, div_z_bot])\n\n        # construct a wire along the angled duct gradient, with the\n        # start and end points div_diag_len away\n        # from the bottom ib point\n        start_end_points = self._xz_points_dist_away_from(\n            (div_x_ib, div_z_bot), self._duct_angle_gradient, div_diag_len\n        )\n        search_wire = self._make_xz_wire_from_points(\n            start_end_points[0], start_end_points[1]\n        )\n\n        closest_pts = self._closest_points(search_wire, self.divertor_face)\n        # just take the point with the highest z, if there's more than one\n        z_highest_pt = max(closest_pts, key=lambda p: p[2])\n\n        return (z_highest_pt[0], z_highest_pt[2]), (div_x_ob, div_z_top)\n\n    def _pad_points(self, ib_point: Tuple, ob_point: Tuple):\n        points_grad = (ib_point[1] - ob_point[1]) / (ib_point[0] - ob_point[0])  # z/x\n        points_len, _ = distance_to(\n            [ib_point[0], 0, ib_point[1]], [ob_point[0], 0, ob_point[1]]\n        )\n\n        padded_ib_pt, _ = self._xz_points_dist_away_from(\n            ob_point, points_grad, points_len + self.div_pad_ib\n        )\n        _, padded_ob_pt = self._xz_points_dist_away_from(\n            ib_point, points_grad, points_len + self.div_pad_ob\n        )\n        return padded_ib_pt, padded_ob_pt\n\n    def _straight_duct_inner_yz_boundary(\n        self,\n        straight_top_inner_pt: Tuple,\n        straight_bot_inner_pt: Tuple,\n    ) -> BluemiraWire:\n        \"\"\"\n        Make the inner yz boundary of the straight duct.\n\n        This takes the straight duct inner (no wall) top and bottom\n        inboard points and uses the port width to make the boundary.\n        \"\"\"\n        x_point = straight_top_inner_pt[0]\n        y_size = self.port_width / 2\n\n        return make_polygon(\n            [\n                [x_point] * 4,\n                [y_size, y_size, -y_size, -y_size],\n                [\n                    straight_top_inner_pt[1],\n                    straight_bot_inner_pt[1],\n                    straight_bot_inner_pt[1],\n                    straight_top_inner_pt[1],\n                ],\n            ],\n            closed=True,\n        )\n\n    def _angled_duct_inner_xy_boundary(\n        self, ib_div_pt_padded: Tuple, ob_div_pt_padded: Tuple\n    ):\n        def _calc_y_point(x_point):\n            x_meet = self.tf_coil_thickness / np.sin(self._half_beta)\n            x_len = x_point - x_meet\n\n            if x_len < 0:\n                raise GeometryError(\n                    \"LowerPortDesigner: tf_coil_thickness is too large for the\"\n                    f\" space between TF coils at x={x_point}.\"\n                )\n\n            y_at_x_proj = x_len * np.tan(self._half_beta)\n            return y_at_x_proj\n\n        ib_inner_y = _calc_y_point(ib_div_pt_padded[0]) - self.wall_tk\n        ob_inner_y = _calc_y_point(ob_div_pt_padded[0]) - self.wall_tk\n\n        # check if the space between the y-points is large enough for the\n        # divertor to fit through:\n        # This uses an approx. of the divertor width at an x-point (ib or ob).\n        # The approx. is valid because the angle is small and tf_coil's\n        # have straight edges.\n        # Half-sector degree\n        angle = np.pi / self.params.n_TF.value / self.params.n_div_cassettes.value\n        div_half_width_at_ib = ib_div_pt_padded[0] * np.tan(angle)\n        div_half_width_at_ob = ob_div_pt_padded[0] * np.tan(angle)\n        # half sector degree is used because ib_inner_y, ob_inner_y are for\n        # the upper half space available for the divertor.\n        if div_half_width_at_ib > ib_inner_y or div_half_width_at_ob > ob_inner_y:\n            raise GeometryError(\n                \"LowerPortDesigner: duct wall thickness is too large for the \"\n                \"space between TF coils. \"\n                \"Making the duct angle shallower or reducing the \"\n                \"duct wall thickness would help.\"\n            )\n\n        ib_div_pt_x, ib_div_pt_z = ib_div_pt_padded\n        ob_div_pt_x, ob_div_pt_z = ob_div_pt_padded\n\n        x = [ib_div_pt_x, ib_div_pt_x, ob_div_pt_x, ob_div_pt_x]\n        y = [ib_inner_y, -ib_inner_y, -ob_inner_y, ob_inner_y]\n        z = [ib_div_pt_z, ib_div_pt_z, ob_div_pt_z, ob_div_pt_z]\n        duct_inner_xy = make_polygon({\"x\": x, \"y\": y, \"z\": z}, closed=True)\n\n        # Translate a little inwards and upwards to ensure penetration to\n        # main body\n        angle = np.deg2rad(self.params.lower_port_angle.value)\n        direction = np.array([np.cos(angle), 0, np.sin(angle)])\n        duct_inner_xy.translate(-1 * direction)\n        return duct_inner_xy\n\n    def _duct_xz_shapes(self, ib_div_pt_padded: Tuple, ob_div_pt_padded: Tuple):\n        angled_duct_boundary = self._angled_duct_xz_boundary(\n            ib_div_pt_padded, ob_div_pt_padded\n        )\n\n        (\n            straight_duct_boundary,\n            straight_top_inner_pt,\n            straight_bot_inner_pt,\n        ) = self._straight_duct_xz_boundary(angled_duct_boundary)\n\n        angled_cuts = boolean_cut(angled_duct_boundary, [straight_duct_boundary])\n\n        angled_duct_top_xz = angled_cuts[0]\n        angled_duct_top_xz.close()\n        angled_duct_top_xz = BluemiraFace(angled_duct_top_xz)\n\n        straight_duct_xz = BluemiraFace(straight_duct_boundary)\n\n        duct_inner_xz: BluemiraFace = boolean_fuse(\n            [angled_duct_top_xz, straight_duct_xz]\n        )\n        duct_inner_boundary = duct_inner_xz.boundary[0]\n\n        duct_outer_boundary = offset_wire(duct_inner_boundary, self.wall_tk)\n        duct_outer_xz = BluemiraFace(duct_outer_boundary)\n\n        return (\n            duct_inner_xz,\n            duct_outer_xz,\n            straight_top_inner_pt,\n            straight_bot_inner_pt,\n        )\n\n    def _angled_duct_xz_boundary(self, ib_pt: Tuple, ob_pt: Tuple):\n        \"\"\"\n        Returns a rectangular face at the duct angle,\n        starting at the inboard and outboard points\n        of the padded points from the divertor.\n        \"\"\"\n        r_search = 40  # must just be large\n\n        # construct a really long angle duct\n        _, ib_end_pt = self._xz_points_dist_away_from(\n            ib_pt, self._duct_angle_gradient, r_search\n        )\n        _, ob_end_pt = self._xz_points_dist_away_from(\n            ob_pt, self._duct_angle_gradient, r_search\n        )\n\n        return make_polygon(\n            [\n                [\n                    ob_pt[0],\n                    ob_end_pt[0],\n                    ib_end_pt[0],\n                    ib_pt[0],\n                ],\n                [0, 0, 0, 0],\n                [\n                    ob_pt[1],\n                    ob_end_pt[1],\n                    ib_end_pt[1],\n                    ib_pt[1],\n                ],\n            ],\n            closed=True,\n        )\n\n    def _straight_duct_xz_boundary(self, angled_duct_boundary: BluemiraWire):\n        x_duct_extent = 30  # must extend past the outer rad. shield\n        tf_offset_boundary = offset_wire(self.tf_coil_xz_boundary, self.tf_offset)\n\n        itc_pts = self._intersection_points(angled_duct_boundary, tf_offset_boundary)\n\n        if len(itc_pts) < 2:\n            raise GeometryError(\n                \"LowerPortDesigner: angled duct must be made larger (increase r_search)\"\n            )\n\n        # find the top and bottom itc points\n        itc_top_pt = max(itc_pts, key=lambda p: p[2])\n        itc_bot_pt = min(itc_pts, key=lambda p: p[2])\n        # remap to 2D point\n        itc_top_pt = (itc_top_pt[0], itc_top_pt[2])\n        itc_bot_pt = (itc_bot_pt[0], itc_bot_pt[2])\n\n        # choose corner point\n        topleft_corner_pt = itc_bot_pt\n        if self.params.lower_port_angle.value > -45:\n            topleft_corner_pt = itc_top_pt\n\n        topright_corner_pt = (\n            x_duct_extent,\n            topleft_corner_pt[1],\n        )\n\n        botright_corner_pt = (\n            x_duct_extent,\n            topleft_corner_pt[1] - self.port_height,\n        )\n\n        botleft_corner_pt = (\n            topleft_corner_pt[0],\n            topleft_corner_pt[1] - self.port_height,\n        )\n\n        # check if the left edge goes below the angled duct when\n        # the corner point is the top itc point (i.e. angle > -45)\n        if topleft_corner_pt == itc_top_pt:\n            left_e = self._make_xz_wire_from_points(topleft_corner_pt, botleft_corner_pt)\n            l_e_itc_pts = self._intersection_points(left_e, angled_duct_boundary)\n            if len(l_e_itc_pts) == 1:\n                raise GeometryError(\n                    \"LowerPortDesigner: port height is too small \"\n                    \"at this angle and will not meet the angled duct.\"\n                )\n\n        straight_boundary = make_polygon(\n            [\n                [\n                    topleft_corner_pt[0],\n                    topright_corner_pt[0],\n                    botright_corner_pt[0],\n                    botleft_corner_pt[0],\n                ],\n                [0] * 4,\n                [\n                    topleft_corner_pt[1],\n                    topright_corner_pt[1],\n                    botright_corner_pt[1],\n                    botleft_corner_pt[1],\n                ],\n            ],\n            closed=True,\n        )\n\n        return straight_boundary, topleft_corner_pt, botleft_corner_pt\n\n    @staticmethod\n    def _xz_points_dist_away_from(\n        starting_xz_point: Union[Tuple, List],\n        gradient: float,\n        distance: float,\n    ) -> Tuple:\n        \"\"\"\n        Returns two points, the first being in the negative x quadrant,\n        the second in the positive x quadrant, at a distance away from\n        from the starting point, along the line with the given gradient.\n        \"\"\"\n        s_x = starting_xz_point[0]\n        s_z = starting_xz_point[1]\n        sqrt_value = np.sqrt(distance**2 / (1 + gradient**2))\n        f_x_pve = sqrt_value + s_x\n        f_z_pve = gradient * sqrt_value + s_z\n        f_x_nve = -sqrt_value + s_x\n        f_z_nve = gradient * -sqrt_value + s_z\n        return [f_x_nve, f_z_nve], [f_x_pve, f_z_pve]\n\n    @staticmethod\n    def _make_xz_wire_from_points(\n        a_xz_point: Tuple,\n        b_xz_point: Tuple,\n    ) -> BluemiraWire:\n        return make_polygon(\n            [[a_xz_point[0], b_xz_point[0]], [0] * 2, [a_xz_point[1], b_xz_point[1]]]\n        )\n\n    @staticmethod\n    def _intersection_points(\n        shape_a: BluemiraGeo,\n        shape_b: BluemiraGeo,\n    ) -> List[Tuple]:\n        dist, vects = distance_to(shape_a, shape_b)\n        if dist > D_TOLERANCE:  # not intersecting\n            return []\n        pois = []\n        for vect_pair in vects:\n            v = vect_pair[0]\n            pois.append((v[0], v[1], v[2]))\n        return pois\n\n    @staticmethod\n    def _closest_points(\n        shape_a: BluemiraGeo,\n        shape_b: BluemiraGeo,\n    ) -> List[Tuple]:\n        dist, vects = distance_to(shape_a, shape_b)\n        if dist < D_TOLERANCE:  # intersecting, return intersection points\n            return LowerPortKOZDesigner._intersection_points(shape_a, shape_b)\n        points = []\n        vect_pairs = vects[0]\n        for v in vect_pairs:\n            points.append((v[0], v[1], v[2]))\n        return points",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Dict,\n        divertor_xz: BluemiraFace,\n        tf_coil_xz_boundary: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.divertor_face = divertor_xz\n        self.tf_coil_xz_boundary = tf_coil_xz_boundary\n\n        # TODO: Cross-check with upper port handling and add casing\n        # sidewall thickness + gaps?\n        self.tf_coil_thickness = 0.5 * self.params.tf_wp_depth.value\n\n        self.tf_offset = (\n            self.params.g_ts_tf.value\n            + self.params.tk_ts.value\n            + self.params.g_vv_ts.value\n        )\n\n        self.div_pad_ob = self.params.lp_duct_div_pad_ob.value\n        self.div_pad_ib = self.params.lp_duct_div_pad_ib.value\n        self.wall_tk = self.params.tk_vv_single_wall.value\n        self.port_height = self.params.lp_height.value\n        self.port_width = self.params.lp_width.value",
  "def run(self) -> Tuple[BluemiraFace, BluemiraFace, BluemiraWire, BluemiraWire]:\n        \"\"\"Run method of Designer\"\"\"\n        # ib -> inboard\n        # ob -> outboard\n        # inner -> closer to the center (or without the duct wall)\n        # outer -> further from the center\n        # pt -> point\n\n        ib_div_pt, ob_div_pt = self._get_div_pts_at_angle()\n        ib_div_pt_padded, ob_div_pt_padded = self._pad_points(ib_div_pt, ob_div_pt)\n\n        (\n            duct_inner_xz,\n            duct_outer_xz,\n            straight_top_inner_pt,\n            straight_bot_inner_pt,\n        ) = self._duct_xz_shapes(ib_div_pt_padded, ob_div_pt_padded)\n\n        duct_angled_inner_extrude_boundary = self._angled_duct_inner_xy_boundary(\n            ib_div_pt_padded, ob_div_pt_padded\n        )\n\n        duct_straight_inner_extrude_boundary = self._straight_duct_inner_yz_boundary(\n            straight_top_inner_pt, straight_bot_inner_pt\n        )\n\n        return (\n            duct_inner_xz,\n            duct_outer_xz,\n            duct_angled_inner_extrude_boundary,\n            duct_straight_inner_extrude_boundary,\n        )",
  "def _duct_angle_gradient(self) -> float:\n        return np.tan(np.deg2rad(self.params.lower_port_angle.value))",
  "def _half_beta(self) -> float:\n        return np.pi / self.params.n_TF.value",
  "def _get_div_pts_at_angle(self) -> Tuple[Tuple, Tuple]:\n        div_z_top = self.divertor_face.bounding_box.z_max\n        div_z_bot = self.divertor_face.bounding_box.z_min\n\n        div_x_ib = self.divertor_face.bounding_box.x_min\n        div_x_ob = self.divertor_face.bounding_box.x_max\n\n        div_diag_len, _ = distance_to([div_x_ob, 0, div_z_top], [div_x_ib, 0, div_z_bot])\n\n        # construct a wire along the angled duct gradient, with the\n        # start and end points div_diag_len away\n        # from the bottom ib point\n        start_end_points = self._xz_points_dist_away_from(\n            (div_x_ib, div_z_bot), self._duct_angle_gradient, div_diag_len\n        )\n        search_wire = self._make_xz_wire_from_points(\n            start_end_points[0], start_end_points[1]\n        )\n\n        closest_pts = self._closest_points(search_wire, self.divertor_face)\n        # just take the point with the highest z, if there's more than one\n        z_highest_pt = max(closest_pts, key=lambda p: p[2])\n\n        return (z_highest_pt[0], z_highest_pt[2]), (div_x_ob, div_z_top)",
  "def _pad_points(self, ib_point: Tuple, ob_point: Tuple):\n        points_grad = (ib_point[1] - ob_point[1]) / (ib_point[0] - ob_point[0])  # z/x\n        points_len, _ = distance_to(\n            [ib_point[0], 0, ib_point[1]], [ob_point[0], 0, ob_point[1]]\n        )\n\n        padded_ib_pt, _ = self._xz_points_dist_away_from(\n            ob_point, points_grad, points_len + self.div_pad_ib\n        )\n        _, padded_ob_pt = self._xz_points_dist_away_from(\n            ib_point, points_grad, points_len + self.div_pad_ob\n        )\n        return padded_ib_pt, padded_ob_pt",
  "def _straight_duct_inner_yz_boundary(\n        self,\n        straight_top_inner_pt: Tuple,\n        straight_bot_inner_pt: Tuple,\n    ) -> BluemiraWire:\n        \"\"\"\n        Make the inner yz boundary of the straight duct.\n\n        This takes the straight duct inner (no wall) top and bottom\n        inboard points and uses the port width to make the boundary.\n        \"\"\"\n        x_point = straight_top_inner_pt[0]\n        y_size = self.port_width / 2\n\n        return make_polygon(\n            [\n                [x_point] * 4,\n                [y_size, y_size, -y_size, -y_size],\n                [\n                    straight_top_inner_pt[1],\n                    straight_bot_inner_pt[1],\n                    straight_bot_inner_pt[1],\n                    straight_top_inner_pt[1],\n                ],\n            ],\n            closed=True,\n        )",
  "def _angled_duct_inner_xy_boundary(\n        self, ib_div_pt_padded: Tuple, ob_div_pt_padded: Tuple\n    ):\n        def _calc_y_point(x_point):\n            x_meet = self.tf_coil_thickness / np.sin(self._half_beta)\n            x_len = x_point - x_meet\n\n            if x_len < 0:\n                raise GeometryError(\n                    \"LowerPortDesigner: tf_coil_thickness is too large for the\"\n                    f\" space between TF coils at x={x_point}.\"\n                )\n\n            y_at_x_proj = x_len * np.tan(self._half_beta)\n            return y_at_x_proj\n\n        ib_inner_y = _calc_y_point(ib_div_pt_padded[0]) - self.wall_tk\n        ob_inner_y = _calc_y_point(ob_div_pt_padded[0]) - self.wall_tk\n\n        # check if the space between the y-points is large enough for the\n        # divertor to fit through:\n        # This uses an approx. of the divertor width at an x-point (ib or ob).\n        # The approx. is valid because the angle is small and tf_coil's\n        # have straight edges.\n        # Half-sector degree\n        angle = np.pi / self.params.n_TF.value / self.params.n_div_cassettes.value\n        div_half_width_at_ib = ib_div_pt_padded[0] * np.tan(angle)\n        div_half_width_at_ob = ob_div_pt_padded[0] * np.tan(angle)\n        # half sector degree is used because ib_inner_y, ob_inner_y are for\n        # the upper half space available for the divertor.\n        if div_half_width_at_ib > ib_inner_y or div_half_width_at_ob > ob_inner_y:\n            raise GeometryError(\n                \"LowerPortDesigner: duct wall thickness is too large for the \"\n                \"space between TF coils. \"\n                \"Making the duct angle shallower or reducing the \"\n                \"duct wall thickness would help.\"\n            )\n\n        ib_div_pt_x, ib_div_pt_z = ib_div_pt_padded\n        ob_div_pt_x, ob_div_pt_z = ob_div_pt_padded\n\n        x = [ib_div_pt_x, ib_div_pt_x, ob_div_pt_x, ob_div_pt_x]\n        y = [ib_inner_y, -ib_inner_y, -ob_inner_y, ob_inner_y]\n        z = [ib_div_pt_z, ib_div_pt_z, ob_div_pt_z, ob_div_pt_z]\n        duct_inner_xy = make_polygon({\"x\": x, \"y\": y, \"z\": z}, closed=True)\n\n        # Translate a little inwards and upwards to ensure penetration to\n        # main body\n        angle = np.deg2rad(self.params.lower_port_angle.value)\n        direction = np.array([np.cos(angle), 0, np.sin(angle)])\n        duct_inner_xy.translate(-1 * direction)\n        return duct_inner_xy",
  "def _duct_xz_shapes(self, ib_div_pt_padded: Tuple, ob_div_pt_padded: Tuple):\n        angled_duct_boundary = self._angled_duct_xz_boundary(\n            ib_div_pt_padded, ob_div_pt_padded\n        )\n\n        (\n            straight_duct_boundary,\n            straight_top_inner_pt,\n            straight_bot_inner_pt,\n        ) = self._straight_duct_xz_boundary(angled_duct_boundary)\n\n        angled_cuts = boolean_cut(angled_duct_boundary, [straight_duct_boundary])\n\n        angled_duct_top_xz = angled_cuts[0]\n        angled_duct_top_xz.close()\n        angled_duct_top_xz = BluemiraFace(angled_duct_top_xz)\n\n        straight_duct_xz = BluemiraFace(straight_duct_boundary)\n\n        duct_inner_xz: BluemiraFace = boolean_fuse(\n            [angled_duct_top_xz, straight_duct_xz]\n        )\n        duct_inner_boundary = duct_inner_xz.boundary[0]\n\n        duct_outer_boundary = offset_wire(duct_inner_boundary, self.wall_tk)\n        duct_outer_xz = BluemiraFace(duct_outer_boundary)\n\n        return (\n            duct_inner_xz,\n            duct_outer_xz,\n            straight_top_inner_pt,\n            straight_bot_inner_pt,\n        )",
  "def _angled_duct_xz_boundary(self, ib_pt: Tuple, ob_pt: Tuple):\n        \"\"\"\n        Returns a rectangular face at the duct angle,\n        starting at the inboard and outboard points\n        of the padded points from the divertor.\n        \"\"\"\n        r_search = 40  # must just be large\n\n        # construct a really long angle duct\n        _, ib_end_pt = self._xz_points_dist_away_from(\n            ib_pt, self._duct_angle_gradient, r_search\n        )\n        _, ob_end_pt = self._xz_points_dist_away_from(\n            ob_pt, self._duct_angle_gradient, r_search\n        )\n\n        return make_polygon(\n            [\n                [\n                    ob_pt[0],\n                    ob_end_pt[0],\n                    ib_end_pt[0],\n                    ib_pt[0],\n                ],\n                [0, 0, 0, 0],\n                [\n                    ob_pt[1],\n                    ob_end_pt[1],\n                    ib_end_pt[1],\n                    ib_pt[1],\n                ],\n            ],\n            closed=True,\n        )",
  "def _straight_duct_xz_boundary(self, angled_duct_boundary: BluemiraWire):\n        x_duct_extent = 30  # must extend past the outer rad. shield\n        tf_offset_boundary = offset_wire(self.tf_coil_xz_boundary, self.tf_offset)\n\n        itc_pts = self._intersection_points(angled_duct_boundary, tf_offset_boundary)\n\n        if len(itc_pts) < 2:\n            raise GeometryError(\n                \"LowerPortDesigner: angled duct must be made larger (increase r_search)\"\n            )\n\n        # find the top and bottom itc points\n        itc_top_pt = max(itc_pts, key=lambda p: p[2])\n        itc_bot_pt = min(itc_pts, key=lambda p: p[2])\n        # remap to 2D point\n        itc_top_pt = (itc_top_pt[0], itc_top_pt[2])\n        itc_bot_pt = (itc_bot_pt[0], itc_bot_pt[2])\n\n        # choose corner point\n        topleft_corner_pt = itc_bot_pt\n        if self.params.lower_port_angle.value > -45:\n            topleft_corner_pt = itc_top_pt\n\n        topright_corner_pt = (\n            x_duct_extent,\n            topleft_corner_pt[1],\n        )\n\n        botright_corner_pt = (\n            x_duct_extent,\n            topleft_corner_pt[1] - self.port_height,\n        )\n\n        botleft_corner_pt = (\n            topleft_corner_pt[0],\n            topleft_corner_pt[1] - self.port_height,\n        )\n\n        # check if the left edge goes below the angled duct when\n        # the corner point is the top itc point (i.e. angle > -45)\n        if topleft_corner_pt == itc_top_pt:\n            left_e = self._make_xz_wire_from_points(topleft_corner_pt, botleft_corner_pt)\n            l_e_itc_pts = self._intersection_points(left_e, angled_duct_boundary)\n            if len(l_e_itc_pts) == 1:\n                raise GeometryError(\n                    \"LowerPortDesigner: port height is too small \"\n                    \"at this angle and will not meet the angled duct.\"\n                )\n\n        straight_boundary = make_polygon(\n            [\n                [\n                    topleft_corner_pt[0],\n                    topright_corner_pt[0],\n                    botright_corner_pt[0],\n                    botleft_corner_pt[0],\n                ],\n                [0] * 4,\n                [\n                    topleft_corner_pt[1],\n                    topright_corner_pt[1],\n                    botright_corner_pt[1],\n                    botleft_corner_pt[1],\n                ],\n            ],\n            closed=True,\n        )\n\n        return straight_boundary, topleft_corner_pt, botleft_corner_pt",
  "def _xz_points_dist_away_from(\n        starting_xz_point: Union[Tuple, List],\n        gradient: float,\n        distance: float,\n    ) -> Tuple:\n        \"\"\"\n        Returns two points, the first being in the negative x quadrant,\n        the second in the positive x quadrant, at a distance away from\n        from the starting point, along the line with the given gradient.\n        \"\"\"\n        s_x = starting_xz_point[0]\n        s_z = starting_xz_point[1]\n        sqrt_value = np.sqrt(distance**2 / (1 + gradient**2))\n        f_x_pve = sqrt_value + s_x\n        f_z_pve = gradient * sqrt_value + s_z\n        f_x_nve = -sqrt_value + s_x\n        f_z_nve = gradient * -sqrt_value + s_z\n        return [f_x_nve, f_z_nve], [f_x_pve, f_z_pve]",
  "def _make_xz_wire_from_points(\n        a_xz_point: Tuple,\n        b_xz_point: Tuple,\n    ) -> BluemiraWire:\n        return make_polygon(\n            [[a_xz_point[0], b_xz_point[0]], [0] * 2, [a_xz_point[1], b_xz_point[1]]]\n        )",
  "def _intersection_points(\n        shape_a: BluemiraGeo,\n        shape_b: BluemiraGeo,\n    ) -> List[Tuple]:\n        dist, vects = distance_to(shape_a, shape_b)\n        if dist > D_TOLERANCE:  # not intersecting\n            return []\n        pois = []\n        for vect_pair in vects:\n            v = vect_pair[0]\n            pois.append((v[0], v[1], v[2]))\n        return pois",
  "def _closest_points(\n        shape_a: BluemiraGeo,\n        shape_b: BluemiraGeo,\n    ) -> List[Tuple]:\n        dist, vects = distance_to(shape_a, shape_b)\n        if dist < D_TOLERANCE:  # intersecting, return intersection points\n            return LowerPortKOZDesigner._intersection_points(shape_a, shape_b)\n        points = []\n        vect_pairs = vects[0]\n        for v in vect_pairs:\n            points.append((v[0], v[1], v[2]))\n        return points",
  "def _calc_y_point(x_point):\n            x_meet = self.tf_coil_thickness / np.sin(self._half_beta)\n            x_len = x_point - x_meet\n\n            if x_len < 0:\n                raise GeometryError(\n                    \"LowerPortDesigner: tf_coil_thickness is too large for the\"\n                    f\" space between TF coils at x={x_point}.\"\n                )\n\n            y_at_x_proj = x_len * np.tan(self._half_beta)\n            return y_at_x_proj",
  "class TSLowerPortDuctBuilderParams(ParameterFrame):\n    \"\"\"Thermal Shield Lower Port Duct Builder Parameters\"\"\"\n\n    n_TF: Parameter[int]\n    lower_port_angle: Parameter[float]\n    tk_ts: Parameter[float]",
  "class TSLowerPortDuctBuilder(Builder):\n    \"\"\"\n    Thermal Shield Lower Port Duct Builder\n    \"\"\"\n\n    param_cls = TSLowerPortDuctBuilderParams\n\n    def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        duct_angled_nowall_extrude_boundary: BluemiraWire,\n        duct_straight_nowall_extrude_boundary: BluemiraWire,\n        x_straight_end: float,\n    ):\n        super().__init__(params, build_config)\n        self.duct_angled_boundary = duct_angled_nowall_extrude_boundary\n        self.duct_straight_boundary = duct_straight_nowall_extrude_boundary\n        self.x_straight_end = x_straight_end\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the thermal shield lower port.\n        \"\"\"\n        return self.component_tree(\n            xz=None,\n            xy=None,\n            xyz=self.build_xyz(),\n        )\n\n    def build_xyz(self) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the thermal shield lower port in x-y-z.\n        \"\"\"\n        duct, void = build_lower_port_xyz(\n            self.duct_angled_boundary,\n            self.duct_straight_boundary,\n            self.params.n_TF.value,\n            self.params.lower_port_angle.value,\n            self.params.tk_ts.value,\n            self.x_straight_end,\n        )\n\n        pc = PhysicalComponent(self.name, duct)\n        void = PhysicalComponent(self.name + \" voidspace\", void, material=Void(\"vacuum\"))\n        apply_component_display_options(pc, color=BLUE_PALETTE[\"TS\"][0])\n        apply_component_display_options(void, color=(0, 0, 0))\n\n        return [pc, void]",
  "class VVLowerPortDuctBuilderParams(ParameterFrame):\n    \"\"\"Vacuum Vessel Lower Port Duct Builder Parameters\"\"\"\n\n    n_TF: Parameter[int]\n    lower_port_angle: Parameter[float]\n    tk_ts: Parameter[float]\n    tk_vv_single_wall: Parameter[float]\n    g_vv_ts: Parameter[float]",
  "class VVLowerPortDuctBuilder(Builder):\n    \"\"\"\n    Vacuum Vessel Lower Port Duct Builder\n    \"\"\"\n\n    param_cls = VVLowerPortDuctBuilderParams\n\n    def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        duct_angled_nowall_extrude_boundary: BluemiraWire,\n        duct_straight_nowall_extrude_boundary: BluemiraWire,\n        x_straight_end: float,\n    ):\n        super().__init__(params, build_config)\n        offset_value = -(self.params.tk_ts.value + self.params.g_vv_ts.value)\n        self.duct_angled_boundary = offset_wire(\n            duct_angled_nowall_extrude_boundary, offset_value\n        )\n        self.duct_straight_boundary = offset_wire(\n            duct_straight_nowall_extrude_boundary, offset_value\n        )\n        self.duct_straight_boundary.translate((-offset_value, 0, 0))\n        self.x_straight_end = x_straight_end\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the vacuum vessel lower port.\n        \"\"\"\n        return self.component_tree(\n            xz=None,\n            xy=None,\n            xyz=self.build_xyz(),\n        )\n\n    def build_xyz(self) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the vacuum vessel lower port in x-y-z.\n        \"\"\"\n        duct, void = build_lower_port_xyz(\n            self.duct_angled_boundary,\n            self.duct_straight_boundary,\n            self.params.n_TF.value,\n            self.params.lower_port_angle.value,\n            self.params.tk_vv_single_wall.value,\n            self.x_straight_end,\n        )\n\n        pc = PhysicalComponent(self.name, duct)\n        void = PhysicalComponent(self.name + \" voidspace\", void, material=Void(\"vacuum\"))\n        apply_component_display_options(pc, color=BLUE_PALETTE[\"VV\"][0])\n        apply_component_display_options(void, color=(0, 0, 0))\n\n        return [pc, void]",
  "def _face_and_void_from_outer_boundary(\n    outer_boundary: BluemiraWire, thickness: float\n) -> Tuple[BluemiraFace]:\n    inner_boundary = offset_wire(outer_boundary, -thickness)\n    return BluemiraFace([outer_boundary, inner_boundary]), BluemiraFace(inner_boundary)",
  "def build_lower_port_xyz(\n    duct_angled_boundary: BluemiraWire,\n    duct_straight_boundary: BluemiraWire,\n    n_TF: int,\n    duct_angle: float,\n    wall_tk: float,\n    x_straight_end: float,\n) -> Tuple[BluemiraSolid]:\n    \"\"\"\n    Build lower port solid geometry, including void (estimate)\n\n    Parameters\n    ----------\n    duct_angled_boundary:\n        Outer x-y boundary wire of the angled port cross-section\n    duct_straight_boundary:\n        Outer x-y boundary wire of the straight port cross-section\n    n_TF:\n        Number of TF coils\n    duct_angle:\n        Angle of the lower port duct [degrees]\n    wall_tk:\n        Wall thickness of the lower port\n    x_straight_end:\n        Radial coordinate of the end point of the straight duct\n\n    Returns\n    -------\n    duct:\n        Solid of the lower port duct\n    void:\n        Solid of the lower port void (estimate)\n    \"\"\"\n    straight_duct_extrude_extent = (\n        x_straight_end - duct_straight_boundary.bounding_box.x_min\n    )\n    if straight_duct_extrude_extent <= 0:\n        BuilderError(\n            \"End radial coordinates of the straight duct is lower than it's start coordinate.\"\n        )\n\n    duct_angle = np.deg2rad(duct_angle)\n\n    angled_duct_face, angled_void_face = _face_and_void_from_outer_boundary(\n        duct_angled_boundary, wall_tk\n    )\n    straight_duct_face, straight_void_face = _face_and_void_from_outer_boundary(\n        duct_straight_boundary, wall_tk\n    )\n    straight_duct_backwall_face = BluemiraFace(duct_straight_boundary)\n\n    angled_bb = duct_angled_boundary.bounding_box\n    strait_bb = duct_straight_boundary.bounding_box\n    if duct_angle < -0.25 * np.pi:\n        # -2 to make sure it goes through\n        angled_duct_extrude_extent = abs(\n            (angled_bb.z_max - (strait_bb.z_max - 2.0)) / np.sin(duct_angle)\n        )\n    else:\n        # +2 to make sure it goes through\n        angled_duct_extrude_extent = abs(\n            (angled_bb.x_min - (strait_bb.x_min + 2.0)) / np.cos(duct_angle)\n        )\n\n    ext_vector = angled_duct_extrude_extent * np.array(\n        [np.cos(duct_angle), 0, np.sin(duct_angle)]\n    )\n    angled_duct = extrude_shape(angled_duct_face, ext_vector)\n    angled_void = extrude_shape(angled_void_face, ext_vector)\n\n    straight_duct_backwall = extrude_shape(\n        straight_duct_backwall_face,\n        straight_duct_backwall_face.normal_at() * wall_tk,\n    )\n\n    ext_vector = straight_duct_face.normal_at() * -straight_duct_extrude_extent\n    straight_duct_length = extrude_shape(straight_duct_face, ext_vector)\n    straight_duct_void = extrude_shape(straight_void_face, ext_vector)\n\n    straight_duct = boolean_fuse([straight_duct_backwall, straight_duct_length])\n\n    angled_pieces = boolean_cut(angled_duct, [straight_duct])\n    angled_top = sorted(\n        angled_pieces, key=lambda s: np.hypot(s.center_of_mass[0], s.center_of_mass[2])\n    )[0]\n    angled_void_pieces = boolean_cut(angled_void, [straight_duct_void])\n    angled_void_piece = sorted(angled_void_pieces, key=lambda s: -s.center_of_mass[2])[0]\n    void = boolean_fuse([angled_void_piece, straight_duct_void])\n\n    straight_with_hole = boolean_cut(straight_duct, [angled_top])[0]\n\n    duct = boolean_fuse([angled_top, straight_with_hole])\n    duct = boolean_cut(duct, [angled_void_piece])[0]\n\n    # rotate pieces to correct positions\n    duct.rotate(degree=180 / n_TF)\n    void.rotate(degree=180 / n_TF)\n    return duct, void",
  "def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        duct_angled_nowall_extrude_boundary: BluemiraWire,\n        duct_straight_nowall_extrude_boundary: BluemiraWire,\n        x_straight_end: float,\n    ):\n        super().__init__(params, build_config)\n        self.duct_angled_boundary = duct_angled_nowall_extrude_boundary\n        self.duct_straight_boundary = duct_straight_nowall_extrude_boundary\n        self.x_straight_end = x_straight_end",
  "def build(self) -> Component:\n        \"\"\"\n        Build the thermal shield lower port.\n        \"\"\"\n        return self.component_tree(\n            xz=None,\n            xy=None,\n            xyz=self.build_xyz(),\n        )",
  "def build_xyz(self) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the thermal shield lower port in x-y-z.\n        \"\"\"\n        duct, void = build_lower_port_xyz(\n            self.duct_angled_boundary,\n            self.duct_straight_boundary,\n            self.params.n_TF.value,\n            self.params.lower_port_angle.value,\n            self.params.tk_ts.value,\n            self.x_straight_end,\n        )\n\n        pc = PhysicalComponent(self.name, duct)\n        void = PhysicalComponent(self.name + \" voidspace\", void, material=Void(\"vacuum\"))\n        apply_component_display_options(pc, color=BLUE_PALETTE[\"TS\"][0])\n        apply_component_display_options(void, color=(0, 0, 0))\n\n        return [pc, void]",
  "def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        duct_angled_nowall_extrude_boundary: BluemiraWire,\n        duct_straight_nowall_extrude_boundary: BluemiraWire,\n        x_straight_end: float,\n    ):\n        super().__init__(params, build_config)\n        offset_value = -(self.params.tk_ts.value + self.params.g_vv_ts.value)\n        self.duct_angled_boundary = offset_wire(\n            duct_angled_nowall_extrude_boundary, offset_value\n        )\n        self.duct_straight_boundary = offset_wire(\n            duct_straight_nowall_extrude_boundary, offset_value\n        )\n        self.duct_straight_boundary.translate((-offset_value, 0, 0))\n        self.x_straight_end = x_straight_end",
  "def build(self) -> Component:\n        \"\"\"\n        Build the vacuum vessel lower port.\n        \"\"\"\n        return self.component_tree(\n            xz=None,\n            xy=None,\n            xyz=self.build_xyz(),\n        )",
  "def build_xyz(self) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the vacuum vessel lower port in x-y-z.\n        \"\"\"\n        duct, void = build_lower_port_xyz(\n            self.duct_angled_boundary,\n            self.duct_straight_boundary,\n            self.params.n_TF.value,\n            self.params.lower_port_angle.value,\n            self.params.tk_vv_single_wall.value,\n            self.x_straight_end,\n        )\n\n        pc = PhysicalComponent(self.name, duct)\n        void = PhysicalComponent(self.name + \" voidspace\", void, material=Void(\"vacuum\"))\n        apply_component_display_options(pc, color=BLUE_PALETTE[\"VV\"][0])\n        apply_component_display_options(void, color=(0, 0, 0))\n\n        return [pc, void]",
  "class PFCoilsDesignerParams(ParameterFrame):\n    \"\"\"Parameters for :class:`PFCoilsDesigner`.\"\"\"\n\n    # TODO(hsaunders1904): docstrings for these parameters?\n    A: Parameter[float]\n    B_0: Parameter[float]\n    B_premag_stray_max: Parameter[float]\n    beta_p: Parameter[float]\n    C_Ejima: Parameter[float]\n    CS_bmax: Parameter[float]\n    CS_jmax: Parameter[float]\n    delta: Parameter[float]\n    F_cs_sepmax: Parameter[float]\n    F_cs_ztotmax: Parameter[float]\n    F_pf_zmax: Parameter[float]\n    g_cs_mod: Parameter[float]\n    I_p: Parameter[float]\n    kappa: Parameter[float]\n    l_i: Parameter[float]\n    n_CS: Parameter[int]\n    n_PF: Parameter[int]\n    PF_bmax: Parameter[float]\n    PF_jmax: Parameter[float]\n    R_0: Parameter[float]\n    r_cs_in: Parameter[float]\n    tau_flattop: Parameter[float]\n    tk_cs_casing: Parameter[float]\n    tk_cs_insulation: Parameter[float]\n    tk_pf_casing: Parameter[float]\n    tk_pf_insulation: Parameter[float]\n    pf_s_tk_plate: Parameter[float]\n    pf_s_g: Parameter[float]\n    tk_cs: Parameter[float]\n    tk_sol_ib: Parameter[float]\n    v_burn: Parameter[float]",
  "class PFCoilsDesigner(Designer[CoilSet]):\n    \"\"\"\n    Design a set of PF Coils for EUDEMO.\n\n    Parameters\n    ----------\n    params:\n        A `PFCoilsDesignerParams` instance, or a dictionary or other\n        `ParameterFrame` that can be converted to a\n        `PFCoilDesignerParams` instance.\n    reference_equilibrium:\n        Reference equilibrium to attempt to match during the design\n    build_config:\n        Build configuration dictionary for the PFCoilsDesigner\n    tf_coil_boundary:\n        Wire giving the outline of outer edge of the reactor's TF coils.\n    keep_out_zones:\n        Faces representing keep-out-zones for the PF coil geometry.\n    \"\"\"\n\n    param_cls = PFCoilsDesignerParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Dict,\n        equilibrium_manager: EquilibriumManager,\n        tf_coil_boundary: BluemiraWire,\n        keep_out_zones: Iterable[BluemiraFace],\n    ):\n        super().__init__(params, build_config)\n        self.ref_eq = equilibrium_manager.get_state(equilibrium_manager.REFERENCE)\n        self.tf_coil_boundary = tf_coil_boundary\n        self.keep_out_zones = keep_out_zones\n        self.file_path = self.build_config.get(\"file_path\", None)\n        self.eq_manager = equilibrium_manager\n\n    def read(self) -> CoilSet:\n        \"\"\"Read in a coilset.\"\"\"\n        if self.file_path is None:\n            raise ValueError(\"No file path to read from!\")\n\n        with open(self.file_path, \"r\") as file:\n            data = json.load(file)\n\n        # TODO: Load up equilibria from files and add states to manager\n\n        eqdsk = EQDSKInterface(**data[next(iter(data))])\n        return CoilSet.from_group_vecs(eqdsk)\n\n    def run(self) -> CoilSet:\n        \"\"\"Create and run the design optimisation problem.\n\n        Create an initial coilset, grid and equilibria profile, and use\n        these to solve an :class:`OptimisedPulsedCoilsetDesign` problem.\n        \"\"\"\n        coilset = self._make_coilset()\n        coil_mapper = self._make_coil_mapper(coilset)\n\n        grid = make_grid(\n            self.params.R_0.value,\n            self.params.A.value,\n            self.params.kappa.value,\n            self.build_config.get(\"grid_settings\", {}),\n        )\n        profiles = deepcopy(self.ref_eq.profiles)\n        constraints = self._make_opt_constraints(coilset)\n        opt_problem = self._make_pulsed_coilset_opt_problem(\n            coilset, grid, profiles, coil_mapper, constraints\n        )\n        bluemira_print(f\"Solving design problem: {opt_problem.__class__.__name__}\")\n        result = opt_problem.optimise(verbose=self.build_config.get(\"verbose\", False))\n        self._save_equilibria(opt_problem)\n        if self.build_config.get(\"plot\", False):\n            opt_problem.plot()\n            plt.show()\n\n        return result\n\n    def _save_equilibria(self, opt_problem):\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        result_dict = {}\n        for k, v in opt_problem.snapshots.items():\n            if k in [opt_problem.SOF, opt_problem.EOF]:\n                result_dict[k] = v.eq.to_dict()\n                result_dict[k][\"name\"] = f\"bluemira {timestamp} {k}\"\n            self.eq_manager.add_state(k, v)\n\n        json_writer(result_dict, self.file_path)\n\n    def _make_pulsed_coilset_opt_problem(\n        self, coilset, grid, profiles, position_mapper, constraints\n    ):\n        breakdown_defaults = {\n            \"param_class\": \"bluemira.equilibria.optimisation.problem::OutboardBreakdownZoneStrategy\",\n            \"problem_class\": \"bluemira.equilibria.optimisation.problem::BreakdownCOP\",\n            \"optimisation_settings\": {\n                \"algorithm_name\": \"COBYLA\",\n                \"conditions\": {\n                    \"max_eval\": 5000,\n                    \"ftol_rel\": 1e-10,\n                },\n            },\n            \"B_stray_con_tol\": 1e-6,\n            \"n_B_stray_points\": 10,\n        }\n        breakdown_settings = {\n            **breakdown_defaults,\n            **self.build_config.get(\"breakdown_settings\", {}),\n        }\n\n        eq_defaults = {\n            \"problem_class\": \"bluemira.equilibria.optimisation.problem::TikhonovCurrentCOP\",\n            \"convergence_class\": \"bluemira.equilibria.solve::DudsonConvergence\",\n            \"conv_limit\": 1e-4,\n            \"gamma\": 1e-12,\n            \"relaxation\": 0.2,\n            \"peak_PF_current_factor\": 1.5,\n            \"optimisation_settings\": {\n                \"algorithm_name\": \"SLSQP\",\n                \"conditions\": {\n                    \"max_eval\": 5000,\n                    \"ftol_rel\": 1e-6,\n                },\n            },\n        }\n        eq_settings = {\n            **eq_defaults,\n            **self.build_config.get(\"equilibrium_settings\", {}),\n        }\n        eq_converger = get_class_from_module(eq_settings[\"convergence_class\"])\n\n        pos_defaults = {\n            \"optimisation_settings\": {\n                \"algorithm_name\": \"COBYLA\",\n                \"conditions\": {\n                    \"max_eval\": 200,\n                    \"ftol_rel\": 1e-6,\n                    \"xtol_rel\": 1e-6,\n                },\n            },\n        }\n        pos_settings = {**pos_defaults, **self.build_config.get(\"position_settings\", {})}\n\n        return OptimisedPulsedCoilsetDesign(\n            self.params,\n            coilset,\n            position_mapper,\n            grid,\n            current_opt_constraints=[constraints[\"psi_inner\"]],\n            coil_constraints=constraints[\"coil_field\"],\n            equilibrium_constraints=[constraints[\"isoflux\"], constraints[\"x_point\"]],\n            profiles=profiles,\n            breakdown_settings=BreakdownCOPSettings(\n                strategy=get_class_from_module(breakdown_settings[\"param_class\"]),\n                problem=get_class_from_module(breakdown_settings[\"problem_class\"]),\n                algorithm=breakdown_settings[\"optimisation_settings\"][\"algorithm_name\"],\n                opt_conditions=breakdown_settings[\"optimisation_settings\"][\"conditions\"],\n                B_stray_con_tol=breakdown_settings[\"B_stray_con_tol\"],\n                n_B_stray_points=breakdown_settings[\"n_B_stray_points\"],\n            ),\n            equilibrium_settings=EQSettings(\n                problem=get_class_from_module(eq_settings[\"problem_class\"]),\n                convergence=eq_converger(eq_settings[\"conv_limit\"]),\n                algorithm=eq_settings[\"optimisation_settings\"][\"algorithm_name\"],\n                opt_conditions=eq_settings[\"optimisation_settings\"][\"conditions\"],\n                gamma=eq_settings[\"gamma\"],\n                relaxation=eq_settings[\"relaxation\"],\n                peak_PF_current_factor=eq_settings[\"peak_PF_current_factor\"],\n            ),\n            position_settings=PositionSettings(\n                problem=PulsedNestedPositionCOP,\n                algorithm=pos_settings[\"optimisation_settings\"][\"algorithm_name\"],\n                opt_conditions=pos_settings[\"optimisation_settings\"][\"conditions\"],\n            ),\n            limiter=None,\n        )\n\n    def _make_opt_constraints(self, coilset):\n        # TODO: Make LCFS constraints from fixed boundary k_95 / d_95 optimisation\n        kappa = self.params.kappa.value\n        kappa_ul_tweak = 0.085\n        kappa_u = (1 - kappa_ul_tweak) * kappa\n        kappa_l = (1 + kappa_ul_tweak) * kappa\n        lcfs_parameterisation = JohnerLCFS(\n            {\n                \"r_0\": {\"value\": self.params.R_0.value},\n                \"z_0\": {\"value\": 0.0},\n                \"a\": {\"value\": self.params.R_0.value / self.params.A.value},\n                \"kappa_u\": {\"value\": kappa_u},\n                \"kappa_l\": {\"value\": kappa_l},\n                \"delta_u\": {\"value\": self.params.delta.value},\n                \"delta_l\": {\"value\": self.params.delta.value},\n                \"phi_u_neg\": {\"value\": 0.0},\n                \"phi_u_pos\": {\"value\": 0.0},\n                \"phi_l_neg\": {\"value\": 45.0},\n                \"phi_l_pos\": {\"value\": 30.0},\n            }\n        )\n        lcfs = lcfs_parameterisation.create_shape().discretize(byedges=True, ndiscr=50)\n        x_lcfs, z_lcfs = lcfs.x, lcfs.z\n        arg_inner = np.argmin(x_lcfs)\n        arg_xp = np.argmin(z_lcfs)\n\n        isoflux = IsofluxConstraint(\n            x_lcfs,\n            z_lcfs,\n            x_lcfs[arg_inner],\n            z_lcfs[arg_inner],\n            tolerance=1.0,\n            constraint_value=0.0,\n        )\n        psi_inner = PsiConstraint(\n            x_lcfs[arg_inner], z_lcfs[arg_inner], target_value=0.0, tolerance=1e-3\n        )\n        x_point = FieldNullConstraint(x_lcfs[arg_xp], z_lcfs[arg_xp], tolerance=1e-4)\n        coil_field_constraints = [\n            CoilFieldConstraints(coilset, coilset.b_max, tolerance=1e-6),\n            CoilForceConstraints(\n                coilset,\n                self.params.F_pf_zmax.value,\n                self.params.F_cs_ztotmax.value,\n                self.params.F_cs_sepmax.value,\n                tolerance=1e-3,\n            ),\n        ]\n        return {\n            \"isoflux\": isoflux,\n            \"psi_inner\": psi_inner,\n            \"x_point\": x_point,\n            \"coil_field\": coil_field_constraints,\n        }\n\n    def _make_coil_mapper(self, coilset):\n        # Get an offset from the TF that corresponds to a PF coil half-width of a\n        # current equal to Ip\n        # TODO may need to thread this better!\n        peak_PF_current_factor = 1.5\n        offset_value = 0.5 * np.sqrt(\n            peak_PF_current_factor * self.params.I_p.value / self.params.PF_jmax.value\n        )\n        offset_value += np.sqrt(2) * (\n            self.params.tk_pf_casing.value\n            + self.params.tk_pf_insulation.value\n            + self.params.pf_s_g.value\n            + self.params.pf_s_tk_plate.value\n        )\n        pf_coil_path = make_pf_coil_path(self.tf_coil_boundary, offset_value)\n        pf_coils = coilset.get_coiltype(\"PF\")._coils\n        return make_coil_mapper(pf_coil_path, self.keep_out_zones, pf_coils)\n\n    def _make_coilset(self):\n        return make_coilset(\n            tf_boundary=self.tf_coil_boundary,\n            R_0=self.params.R_0.value,\n            kappa=self.params.kappa.value,\n            delta=self.params.delta.value,\n            r_cs=self.params.r_cs_in.value + 0.5 * self.params.tk_cs.value,\n            tk_cs=0.5 * self.params.tk_cs.value,\n            g_cs=self.params.g_cs_mod.value,\n            tk_cs_ins=self.params.tk_cs_insulation.value,\n            tk_cs_cas=self.params.tk_cs_casing.value,\n            n_CS=self.params.n_CS.value,\n            n_PF=self.params.n_PF.value,\n            CS_jmax=self.params.CS_jmax.value,\n            CS_bmax=self.params.CS_bmax.value,\n            PF_jmax=self.params.PF_jmax.value,\n            PF_bmax=self.params.PF_bmax.value,\n        )",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Dict,\n        equilibrium_manager: EquilibriumManager,\n        tf_coil_boundary: BluemiraWire,\n        keep_out_zones: Iterable[BluemiraFace],\n    ):\n        super().__init__(params, build_config)\n        self.ref_eq = equilibrium_manager.get_state(equilibrium_manager.REFERENCE)\n        self.tf_coil_boundary = tf_coil_boundary\n        self.keep_out_zones = keep_out_zones\n        self.file_path = self.build_config.get(\"file_path\", None)\n        self.eq_manager = equilibrium_manager",
  "def read(self) -> CoilSet:\n        \"\"\"Read in a coilset.\"\"\"\n        if self.file_path is None:\n            raise ValueError(\"No file path to read from!\")\n\n        with open(self.file_path, \"r\") as file:\n            data = json.load(file)\n\n        # TODO: Load up equilibria from files and add states to manager\n\n        eqdsk = EQDSKInterface(**data[next(iter(data))])\n        return CoilSet.from_group_vecs(eqdsk)",
  "def run(self) -> CoilSet:\n        \"\"\"Create and run the design optimisation problem.\n\n        Create an initial coilset, grid and equilibria profile, and use\n        these to solve an :class:`OptimisedPulsedCoilsetDesign` problem.\n        \"\"\"\n        coilset = self._make_coilset()\n        coil_mapper = self._make_coil_mapper(coilset)\n\n        grid = make_grid(\n            self.params.R_0.value,\n            self.params.A.value,\n            self.params.kappa.value,\n            self.build_config.get(\"grid_settings\", {}),\n        )\n        profiles = deepcopy(self.ref_eq.profiles)\n        constraints = self._make_opt_constraints(coilset)\n        opt_problem = self._make_pulsed_coilset_opt_problem(\n            coilset, grid, profiles, coil_mapper, constraints\n        )\n        bluemira_print(f\"Solving design problem: {opt_problem.__class__.__name__}\")\n        result = opt_problem.optimise(verbose=self.build_config.get(\"verbose\", False))\n        self._save_equilibria(opt_problem)\n        if self.build_config.get(\"plot\", False):\n            opt_problem.plot()\n            plt.show()\n\n        return result",
  "def _save_equilibria(self, opt_problem):\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        result_dict = {}\n        for k, v in opt_problem.snapshots.items():\n            if k in [opt_problem.SOF, opt_problem.EOF]:\n                result_dict[k] = v.eq.to_dict()\n                result_dict[k][\"name\"] = f\"bluemira {timestamp} {k}\"\n            self.eq_manager.add_state(k, v)\n\n        json_writer(result_dict, self.file_path)",
  "def _make_pulsed_coilset_opt_problem(\n        self, coilset, grid, profiles, position_mapper, constraints\n    ):\n        breakdown_defaults = {\n            \"param_class\": \"bluemira.equilibria.optimisation.problem::OutboardBreakdownZoneStrategy\",\n            \"problem_class\": \"bluemira.equilibria.optimisation.problem::BreakdownCOP\",\n            \"optimisation_settings\": {\n                \"algorithm_name\": \"COBYLA\",\n                \"conditions\": {\n                    \"max_eval\": 5000,\n                    \"ftol_rel\": 1e-10,\n                },\n            },\n            \"B_stray_con_tol\": 1e-6,\n            \"n_B_stray_points\": 10,\n        }\n        breakdown_settings = {\n            **breakdown_defaults,\n            **self.build_config.get(\"breakdown_settings\", {}),\n        }\n\n        eq_defaults = {\n            \"problem_class\": \"bluemira.equilibria.optimisation.problem::TikhonovCurrentCOP\",\n            \"convergence_class\": \"bluemira.equilibria.solve::DudsonConvergence\",\n            \"conv_limit\": 1e-4,\n            \"gamma\": 1e-12,\n            \"relaxation\": 0.2,\n            \"peak_PF_current_factor\": 1.5,\n            \"optimisation_settings\": {\n                \"algorithm_name\": \"SLSQP\",\n                \"conditions\": {\n                    \"max_eval\": 5000,\n                    \"ftol_rel\": 1e-6,\n                },\n            },\n        }\n        eq_settings = {\n            **eq_defaults,\n            **self.build_config.get(\"equilibrium_settings\", {}),\n        }\n        eq_converger = get_class_from_module(eq_settings[\"convergence_class\"])\n\n        pos_defaults = {\n            \"optimisation_settings\": {\n                \"algorithm_name\": \"COBYLA\",\n                \"conditions\": {\n                    \"max_eval\": 200,\n                    \"ftol_rel\": 1e-6,\n                    \"xtol_rel\": 1e-6,\n                },\n            },\n        }\n        pos_settings = {**pos_defaults, **self.build_config.get(\"position_settings\", {})}\n\n        return OptimisedPulsedCoilsetDesign(\n            self.params,\n            coilset,\n            position_mapper,\n            grid,\n            current_opt_constraints=[constraints[\"psi_inner\"]],\n            coil_constraints=constraints[\"coil_field\"],\n            equilibrium_constraints=[constraints[\"isoflux\"], constraints[\"x_point\"]],\n            profiles=profiles,\n            breakdown_settings=BreakdownCOPSettings(\n                strategy=get_class_from_module(breakdown_settings[\"param_class\"]),\n                problem=get_class_from_module(breakdown_settings[\"problem_class\"]),\n                algorithm=breakdown_settings[\"optimisation_settings\"][\"algorithm_name\"],\n                opt_conditions=breakdown_settings[\"optimisation_settings\"][\"conditions\"],\n                B_stray_con_tol=breakdown_settings[\"B_stray_con_tol\"],\n                n_B_stray_points=breakdown_settings[\"n_B_stray_points\"],\n            ),\n            equilibrium_settings=EQSettings(\n                problem=get_class_from_module(eq_settings[\"problem_class\"]),\n                convergence=eq_converger(eq_settings[\"conv_limit\"]),\n                algorithm=eq_settings[\"optimisation_settings\"][\"algorithm_name\"],\n                opt_conditions=eq_settings[\"optimisation_settings\"][\"conditions\"],\n                gamma=eq_settings[\"gamma\"],\n                relaxation=eq_settings[\"relaxation\"],\n                peak_PF_current_factor=eq_settings[\"peak_PF_current_factor\"],\n            ),\n            position_settings=PositionSettings(\n                problem=PulsedNestedPositionCOP,\n                algorithm=pos_settings[\"optimisation_settings\"][\"algorithm_name\"],\n                opt_conditions=pos_settings[\"optimisation_settings\"][\"conditions\"],\n            ),\n            limiter=None,\n        )",
  "def _make_opt_constraints(self, coilset):\n        # TODO: Make LCFS constraints from fixed boundary k_95 / d_95 optimisation\n        kappa = self.params.kappa.value\n        kappa_ul_tweak = 0.085\n        kappa_u = (1 - kappa_ul_tweak) * kappa\n        kappa_l = (1 + kappa_ul_tweak) * kappa\n        lcfs_parameterisation = JohnerLCFS(\n            {\n                \"r_0\": {\"value\": self.params.R_0.value},\n                \"z_0\": {\"value\": 0.0},\n                \"a\": {\"value\": self.params.R_0.value / self.params.A.value},\n                \"kappa_u\": {\"value\": kappa_u},\n                \"kappa_l\": {\"value\": kappa_l},\n                \"delta_u\": {\"value\": self.params.delta.value},\n                \"delta_l\": {\"value\": self.params.delta.value},\n                \"phi_u_neg\": {\"value\": 0.0},\n                \"phi_u_pos\": {\"value\": 0.0},\n                \"phi_l_neg\": {\"value\": 45.0},\n                \"phi_l_pos\": {\"value\": 30.0},\n            }\n        )\n        lcfs = lcfs_parameterisation.create_shape().discretize(byedges=True, ndiscr=50)\n        x_lcfs, z_lcfs = lcfs.x, lcfs.z\n        arg_inner = np.argmin(x_lcfs)\n        arg_xp = np.argmin(z_lcfs)\n\n        isoflux = IsofluxConstraint(\n            x_lcfs,\n            z_lcfs,\n            x_lcfs[arg_inner],\n            z_lcfs[arg_inner],\n            tolerance=1.0,\n            constraint_value=0.0,\n        )\n        psi_inner = PsiConstraint(\n            x_lcfs[arg_inner], z_lcfs[arg_inner], target_value=0.0, tolerance=1e-3\n        )\n        x_point = FieldNullConstraint(x_lcfs[arg_xp], z_lcfs[arg_xp], tolerance=1e-4)\n        coil_field_constraints = [\n            CoilFieldConstraints(coilset, coilset.b_max, tolerance=1e-6),\n            CoilForceConstraints(\n                coilset,\n                self.params.F_pf_zmax.value,\n                self.params.F_cs_ztotmax.value,\n                self.params.F_cs_sepmax.value,\n                tolerance=1e-3,\n            ),\n        ]\n        return {\n            \"isoflux\": isoflux,\n            \"psi_inner\": psi_inner,\n            \"x_point\": x_point,\n            \"coil_field\": coil_field_constraints,\n        }",
  "def _make_coil_mapper(self, coilset):\n        # Get an offset from the TF that corresponds to a PF coil half-width of a\n        # current equal to Ip\n        # TODO may need to thread this better!\n        peak_PF_current_factor = 1.5\n        offset_value = 0.5 * np.sqrt(\n            peak_PF_current_factor * self.params.I_p.value / self.params.PF_jmax.value\n        )\n        offset_value += np.sqrt(2) * (\n            self.params.tk_pf_casing.value\n            + self.params.tk_pf_insulation.value\n            + self.params.pf_s_g.value\n            + self.params.pf_s_tk_plate.value\n        )\n        pf_coil_path = make_pf_coil_path(self.tf_coil_boundary, offset_value)\n        pf_coils = coilset.get_coiltype(\"PF\")._coils\n        return make_coil_mapper(pf_coil_path, self.keep_out_zones, pf_coils)",
  "def _make_coilset(self):\n        return make_coilset(\n            tf_boundary=self.tf_coil_boundary,\n            R_0=self.params.R_0.value,\n            kappa=self.params.kappa.value,\n            delta=self.params.delta.value,\n            r_cs=self.params.r_cs_in.value + 0.5 * self.params.tk_cs.value,\n            tk_cs=0.5 * self.params.tk_cs.value,\n            g_cs=self.params.g_cs_mod.value,\n            tk_cs_ins=self.params.tk_cs_insulation.value,\n            tk_cs_cas=self.params.tk_cs_casing.value,\n            n_CS=self.params.n_CS.value,\n            n_PF=self.params.n_PF.value,\n            CS_jmax=self.params.CS_jmax.value,\n            CS_bmax=self.params.CS_bmax.value,\n            PF_jmax=self.params.PF_jmax.value,\n            PF_bmax=self.params.PF_bmax.value,\n        )",
  "class PFCoil(ComponentManager):\n    \"\"\"\n    Wrapper around the PF Coil component tree.\n    \"\"\"\n\n    def __init__(self, component, coilset):\n        super().__init__(component)\n        self._coilset = coilset\n\n    @property\n    def coilset(self):\n        \"\"\"\n        The poloidal coilset\n        \"\"\"\n        return self._coilset\n\n    def xz_boundary(self):\n        \"\"\"\n        Boundaries of the coils in xz\n        \"\"\"\n        return self.PF_xz_boundary() + self.CS_xz_boundary()\n\n    def PF_xz_boundary(self):\n        \"\"\"\n        Boundaries of the PF coils in xz\n        \"\"\"\n        return [\n            pf.get_component(\"Casing\").shape.boundary[0]\n            for pf in self.component()\n            .get_component(\"PF coils\")\n            .get_component(\"xz\", first=False)\n        ]\n\n    def CS_xz_boundary(self):\n        \"\"\"\n        Boundaries of the CS coils in xz\n        \"\"\"\n        return [\n            pf.get_component(\"Casing\").shape.boundary[0]\n            for pf in self.component()\n            .get_component(\"CS coils\")\n            .get_component(\"xz\", first=False)\n        ]",
  "def __init__(self, component, coilset):\n        super().__init__(component)\n        self._coilset = coilset",
  "def coilset(self):\n        \"\"\"\n        The poloidal coilset\n        \"\"\"\n        return self._coilset",
  "def xz_boundary(self):\n        \"\"\"\n        Boundaries of the coils in xz\n        \"\"\"\n        return self.PF_xz_boundary() + self.CS_xz_boundary()",
  "def PF_xz_boundary(self):\n        \"\"\"\n        Boundaries of the PF coils in xz\n        \"\"\"\n        return [\n            pf.get_component(\"Casing\").shape.boundary[0]\n            for pf in self.component()\n            .get_component(\"PF coils\")\n            .get_component(\"xz\", first=False)\n        ]",
  "def CS_xz_boundary(self):\n        \"\"\"\n        Boundaries of the CS coils in xz\n        \"\"\"\n        return [\n            pf.get_component(\"Casing\").shape.boundary[0]\n            for pf in self.component()\n            .get_component(\"CS coils\")\n            .get_component(\"xz\", first=False)\n        ]",
  "class PFCoilsBuilderParams(ParameterFrame):\n    \"\"\"\n    Parameters for the `PFCoilsBuilder` class.\n    \"\"\"\n\n    n_TF: Parameter[int]\n    tk_pf_insulation: Parameter[float]\n    tk_pf_casing: Parameter[float]\n    tk_cs_insulation: Parameter[float]\n    tk_cs_casing: Parameter[float]\n    r_pf_corner: Parameter[float]\n    r_cs_corner: Parameter[float]",
  "def build_pf_coils_component(params, build_config, coilset):\n    \"\"\"\n    Build the PF coils component\n    \"\"\"\n    params = make_parameter_frame(params, PFCoilsBuilderParams)\n\n    wires = []\n    for name in coilset.name:\n        coil = coilset[name]\n        coil_type = coil.ctype\n        r_corner = (\n            params.r_pf_corner.value if coil_type == \"PF\" else params.r_cs_corner.value\n        )\n        if not (coil.dx == 0 or coil.dz == 0):\n            wires.append(\n                (\n                    PFCoilPictureFrame(\n                        {\"r_corner\": {\"value\": r_corner, \"unit\": \"m\"}}, coil\n                    ),\n                    coil_type,\n                    name,\n                )\n            )\n        else:\n            bluemira_warn(f\"Coil {name} has no size\")\n\n    pf_builders = []\n    cs_builders = []\n    for designer, coil_type, coil_name in wires:\n        tk_ins = (\n            params.tk_pf_insulation.value\n            if coil_type.name == \"PF\"\n            else params.tk_cs_insulation.value\n        )\n        tk_case = (\n            params.tk_pf_casing.value\n            if coil_type.name == \"PF\"\n            else params.tk_cs_casing.value\n        )\n        bc = {\n            **build_config,\n            \"name\": coil_name,\n        }\n        builder = PFCoilBuilder(\n            {\n                \"n_TF\": {\"value\": params.n_TF.value, \"unit\": params.n_TF.unit},\n                \"tk_insulation\": {\"value\": tk_ins, \"unit\": \"m\"},\n                \"tk_casing\": {\"value\": tk_case, \"unit\": \"m\"},\n                \"ctype\": {\"value\": coil_type.name, \"unit\": \"\"},\n            },\n            bc,\n            designer.execute(),\n        )\n        if coil_type.name == \"PF\":\n            pf_builders.append(builder)\n        else:\n            cs_builders.append(builder)\n\n    pf_coils = Component(\n        \"PF coils\", children=[builder.build() for builder in pf_builders]\n    )\n    cs_coils = Component(\n        \"CS coils\", children=[builder.build() for builder in cs_builders]\n    )\n\n    return Component(\"Poloidal Coils\", children=[pf_coils, cs_coils])",
  "def make_solenoid(\n    r_cs: float,\n    tk_cs: float,\n    z_min: float,\n    z_max: float,\n    g_cs: float,\n    tk_cs_ins: float,\n    tk_cs_cas: float,\n    n_CS: int,\n) -> List[Coil]:\n    \"\"\"\n    Make a set of solenoid coils in an EU-DEMO fashion. If n_CS is odd, the central\n    module is twice the size of the others. If n_CS is even, all the modules are the\n    same size.\n\n    Parameters\n    ----------\n    r_cs:\n        Radius of the solenoid\n    tk_cs:\n        Half-thickness of the solenoid in the radial direction (including insulation and\n        casing)\n    z_min:\n        Minimum vertical position of the solenoid\n    z_max:\n        Maximum vertical position of the solenoid\n    g_cs:\n        Gap between modules\n    tk_cs_ins:\n        Insulation thickness around modules\n    tk_cs_cas:\n        Casing thickness around modules\n    n_CS:\n        Number of modules in the solenoid\n\n    Returns\n    -------\n    List of solenoid coil(s)\n    \"\"\"\n\n    def make_CS_coil(z_coil, dz_coil, i):\n        return Coil(\n            r_cs,\n            z_coil,\n            current=0,\n            dx=tk_cs - tk_inscas,\n            dz=dz_coil,\n            ctype=\"CS\",\n            name=f\"CS_{i+1}\",\n        )\n\n    if z_max < z_min:\n        z_min, z_max = z_max, z_min\n    if np.isclose(z_max, z_min):\n        raise BuilderError(f\"Cannot make a solenoid with z_min==z_max=={z_min}\")\n\n    total_height = z_max - z_min\n    tk_inscas = tk_cs_ins + tk_cs_cas\n    total_gaps = (n_CS - 1) * g_cs + n_CS * 2 * tk_inscas\n    if total_gaps >= total_height:\n        raise BuilderError(\n            \"Cannot make a solenoid where the gaps and insulation + casing are larger than the height available.\"\n        )\n\n    coils = []\n    if n_CS == 1:\n        # Single CS module solenoid (no gaps)\n        module_height = total_height - 2 * tk_inscas\n        coil = make_CS_coil(0.5 * total_height, 0.5 * module_height, 0)\n        coils.append(coil)\n\n    elif n_CS % 2 == 0:\n        # Equally-spaced CS modules for even numbers of CS coils\n        module_height = (total_height - total_gaps) / n_CS\n        dz_coil = 0.5 * module_height\n        z_iter = z_max\n        for i in range(n_CS):\n            z_coil = z_iter - tk_inscas - dz_coil\n            coil = make_CS_coil(z_coil, dz_coil, i)\n            coils.append(coil)\n            z_iter = z_coil - dz_coil - tk_inscas - g_cs\n\n    else:\n        # Odd numbers of modules -> Make a central module that is twice the size of the\n        # others.\n        module_height = (total_height - total_gaps) / (n_CS + 1)\n        z_iter = z_max\n        for i in range(n_CS):\n            if i == n_CS // 2:\n                # Central module\n                dz_coil = module_height\n                z_coil = z_iter - tk_inscas - dz_coil\n\n            else:\n                # All other modules\n                dz_coil = 0.5 * module_height\n                z_coil = z_iter - tk_inscas - dz_coil\n\n            coil = make_CS_coil(z_coil, dz_coil, i)\n            coils.append(coil)\n            z_iter = z_coil - dz_coil - tk_inscas - g_cs\n\n    return coils",
  "def _get_intersections_from_angles(boundary, ref_x, ref_z, angles):\n    n_angles = len(angles)\n    x_c, z_c = np.zeros(n_angles), np.zeros(n_angles)\n    for i, angle in enumerate(angles):\n        line = make_polygon(\n            [\n                [ref_x, ref_x + VERY_BIG * np.cos(angle)],\n                [0, 0],\n                [ref_z, ref_z + VERY_BIG * np.sin(angle)],\n            ]\n        )\n        _, intersection = distance_to(boundary, line)\n        x_c[i], _, z_c[i] = intersection[0][0]\n    return x_c, z_c",
  "def make_PF_coil_positions(tf_boundary, n_PF, R_0, kappa, delta):\n    \"\"\"\n    Make a set of PF coil positions crudely with respect to the intended plasma\n    shape.\n    \"\"\"\n    # Project plasma centroid through plasma upper and lower extrema\n    angle_upper = np.arctan2(kappa, -delta)\n    angle_lower = np.arctan2(-kappa, -delta)\n    scale = 1.1\n\n    angles = np.linspace(scale * angle_upper, scale * angle_lower, n_PF)\n    return _get_intersections_from_angles(tf_boundary, R_0, 0.0, angles)",
  "def make_coilset(\n    tf_boundary: BluemiraWire,\n    R_0: float,\n    kappa: float,\n    delta: float,\n    r_cs: float,\n    tk_cs: float,\n    g_cs: float,\n    tk_cs_ins: float,\n    tk_cs_cas: float,\n    n_CS: int,\n    n_PF: int,\n    CS_jmax: float,\n    CS_bmax: float,\n    PF_jmax: float,\n    PF_bmax: float,\n) -> CoilSet:\n    \"\"\"\n    Make an initial EU-DEMO-like coilset.\n    \"\"\"\n    bb = tf_boundary.bounding_box\n    z_min = bb.z_min\n    z_max = bb.z_max\n    solenoid = make_solenoid(r_cs, tk_cs, z_min, z_max, g_cs, tk_cs_ins, tk_cs_cas, n_CS)\n    for s in solenoid:\n        s.fix_size()\n\n    tf_track = offset_wire(tf_boundary, 1)\n    x_c, z_c = make_PF_coil_positions(\n        tf_track,\n        n_PF,\n        R_0,\n        kappa,\n        delta,\n    )\n    pf_coils = []\n    for i, (x, z) in enumerate(zip(x_c, z_c)):\n        coil = Coil(\n            x,\n            z,\n            current=0,\n            ctype=\"PF\",\n            name=f\"PF_{i+1}\",\n            j_max=PF_jmax,\n            b_max=PF_bmax,\n        )\n        pf_coils.append(coil)\n    coilset = CoilSet(*pf_coils + solenoid, control_names=True)\n    coilset.assign_material(\"PF\", j_max=PF_jmax, b_max=PF_bmax)\n    coilset.assign_material(\"CS\", j_max=CS_jmax, b_max=CS_bmax)\n    return coilset",
  "def make_reference_coilset(\n    tf_track: BluemiraWire,\n    lcfs_shape: BluemiraWire,\n    r_cs: float,\n    tk_cs: float,\n    g_cs_mod: float,\n    tk_cs_casing: float,\n    tk_cs_insulation: float,\n    n_CS: int,\n    n_PF: int,\n) -> CoilSet:\n    \"\"\"\n    Make a reference coilset.\n    \"\"\"\n    bb = tf_track.bounding_box\n    z_min = bb.z_min\n    z_max = bb.z_max\n    solenoid = make_solenoid(\n        r_cs,\n        tk_cs,\n        z_min,\n        z_max,\n        g_cs_mod,\n        tk_cs_ins=tk_cs_insulation,\n        tk_cs_cas=tk_cs_casing,\n        n_CS=n_CS,\n    )\n\n    lcfs_coords = lcfs_shape.discretize(byedges=True)\n    arg_z_max = np.argmax(lcfs_coords.z)\n    arg_z_min = np.argmin(lcfs_coords.z)\n\n    r_mid = 0.5 * (np.min(lcfs_coords.x) + np.max(lcfs_coords.x))\n    d_delta_u = lcfs_coords.x[arg_z_max] - r_mid\n    d_kappa_u = lcfs_coords.z[arg_z_max]\n    d_delta_l = lcfs_coords.x[arg_z_min] - r_mid\n    d_kappa_l = lcfs_coords.z[arg_z_min]\n\n    angle_upper = np.arctan2(d_kappa_u, d_delta_u)\n    angle_lower = np.arctan2(d_kappa_l, d_delta_l)\n    angles = np.linspace(angle_upper, angle_lower, n_PF)\n    x_c, z_c = _get_intersections_from_angles(tf_track, r_mid, 0.0, angles)\n\n    pf_coils = []\n    for i, (x, z) in enumerate(zip(x_c, z_c)):\n        coil = Coil(\n            x,\n            z,\n            current=0,\n            ctype=\"PF\",\n            name=f\"PF_{i+1}\",\n            j_max=100.0e6,\n        )\n        pf_coils.append(coil)\n    return CoilSet(*pf_coils + solenoid, control_names=True)",
  "def make_coil_mapper(\n    track: BluemiraWire, exclusion_zones: List[BluemiraFace], coils: List[Coil]\n) -> PositionMapper:\n    \"\"\"\n    Make a PositionMapper for the given coils.\n\n    Break a track down into individual interpolator segments\n    incorporating exclusion zones and mapping tracks to coils.\n\n    Parameters\n    ----------\n    track:\n        Full length interpolator track for PF coils\n    exclusion_zones:\n        List of exclusion zones\n    coils:\n        List of coils\n\n    Returns\n    -------\n    Position mapper for coil position interpolation\n\n    Notes\n    -----\n    TODO use coilset directly instead of list of coils\n    \"\"\"\n    # Break down the track into subsegments\n    if exclusion_zones:\n        segments = boolean_cut(track, exclusion_zones)\n    else:\n        segments = [track]\n\n    # Sort the coils into the segments\n    coil_bins = [[] for _ in range(len(segments))]\n    for i, coil in enumerate(coils):\n        distances = [distance_to([coil.x, 0, coil.z], seg)[0] for seg in segments]\n        coil_bins[np.argmin(distances)].append(coil)\n\n    # Check if multiple coils are on the same segment and split the segments and make\n    # PathInterpolators\n    interpolator_dict = {}\n    for segment, _bin in zip(segments, coil_bins):\n        if len(_bin) < 1:\n            bluemira_warn(\"There is a segment of the track which has no coils on it.\")\n        elif len(_bin) == 1:\n            coil = _bin[0]\n            interpolator_dict[coil.name] = PathInterpolator(segment)\n        else:\n            coils = _bin\n            l_values = np.array(\n                [segment.parameter_at([c.x, 0, c.z], tolerance=VERY_BIG) for c in coils]\n            )\n            idx = np.argsort(l_values)\n            l_values = l_values[idx]\n            split_values = l_values[:-1] + 0.5 * np.diff(l_values)\n            split_positions = [segment.value_at(alpha=split) for split in split_values]\n\n            sorted_coils = []\n            for i in idx:\n                sorted_coils.append(coils[i])\n            coils = sorted_coils\n\n            sub_segs = _split_segment(segment, split_positions)\n\n            for coil, sub_seg in zip(coils, sub_segs):\n                interpolator_dict[coil.name] = PathInterpolator(sub_seg)\n\n    return PositionMapper(interpolator_dict)",
  "def _split_segment(segment, split_positions):\n    \"\"\"\n    Split a segment into sub-segments at various split positions\n    \"\"\"\n    sub_segs = []\n    for _, split_pos in enumerate(split_positions):\n        split = segment.parameter_at(split_pos, tolerance=10 * EPS)\n        sub_seg_1, segment = split_wire(\n            segment, segment.value_at(alpha=split), tolerance=10 * EPS\n        )\n        if sub_seg_1:\n            sub_segs.append(sub_seg_1)\n        else:\n            bluemira_warn(\"Sub-segment of 0 length!\")\n    sub_segs.append(segment)\n    return sub_segs",
  "def make_pf_coil_path(tf_boundary: BluemiraWire, offset_value: float) -> BluemiraWire:\n    \"\"\"\n    Make an open wire along which the PF coils can move.\n\n    Parameters\n    ----------\n    tf_boundary:\n        Outside edge of the TF coil in the x-z plane\n    offset_value:\n        Offset value from the TF coil edge\n\n    Returns\n    -------\n    Path along which the PF coil centroids should be positioned\n    \"\"\"\n    tf_offset = offset_wire(tf_boundary, offset_value)\n\n    # Find top-left and bottom-left \"corners\"\n    coordinates = tf_offset.discretize(byedges=True, ndiscr=200)\n    x_min = np.min(coordinates.x)\n    z_min, z_max = 0.0, 0.0\n    eps = 0.0\n    while np.isclose(z_min, z_max):\n        # This is unlikely, but if so, shifting x_min a little ensures the boolean cut\n        # can be performed and that an open wire will be returned\n        idx_inner = np.where(np.isclose(coordinates.x, x_min))[0]\n        z_min = np.min(coordinates.z[idx_inner])\n        z_max = np.max(coordinates.z[idx_inner])\n        x_min += eps\n        eps += 1e-3\n\n    cutter = BluemiraFace(\n        make_polygon(\n            {\"x\": [0, x_min, x_min, 0], \"z\": [z_min, z_min, z_max, z_max]}, closed=True\n        )\n    )\n\n    result = boolean_cut(tf_offset, cutter)\n    if len(result) > 1:\n        bluemira_warn(\n            \"Boolean cut of the TF boundary resulted in more than one wire.. returning the longest one. Fingers crossed.\"\n        )\n        result.sort(key=lambda wire: -wire.length)\n    pf_coil_path = result[0]\n    return pf_coil_path",
  "def make_CS_coil(z_coil, dz_coil, i):\n        return Coil(\n            r_cs,\n            z_coil,\n            current=0,\n            dx=tk_cs - tk_inscas,\n            dz=dz_coil,\n            ctype=\"CS\",\n            name=f\"CS_{i+1}\",\n        )",
  "class BlanketDesignerParams(ParameterFrame):\n    \"\"\"EUDEMO blanket designer parameters for :class:`BlanketDesigner`.\"\"\"\n\n    n_TF: Parameter[int]\n    \"\"\"Number of TF coils.\"\"\"\n    n_bb_inboard: Parameter[int]\n    \"\"\"Number of inboard blanket segments.\"\"\"\n    n_bb_outboard: Parameter[int]\n    \"\"\"Number of outboard blanket segments.\"\"\"\n    c_rm: Parameter[float]\n    \"\"\"Remote maintenance clearance [m].\"\"\"\n    fw_a_max: Parameter[float]\n    \"\"\"Maximum angle of rotation between adjacent panels [degrees].\"\"\"\n    fw_dL_min: Parameter[float]  # noqa: N815\n    \"\"\"Minimum length for an individual panel [m].\"\"\"",
  "class BlanketSegments:\n    \"\"\"Container for parts of a blanket.\"\"\"\n\n    inboard: BluemiraFace\n    outboard: BluemiraFace\n    inboard_boundary: BluemiraWire\n    outboard_boundary: BluemiraWire",
  "class BlanketDesigner(Designer[Tuple[BluemiraFace, BluemiraFace]]):\n    \"\"\"\n    Designer for an EUDEMO-style blanket.\n\n    This takes a blanket boundary and silhouette, cuts them into inboard\n    and outboard segments, and panels each segment.\n\n    Parameters\n    ----------\n    params:\n        The parameters for the designer.\n        See :class:`.BlanketDesignerParams` for more details.\n    blanket_boundary:\n        The wire defining the inner boundary of the blanket.\n        This should be an open wire, where the start and end points\n        share the same z-coordinate (i.e., an open loop).\n    blanket_silhouette:\n        A face defining the poloidal shape of the blanket.\n        The inner boundary of this face *must* be the same as the\n        :obj:`blanket_boundary`. It's difficult to reverse engineer the\n        wire from the face, so both are required.\n    r_inner_cut:\n        The x coordinate at which to cut the blanket into segments.\n        Note that this is the coordinate of the x-most end of the cut on\n        the inner wire of the boundary, not the center.\n    cut_angle:\n        The angle at which to segment the blanket [degrees].\n        A positive angle will result in a downward top-to-bottom slope\n        on the inboard.\n    \"\"\"\n\n    param_cls = BlanketDesignerParams\n    params: BlanketDesignerParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        blanket_boundary: BluemiraWire,\n        blanket_silhouette: BluemiraFace,\n        r_inner_cut: float,\n        cut_angle: float,\n        build_config: Optional[Dict] = None,\n    ):\n        super().__init__(params, build_config)\n        self.boundary = blanket_boundary\n        self.silhouette = blanket_silhouette\n        self.r_inner_cut = r_inner_cut\n        if abs(cut_angle) >= 90:\n            raise ValueError(\n                \"Cannot cut boundary silhouette at an angle greater than 90\u00b0.\"\n            )\n        self.cut_angle = cut_angle\n\n    def run(self) -> Tuple[BluemiraFace, BluemiraFace]:\n        \"\"\"Run the blanket design problem.\"\"\"\n        segments = self.segment_blanket()\n        # Inboard\n        ib_panels = self.panel_boundary(segments.inboard_boundary)\n        ib_panels_face = BluemiraFace(ib_panels)\n        cut_ib = boolean_cut(segments.inboard, [ib_panels_face])[0]\n        # Outboard\n        ob_panels = self.panel_boundary(segments.outboard_boundary)\n        ob_panels_face = BluemiraFace(ob_panels)\n        cut_ob = boolean_cut(segments.outboard, [ob_panels_face])[0]\n        return cut_ib, cut_ob\n\n    def segment_blanket(self) -> BlanketSegments:\n        \"\"\"\n        Segment the breeding blanket's poloidal cross-section.\n\n        Segment it into inboard and outboard silhouettes.\n\n        Returns\n        -------\n        An instance of :class:`.BlanketSegments` containing the\n        blanket segment geometries.\n        \"\"\"\n        cut_zone = self._make_cutting_face()\n        ib_face, ob_face = self._cut_geom(self.silhouette, cut_zone)\n        ib_bound, ob_bound = self._cut_geom(self.boundary, cut_zone)\n        return BlanketSegments(\n            inboard=ib_face,\n            outboard=ob_face,\n            inboard_boundary=ib_bound,\n            outboard_boundary=ob_bound,\n        )\n\n    def panel_boundary(self, boundary: BluemiraWire) -> BluemiraWire:\n        \"\"\"Create the panel shapes for the given boundary.\"\"\"\n        panel_coords = PanellingDesigner(self.params, boundary).run()\n        return make_polygon(\n            {\"x\": panel_coords[0], \"z\": panel_coords[1]}, label=\"panels\", closed=True\n        )\n\n    def _make_cutting_face(self) -> BluemiraFace:\n        \"\"\"Make a face that can be used to cut the blanket into inboard & outboard.\"\"\"\n        p0 = get_inner_cut_point(self.silhouette, self.r_inner_cut)\n        p1 = [p0[0], 0, p0[2] + VERY_BIG]\n        p2 = [p0[0] - self.params.c_rm.value, 0, p1[2]]\n        p3 = [p2[0], 0, p0[2] - np.sqrt(2) * self.params.c_rm.value]\n        cut_zone = BluemiraFace(make_polygon([p0, p1, p2, p3], closed=True))\n        if self.cut_angle != 0.0:\n            cut_zone.rotate(base=p0, direction=(0, -1, 0), degree=self.cut_angle)\n        return cut_zone\n\n    _GeomT = TypeVar(\"_GeomT\", BluemiraFace, BluemiraWire)\n\n    def _cut_geom(self, geom: _GeomT, cut_tool: BluemiraFace) -> Tuple[_GeomT, _GeomT]:\n        \"\"\"Cut the given geometry into two using the given cutting tool.\"\"\"\n        parts = boolean_cut(geom, cut_tool)\n        if len(parts) < 2:\n            raise BuilderError(\n                f\"BB poloidal segmentation only returned {len(parts)} part(s), expected \"\n                \"2.\"\n            )\n        if len(parts) > 2:\n            bluemira_warn(\n                \"The BB poloidal segmentation operation returned more than 2 parts \"\n                f\"({len(parts)}); only taking the first two...\"\n            )\n        inboard, outboard = sorted(parts, key=lambda x: x.center_of_mass[0])[:2]\n        return inboard, outboard",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        blanket_boundary: BluemiraWire,\n        blanket_silhouette: BluemiraFace,\n        r_inner_cut: float,\n        cut_angle: float,\n        build_config: Optional[Dict] = None,\n    ):\n        super().__init__(params, build_config)\n        self.boundary = blanket_boundary\n        self.silhouette = blanket_silhouette\n        self.r_inner_cut = r_inner_cut\n        if abs(cut_angle) >= 90:\n            raise ValueError(\n                \"Cannot cut boundary silhouette at an angle greater than 90\u00b0.\"\n            )\n        self.cut_angle = cut_angle",
  "def run(self) -> Tuple[BluemiraFace, BluemiraFace]:\n        \"\"\"Run the blanket design problem.\"\"\"\n        segments = self.segment_blanket()\n        # Inboard\n        ib_panels = self.panel_boundary(segments.inboard_boundary)\n        ib_panels_face = BluemiraFace(ib_panels)\n        cut_ib = boolean_cut(segments.inboard, [ib_panels_face])[0]\n        # Outboard\n        ob_panels = self.panel_boundary(segments.outboard_boundary)\n        ob_panels_face = BluemiraFace(ob_panels)\n        cut_ob = boolean_cut(segments.outboard, [ob_panels_face])[0]\n        return cut_ib, cut_ob",
  "def segment_blanket(self) -> BlanketSegments:\n        \"\"\"\n        Segment the breeding blanket's poloidal cross-section.\n\n        Segment it into inboard and outboard silhouettes.\n\n        Returns\n        -------\n        An instance of :class:`.BlanketSegments` containing the\n        blanket segment geometries.\n        \"\"\"\n        cut_zone = self._make_cutting_face()\n        ib_face, ob_face = self._cut_geom(self.silhouette, cut_zone)\n        ib_bound, ob_bound = self._cut_geom(self.boundary, cut_zone)\n        return BlanketSegments(\n            inboard=ib_face,\n            outboard=ob_face,\n            inboard_boundary=ib_bound,\n            outboard_boundary=ob_bound,\n        )",
  "def panel_boundary(self, boundary: BluemiraWire) -> BluemiraWire:\n        \"\"\"Create the panel shapes for the given boundary.\"\"\"\n        panel_coords = PanellingDesigner(self.params, boundary).run()\n        return make_polygon(\n            {\"x\": panel_coords[0], \"z\": panel_coords[1]}, label=\"panels\", closed=True\n        )",
  "def _make_cutting_face(self) -> BluemiraFace:\n        \"\"\"Make a face that can be used to cut the blanket into inboard & outboard.\"\"\"\n        p0 = get_inner_cut_point(self.silhouette, self.r_inner_cut)\n        p1 = [p0[0], 0, p0[2] + VERY_BIG]\n        p2 = [p0[0] - self.params.c_rm.value, 0, p1[2]]\n        p3 = [p2[0], 0, p0[2] - np.sqrt(2) * self.params.c_rm.value]\n        cut_zone = BluemiraFace(make_polygon([p0, p1, p2, p3], closed=True))\n        if self.cut_angle != 0.0:\n            cut_zone.rotate(base=p0, direction=(0, -1, 0), degree=self.cut_angle)\n        return cut_zone",
  "def _cut_geom(self, geom: _GeomT, cut_tool: BluemiraFace) -> Tuple[_GeomT, _GeomT]:\n        \"\"\"Cut the given geometry into two using the given cutting tool.\"\"\"\n        parts = boolean_cut(geom, cut_tool)\n        if len(parts) < 2:\n            raise BuilderError(\n                f\"BB poloidal segmentation only returned {len(parts)} part(s), expected \"\n                \"2.\"\n            )\n        if len(parts) > 2:\n            bluemira_warn(\n                \"The BB poloidal segmentation operation returned more than 2 parts \"\n                f\"({len(parts)}); only taking the first two...\"\n            )\n        inboard, outboard = sorted(parts, key=lambda x: x.center_of_mass[0])[:2]\n        return inboard, outboard",
  "class BlanketBuilderParams(ParameterFrame):\n    \"\"\"\n    Blanket builder parameters\n    \"\"\"\n\n    n_TF: Parameter[int]\n    n_bb_inboard: Parameter[int]\n    n_bb_outboard: Parameter[int]\n    c_rm: Parameter[float]",
  "class BlanketBuilder(Builder):\n    \"\"\"\n    Blanket builder\n\n    Parameters\n    ----------\n    params:\n        the parameter frame\n    build_config:\n        the build config\n    blanket_silhouette:\n        breeding blanket silhouette\n    \"\"\"\n\n    BB = \"BB\"\n    IBS = \"IBS\"\n    OBS = \"OBS\"\n    param_cls: Type[BlanketBuilderParams] = BlanketBuilderParams\n    params: BlanketBuilderParams\n\n    def __init__(\n        self,\n        params: Union[BlanketBuilderParams, Dict],\n        build_config: Dict,\n        ib_silhouette: BluemiraFace,\n        ob_silhouette: BluemiraFace,\n    ):\n        super().__init__(params, build_config)\n        self.ib_silhouette = ib_silhouette\n        self.ob_silhouette = ob_silhouette\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the blanket component.\n        \"\"\"\n        segments = self.get_segments(self.ib_silhouette, self.ob_silhouette)\n        return self.component_tree(\n            xz=[self.build_xz(self.ib_silhouette, self.ob_silhouette)],\n            xy=self.build_xy(segments),\n            xyz=self.build_xyz(segments, degree=0),\n        )\n\n    def build_xz(self, ibs_silhouette: BluemiraFace, obs_silhouette: BluemiraFace):\n        \"\"\"\n        Build the x-z components of the blanket.\n        \"\"\"\n        ibs = PhysicalComponent(self.IBS, ibs_silhouette)\n        obs = PhysicalComponent(self.OBS, obs_silhouette)\n        apply_component_display_options(ibs, color=BLUE_PALETTE[self.BB][0])\n        apply_component_display_options(obs, color=BLUE_PALETTE[self.BB][1])\n        return Component(self.BB, children=[ibs, obs])\n\n    def build_xy(self, segments: List[PhysicalComponent]):\n        \"\"\"\n        Build the x-y components of the blanket.\n        \"\"\"\n        xy_plane = BluemiraPlacement.from_3_points([0, 0, 0], [1, 0, 0], [0, 1, 0])\n\n        slices = []\n        for i, segment in enumerate(segments):\n            single_slice = PhysicalComponent(\n                segment.name, BluemiraFace(slice_shape(segment.shape, xy_plane)[0])\n            )\n            apply_component_display_options(single_slice, color=BLUE_PALETTE[self.BB][i])\n            slices.append(single_slice)\n\n        return circular_pattern_component(\n            Component(self.BB, children=slices), self.params.n_TF.value\n        )\n\n    def build_xyz(self, segments: List[PhysicalComponent], degree: float = 360.0):\n        \"\"\"\n        Build the x-y-z components of the blanket.\n        \"\"\"\n        sector_degree, n_sectors = get_n_sectors(self.params.n_TF.value, degree)\n\n        # TODO: Add blanket cuts properly in 3-D\n        return circular_pattern_component(\n            Component(self.BB, children=segments),\n            n_sectors,\n            degree=sector_degree * n_sectors,\n        )\n\n    def get_segments(self, ibs_silhouette: BluemiraFace, obs_silhouette: BluemiraFace):\n        \"\"\"\n        Create segments of the blanket from inboard and outboard silhouettes\n        \"\"\"\n        ibs_shapes = pattern_revolved_silhouette(\n            ibs_silhouette,\n            self.params.n_bb_inboard.value,\n            self.params.n_TF.value,\n            self.params.c_rm.value,\n        )\n\n        obs_shapes = pattern_revolved_silhouette(\n            obs_silhouette,\n            self.params.n_bb_outboard.value,\n            self.params.n_TF.value,\n            self.params.c_rm.value,\n        )\n\n        segments = []\n        for name, base_no, bs_shape in [\n            [self.IBS, 0, ibs_shapes],\n            [self.OBS, self.params.n_bb_inboard.value + 1, obs_shapes],\n        ]:\n            for no, shape in enumerate(bs_shape):\n                segment = PhysicalComponent(f\"{name}_{no}\", shape)\n                apply_component_display_options(\n                    segment, color=BLUE_PALETTE[self.BB][base_no + no]\n                )\n                segments.append(segment)\n        return segments",
  "def __init__(\n        self,\n        params: Union[BlanketBuilderParams, Dict],\n        build_config: Dict,\n        ib_silhouette: BluemiraFace,\n        ob_silhouette: BluemiraFace,\n    ):\n        super().__init__(params, build_config)\n        self.ib_silhouette = ib_silhouette\n        self.ob_silhouette = ob_silhouette",
  "def build(self) -> Component:\n        \"\"\"\n        Build the blanket component.\n        \"\"\"\n        segments = self.get_segments(self.ib_silhouette, self.ob_silhouette)\n        return self.component_tree(\n            xz=[self.build_xz(self.ib_silhouette, self.ob_silhouette)],\n            xy=self.build_xy(segments),\n            xyz=self.build_xyz(segments, degree=0),\n        )",
  "def build_xz(self, ibs_silhouette: BluemiraFace, obs_silhouette: BluemiraFace):\n        \"\"\"\n        Build the x-z components of the blanket.\n        \"\"\"\n        ibs = PhysicalComponent(self.IBS, ibs_silhouette)\n        obs = PhysicalComponent(self.OBS, obs_silhouette)\n        apply_component_display_options(ibs, color=BLUE_PALETTE[self.BB][0])\n        apply_component_display_options(obs, color=BLUE_PALETTE[self.BB][1])\n        return Component(self.BB, children=[ibs, obs])",
  "def build_xy(self, segments: List[PhysicalComponent]):\n        \"\"\"\n        Build the x-y components of the blanket.\n        \"\"\"\n        xy_plane = BluemiraPlacement.from_3_points([0, 0, 0], [1, 0, 0], [0, 1, 0])\n\n        slices = []\n        for i, segment in enumerate(segments):\n            single_slice = PhysicalComponent(\n                segment.name, BluemiraFace(slice_shape(segment.shape, xy_plane)[0])\n            )\n            apply_component_display_options(single_slice, color=BLUE_PALETTE[self.BB][i])\n            slices.append(single_slice)\n\n        return circular_pattern_component(\n            Component(self.BB, children=slices), self.params.n_TF.value\n        )",
  "def build_xyz(self, segments: List[PhysicalComponent], degree: float = 360.0):\n        \"\"\"\n        Build the x-y-z components of the blanket.\n        \"\"\"\n        sector_degree, n_sectors = get_n_sectors(self.params.n_TF.value, degree)\n\n        # TODO: Add blanket cuts properly in 3-D\n        return circular_pattern_component(\n            Component(self.BB, children=segments),\n            n_sectors,\n            degree=sector_degree * n_sectors,\n        )",
  "def get_segments(self, ibs_silhouette: BluemiraFace, obs_silhouette: BluemiraFace):\n        \"\"\"\n        Create segments of the blanket from inboard and outboard silhouettes\n        \"\"\"\n        ibs_shapes = pattern_revolved_silhouette(\n            ibs_silhouette,\n            self.params.n_bb_inboard.value,\n            self.params.n_TF.value,\n            self.params.c_rm.value,\n        )\n\n        obs_shapes = pattern_revolved_silhouette(\n            obs_silhouette,\n            self.params.n_bb_outboard.value,\n            self.params.n_TF.value,\n            self.params.c_rm.value,\n        )\n\n        segments = []\n        for name, base_no, bs_shape in [\n            [self.IBS, 0, ibs_shapes],\n            [self.OBS, self.params.n_bb_inboard.value + 1, obs_shapes],\n        ]:\n            for no, shape in enumerate(bs_shape):\n                segment = PhysicalComponent(f\"{name}_{no}\", shape)\n                apply_component_display_options(\n                    segment, color=BLUE_PALETTE[self.BB][base_no + no]\n                )\n                segments.append(segment)\n        return segments",
  "class Blanket(ComponentManager):\n    \"\"\"Wrapper around a Blanket component tree.\"\"\"\n\n    def inboard_xz_silhouette(self) -> BluemiraFace:\n        \"\"\"The poloidal plane silhouette of the inboard blanket segment.\"\"\"\n        return (\n            self.component().get_component(\"xz\").get_component(BlanketBuilder.IBS).shape\n        )\n\n    def outboard_xz_silhouette(self) -> BluemiraFace:\n        \"\"\"The poloidal plane silhouette of the outboard blanket segment.\"\"\"\n        return (\n            self.component().get_component(\"xz\").get_component(BlanketBuilder.OBS).shape\n        )",
  "def inboard_xz_silhouette(self) -> BluemiraFace:\n        \"\"\"The poloidal plane silhouette of the inboard blanket segment.\"\"\"\n        return (\n            self.component().get_component(\"xz\").get_component(BlanketBuilder.IBS).shape\n        )",
  "def outboard_xz_silhouette(self) -> BluemiraFace:\n        \"\"\"The poloidal plane silhouette of the outboard blanket segment.\"\"\"\n        return (\n            self.component().get_component(\"xz\").get_component(BlanketBuilder.OBS).shape\n        )",
  "def make_pivoted_string(\n    boundary_points: np.ndarray,\n    max_angle: float = 10,\n    dx_min: float = 0,\n    dx_max: float = np.inf,\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Generate a set of pivot points along the given boundary.\n\n    Given a set of boundary points, some maximum angle, and minimum and\n    maximum segment length, this function derives a set of pivot points\n    along the boundary, that define a 'string'. You might picture a\n    'string' as a thread wrapped around some nails (pivot points) on a\n    board.\n\n    Parameters\n    ----------\n    points:\n        The coordinates (in 3D) of the pivot points. Must have shape\n        (N, 3) where N is the number of boundary points.\n    max_angle:\n        The maximum angle between neighbouring pivot points.\n    dx_min:\n        The minimum distance between pivot points.\n    dx_max:\n        The maximum distance between pivot points.\n\n    Returns\n    -------\n    new_points:\n        The pivot points' coordinates. Has shape (M, 3), where M is the\n        number of pivot points.\n    index:\n        The indices of the pivot points into the input points.\n    \"\"\"\n    if dx_min > dx_max:\n        raise ValueError(\n            f\"'dx_min' cannot be greater than 'dx_max': '{dx_min} > {dx_max}'\"\n        )\n    tangent_vec = boundary_points[1:] - boundary_points[:-1]\n    tangent_vec_norm = np.linalg.norm(tangent_vec, axis=1)\n    # Protect against dividing by zero\n    tangent_vec_norm[tangent_vec_norm == 0] = 1e-32\n    average_step_length = np.median(tangent_vec_norm)\n    tangent_vec /= tangent_vec_norm.reshape(-1, 1) * np.ones(\n        (1, np.shape(tangent_vec)[1])\n    )\n\n    new_points = np.zeros_like(boundary_points)\n    index = np.zeros(boundary_points.shape[0], dtype=int)\n\n    new_points[0] = boundary_points[0]\n    to, po = tangent_vec[0], boundary_points[0]\n\n    k = count(1)\n    for i, (p, t) in enumerate(zip(boundary_points[1:], tangent_vec)):\n        c = np.cross(to, t)\n        c_mag = np.linalg.norm(c)\n        dx = np.linalg.norm(p - po)  # segment length\n        if (\n            c_mag > np.sin(np.deg2rad(max_angle)) and dx > dx_min\n        ) or dx + average_step_length > dx_max:\n            j = next(k)\n            new_points[j] = boundary_points[i]  # pivot point\n            index[j] = i + 1  # pivot index\n            to, po = t, p  # update\n    if dx > dx_min:\n        j = next(k)\n    new_points[j] = p  # replace/append last point\n    index[j] = i + 1  # replace/append last point index\n    new_points = new_points[: j + 1]  # trim\n    index = index[: j + 1]  # trim\n    return new_points, index",
  "class PanellingOptProblem(OptimisationProblem):\n    \"\"\"\n    Optimisation problem to minimise the cumulative length of first wall panels.\n\n    The optimisation parameters are the normalised lengths along the\n    panelling boundary at which the panels and boundary touch.\n\n    The objective is to minimise the cumulative length of the panels,\n    subject to a maximum tail-to-tail angle between panels and a minimum\n    panel length. Note that the parameters for these constraints are\n    properties of the ``paneller``.\n\n    Parameters\n    ----------\n    paneller:\n        The :class:`.Paneller` to optimise the parameters of. Note that\n        these parameters are the normalised length along the paneller's\n        boundary where the panels and boundary meet.\n    \"\"\"\n\n    def __init__(self, paneller: Paneller):\n        self.paneller = paneller\n\n    def objective(self, x: np.ndarray) -> float:\n        \"\"\"Objective function to minimise the total panel length.\"\"\"\n        return self.paneller.length(x)\n\n    def bounds(self) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"The normalized bounds of the parameterisation.\"\"\"\n        return np.zeros_like(self.paneller.x0), np.ones_like(self.paneller.x0)\n\n    def ineq_constraints(self) -> List[ConstraintT]:\n        \"\"\"\n        The inequality constraints for the optimiser.\n\n        We are constraining the tail-to-tail angle between panels and\n        the minimum panel length.\n        \"\"\"\n        return [\n            {\n                \"f_constraint\": self.constrain_min_length_and_angles,\n                \"tolerance\": np.full(self.n_constraints, 1e-8),\n            }\n        ]\n\n    @property\n    def n_opts(self) -> int:\n        \"\"\"\n        The number of optimisation parameters.\n\n        The optimisation parameters are how far along the boundary's\n        length each panel tangents the boundary (normalized to between\n        0 and 1). We exclude the panel's start and end points, which are\n        fixed.\n        \"\"\"\n        # exclude start and end points; hence 'N - 2'\n        return self.paneller.n_panels - 2\n\n    @property\n    def n_constraints(self) -> int:\n        \"\"\"\n        The number of optimisation constraints.\n\n        We constrain:\n\n            - the minimum length of each panel\n            - the angle between each panel\n              (no. of angles = no. of panels - 1)\n\n        Note that we exclude the start and end touch points which are\n        fixed.\n        \"\"\"\n        return 2 * self.paneller.n_panels - 1\n\n    def constrain_min_length_and_angles(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"Constraint function function for the optimiser.\"\"\"\n        n_panels = self.paneller.n_panels\n        constraint = np.empty(self.n_constraints, dtype=float)\n        constraint[:n_panels] = self._constrain_min_length(x)\n        constraint[n_panels:] = self._constrain_max_angle(x)\n        return constraint\n\n    def _constrain_min_length(self, x: np.ndarray) -> np.ndarray:\n        lengths = self.paneller.panel_lengths(x)\n        return self.paneller.dx_min - lengths\n\n    def _constrain_max_angle(self, x: np.ndarray) -> np.ndarray:\n        return self.paneller.angles(x) - self.paneller.max_angle\n\n    def constraints_violated_by(self, x: np.ndarray, atol: float) -> bool:\n        \"\"\"Return True if any constraints are violated by more that ``atol``.\"\"\"\n        constraint = self.constrain_min_length_and_angles(x)\n        return np.any(constraint > atol)",
  "def __init__(self, paneller: Paneller):\n        self.paneller = paneller",
  "def objective(self, x: np.ndarray) -> float:\n        \"\"\"Objective function to minimise the total panel length.\"\"\"\n        return self.paneller.length(x)",
  "def bounds(self) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"The normalized bounds of the parameterisation.\"\"\"\n        return np.zeros_like(self.paneller.x0), np.ones_like(self.paneller.x0)",
  "def ineq_constraints(self) -> List[ConstraintT]:\n        \"\"\"\n        The inequality constraints for the optimiser.\n\n        We are constraining the tail-to-tail angle between panels and\n        the minimum panel length.\n        \"\"\"\n        return [\n            {\n                \"f_constraint\": self.constrain_min_length_and_angles,\n                \"tolerance\": np.full(self.n_constraints, 1e-8),\n            }\n        ]",
  "def n_opts(self) -> int:\n        \"\"\"\n        The number of optimisation parameters.\n\n        The optimisation parameters are how far along the boundary's\n        length each panel tangents the boundary (normalized to between\n        0 and 1). We exclude the panel's start and end points, which are\n        fixed.\n        \"\"\"\n        # exclude start and end points; hence 'N - 2'\n        return self.paneller.n_panels - 2",
  "def n_constraints(self) -> int:\n        \"\"\"\n        The number of optimisation constraints.\n\n        We constrain:\n\n            - the minimum length of each panel\n            - the angle between each panel\n              (no. of angles = no. of panels - 1)\n\n        Note that we exclude the start and end touch points which are\n        fixed.\n        \"\"\"\n        return 2 * self.paneller.n_panels - 1",
  "def constrain_min_length_and_angles(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"Constraint function function for the optimiser.\"\"\"\n        n_panels = self.paneller.n_panels\n        constraint = np.empty(self.n_constraints, dtype=float)\n        constraint[:n_panels] = self._constrain_min_length(x)\n        constraint[n_panels:] = self._constrain_max_angle(x)\n        return constraint",
  "def _constrain_min_length(self, x: np.ndarray) -> np.ndarray:\n        lengths = self.paneller.panel_lengths(x)\n        return self.paneller.dx_min - lengths",
  "def _constrain_max_angle(self, x: np.ndarray) -> np.ndarray:\n        return self.paneller.angles(x) - self.paneller.max_angle",
  "def constraints_violated_by(self, x: np.ndarray, atol: float) -> bool:\n        \"\"\"Return True if any constraints are violated by more that ``atol``.\"\"\"\n        constraint = self.constrain_min_length_and_angles(x)\n        return np.any(constraint > atol)",
  "class PanellingDesignerParams(ParameterFrame):\n    \"\"\"Parameters for :class:`.PanellingDesigner`.\"\"\"\n\n    fw_a_max: Parameter[float]\n    \"\"\"The maximum angle of rotation between adjacent panels [degrees].\"\"\"\n    fw_dL_min: Parameter[float]  # noqa: N815\n    \"\"\"The minimum length for an individual panel [m].\"\"\"",
  "class PanellingDesigner(Designer[np.ndarray]):\n    r\"\"\"\n    Design the shape for panels of the first wall.\n\n    The panel design's objective is to minimise the cumulative panel\n    length (minimising the amount of material required), whilst\n    constraining the maximum angle of rotation between adjacent panels,\n    and the minimum length of a panel.\n\n    A best first guess will be made for the number of panels and their\n    positions and then an optimiser will be run to minimise the\n    cumulative length of the panels, whilst satisfying the minimum length\n    and maximum angle constraints.\n\n    Sometimes the initial guess will not enable the optimiser to find a\n    solution that satisfies the constraints. In these cases an extra\n    panel is added and the optimiser run again, until the constraints\n    are satisfied, or the number of panels added exceeds the\n    ``n_panel_increment_attempts`` build config parameter.\n\n    Parameters\n    ----------\n    params:\n        The parameters for the panelling design problem. See\n        :class:`.PanellingDesignerParams` for the required parameters.\n    wall_boundary:\n        The boundary of the first wall to build the panels around. Note\n        that this designer constructs panels around the *outside* of the\n        given wall boundary; i.e., the panels enclose the wall.\n    build_config:\n        Configuration options for the designer:\n\n        * algorithm: str\n            The optimisation algorithm to use (default: ``'SLSQP'``\\).\n        * opt_conditions: Dict[str, Union[float, int]]\n            The stopping conditions for the optimiser\n            (default: ``{\"max_eval\": 400, \"ftol_rel\": 1e-4}``\\).\n        * n_panel_increment_attempts: int\n            The number of times to try incrementing the number of panels\n            in order to satisfy the given constraints (default: 3).\n        * boundary_discretisation: int\n            The number of points to discretise the input boundary wire\n            into. A higher number here increases the fidelity in the\n            interpolation used in the :class:`.Paneller`, and can prevent\n            overlaps in the panels and boundary.\n    \"\"\"\n\n    param_cls = PanellingDesignerParams\n    params: PanellingDesignerParams\n    _defaults = {\n        \"algorithm\": \"SLSQP\",\n        \"opt_conditions\": {\"max_eval\": 500, \"ftol_rel\": 1e-8},\n        \"n_panel_increment_attempts\": 3,\n        \"boundary_discretisation\": 200,\n    }\n\n    def __init__(\n        self,\n        params: Union[Dict, PanellingDesignerParams, ParameterFrame],\n        wall_boundary: BluemiraWire,\n        build_config: Optional[Dict] = None,\n    ):\n        super().__init__(params, build_config)\n        self.wall_boundary = wall_boundary\n        self._n_boundary_discr = int(\n            self._get_config_or_default(\"boundary_discretisation\")\n        )\n        self.opt_algorithm = str(self._get_config_or_default(\"algorithm\"))\n        self.opt_conditions = dict(self._get_config_or_default(\"opt_conditions\"))\n\n    def run(self) -> np.ndarray:\n        \"\"\"\n        Run the design problem, performing the optimisation.\n\n        Returns\n        -------\n        The coordinates of the panel end points (or joints). Has\n        shape (2, N).\n        \"\"\"\n        boundary = self.wall_boundary.discretize(\n            ndiscr=self._n_boundary_discr, byedges=True\n        ).xz\n        opt_problem = self._set_up_opt_problem(boundary)\n        initial_solution = opt_problem.paneller.joints(opt_problem.paneller.x0)\n        max_retries = int(self._get_config_or_default(\"n_panel_increment_attempts\"))\n        x_opt, opt_problem, num_retries = self._run_opt_problem_with_retries(\n            boundary, opt_problem, max_retries\n        )\n\n        # Make sure we warn about broken tolerances this time.\n        if num_retries == max_retries and (\n            x_opt is None or not opt_problem.check_constraints(x_opt, warn=True)\n        ):\n            bluemira_warn(\n                \"Could not solve panelling optimisation problem: no feasible \"\n                \"solution found. Try reducing the minimum length and/or increasing \"\n                \"the maximum allowed angle.\"\n            )\n        if x_opt is None or opt_problem.constraints_violated_by(x_opt, 1):\n            return initial_solution\n\n        return opt_problem.paneller.joints(x_opt)\n\n    def mock(self) -> np.ndarray:\n        \"\"\"\n        Mock the design problem, returning the initial guess for panel placement.\n\n        This guarantees that panels will always fully contain the given\n        boundary, but does not guarantee the maximum angle and minimum\n        length constraints are honoured.\n        \"\"\"\n        boundary = self.wall_boundary.discretize(\n            ndiscr=self._n_boundary_discr, byedges=True\n        ).xz\n        paneller = Paneller(\n            boundary, self.params.fw_a_max.value, self.params.fw_dL_min.value\n        )\n        return paneller.joints(paneller.x0)\n\n    def _run_opt_problem_with_retries(\n        self,\n        boundary: np.ndarray,\n        opt_problem: PanellingOptProblem,\n        max_retries: int,\n    ) -> Tuple[Union[np.ndarray, None], PanellingOptProblem, int]:\n        \"\"\"\n        Run the minimise panel length optimisation problem.\n\n        If the optimisation fails, retry with an extra panel\n        ``max_retries`` times.\n\n        Return ``None`` as the first return value if the final\n        optimisation crashes with a 'more than iter SQP iterations'\n        error (which it often does given an infeasible problem).\n        \"\"\"\n        try:\n            x_opt = opt_problem.optimise(\n                opt_problem.paneller.x0,\n                check_constraints=False,\n                algorithm=self.opt_algorithm,\n                opt_conditions=self.opt_conditions,\n            ).x\n        except ExternalOptError:\n            # Avoid 'more than iter SQP iterations' errors stopping the\n            # design.\n            # Ignoring the error here is OK, as the optimiser prints a\n            # warning and we either try again with more panels, or\n            # return our initial guess as a fall back.\n            x_opt = None\n        iter_num = 0\n        while (\n            x_opt is None or not opt_problem.check_constraints(x_opt, warn=False)\n        ) and iter_num < max_retries:\n            # We couldn't satisfy the constraints on our last attempt,\n            # so try increasing the number of panels.\n            # Note we're actually increasing the number of panels by 1\n            # by adding 3 below, as there are two more panels than\n            # optimisation parameters.\n            n_panels = opt_problem.n_opts + 3\n            opt_problem = self._set_up_opt_problem(boundary, n_panels)\n            try:\n                x_opt = opt_problem.optimise(\n                    opt_problem.paneller.x0,\n                    check_constraints=False,\n                    algorithm=self.opt_algorithm,\n                    opt_conditions=self.opt_conditions,\n                ).x\n            except ExternalOptError:\n                x_opt = None\n            iter_num += 1\n        return x_opt, opt_problem, iter_num\n\n    def _set_up_opt_problem(\n        self, boundary: np.ndarray, fix_num_panels: Optional[int] = None\n    ) -> PanellingOptProblem:\n        \"\"\"Set up an instance of the minimise panel length optimisation problem.\"\"\"\n        paneller = Paneller(\n            boundary,\n            self.params.fw_a_max.value,\n            self.params.fw_dL_min.value,\n            fix_num_panels=fix_num_panels,\n        )\n        return PanellingOptProblem(paneller)\n\n    def _get_config_or_default(self, config_key: str) -> Any:\n        return self.build_config.get(config_key, self._defaults[config_key])",
  "def __init__(\n        self,\n        params: Union[Dict, PanellingDesignerParams, ParameterFrame],\n        wall_boundary: BluemiraWire,\n        build_config: Optional[Dict] = None,\n    ):\n        super().__init__(params, build_config)\n        self.wall_boundary = wall_boundary\n        self._n_boundary_discr = int(\n            self._get_config_or_default(\"boundary_discretisation\")\n        )\n        self.opt_algorithm = str(self._get_config_or_default(\"algorithm\"))\n        self.opt_conditions = dict(self._get_config_or_default(\"opt_conditions\"))",
  "def run(self) -> np.ndarray:\n        \"\"\"\n        Run the design problem, performing the optimisation.\n\n        Returns\n        -------\n        The coordinates of the panel end points (or joints). Has\n        shape (2, N).\n        \"\"\"\n        boundary = self.wall_boundary.discretize(\n            ndiscr=self._n_boundary_discr, byedges=True\n        ).xz\n        opt_problem = self._set_up_opt_problem(boundary)\n        initial_solution = opt_problem.paneller.joints(opt_problem.paneller.x0)\n        max_retries = int(self._get_config_or_default(\"n_panel_increment_attempts\"))\n        x_opt, opt_problem, num_retries = self._run_opt_problem_with_retries(\n            boundary, opt_problem, max_retries\n        )\n\n        # Make sure we warn about broken tolerances this time.\n        if num_retries == max_retries and (\n            x_opt is None or not opt_problem.check_constraints(x_opt, warn=True)\n        ):\n            bluemira_warn(\n                \"Could not solve panelling optimisation problem: no feasible \"\n                \"solution found. Try reducing the minimum length and/or increasing \"\n                \"the maximum allowed angle.\"\n            )\n        if x_opt is None or opt_problem.constraints_violated_by(x_opt, 1):\n            return initial_solution\n\n        return opt_problem.paneller.joints(x_opt)",
  "def mock(self) -> np.ndarray:\n        \"\"\"\n        Mock the design problem, returning the initial guess for panel placement.\n\n        This guarantees that panels will always fully contain the given\n        boundary, but does not guarantee the maximum angle and minimum\n        length constraints are honoured.\n        \"\"\"\n        boundary = self.wall_boundary.discretize(\n            ndiscr=self._n_boundary_discr, byedges=True\n        ).xz\n        paneller = Paneller(\n            boundary, self.params.fw_a_max.value, self.params.fw_dL_min.value\n        )\n        return paneller.joints(paneller.x0)",
  "def _run_opt_problem_with_retries(\n        self,\n        boundary: np.ndarray,\n        opt_problem: PanellingOptProblem,\n        max_retries: int,\n    ) -> Tuple[Union[np.ndarray, None], PanellingOptProblem, int]:\n        \"\"\"\n        Run the minimise panel length optimisation problem.\n\n        If the optimisation fails, retry with an extra panel\n        ``max_retries`` times.\n\n        Return ``None`` as the first return value if the final\n        optimisation crashes with a 'more than iter SQP iterations'\n        error (which it often does given an infeasible problem).\n        \"\"\"\n        try:\n            x_opt = opt_problem.optimise(\n                opt_problem.paneller.x0,\n                check_constraints=False,\n                algorithm=self.opt_algorithm,\n                opt_conditions=self.opt_conditions,\n            ).x\n        except ExternalOptError:\n            # Avoid 'more than iter SQP iterations' errors stopping the\n            # design.\n            # Ignoring the error here is OK, as the optimiser prints a\n            # warning and we either try again with more panels, or\n            # return our initial guess as a fall back.\n            x_opt = None\n        iter_num = 0\n        while (\n            x_opt is None or not opt_problem.check_constraints(x_opt, warn=False)\n        ) and iter_num < max_retries:\n            # We couldn't satisfy the constraints on our last attempt,\n            # so try increasing the number of panels.\n            # Note we're actually increasing the number of panels by 1\n            # by adding 3 below, as there are two more panels than\n            # optimisation parameters.\n            n_panels = opt_problem.n_opts + 3\n            opt_problem = self._set_up_opt_problem(boundary, n_panels)\n            try:\n                x_opt = opt_problem.optimise(\n                    opt_problem.paneller.x0,\n                    check_constraints=False,\n                    algorithm=self.opt_algorithm,\n                    opt_conditions=self.opt_conditions,\n                ).x\n            except ExternalOptError:\n                x_opt = None\n            iter_num += 1\n        return x_opt, opt_problem, iter_num",
  "def _set_up_opt_problem(\n        self, boundary: np.ndarray, fix_num_panels: Optional[int] = None\n    ) -> PanellingOptProblem:\n        \"\"\"Set up an instance of the minimise panel length optimisation problem.\"\"\"\n        paneller = Paneller(\n            boundary,\n            self.params.fw_a_max.value,\n            self.params.fw_dL_min.value,\n            fix_num_panels=fix_num_panels,\n        )\n        return PanellingOptProblem(paneller)",
  "def _get_config_or_default(self, config_key: str) -> Any:\n        return self.build_config.get(config_key, self._defaults[config_key])",
  "class Paneller:\n    \"\"\"\n    Provides functions for generating panelling along the outside of a boundary.\n\n    Parameters\n    ----------\n    boundary_points:\n        The points defining the boundary along which to build the panels.\n        This should have shape (2, N), where N is the number of points.\n    max_angle:\n        Maximum turning angle of the panels\n    dx_min:\n        Minimum panel length\n    fix_num_panels:\n        If specified, fix the number of panels to an integer value\n    \"\"\"\n\n    def __init__(\n        self,\n        boundary_points: np.ndarray,\n        max_angle: float,\n        dx_min: float,\n        fix_num_panels: Optional[int] = None,\n    ):\n        self.max_angle = max_angle\n        self.dx_min = dx_min\n        self.boundary = LengthNormBoundary(boundary_points)\n\n        if fix_num_panels:\n            self.x0 = np.linspace(0, 1, fix_num_panels)[1:-1]\n        else:\n            # Build the initial guess of our panels, these points are the\n            # coordinates of where the panels tangent the boundary\n            _, idx = make_pivoted_string(\n                boundary_points.T,\n                max_angle=max_angle,\n                dx_min=dx_min,\n            )\n            self.x0: np.ndarray = self.boundary.length_norm[idx][1:-1]\n\n    @property\n    def n_panels(self) -> int:\n        \"\"\"The number of panels defined by this paneller.\"\"\"\n        return len(self.x0) + 2\n\n    def joints(self, dists: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Calculate panel joint coordinates from panel-boundary tangent points.\n\n        Parameters\n        ----------\n        dists:\n            The normalised distances along the boundary at which there\n            are panel-boundary tangent points.\n        \"\"\"\n        # Add the start and end panel joints at distances 0 & 1\n        dists = np.hstack((0, dists, 1))\n        points = np.vstack((self.boundary.x(dists), self.boundary.z(dists)))\n        tangents = np.vstack(\n            (self.boundary.x_tangent(dists), self.boundary.z_tangent(dists))\n        )\n        # This could potentially be vectorized, if we need a speed up.\n        joints = np.zeros((2, len(dists) + 1))\n        joints[:, 0] = points[:, 0]\n        joints[:, -1] = points[:, -1]\n        for i in range(joints.shape[1] - 2):\n            joints[:, i + 1] = vector_intersect(\n                points[:, i],\n                points[:, i] + tangents[:, i],\n                points[:, i + 1],\n                points[:, i + 1] + tangents[:, i + 1],\n            )\n        return joints\n\n    # Typically, in a panelling optimisation loop, we'll call, at least,\n    # 'length' and 'angles', which both call out to 'joints'.\n    # For a potential optimisation we could cache the result of 'joints'.\n    def length(self, dists: np.ndarray) -> float:\n        \"\"\"The cumulative length of the panels.\"\"\"\n        return self.panel_lengths(dists).sum()\n\n    def angles(self, dists: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Return the angles of rotation between each set of adjacent panels.\n\n        Note that this is the tail-tail angle between the panel vectors,\n        not the head-tail angles.\n        \"\"\"\n        joints = self.joints(dists)\n        line_vectors = np.diff(joints, axis=1)\n        magnitudes = np.linalg.norm(line_vectors, axis=0)\n        # avoid division by zero later\n        magnitudes[np.isclose(magnitudes, 0)] += 1e-8\n        dots = (line_vectors[:, :-1] * line_vectors[:, 1:]).sum(axis=0)\n        dots /= magnitudes[:-1] * magnitudes[1:]\n        return np.degrees(np.arccos(np.clip(dots, -1.0, 1.0)), out=dots)\n\n    def panel_lengths(self, dists: np.ndarray) -> np.ndarray:\n        \"\"\"Return the lengths of each panel.\"\"\"\n        panel_vecs = np.diff(self.joints(dists))\n        return np.hypot(panel_vecs[0], panel_vecs[1])",
  "class LengthNormBoundary:\n    \"\"\"Class to represent a wire interpolated over the normalised distance along it.\"\"\"\n\n    def __init__(self, boundary_points: np.ndarray):\n        self.length_norm = vector_lengthnorm(boundary_points[0], boundary_points[1])\n        self._x_spline = InterpolatedUnivariateSpline(\n            self.length_norm, boundary_points[0]\n        )\n        self._z_spline = InterpolatedUnivariateSpline(\n            self.length_norm, boundary_points[1]\n        )\n\n        self.tangent_norm = norm_tangents(boundary_points)\n        self._x_tangent_spline = InterpolatedUnivariateSpline(\n            self.length_norm, self.tangent_norm[0]\n        )\n        self._z_tangent_spline = InterpolatedUnivariateSpline(\n            self.length_norm, self.tangent_norm[1]\n        )\n\n    def x(self, dist: Union[float, np.ndarray]) -> np.ndarray:\n        \"\"\"Find x at the given normalised distance along the boundary.\"\"\"\n        return self._x_spline(dist)\n\n    def z(self, dist: Union[float, np.ndarray]) -> np.ndarray:\n        \"\"\"Find z at the given normalised distance along the boundary.\"\"\"\n        return self._z_spline(dist)\n\n    def x_tangent(self, dist: Union[float, np.ndarray]) -> np.ndarray:\n        \"\"\"Find x at the tangent vector a given distance along the boundary.\"\"\"\n        return self._x_tangent_spline(dist)\n\n    def z_tangent(self, dist: Union[float, np.ndarray]) -> np.ndarray:\n        \"\"\"Find z at the tangent vector a given distance along the boundary.\"\"\"\n        return self._z_tangent_spline(dist)",
  "def norm_tangents(points: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculate the normalised tangent vector at each of the given points.\n\n    Parameters\n    ----------\n    points:\n        Array of coordinates. This must have shape (2, N), where N is\n        the number of points.\n\n    Returns\n    -------\n    The normalised vector of tangents.\n    \"\"\"\n    grad = np.gradient(points, axis=1)\n    magnitudes = np.hypot(grad[0], grad[1])\n    return np.divide(grad, magnitudes)",
  "def __init__(\n        self,\n        boundary_points: np.ndarray,\n        max_angle: float,\n        dx_min: float,\n        fix_num_panels: Optional[int] = None,\n    ):\n        self.max_angle = max_angle\n        self.dx_min = dx_min\n        self.boundary = LengthNormBoundary(boundary_points)\n\n        if fix_num_panels:\n            self.x0 = np.linspace(0, 1, fix_num_panels)[1:-1]\n        else:\n            # Build the initial guess of our panels, these points are the\n            # coordinates of where the panels tangent the boundary\n            _, idx = make_pivoted_string(\n                boundary_points.T,\n                max_angle=max_angle,\n                dx_min=dx_min,\n            )\n            self.x0: np.ndarray = self.boundary.length_norm[idx][1:-1]",
  "def n_panels(self) -> int:\n        \"\"\"The number of panels defined by this paneller.\"\"\"\n        return len(self.x0) + 2",
  "def joints(self, dists: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Calculate panel joint coordinates from panel-boundary tangent points.\n\n        Parameters\n        ----------\n        dists:\n            The normalised distances along the boundary at which there\n            are panel-boundary tangent points.\n        \"\"\"\n        # Add the start and end panel joints at distances 0 & 1\n        dists = np.hstack((0, dists, 1))\n        points = np.vstack((self.boundary.x(dists), self.boundary.z(dists)))\n        tangents = np.vstack(\n            (self.boundary.x_tangent(dists), self.boundary.z_tangent(dists))\n        )\n        # This could potentially be vectorized, if we need a speed up.\n        joints = np.zeros((2, len(dists) + 1))\n        joints[:, 0] = points[:, 0]\n        joints[:, -1] = points[:, -1]\n        for i in range(joints.shape[1] - 2):\n            joints[:, i + 1] = vector_intersect(\n                points[:, i],\n                points[:, i] + tangents[:, i],\n                points[:, i + 1],\n                points[:, i + 1] + tangents[:, i + 1],\n            )\n        return joints",
  "def length(self, dists: np.ndarray) -> float:\n        \"\"\"The cumulative length of the panels.\"\"\"\n        return self.panel_lengths(dists).sum()",
  "def angles(self, dists: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Return the angles of rotation between each set of adjacent panels.\n\n        Note that this is the tail-tail angle between the panel vectors,\n        not the head-tail angles.\n        \"\"\"\n        joints = self.joints(dists)\n        line_vectors = np.diff(joints, axis=1)\n        magnitudes = np.linalg.norm(line_vectors, axis=0)\n        # avoid division by zero later\n        magnitudes[np.isclose(magnitudes, 0)] += 1e-8\n        dots = (line_vectors[:, :-1] * line_vectors[:, 1:]).sum(axis=0)\n        dots /= magnitudes[:-1] * magnitudes[1:]\n        return np.degrees(np.arccos(np.clip(dots, -1.0, 1.0)), out=dots)",
  "def panel_lengths(self, dists: np.ndarray) -> np.ndarray:\n        \"\"\"Return the lengths of each panel.\"\"\"\n        panel_vecs = np.diff(self.joints(dists))\n        return np.hypot(panel_vecs[0], panel_vecs[1])",
  "def __init__(self, boundary_points: np.ndarray):\n        self.length_norm = vector_lengthnorm(boundary_points[0], boundary_points[1])\n        self._x_spline = InterpolatedUnivariateSpline(\n            self.length_norm, boundary_points[0]\n        )\n        self._z_spline = InterpolatedUnivariateSpline(\n            self.length_norm, boundary_points[1]\n        )\n\n        self.tangent_norm = norm_tangents(boundary_points)\n        self._x_tangent_spline = InterpolatedUnivariateSpline(\n            self.length_norm, self.tangent_norm[0]\n        )\n        self._z_tangent_spline = InterpolatedUnivariateSpline(\n            self.length_norm, self.tangent_norm[1]\n        )",
  "def x(self, dist: Union[float, np.ndarray]) -> np.ndarray:\n        \"\"\"Find x at the given normalised distance along the boundary.\"\"\"\n        return self._x_spline(dist)",
  "def z(self, dist: Union[float, np.ndarray]) -> np.ndarray:\n        \"\"\"Find z at the given normalised distance along the boundary.\"\"\"\n        return self._z_spline(dist)",
  "def x_tangent(self, dist: Union[float, np.ndarray]) -> np.ndarray:\n        \"\"\"Find x at the tangent vector a given distance along the boundary.\"\"\"\n        return self._x_tangent_spline(dist)",
  "def z_tangent(self, dist: Union[float, np.ndarray]) -> np.ndarray:\n        \"\"\"Find z at the tangent vector a given distance along the boundary.\"\"\"\n        return self._z_tangent_spline(dist)",
  "class IVCBoundaryParams(ParameterFrame):\n    \"\"\"Parameters for running the `WallSolver`.\"\"\"\n\n    tk_bb_ib: Parameter[float]  # Inboard blanket thickness\n    tk_bb_ob: Parameter[float]  # Outboard blanket thickness\n    ib_offset_angle: Parameter[float]  # 45 degrees\n    ob_offset_angle: Parameter[float]",
  "class IVCBoundaryDesigner(Designer[BluemiraWire]):\n    \"\"\"\n    Designs the IVC Boundary ie the Vacuum Vessel keep out zone\n\n    Parameters\n    ----------\n    params:\n        IVC Boundary designer parameters\n    wall_shape:\n        Wall shape as defined by the wall silhouette designer\n\n    \"\"\"\n\n    param_cls = IVCBoundaryParams\n\n    def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        wall_shape: BluemiraWire,\n    ):\n        super().__init__(params)\n\n        if not wall_shape.is_closed():\n            raise DesignError(\"Wall shape must be closed.\")\n        self.wall_shape = wall_shape\n\n    def run(self) -> BluemiraWire:\n        \"\"\"\n        Run the IVC Boundary designer\n        \"\"\"\n        return varied_offset(\n            self.wall_shape,\n            self.params.tk_bb_ib.value,\n            self.params.tk_bb_ob.value,\n            self.params.ib_offset_angle.value,\n            self.params.ob_offset_angle.value,\n        )",
  "def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        wall_shape: BluemiraWire,\n    ):\n        super().__init__(params)\n\n        if not wall_shape.is_closed():\n            raise DesignError(\"Wall shape must be closed.\")\n        self.wall_shape = wall_shape",
  "def run(self) -> BluemiraWire:\n        \"\"\"\n        Run the IVC Boundary designer\n        \"\"\"\n        return varied_offset(\n            self.wall_shape,\n            self.params.tk_bb_ib.value,\n            self.params.tk_bb_ob.value,\n            self.params.ib_offset_angle.value,\n            self.params.ob_offset_angle.value,\n        )",
  "class WallSilhouetteDesignerParams(ParameterFrame):\n    \"\"\"Parameters for running the `WallSilhouetteDesigner`.\"\"\"\n\n    R_0: Parameter[float]  # major radius\n    kappa_95: Parameter[float]  # 95th percentile plasma elongation\n    r_fw_ib_in: Parameter[float]  # inboard first wall inner radius\n    r_fw_ob_in: Parameter[float]  # inboard first wall outer radius\n    A: Parameter[float]  # aspect ratio\n    tk_sol_ib: Parameter[float]\n    fw_psi_n: Parameter[float]\n    div_L2D_ib: Parameter[float]\n    div_L2D_ob: Parameter[float]",
  "class WallSilhouetteDesigner(Designer[GeometryParameterisation]):\n    \"\"\"\n    Designs the first wall silhouette to inform the divertor and IVC design areas\n\n    Parameters\n    ----------\n    params:\n        Wall silhouette designer parameters\n    build_config:\n        configuration of the design\n    equilibrium:\n        The equilibrium to design around\n\n    \"\"\"\n\n    param_cls = WallSilhouetteDesignerParams\n\n    def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        equilibrium: Equilibrium,\n    ) -> None:\n        super().__init__(params, build_config)\n\n        self.parameterisation_cls: Type[\n            GeometryParameterisation\n        ] = get_class_from_module(\n            self.build_config[\"param_class\"],\n            default_module=\"bluemira.geometry.parameterisations\",\n        )\n\n        self.variables_map = self.build_config.get(\"variables_map\", {})\n        self.file_path = self.build_config.get(\"file_path\", None)\n\n        self.problem_settings = self.build_config.get(\"problem_settings\", {})\n        self.opt_config = self.build_config.get(\"optimisation_settings\", {})\n        self.algorithm_name = self.opt_config.get(\"algorithm_name\", \"SLSQP\")\n        self.opt_conditions = self.opt_config.get(\"conditions\", {\"max_eval\": 100})\n        self.opt_parameters = self.opt_config.get(\"parameters\", {})\n\n        self.equilibrium = equilibrium\n\n    def execute(self) -> GeometryParameterisation:\n        \"\"\"\n        Execute method of WallSilhouetteDesigner\n        \"\"\"\n        result = super().execute()\n\n        # TODO move to plasma component manager\n        _, x_points = find_OX_points(\n            self.equilibrium.x, self.equilibrium.z, self.equilibrium.psi()\n        )\n\n        if result.create_shape().bounding_box.z_min >= x_points[0].z:\n            raise DesignError(\"First wall boundary does not enclose separatrix x-point.\")\n        return result\n\n    def mock(self) -> GeometryParameterisation:\n        \"\"\"\n        Mock method of WallSilhouetteDesigner\n        \"\"\"\n        return self._get_parameterisation()\n\n    def read(self) -> GeometryParameterisation:\n        \"\"\"\n        Read method of WallSilhouetteDesigner\n        \"\"\"\n        if not self.file_path:\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'read' mode: no file path specified.\"\n            )\n        return self.parameterisation_cls.from_json(file=self.file_path)\n\n    def run(self) -> GeometryParameterisation:\n        \"\"\"\n        Optimise the shape using the provided parameterisation and optimiser.\n        \"\"\"\n        parameterisation = self._get_parameterisation()\n\n        def f_objective(geom: GeometryParameterisation) -> float:\n            \"\"\"Objective function to minimise a shape's length.\"\"\"\n            return geom.create_shape().length\n\n        bluemira_print(\"Solving WallSilhouette optimisation\")\n        bluemira_debug(\n            f\"Setting up design problem with:\\n\"\n            f\"algorithm_name: {self.algorithm_name}\\n\"\n            f\"n_variables: {parameterisation.variables.n_free_variables}\\n\"\n            f\"opt_conditions: {self.opt_conditions}\\n\"\n            f\"opt_parameters: {self.opt_parameters}\"\n        )\n\n        if self.problem_settings != {}:\n            bluemira_debug(\n                f\"Applying non-default settings to problem: {self.problem_settings}\"\n            )\n        result = optimise_geometry(\n            parameterisation,\n            algorithm=self.algorithm_name,\n            f_objective=f_objective,\n            opt_conditions=self.opt_conditions,\n            opt_parameters=self.opt_parameters,\n            keep_out_zones=[\n                KeepOutZone(\n                    self._make_wall_keep_out_zone(),\n                    n_discr=self.problem_settings.get(\"n_koz_points\", 100),\n                )\n            ],\n        )\n        return result.geom\n\n    def _get_parameterisation(self) -> GeometryParameterisation:\n        return self.parameterisation_cls(self._derive_shape_params())\n\n    def _derive_shape_params(self) -> Dict:\n        shape_params = {}\n        for key, val in self.variables_map.items():\n            if isinstance(val, str):\n                val = getattr(self.params, val).value\n\n            if isinstance(val, dict):\n                if isinstance(val[\"value\"], str):\n                    val[\"value\"] = getattr(self.params, val[\"value\"]).value\n            else:\n                val = {\"value\": val}\n\n            shape_params[key] = val\n\n        if issubclass(self.parameterisation_cls, PolySpline):\n            height_value = self._derive_polyspline_height()\n            shape_params[\"height\"] = {\n                \"value\": height_value,\n                \"lower_bound\": 0.8 * height_value,\n                \"upper_bound\": 2.0 * height_value,\n            }\n\n        return shape_params\n\n    def _derive_polyspline_height(self) -> float:\n        \"\"\"Derive the PolySpline height from relevant parameters.\"\"\"\n        r_minor = self.params.R_0.value / self.params.A.value\n        return (self.params.kappa_95.value * r_minor) * 2\n\n    def _make_wall_keep_out_zone(self) -> BluemiraWire:\n        \"\"\"\n        Create a \"keep-out zone\" to be used as a constraint in the\n        wall shape optimiser.\n        \"\"\"\n        geom_offset = self.params.tk_sol_ib.value\n        psi_n = self.params.fw_psi_n.value\n        geom_offset = 0.2  # TODO: Unpin\n        psi_n = 1.05  # TODO: Unpin\n        geom_offset_zone = self._make_geometric_keep_out_zone(geom_offset)\n        flux_surface_zone = self._make_flux_surface_keep_out_zone(psi_n)\n        leg_zone = self._make_divertor_leg_keep_out_zone(\n            self.params.div_L2D_ib.value, self.params.div_L2D_ob.value\n        )\n        return convex_hull_wires_2d(\n            [geom_offset_zone, flux_surface_zone, leg_zone], ndiscr=200, plane=\"xz\"\n        )\n\n    def _make_geometric_keep_out_zone(self, offset: float) -> BluemiraWire:\n        \"\"\"\n        Make a \"keep-out zone\" from a geometric offset of the LCFS.\n        \"\"\"\n        lcfs = make_polygon(self.equilibrium.get_LCFS().xyz, closed=True)\n        return offset_wire(lcfs, offset, join=\"arc\")\n\n    def _make_flux_surface_keep_out_zone(self, psi_n: float) -> BluemiraWire:\n        \"\"\"\n        Make a \"keep-out zone\" from an equilibrium's flux surface.\n        \"\"\"\n        # TODO: This is currently called three times once here, once above\n        # and once for setup of the remaining ivc\n        o_points, _ = find_OX_points(\n            self.equilibrium.x, self.equilibrium.z, self.equilibrium.psi()\n        )\n        flux_surface_zone = self.equilibrium.get_flux_surface(psi_n)\n        # Chop the flux surface to only take the upper half\n        indices = flux_surface_zone.z >= o_points[0][1]\n        flux_surface_zone = make_polygon(flux_surface_zone.xyz[:, indices], closed=True)\n        return flux_surface_zone\n\n    def _make_divertor_leg_keep_out_zone(\n        self, leg_length_ib_2D, leg_length_ob_2D\n    ) -> BluemiraWire:\n        \"\"\"\n        Make a \"keep-out zone\" from an equilibrium's divertor legs\n        \"\"\"\n        # TODO move to plasma component manager\n        legs = get_legs(self.equilibrium, n_layers=1, dx_off=0.0)\n\n        ib_leg = make_polygon(legs[\"lower_inner\"][0].xyz)\n        ob_leg = make_polygon(legs[\"lower_outer\"][0].xyz)\n\n        return make_polygon(\n            [\n                ib_leg.value_at(distance=leg_length_ib_2D),\n                ob_leg.value_at(distance=leg_length_ob_2D),\n            ],\n            closed=False,\n        )",
  "def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        equilibrium: Equilibrium,\n    ) -> None:\n        super().__init__(params, build_config)\n\n        self.parameterisation_cls: Type[\n            GeometryParameterisation\n        ] = get_class_from_module(\n            self.build_config[\"param_class\"],\n            default_module=\"bluemira.geometry.parameterisations\",\n        )\n\n        self.variables_map = self.build_config.get(\"variables_map\", {})\n        self.file_path = self.build_config.get(\"file_path\", None)\n\n        self.problem_settings = self.build_config.get(\"problem_settings\", {})\n        self.opt_config = self.build_config.get(\"optimisation_settings\", {})\n        self.algorithm_name = self.opt_config.get(\"algorithm_name\", \"SLSQP\")\n        self.opt_conditions = self.opt_config.get(\"conditions\", {\"max_eval\": 100})\n        self.opt_parameters = self.opt_config.get(\"parameters\", {})\n\n        self.equilibrium = equilibrium",
  "def execute(self) -> GeometryParameterisation:\n        \"\"\"\n        Execute method of WallSilhouetteDesigner\n        \"\"\"\n        result = super().execute()\n\n        # TODO move to plasma component manager\n        _, x_points = find_OX_points(\n            self.equilibrium.x, self.equilibrium.z, self.equilibrium.psi()\n        )\n\n        if result.create_shape().bounding_box.z_min >= x_points[0].z:\n            raise DesignError(\"First wall boundary does not enclose separatrix x-point.\")\n        return result",
  "def mock(self) -> GeometryParameterisation:\n        \"\"\"\n        Mock method of WallSilhouetteDesigner\n        \"\"\"\n        return self._get_parameterisation()",
  "def read(self) -> GeometryParameterisation:\n        \"\"\"\n        Read method of WallSilhouetteDesigner\n        \"\"\"\n        if not self.file_path:\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'read' mode: no file path specified.\"\n            )\n        return self.parameterisation_cls.from_json(file=self.file_path)",
  "def run(self) -> GeometryParameterisation:\n        \"\"\"\n        Optimise the shape using the provided parameterisation and optimiser.\n        \"\"\"\n        parameterisation = self._get_parameterisation()\n\n        def f_objective(geom: GeometryParameterisation) -> float:\n            \"\"\"Objective function to minimise a shape's length.\"\"\"\n            return geom.create_shape().length\n\n        bluemira_print(\"Solving WallSilhouette optimisation\")\n        bluemira_debug(\n            f\"Setting up design problem with:\\n\"\n            f\"algorithm_name: {self.algorithm_name}\\n\"\n            f\"n_variables: {parameterisation.variables.n_free_variables}\\n\"\n            f\"opt_conditions: {self.opt_conditions}\\n\"\n            f\"opt_parameters: {self.opt_parameters}\"\n        )\n\n        if self.problem_settings != {}:\n            bluemira_debug(\n                f\"Applying non-default settings to problem: {self.problem_settings}\"\n            )\n        result = optimise_geometry(\n            parameterisation,\n            algorithm=self.algorithm_name,\n            f_objective=f_objective,\n            opt_conditions=self.opt_conditions,\n            opt_parameters=self.opt_parameters,\n            keep_out_zones=[\n                KeepOutZone(\n                    self._make_wall_keep_out_zone(),\n                    n_discr=self.problem_settings.get(\"n_koz_points\", 100),\n                )\n            ],\n        )\n        return result.geom",
  "def _get_parameterisation(self) -> GeometryParameterisation:\n        return self.parameterisation_cls(self._derive_shape_params())",
  "def _derive_shape_params(self) -> Dict:\n        shape_params = {}\n        for key, val in self.variables_map.items():\n            if isinstance(val, str):\n                val = getattr(self.params, val).value\n\n            if isinstance(val, dict):\n                if isinstance(val[\"value\"], str):\n                    val[\"value\"] = getattr(self.params, val[\"value\"]).value\n            else:\n                val = {\"value\": val}\n\n            shape_params[key] = val\n\n        if issubclass(self.parameterisation_cls, PolySpline):\n            height_value = self._derive_polyspline_height()\n            shape_params[\"height\"] = {\n                \"value\": height_value,\n                \"lower_bound\": 0.8 * height_value,\n                \"upper_bound\": 2.0 * height_value,\n            }\n\n        return shape_params",
  "def _derive_polyspline_height(self) -> float:\n        \"\"\"Derive the PolySpline height from relevant parameters.\"\"\"\n        r_minor = self.params.R_0.value / self.params.A.value\n        return (self.params.kappa_95.value * r_minor) * 2",
  "def _make_wall_keep_out_zone(self) -> BluemiraWire:\n        \"\"\"\n        Create a \"keep-out zone\" to be used as a constraint in the\n        wall shape optimiser.\n        \"\"\"\n        geom_offset = self.params.tk_sol_ib.value\n        psi_n = self.params.fw_psi_n.value\n        geom_offset = 0.2  # TODO: Unpin\n        psi_n = 1.05  # TODO: Unpin\n        geom_offset_zone = self._make_geometric_keep_out_zone(geom_offset)\n        flux_surface_zone = self._make_flux_surface_keep_out_zone(psi_n)\n        leg_zone = self._make_divertor_leg_keep_out_zone(\n            self.params.div_L2D_ib.value, self.params.div_L2D_ob.value\n        )\n        return convex_hull_wires_2d(\n            [geom_offset_zone, flux_surface_zone, leg_zone], ndiscr=200, plane=\"xz\"\n        )",
  "def _make_geometric_keep_out_zone(self, offset: float) -> BluemiraWire:\n        \"\"\"\n        Make a \"keep-out zone\" from a geometric offset of the LCFS.\n        \"\"\"\n        lcfs = make_polygon(self.equilibrium.get_LCFS().xyz, closed=True)\n        return offset_wire(lcfs, offset, join=\"arc\")",
  "def _make_flux_surface_keep_out_zone(self, psi_n: float) -> BluemiraWire:\n        \"\"\"\n        Make a \"keep-out zone\" from an equilibrium's flux surface.\n        \"\"\"\n        # TODO: This is currently called three times once here, once above\n        # and once for setup of the remaining ivc\n        o_points, _ = find_OX_points(\n            self.equilibrium.x, self.equilibrium.z, self.equilibrium.psi()\n        )\n        flux_surface_zone = self.equilibrium.get_flux_surface(psi_n)\n        # Chop the flux surface to only take the upper half\n        indices = flux_surface_zone.z >= o_points[0][1]\n        flux_surface_zone = make_polygon(flux_surface_zone.xyz[:, indices], closed=True)\n        return flux_surface_zone",
  "def _make_divertor_leg_keep_out_zone(\n        self, leg_length_ib_2D, leg_length_ob_2D\n    ) -> BluemiraWire:\n        \"\"\"\n        Make a \"keep-out zone\" from an equilibrium's divertor legs\n        \"\"\"\n        # TODO move to plasma component manager\n        legs = get_legs(self.equilibrium, n_layers=1, dx_off=0.0)\n\n        ib_leg = make_polygon(legs[\"lower_inner\"][0].xyz)\n        ob_leg = make_polygon(legs[\"lower_outer\"][0].xyz)\n\n        return make_polygon(\n            [\n                ib_leg.value_at(distance=leg_length_ib_2D),\n                ob_leg.value_at(distance=leg_length_ob_2D),\n            ],\n            closed=False,\n        )",
  "def f_objective(geom: GeometryParameterisation) -> float:\n            \"\"\"Objective function to minimise a shape's length.\"\"\"\n            return geom.create_shape().length",
  "class WallPolySpline(PolySpline):\n    \"\"\"\n    Defines the geometry for reactor first wall, without a divertor,\n    based on the PolySpline parameterisation.\n    \"\"\"\n\n    _defaults = {\n        \"x1\": {\"value\": 5.8},\n        \"x2\": {\"value\": 12.1},\n        \"z2\": {\"value\": 0},\n        \"height\": {\"value\": 9.3},\n        \"top\": {\"value\": 0.4},\n        \"upper\": {\"value\": 0.3},\n        \"dz\": {\"value\": -0.5},\n        \"tilt\": {\"value\": 0},\n        \"lower\": {\"value\": 0.5},\n        \"bottom\": {\"value\": 0.2},\n    }\n\n    def __init__(self, var_dict: Optional[VarDictT] = None):\n        defaults = copy.deepcopy(self._defaults)\n        if var_dict:\n            defaults.update(var_dict)\n        super().__init__(defaults)\n\n        ib_radius = self.variables.x1.value\n        ob_radius = self.variables.x2.value\n        z2 = self.variables.z2.value\n        height = self.variables.height.value\n        top = self.variables.top.value\n        upper = self.variables.upper.value\n        dz = self.variables.dz.value\n        tilt = self.variables.tilt.value\n        lower = self.variables.lower.value\n        bottom = self.variables.bottom.value\n\n        if not self.variables.x1.fixed:\n            self.adjust_variable(\n                \"x1\",\n                ib_radius,\n                lower_bound=ib_radius - 2,\n                upper_bound=ib_radius * 1.1,\n            )\n        if not self.variables.x2.fixed:\n            self.adjust_variable(\n                \"x2\",\n                value=ob_radius,\n                lower_bound=ob_radius * 0.9,\n                upper_bound=ob_radius + 2,\n            )\n        self.adjust_variable(\"z2\", z2, lower_bound=-0.9, upper_bound=0.9)\n        self.adjust_variable(\n            \"height\", height, lower_bound=height - 0.001, upper_bound=50\n        )\n        self.adjust_variable(\"top\", top, lower_bound=0.05, upper_bound=0.75)\n        self.adjust_variable(\"upper\", upper, lower_bound=0.2, upper_bound=0.7)\n        self.adjust_variable(\"dz\", dz, lower_bound=-5, upper_bound=5)\n        self.adjust_variable(\"tilt\", tilt, lower_bound=-25, upper_bound=25)\n        self.adjust_variable(\"lower\", lower, lower_bound=0.2, upper_bound=0.7)\n        self.adjust_variable(\"bottom\", bottom, lower_bound=0.05, upper_bound=0.75)\n\n        # Fix 'flat' to avoid drawing the PolySpline's outer straight.\n        # The straight is often optimised to near-zero length, which\n        # causes an error when CAD tries to draw it\n        self.fix_variable(\"flat\", 0)",
  "class WallPrincetonD(PrincetonD):\n    \"\"\"\n    Defines the geometry for reactor first wall, without a divertor,\n    based on the PrincetonD parameterisation.\n    \"\"\"\n\n    _defaults: Dict[str, OptVarVarDictValueT] = {\n        \"x1\": {\"value\": 5.8},\n        \"x2\": {\"value\": 12.1},\n        \"dz\": {\"value\": -0.5},\n    }\n\n    def __init__(self, var_dict: Optional[VarDictT] = None):\n        defaults = copy.deepcopy(self._defaults)\n        if var_dict:\n            defaults.update(var_dict)\n        super().__init__(defaults)\n\n        ib_radius = self.variables.x1.value\n        ob_radius = self.variables.x2.value\n        if not self.variables.x1.fixed:\n            self.adjust_variable(\n                \"x1\", ib_radius, lower_bound=ib_radius - 2, upper_bound=ib_radius * 1.02\n            )\n\n        if not self.variables.x2.fixed:\n            self.adjust_variable(\n                \"x2\", ob_radius, lower_bound=ob_radius * 0.98, upper_bound=ob_radius + 2\n            )\n        self.adjust_variable(\n            \"dz\", self.variables.dz.value, lower_bound=-3, upper_bound=3\n        )",
  "def __init__(self, var_dict: Optional[VarDictT] = None):\n        defaults = copy.deepcopy(self._defaults)\n        if var_dict:\n            defaults.update(var_dict)\n        super().__init__(defaults)\n\n        ib_radius = self.variables.x1.value\n        ob_radius = self.variables.x2.value\n        z2 = self.variables.z2.value\n        height = self.variables.height.value\n        top = self.variables.top.value\n        upper = self.variables.upper.value\n        dz = self.variables.dz.value\n        tilt = self.variables.tilt.value\n        lower = self.variables.lower.value\n        bottom = self.variables.bottom.value\n\n        if not self.variables.x1.fixed:\n            self.adjust_variable(\n                \"x1\",\n                ib_radius,\n                lower_bound=ib_radius - 2,\n                upper_bound=ib_radius * 1.1,\n            )\n        if not self.variables.x2.fixed:\n            self.adjust_variable(\n                \"x2\",\n                value=ob_radius,\n                lower_bound=ob_radius * 0.9,\n                upper_bound=ob_radius + 2,\n            )\n        self.adjust_variable(\"z2\", z2, lower_bound=-0.9, upper_bound=0.9)\n        self.adjust_variable(\n            \"height\", height, lower_bound=height - 0.001, upper_bound=50\n        )\n        self.adjust_variable(\"top\", top, lower_bound=0.05, upper_bound=0.75)\n        self.adjust_variable(\"upper\", upper, lower_bound=0.2, upper_bound=0.7)\n        self.adjust_variable(\"dz\", dz, lower_bound=-5, upper_bound=5)\n        self.adjust_variable(\"tilt\", tilt, lower_bound=-25, upper_bound=25)\n        self.adjust_variable(\"lower\", lower, lower_bound=0.2, upper_bound=0.7)\n        self.adjust_variable(\"bottom\", bottom, lower_bound=0.05, upper_bound=0.75)\n\n        # Fix 'flat' to avoid drawing the PolySpline's outer straight.\n        # The straight is often optimised to near-zero length, which\n        # causes an error when CAD tries to draw it\n        self.fix_variable(\"flat\", 0)",
  "def __init__(self, var_dict: Optional[VarDictT] = None):\n        defaults = copy.deepcopy(self._defaults)\n        if var_dict:\n            defaults.update(var_dict)\n        super().__init__(defaults)\n\n        ib_radius = self.variables.x1.value\n        ob_radius = self.variables.x2.value\n        if not self.variables.x1.fixed:\n            self.adjust_variable(\n                \"x1\", ib_radius, lower_bound=ib_radius - 2, upper_bound=ib_radius * 1.02\n            )\n\n        if not self.variables.x2.fixed:\n            self.adjust_variable(\n                \"x2\", ob_radius, lower_bound=ob_radius * 0.98, upper_bound=ob_radius + 2\n            )\n        self.adjust_variable(\n            \"dz\", self.variables.dz.value, lower_bound=-3, upper_bound=3\n        )",
  "class PlasmaFaceDesignerParams(ParameterFrame):\n    \"\"\"Parameters for running the :class:`.PlasmaFaceDesigner`.\"\"\"\n\n    div_type: Parameter[str]\n    c_rm: Parameter[float]",
  "class PlasmaFaceDesigner(Designer[Tuple[BluemiraFace, BluemiraFace]]):\n    \"\"\"\n    Designs the Plasma facing keep out zones\n\n    Parameters\n    ----------\n    params:\n        Plasma face designer parameters\n    ivc_boundary:\n        IVC boundary keep out zone\n    wall_boundary:\n        wall boundary keep out zone (cut at divertor)\n    divertor_silhouette:\n        divertor keep out zone\n    \"\"\"\n\n    param_cls = PlasmaFaceDesignerParams\n    params: PlasmaFaceDesignerParams\n\n    def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        ivc_boundary: BluemiraWire,\n        wall_boundary: BluemiraWire,\n        divertor_silhouette: Tuple[BluemiraWire, ...],\n    ):\n        super().__init__(params)\n        if self.params.div_type.value == \"DN\":\n            raise NotImplementedError(\"Double Null divertor not implemented\")\n        self.ivc_boundary = ivc_boundary\n        self.wall_boundary = wall_boundary\n        self.divertor_silhouette = divertor_silhouette\n\n    def run(self) -> Tuple[BluemiraFace, BluemiraFace]:\n        \"\"\"\n        Run method for PlasmaFaceDesigner\n        \"\"\"\n        # For double null this and self.divertor_silhouette need a structure\n        # to accommodate two divertors\n        plasma_facing_wire = BluemiraWire(\n            [self.wall_boundary, *self.divertor_silhouette]\n        )\n\n        in_vessel_face = BluemiraFace([self.ivc_boundary, plasma_facing_wire])\n\n        # Cut a clearance between the blankets and divertor - getting two\n        # new faces\n        vessel_bbox = in_vessel_face.bounding_box\n        # The minimum z-value of the wall boundary. The boundary should\n        # be open at the lower end and the start and end points of the\n        # wire should be at the same z. But take the minimum z value of\n        # the start and end points.\n        # Note we do not use bounding_box here due to a bug: 34228d3\n        min_z = min(self.wall_boundary.start_point().z, self.wall_boundary.end_point().z)\n        rm_clearance_face = _make_clearance_face(\n            vessel_bbox.x_min,\n            vessel_bbox.x_max,\n            min_z,\n            self.params.c_rm.value,\n        )\n\n        return _cut_vessel_shape(in_vessel_face, rm_clearance_face)",
  "def _make_clearance_face(\n    x_min: float, x_max: float, z: float, thickness: float\n) -> BluemiraFace:\n    \"\"\"\n    Makes a rectangular face in xz with the given thickness in z.\n\n    The face is intended to be used to cut a remote maintenance\n    clearance between blankets and divertor.\n    \"\"\"\n    x_coords = np.zeros(4)\n    x_coords[:2] = x_min\n    x_coords[2:] = x_max\n\n    y_coords = np.zeros(4)\n\n    z_coords = np.zeros(4)\n    z_coords[[0, 3]] = z + thickness / 2\n    z_coords[[1, 2]] = z - thickness / 2\n\n    return BluemiraFace(make_polygon([x_coords, y_coords, z_coords], closed=True))",
  "def _cut_vessel_shape(\n    in_vessel_face: BluemiraFace, rm_clearance_face: BluemiraFace\n) -> Tuple[BluemiraFace, BluemiraFace]:\n    \"\"\"\n    Cut a remote maintenance clearance into the given vessel shape.\n    \"\"\"\n    pieces = boolean_cut(in_vessel_face, [rm_clearance_face])\n    blanket_face = pieces[np.argmax([p.center_of_mass[2] for p in pieces])]\n    divertor_face = pieces[np.argmin([p.center_of_mass[2] for p in pieces])]\n    return blanket_face, divertor_face",
  "def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        ivc_boundary: BluemiraWire,\n        wall_boundary: BluemiraWire,\n        divertor_silhouette: Tuple[BluemiraWire, ...],\n    ):\n        super().__init__(params)\n        if self.params.div_type.value == \"DN\":\n            raise NotImplementedError(\"Double Null divertor not implemented\")\n        self.ivc_boundary = ivc_boundary\n        self.wall_boundary = wall_boundary\n        self.divertor_silhouette = divertor_silhouette",
  "def run(self) -> Tuple[BluemiraFace, BluemiraFace]:\n        \"\"\"\n        Run method for PlasmaFaceDesigner\n        \"\"\"\n        # For double null this and self.divertor_silhouette need a structure\n        # to accommodate two divertors\n        plasma_facing_wire = BluemiraWire(\n            [self.wall_boundary, *self.divertor_silhouette]\n        )\n\n        in_vessel_face = BluemiraFace([self.ivc_boundary, plasma_facing_wire])\n\n        # Cut a clearance between the blankets and divertor - getting two\n        # new faces\n        vessel_bbox = in_vessel_face.bounding_box\n        # The minimum z-value of the wall boundary. The boundary should\n        # be open at the lower end and the start and end points of the\n        # wire should be at the same z. But take the minimum z value of\n        # the start and end points.\n        # Note we do not use bounding_box here due to a bug: 34228d3\n        min_z = min(self.wall_boundary.start_point().z, self.wall_boundary.end_point().z)\n        rm_clearance_face = _make_clearance_face(\n            vessel_bbox.x_min,\n            vessel_bbox.x_max,\n            min_z,\n            self.params.c_rm.value,\n        )\n\n        return _cut_vessel_shape(in_vessel_face, rm_clearance_face)",
  "class IVCShapes:\n    \"\"\"Collection of geometries used to design/build in-vessel components.\"\"\"\n\n    blanket_face: BluemiraFace\n    divertor_face: BluemiraFace\n    outer_boundary: BluemiraWire\n    inner_boundary: BluemiraWire",
  "def design_ivc(\n    params: ParameterFrame, build_config: Dict, equilibrium: Equilibrium\n) -> IVCShapes:\n    \"\"\"\n    Run the IVC component designers in sequence.\n\n    Returns\n    -------\n    blanket_face: BluemiraFace\n        Face of the blanket, does not include anything below the\n        divertor.\n    divertor_face: BluemiraFace\n        A face with the shape of divertor in xz.\n    ive_boundary: BluemiraWire\n        A wire defining the xz boundary of the in-vessel components.\n    \"\"\"\n    wall_boundary = run_designer(\n        WallSilhouetteDesigner,\n        params,\n        build_config[\"Wall silhouette\"],\n        equilibrium=equilibrium,\n    ).create_shape(label=\"wall\")\n    _, x_points = find_OX_points(equilibrium.x, equilibrium.z, equilibrium.psi())\n    cut_wall_boundary = cut_wall_below_x_point(wall_boundary, x_points[0].z)\n    divertor_shapes = DivertorSilhouetteDesigner(\n        params,\n        equilibrium=equilibrium,\n        wall=cut_wall_boundary,\n    ).execute()\n    ivc_boundary = IVCBoundaryDesigner(params, wall_shape=wall_boundary).execute()\n    plasma_face, divertor_face = PlasmaFaceDesigner(\n        params,\n        ivc_boundary=ivc_boundary,\n        wall_boundary=cut_wall_boundary,\n        divertor_silhouette=divertor_shapes,\n    ).execute()\n\n    # We have already cut the wall boundary once below the x-point in\n    # order to generate our blanket face. However, we then cut that\n    # blanket face using some thickness (remote maintenance clearance).\n    # We want the boundary wire and face to start and end at the same\n    # place, so we cut the wire again here.\n    wall_boundary = cut_wall_below_x_point(wall_boundary, plasma_face.bounding_box.z_min)\n    return IVCShapes(\n        blanket_face=plasma_face,\n        divertor_face=divertor_face,\n        outer_boundary=ivc_boundary,\n        inner_boundary=wall_boundary,\n    )",
  "def cut_wall_below_x_point(shape: BluemiraWire, x_point_z: float) -> BluemiraWire:\n    \"\"\"\n    Remove the parts of the wire below the given value in the z-axis.\n    \"\"\"\n    # Create a box that surrounds the wall below the given z\n    # coordinate, then perform a boolean cut to remove that portion\n    # of the wall's shape.\n    bounding_box = shape.bounding_box\n    cut_box_points = np.array(\n        [\n            [bounding_box.x_min, 0, bounding_box.z_min],\n            [bounding_box.x_min, 0, x_point_z],\n            [bounding_box.x_max, 0, x_point_z],\n            [bounding_box.x_max, 0, bounding_box.z_min],\n            [bounding_box.x_min, 0, bounding_box.z_min],\n        ]\n    )\n    cut_zone = make_polygon(cut_box_points, label=\"_shape_cut_exclusion\", closed=True)\n    # For a single-null, we expect three 'pieces' from the cut: the\n    # upper wall shape and the two separatrix legs\n    pieces = boolean_cut(shape, [cut_zone])\n\n    wall_piece = pieces[np.argmax([p.center_of_mass[2] for p in pieces])]\n    if wall_piece.center_of_mass[2] < x_point_z:\n        raise ValueError(\n            \"Could not cut wall shape below x-point. \"\n            \"No parts of the wall found above x-point.\"\n        )\n    return wall_piece",
  "class Divertor(ComponentManager):\n    \"\"\"\n    Wrapper around a divertor component tree.\n    \"\"\"\n\n    def silhouette(self) -> BluemiraWire:\n        \"\"\"Return a wire representing the divertor poloidal silhouette.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(DivertorBuilder.BODY)\n            .shape.boundary[0]\n        )",
  "class DivertorSilhouetteParams(ParameterFrame):\n    \"\"\"Parameters for running the `DivertorSilhouetteDesigner`.\"\"\"\n\n    div_type: Parameter[str]\n    div_L2D_ib: Parameter[float]\n    div_L2D_ob: Parameter[float]\n    div_Ltarg: Parameter[float]  # noqa: N815\n    div_open: Parameter[bool]",
  "class LegPosition(enum.Enum):\n    \"\"\"\n    Enum classifying divertor/separatrix leg positions\n    \"\"\"\n\n    INNER = enum.auto()\n    OUTER = enum.auto()",
  "class WireEndAxis(enum.Enum):\n    \"\"\"\n    Enum for wire end axis\n    \"\"\"\n\n    X = enum.auto()\n    Z = enum.auto()",
  "def get_separatrix_legs(\n    equilibrium: Equilibrium,\n) -> Dict[LegPosition, List[BluemiraWire]]:\n    \"\"\"\n    Find the separatrix legs for the given equilibrium.\n    \"\"\"\n    # A flag specifying which end of the plasma (i.e., upper or lower)\n    # we want the legs from will need to be added\n    legs = get_legs(equilibrium)\n    separatrix_legs = {\n        LegPosition.INNER: [make_polygon(loop.xyz) for loop in legs[\"lower_inner\"]],\n        LegPosition.OUTER: [make_polygon(loop.xyz) for loop in legs[\"lower_outer\"]],\n    }\n    return separatrix_legs",
  "class DivertorSilhouetteDesigner(Designer[Tuple[BluemiraWire, ...]]):\n    \"\"\"\n    Designs the divertor silhouette to help design the divertor keep out zone\n\n    Parameters\n    ----------\n    params:\n        Divertor silhouette designer parameters\n    equilibrium:\n        The equilibrium to design around\n    wall:\n        wall boundary keep out zone (cut at divertor)\n\n    \"\"\"\n\n    INNER_BAFFLE = \"inner_baffle\"\n    OUTER_BAFFLE = \"outer_baffle\"\n    DOME = \"dome\"\n    INNER_TARGET = \"inner_target\"\n    OUTER_TARGET = \"outer_target\"\n\n    param_cls = DivertorSilhouetteParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        equilibrium: Equilibrium,\n        wall: BluemiraWire,\n    ):\n        super().__init__(params)\n        if self.params.div_type.value == \"DN\":\n            raise NotImplementedError(\"Double Null divertor not implemented\")\n\n        self.equilibrium = equilibrium\n        self.x_limits = (wall.start_point().x[0], wall.end_point().x[0])\n        self.z_limits = (wall.start_point().z[0], wall.end_point().z[0])\n        self.leg_length = {\n            LegPosition.INNER: self.params.div_L2D_ib,\n            LegPosition.OUTER: self.params.div_L2D_ob,\n        }\n        self.separatrix_legs = get_separatrix_legs(self.equilibrium)\n\n    def run(self) -> Tuple[BluemiraWire, ...]:\n        \"\"\"\n        Run method of DivertorSilhouetteDesigner\n        \"\"\"\n        # Build the targets for each separatrix leg\n        inner_target = self.make_target(LegPosition.INNER, self.INNER_TARGET)\n        outer_target = self.make_target(LegPosition.OUTER, self.OUTER_TARGET)\n\n        # Build the dome based on target positions\n        inner_target_end = self._get_wire_end_with_smallest(inner_target, \"z\")\n        outer_target_start = self._get_wire_end_with_smallest(outer_target, \"z\")\n\n        dome = self.make_dome(inner_target_end, outer_target_start, label=self.DOME)\n\n        # Build the baffles\n        idx_inner = np.argmin(self.x_limits)\n        idx_outer = np.argmax(self.x_limits)\n\n        inner_baffle = self.make_inner_baffle(\n            inner_target, self.x_limits[idx_inner], self.z_limits[idx_inner]\n        )\n        outer_baffle = self.make_outer_baffle(\n            outer_target, self.x_limits[idx_outer], self.z_limits[idx_outer]\n        )\n\n        return inner_baffle, inner_target, dome, outer_target, outer_baffle\n\n    def make_target(self, leg: LegPosition, label: str) -> BluemiraWire:\n        \"\"\"\n        Make a divertor target for a the given leg.\n        \"\"\"\n        sols = self._get_sols_for_leg(leg)\n\n        # Just use the first scrape-off layer for now\n        point = sols[0].value_at(distance=self.leg_length[leg].value)\n\n        # Create some vertical targets for now. Eventually the target\n        # angle will be derived from the grazing-angle parameter\n        target_length = self.params.div_Ltarg.value\n        target_coords = np.array(\n            [\n                [point[0], point[0]],\n                [point[1], point[1]],\n                [point[2] - target_length / 2, point[2] + target_length / 2],\n            ]\n        )\n        return make_polygon(target_coords, label=label)\n\n    def make_dome(\n        self, start: Sequence[float], end: Sequence[float], label: str\n    ) -> BluemiraWire:\n        \"\"\"\n        Make a dome between the two given points.\n\n        Notes\n        -----\n        The dome shape follows a constant line of flux that is closest to the input\n        coordinates.\n        The nearest point on the flux surface to the start point and the end point are\n        joined.\n        The flux surface is picked based on the lowest z coordinate of the start and end\n        point to ensure a continuous divertor shape is produced.\n        \"\"\"\n        # Get the flux surface that crosses the through the start or end point.\n        # We can use this surface to guide the shape of the dome.\n        psi_start = self.equilibrium.psi(*(start if start[1] < end[1] else end))\n        flux_surface = find_flux_surface_through_point(\n            self.equilibrium.x,\n            self.equilibrium.z,\n            self.equilibrium.psi(),\n            start[0],\n            start[1],\n            psi_start,\n        )\n\n        # Get the indices of the closest points on the flux surface to\n        # the input start and end points\n        start_coord = np.array([[start[0]], [start[1]]])  # [[x], [z]]\n        end_coord = np.array([[end[0]], [end[1]]])\n        idx = np.array(\n            [\n                np.argmin(np.hypot(*(flux_surface - start_coord))),\n                np.argmin(np.hypot(*(flux_surface - end_coord))),\n            ]\n        )\n\n        # Make sure the start and end are in the right order\n        if idx[0] > idx[1]:\n            idx = idx[::-1]\n            dome_contour = flux_surface[:, idx[0] + 1 : idx[1]]\n            dome_contour = dome_contour[:, ::-1]\n        else:\n            dome_contour = flux_surface[:, idx[0] + 1 : idx[1]]\n\n        # Build the coords of the dome in 3D (all(y == 0))\n        dome = np.zeros((3, dome_contour.shape[1] + 2))\n        dome[(0, 2), 0] = start_coord.T\n        dome[(0, 2), 1:-1] = dome_contour\n        dome[(0, 2), -1] = end_coord.T\n\n        return make_polygon(dome, label=label)\n\n    def _make_baffle(\n        self,\n        label: str,\n        start: Sequence[float],\n        end: Sequence[float],\n    ) -> BluemiraWire:\n        \"\"\"\n        Make a baffle.\n        The baffle shape is a straight line between the given start and\n        end points.\n\n        Parameters\n        ----------\n        label:\n            The label to give the returned Component.\n        start:\n            The position (in x-z) to start drawing the baffle from,\n            e.g., the outside end of a target.\n        end:\n            The position (in x-z) to stop drawing the baffle, e.g., the\n            position to the upper part of the first wall.\n        \"\"\"\n        return make_polygon(\n            np.array([[start[0], end[0]], [0, 0], [start[1], end[1]]]), label=label\n        )\n\n    def make_inner_baffle(\n        self,\n        target: BluemiraWire,\n        x_lim: float,\n        z_lim: float,\n    ) -> BluemiraWire:\n        \"\"\"\n        Build the inner baffle to join with the given target.\n        \"\"\"\n        if self.params.div_open.value:\n            raise NotImplementedError(\"Open divertor baffles not yet supported\")\n        else:\n            inner_target_start = self._get_wire_end_with_largest(target, \"x\")\n        return self._make_baffle(\n            label=self.INNER_BAFFLE,\n            start=np.array([x_lim, z_lim]),\n            end=inner_target_start,\n        )\n\n    def make_outer_baffle(\n        self,\n        target: BluemiraWire,\n        x_lim: float,\n        z_lim: float,\n    ) -> BluemiraWire:\n        \"\"\"\n        Build the outer baffle to join with the given target.\n        \"\"\"\n        if self.params.div_open.value:\n            raise NotImplementedError(\"Open divertor baffles not yet supported\")\n        else:\n            outer_target_end = self._get_wire_end_with_largest(target, \"x\")\n        return self._make_baffle(\n            label=self.OUTER_BAFFLE,\n            start=outer_target_end,\n            end=np.array([x_lim, z_lim]),\n        )\n\n    def _get_sols_for_leg(\n        self, leg: LegPosition, layers: Iterable[int] = (0, -1)\n    ) -> List[BluemiraWire]:\n        \"\"\"\n        Get the selected scrape-off-leg layers from the separatrix legs.\n        \"\"\"\n        sols = []\n        for layer in layers:\n            sols.append(self.separatrix_legs[leg][layer])\n        return sols\n\n    @staticmethod\n    def _get_wire_end_with_smallest(wire: BluemiraWire, axis: str) -> np.ndarray:\n        \"\"\"\n        Get the coordinates of the end of a wire with largest value in\n        the given dimension\n        \"\"\"\n        return DivertorSilhouetteDesigner._get_wire_end(wire, axis, operator.lt)\n\n    @staticmethod\n    def _get_wire_end_with_largest(wire: BluemiraWire, axis: str) -> np.ndarray:\n        \"\"\"\n        Get the coordinates of the end of a wire with largest value in\n        the given dimension\n        \"\"\"\n        return DivertorSilhouetteDesigner._get_wire_end(wire, axis, operator.gt)\n\n    @staticmethod\n    def _get_wire_end(wire: BluemiraWire, axis: str, comp: Callable) -> np.ndarray:\n        \"\"\"\n        Get the coordinates of the end of a wire whose coordinate in the\n        given axis satisfies the comparison function.\n        \"\"\"\n        axis = WireEndAxis[axis.upper()].name.lower()\n\n        start_point = wire.start_point()\n        end_point = wire.end_point()\n        if comp(getattr(start_point, axis), getattr(end_point, axis)):\n            return start_point.xz.flatten()\n        return end_point.xz.flatten()",
  "def silhouette(self) -> BluemiraWire:\n        \"\"\"Return a wire representing the divertor poloidal silhouette.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(DivertorBuilder.BODY)\n            .shape.boundary[0]\n        )",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        equilibrium: Equilibrium,\n        wall: BluemiraWire,\n    ):\n        super().__init__(params)\n        if self.params.div_type.value == \"DN\":\n            raise NotImplementedError(\"Double Null divertor not implemented\")\n\n        self.equilibrium = equilibrium\n        self.x_limits = (wall.start_point().x[0], wall.end_point().x[0])\n        self.z_limits = (wall.start_point().z[0], wall.end_point().z[0])\n        self.leg_length = {\n            LegPosition.INNER: self.params.div_L2D_ib,\n            LegPosition.OUTER: self.params.div_L2D_ob,\n        }\n        self.separatrix_legs = get_separatrix_legs(self.equilibrium)",
  "def run(self) -> Tuple[BluemiraWire, ...]:\n        \"\"\"\n        Run method of DivertorSilhouetteDesigner\n        \"\"\"\n        # Build the targets for each separatrix leg\n        inner_target = self.make_target(LegPosition.INNER, self.INNER_TARGET)\n        outer_target = self.make_target(LegPosition.OUTER, self.OUTER_TARGET)\n\n        # Build the dome based on target positions\n        inner_target_end = self._get_wire_end_with_smallest(inner_target, \"z\")\n        outer_target_start = self._get_wire_end_with_smallest(outer_target, \"z\")\n\n        dome = self.make_dome(inner_target_end, outer_target_start, label=self.DOME)\n\n        # Build the baffles\n        idx_inner = np.argmin(self.x_limits)\n        idx_outer = np.argmax(self.x_limits)\n\n        inner_baffle = self.make_inner_baffle(\n            inner_target, self.x_limits[idx_inner], self.z_limits[idx_inner]\n        )\n        outer_baffle = self.make_outer_baffle(\n            outer_target, self.x_limits[idx_outer], self.z_limits[idx_outer]\n        )\n\n        return inner_baffle, inner_target, dome, outer_target, outer_baffle",
  "def make_target(self, leg: LegPosition, label: str) -> BluemiraWire:\n        \"\"\"\n        Make a divertor target for a the given leg.\n        \"\"\"\n        sols = self._get_sols_for_leg(leg)\n\n        # Just use the first scrape-off layer for now\n        point = sols[0].value_at(distance=self.leg_length[leg].value)\n\n        # Create some vertical targets for now. Eventually the target\n        # angle will be derived from the grazing-angle parameter\n        target_length = self.params.div_Ltarg.value\n        target_coords = np.array(\n            [\n                [point[0], point[0]],\n                [point[1], point[1]],\n                [point[2] - target_length / 2, point[2] + target_length / 2],\n            ]\n        )\n        return make_polygon(target_coords, label=label)",
  "def make_dome(\n        self, start: Sequence[float], end: Sequence[float], label: str\n    ) -> BluemiraWire:\n        \"\"\"\n        Make a dome between the two given points.\n\n        Notes\n        -----\n        The dome shape follows a constant line of flux that is closest to the input\n        coordinates.\n        The nearest point on the flux surface to the start point and the end point are\n        joined.\n        The flux surface is picked based on the lowest z coordinate of the start and end\n        point to ensure a continuous divertor shape is produced.\n        \"\"\"\n        # Get the flux surface that crosses the through the start or end point.\n        # We can use this surface to guide the shape of the dome.\n        psi_start = self.equilibrium.psi(*(start if start[1] < end[1] else end))\n        flux_surface = find_flux_surface_through_point(\n            self.equilibrium.x,\n            self.equilibrium.z,\n            self.equilibrium.psi(),\n            start[0],\n            start[1],\n            psi_start,\n        )\n\n        # Get the indices of the closest points on the flux surface to\n        # the input start and end points\n        start_coord = np.array([[start[0]], [start[1]]])  # [[x], [z]]\n        end_coord = np.array([[end[0]], [end[1]]])\n        idx = np.array(\n            [\n                np.argmin(np.hypot(*(flux_surface - start_coord))),\n                np.argmin(np.hypot(*(flux_surface - end_coord))),\n            ]\n        )\n\n        # Make sure the start and end are in the right order\n        if idx[0] > idx[1]:\n            idx = idx[::-1]\n            dome_contour = flux_surface[:, idx[0] + 1 : idx[1]]\n            dome_contour = dome_contour[:, ::-1]\n        else:\n            dome_contour = flux_surface[:, idx[0] + 1 : idx[1]]\n\n        # Build the coords of the dome in 3D (all(y == 0))\n        dome = np.zeros((3, dome_contour.shape[1] + 2))\n        dome[(0, 2), 0] = start_coord.T\n        dome[(0, 2), 1:-1] = dome_contour\n        dome[(0, 2), -1] = end_coord.T\n\n        return make_polygon(dome, label=label)",
  "def _make_baffle(\n        self,\n        label: str,\n        start: Sequence[float],\n        end: Sequence[float],\n    ) -> BluemiraWire:\n        \"\"\"\n        Make a baffle.\n        The baffle shape is a straight line between the given start and\n        end points.\n\n        Parameters\n        ----------\n        label:\n            The label to give the returned Component.\n        start:\n            The position (in x-z) to start drawing the baffle from,\n            e.g., the outside end of a target.\n        end:\n            The position (in x-z) to stop drawing the baffle, e.g., the\n            position to the upper part of the first wall.\n        \"\"\"\n        return make_polygon(\n            np.array([[start[0], end[0]], [0, 0], [start[1], end[1]]]), label=label\n        )",
  "def make_inner_baffle(\n        self,\n        target: BluemiraWire,\n        x_lim: float,\n        z_lim: float,\n    ) -> BluemiraWire:\n        \"\"\"\n        Build the inner baffle to join with the given target.\n        \"\"\"\n        if self.params.div_open.value:\n            raise NotImplementedError(\"Open divertor baffles not yet supported\")\n        else:\n            inner_target_start = self._get_wire_end_with_largest(target, \"x\")\n        return self._make_baffle(\n            label=self.INNER_BAFFLE,\n            start=np.array([x_lim, z_lim]),\n            end=inner_target_start,\n        )",
  "def make_outer_baffle(\n        self,\n        target: BluemiraWire,\n        x_lim: float,\n        z_lim: float,\n    ) -> BluemiraWire:\n        \"\"\"\n        Build the outer baffle to join with the given target.\n        \"\"\"\n        if self.params.div_open.value:\n            raise NotImplementedError(\"Open divertor baffles not yet supported\")\n        else:\n            outer_target_end = self._get_wire_end_with_largest(target, \"x\")\n        return self._make_baffle(\n            label=self.OUTER_BAFFLE,\n            start=outer_target_end,\n            end=np.array([x_lim, z_lim]),\n        )",
  "def _get_sols_for_leg(\n        self, leg: LegPosition, layers: Iterable[int] = (0, -1)\n    ) -> List[BluemiraWire]:\n        \"\"\"\n        Get the selected scrape-off-leg layers from the separatrix legs.\n        \"\"\"\n        sols = []\n        for layer in layers:\n            sols.append(self.separatrix_legs[leg][layer])\n        return sols",
  "def _get_wire_end_with_smallest(wire: BluemiraWire, axis: str) -> np.ndarray:\n        \"\"\"\n        Get the coordinates of the end of a wire with largest value in\n        the given dimension\n        \"\"\"\n        return DivertorSilhouetteDesigner._get_wire_end(wire, axis, operator.lt)",
  "def _get_wire_end_with_largest(wire: BluemiraWire, axis: str) -> np.ndarray:\n        \"\"\"\n        Get the coordinates of the end of a wire with largest value in\n        the given dimension\n        \"\"\"\n        return DivertorSilhouetteDesigner._get_wire_end(wire, axis, operator.gt)",
  "def _get_wire_end(wire: BluemiraWire, axis: str, comp: Callable) -> np.ndarray:\n        \"\"\"\n        Get the coordinates of the end of a wire whose coordinate in the\n        given axis satisfies the comparison function.\n        \"\"\"\n        axis = WireEndAxis[axis.upper()].name.lower()\n\n        start_point = wire.start_point()\n        end_point = wire.end_point()\n        if comp(getattr(start_point, axis), getattr(end_point, axis)):\n            return start_point.xz.flatten()\n        return end_point.xz.flatten()",
  "class TFCoil(ComponentManager):\n    \"\"\"\n    Wrapper around the TF Coil component tree.\n    \"\"\"\n\n    def __init__(self, component, field_solver):\n        super().__init__(component)\n        self._field_solver = field_solver\n\n    def field(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate the magnetic field due to the TF coils at a set of points.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the field\n        y:\n            The y coordinate(s) of the points at which to calculate the field\n        z:\n            The z coordinate(s) of the points at which to calculate the field\n\n        Returns\n        -------\n        The magnetic field vector {Bx, By, Bz} in [T]\n        \"\"\"\n        return self._field_solver.field(x, y, z)\n\n    def xz_outer_boundary(self) -> BluemiraWire:\n        \"\"\"Return the outer xz-boundary of the TF Coils.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(\"Casing\")\n            .get_component(\"outer\")\n            .shape.boundary[0]\n        )\n\n    def xz_face(self) -> BluemiraFace:\n        \"\"\"Return the x-z face of the TF Coils.\"\"\"\n        outer = self.xz_outer_boundary()\n        inner = (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(\"Casing\")\n            .get_component(\"inner\")\n            .shape.boundary[1]\n        )\n        return BluemiraFace([outer, inner])",
  "class TFCoilDesignerParams(ParameterFrame):\n    \"\"\"\n    TF Coil builder parameters\n    \"\"\"\n\n    r_tf_current_ib: Parameter[float]\n    tk_tf_wp: Parameter[float]\n    tk_tf_wp_y: Parameter[float]\n    tf_wp_depth: Parameter[float]\n    tf_wp_width: Parameter[float]\n    tk_tf_front_ib: Parameter[float]\n    g_ts_tf: Parameter[float]\n    TF_ripple_limit: Parameter[float]\n    R_0: Parameter[float]\n    z_0: Parameter[float]\n    B_0: Parameter[float]\n    n_TF: Parameter[int]\n    tk_tf_ins: Parameter[float]\n    tk_tf_insgap: Parameter[float]\n    tk_tf_nose: Parameter[float]\n    r_tf_in: Parameter[float]",
  "class TFCoilDesigner(Designer[GeometryParameterisation]):\n    \"\"\"\n    TF Coil Designer\n\n    Parameters\n    ----------\n    params:\n        TF Coil Designer parameters\n    build_config:\n        Required keys:\n\n            * param_class: str\n                A string of the import location for the parameterisation\n                class of the TF Coil\n                eg., `bluemira.geometry.parameterisations::TripleArc`.\n\n        Optional keys:\n\n            * variables_map: Dict\n                param_class variables map to modify the parameterisation defaults.\n                eg:\n\n                ..code-block::python\n\n                    variables_map = {\n\n                        \"x1\":{\n                            \"value\": \"r_tf_in_centre\",\n                            \"fixed\": True,\n                        },\n                        \"x2\": 5,\n                        \"x3\": {\"value\": 6},\n                        \"x4\": \"R_0\",\n                    }\n\n            * file_path: str\n                file path for loading parameterisation used only in 'read' mode\n            * problem_class: str\n                A string of the import location for the problem class to\n                solve\n            * optimisation_settings: Dict\n                problem_class optimisation settings\n    separatrix:\n        Wire of the separatrix along which to constrain ripple\n    keep_out_zone:\n        Wire of the keep-out-zone for the TF coil\n    \"\"\"\n\n    param_cls = TFCoilDesignerParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Dict,\n        separatrix: Optional[BluemiraWire] = None,\n        keep_out_zone: Optional[BluemiraWire] = None,\n    ):\n        super().__init__(params, build_config)\n\n        self.parameterisation_cls: Type[\n            GeometryParameterisation\n        ] = get_class_from_module(\n            self.build_config[\"param_class\"],\n            default_module=\"bluemira.geometry.parameterisations\",\n        )\n\n        self.variables_map = self.build_config.get(\"variables_map\", {})\n\n        self.file_path = self.build_config.get(\"file_path\", None)\n\n        if (problem_class := self.build_config.get(\"problem_class\", None)) is not None:\n            self.problem_class = get_class_from_module(problem_class)\n            self.problem_settings = self.build_config.get(\"problem_settings\", {})\n\n            self.opt_config = self.build_config.get(\"optimisation_settings\", {})\n\n            self.algorithm_name = self.opt_config.get(\"algorithm_name\", \"SLSQP\")\n            self.opt_conditions = self.opt_config.get(\"conditions\", {\"max_eval\": 100})\n            self.opt_parameters = self.opt_config.get(\"parameters\", {})\n\n        self.separatrix = separatrix\n        self.keep_out_zone = keep_out_zone\n\n    def _make_wp_xs(self, inboard_centroid: float) -> BluemiraWire:\n        \"\"\"\n        Make the winding pack x-y cross-section wire (excluding insulation and\n        insertion gap)\n        \"\"\"\n        d_xc = 0.5 * self.params.tk_tf_wp.value\n        d_yc = np.full(4, 0.5 * self.params.tk_tf_wp_y.value)\n        d_yc[:2] = -d_yc[:2]\n\n        x_c = np.full(4, inboard_centroid)\n        x_c[[0, -1]] -= d_xc\n        x_c[[1, 2]] += d_xc\n\n        wp_xs = make_polygon([x_c, d_yc, np.zeros(4)], closed=True)\n        return wp_xs\n\n    def _make_centreline_koz(self, keep_out_zone: BluemiraWire) -> BluemiraWire:\n        \"\"\"\n        Make a keep-out-zone for the TF coil centreline optimisation problem.\n        \"\"\"\n        # The keep-out zone is for the TF WP centreline, so we need to add to it to\n        # prevent clashes when the winding pack thickness and casing are added.\n        tk_offset = 0.5 * self.params.tf_wp_width.value\n        # Variable thickness of the casing is problematic...\n        # TODO: Improve this estimate (or use variable offset here too..)\n        tk_offset += 2 * np.sqrt(2) * self.params.tk_tf_front_ib.value\n        tk_offset += np.sqrt(2) * self.params.g_ts_tf.value\n        return offset_wire(keep_out_zone, tk_offset, open_wire=False, join=\"arc\")\n\n    def _derive_shape_params(self, variables_map: Dict[str, str]) -> Dict:\n        shape_params = {}\n        for key, val in variables_map.items():\n            if isinstance(val, str):\n                new_val = getattr(self.params, val).value\n            else:\n                new_val = deepcopy(val)\n\n            if isinstance(new_val, dict):\n                if isinstance(new_val[\"value\"], str):\n                    new_val[\"value\"] = getattr(self.params, new_val[\"value\"]).value\n            else:\n                new_val = {\"value\": new_val}\n\n            shape_params[key] = new_val\n\n        # Radial width of the winding pack with no insulation or insertion gap\n        dr_wp = (\n            self.params.tf_wp_width.value\n            - 2 * self.params.tk_tf_ins.value\n            - 2 * self.params.tk_tf_insgap.value\n        )\n        # Toroidal width of the winding pack no insulation\n        dy_wp = (\n            self.params.tf_wp_depth.value\n            - 2 * self.params.tk_tf_ins.value\n            - 2 * self.params.tk_tf_insgap.value\n        )\n        # PROCESS doesn't output the radius of the current centroid on the inboard\n        r_current_in_board = (\n            self.params.r_tf_in.value\n            + self.params.tk_tf_nose.value\n            + self.params.tk_tf_ins.value\n            + self.params.tk_tf_insgap.value\n            + 0.5 * dr_wp\n        )\n\n        self.params.update_values(\n            {\n                \"tk_tf_wp\": dr_wp,\n                \"tk_tf_wp_y\": dy_wp,\n                \"r_tf_current_ib\": r_current_in_board,\n            },\n            source=type(self).__name__,\n        )\n\n        shape_params[\"x1\"] = {\"value\": r_current_in_board, \"fixed\": True}\n        return shape_params\n\n    def _get_parameterisation(self) -> GeometryParameterisation:\n        return self.parameterisation_cls(self._derive_shape_params(self.variables_map))\n\n    def run(self) -> Tuple[GeometryParameterisation, BluemiraWire]:\n        \"\"\"\n        Run the specified design optimisation problem to generate the TF coil winding\n        pack current centreline.\n        \"\"\"\n        parameterisation = self._get_parameterisation()\n        wp_cross_section = self._make_wp_xs(self.params.r_tf_current_ib.value)\n\n        if not hasattr(self, \"problem_class\"):\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'run' mode: no problem_class specified.\"\n            )\n        if self.separatrix is None:\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'run' mode: no separatrix specified\"\n            )\n\n        bluemira_debug(\n            f\"Setting up design problem with:\\n\"\n            f\"algorithm_name: {self.algorithm_name}\\n\"\n            f\"n_variables: {parameterisation.variables.n_free_variables}\\n\"\n            f\"opt_conditions: {self.opt_conditions}\\n\"\n            f\"opt_parameters: {self.opt_parameters}\"\n        )\n\n        if self.problem_settings != {}:\n            bluemira_debug(\n                f\"Applying non-default settings to problem: {self.problem_settings}\"\n            )\n        if \"ripple_selector\" not in self.problem_settings:\n            self.problem_settings[\"ripple_selector\"] = EquispacedSelector(100)\n        else:\n            rs_config = self.problem_settings[\"ripple_selector\"]\n            ripple_selector = get_class_from_module(\n                rs_config[\"cls\"],\n                default_module=\"bluemira.builders.tf_coils\",\n            )\n            self.problem_settings[\"ripple_selector\"] = ripple_selector(\n                **rs_config.get(\"args\", {})\n            )\n        design_problem = self.problem_class(\n            parameterisation,\n            self.algorithm_name,\n            self.opt_conditions,\n            self.opt_parameters,\n            self.params,\n            wp_cross_section=wp_cross_section,\n            separatrix=self.separatrix,\n            keep_out_zone=None\n            if self.keep_out_zone is None\n            else self._make_centreline_koz(self.keep_out_zone),\n            **self.problem_settings,\n        )\n\n        bluemira_print(f\"Solving design problem: {type(design_problem).__name__}\")\n\n        result = design_problem.optimise()\n        result.to_json(self.file_path)\n        if self.build_config.get(\"plot\", False):\n            design_problem.plot()\n            plt.show()\n        return result, wp_cross_section\n\n    def read(self) -> Tuple[GeometryParameterisation, BluemiraWire]:\n        \"\"\"\n        Read in a file to set up a specified GeometryParameterisation and extract the\n        current centreline.\n        \"\"\"\n        if not self.file_path:\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'read' mode: no file path specified.\"\n            )\n\n        parameterisation = self.parameterisation_cls.from_json(file=self.file_path)\n        return (\n            parameterisation,\n            self._make_wp_xs(parameterisation.create_shape().bounding_box.x_min),\n        )\n\n    def mock(self) -> Tuple[GeometryParameterisation, BluemiraWire]:\n        \"\"\"\n        Mock a design of TF coils using the original parameterisation of the current\n        centreline.\n        \"\"\"\n        parameterisation = self._get_parameterisation()\n        return parameterisation, self._make_wp_xs(\n            parameterisation.create_shape().bounding_box.x_min\n        )",
  "class TFCoilBuilderParams(ParameterFrame):\n    \"\"\"\n    TF Coil builder parameters\n    \"\"\"\n\n    R_0: Parameter[float]\n    z_0: Parameter[float]\n    B_0: Parameter[float]\n    n_TF: Parameter[int]\n    tf_wp_depth: Parameter[float]\n    tf_wp_width: Parameter[float]\n    tk_tf_front_ib: Parameter[float]\n    tk_tf_ins: Parameter[float]\n    tk_tf_insgap: Parameter[float]\n    tk_tf_nose: Parameter[float]\n    tk_tf_side: Parameter[float]",
  "class TFCoilBuilder(Builder):\n    \"\"\"\n    TFCoil Builder\n    \"\"\"\n\n    # TODO tf_wp_width and tf_wp_depth can be completely disconnected from the\n    # wp_cross_section passed in\n    # so can R_0 and z_0\n\n    WP = \"Winding Pack\"\n    OUT = \"outer\"\n    IN = \"inner\"\n    CASING = \"Casing\"\n    INS = \"Insulation\"\n    INB = \"inboard\"\n    OUTB = \"outboard\"\n    param_cls: Type[TFCoilBuilderParams] = TFCoilBuilderParams\n\n    def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        centreline: BluemiraWire,\n        wp_cross_section: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.centreline = centreline\n\n        self.wp_cross_section = wp_cross_section\n        bb = self.wp_cross_section.bounding_box\n        self.wp_x_size = bb.x_max - bb.x_min\n        self.wp_y_size = bb.y_max - bb.y_min\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the vacuum vessel component.\n        \"\"\"\n        ins_inner_face, ins_outer_face = self._make_ins_xsec()\n        y_in, ib_cas_wire, ob_cas_wire = self._make_cas_xsec()\n\n        xyz_case, xyz = self.build_xyz(\n            y_in,\n            ins_inner_face,\n            ib_cas_wire,\n            ob_cas_wire,\n            degree=0,\n        )\n        return self.component_tree(\n            xz=self.build_xz(xyz_case),\n            xy=self.build_xy(ins_inner_face, ins_outer_face, ib_cas_wire, ob_cas_wire),\n            xyz=xyz,\n        )\n\n    def build_xz(\n        self, xyz_shape: BluemiraSolid\n    ) -> List[Union[PhysicalComponent, Component]]:\n        \"\"\"\n        Build the x-z components of the TF coils.\n        \"\"\"\n        wp_inner, wp_outer, winding_pack = self._build_xz_wp()\n\n        return [\n            winding_pack,\n            self._build_xz_ins(wp_inner, wp_outer),\n            self._build_xz_case(xyz_shape),\n        ]\n\n    def build_xy(\n        self,\n        ins_inner_face: BluemiraFace,\n        ins_outer_face: BluemiraFace,\n        ib_cas_wire: BluemiraWire,\n        ob_cas_wire: BluemiraWire,\n    ) -> List[Component]:\n        \"\"\"\n        Build the x-y components of the TF coils.\n        \"\"\"\n        return circular_pattern_component(\n            [\n                self._build_xy_wp(),\n                self._build_xy_ins(ins_inner_face, ins_outer_face),\n                self._build_xy_case(\n                    ins_inner_face, ins_outer_face, ib_cas_wire, ob_cas_wire\n                ),\n            ],\n            self.params.n_TF.value,\n        )\n\n    def build_xyz(\n        self,\n        y_in: float,\n        ins_inner_face: BluemiraFace,\n        ib_cas_wire: BluemiraWire,\n        ob_cas_wire: BluemiraWire,\n        degree: float = 360.0,\n    ) -> Tuple[BluemiraSolid, List[Component]]:\n        \"\"\"\n        Build the x-y-z components of the TF coils.\n        \"\"\"\n        # Minimum angle per TF coil (nudged by a tiny length since we start counting a\n        # sector at theta=0). This means we can draw a sector as 360 / n_TF and get one\n        # TF coil per sector. Python represents floats with 16 significant figures before\n        # getting round off, so adding on 1e3*EPS works here, in case someone sets n_TF\n        # to be 2.\n        sector_degree, n_sectors = get_n_sectors(self.params.n_TF.value, degree)\n        n_sectors = min(\n            n_sectors, get_n_sectors(self.params.n_TF.value + 1e3 * EPS, degree)[1] + 1\n        )\n\n        wp_solid, wp_sector = self._build_xyz_wp()\n\n        ins_solid, ins_sector = self._build_xyz_ins(wp_solid, ins_inner_face)\n\n        case_solid, case_sector = self._build_xyz_case(\n            y_in, ins_solid, ib_cas_wire, ob_cas_wire\n        )\n\n        return case_solid, circular_pattern_component(\n            [wp_sector, ins_sector, case_sector],\n            n_sectors,\n            degree=n_sectors * sector_degree,\n        )\n\n    def _build_xz_wp(self) -> Tuple[BluemiraWire, BluemiraWire, PhysicalComponent]:\n        \"\"\"\n        Winding pack x-z\n        \"\"\"\n        wp_outer = offset_wire(self.centreline, 0.5 * self.wp_x_size, join=\"arc\")\n        wp_inner = offset_wire(self.centreline, -0.5 * self.wp_x_size, join=\"arc\")\n\n        winding_pack = PhysicalComponent(self.WP, BluemiraFace([wp_outer, wp_inner]))\n        apply_component_display_options(winding_pack, color=BLUE_PALETTE[\"TF\"][1])\n\n        return wp_inner, wp_outer, winding_pack\n\n    def _build_xz_ins(self, wp_inner: BluemiraWire, wp_outer: BluemiraWire) -> Component:\n        \"\"\"\n        Insulation and Insertion gap x-z\n        \"\"\"\n        offset_tk = self.params.tk_tf_ins.value + self.params.tk_tf_insgap.value\n\n        ins_o_outer = offset_wire(wp_outer, offset_tk, join=\"arc\")\n        ins_outer = PhysicalComponent(self.OUT, BluemiraFace([ins_o_outer, wp_outer]))\n\n        ins_i_inner = offset_wire(wp_inner, -offset_tk, join=\"arc\")\n        ins_inner = PhysicalComponent(self.IN, BluemiraFace([wp_inner, ins_i_inner]))\n\n        apply_component_display_options(ins_outer, color=BLUE_PALETTE[\"TF\"][2])\n        apply_component_display_options(ins_inner, color=BLUE_PALETTE[\"TF\"][2])\n\n        return Component(self.INS, children=[ins_outer, ins_inner])\n\n    def _build_xz_case(self, xyz_shape) -> Component:\n        \"\"\"\n        Casing x-z\n        \"\"\"\n        cas_inner, cas_outer = self._make_cas_xz(xyz_shape)\n\n        cas_inner = PhysicalComponent(self.IN, cas_inner)\n        cas_outer = PhysicalComponent(self.OUT, cas_outer)\n\n        apply_component_display_options(cas_inner, color=BLUE_PALETTE[\"TF\"][0])\n        apply_component_display_options(cas_outer, color=BLUE_PALETTE[\"TF\"][0])\n\n        return Component(self.CASING, children=[cas_inner, cas_outer])\n\n    def _build_xy_wp(self) -> Component:\n        \"\"\"\n        Winding pack x-y\n        \"\"\"\n        # Should normally be gotten with wire_plane_intersect\n        # (it's not OK to assume that the maximum x value occurs on the midplane)\n        x_out = self.centreline.bounding_box.x_max\n        xs = BluemiraFace(deepcopy(self.wp_cross_section))\n        xs2 = deepcopy(xs)\n        xs2.translate((x_out - xs2.center_of_mass[0], 0, 0))\n\n        ib_wp_comp = PhysicalComponent(self.INB, xs)\n        ob_wp_comp = PhysicalComponent(self.OUTB, xs2)\n\n        apply_component_display_options(ib_wp_comp, color=BLUE_PALETTE[\"TF\"][1])\n        apply_component_display_options(ob_wp_comp, color=BLUE_PALETTE[\"TF\"][1])\n\n        return Component(self.WP, children=[ib_wp_comp, ob_wp_comp])\n\n    def _build_xy_ins(\n        self, ins_inner_face: BluemiraFace, ins_outer_face: BluemiraFace\n    ) -> Component:\n        \"\"\"\n        Insulation x-y\n        \"\"\"\n        ib_ins_comp = PhysicalComponent(self.INB, ins_inner_face)\n        ob_ins_comp = PhysicalComponent(self.OUTB, ins_outer_face)\n\n        apply_component_display_options(ib_ins_comp, color=BLUE_PALETTE[\"TF\"][2])\n        apply_component_display_options(ob_ins_comp, color=BLUE_PALETTE[\"TF\"][2])\n\n        return Component(self.INS, children=[ib_ins_comp, ob_ins_comp])\n\n    def _build_xy_case(\n        self,\n        ins_inner_face: BluemiraFace,\n        ins_outer_face: BluemiraFace,\n        ib_cas_wire: BluemiraWire,\n        ob_cas_wire: BluemiraWire,\n    ) -> List[Component]:\n        \"\"\"\n        Casing x-y\n        \"\"\"\n        cas_inner_face = BluemiraFace(\n            [ib_cas_wire, deepcopy(ins_inner_face.boundary[0])]\n        )\n        cas_outer_face = BluemiraFace(\n            [ob_cas_wire, deepcopy(ins_outer_face.boundary[0])]\n        )\n\n        ib_cas_comp = PhysicalComponent(self.INB, cas_inner_face)\n        ob_cas_comp = PhysicalComponent(self.OUTB, cas_outer_face)\n\n        apply_component_display_options(ib_cas_comp, color=BLUE_PALETTE[\"TF\"][0])\n        apply_component_display_options(ob_cas_comp, color=BLUE_PALETTE[\"TF\"][0])\n\n        return Component(\n            self.CASING,\n            children=[ib_cas_comp, ob_cas_comp],\n        )\n\n    def _build_xyz_wp(self) -> Tuple[BluemiraSolid, PhysicalComponent]:\n        \"\"\"\n        Winding pack x-y-z\n        \"\"\"\n        wp_solid = sweep_shape(self.wp_cross_section, self.centreline)\n        winding_pack = PhysicalComponent(self.WP, wp_solid)\n\n        apply_component_display_options(winding_pack, color=BLUE_PALETTE[\"TF\"][1])\n\n        return wp_solid, winding_pack\n\n    def _build_xyz_ins(\n        self,\n        wp_solid: BluemiraSolid,\n        ins_inner_face: BluemiraFace,\n    ) -> Tuple[BluemiraSolid, PhysicalComponent]:\n        \"\"\"\n        Insulation x-y-z\n        \"\"\"\n        ins_solid = boolean_cut(\n            sweep_shape(ins_inner_face.boundary[0], self.centreline), wp_solid\n        )[0]\n        insulation = PhysicalComponent(\n            self.INS,\n            ins_solid,\n        )\n\n        apply_component_display_options(insulation, color=BLUE_PALETTE[\"TF\"][2])\n\n        return ins_solid, insulation\n\n    def _build_xyz_case(\n        self,\n        y_in: float,\n        ins_solid: BluemiraSolid,\n        inner_xs: BluemiraWire,\n        outer_xs: BluemiraWire,\n    ) -> Tuple[BluemiraSolid, PhysicalComponent]:\n        \"\"\"\n        Casing x-y-z\n        \"\"\"\n        # Normally I'd do lots more here to get to a proper casing\n        # This is just a proof-of-principle\n        centreline_points = self.centreline.discretize(byedges=True, ndiscr=2000)\n\n        solid = self._make_casing_sweep_shape(\n            y_in, inner_xs, outer_xs, centreline_points\n        )\n\n        casing_xz_face, z_min, z_max = self._make_casing_xz_face(solid)\n\n        casing_half_tk = 0.5 * (\n            self.params.tf_wp_depth.value + self.params.tk_tf_side.value\n        )\n        casing_xz_face.translate((0, -casing_half_tk, 0))\n        solid = extrude_shape(casing_xz_face, (0, 2 * casing_half_tk, 0))\n\n        inner_xs.translate((0, 0, z_min - inner_xs.center_of_mass[2]))\n        inboard_casing = extrude_shape(BluemiraFace(inner_xs), (0, 0, z_max - z_min))\n\n        # This cut operation will hopefully protect against degenerate faces\n        # when doing the subsequent boolean_fuse operation\n        # Note to future self: this is likely due to some accuracy differences\n        # around the usually flat inner plasma-facing edge of the TF.\n        solid = boolean_cut(solid, inboard_casing)[0]\n\n        case_solid = boolean_fuse([solid, inboard_casing])\n        case_solid_hollow = boolean_cut(\n            case_solid, BluemiraSolid(ins_solid.boundary[0])\n        )[0]\n\n        casing = PhysicalComponent(self.CASING, case_solid_hollow)\n\n        apply_component_display_options(casing, color=BLUE_PALETTE[\"TF\"][0])\n\n        return case_solid_hollow, casing\n\n    def _make_ins_xsec(self) -> Tuple[BluemiraFace, BluemiraFace]:\n        \"\"\"\n        Make the insulation + insertion gap x-y cross-section faces\n        \"\"\"\n        ins_outer = offset_wire(\n            self.wp_cross_section,\n            self.params.tk_tf_ins.value + self.params.tk_tf_insgap.value,\n        )\n        face = BluemiraFace([ins_outer, self.wp_cross_section])\n\n        outer_face = deepcopy(face)\n        outer_face.translate(\n            (self.centreline.bounding_box.x_max - outer_face.center_of_mass[0], 0, 0)\n        )\n        return face, outer_face\n\n    def _make_cas_xsec(self) -> Tuple[float, BluemiraWire, BluemiraWire]:\n        \"\"\"\n        Make the casing x-y cross-section wires\n\n        TODO tf_wp_width and tf_wp_depth can be completely disconnected from the\n        wp_cross_section passed in\n\n        \"\"\"\n        tf_centreline_min = self.centreline.bounding_box.x_min\n\n        x_in = (\n            tf_centreline_min\n            - self.params.tk_tf_nose.value\n            - 0.5 * self.params.tf_wp_width.value\n        )\n        # Insulation and insertion gap included in WP width\n        x_out = (\n            tf_centreline_min\n            + 0.5 * self.params.tf_wp_width.value\n            + self.params.tk_tf_front_ib.value\n        )\n\n        tan_half_angle = np.tan(np.pi / self.params.n_TF.value)\n        y_in = x_in * tan_half_angle\n        y_out = x_out * tan_half_angle\n        inboard_wire = make_polygon(\n            [\n                [x_in, x_out, x_out, x_in],\n                [-y_in, -y_out, y_out, y_in],\n                [0, 0, 0, 0],\n            ],\n            closed=True,\n        )\n\n        dx_ins = 0.5 * self.params.tf_wp_width.value\n        dy_ins = 0.5 * self.params.tf_wp_depth.value\n\n        # Split the total radial thickness equally on the outboard\n        # This could be done with input params too..\n        dx_out = np.full(\n            4,\n            dx_ins\n            + 0.5 * (self.params.tk_tf_front_ib.value + self.params.tk_tf_nose.value),\n        )\n        dx_out[[0, -1]] = -dx_out[[0, -1]]\n\n        dy_out = np.full(4, dy_ins + self.params.tk_tf_side.value)\n        dy_out[[0, 1]] = -dy_out[[0, 1]]\n\n        outboard_wire = make_polygon([dx_out, dy_out, np.zeros(4)], closed=True)\n        outboard_wire.translate((self.centreline.bounding_box.x_max, 0, 0))\n\n        return y_in, inboard_wire, outboard_wire\n\n    def _make_cas_xz(self, solid: BluemiraSolid) -> Tuple[BluemiraFace, BluemiraFace]:\n        \"\"\"\n        Make the casing x-z cross-section from a 3-D volume.\n        \"\"\"\n        wires = slice_shape(\n            solid, BluemiraPlane.from_3_points([0, 0, 0], [1, 0, 0], [1, 0, 1])\n        )\n        wires.sort(key=lambda wire: wire.length)\n        if len(wires) != 4:\n            raise BuilderError(\n                \"Unexpected TF coil x-z cross-section. It is likely that a previous \"\n                \"boolean cutting operation failed to create a hollow solid.\"\n            )\n\n        return BluemiraFace([wires[1], wires[0]]), BluemiraFace([wires[3], wires[2]])\n\n    def _make_casing_sweep_shape(\n        self,\n        y_in: float,\n        inner_xs: BluemiraWire,\n        outer_xs: BluemiraWire,\n        centreline_points: np.ndarray,\n    ) -> BluemiraSolid:\n        \"\"\"\n        Make inner cross section for casing x-y-z\n        \"\"\"\n        # Make inner xs into a rectangle\n        bb = inner_xs.bounding_box\n        x_in = np.zeros(4)\n        x_in[[0, -1]] = bb.x_min\n        x_in[[1, 2]] = bb.x_max\n\n        y_in = np.full(4, y_in)\n        y_in[:2] = -y_in[:2]\n\n        inner_xs_rect = make_polygon([x_in, y_in, np.zeros(4)], closed=True)\n\n        # Sweep with a varying rectangular cross-section\n        idx = np.where(np.isclose(centreline_points.x, np.min(centreline_points.x)))[0]\n        z_turn_top = np.max(centreline_points.z[idx])\n        z_turn_bot = np.min(centreline_points.z[idx])\n\n        inner_xs_rect_top = deepcopy(inner_xs_rect)\n        inner_xs_rect_top.translate((0, 0, z_turn_top))\n        inner_xs_rect_bot = deepcopy(inner_xs_rect)\n        inner_xs_rect_bot.translate((0, 0, z_turn_bot))\n        return sweep_shape(\n            [inner_xs_rect_top, outer_xs, inner_xs_rect_bot], self.centreline\n        )\n\n    def _make_casing_xz_face(self, casing_solid):\n        # Get the outer casing wire\n        xz_plane = BluemiraPlane.from_3_points([0, 0, 0], [1, 0, 0], [1, 0, 1])\n        cut_wires = slice_shape(casing_solid, xz_plane)\n        cut_wires.sort(key=lambda wire: wire.length)\n        if len(cut_wires) != 2:\n            raise BuilderError(\n                f\"Expecting 2 wires here but there are: {len(cut_wires)} of them\"\n            )\n        inner_wire = cut_wires[0]\n        outer_wire = cut_wires[1]\n\n        # Get the outboard half of this wire\n\n        z_max = outer_wire.bounding_box.z_max\n        # Should do this by optimisation, but parameter_at is fragile for circle arcs\n        # Also cannot trust bounding boxes, ffs.\n        points = outer_wire.discretize(ndiscr=1000, byedges=True)\n        idx_max = np.argmax(points.z)\n        idx_min = np.argmin(points.z)\n        x_max, z_max = points.x[idx_max], points.z[idx_max]\n        x_min, z_min = points.x[idx_min], points.z[idx_min]\n\n        offset = 1.0\n        x = [0, x_max, x_max, x_min, x_min, 0]\n        z = [\n            z_max + offset,\n            z_max + offset,\n            z_max,\n            z_min,\n            z_min - offset,\n            z_min - offset,\n        ]\n        cut_face = BluemiraFace(make_polygon({\"x\": x, \"y\": 0, \"z\": z}, closed=True))\n        cut_result = boolean_cut(outer_wire, cut_face)\n        cut_result.sort(key=lambda wire: wire.center_of_mass[0])\n        outboard_outer_wire = cut_result[-1]\n\n        x_inboard = np.min(points.x)\n        # Make the \"joining\" corners to the inboard\n        start_point = outboard_outer_wire.start_point()\n        end_point = outboard_outer_wire.end_point()\n        if start_point.z[0] > end_point.z[0]:\n            start_point, end_point = end_point, start_point\n\n        x1, z1 = start_point.x[0], start_point.z[0]\n        x2, z2 = end_point.x[0], end_point.z[0]\n\n        joiner_wire = make_polygon(\n            {\"x\": [x2, x_inboard, x_inboard, x1], \"y\": 0, \"z\": [z2, z2, z1, z1]}\n        )\n\n        # Make the final casing xz face\n        outer_wire = BluemiraWire([outboard_outer_wire, joiner_wire])\n        return BluemiraFace([outer_wire, inner_wire]), min(z1, z2), max(z1, z2)\n\n    def _make_field_solver(self) -> HelmholtzCage:\n        \"\"\"\n        Make a magnetostatics solver for the field from the TF coils.\n        \"\"\"\n        circuit = ArbitraryPlanarRectangularXSCircuit(\n            self.centreline.discretize(byedges=True, ndiscr=100),\n            breadth=0.5 * self.wp_x_size,\n            depth=0.5 * self.wp_y_size,\n            current=1,\n        )\n        solver = HelmholtzCage(circuit, self.params.n_TF.value)\n        # single coil amp-turns\n        solver.set_current(\n            -self.params.B_0.value\n            / solver.field(self.params.R_0.value, 0, self.params.z_0.value)[1]\n        )\n        return solver",
  "def __init__(self, component, field_solver):\n        super().__init__(component)\n        self._field_solver = field_solver",
  "def field(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate the magnetic field due to the TF coils at a set of points.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the field\n        y:\n            The y coordinate(s) of the points at which to calculate the field\n        z:\n            The z coordinate(s) of the points at which to calculate the field\n\n        Returns\n        -------\n        The magnetic field vector {Bx, By, Bz} in [T]\n        \"\"\"\n        return self._field_solver.field(x, y, z)",
  "def xz_outer_boundary(self) -> BluemiraWire:\n        \"\"\"Return the outer xz-boundary of the TF Coils.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(\"Casing\")\n            .get_component(\"outer\")\n            .shape.boundary[0]\n        )",
  "def xz_face(self) -> BluemiraFace:\n        \"\"\"Return the x-z face of the TF Coils.\"\"\"\n        outer = self.xz_outer_boundary()\n        inner = (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(\"Casing\")\n            .get_component(\"inner\")\n            .shape.boundary[1]\n        )\n        return BluemiraFace([outer, inner])",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Dict,\n        separatrix: Optional[BluemiraWire] = None,\n        keep_out_zone: Optional[BluemiraWire] = None,\n    ):\n        super().__init__(params, build_config)\n\n        self.parameterisation_cls: Type[\n            GeometryParameterisation\n        ] = get_class_from_module(\n            self.build_config[\"param_class\"],\n            default_module=\"bluemira.geometry.parameterisations\",\n        )\n\n        self.variables_map = self.build_config.get(\"variables_map\", {})\n\n        self.file_path = self.build_config.get(\"file_path\", None)\n\n        if (problem_class := self.build_config.get(\"problem_class\", None)) is not None:\n            self.problem_class = get_class_from_module(problem_class)\n            self.problem_settings = self.build_config.get(\"problem_settings\", {})\n\n            self.opt_config = self.build_config.get(\"optimisation_settings\", {})\n\n            self.algorithm_name = self.opt_config.get(\"algorithm_name\", \"SLSQP\")\n            self.opt_conditions = self.opt_config.get(\"conditions\", {\"max_eval\": 100})\n            self.opt_parameters = self.opt_config.get(\"parameters\", {})\n\n        self.separatrix = separatrix\n        self.keep_out_zone = keep_out_zone",
  "def _make_wp_xs(self, inboard_centroid: float) -> BluemiraWire:\n        \"\"\"\n        Make the winding pack x-y cross-section wire (excluding insulation and\n        insertion gap)\n        \"\"\"\n        d_xc = 0.5 * self.params.tk_tf_wp.value\n        d_yc = np.full(4, 0.5 * self.params.tk_tf_wp_y.value)\n        d_yc[:2] = -d_yc[:2]\n\n        x_c = np.full(4, inboard_centroid)\n        x_c[[0, -1]] -= d_xc\n        x_c[[1, 2]] += d_xc\n\n        wp_xs = make_polygon([x_c, d_yc, np.zeros(4)], closed=True)\n        return wp_xs",
  "def _make_centreline_koz(self, keep_out_zone: BluemiraWire) -> BluemiraWire:\n        \"\"\"\n        Make a keep-out-zone for the TF coil centreline optimisation problem.\n        \"\"\"\n        # The keep-out zone is for the TF WP centreline, so we need to add to it to\n        # prevent clashes when the winding pack thickness and casing are added.\n        tk_offset = 0.5 * self.params.tf_wp_width.value\n        # Variable thickness of the casing is problematic...\n        # TODO: Improve this estimate (or use variable offset here too..)\n        tk_offset += 2 * np.sqrt(2) * self.params.tk_tf_front_ib.value\n        tk_offset += np.sqrt(2) * self.params.g_ts_tf.value\n        return offset_wire(keep_out_zone, tk_offset, open_wire=False, join=\"arc\")",
  "def _derive_shape_params(self, variables_map: Dict[str, str]) -> Dict:\n        shape_params = {}\n        for key, val in variables_map.items():\n            if isinstance(val, str):\n                new_val = getattr(self.params, val).value\n            else:\n                new_val = deepcopy(val)\n\n            if isinstance(new_val, dict):\n                if isinstance(new_val[\"value\"], str):\n                    new_val[\"value\"] = getattr(self.params, new_val[\"value\"]).value\n            else:\n                new_val = {\"value\": new_val}\n\n            shape_params[key] = new_val\n\n        # Radial width of the winding pack with no insulation or insertion gap\n        dr_wp = (\n            self.params.tf_wp_width.value\n            - 2 * self.params.tk_tf_ins.value\n            - 2 * self.params.tk_tf_insgap.value\n        )\n        # Toroidal width of the winding pack no insulation\n        dy_wp = (\n            self.params.tf_wp_depth.value\n            - 2 * self.params.tk_tf_ins.value\n            - 2 * self.params.tk_tf_insgap.value\n        )\n        # PROCESS doesn't output the radius of the current centroid on the inboard\n        r_current_in_board = (\n            self.params.r_tf_in.value\n            + self.params.tk_tf_nose.value\n            + self.params.tk_tf_ins.value\n            + self.params.tk_tf_insgap.value\n            + 0.5 * dr_wp\n        )\n\n        self.params.update_values(\n            {\n                \"tk_tf_wp\": dr_wp,\n                \"tk_tf_wp_y\": dy_wp,\n                \"r_tf_current_ib\": r_current_in_board,\n            },\n            source=type(self).__name__,\n        )\n\n        shape_params[\"x1\"] = {\"value\": r_current_in_board, \"fixed\": True}\n        return shape_params",
  "def _get_parameterisation(self) -> GeometryParameterisation:\n        return self.parameterisation_cls(self._derive_shape_params(self.variables_map))",
  "def run(self) -> Tuple[GeometryParameterisation, BluemiraWire]:\n        \"\"\"\n        Run the specified design optimisation problem to generate the TF coil winding\n        pack current centreline.\n        \"\"\"\n        parameterisation = self._get_parameterisation()\n        wp_cross_section = self._make_wp_xs(self.params.r_tf_current_ib.value)\n\n        if not hasattr(self, \"problem_class\"):\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'run' mode: no problem_class specified.\"\n            )\n        if self.separatrix is None:\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'run' mode: no separatrix specified\"\n            )\n\n        bluemira_debug(\n            f\"Setting up design problem with:\\n\"\n            f\"algorithm_name: {self.algorithm_name}\\n\"\n            f\"n_variables: {parameterisation.variables.n_free_variables}\\n\"\n            f\"opt_conditions: {self.opt_conditions}\\n\"\n            f\"opt_parameters: {self.opt_parameters}\"\n        )\n\n        if self.problem_settings != {}:\n            bluemira_debug(\n                f\"Applying non-default settings to problem: {self.problem_settings}\"\n            )\n        if \"ripple_selector\" not in self.problem_settings:\n            self.problem_settings[\"ripple_selector\"] = EquispacedSelector(100)\n        else:\n            rs_config = self.problem_settings[\"ripple_selector\"]\n            ripple_selector = get_class_from_module(\n                rs_config[\"cls\"],\n                default_module=\"bluemira.builders.tf_coils\",\n            )\n            self.problem_settings[\"ripple_selector\"] = ripple_selector(\n                **rs_config.get(\"args\", {})\n            )\n        design_problem = self.problem_class(\n            parameterisation,\n            self.algorithm_name,\n            self.opt_conditions,\n            self.opt_parameters,\n            self.params,\n            wp_cross_section=wp_cross_section,\n            separatrix=self.separatrix,\n            keep_out_zone=None\n            if self.keep_out_zone is None\n            else self._make_centreline_koz(self.keep_out_zone),\n            **self.problem_settings,\n        )\n\n        bluemira_print(f\"Solving design problem: {type(design_problem).__name__}\")\n\n        result = design_problem.optimise()\n        result.to_json(self.file_path)\n        if self.build_config.get(\"plot\", False):\n            design_problem.plot()\n            plt.show()\n        return result, wp_cross_section",
  "def read(self) -> Tuple[GeometryParameterisation, BluemiraWire]:\n        \"\"\"\n        Read in a file to set up a specified GeometryParameterisation and extract the\n        current centreline.\n        \"\"\"\n        if not self.file_path:\n            raise ValueError(\n                f\"Cannot execute {type(self).__name__} in 'read' mode: no file path specified.\"\n            )\n\n        parameterisation = self.parameterisation_cls.from_json(file=self.file_path)\n        return (\n            parameterisation,\n            self._make_wp_xs(parameterisation.create_shape().bounding_box.x_min),\n        )",
  "def mock(self) -> Tuple[GeometryParameterisation, BluemiraWire]:\n        \"\"\"\n        Mock a design of TF coils using the original parameterisation of the current\n        centreline.\n        \"\"\"\n        parameterisation = self._get_parameterisation()\n        return parameterisation, self._make_wp_xs(\n            parameterisation.create_shape().bounding_box.x_min\n        )",
  "def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        centreline: BluemiraWire,\n        wp_cross_section: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.centreline = centreline\n\n        self.wp_cross_section = wp_cross_section\n        bb = self.wp_cross_section.bounding_box\n        self.wp_x_size = bb.x_max - bb.x_min\n        self.wp_y_size = bb.y_max - bb.y_min",
  "def build(self) -> Component:\n        \"\"\"\n        Build the vacuum vessel component.\n        \"\"\"\n        ins_inner_face, ins_outer_face = self._make_ins_xsec()\n        y_in, ib_cas_wire, ob_cas_wire = self._make_cas_xsec()\n\n        xyz_case, xyz = self.build_xyz(\n            y_in,\n            ins_inner_face,\n            ib_cas_wire,\n            ob_cas_wire,\n            degree=0,\n        )\n        return self.component_tree(\n            xz=self.build_xz(xyz_case),\n            xy=self.build_xy(ins_inner_face, ins_outer_face, ib_cas_wire, ob_cas_wire),\n            xyz=xyz,\n        )",
  "def build_xz(\n        self, xyz_shape: BluemiraSolid\n    ) -> List[Union[PhysicalComponent, Component]]:\n        \"\"\"\n        Build the x-z components of the TF coils.\n        \"\"\"\n        wp_inner, wp_outer, winding_pack = self._build_xz_wp()\n\n        return [\n            winding_pack,\n            self._build_xz_ins(wp_inner, wp_outer),\n            self._build_xz_case(xyz_shape),\n        ]",
  "def build_xy(\n        self,\n        ins_inner_face: BluemiraFace,\n        ins_outer_face: BluemiraFace,\n        ib_cas_wire: BluemiraWire,\n        ob_cas_wire: BluemiraWire,\n    ) -> List[Component]:\n        \"\"\"\n        Build the x-y components of the TF coils.\n        \"\"\"\n        return circular_pattern_component(\n            [\n                self._build_xy_wp(),\n                self._build_xy_ins(ins_inner_face, ins_outer_face),\n                self._build_xy_case(\n                    ins_inner_face, ins_outer_face, ib_cas_wire, ob_cas_wire\n                ),\n            ],\n            self.params.n_TF.value,\n        )",
  "def build_xyz(\n        self,\n        y_in: float,\n        ins_inner_face: BluemiraFace,\n        ib_cas_wire: BluemiraWire,\n        ob_cas_wire: BluemiraWire,\n        degree: float = 360.0,\n    ) -> Tuple[BluemiraSolid, List[Component]]:\n        \"\"\"\n        Build the x-y-z components of the TF coils.\n        \"\"\"\n        # Minimum angle per TF coil (nudged by a tiny length since we start counting a\n        # sector at theta=0). This means we can draw a sector as 360 / n_TF and get one\n        # TF coil per sector. Python represents floats with 16 significant figures before\n        # getting round off, so adding on 1e3*EPS works here, in case someone sets n_TF\n        # to be 2.\n        sector_degree, n_sectors = get_n_sectors(self.params.n_TF.value, degree)\n        n_sectors = min(\n            n_sectors, get_n_sectors(self.params.n_TF.value + 1e3 * EPS, degree)[1] + 1\n        )\n\n        wp_solid, wp_sector = self._build_xyz_wp()\n\n        ins_solid, ins_sector = self._build_xyz_ins(wp_solid, ins_inner_face)\n\n        case_solid, case_sector = self._build_xyz_case(\n            y_in, ins_solid, ib_cas_wire, ob_cas_wire\n        )\n\n        return case_solid, circular_pattern_component(\n            [wp_sector, ins_sector, case_sector],\n            n_sectors,\n            degree=n_sectors * sector_degree,\n        )",
  "def _build_xz_wp(self) -> Tuple[BluemiraWire, BluemiraWire, PhysicalComponent]:\n        \"\"\"\n        Winding pack x-z\n        \"\"\"\n        wp_outer = offset_wire(self.centreline, 0.5 * self.wp_x_size, join=\"arc\")\n        wp_inner = offset_wire(self.centreline, -0.5 * self.wp_x_size, join=\"arc\")\n\n        winding_pack = PhysicalComponent(self.WP, BluemiraFace([wp_outer, wp_inner]))\n        apply_component_display_options(winding_pack, color=BLUE_PALETTE[\"TF\"][1])\n\n        return wp_inner, wp_outer, winding_pack",
  "def _build_xz_ins(self, wp_inner: BluemiraWire, wp_outer: BluemiraWire) -> Component:\n        \"\"\"\n        Insulation and Insertion gap x-z\n        \"\"\"\n        offset_tk = self.params.tk_tf_ins.value + self.params.tk_tf_insgap.value\n\n        ins_o_outer = offset_wire(wp_outer, offset_tk, join=\"arc\")\n        ins_outer = PhysicalComponent(self.OUT, BluemiraFace([ins_o_outer, wp_outer]))\n\n        ins_i_inner = offset_wire(wp_inner, -offset_tk, join=\"arc\")\n        ins_inner = PhysicalComponent(self.IN, BluemiraFace([wp_inner, ins_i_inner]))\n\n        apply_component_display_options(ins_outer, color=BLUE_PALETTE[\"TF\"][2])\n        apply_component_display_options(ins_inner, color=BLUE_PALETTE[\"TF\"][2])\n\n        return Component(self.INS, children=[ins_outer, ins_inner])",
  "def _build_xz_case(self, xyz_shape) -> Component:\n        \"\"\"\n        Casing x-z\n        \"\"\"\n        cas_inner, cas_outer = self._make_cas_xz(xyz_shape)\n\n        cas_inner = PhysicalComponent(self.IN, cas_inner)\n        cas_outer = PhysicalComponent(self.OUT, cas_outer)\n\n        apply_component_display_options(cas_inner, color=BLUE_PALETTE[\"TF\"][0])\n        apply_component_display_options(cas_outer, color=BLUE_PALETTE[\"TF\"][0])\n\n        return Component(self.CASING, children=[cas_inner, cas_outer])",
  "def _build_xy_wp(self) -> Component:\n        \"\"\"\n        Winding pack x-y\n        \"\"\"\n        # Should normally be gotten with wire_plane_intersect\n        # (it's not OK to assume that the maximum x value occurs on the midplane)\n        x_out = self.centreline.bounding_box.x_max\n        xs = BluemiraFace(deepcopy(self.wp_cross_section))\n        xs2 = deepcopy(xs)\n        xs2.translate((x_out - xs2.center_of_mass[0], 0, 0))\n\n        ib_wp_comp = PhysicalComponent(self.INB, xs)\n        ob_wp_comp = PhysicalComponent(self.OUTB, xs2)\n\n        apply_component_display_options(ib_wp_comp, color=BLUE_PALETTE[\"TF\"][1])\n        apply_component_display_options(ob_wp_comp, color=BLUE_PALETTE[\"TF\"][1])\n\n        return Component(self.WP, children=[ib_wp_comp, ob_wp_comp])",
  "def _build_xy_ins(\n        self, ins_inner_face: BluemiraFace, ins_outer_face: BluemiraFace\n    ) -> Component:\n        \"\"\"\n        Insulation x-y\n        \"\"\"\n        ib_ins_comp = PhysicalComponent(self.INB, ins_inner_face)\n        ob_ins_comp = PhysicalComponent(self.OUTB, ins_outer_face)\n\n        apply_component_display_options(ib_ins_comp, color=BLUE_PALETTE[\"TF\"][2])\n        apply_component_display_options(ob_ins_comp, color=BLUE_PALETTE[\"TF\"][2])\n\n        return Component(self.INS, children=[ib_ins_comp, ob_ins_comp])",
  "def _build_xy_case(\n        self,\n        ins_inner_face: BluemiraFace,\n        ins_outer_face: BluemiraFace,\n        ib_cas_wire: BluemiraWire,\n        ob_cas_wire: BluemiraWire,\n    ) -> List[Component]:\n        \"\"\"\n        Casing x-y\n        \"\"\"\n        cas_inner_face = BluemiraFace(\n            [ib_cas_wire, deepcopy(ins_inner_face.boundary[0])]\n        )\n        cas_outer_face = BluemiraFace(\n            [ob_cas_wire, deepcopy(ins_outer_face.boundary[0])]\n        )\n\n        ib_cas_comp = PhysicalComponent(self.INB, cas_inner_face)\n        ob_cas_comp = PhysicalComponent(self.OUTB, cas_outer_face)\n\n        apply_component_display_options(ib_cas_comp, color=BLUE_PALETTE[\"TF\"][0])\n        apply_component_display_options(ob_cas_comp, color=BLUE_PALETTE[\"TF\"][0])\n\n        return Component(\n            self.CASING,\n            children=[ib_cas_comp, ob_cas_comp],\n        )",
  "def _build_xyz_wp(self) -> Tuple[BluemiraSolid, PhysicalComponent]:\n        \"\"\"\n        Winding pack x-y-z\n        \"\"\"\n        wp_solid = sweep_shape(self.wp_cross_section, self.centreline)\n        winding_pack = PhysicalComponent(self.WP, wp_solid)\n\n        apply_component_display_options(winding_pack, color=BLUE_PALETTE[\"TF\"][1])\n\n        return wp_solid, winding_pack",
  "def _build_xyz_ins(\n        self,\n        wp_solid: BluemiraSolid,\n        ins_inner_face: BluemiraFace,\n    ) -> Tuple[BluemiraSolid, PhysicalComponent]:\n        \"\"\"\n        Insulation x-y-z\n        \"\"\"\n        ins_solid = boolean_cut(\n            sweep_shape(ins_inner_face.boundary[0], self.centreline), wp_solid\n        )[0]\n        insulation = PhysicalComponent(\n            self.INS,\n            ins_solid,\n        )\n\n        apply_component_display_options(insulation, color=BLUE_PALETTE[\"TF\"][2])\n\n        return ins_solid, insulation",
  "def _build_xyz_case(\n        self,\n        y_in: float,\n        ins_solid: BluemiraSolid,\n        inner_xs: BluemiraWire,\n        outer_xs: BluemiraWire,\n    ) -> Tuple[BluemiraSolid, PhysicalComponent]:\n        \"\"\"\n        Casing x-y-z\n        \"\"\"\n        # Normally I'd do lots more here to get to a proper casing\n        # This is just a proof-of-principle\n        centreline_points = self.centreline.discretize(byedges=True, ndiscr=2000)\n\n        solid = self._make_casing_sweep_shape(\n            y_in, inner_xs, outer_xs, centreline_points\n        )\n\n        casing_xz_face, z_min, z_max = self._make_casing_xz_face(solid)\n\n        casing_half_tk = 0.5 * (\n            self.params.tf_wp_depth.value + self.params.tk_tf_side.value\n        )\n        casing_xz_face.translate((0, -casing_half_tk, 0))\n        solid = extrude_shape(casing_xz_face, (0, 2 * casing_half_tk, 0))\n\n        inner_xs.translate((0, 0, z_min - inner_xs.center_of_mass[2]))\n        inboard_casing = extrude_shape(BluemiraFace(inner_xs), (0, 0, z_max - z_min))\n\n        # This cut operation will hopefully protect against degenerate faces\n        # when doing the subsequent boolean_fuse operation\n        # Note to future self: this is likely due to some accuracy differences\n        # around the usually flat inner plasma-facing edge of the TF.\n        solid = boolean_cut(solid, inboard_casing)[0]\n\n        case_solid = boolean_fuse([solid, inboard_casing])\n        case_solid_hollow = boolean_cut(\n            case_solid, BluemiraSolid(ins_solid.boundary[0])\n        )[0]\n\n        casing = PhysicalComponent(self.CASING, case_solid_hollow)\n\n        apply_component_display_options(casing, color=BLUE_PALETTE[\"TF\"][0])\n\n        return case_solid_hollow, casing",
  "def _make_ins_xsec(self) -> Tuple[BluemiraFace, BluemiraFace]:\n        \"\"\"\n        Make the insulation + insertion gap x-y cross-section faces\n        \"\"\"\n        ins_outer = offset_wire(\n            self.wp_cross_section,\n            self.params.tk_tf_ins.value + self.params.tk_tf_insgap.value,\n        )\n        face = BluemiraFace([ins_outer, self.wp_cross_section])\n\n        outer_face = deepcopy(face)\n        outer_face.translate(\n            (self.centreline.bounding_box.x_max - outer_face.center_of_mass[0], 0, 0)\n        )\n        return face, outer_face",
  "def _make_cas_xsec(self) -> Tuple[float, BluemiraWire, BluemiraWire]:\n        \"\"\"\n        Make the casing x-y cross-section wires\n\n        TODO tf_wp_width and tf_wp_depth can be completely disconnected from the\n        wp_cross_section passed in\n\n        \"\"\"\n        tf_centreline_min = self.centreline.bounding_box.x_min\n\n        x_in = (\n            tf_centreline_min\n            - self.params.tk_tf_nose.value\n            - 0.5 * self.params.tf_wp_width.value\n        )\n        # Insulation and insertion gap included in WP width\n        x_out = (\n            tf_centreline_min\n            + 0.5 * self.params.tf_wp_width.value\n            + self.params.tk_tf_front_ib.value\n        )\n\n        tan_half_angle = np.tan(np.pi / self.params.n_TF.value)\n        y_in = x_in * tan_half_angle\n        y_out = x_out * tan_half_angle\n        inboard_wire = make_polygon(\n            [\n                [x_in, x_out, x_out, x_in],\n                [-y_in, -y_out, y_out, y_in],\n                [0, 0, 0, 0],\n            ],\n            closed=True,\n        )\n\n        dx_ins = 0.5 * self.params.tf_wp_width.value\n        dy_ins = 0.5 * self.params.tf_wp_depth.value\n\n        # Split the total radial thickness equally on the outboard\n        # This could be done with input params too..\n        dx_out = np.full(\n            4,\n            dx_ins\n            + 0.5 * (self.params.tk_tf_front_ib.value + self.params.tk_tf_nose.value),\n        )\n        dx_out[[0, -1]] = -dx_out[[0, -1]]\n\n        dy_out = np.full(4, dy_ins + self.params.tk_tf_side.value)\n        dy_out[[0, 1]] = -dy_out[[0, 1]]\n\n        outboard_wire = make_polygon([dx_out, dy_out, np.zeros(4)], closed=True)\n        outboard_wire.translate((self.centreline.bounding_box.x_max, 0, 0))\n\n        return y_in, inboard_wire, outboard_wire",
  "def _make_cas_xz(self, solid: BluemiraSolid) -> Tuple[BluemiraFace, BluemiraFace]:\n        \"\"\"\n        Make the casing x-z cross-section from a 3-D volume.\n        \"\"\"\n        wires = slice_shape(\n            solid, BluemiraPlane.from_3_points([0, 0, 0], [1, 0, 0], [1, 0, 1])\n        )\n        wires.sort(key=lambda wire: wire.length)\n        if len(wires) != 4:\n            raise BuilderError(\n                \"Unexpected TF coil x-z cross-section. It is likely that a previous \"\n                \"boolean cutting operation failed to create a hollow solid.\"\n            )\n\n        return BluemiraFace([wires[1], wires[0]]), BluemiraFace([wires[3], wires[2]])",
  "def _make_casing_sweep_shape(\n        self,\n        y_in: float,\n        inner_xs: BluemiraWire,\n        outer_xs: BluemiraWire,\n        centreline_points: np.ndarray,\n    ) -> BluemiraSolid:\n        \"\"\"\n        Make inner cross section for casing x-y-z\n        \"\"\"\n        # Make inner xs into a rectangle\n        bb = inner_xs.bounding_box\n        x_in = np.zeros(4)\n        x_in[[0, -1]] = bb.x_min\n        x_in[[1, 2]] = bb.x_max\n\n        y_in = np.full(4, y_in)\n        y_in[:2] = -y_in[:2]\n\n        inner_xs_rect = make_polygon([x_in, y_in, np.zeros(4)], closed=True)\n\n        # Sweep with a varying rectangular cross-section\n        idx = np.where(np.isclose(centreline_points.x, np.min(centreline_points.x)))[0]\n        z_turn_top = np.max(centreline_points.z[idx])\n        z_turn_bot = np.min(centreline_points.z[idx])\n\n        inner_xs_rect_top = deepcopy(inner_xs_rect)\n        inner_xs_rect_top.translate((0, 0, z_turn_top))\n        inner_xs_rect_bot = deepcopy(inner_xs_rect)\n        inner_xs_rect_bot.translate((0, 0, z_turn_bot))\n        return sweep_shape(\n            [inner_xs_rect_top, outer_xs, inner_xs_rect_bot], self.centreline\n        )",
  "def _make_casing_xz_face(self, casing_solid):\n        # Get the outer casing wire\n        xz_plane = BluemiraPlane.from_3_points([0, 0, 0], [1, 0, 0], [1, 0, 1])\n        cut_wires = slice_shape(casing_solid, xz_plane)\n        cut_wires.sort(key=lambda wire: wire.length)\n        if len(cut_wires) != 2:\n            raise BuilderError(\n                f\"Expecting 2 wires here but there are: {len(cut_wires)} of them\"\n            )\n        inner_wire = cut_wires[0]\n        outer_wire = cut_wires[1]\n\n        # Get the outboard half of this wire\n\n        z_max = outer_wire.bounding_box.z_max\n        # Should do this by optimisation, but parameter_at is fragile for circle arcs\n        # Also cannot trust bounding boxes, ffs.\n        points = outer_wire.discretize(ndiscr=1000, byedges=True)\n        idx_max = np.argmax(points.z)\n        idx_min = np.argmin(points.z)\n        x_max, z_max = points.x[idx_max], points.z[idx_max]\n        x_min, z_min = points.x[idx_min], points.z[idx_min]\n\n        offset = 1.0\n        x = [0, x_max, x_max, x_min, x_min, 0]\n        z = [\n            z_max + offset,\n            z_max + offset,\n            z_max,\n            z_min,\n            z_min - offset,\n            z_min - offset,\n        ]\n        cut_face = BluemiraFace(make_polygon({\"x\": x, \"y\": 0, \"z\": z}, closed=True))\n        cut_result = boolean_cut(outer_wire, cut_face)\n        cut_result.sort(key=lambda wire: wire.center_of_mass[0])\n        outboard_outer_wire = cut_result[-1]\n\n        x_inboard = np.min(points.x)\n        # Make the \"joining\" corners to the inboard\n        start_point = outboard_outer_wire.start_point()\n        end_point = outboard_outer_wire.end_point()\n        if start_point.z[0] > end_point.z[0]:\n            start_point, end_point = end_point, start_point\n\n        x1, z1 = start_point.x[0], start_point.z[0]\n        x2, z2 = end_point.x[0], end_point.z[0]\n\n        joiner_wire = make_polygon(\n            {\"x\": [x2, x_inboard, x_inboard, x1], \"y\": 0, \"z\": [z2, z2, z1, z1]}\n        )\n\n        # Make the final casing xz face\n        outer_wire = BluemiraWire([outboard_outer_wire, joiner_wire])\n        return BluemiraFace([outer_wire, inner_wire]), min(z1, z2), max(z1, z2)",
  "def _make_field_solver(self) -> HelmholtzCage:\n        \"\"\"\n        Make a magnetostatics solver for the field from the TF coils.\n        \"\"\"\n        circuit = ArbitraryPlanarRectangularXSCircuit(\n            self.centreline.discretize(byedges=True, ndiscr=100),\n            breadth=0.5 * self.wp_x_size,\n            depth=0.5 * self.wp_y_size,\n            current=1,\n        )\n        solver = HelmholtzCage(circuit, self.params.n_TF.value)\n        # single coil amp-turns\n        solver.set_current(\n            -self.params.B_0.value\n            / solver.field(self.params.R_0.value, 0, self.params.z_0.value)[1]\n        )\n        return solver",
  "class TFCoilPolySpline(PolySpline):\n    \"\"\"\n    Defines the geometry for reactor TF coil, based on the PolySpline\n     parameterisation.\n    \"\"\"\n\n    _defaults = {\n        \"x1\": {\"value\": 3.8},\n        \"x2\": {\"value\": 16},\n        \"z2\": {\"value\": 0},\n        \"height\": {\"value\": 14},\n        \"top\": {\"value\": 0.4},\n        \"upper\": {\"value\": 0.3},\n        \"dz\": {\"value\": 0},\n        \"tilt\": {\"value\": 0},\n        \"lower\": {\"value\": 0.5},\n        \"bottom\": {\"value\": 0.2},\n        \"flat\": {\"value\": 0.0},\n    }\n\n    def __init__(self, var_dict: Optional[VarDictT] = None):\n        if var_dict is None:\n            var_dict = {}\n        defaults = copy.deepcopy(self._defaults)\n        defaults.update(var_dict)\n        super().__init__(defaults)\n\n        ib_radius = self.variables.x1.value\n        ob_radius = self.variables.x2.value\n        z2 = self.variables.z2.value\n        height = self.variables.height.value\n        top = self.variables.top.value\n        upper = self.variables.upper.value\n        dz = self.variables.dz.value\n        tilt = self.variables.tilt.value\n        lower = self.variables.lower.value\n        bottom = self.variables.bottom.value\n\n        if not self.variables.x1.fixed:\n            self.adjust_variable(\n                \"x1\",\n                ib_radius,\n                lower_bound=ib_radius - 2,\n                upper_bound=ib_radius * 1.1,\n            )\n        if not self.variables.x2.fixed:\n            self.adjust_variable(\n                \"x2\",\n                value=ob_radius,\n                lower_bound=ob_radius * 0.9,\n                upper_bound=ob_radius + 2,\n            )\n        self.adjust_variable(\"z2\", z2, lower_bound=-0.9, upper_bound=0.9)\n        self.adjust_variable(\n            \"height\", height, lower_bound=height - 0.001, upper_bound=50\n        )\n        self.adjust_variable(\"top\", top, lower_bound=0.05, upper_bound=0.75)\n        self.adjust_variable(\"upper\", upper, lower_bound=0.2, upper_bound=0.7)\n        self.adjust_variable(\"dz\", dz, lower_bound=-5, upper_bound=5)\n        self.adjust_variable(\"tilt\", tilt, lower_bound=-25, upper_bound=25)\n        self.adjust_variable(\"lower\", lower, lower_bound=0.2, upper_bound=0.7)\n        self.adjust_variable(\"bottom\", bottom, lower_bound=0.05, upper_bound=0.75)\n\n        # Fix 'flat' to avoid drawing the PolySpline's outer straight.\n        # The straight is often optimised to near-zero length, which\n        # causes an error when CAD tries to draw it\n        self.fix_variable(\"flat\", 0)\n\n        for var in [\"l0s\", \"l0e\", \"l1s\", \"l1e\", \"l2s\", \"l2e\", \"l3s\", \"l3e\"]:\n            self.fix_variable(var)",
  "def __init__(self, var_dict: Optional[VarDictT] = None):\n        if var_dict is None:\n            var_dict = {}\n        defaults = copy.deepcopy(self._defaults)\n        defaults.update(var_dict)\n        super().__init__(defaults)\n\n        ib_radius = self.variables.x1.value\n        ob_radius = self.variables.x2.value\n        z2 = self.variables.z2.value\n        height = self.variables.height.value\n        top = self.variables.top.value\n        upper = self.variables.upper.value\n        dz = self.variables.dz.value\n        tilt = self.variables.tilt.value\n        lower = self.variables.lower.value\n        bottom = self.variables.bottom.value\n\n        if not self.variables.x1.fixed:\n            self.adjust_variable(\n                \"x1\",\n                ib_radius,\n                lower_bound=ib_radius - 2,\n                upper_bound=ib_radius * 1.1,\n            )\n        if not self.variables.x2.fixed:\n            self.adjust_variable(\n                \"x2\",\n                value=ob_radius,\n                lower_bound=ob_radius * 0.9,\n                upper_bound=ob_radius + 2,\n            )\n        self.adjust_variable(\"z2\", z2, lower_bound=-0.9, upper_bound=0.9)\n        self.adjust_variable(\n            \"height\", height, lower_bound=height - 0.001, upper_bound=50\n        )\n        self.adjust_variable(\"top\", top, lower_bound=0.05, upper_bound=0.75)\n        self.adjust_variable(\"upper\", upper, lower_bound=0.2, upper_bound=0.7)\n        self.adjust_variable(\"dz\", dz, lower_bound=-5, upper_bound=5)\n        self.adjust_variable(\"tilt\", tilt, lower_bound=-25, upper_bound=25)\n        self.adjust_variable(\"lower\", lower, lower_bound=0.2, upper_bound=0.7)\n        self.adjust_variable(\"bottom\", bottom, lower_bound=0.05, upper_bound=0.75)\n\n        # Fix 'flat' to avoid drawing the PolySpline's outer straight.\n        # The straight is often optimised to near-zero length, which\n        # causes an error when CAD tries to draw it\n        self.fix_variable(\"flat\", 0)\n\n        for var in [\"l0s\", \"l0e\", \"l1s\", \"l1e\", \"l2s\", \"l2e\", \"l3s\", \"l3e\"]:\n            self.fix_variable(var)",
  "def get_keywords() -> Dict[str, str]:\n    \"\"\"Get the keywords needed to look up the version information.\"\"\"\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = \"$Format:%d$\"\n    git_full = \"$Format:%H$\"\n    git_date = \"$Format:%ci$\"\n    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n    return keywords",
  "class VersioneerConfig:\n    \"\"\"Container for Versioneer configuration parameters.\"\"\"\n\n    VCS: str\n    style: str\n    tag_prefix: str\n    parentdir_prefix: str\n    versionfile_source: str\n    verbose: bool",
  "def get_config() -> VersioneerConfig:\n    \"\"\"Create, populate and return the VersioneerConfig() object.\"\"\"\n    # these strings are filled in when 'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"bluemira-\"\n    cfg.versionfile_source = \"bluemira/_version.py\"\n    cfg.verbose = False\n    return cfg",
  "class NotThisMethod(Exception):\n    \"\"\"Exception raised if a method is not valid for the current scenario.\"\"\"",
  "def register_vcs_handler(vcs: str, method: str) -> Callable:  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n\n    def decorate(f: Callable) -> Callable:\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n\n    return decorate",
  "def run_command(\n    commands: List[str],\n    args: List[str],\n    cwd: Optional[str] = None,\n    verbose: bool = False,\n    hide_stderr: bool = False,\n    env: Optional[Dict[str, str]] = None,\n) -> Tuple[Optional[str], Optional[int]]:\n    \"\"\"Call the given command(s).\"\"\"\n    assert isinstance(commands, list)\n    process = None\n\n    popen_kwargs: Dict[str, Any] = {}\n    if sys.platform == \"win32\":\n        # This hides the console window if pythonw.exe is used\n        startupinfo = subprocess.STARTUPINFO()\n        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n        popen_kwargs[\"startupinfo\"] = startupinfo\n\n    for command in commands:\n        try:\n            dispcmd = str([command] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            process = subprocess.Popen(\n                [command] + args,\n                cwd=cwd,\n                env=env,\n                stdout=subprocess.PIPE,\n                stderr=(subprocess.PIPE if hide_stderr else None),\n                **popen_kwargs,\n            )\n            break\n        except OSError as e:\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(\"unable to find command, tried %s\" % (commands,))\n        return None, None\n    stdout = process.communicate()[0].strip().decode()\n    if process.returncode != 0:\n        if verbose:\n            print(\"unable to run %s (error)\" % dispcmd)\n            print(\"stdout was %s\" % stdout)\n        return None, process.returncode\n    return stdout, process.returncode",
  "def versions_from_parentdir(\n    parentdir_prefix: str,\n    root: str,\n    verbose: bool,\n) -> Dict[str, Any]:\n    \"\"\"Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    \"\"\"\n    rootdirs = []\n\n    for _ in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\n                \"version\": dirname[len(parentdir_prefix) :],\n                \"full-revisionid\": None,\n                \"dirty\": False,\n                \"error\": None,\n                \"date\": None,\n            }\n        rootdirs.append(root)\n        root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(\n            \"Tried directories %s but none started with prefix %s\"\n            % (str(rootdirs), parentdir_prefix)\n        )\n    raise NotThisMethod(\"rootdir doesn't start with parentdir_prefix\")",
  "def git_get_keywords(versionfile_abs: str) -> Dict[str, str]:\n    \"\"\"Extract version information from the given file.\"\"\"\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords: Dict[str, str] = {}\n    try:\n        with open(versionfile_abs, \"r\") as fobj:\n            for line in fobj:\n                if line.strip().startswith(\"git_refnames =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"refnames\"] = mo.group(1)\n                if line.strip().startswith(\"git_full =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"full\"] = mo.group(1)\n                if line.strip().startswith(\"git_date =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"date\"] = mo.group(1)\n    except OSError:\n        pass\n    return keywords",
  "def git_versions_from_keywords(\n    keywords: Dict[str, str],\n    tag_prefix: str,\n    verbose: bool,\n) -> Dict[str, Any]:\n    \"\"\"Get version information from git keywords.\"\"\"\n    if \"refnames\" not in keywords:\n        raise NotThisMethod(\"Short version file found\")\n    date = keywords.get(\"date\")\n    if date is not None:\n        # Use only the last line.  Previous lines may contain GPG signature\n        # information.\n        date = date.splitlines()[-1]\n\n        # git-2.2.0 added \"%cI\", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer \"%ci\" (which expands to an \"ISO-8601\n        # -like\" string, which we must then edit to make compliant), because\n        # it's been around since git-1.5.3, and it's too difficult to\n        # discover which version we're using, or to work around using an\n        # older one.\n        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = {r[len(TAG) :] for r in refs if r.startswith(TAG)}\n    if not tags:\n        # Either we're using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like \"release\" and\n        # \"stabilization\", as well as \"HEAD\" and \"master\".\n        tags = {r for r in refs if re.search(r\"\\d\", r)}\n        if verbose:\n            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n    if verbose:\n        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. \"2.0\" over \"2.0rc1\"\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix) :]\n            # Filter out refs that exactly match prefix or that don't start\n            # with a number once the prefix is stripped (mostly a concern\n            # when prefix is '')\n            if not re.match(r\"\\d\", r):\n                continue\n            if verbose:\n                print(\"picking %s\" % r)\n            return {\n                \"version\": r,\n                \"full-revisionid\": keywords[\"full\"].strip(),\n                \"dirty\": False,\n                \"error\": None,\n                \"date\": date,\n            }\n    # no suitable tags, so version is \"0+unknown\", but full hex is still there\n    if verbose:\n        print(\"no suitable tags, using unknown + full revision id\")\n    return {\n        \"version\": \"0+unknown\",\n        \"full-revisionid\": keywords[\"full\"].strip(),\n        \"dirty\": False,\n        \"error\": \"no suitable tags\",\n        \"date\": None,\n    }",
  "def git_pieces_from_vcs(\n    tag_prefix: str, root: str, verbose: bool, runner: Callable = run_command\n) -> Dict[str, Any]:\n    \"\"\"Get version from 'git describe' in the root of the source tree.\n\n    This only gets called if the git-archive 'subst' keywords were *not*\n    expanded, and _version.py hasn't already been rewritten with a short\n    version string, meaning we're inside a checked out source tree.\n    \"\"\"\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n\n    # GIT_DIR can interfere with correct operation of Versioneer.\n    # It may be intended to be passed to the Versioneer-versioned project,\n    # but that should not change where we get our version from.\n    env = os.environ.copy()\n    env.pop(\"GIT_DIR\", None)\n    runner = functools.partial(runner, env=env)\n\n    _, rc = runner(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root, hide_stderr=not verbose)\n    if rc != 0:\n        if verbose:\n            print(\"Directory %s not under git control\" % root)\n        raise NotThisMethod(\"'git rev-parse --git-dir' returned error\")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn't one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = runner(\n        GITS,\n        [\n            \"describe\",\n            \"--tags\",\n            \"--dirty\",\n            \"--always\",\n            \"--long\",\n            \"--match\",\n            f\"{tag_prefix}[[:digit:]]*\",\n        ],\n        cwd=root,\n    )\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(\"'git describe' failed\")\n    describe_out = describe_out.strip()\n    full_out, rc = runner(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(\"'git rev-parse' failed\")\n    full_out = full_out.strip()\n\n    pieces: Dict[str, Any] = {}\n    pieces[\"long\"] = full_out\n    pieces[\"short\"] = full_out[:7]  # maybe improved later\n    pieces[\"error\"] = None\n\n    branch_name, rc = runner(GITS, [\"rev-parse\", \"--abbrev-ref\", \"HEAD\"], cwd=root)\n    # --abbrev-ref was added in git-1.6.3\n    if rc != 0 or branch_name is None:\n        raise NotThisMethod(\"'git rev-parse --abbrev-ref' returned error\")\n    branch_name = branch_name.strip()\n\n    if branch_name == \"HEAD\":\n        # If we aren't exactly on a branch, pick a branch which represents\n        # the current commit. If all else fails, we are on a branchless\n        # commit.\n        branches, rc = runner(GITS, [\"branch\", \"--contains\"], cwd=root)\n        # --contains was added in git-1.5.4\n        if rc != 0 or branches is None:\n            raise NotThisMethod(\"'git branch --contains' returned error\")\n        branches = branches.split(\"\\n\")\n\n        # Remove the first line if we're running detached\n        if \"(\" in branches[0]:\n            branches.pop(0)\n\n        # Strip off the leading \"* \" from the list of branches.\n        branches = [branch[2:] for branch in branches]\n        if \"master\" in branches:\n            branch_name = \"master\"\n        elif not branches:\n            branch_name = None\n        else:\n            # Pick the first branch that is returned. Good or bad.\n            branch_name = branches[0]\n\n    pieces[\"branch\"] = branch_name\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(\"-dirty\")\n    pieces[\"dirty\"] = dirty\n    if dirty:\n        git_describe = git_describe[: git_describe.rindex(\"-dirty\")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if \"-\" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\"^(.+)-(\\d+)-g([0-9a-f]+)$\", git_describe)\n        if not mo:\n            # unparsable. Maybe git-describe is misbehaving?\n            pieces[\"error\"] = \"unable to parse git-describe output: '%s'\" % describe_out\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n                print(fmt % (full_tag, tag_prefix))\n            pieces[\"error\"] = \"tag '%s' doesn't start with prefix '%s'\" % (\n                full_tag,\n                tag_prefix,\n            )\n            return pieces\n        pieces[\"closest-tag\"] = full_tag[len(tag_prefix) :]\n\n        # distance: number of commits since tag\n        pieces[\"distance\"] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[\"short\"] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[\"closest-tag\"] = None\n        out, rc = runner(GITS, [\"rev-list\", \"HEAD\", \"--left-right\"], cwd=root)\n        pieces[\"distance\"] = len(out.split())  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = runner(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"], cwd=root)[0].strip()\n    # Use only the last line.  Previous lines may contain GPG signature\n    # information.\n    date = date.splitlines()[-1]\n    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n\n    return pieces",
  "def plus_or_dot(pieces: Dict[str, Any]) -> str:\n    \"\"\"Return a + if we don't already have one, else return a .\"\"\"\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"",
  "def render_pep440(pieces: Dict[str, Any]) -> str:\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += plus_or_dot(pieces)\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered",
  "def render_pep440_branch(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch. Note that .dev0 sorts backwards\n    (a feature branch will appear \"older\" than the master branch).\n\n    Exceptions:\n    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0\"\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+untagged.%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered",
  "def pep440_split_post(ver: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Split pep440 version string at the post-release segment.\n\n    Returns the release segments before the post-release and the\n    post-release version number (or -1 if no post-release segment is present).\n    \"\"\"\n    vc = str.split(ver, \".post\")\n    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None",
  "def render_pep440_pre(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postN.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post0.devDISTANCE\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        if pieces[\"distance\"]:\n            # update the post release segment\n            tag_version, post_version = pep440_split_post(pieces[\"closest-tag\"])\n            rendered = tag_version\n            if post_version is not None:\n                rendered += \".post%d.dev%d\" % (post_version + 1, pieces[\"distance\"])\n            else:\n                rendered += \".post0.dev%d\" % (pieces[\"distance\"])\n        else:\n            # no commits, use the tag as the version\n            rendered = pieces[\"closest-tag\"]\n    else:\n        # exception #1\n        rendered = \"0.post0.dev%d\" % pieces[\"distance\"]\n    return rendered",
  "def render_pep440_post(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The \".dev0\" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear \"older\" than the corresponding clean one),\n    but you shouldn't be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%s\" % pieces[\"short\"]\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n        rendered += \"+g%s\" % pieces[\"short\"]\n    return rendered",
  "def render_pep440_post_branch(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%s\" % pieces[\"short\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+g%s\" % pieces[\"short\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered",
  "def render_pep440_old(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]] .\n\n    The \".dev0\" means dirty.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n    return rendered",
  "def render_git_describe(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[-DISTANCE-gHEX][-dirty].\n\n    Like 'git describe --tags --dirty --always'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered",
  "def render_git_describe_long(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG-DISTANCE-gHEX[-dirty].\n\n    Like 'git describe --tags --dirty --always -long'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered",
  "def render(pieces: Dict[str, Any], style: str) -> Dict[str, Any]:\n    \"\"\"Render the given version pieces into the requested style.\"\"\"\n    if pieces[\"error\"]:\n        return {\n            \"version\": \"unknown\",\n            \"full-revisionid\": pieces.get(\"long\"),\n            \"dirty\": None,\n            \"error\": pieces[\"error\"],\n            \"date\": None,\n        }\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-branch\":\n        rendered = render_pep440_branch(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-post-branch\":\n        rendered = render_pep440_post_branch(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\n        \"version\": rendered,\n        \"full-revisionid\": pieces[\"long\"],\n        \"dirty\": pieces[\"dirty\"],\n        \"error\": None,\n        \"date\": pieces.get(\"date\"),\n    }",
  "def get_versions() -> Dict[str, Any]:\n    \"\"\"Get version information or return default if unable to do so.\"\"\"\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix, verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for _ in cfg.versionfile_source.split(\"/\"):\n            root = os.path.dirname(root)\n    except NameError:\n        return {\n            \"version\": \"0+unknown\",\n            \"full-revisionid\": None,\n            \"dirty\": None,\n            \"error\": \"unable to find root of source tree\",\n            \"date\": None,\n        }\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {\n        \"version\": \"0+unknown\",\n        \"full-revisionid\": None,\n        \"dirty\": None,\n        \"error\": \"unable to compute version\",\n        \"date\": None,\n    }",
  "def decorate(f: Callable) -> Callable:\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f",
  "def def_param() -> Dict:\n    \"\"\"\n    Get the default parameter json skeleton\n    \"\"\"\n    dp = deepcopy(ParamDictT.__annotations__)\n    del dp[\"name\"]\n    dp[\"description\"] = dp[\"long_name\"] = \"\"\n    dp[\"unit\"] = dp[\"source\"] = \"str\"\n    return dp",
  "def add_to_dict(pf: ParameterFrame, json_dict: Dict, params: Dict):\n    \"\"\"\n    Add each parameter to the json dict and params dict\n    \"\"\"\n    for param, param_type in pf.__annotations__.items():\n        dv = deepcopy(DEFAULT_PARAM)\n        dv[\"value\"] = str(param_type).split(\"[\")[-1][:-1]\n        json_dict[param] = dv\n        params[param] = param_type",
  "def create_parameterframe(\n    params: Dict, name: Optional[str] = None, *, header: bool = True\n) -> str:\n    \"\"\"\n    Create parameterframe python files as a string\n\n    Parameters\n    ----------\n    params: Dict\n        Dictionary of parameters to add to ParameterFrame\n    name: Optional[str]\n        name of ParameterFrame\n    header: bool\n        add import header\n\n    \"\"\"\n    param_cls = (\n        (\n            \"from dataclasses import dataclass\\n\\n\"\n            \"from bluemira.base.parameterframe import Parameter, ParameterFrame\\n\\n\\n\"\n        )\n        if header\n        else \"\"\n    )\n\n    param_cls += \"@dataclass\\nclass {}(ParameterFrame):\\n\"\n\n    if name is None:\n        param_cls = param_cls.format(\"ReactorParams\")\n    else:\n        param_cls = param_cls.format(name)\n\n    param_row = \"    {name}: {_type}\\n\"\n\n    for param, param_type in params.items():\n        param_cls += param_row.format(name=param, _type=str(param_type).split(\".\")[-1])\n\n    return param_cls",
  "def parse_args():\n    \"\"\"\n    Parse arguments\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Generate ParameterFrame files from module or package\"\n    )\n    parser.add_argument(\"module\", type=str, help=\"Module or Package to search through\")\n    parser.add_argument(\n        \"-c\", \"--collapse\", action=\"store_true\", help=\"Collapse to one ParameterFrame\"\n    )\n    parser.add_argument(\n        \"-d\", \"--save-directory\", dest=\"directory\", type=str, default=\"./\"\n    )\n    parser.add_argument(\n        \"-v\",\n        action=\"count\",\n        default=0,\n        help=\"Increase logging severity level.\",\n    )\n    parser.add_argument(\n        \"-q\",\n        action=\"count\",\n        default=0,\n        help=\"Decrease logging severity level.\",\n    )\n\n    args = parser.parse_args()\n    args.module = str(Path(args.module).resolve())\n    args.directory = str(Path(args.directory).resolve())\n\n    set_log_level(min(max(0, 2 + args.q - args.v), 5))\n    print_banner()\n    return args",
  "def get_param_classes(module) -> Dict:\n    \"\"\"\n    Get all ParameterFrame classes\n    \"\"\"\n    return {\n        f\"{m[0]}: {m[1].param_cls.__name__}\": m[1].param_cls\n        for m in inspect.getmembers(module, inspect.isclass)\n        if hasattr(m[1], \"param_cls\")\n        and not isinstance(m[1].param_cls, (type(None), abstractproperty))\n    }",
  "def find_modules(path: str) -> Set:\n    \"\"\"Recursively get modules from package\"\"\"\n    modules = set()\n    for pkg in find_packages(path):\n        if \"test\" in pkg:\n            bluemira_debug(f\"Ignoring {pkg}, possible test package\")\n            continue\n        modules.add(pkg)\n        pkgpath = path + \"/\" + pkg.replace(\".\", \"/\")\n        for info in iter_modules([pkgpath]):\n            if \"test\" in info.name:\n                bluemira_debug(f\"Ignoring {info.name}, possible test module\")\n            elif not info.ispkg:\n                modules.add(f\"{pkg}.{info.name}\")\n    bluemira_print(\"Found modules:\\n\" + \"\\n\".join(sorted(m for m in modules)))\n    if not os.path.commonprefix(list(modules)):\n        bluemira_warn(\n            \"Not all modules come from the same package.\"\n            \" Is your module path one level too deep?\"\n        )\n\n    return modules",
  "def main():\n    \"\"\"\n    Generate python and json parameterframe files\n    \"\"\"\n    args = parse_args()\n\n    param_classes = {}\n\n    sys.path.insert(0, args.module)\n    mods = find_modules(args.module)\n    if len(mods) > 0:\n        for mod in mods:\n            path = Path(args.module, mod.replace(\".\", \"/\"))\n            if not path.is_dir():\n                module = get_module(f\"{path}.py\")\n                param_classes.update(get_param_classes(module))\n    else:\n        module = get_module(args.module)\n        param_classes.update(get_param_classes(module))\n\n    bluemira_print(\n        \"Found ParameterFrames:\\n\" + \"\\n\".join(sorted(k for k in param_classes.keys()))\n    )\n\n    output = {}\n    params = {}\n\n    bluemira_print(f\"Writing output files to {args.directory}\")\n    if args.collapse:\n        for vv in param_classes.values():\n            add_to_dict(vv, output, params)\n\n        with open(Path(args.directory, \"params.py\"), \"w\") as fh:\n            fh.write(create_parameterframe(params))\n        json_writer(output, file=Path(args.directory, \"params.json\"))\n\n    else:\n        for kk, vv in param_classes.items():\n            output[kk] = {}\n            params[kk] = {}\n            add_to_dict(vv, output[kk], params[kk])\n\n        with open(Path(args.directory, \"params.py\"), \"w\") as fh:\n            header = True\n            for out_name, out_val in output.items():\n                pname = out_name.replace(\" \", \"\")\n                pname = pname.replace(\":\", \"_\")\n                fh.write(create_parameterframe(params[out_name], pname, header=header))\n                fh.write(\"\\n\")\n                json_writer(out_val, file=Path(args.directory, f\"{pname}.json\"))\n                header = False\n    bluemira_print(\"Done\")",
  "def _k_array(\n    k11: float,\n    k22: float,\n    k33: float,\n    k44: float,\n    k55: float,\n    k66: float,\n    k35: float,\n    k26: float,\n    k511: float,\n    k612: float,\n) -> np.ndarray:\n    \"\"\"\n    3-D stiffness local member stiffness matrix, generalised for cases with\n    and without shear\n\n    Parameters\n    ----------\n    Local stiffness matrix non-zero elements\n\n    Returns\n    -------\n    The local member stiffness matrix\n    \"\"\"\n    return np.array(\n        [\n            [k11, 0, 0, 0, 0, 0, -k11, 0, 0, 0, 0, 0],\n            [0, k22, 0, 0, 0, k26, 0, -k22, 0, 0, 0, k26],\n            [0, 0, k33, 0, k35, 0, 0, 0, -k33, 0, k35, 0],\n            [0, 0, 0, k44, 0, 0, 0, 0, 0, -k44, 0, 0],\n            [0, 0, k35, 0, k55, 0, 0, 0, -k35, 0, k511, 0],\n            [0, k26, 0, 0, 0, k66, 0, -k26, 0, 0, 0, k612],\n            [-k11, 0, 0, 0, 0, 0, k11, 0, 0, 0, 0, 0],\n            [0, -k22, 0, 0, 0, -k26, 0, k22, 0, 0, 0, -k26],\n            [0, 0, -k33, 0, -k35, 0, 0, 0, k33, 0, -k35, 0],\n            [0, 0, 0, -k44, 0, 0, 0, 0, 0, k44, 0, 0],\n            [0, 0, k35, 0, k511, 0, 0, 0, -k35, 0, k55, 0],\n            [0, k26, 0, 0, 0, k612, 0, -k26, 0, 0, 0, k66],\n        ]\n    )",
  "def local_k_shear(\n    EA: float,  # noqa: N803\n    EIyy: float,  # noqa: N803\n    EIzz: float,  # noqa: N803\n    ry: float,\n    rz: float,\n    L: float,  # noqa: N803\n    GJ: float,  # noqa: N803\n    A: float,  # noqa: N803\n    A_sy: float,  # noqa: N803\n    A_sz: float,  # noqa: N803\n    nu: float = NU,\n) -> np.ndarray:\n    \"\"\"\n    3-D stiffness local member stiffness matrix, including shear deformation\n\n    Parameters\n    ----------\n    EA:\n        Youngs modulus x cross-sectional area\n    EIyy:\n        Youngs modulus x second moment of area about the element y-axis\n    EIzz:\n        Youngs modulus x second moment of area about the element z-axis\n    L:\n        The length of the beam\n    GJ:\n        The rigidity modulus x torsion constant\n    A_sy:\n        The shear area in the y-plane\n    A_sz:\n        The shear area in the z-plane\n    nu:\n        Poisson ratio\n\n    Returns\n    -------\n    The local member stiffness matrix\n    \"\"\"\n    phi_y = 24 * (1 + nu) * (A / A_sy) * (rz / L) ** 2  # y shear deformation parameter\n    phi_z = 24 * (1 + nu) * (A / A_sz) * (ry / L) ** 2  # z shear deformation parameter\n    k11 = EA / L\n    k22 = 12 * EIzz / (L**3 * (1 + phi_y))\n    k33 = 12 * EIyy / (L**3 * (1 + phi_z))\n    k44 = GJ / L\n    k55 = (4 + phi_z) * EIyy / (L * (1 + phi_z))\n    k66 = (4 + phi_y) * EIzz / (L * (1 + phi_y))\n    k35 = -6 * EIyy / (L**2 * (1 + phi_z))\n    k26 = 6 * EIzz / (L**2 * (1 + phi_y))\n    k511 = (2 - phi_z) * EIyy / (L * (1 + phi_z))\n    k612 = (2 - phi_y) * EIzz / (L * (1 + phi_y))\n    return _k_array(k11, k22, k33, k44, k55, k66, k35, k26, k511, k612)",
  "def local_k(\n    EA: float, EIyy: float, EIzz: float, L: float, GJ: float  # noqa (N803)\n) -> np.ndarray:\n    \"\"\"\n    3-D stiffness local member stiffness matrix, including shear deformation\n\n    Parameters\n    ----------\n    EA:\n        Youngs modulus x cross-sectional area\n    EIyy:\n        Youngs modulus x second moment of area about the element y-axis\n    EIzz:\n        Youngs modulus x second moment of area about the element z-axis\n    L:\n        The length of the beam\n    GJ:\n        The rigidity modulus x torsion constant\n\n    Returns\n    -------\n    The local member stiffness matrix\n    \"\"\"\n    k11 = EA / L\n    k22 = 12 * EIzz / L**3\n    k33 = 12 * EIyy / L**3\n    k44 = GJ / L\n    k55 = 4 * EIyy / L\n    k66 = 4 * EIzz / L\n    k35 = -6 * EIyy / L**2\n    k26 = 6 * EIzz / L**2\n    k511 = 2 * EIyy / L\n    k612 = 2 * EIzz / L\n    return _k_array(k11, k22, k33, k44, k55, k66, k35, k26, k511, k612)",
  "class Element:\n    \"\"\"\n    A 3-D beam element (Euler-Bernoulli type)\n\n    Parameters\n    ----------\n    node_1:\n        The first node\n    node_2:\n        The second node\n    id_number:\n        The ID number of this element\n    cross_section:\n        The CrossSection property object of the element\n    material:\n        The Material property object of the element\n    \"\"\"\n\n    HERMITE_POLYS = hermite_polynomials(N_INTERP)\n\n    __slots__ = (\n        \"node_1\",\n        \"node_2\",\n        \"id_number\",\n        \"loads\",\n        \"stresses\",\n        \"max_stress\",\n        \"safety_factor\",\n        \"shapes\",\n        \"material\",\n        \"_properties\",\n        \"_material\",\n        \"_cross_section\",\n        \"_length\",\n        \"_weight\",\n        \"_k_matrix\",\n        \"_lambda_matrix\",\n        \"_k_matrix_glob\",\n        \"_s_functs\",\n    )\n\n    def __init__(\n        self,\n        node_1: Node,\n        node_2: Node,\n        id_number: int,\n        cross_section: CrossSection,\n        material: Optional[StructuralMaterial] = None,\n    ):\n        # Utility properties\n        self.node_1 = node_1\n        self.node_2 = node_2\n        self.id_number = id_number\n\n        # Public properties\n        self.loads = []\n\n        # Calculated properties\n        self.shapes = None\n        self.stresses = None\n        self.max_stress = None\n        self.safety_factor = None\n\n        # Private properties\n        self._material = material  # Record input material\n        self.material = None\n        self._properties = self._process_properties(cross_section, material)\n\n        self._cross_section = cross_section\n\n        # Cheap memo-isation of matrices (headache-free cached properties)\n        self._length = None\n        self._weight = None\n        self._k_matrix = None\n        self._lambda_matrix = None\n        self._k_matrix_glob = None\n\n        # Private construction utilities\n        self._s_functs = None\n\n    def _process_properties(self, cross_section, material):\n        \"\"\"\n        Handles cross-sectional and material properties, including if a\n        composite material cross-section is specified.\n        \"\"\"\n        properties = {}\n        if material is None:\n            # A composite cross-section was hopefully specified\n\n            properties[\"EA\"] = cross_section.ea\n            properties[\"EIyy\"] = cross_section.ei_yy\n            properties[\"EIzz\"] = cross_section.ei_zz\n            properties[\"GJ\"] = cross_section.gj\n            properties[\"nu\"] = cross_section.nu\n            properties[\"ry\"] = cross_section.ry\n            properties[\"rz\"] = cross_section.rz\n            properties[\"A\"] = cross_section.area\n            properties[\"rho\"] = cross_section.rho  # area-weighted density\n\n            # Override material=None with a list of materials from the CS\n            self.material = cross_section.material\n        else:\n            # Single material weight cross-section properties\n            e_mat, g_mat = material.E, material.G\n            properties[\"EA\"] = e_mat * cross_section.area\n            properties[\"EIyy\"] = e_mat * cross_section.i_yy\n            properties[\"EIzz\"] = e_mat * cross_section.i_zz\n            properties[\"GJ\"] = g_mat * cross_section.j\n            properties[\"ry\"] = cross_section.ry\n            properties[\"rz\"] = cross_section.rz\n            properties[\"rho\"] = material.rho\n            properties[\"A\"] = cross_section.area\n            self.material = material\n\n        return properties\n\n    @property\n    def length(self) -> float:\n        \"\"\"\n        Element length\n        \"\"\"\n        if self._length is None:\n            self._length = self.node_2.distance_to_other(self.node_1)\n        return self._length\n\n    @property\n    def weight(self) -> float:\n        \"\"\"\n        Element self-weight force per unit length\n        \"\"\"\n        if self._weight is None:\n            mass = self._properties[\"A\"] * self._properties[\"rho\"]\n            self._weight = GRAVITY * mass\n        return self._weight\n\n    @property\n    def mid_point(self) -> np.ndarray:\n        \"\"\"\n        The mid point of the Element\n\n        Returns\n        -------\n        vector: np.array(3)\n            The [x, y, z] vector of the midpoint\n        \"\"\"\n        return get_midpoint(self.node_1, self.node_2)\n\n    @property\n    def space_vector(self):\n        \"\"\"\n        Spatial vector of the Element\n\n        Returns\n        -------\n        vector: np.array(3)\n            The [dx, dy, dz] vector of the Element\n        \"\"\"\n        return np.array(\n            [\n                self.node_2.x - self.node_1.x,\n                self.node_2.y - self.node_1.y,\n                self.node_2.z - self.node_1.z,\n            ]\n        )\n\n    @property\n    def displacements(self) -> np.ndarray:\n        \"\"\"\n        Element global displacement vector at nodes\n        \"\"\"\n        u = np.zeros(12)\n        u[:6] = self.node_1.displacements\n        u[6:] = self.node_2.displacements\n        return u\n\n    @property\n    def max_displacement(self) -> float:\n        \"\"\"\n        Maximum element absolute displacement values\n\n        Returns\n        -------\n        The maximum absolute deflection distance of the two Nodes\n        \"\"\"\n        d_1 = self.node_1.displacements[:3]\n        d_2 = self.node_2.displacements[:3]\n        return max(np.sqrt(np.sum(d_1**2)), np.sqrt(np.sum(d_2**2)))\n\n    @property\n    def k_matrix(self) -> np.ndarray:\n        \"\"\"\n        Element stiffness matrix in local coordinates\n        \"\"\"\n        if self._k_matrix is None:\n            p = self._properties\n            k = local_k(p[\"EA\"], p[\"EIyy\"], p[\"EIzz\"], self.length, p[\"GJ\"])\n\n            if (p[\"ry\"] / self.length > SD_LIMIT) or (p[\"rz\"] / self.length < SD_LIMIT):\n                bluemira_warn(\n                    \"Thick cross-section detected. Slender beam approximation being used, so be careful.\"\n                )\n\n            self._k_matrix = k\n\n        return self._k_matrix\n\n    @property\n    def k_matrix_glob(self) -> np.ndarray:\n        \"\"\"\n        Element stiffness matrix in global coordinates\n        \"\"\"\n        if self._k_matrix_glob is None:\n            lambda_m = self.lambda_matrix\n            self._k_matrix_glob = lambda_m.T @ self.k_matrix @ lambda_m\n\n        return self._k_matrix_glob\n\n    @property\n    def lambda_matrix(self) -> np.ndarray:\n        \"\"\"\n        Transformation (direction cosine) matrix\n\n        Notes\n        -----\n        This matrix is cached but involves properties that may be externally\n        modified (e.g. by moving a node). Be careful to reset _lambda_matrix to\n        None if you are doing this, so that it gets recalculated upon call.\n        \"\"\"\n        if self._lambda_matrix is None:\n            d_x, d_y, d_z = self.space_vector\n\n            if d_x == 0 and d_y == 0 and d_z == 0:\n                raise StructuralError(\"Coincident nodes!?\")\n\n            self._lambda_matrix = lambda_matrix(d_x, d_y, d_z)\n\n        return self._lambda_matrix\n\n    def add_load(self, load: Dict[str, float]):\n        \"\"\"\n        Applies a load to the Element object.\n\n        Parameters\n        ----------\n        load:\n            The dictionary of load values (in local coordinates)\n        \"\"\"\n        self.loads.append(load)\n\n    def clear_loads(self):\n        \"\"\"\n        Clears all loads applied to the Element\n        \"\"\"\n        self.loads = []\n\n    def clear_cache(self):\n        \"\"\"\n        Clears all cached properties and matrices for the Element. Use if\n        an Element's geometry has been modified.\n        \"\"\"\n        self._length = None\n        self._weight = None\n        self._k_matrix = None\n        self._lambda_matrix = None\n        self._k_matrix_glob = None\n        self._s_functs = None\n\n    def u_vector(self) -> np.ndarray:\n        \"\"\"\n        Element local displacement vector\n        \"\"\"\n        return self.lambda_matrix @ self.displacements\n\n    def p_vector(self) -> np.ndarray:\n        \"\"\"\n        The local force vector of the element\n        \"\"\"\n        return self.k_matrix @ self.u_vector() - self._equivalent_node_forces()\n\n    def p_vector_glob(self) -> np.ndarray:\n        \"\"\"\n        The global force vector of the element\n        \"\"\"\n        return self.lambda_matrix.T @ self.p_vector()\n\n    def equivalent_node_forces(self) -> np.ndarray:\n        \"\"\"\n        Equivalent concentrated forces in global coordinates\n        \"\"\"\n        return self.lambda_matrix.T @ self._equivalent_node_forces()\n\n    def _equivalent_node_forces(self) -> np.ndarray:\n        \"\"\"\n        Element local nodal force vector\n\n        Equivalent concentrated forces in local coordinates\n        \"\"\"\n        enf = np.zeros(12)\n        for load in self.loads:\n            if load[\"type\"] == \"Element Load\":\n                enf += point_load(load[\"Q\"], load[\"x\"], self.length, load[\"sub_type\"])\n            elif load[\"type\"] == \"Distributed Load\":\n                enf += distributed_load(load[\"w\"], self.length, load[\"sub_type\"])\n            else:\n                raise StructuralError(f'Unknown load type: \"{load[\"type\"]}\"')\n\n        return enf\n\n    @property\n    def _shape_functions(self):\n        if self._s_functs is None:\n\n            def multiply_length(i):\n                n_matrix = np.copy(self.HERMITE_POLYS[i])\n                n_matrix[:, 1] *= self.length\n                n_matrix[:, 3] *= self.length\n                return n_matrix\n\n            self._s_functs = [multiply_length(0), multiply_length(1), multiply_length(2)]\n\n        return self._s_functs\n\n    def interpolate(self, scale: float):\n        \"\"\"\n        Interpolates the displacement of the beam with Hermite polynomial\n        shape functions to obtain inter-node displacement and stress\n\n        Parameters\n        ----------\n        scale:\n            The scale at which to calculate the interpolated displacements\n        \"\"\"\n        length = self.length\n        u = self.u_vector()  # Local displacements\n        s_funcs = self._shape_functions\n\n        d = np.zeros((N_INTERP, 2))  # displacement\n        m = np.zeros((N_INTERP, 2))  # curvature\n        v = np.zeros((N_INTERP, 2))  # shear\n\n        for i in range(2):\n            if i == 0:\n                # dy, rz\n                u1d = np.array([u[1], u[5], u[7], u[11]])\n            else:\n                # dz, ry\n                u1d = np.array([u[2], u[4], u[8], u[10]])\n\n            d[:, i] = np.dot(s_funcs[0], u1d)\n            m[:, i] = np.dot(s_funcs[1], u1d) / length**2\n            v[:, i] = np.dot(s_funcs[2], u1d) / length**3\n        self.calculate_stress(u, m)\n        self.calculate_shape(u, d, m, v, scale)\n\n    def calculate_stress(self, u, m_matrix):\n        \"\"\"\n        Calculates the stresses in the Element, using Hermite polynomials for\n        interpolation between the Nodes\n        \"\"\"\n        xsections = self._cross_section\n        materials = self.material\n\n        # Handle both single and multiple composite cross-sections\n        if not isinstance(xsections, list):\n            xsections = [xsections]\n        if not isinstance(materials, list):\n            materials = [materials]\n\n        stresses = []\n        safety_factors = []\n        for c_s, mat in zip(xsections, materials):\n            y = c_s.y - c_s.centroid[1]  # y-distances to centroid\n            z = c_s.z - c_s.centroid[2]  # z-distances to centroid\n\n            n_points = len(y)\n            # Tile coordinates\n            y = np.ones((N_INTERP, 1)) @ y.reshape(1, -1)\n            z = np.ones((N_INTERP, 1)) @ z.reshape(1, -1)\n\n            # Tile curvature (M/EI)\n            kappa_z = m_matrix[:, 0].reshape(-1, 1) @ np.ones((1, n_points))\n            kappa_y = m_matrix[:, 1].reshape(-1, 1) @ np.ones((1, n_points))\n\n            # Bending stresses (at all interp points, at all loop points)\n            sigma_z = -mat.E * y * kappa_z\n            sigma_y = -mat.E * z * kappa_y\n\n            # Axial stress = E*axial strain (constant along Element)\n            du = u[6] - u[0]\n            sigma_axial = mat.E * du / self.length\n\n            stress = sigma_axial + sigma_y + sigma_z\n            stresses.append(stress)\n\n            argmax = np.argmax(np.abs(stress))\n            safety_factor = stress.flatten()[argmax] / mat.sigma_y\n            safety_factors.append(safety_factor)\n\n        part_index = int(np.argmax(np.abs(safety_factors)))\n        max_index = np.argmax(np.abs(stresses[part_index]))\n\n        self.stresses = stresses[part_index]  # Only store most stressed mat\n        # Store peak stress (with sign)\n        self.max_stress = stresses[part_index].flatten()[max_index]\n        self.safety_factor = min(np.abs(safety_factors))\n\n    def calculate_shape(self, u, d, m, v, scale):\n        \"\"\"\n        Calculates the interpolated shape of the Element\n        \"\"\"\n        # Global interpolated displacements\n        u = np.array([np.linspace(u[0], u[1], N_INTERP), d[:, 0], d[:, 1]])\n        displacements = self.lambda_matrix[0:3, 0:3].T @ u\n\n        # Global interpolated positions\n        c = np.array(\n            [\n                np.linspace(self.node_1.x, self.node_2.x, N_INTERP),\n                np.linspace(self.node_1.y, self.node_2.y, N_INTERP),\n                np.linspace(self.node_1.z, self.node_2.z, N_INTERP),\n            ]\n        )\n        self.shapes = c + scale * displacements",
  "def __init__(\n        self,\n        node_1: Node,\n        node_2: Node,\n        id_number: int,\n        cross_section: CrossSection,\n        material: Optional[StructuralMaterial] = None,\n    ):\n        # Utility properties\n        self.node_1 = node_1\n        self.node_2 = node_2\n        self.id_number = id_number\n\n        # Public properties\n        self.loads = []\n\n        # Calculated properties\n        self.shapes = None\n        self.stresses = None\n        self.max_stress = None\n        self.safety_factor = None\n\n        # Private properties\n        self._material = material  # Record input material\n        self.material = None\n        self._properties = self._process_properties(cross_section, material)\n\n        self._cross_section = cross_section\n\n        # Cheap memo-isation of matrices (headache-free cached properties)\n        self._length = None\n        self._weight = None\n        self._k_matrix = None\n        self._lambda_matrix = None\n        self._k_matrix_glob = None\n\n        # Private construction utilities\n        self._s_functs = None",
  "def _process_properties(self, cross_section, material):\n        \"\"\"\n        Handles cross-sectional and material properties, including if a\n        composite material cross-section is specified.\n        \"\"\"\n        properties = {}\n        if material is None:\n            # A composite cross-section was hopefully specified\n\n            properties[\"EA\"] = cross_section.ea\n            properties[\"EIyy\"] = cross_section.ei_yy\n            properties[\"EIzz\"] = cross_section.ei_zz\n            properties[\"GJ\"] = cross_section.gj\n            properties[\"nu\"] = cross_section.nu\n            properties[\"ry\"] = cross_section.ry\n            properties[\"rz\"] = cross_section.rz\n            properties[\"A\"] = cross_section.area\n            properties[\"rho\"] = cross_section.rho  # area-weighted density\n\n            # Override material=None with a list of materials from the CS\n            self.material = cross_section.material\n        else:\n            # Single material weight cross-section properties\n            e_mat, g_mat = material.E, material.G\n            properties[\"EA\"] = e_mat * cross_section.area\n            properties[\"EIyy\"] = e_mat * cross_section.i_yy\n            properties[\"EIzz\"] = e_mat * cross_section.i_zz\n            properties[\"GJ\"] = g_mat * cross_section.j\n            properties[\"ry\"] = cross_section.ry\n            properties[\"rz\"] = cross_section.rz\n            properties[\"rho\"] = material.rho\n            properties[\"A\"] = cross_section.area\n            self.material = material\n\n        return properties",
  "def length(self) -> float:\n        \"\"\"\n        Element length\n        \"\"\"\n        if self._length is None:\n            self._length = self.node_2.distance_to_other(self.node_1)\n        return self._length",
  "def weight(self) -> float:\n        \"\"\"\n        Element self-weight force per unit length\n        \"\"\"\n        if self._weight is None:\n            mass = self._properties[\"A\"] * self._properties[\"rho\"]\n            self._weight = GRAVITY * mass\n        return self._weight",
  "def mid_point(self) -> np.ndarray:\n        \"\"\"\n        The mid point of the Element\n\n        Returns\n        -------\n        vector: np.array(3)\n            The [x, y, z] vector of the midpoint\n        \"\"\"\n        return get_midpoint(self.node_1, self.node_2)",
  "def space_vector(self):\n        \"\"\"\n        Spatial vector of the Element\n\n        Returns\n        -------\n        vector: np.array(3)\n            The [dx, dy, dz] vector of the Element\n        \"\"\"\n        return np.array(\n            [\n                self.node_2.x - self.node_1.x,\n                self.node_2.y - self.node_1.y,\n                self.node_2.z - self.node_1.z,\n            ]\n        )",
  "def displacements(self) -> np.ndarray:\n        \"\"\"\n        Element global displacement vector at nodes\n        \"\"\"\n        u = np.zeros(12)\n        u[:6] = self.node_1.displacements\n        u[6:] = self.node_2.displacements\n        return u",
  "def max_displacement(self) -> float:\n        \"\"\"\n        Maximum element absolute displacement values\n\n        Returns\n        -------\n        The maximum absolute deflection distance of the two Nodes\n        \"\"\"\n        d_1 = self.node_1.displacements[:3]\n        d_2 = self.node_2.displacements[:3]\n        return max(np.sqrt(np.sum(d_1**2)), np.sqrt(np.sum(d_2**2)))",
  "def k_matrix(self) -> np.ndarray:\n        \"\"\"\n        Element stiffness matrix in local coordinates\n        \"\"\"\n        if self._k_matrix is None:\n            p = self._properties\n            k = local_k(p[\"EA\"], p[\"EIyy\"], p[\"EIzz\"], self.length, p[\"GJ\"])\n\n            if (p[\"ry\"] / self.length > SD_LIMIT) or (p[\"rz\"] / self.length < SD_LIMIT):\n                bluemira_warn(\n                    \"Thick cross-section detected. Slender beam approximation being used, so be careful.\"\n                )\n\n            self._k_matrix = k\n\n        return self._k_matrix",
  "def k_matrix_glob(self) -> np.ndarray:\n        \"\"\"\n        Element stiffness matrix in global coordinates\n        \"\"\"\n        if self._k_matrix_glob is None:\n            lambda_m = self.lambda_matrix\n            self._k_matrix_glob = lambda_m.T @ self.k_matrix @ lambda_m\n\n        return self._k_matrix_glob",
  "def lambda_matrix(self) -> np.ndarray:\n        \"\"\"\n        Transformation (direction cosine) matrix\n\n        Notes\n        -----\n        This matrix is cached but involves properties that may be externally\n        modified (e.g. by moving a node). Be careful to reset _lambda_matrix to\n        None if you are doing this, so that it gets recalculated upon call.\n        \"\"\"\n        if self._lambda_matrix is None:\n            d_x, d_y, d_z = self.space_vector\n\n            if d_x == 0 and d_y == 0 and d_z == 0:\n                raise StructuralError(\"Coincident nodes!?\")\n\n            self._lambda_matrix = lambda_matrix(d_x, d_y, d_z)\n\n        return self._lambda_matrix",
  "def add_load(self, load: Dict[str, float]):\n        \"\"\"\n        Applies a load to the Element object.\n\n        Parameters\n        ----------\n        load:\n            The dictionary of load values (in local coordinates)\n        \"\"\"\n        self.loads.append(load)",
  "def clear_loads(self):\n        \"\"\"\n        Clears all loads applied to the Element\n        \"\"\"\n        self.loads = []",
  "def clear_cache(self):\n        \"\"\"\n        Clears all cached properties and matrices for the Element. Use if\n        an Element's geometry has been modified.\n        \"\"\"\n        self._length = None\n        self._weight = None\n        self._k_matrix = None\n        self._lambda_matrix = None\n        self._k_matrix_glob = None\n        self._s_functs = None",
  "def u_vector(self) -> np.ndarray:\n        \"\"\"\n        Element local displacement vector\n        \"\"\"\n        return self.lambda_matrix @ self.displacements",
  "def p_vector(self) -> np.ndarray:\n        \"\"\"\n        The local force vector of the element\n        \"\"\"\n        return self.k_matrix @ self.u_vector() - self._equivalent_node_forces()",
  "def p_vector_glob(self) -> np.ndarray:\n        \"\"\"\n        The global force vector of the element\n        \"\"\"\n        return self.lambda_matrix.T @ self.p_vector()",
  "def equivalent_node_forces(self) -> np.ndarray:\n        \"\"\"\n        Equivalent concentrated forces in global coordinates\n        \"\"\"\n        return self.lambda_matrix.T @ self._equivalent_node_forces()",
  "def _equivalent_node_forces(self) -> np.ndarray:\n        \"\"\"\n        Element local nodal force vector\n\n        Equivalent concentrated forces in local coordinates\n        \"\"\"\n        enf = np.zeros(12)\n        for load in self.loads:\n            if load[\"type\"] == \"Element Load\":\n                enf += point_load(load[\"Q\"], load[\"x\"], self.length, load[\"sub_type\"])\n            elif load[\"type\"] == \"Distributed Load\":\n                enf += distributed_load(load[\"w\"], self.length, load[\"sub_type\"])\n            else:\n                raise StructuralError(f'Unknown load type: \"{load[\"type\"]}\"')\n\n        return enf",
  "def _shape_functions(self):\n        if self._s_functs is None:\n\n            def multiply_length(i):\n                n_matrix = np.copy(self.HERMITE_POLYS[i])\n                n_matrix[:, 1] *= self.length\n                n_matrix[:, 3] *= self.length\n                return n_matrix\n\n            self._s_functs = [multiply_length(0), multiply_length(1), multiply_length(2)]\n\n        return self._s_functs",
  "def interpolate(self, scale: float):\n        \"\"\"\n        Interpolates the displacement of the beam with Hermite polynomial\n        shape functions to obtain inter-node displacement and stress\n\n        Parameters\n        ----------\n        scale:\n            The scale at which to calculate the interpolated displacements\n        \"\"\"\n        length = self.length\n        u = self.u_vector()  # Local displacements\n        s_funcs = self._shape_functions\n\n        d = np.zeros((N_INTERP, 2))  # displacement\n        m = np.zeros((N_INTERP, 2))  # curvature\n        v = np.zeros((N_INTERP, 2))  # shear\n\n        for i in range(2):\n            if i == 0:\n                # dy, rz\n                u1d = np.array([u[1], u[5], u[7], u[11]])\n            else:\n                # dz, ry\n                u1d = np.array([u[2], u[4], u[8], u[10]])\n\n            d[:, i] = np.dot(s_funcs[0], u1d)\n            m[:, i] = np.dot(s_funcs[1], u1d) / length**2\n            v[:, i] = np.dot(s_funcs[2], u1d) / length**3\n        self.calculate_stress(u, m)\n        self.calculate_shape(u, d, m, v, scale)",
  "def calculate_stress(self, u, m_matrix):\n        \"\"\"\n        Calculates the stresses in the Element, using Hermite polynomials for\n        interpolation between the Nodes\n        \"\"\"\n        xsections = self._cross_section\n        materials = self.material\n\n        # Handle both single and multiple composite cross-sections\n        if not isinstance(xsections, list):\n            xsections = [xsections]\n        if not isinstance(materials, list):\n            materials = [materials]\n\n        stresses = []\n        safety_factors = []\n        for c_s, mat in zip(xsections, materials):\n            y = c_s.y - c_s.centroid[1]  # y-distances to centroid\n            z = c_s.z - c_s.centroid[2]  # z-distances to centroid\n\n            n_points = len(y)\n            # Tile coordinates\n            y = np.ones((N_INTERP, 1)) @ y.reshape(1, -1)\n            z = np.ones((N_INTERP, 1)) @ z.reshape(1, -1)\n\n            # Tile curvature (M/EI)\n            kappa_z = m_matrix[:, 0].reshape(-1, 1) @ np.ones((1, n_points))\n            kappa_y = m_matrix[:, 1].reshape(-1, 1) @ np.ones((1, n_points))\n\n            # Bending stresses (at all interp points, at all loop points)\n            sigma_z = -mat.E * y * kappa_z\n            sigma_y = -mat.E * z * kappa_y\n\n            # Axial stress = E*axial strain (constant along Element)\n            du = u[6] - u[0]\n            sigma_axial = mat.E * du / self.length\n\n            stress = sigma_axial + sigma_y + sigma_z\n            stresses.append(stress)\n\n            argmax = np.argmax(np.abs(stress))\n            safety_factor = stress.flatten()[argmax] / mat.sigma_y\n            safety_factors.append(safety_factor)\n\n        part_index = int(np.argmax(np.abs(safety_factors)))\n        max_index = np.argmax(np.abs(stresses[part_index]))\n\n        self.stresses = stresses[part_index]  # Only store most stressed mat\n        # Store peak stress (with sign)\n        self.max_stress = stresses[part_index].flatten()[max_index]\n        self.safety_factor = min(np.abs(safety_factors))",
  "def calculate_shape(self, u, d, m, v, scale):\n        \"\"\"\n        Calculates the interpolated shape of the Element\n        \"\"\"\n        # Global interpolated displacements\n        u = np.array([np.linspace(u[0], u[1], N_INTERP), d[:, 0], d[:, 1]])\n        displacements = self.lambda_matrix[0:3, 0:3].T @ u\n\n        # Global interpolated positions\n        c = np.array(\n            [\n                np.linspace(self.node_1.x, self.node_2.x, N_INTERP),\n                np.linspace(self.node_1.y, self.node_2.y, N_INTERP),\n                np.linspace(self.node_1.z, self.node_2.z, N_INTERP),\n            ]\n        )\n        self.shapes = c + scale * displacements",
  "def multiply_length(i):\n                n_matrix = np.copy(self.HERMITE_POLYS[i])\n                n_matrix[:, 1] *= self.length\n                n_matrix[:, 3] *= self.length\n                return n_matrix",
  "def k_condensation(k: np.ndarray, releases: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Section 6.5 in J.S. Prz..\n    \"\"\"\n    # Initialise matrix partitions\n    n = np.count_nonzero(releases)\n    kxy = np.zeros((12 - n) * n)\n    kyy = np.zeros(n * n)\n\n    count_xy = 0\n    count_yy = 0\n    for i, free_1 in enumerate(releases):\n        for j, free_2 in enumerate(releases):\n            if not free_1 and free_2:\n                kxy[count_xy] = k[i, j]\n                count_xy += 1\n            elif free_1 and free_2:\n                kyy[count_yy] = k[i, j]\n                count_yy += 1\n    kxy = kxy.reshape((12 - n, n))\n    kyy = kyy.reshape((n, n))\n    return kxy, kyy",
  "def cyclic_decomposition(\n    k: np.ndarray, p: np.ndarray, l_nodes: List[int], r_nodes: List[int]\n) -> Tuple[np.ndarray, np.ndarray, List[np.ndarray]]:\n    \"\"\"\n    Perform a cyclic symmetry decomposition of the stiffness matrix and load\n    vector.\n\n    Parameters\n    ----------\n    k:\n        The stiffness matrix to decompose\n    p:\n        The load vector to decompose\n    l_nodes:\n        The left nodes indices where a symmetry condition was specified\n    r_nodes:\n        The right node indices where a symmetry condition was specified\n\n    Returns\n    -------\n    k_cyc:\n        The partitioned and ordered stiffness matrix\n    p_cyc:\n        The partitioned and ordered load vector\n    selections:\n        The list of left, right, and interior node selection arrays\n    \"\"\"\n\n    def selection_vec(node_ids):\n        ranges = [list(range(6 * i, 6 * i + 6)) for i in node_ids]\n        return np.array(ranges).flatten()\n\n    k = deepcopy(k)\n    p = deepcopy(p)\n\n    size = k.shape[0]\n    left = selection_vec(l_nodes)\n    right = selection_vec(r_nodes)\n    interior = np.arange(0, size)\n    drop = np.append(left, right)\n    drop.sort()\n    interior = np.delete(interior, drop)\n\n    k_rr = k[np.ix_(right, right)]\n    k_rl = k[np.ix_(right, left)]\n    k_ri = k[np.ix_(right, interior)]\n    k_lr = k[np.ix_(left, right)]\n    k_ll = k[np.ix_(left, left)]\n    k_li = k[np.ix_(left, interior)]\n    k_ir = k[np.ix_(interior, right)]\n    k_il = k[np.ix_(interior, left)]\n    k_ii = k[np.ix_(interior, interior)]\n\n    p_r = p[right]\n    p_l = p[left]\n    p_i = p[interior]\n\n    k_cyc = np.array(\n        [[k_rr, k_rl, k_ri], [k_lr, k_ll, k_li], [k_ir, k_il, k_ii]], dtype=object\n    )\n    p_cyc = np.array([p_r, p_l, p_i], dtype=object)\n    selections = [left, right, interior]\n\n    return k_cyc, p_cyc, selections",
  "def selection_vec(node_ids):\n        ranges = [list(range(6 * i, 6 * i + 6)) for i in node_ids]\n        return np.array(ranges).flatten()",
  "def check_matrix_condition(matrix: np.ndarray, digits: int):\n    \"\"\"\n    Checks the condition number of a matrix and warns if it is unsuitable for\n    working with.\n\n    Parameters\n    ----------\n    matrix:\n        The matrix to check the condition number of\n    digits:\n        The desired level of digit-precision (higher is less demanding)\n\n    Raises\n    ------\n    StructuralError\n        If the stiffness matrix is singular or ill-conditioned\n    \"\"\"\n    condition_number = np.linalg.cond(matrix)\n    digit_loss = np.log10(condition_number)\n\n    err_txt = \"\"\n    if condition_number > 1 / EPS:\n        err_txt = \"\"\"\n            \"Structural::FiniteElementModel:\\n Singular stiffness matrix will \"\n            \"cause LinAlgErrors.\\n\"\n            f\"matrix condition number: {condition_number}\"\n            \"\"\"\n\n    if digit_loss > digits:\n        digit_loss = int(np.ceil(digit_loss))\n\n        err_txt = \"\"\"\n            \"Structural::FiniteElementModel:\\n Ill-conditioned matrix\"\n            f\"\\n|\\tAccuracy loss below the {digit_loss}-th digit.\"\n        \"\"\"\n\n    if err_txt:\n        err_txt += \"\\nProbably worth checking model boundary conditions.\"\n        raise StructuralError(err_txt)",
  "class FiniteElementModel:\n    \"\"\"\n    3-D beam finite element model. The main interface object with other modules\n    As such, all important functionality is brought to the surface here, hence\n    the large number of class methods\n\n    Attributes\n    ----------\n    geometry:\n        The geometry in the FiniteElementModel\n    load_case:\n        The load case applied in the FiniteElementModel\n    n_fixed_dofs:\n        The number of fixed degrees of freedom\n    fixed_dofs:\n        The fixed degrees of freedom\n    fixed_dof_ids:\n        The id_numbers of the fixed degrees of freedom\n\n    \"\"\"\n\n    N_INTERP = 7  # Number of interpolation points in an Element\n\n    def __init__(self):\n        self.geometry = Geometry()\n        self.load_case = LoadCase()\n        self.n_fixed_dofs = 0\n        self.fixed_dofs = np.zeros(6, dtype=bool)  # Defaults to False\n        self.fixed_dof_ids = []\n        self.cycle_sym_ids = []\n        self.cycle_sym = None\n\n    # =========================================================================\n    # Geometry definition methods\n    # =========================================================================\n\n    def set_geometry(self, geometry: Geometry):\n        \"\"\"\n        Set a Geometry in the FiniteElementModel\n\n        Parameters\n        ----------\n        geometry:\n            The Geometry to add to the FiniteElementModel\n        \"\"\"\n        self.geometry = geometry\n\n    def add_node(self, x: float, y: float, z: float) -> int:\n        \"\"\"\n        Adds a Node to the FiniteElementModel\n\n        Parameters\n        ----------\n        x:\n            The node global x coordinate\n        y:\n            The node global y coordinate\n        z:\n            The node global z coordinate\n\n        Returns\n        -------\n        The ID number of the node that was added\n        \"\"\"\n        return self.geometry.add_node(x, y, z)\n\n    def add_element(\n        self,\n        node_id1: int,\n        node_id2: int,\n        cross_section: CrossSection,\n        material: Optional[StructuralMaterial] = None,\n    ) -> int:\n        \"\"\"\n        Adds an Element to the FiniteElementModel\n\n        Parameters\n        ----------\n        node_id1:\n            The ID number of the first node\n        node_id2:\n            The ID number of the second node\n        cross_section:\n            The CrossSection property object of the element\n        material:\n            The Material property object of the element\n\n        Returns\n        -------\n        The ID number of the element that was added\n        \"\"\"\n        return self.geometry.add_element(node_id1, node_id2, cross_section, material)\n\n    def add_coordinates(\n        self,\n        coords: Coordinates,\n        cross_section: CrossSection,\n        material: Optional[StructuralMaterial] = None,\n    ):\n        \"\"\"\n        Adds a Coordinates object to the FiniteElementModel\n\n        Parameters\n        ----------\n        coordinates:\n            The coordinates to transform into connected Nodes and Elements\n        cross_section:\n            The cross section of all the Elements in the Coordinates\n        material:\n            The material of all the Elements in the Coordinates\n        \"\"\"\n        self.geometry.add_coordinates(coords, cross_section, material)\n\n    def add_support(\n        self,\n        node_id: int,\n        dx: bool = False,\n        dy: bool = False,\n        dz: bool = False,\n        rx: bool = False,\n        ry: bool = False,\n        rz: bool = False,\n    ):\n        \"\"\"\n        Applies a support condition at a Node in the FiniteElementModel\n\n        Parameters\n        ----------\n        node_id:\n            The id_number of the Node where to apply the condition\n        dx, dy, dz:\n            Whether or not the linear DOFs at the Node are constrained\n        rx, ry, rz:\n            Whether or not the rotational DOFs at the Node\n        \"\"\"\n        supports = np.array([dx, dy, dz, rx, ry, rz], dtype=bool)\n        self.geometry.nodes[node_id].add_support(supports)\n\n    def find_supports(self):\n        \"\"\"\n        Find the support conditions in the FiniteElementModel.\n        \"\"\"\n        # Clear and start from scratch\n        self.n_fixed_dofs = 0\n        self.fixed_dof_ids = []\n\n        # Search each node for boundary conditions\n        for node in self.geometry.nodes:\n            n_supports = np.count_nonzero(node.supports)\n            self.n_fixed_dofs += n_supports  # Count fixed DOFs\n\n            if n_supports != 0:\n                support_indices = np.where(node.supports == True)[0]  # noqa (E712)\n                dofs = [6 * node.id_number + i for i in support_indices]\n                # Keep tracked of fixed DOFs\n                self.fixed_dof_ids.extend(dofs)\n                # Keep track of which DOFs are fixed\n                self.fixed_dofs[support_indices] = True\n\n    def apply_cyclic_symmetry(\n        self,\n        left_node_ids: List[int],\n        right_node_ids: List[int],\n        p1: Optional[np.ndarray] = None,\n        p2: Optional[np.ndarray] = None,\n    ):\n        \"\"\"\n        Applies a cyclic symmetry condition to the FiniteElementModel\n\n        Parameters\n        ----------\n        left_node_ids:\n            The id numbers of the nodes on the left boundary\n        right_node_ids:\n            The id numbers of the nodes on the right boundary\n        p1:\n            The first point of the symmetry rotation axis\n        p1:\n            The second point of the symmetry rotation axis\n        \"\"\"\n        if p1 is None:\n            p1 = [0, 0, 0]\n        if p2 is None:\n            p2 = [0, 0, 1]\n\n        # Apply symmetry flag at node level for plotting\n        for id_number in [left_node_ids, right_node_ids]:\n            self.geometry.nodes[id_number].symmetry = True\n\n        self.cycle_sym_ids.append([left_node_ids, right_node_ids, p1, p2])\n\n    # =========================================================================\n    # Load definition methods\n    # =========================================================================\n\n    def apply_load_case(self, load_case: LoadCase):\n        \"\"\"\n        Apply a load case to the FiniteElementModel.\n\n        Parameters\n        ----------\n        load_case:\n            The load case to apply to the model.\n        \"\"\"\n        self.load_case = load_case\n\n    def add_node_load(self, node_id: int, load: float, load_type: str):\n        \"\"\"\n        Adds a node load to the FiniteElementModel\n\n        Parameters\n        ----------\n        node_id:\n            The id_number of the Node to apply the load at\n        load:\n            The value of the load\n        load_type:\n            The type and axis of the load (from ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz'])\n        \"\"\"\n        self.load_case.add_node_load(node_id, load, load_type)\n\n    def add_element_load(self, element_id: int, load: float, x: float, load_type: str):\n        \"\"\"\n        Adds an element point load to the FiniteElementModel\n\n        Parameters\n        ----------\n        element_id:\n            The id_number of the Element to apply the load at\n        load:\n            The value of the load\n        x:\n            The parameterised and normalised distance along the element x-axis\n        load_type:\n            The type and axis of the load (from ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz'])\n        \"\"\"\n        self.load_case.add_element_load(element_id, load, x, load_type)\n\n    def add_distributed_load(self, element_id: int, w: float, load_type: str):\n        \"\"\"\n        Adds a distributed load to the FiniteElementModel\n\n        Parameters\n        ----------\n        element_id:\n            The id_number of the Element to apply the load at\n        w:\n            The value of the distributed load\n        load_type:\n            The type and axis of the load (from ['Fx', 'Fy', 'Fz'])\n        \"\"\"\n        self.load_case.add_distributed_load(element_id, w, load_type)\n\n    def add_gravity_loads(self):\n        \"\"\"\n        Applies self-weight distributed loads to all members\n        \"\"\"\n        for element in self.geometry.elements:\n            w = np.array([0, 0, -element.weight * element.length])\n            forces = element.lambda_matrix[0:3, 0:3] @ w\n\n            for i, direction in enumerate([\"Fx\", \"Fy\", \"Fz\"]):\n                if forces[i] != 0:\n                    self.add_distributed_load(element.id_number, forces[i], direction)\n\n    def clear_loads(self):\n        \"\"\"\n        Clears any applied loads to the model, and removes any displacements\n        \"\"\"\n        for node in self.geometry.nodes:\n            node.clear_loads()\n        for element in self.geometry.elements:\n            element.clear_loads()\n        self.load_case = LoadCase()\n\n    def clear_load_case(self):\n        \"\"\"\n        Clears the LoadCase applied to the model\n        \"\"\"\n        self.load_case = LoadCase()\n\n    # =========================================================================\n    # Private solution methods\n    # =========================================================================\n\n    def _apply_load_case(self, load_case: LoadCase):\n        \"\"\"\n        Applies a LoadCase to the FiniteElementModel. Maps individual loads to\n        their respective Nodes and Elements.\n\n        Parameters\n        ----------\n        load_case: LoadCase object\n            The list of loads to apply to the model\n        \"\"\"\n        for load in load_case:\n            if load[\"type\"] == \"Node Load\":\n                node = self.geometry.nodes[load[\"node_id\"]]\n                node.add_load(load)\n\n            elif load[\"type\"] in [\"Element Load\", \"Distributed Load\"]:\n                element = self.geometry.elements[load[\"element_id\"]]\n                element.add_load(load)\n            else:\n                raise StructuralError(f'Unknown load type \"{load[\"type\"]}\"')\n\n    def _get_nodal_forces(self) -> np.ndarray:\n        \"\"\"\n        Calculates the total nodal forces (including forces applied at nodes\n        and equivalent concentrated forces from element loads).\n\n        Returns\n        -------\n        The global nodal force vector (6*n_nodes)\n        \"\"\"\n        # NOTE: looping over loads in a LoadCase would no doubt be faster\n        # but it is more difficult to keep track of things in OO like this\n        p_vector = np.zeros(6 * self.geometry.n_nodes)\n\n        for node in self.geometry.nodes:\n            idn = 6 * node.id_number\n            p_vector[idn : idn + 6] += node.p_vector()\n\n        for element in self.geometry.elements:\n            enf = element.equivalent_node_forces()\n            i = 6 * element.node_1.id_number\n            j = 6 * element.node_2.id_number\n            p_vector[i : i + 6] += enf[:6]\n            p_vector[j : j + 6] += enf[6:]\n        return p_vector\n\n    def _get_reaction_forces(self) -> np.ndarray:\n        \"\"\"\n        Calculates the reaction forces, applying them to each of the nodes\n        and returning the full vector\n\n        Returns\n        -------\n        The full reaction vector in global coordinates over all the nodes (6*n_nodes)\n        \"\"\"\n        reactions = np.zeros(6 * self.geometry.n_nodes)\n\n        for element in self.geometry.elements:\n            p_glob = element.p_vector_glob()\n            element.node_1.reactions += p_glob[:6]\n            element.node_2.reactions += p_glob[6:]\n        for node in self.geometry.nodes:\n            p = node.p_vector()\n            node.reactions += p\n            idn = 6 * node.id_number\n            reactions[idn : idn + 6] = node.reactions\n        return reactions\n\n    def _math_checks(self, k_matrix: np.ndarray):\n        \"\"\"\n        Performs a series of checks on the model boundary conditions and the\n        global stiffness matrix K, prior to the solution of the system of\n        equations.\n\n        Parameters\n        ----------\n        k_matrix:\n            The global stiffness matrix to be checked ((6*n_nodes, 6*n_nodes))\n        \"\"\"\n        if self.n_fixed_dofs < 6:\n            # TODO: check dimensionality of problem (1-D, 2-D, 3-D) and reduce\n            # number of fixed DOFs required accordingly.\n            raise StructuralError(\n                \"Insufficient boundary conditions to carry out \"\n                f\"analysis:\\n fixed_dofs: {self.fixed_dofs}\"\n                \"\\n|\\tRigid-body motion.\"\n            )\n        if not self.fixed_dofs.all():\n            raise StructuralError(\n                \"Can only solve systems in which all DOFs have \"\n                \"been constrained at least once.\"\n            )\n        check_matrix_condition(k_matrix, 15)\n\n    def _displacement_check(self, deflections: np.ndarray):\n        \"\"\"\n        Checks to see if the displacements are not too big relative to the\n        size of the model.\n\n        Parameters\n        ----------\n        deflections:\n            The vector of absolute displacements (6*n_nodes)\n        \"\"\"\n        xmax, xmin, ymax, ymin, zmax, zmin = self.geometry.bounds()\n        dx, dy, dz = xmax - xmin, ymax - ymin, zmax - zmin\n        length = np.sqrt(dx**2 + dy**2 + dz**2)\n\n        # Get per node displacements\n        deflections = deflections.reshape((self.geometry.n_nodes, -1))\n        # Get absolute x, y, z displacement at each node\n        deflections = np.sum(deflections[:, :3] ** 2, axis=1) ** 0.5\n        u_max = np.max(deflections)\n\n        if u_max >= length / R_LARGE_DISP:\n            bluemira_warn(\n                \"structural::FiniteElementModel:\\n Large displacements detected\"\n                \"!\\nYou can't trust the results...\"\n            )\n\n    def _apply_boundary_conditions(\n        self, k: np.ndarray, p: np.ndarray, method: str = \"Przemieniecki\"\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Applies the boundary conditions to the matrices to make the problem\n        solvable. This is creation of the \"reduced\" stiffness matrix and\n        force vector, Kr and Pr.\n\n        Parameters\n        ----------\n        k:\n            The global stiffness matrix of the problem\n        p:\n            The global nodal force vector of the problem\n\n        Returns\n        -------\n        kr:\n            The reduced global stiffness matrix of the problem\n        pr:\n            The reduced global nodal force vector of the problem\n        \"\"\"\n        # TODO: determine which approach is more suitable!\n\n        # Modification of K and P matrices to remove the rigid-body DOFs\n        # This is the method recommended by Przemieniecki in the book\n        # Need to check which is faster with sparse matrices on real problems\n        # This method is also easier to unittest!! Indices stay the same :)\n        if method == \"Przemieniecki\":\n            for i in self.fixed_dof_ids:\n                # empty row or col of 0's with back-fill of diagonal term to 1\n                entry = np.zeros(6 * self.geometry.n_nodes)\n                entry[i] = 1\n                k[i, :] = entry\n                k[:, i] = entry\n                p[i] = 0\n\n        elif method == \"deletion\":\n            # Removes the rows and columns of the fixed degrees of freedom\n            # This reduces the size of the problem being solved, but this\n            # may not be the fastest way!\n            for i in sorted(self.fixed_dof_ids)[::-1]:\n                # Travel backwards to preserve numbering\n                k = np.delete(k, i, axis=0)\n                k = np.delete(k, i, axis=1)\n                p = np.delete(p, i)\n        else:\n            raise StructuralError(f\"Unrecognised method: {method}.\")\n        return k, p\n\n    def _apply_boundary_conditions_sparse(self, k, p):\n        for i in self.fixed_dof_ids:\n            row = np.zeros((1, 6 * self.geometry.n_nodes))\n            row[0, i] = 1\n            k[i, :] = row\n            k[:, i] = row.T\n            p[i] = 0\n        return k, p\n\n    def _apply_displacements(self, u_r):\n        \"\"\"\n        Applies the displacements to the individual nodes in the Geometry\n        \"\"\"\n        for i, node in enumerate(self.geometry.nodes):\n            node.displacements = u_r[6 * i : 6 * i + 6]\n\n    def plot(self, ax=None, **kwargs):\n        \"\"\"\n        Plots the model geometry, boundary conditions, and loads\n        \"\"\"\n        return self.geometry.plot(ax=ax, **kwargs)\n\n    def solve(\n        self, load_case: Optional[LoadCase] = None, sparse: bool = False\n    ) -> Result:\n        \"\"\"\n        Solves the system of linear equations for deflection and applies the\n        deflections to the nodes and elements of the geometry\n\n        Parameters\n        ----------\n        load_case:\n            Will default to the loads applied to the elements and nodes in the\n            geometry\n        sparse:\n            Whether or not to use sparse matrices to solve\n\n        Returns\n        -------\n        The result of the FE analysis with the applied LoadCase\n        \"\"\"\n        # Find model physical boundary conditions\n        self.find_supports()\n\n        # If no load_case is specified, take the class load_case\n        if load_case is None:\n            load_case = self.load_case\n\n        # Get the nodal force vector\n        self._apply_load_case(load_case)\n        p = self._get_nodal_forces()\n\n        # Check for cyclical symmetry\n        self.cycle_sym = CyclicSymmetry(self.geometry, self.cycle_sym_ids)\n\n        if not sparse:\n            # Get the global stiffness matrix\n            k = self.geometry.k_matrix()\n\n            # Constrain matrix and vector\n            kr, pr = self._apply_boundary_conditions(k, p, method=\"Przemieniecki\")\n\n            # Check boundary conditions and stiffness matrix\n            self._math_checks(kr)\n\n            # Apply cyclic boundary condition (if present)\n\n            kr, pr = self.cycle_sym.apply_cyclic_symmetry(kr, pr)\n\n            ur = np.linalg.solve(kr, pr)\n\n            ur = self.cycle_sym.reorder(ur)\n\n        else:\n            print(\"sparse\")\n            k = self.geometry.k_matrix_sparse()\n\n            kr, pr = self._apply_boundary_conditions_sparse(k, p)\n            ur = spsolve(kr.tocsr(), pr)\n\n        # Check for large displacements\n        self._displacement_check(ur)\n\n        # Apply the displacements to the nodes (and elements)\n        self._apply_displacements(ur)\n\n        # Calculate reaction forces at the nodes\n        reactions = self._get_reaction_forces()\n\n        # Interpolate the result between nodes, and calculate stresses\n        self.geometry.interpolate()\n\n        return Result(deepcopy(self.geometry), load_case, ur, reactions, self.cycle_sym)",
  "def __init__(self):\n        self.geometry = Geometry()\n        self.load_case = LoadCase()\n        self.n_fixed_dofs = 0\n        self.fixed_dofs = np.zeros(6, dtype=bool)  # Defaults to False\n        self.fixed_dof_ids = []\n        self.cycle_sym_ids = []\n        self.cycle_sym = None",
  "def set_geometry(self, geometry: Geometry):\n        \"\"\"\n        Set a Geometry in the FiniteElementModel\n\n        Parameters\n        ----------\n        geometry:\n            The Geometry to add to the FiniteElementModel\n        \"\"\"\n        self.geometry = geometry",
  "def add_node(self, x: float, y: float, z: float) -> int:\n        \"\"\"\n        Adds a Node to the FiniteElementModel\n\n        Parameters\n        ----------\n        x:\n            The node global x coordinate\n        y:\n            The node global y coordinate\n        z:\n            The node global z coordinate\n\n        Returns\n        -------\n        The ID number of the node that was added\n        \"\"\"\n        return self.geometry.add_node(x, y, z)",
  "def add_element(\n        self,\n        node_id1: int,\n        node_id2: int,\n        cross_section: CrossSection,\n        material: Optional[StructuralMaterial] = None,\n    ) -> int:\n        \"\"\"\n        Adds an Element to the FiniteElementModel\n\n        Parameters\n        ----------\n        node_id1:\n            The ID number of the first node\n        node_id2:\n            The ID number of the second node\n        cross_section:\n            The CrossSection property object of the element\n        material:\n            The Material property object of the element\n\n        Returns\n        -------\n        The ID number of the element that was added\n        \"\"\"\n        return self.geometry.add_element(node_id1, node_id2, cross_section, material)",
  "def add_coordinates(\n        self,\n        coords: Coordinates,\n        cross_section: CrossSection,\n        material: Optional[StructuralMaterial] = None,\n    ):\n        \"\"\"\n        Adds a Coordinates object to the FiniteElementModel\n\n        Parameters\n        ----------\n        coordinates:\n            The coordinates to transform into connected Nodes and Elements\n        cross_section:\n            The cross section of all the Elements in the Coordinates\n        material:\n            The material of all the Elements in the Coordinates\n        \"\"\"\n        self.geometry.add_coordinates(coords, cross_section, material)",
  "def add_support(\n        self,\n        node_id: int,\n        dx: bool = False,\n        dy: bool = False,\n        dz: bool = False,\n        rx: bool = False,\n        ry: bool = False,\n        rz: bool = False,\n    ):\n        \"\"\"\n        Applies a support condition at a Node in the FiniteElementModel\n\n        Parameters\n        ----------\n        node_id:\n            The id_number of the Node where to apply the condition\n        dx, dy, dz:\n            Whether or not the linear DOFs at the Node are constrained\n        rx, ry, rz:\n            Whether or not the rotational DOFs at the Node\n        \"\"\"\n        supports = np.array([dx, dy, dz, rx, ry, rz], dtype=bool)\n        self.geometry.nodes[node_id].add_support(supports)",
  "def find_supports(self):\n        \"\"\"\n        Find the support conditions in the FiniteElementModel.\n        \"\"\"\n        # Clear and start from scratch\n        self.n_fixed_dofs = 0\n        self.fixed_dof_ids = []\n\n        # Search each node for boundary conditions\n        for node in self.geometry.nodes:\n            n_supports = np.count_nonzero(node.supports)\n            self.n_fixed_dofs += n_supports  # Count fixed DOFs\n\n            if n_supports != 0:\n                support_indices = np.where(node.supports == True)[0]  # noqa (E712)\n                dofs = [6 * node.id_number + i for i in support_indices]\n                # Keep tracked of fixed DOFs\n                self.fixed_dof_ids.extend(dofs)\n                # Keep track of which DOFs are fixed\n                self.fixed_dofs[support_indices] = True",
  "def apply_cyclic_symmetry(\n        self,\n        left_node_ids: List[int],\n        right_node_ids: List[int],\n        p1: Optional[np.ndarray] = None,\n        p2: Optional[np.ndarray] = None,\n    ):\n        \"\"\"\n        Applies a cyclic symmetry condition to the FiniteElementModel\n\n        Parameters\n        ----------\n        left_node_ids:\n            The id numbers of the nodes on the left boundary\n        right_node_ids:\n            The id numbers of the nodes on the right boundary\n        p1:\n            The first point of the symmetry rotation axis\n        p1:\n            The second point of the symmetry rotation axis\n        \"\"\"\n        if p1 is None:\n            p1 = [0, 0, 0]\n        if p2 is None:\n            p2 = [0, 0, 1]\n\n        # Apply symmetry flag at node level for plotting\n        for id_number in [left_node_ids, right_node_ids]:\n            self.geometry.nodes[id_number].symmetry = True\n\n        self.cycle_sym_ids.append([left_node_ids, right_node_ids, p1, p2])",
  "def apply_load_case(self, load_case: LoadCase):\n        \"\"\"\n        Apply a load case to the FiniteElementModel.\n\n        Parameters\n        ----------\n        load_case:\n            The load case to apply to the model.\n        \"\"\"\n        self.load_case = load_case",
  "def add_node_load(self, node_id: int, load: float, load_type: str):\n        \"\"\"\n        Adds a node load to the FiniteElementModel\n\n        Parameters\n        ----------\n        node_id:\n            The id_number of the Node to apply the load at\n        load:\n            The value of the load\n        load_type:\n            The type and axis of the load (from ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz'])\n        \"\"\"\n        self.load_case.add_node_load(node_id, load, load_type)",
  "def add_element_load(self, element_id: int, load: float, x: float, load_type: str):\n        \"\"\"\n        Adds an element point load to the FiniteElementModel\n\n        Parameters\n        ----------\n        element_id:\n            The id_number of the Element to apply the load at\n        load:\n            The value of the load\n        x:\n            The parameterised and normalised distance along the element x-axis\n        load_type:\n            The type and axis of the load (from ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz'])\n        \"\"\"\n        self.load_case.add_element_load(element_id, load, x, load_type)",
  "def add_distributed_load(self, element_id: int, w: float, load_type: str):\n        \"\"\"\n        Adds a distributed load to the FiniteElementModel\n\n        Parameters\n        ----------\n        element_id:\n            The id_number of the Element to apply the load at\n        w:\n            The value of the distributed load\n        load_type:\n            The type and axis of the load (from ['Fx', 'Fy', 'Fz'])\n        \"\"\"\n        self.load_case.add_distributed_load(element_id, w, load_type)",
  "def add_gravity_loads(self):\n        \"\"\"\n        Applies self-weight distributed loads to all members\n        \"\"\"\n        for element in self.geometry.elements:\n            w = np.array([0, 0, -element.weight * element.length])\n            forces = element.lambda_matrix[0:3, 0:3] @ w\n\n            for i, direction in enumerate([\"Fx\", \"Fy\", \"Fz\"]):\n                if forces[i] != 0:\n                    self.add_distributed_load(element.id_number, forces[i], direction)",
  "def clear_loads(self):\n        \"\"\"\n        Clears any applied loads to the model, and removes any displacements\n        \"\"\"\n        for node in self.geometry.nodes:\n            node.clear_loads()\n        for element in self.geometry.elements:\n            element.clear_loads()\n        self.load_case = LoadCase()",
  "def clear_load_case(self):\n        \"\"\"\n        Clears the LoadCase applied to the model\n        \"\"\"\n        self.load_case = LoadCase()",
  "def _apply_load_case(self, load_case: LoadCase):\n        \"\"\"\n        Applies a LoadCase to the FiniteElementModel. Maps individual loads to\n        their respective Nodes and Elements.\n\n        Parameters\n        ----------\n        load_case: LoadCase object\n            The list of loads to apply to the model\n        \"\"\"\n        for load in load_case:\n            if load[\"type\"] == \"Node Load\":\n                node = self.geometry.nodes[load[\"node_id\"]]\n                node.add_load(load)\n\n            elif load[\"type\"] in [\"Element Load\", \"Distributed Load\"]:\n                element = self.geometry.elements[load[\"element_id\"]]\n                element.add_load(load)\n            else:\n                raise StructuralError(f'Unknown load type \"{load[\"type\"]}\"')",
  "def _get_nodal_forces(self) -> np.ndarray:\n        \"\"\"\n        Calculates the total nodal forces (including forces applied at nodes\n        and equivalent concentrated forces from element loads).\n\n        Returns\n        -------\n        The global nodal force vector (6*n_nodes)\n        \"\"\"\n        # NOTE: looping over loads in a LoadCase would no doubt be faster\n        # but it is more difficult to keep track of things in OO like this\n        p_vector = np.zeros(6 * self.geometry.n_nodes)\n\n        for node in self.geometry.nodes:\n            idn = 6 * node.id_number\n            p_vector[idn : idn + 6] += node.p_vector()\n\n        for element in self.geometry.elements:\n            enf = element.equivalent_node_forces()\n            i = 6 * element.node_1.id_number\n            j = 6 * element.node_2.id_number\n            p_vector[i : i + 6] += enf[:6]\n            p_vector[j : j + 6] += enf[6:]\n        return p_vector",
  "def _get_reaction_forces(self) -> np.ndarray:\n        \"\"\"\n        Calculates the reaction forces, applying them to each of the nodes\n        and returning the full vector\n\n        Returns\n        -------\n        The full reaction vector in global coordinates over all the nodes (6*n_nodes)\n        \"\"\"\n        reactions = np.zeros(6 * self.geometry.n_nodes)\n\n        for element in self.geometry.elements:\n            p_glob = element.p_vector_glob()\n            element.node_1.reactions += p_glob[:6]\n            element.node_2.reactions += p_glob[6:]\n        for node in self.geometry.nodes:\n            p = node.p_vector()\n            node.reactions += p\n            idn = 6 * node.id_number\n            reactions[idn : idn + 6] = node.reactions\n        return reactions",
  "def _math_checks(self, k_matrix: np.ndarray):\n        \"\"\"\n        Performs a series of checks on the model boundary conditions and the\n        global stiffness matrix K, prior to the solution of the system of\n        equations.\n\n        Parameters\n        ----------\n        k_matrix:\n            The global stiffness matrix to be checked ((6*n_nodes, 6*n_nodes))\n        \"\"\"\n        if self.n_fixed_dofs < 6:\n            # TODO: check dimensionality of problem (1-D, 2-D, 3-D) and reduce\n            # number of fixed DOFs required accordingly.\n            raise StructuralError(\n                \"Insufficient boundary conditions to carry out \"\n                f\"analysis:\\n fixed_dofs: {self.fixed_dofs}\"\n                \"\\n|\\tRigid-body motion.\"\n            )\n        if not self.fixed_dofs.all():\n            raise StructuralError(\n                \"Can only solve systems in which all DOFs have \"\n                \"been constrained at least once.\"\n            )\n        check_matrix_condition(k_matrix, 15)",
  "def _displacement_check(self, deflections: np.ndarray):\n        \"\"\"\n        Checks to see if the displacements are not too big relative to the\n        size of the model.\n\n        Parameters\n        ----------\n        deflections:\n            The vector of absolute displacements (6*n_nodes)\n        \"\"\"\n        xmax, xmin, ymax, ymin, zmax, zmin = self.geometry.bounds()\n        dx, dy, dz = xmax - xmin, ymax - ymin, zmax - zmin\n        length = np.sqrt(dx**2 + dy**2 + dz**2)\n\n        # Get per node displacements\n        deflections = deflections.reshape((self.geometry.n_nodes, -1))\n        # Get absolute x, y, z displacement at each node\n        deflections = np.sum(deflections[:, :3] ** 2, axis=1) ** 0.5\n        u_max = np.max(deflections)\n\n        if u_max >= length / R_LARGE_DISP:\n            bluemira_warn(\n                \"structural::FiniteElementModel:\\n Large displacements detected\"\n                \"!\\nYou can't trust the results...\"\n            )",
  "def _apply_boundary_conditions(\n        self, k: np.ndarray, p: np.ndarray, method: str = \"Przemieniecki\"\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Applies the boundary conditions to the matrices to make the problem\n        solvable. This is creation of the \"reduced\" stiffness matrix and\n        force vector, Kr and Pr.\n\n        Parameters\n        ----------\n        k:\n            The global stiffness matrix of the problem\n        p:\n            The global nodal force vector of the problem\n\n        Returns\n        -------\n        kr:\n            The reduced global stiffness matrix of the problem\n        pr:\n            The reduced global nodal force vector of the problem\n        \"\"\"\n        # TODO: determine which approach is more suitable!\n\n        # Modification of K and P matrices to remove the rigid-body DOFs\n        # This is the method recommended by Przemieniecki in the book\n        # Need to check which is faster with sparse matrices on real problems\n        # This method is also easier to unittest!! Indices stay the same :)\n        if method == \"Przemieniecki\":\n            for i in self.fixed_dof_ids:\n                # empty row or col of 0's with back-fill of diagonal term to 1\n                entry = np.zeros(6 * self.geometry.n_nodes)\n                entry[i] = 1\n                k[i, :] = entry\n                k[:, i] = entry\n                p[i] = 0\n\n        elif method == \"deletion\":\n            # Removes the rows and columns of the fixed degrees of freedom\n            # This reduces the size of the problem being solved, but this\n            # may not be the fastest way!\n            for i in sorted(self.fixed_dof_ids)[::-1]:\n                # Travel backwards to preserve numbering\n                k = np.delete(k, i, axis=0)\n                k = np.delete(k, i, axis=1)\n                p = np.delete(p, i)\n        else:\n            raise StructuralError(f\"Unrecognised method: {method}.\")\n        return k, p",
  "def _apply_boundary_conditions_sparse(self, k, p):\n        for i in self.fixed_dof_ids:\n            row = np.zeros((1, 6 * self.geometry.n_nodes))\n            row[0, i] = 1\n            k[i, :] = row\n            k[:, i] = row.T\n            p[i] = 0\n        return k, p",
  "def _apply_displacements(self, u_r):\n        \"\"\"\n        Applies the displacements to the individual nodes in the Geometry\n        \"\"\"\n        for i, node in enumerate(self.geometry.nodes):\n            node.displacements = u_r[6 * i : 6 * i + 6]",
  "def plot(self, ax=None, **kwargs):\n        \"\"\"\n        Plots the model geometry, boundary conditions, and loads\n        \"\"\"\n        return self.geometry.plot(ax=ax, **kwargs)",
  "def solve(\n        self, load_case: Optional[LoadCase] = None, sparse: bool = False\n    ) -> Result:\n        \"\"\"\n        Solves the system of linear equations for deflection and applies the\n        deflections to the nodes and elements of the geometry\n\n        Parameters\n        ----------\n        load_case:\n            Will default to the loads applied to the elements and nodes in the\n            geometry\n        sparse:\n            Whether or not to use sparse matrices to solve\n\n        Returns\n        -------\n        The result of the FE analysis with the applied LoadCase\n        \"\"\"\n        # Find model physical boundary conditions\n        self.find_supports()\n\n        # If no load_case is specified, take the class load_case\n        if load_case is None:\n            load_case = self.load_case\n\n        # Get the nodal force vector\n        self._apply_load_case(load_case)\n        p = self._get_nodal_forces()\n\n        # Check for cyclical symmetry\n        self.cycle_sym = CyclicSymmetry(self.geometry, self.cycle_sym_ids)\n\n        if not sparse:\n            # Get the global stiffness matrix\n            k = self.geometry.k_matrix()\n\n            # Constrain matrix and vector\n            kr, pr = self._apply_boundary_conditions(k, p, method=\"Przemieniecki\")\n\n            # Check boundary conditions and stiffness matrix\n            self._math_checks(kr)\n\n            # Apply cyclic boundary condition (if present)\n\n            kr, pr = self.cycle_sym.apply_cyclic_symmetry(kr, pr)\n\n            ur = np.linalg.solve(kr, pr)\n\n            ur = self.cycle_sym.reorder(ur)\n\n        else:\n            print(\"sparse\")\n            k = self.geometry.k_matrix_sparse()\n\n            kr, pr = self._apply_boundary_conditions_sparse(k, p)\n            ur = spsolve(kr.tocsr(), pr)\n\n        # Check for large displacements\n        self._displacement_check(ur)\n\n        # Apply the displacements to the nodes (and elements)\n        self._apply_displacements(ur)\n\n        # Calculate reaction forces at the nodes\n        reactions = self._get_reaction_forces()\n\n        # Interpolate the result between nodes, and calculate stresses\n        self.geometry.interpolate()\n\n        return Result(deepcopy(self.geometry), load_case, ur, reactions, self.cycle_sym)",
  "def _check_load_type(load_type, sub_type=\"all\"):\n    if load_type not in LOAD_TYPES:\n        raise StructuralError(f\"Unrecognised load type: {load_type}.\")\n\n    if sub_type == \"force\" and load_type not in LOAD_TYPES[:3]:\n        raise StructuralError(\n            f\"Cannot set a force load with a moment load type: {load_type}\"\n        )\n\n    elif sub_type == \"moment\" and load_type not in LOAD_TYPES[3:]:\n        raise StructuralError(\n            f\"Cannot set a moment load with a force load type: {load_type}\"\n        )",
  "def node_load(load: float, load_type: str) -> np.ndarray:\n    \"\"\"\n    Calculates the reaction force vector due to a point load Q, applied at a\n    Node.\n\n    Parameters\n    ----------\n    load:\n        The value of the point load (which may be a force or a moment)\n    load_type:\n        The type of load to apply (from 'Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz'])\n            'Fi': force in the 'i' direction\n            'Mi': moment about the 'i' direction\n\n    Returns\n    -------\n    The fixed-ends reaction force vector (6)\n    \"\"\"\n    reactions = np.zeros(6)\n    _check_load_type(load_type)\n    reactions[LOAD_MAPPING[load_type]] = load\n    return reactions",
  "def point_load(load: float, x: float, length: float, load_type: str) -> np.ndarray:\n    \"\"\"\n    Calculates the reaction force vector due to a point load Q, applied at x\n    along the element of length L, going from node_1 to node_2.\n\n    Parameters\n    ----------\n    load:\n        The value of the point load (which may be a force or a moment)\n    x:\n        The parameterised distance along the element from node_1 to node_2,\n        from 0 to 1.\n    length:\n        The element length\n    load_type:\n        The type of load to apply (from['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz'])\n            'Fi': force in the 'i' direction\n            'Mi': moment about the 'i' direction\n\n    Returns\n    -------\n    The fixed-ends reaction force vector (12)\n    \"\"\"\n    _check_load_type(load_type)\n\n    reactions = np.zeros(12)\n    x *= length\n    a = length - x\n    if load_type == \"Fx\":\n        reactions[0] = -load * a / length\n        reactions[6] = -load * x / length\n    elif load_type == \"Fy\":\n        reactions[1] = load * a**2 * (length + 2 * x) / length**3\n        reactions[5] = load * x * a**2 / length**2\n        reactions[7] = load * x**2 * (length + 2 * a) / length**3\n        reactions[11] = -load * x**2 * a / length**2\n    elif load_type == \"Fz\":\n        reactions[2] = load * a**2 * (length + 2 * x) / length**3\n        reactions[4] = -load * x * a**2 / length**2\n        reactions[8] = load * x**2 * (length + 2 * a) / length**3\n        reactions[10] = load * x**2 * a / length**2\n    elif load_type == \"Mx\":\n        reactions[3] = -load * a / length\n        reactions[9] = -load * x / length\n    elif load_type == \"My\":\n        reactions[2] = 6 * load * x * a / length**3\n        reactions[4] = load * a * (2 * x - a) / length**2\n        reactions[8] = -load * x * a / length**3\n        reactions[10] = load * x * (2 * a - x) / length**2\n    elif load_type == \"Mz\":\n        reactions[1] = -load * x * a / length**3\n        reactions[5] = load * a * (2 * x - a) / length**2\n        reactions[7] = load * x * a / length**3\n        reactions[11] = load * x * (2 * a - x) / length**2\n\n    return reactions",
  "def distributed_load(w: float, length: float, load_type: str) -> np.ndarray:\n    \"\"\"\n    Calculates the reactor force vector due to a distributed load w, applied\n    over the length of the element.\n\n    Parameters\n    ----------\n    w:\n        The value of the distributed load\n    length:\n        Length of the element along which the load is applied\n    load_type:\n        The type of load to apply (from ['Fx', 'Fy', 'Fz']):\n            'Fi': force in the 'i' direction\n    \"\"\"\n    _check_load_type(load_type, sub_type=\"force\")\n\n    reactions = np.zeros(12)\n    if load_type == \"Fx\":\n        reactions[0] = w * length / 2\n        reactions[6] = -w * length / 2\n    elif load_type == \"Fy\":\n        reactions[1] = w * length / 2\n        reactions[5] = w * length**2 / 12\n        reactions[7] = w * length / 2\n        reactions[11] = -w * length**2 / 12\n    elif load_type == \"Fz\":\n        reactions[2] = w * length / 2\n        reactions[4] = -w * length**2 / 12\n        reactions[8] = w * length / 2\n        reactions[10] = w * length**2 / 12\n\n    return reactions",
  "class LoadCase(list):\n    \"\"\"\n    A simple container object for a collection of loads\n    \"\"\"\n\n    def add_node_load(self, node_id: int, load: float, load_type: str):\n        \"\"\"\n        Adds a node load to the LoadCase\n\n        Parameters\n        ----------\n        node_id:\n            The id_number of the Node to apply the load at\n        load:\n            The value of the load\n        load_type:\n            The type and axis of the load from ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']\n        \"\"\"\n        _check_load_type(load_type)\n        self.append(\n            {\"type\": \"Node Load\", \"sub_type\": load_type, \"node_id\": node_id, \"Q\": load}\n        )\n\n    def add_element_load(self, element_id: int, load: float, x: float, load_type: str):\n        \"\"\"\n        Adds an element point load to the LoadCase\n\n        Parameters\n        ----------\n        element_id:\n            The id_number of the Element to apply the load at\n        load:\n            The value of the load\n        x:\n            The parameterised and normalised distance along the element x-axis\n        load_type: str from ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']\n            The type and axis of the load\n        \"\"\"\n        _check_load_type(load_type)\n        x_clip = np.clip(x, 0, 1)\n        if x_clip != x:\n            bluemira_warn(\"x should be between 0 and 1.\")\n        self.append(\n            {\n                \"type\": \"Element Load\",\n                \"sub_type\": load_type,\n                \"element_id\": element_id,\n                \"Q\": load,\n                \"x\": x,\n            }\n        )\n\n    def add_distributed_load(self, element_id: int, w: float, load_type: str):\n        \"\"\"\n        Adds a distributed load to the LoadCase\n\n        Parameters\n        ----------\n        element_id:\n            The id_number of the Element to apply the load at\n        w:\n            The value of the distributed load\n        load_type:\n            The type and axis of the load (from ['Fx', 'Fy', 'Fz'])\n        \"\"\"\n        _check_load_type(load_type)\n        self.append(\n            {\n                \"type\": \"Distributed Load\",\n                \"sub_type\": load_type,\n                \"element_id\": element_id,\n                \"w\": w,\n            }\n        )",
  "def add_node_load(self, node_id: int, load: float, load_type: str):\n        \"\"\"\n        Adds a node load to the LoadCase\n\n        Parameters\n        ----------\n        node_id:\n            The id_number of the Node to apply the load at\n        load:\n            The value of the load\n        load_type:\n            The type and axis of the load from ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']\n        \"\"\"\n        _check_load_type(load_type)\n        self.append(\n            {\"type\": \"Node Load\", \"sub_type\": load_type, \"node_id\": node_id, \"Q\": load}\n        )",
  "def add_element_load(self, element_id: int, load: float, x: float, load_type: str):\n        \"\"\"\n        Adds an element point load to the LoadCase\n\n        Parameters\n        ----------\n        element_id:\n            The id_number of the Element to apply the load at\n        load:\n            The value of the load\n        x:\n            The parameterised and normalised distance along the element x-axis\n        load_type: str from ['Fx', 'Fy', 'Fz', 'Mx', 'My', 'Mz']\n            The type and axis of the load\n        \"\"\"\n        _check_load_type(load_type)\n        x_clip = np.clip(x, 0, 1)\n        if x_clip != x:\n            bluemira_warn(\"x should be between 0 and 1.\")\n        self.append(\n            {\n                \"type\": \"Element Load\",\n                \"sub_type\": load_type,\n                \"element_id\": element_id,\n                \"Q\": load,\n                \"x\": x,\n            }\n        )",
  "def add_distributed_load(self, element_id: int, w: float, load_type: str):\n        \"\"\"\n        Adds a distributed load to the LoadCase\n\n        Parameters\n        ----------\n        element_id:\n            The id_number of the Element to apply the load at\n        w:\n            The value of the distributed load\n        load_type:\n            The type and axis of the load (from ['Fx', 'Fy', 'Fz'])\n        \"\"\"\n        _check_load_type(load_type)\n        self.append(\n            {\n                \"type\": \"Distributed Load\",\n                \"sub_type\": load_type,\n                \"element_id\": element_id,\n                \"w\": w,\n            }\n        )",
  "class Result:\n    \"\"\"\n    Container class for storing results\n    \"\"\"\n\n    __slots__ = [\n        \"geometry\",\n        \"load_case\",\n        \"deflections\",\n        \"reactions\",\n        \"deflections_xyz\",\n        \"_cycle_sym\",\n        \"_stresses\",\n        \"_max_stresses\",\n        \"_safety_factors\",\n        \"_max_deflections\",\n    ]\n\n    def __init__(\n        self,\n        geometry: Geometry,\n        load_case: LoadCase,\n        deflections: np.ndarray,\n        reactions: np.ndarray,\n        cyclic_symmetry: Optional[CyclicSymmetry],\n    ):\n        self.geometry = geometry\n        self.load_case = load_case\n        self.deflections = deflections\n        self.deflections_xyz = deflections.reshape(self.geometry.n_nodes, 6)\n        self.reactions = reactions\n        self._cycle_sym = cyclic_symmetry\n\n        self._stresses = None\n        self._max_stresses = None\n        self._safety_factors = None\n        self._max_deflections = None\n        self._get_values()\n\n    def _get_values(self):\n        \"\"\"\n        Get the maximum values of stress, deflection, and safety factors over\n        all the Elements in the Geometry.\n        \"\"\"\n        s = []\n        max_stresses = np.zeros(self.geometry.n_elements)\n        safety_factors = np.zeros(self.geometry.n_elements)\n        max_deflections = np.zeros(self.geometry.n_elements)\n        for i, element in enumerate(self.geometry.elements):\n            s.append(element.stresses)\n            safety_factors[i] = element.safety_factor\n            max_stresses[i] = element.max_stress\n            d_n1 = element.node_1.displacements[:3]\n            d_n2 = element.node_2.displacements[3:]\n\n            d1 = np.sqrt(np.sum(d_n1**2))\n            d2 = np.sqrt(np.sum(d_n2**2))\n\n            max_deflections[i] = max(d1, d2)\n        self._safety_factors = safety_factors\n        self._max_stresses = max_stresses\n        self._stresses = s\n        self._max_deflections = max_deflections\n\n    def make_deformed_geometry(self, scale: float = 30.0) -> DeformedGeometry:\n        \"\"\"\n        Make deformed geometry of the result\n\n        Parameters\n        ----------\n        scale:\n            The scale for the deformations\n\n        Returns\n        -------\n        The deformed geometry of the Result at the specified scale\n        \"\"\"\n        return DeformedGeometry(self.geometry, scale=scale)\n\n    def _make_cyclic_geometry(self, geometry: Optional[Geometry] = None):\n        if geometry is None:\n            geometry = self.geometry\n\n        n = self._cycle_sym.n\n        theta = self._cycle_sym.theta\n        axis = self._cycle_sym.axis\n\n        return cyclic_pattern(geometry, axis, theta, n, include_first=False)\n\n    def plot(\n        self,\n        deformation_scale: float = 10.0,\n        ax: Optional[Axes] = None,\n        stress: bool = False,\n        deflection: bool = False,\n        pattern: bool = False,\n        **kwargs,\n    ):\n        \"\"\"\n        Plot the Result of the finite element analysis\n\n        Parameters\n        ----------\n        deformation_scale:\n            The scale of the deformation to be shown in the plot\n        ax:\n            The Axes onto which to plot (should be 3-D).\n        stress:\n            Whether or not to plot stresses [color map]\n        deflection:\n            Whether or not to plot deflection [color map]\n        pattern:\n            Whether or not to pattern the model (if symmetry was used)\n        \"\"\"\n        if ax is None:\n            ax = Plot3D()\n\n        dg = self.make_deformed_geometry(deformation_scale)\n\n        if stress:\n            dg.plot(ax, stress=self._max_stresses, **kwargs)\n        elif deflection:\n            dg.plot(ax, stress=self._max_deflections, **kwargs)\n\n        else:\n            self.geometry.plot(ax)\n            dg.plot(ax)\n\n        if pattern:\n            pdg = self._make_cyclic_geometry(dg)\n            pdg.plot(ax, **kwargs)",
  "def __init__(\n        self,\n        geometry: Geometry,\n        load_case: LoadCase,\n        deflections: np.ndarray,\n        reactions: np.ndarray,\n        cyclic_symmetry: Optional[CyclicSymmetry],\n    ):\n        self.geometry = geometry\n        self.load_case = load_case\n        self.deflections = deflections\n        self.deflections_xyz = deflections.reshape(self.geometry.n_nodes, 6)\n        self.reactions = reactions\n        self._cycle_sym = cyclic_symmetry\n\n        self._stresses = None\n        self._max_stresses = None\n        self._safety_factors = None\n        self._max_deflections = None\n        self._get_values()",
  "def _get_values(self):\n        \"\"\"\n        Get the maximum values of stress, deflection, and safety factors over\n        all the Elements in the Geometry.\n        \"\"\"\n        s = []\n        max_stresses = np.zeros(self.geometry.n_elements)\n        safety_factors = np.zeros(self.geometry.n_elements)\n        max_deflections = np.zeros(self.geometry.n_elements)\n        for i, element in enumerate(self.geometry.elements):\n            s.append(element.stresses)\n            safety_factors[i] = element.safety_factor\n            max_stresses[i] = element.max_stress\n            d_n1 = element.node_1.displacements[:3]\n            d_n2 = element.node_2.displacements[3:]\n\n            d1 = np.sqrt(np.sum(d_n1**2))\n            d2 = np.sqrt(np.sum(d_n2**2))\n\n            max_deflections[i] = max(d1, d2)\n        self._safety_factors = safety_factors\n        self._max_stresses = max_stresses\n        self._stresses = s\n        self._max_deflections = max_deflections",
  "def make_deformed_geometry(self, scale: float = 30.0) -> DeformedGeometry:\n        \"\"\"\n        Make deformed geometry of the result\n\n        Parameters\n        ----------\n        scale:\n            The scale for the deformations\n\n        Returns\n        -------\n        The deformed geometry of the Result at the specified scale\n        \"\"\"\n        return DeformedGeometry(self.geometry, scale=scale)",
  "def _make_cyclic_geometry(self, geometry: Optional[Geometry] = None):\n        if geometry is None:\n            geometry = self.geometry\n\n        n = self._cycle_sym.n\n        theta = self._cycle_sym.theta\n        axis = self._cycle_sym.axis\n\n        return cyclic_pattern(geometry, axis, theta, n, include_first=False)",
  "def plot(\n        self,\n        deformation_scale: float = 10.0,\n        ax: Optional[Axes] = None,\n        stress: bool = False,\n        deflection: bool = False,\n        pattern: bool = False,\n        **kwargs,\n    ):\n        \"\"\"\n        Plot the Result of the finite element analysis\n\n        Parameters\n        ----------\n        deformation_scale:\n            The scale of the deformation to be shown in the plot\n        ax:\n            The Axes onto which to plot (should be 3-D).\n        stress:\n            Whether or not to plot stresses [color map]\n        deflection:\n            Whether or not to plot deflection [color map]\n        pattern:\n            Whether or not to pattern the model (if symmetry was used)\n        \"\"\"\n        if ax is None:\n            ax = Plot3D()\n\n        dg = self.make_deformed_geometry(deformation_scale)\n\n        if stress:\n            dg.plot(ax, stress=self._max_stresses, **kwargs)\n        elif deflection:\n            dg.plot(ax, stress=self._max_deflections, **kwargs)\n\n        else:\n            self.geometry.plot(ax)\n            dg.plot(ax)\n\n        if pattern:\n            pdg = self._make_cyclic_geometry(dg)\n            pdg.plot(ax, **kwargs)",
  "class StructuralMaterial:\n    \"\"\"\n    Dataclass for a structural representation of a material.\n\n    Parameters\n    ----------\n    E:\n        Youngs modulus [Pa]\n    nu:\n        Poisson ratio\n    rho:\n        Density [kg/m^3]\n    sigma_y:\n        Yield stress [Pa]\n    description:\n        A description of the material\n    \"\"\"\n\n    E: float\n    nu: float\n    rho: float\n    alpha: float\n    sigma_y: float\n    G: float = field(init=False, repr=True)\n    description: Optional[str] = field(default=\"\", repr=True)\n\n    def __post_init__(self):\n        \"\"\"\n        Shear modulus for isotropic materials\n        \"\"\"\n        self.G = self.E / (0.5 + 0.5 * self.nu)",
  "def make_structural_material(\n    material: MaterialType, temperature: float\n) -> StructuralMaterial:\n    \"\"\"\n    Make a structural representation of a material.\n\n    Parameters\n    ----------\n    material:\n        Material type to create a structural representation for\n    temperature:\n        Temperature at which to make a structural representation of a material [K]\n\n    Returns\n    -------\n    Structural representation of a material\n    \"\"\"\n    description = f\"{material.name} at {temperature:.2f} K\"\n    return StructuralMaterial(\n        material.E(temperature),\n        material.mu(temperature),\n        material.rho(temperature),\n        material.CTE(temperature),\n        material.Sy(temperature),\n        description,\n    )",
  "class Material(dict):\n    \"\"\"\n    A simple material property dictionary (keep small for speed and memory)\n    \"\"\"\n\n    __slots__ = []\n\n    def __init__(self, e_modulus, nu, rho, alpha, sigma_y):\n        self[\"E\"] = e_modulus\n        self[\"nu\"] = nu\n        self[\"alpha\"] = alpha\n        self[\"rho\"] = rho\n        self[\"G\"] = e_modulus / (1 + nu) / 2\n        self[\"sigma_y\"] = sigma_y",
  "def __post_init__(self):\n        \"\"\"\n        Shear modulus for isotropic materials\n        \"\"\"\n        self.G = self.E / (0.5 + 0.5 * self.nu)",
  "def __init__(self, e_modulus, nu, rho, alpha, sigma_y):\n        self[\"E\"] = e_modulus\n        self[\"nu\"] = nu\n        self[\"alpha\"] = alpha\n        self[\"rho\"] = rho\n        self[\"G\"] = e_modulus / (1 + nu) / 2\n        self[\"sigma_y\"] = sigma_y",
  "def _calculate_properties(y, z):\n    \"\"\"\n    Calculate cross-sectional properties for arbitrary polygons.\n    \"\"\"\n    q_zz, q_yy, i_zz, i_yy, i_zy = 0, 0, 0, 0, 0\n\n    for i in range(len(y) - 1):  # zip is slow in numba\n        y1, y2 = y[i], y[i + 1]\n        z1, z2 = z[i], z[i + 1]\n        d_area = y1 * z2 - y2 * z1\n        q_zz += (y2 + y1) * d_area\n        q_yy += (z2 + z1) * d_area\n        i_zz += (y1**2 + y1 * y2 + y2**2) * d_area\n        i_yy += (z1**2 + z1 * z2 + z2**2) * d_area\n        i_zy += (z1 * y2 + 2 * z1 * y1 + 2 * z2 * y2 + z2 * y1) * d_area\n    return q_zz / 6, q_yy / 6, i_zz / 12, i_yy / 12, i_zy / 24",
  "def _transform_properties(izz, iyy, izy, alpha):\n    \"\"\"\n    Transform second moments of area for a rotation about the centroid.\n\n    \\t:math:`I_{uu}=(I_{xx}+I_{yy})/2+[(I_{xx}-I_{yy})/2]cos(2\\\\alpha)-I_{xy}sin(2\\\\alpha)`\n\n    \\t:math:`I_{vv}=(I_{xx}+I_{yy})/2-[(I_{xx}-I_{yy})/2]cos(2\\\\alpha)+I_{xy}sin(2\\\\alpha)`\n\n    \\t:math:`I_{uv}=[(I_{xx}-I_{yy})/2]sin(2\\\\alpha)+I_{xy}cos(2\\\\alpha)`\n    \"\"\"\n    # We need to clip the cos and sin terms for near-zero values, because they\n    # are about to be multiplied with E (often very big!)\n    cos2alpha = np.cos(2 * alpha)\n    sin2alpha = np.sin(2 * alpha)\n\n    if np.abs(cos2alpha) < NEAR_ZERO:\n        cos2alpha = 0.0\n    if np.abs(sin2alpha) < NEAR_ZERO:\n        sin2alpha = 0.0\n\n    i_uu = 0.5 * (izz + iyy) + 0.5 * (izz - iyy) * cos2alpha - izy * sin2alpha\n    i_vv = 0.5 * (izz + iyy) - 0.5 * (izz - iyy) * np.cos(2 * alpha) + izy * sin2alpha\n    i_uv = 0.5 * (izz - iyy) * sin2alpha + izy * cos2alpha\n    return i_uu, i_vv, i_uv",
  "class CrossSection:\n    \"\"\"\n    Base class for a structural cross-section of a 1-D beam.\n    \"\"\"\n\n    __slots__ = (\n        \"area\",\n        \"i_yy\",\n        \"i_zz\",\n        \"i_zy\",\n        \"ei_yy\",\n        \"ei_zz\",\n        \"ei_zy\",\n        \"j\",\n        \"area_sy\",\n        \"area_sz\",\n        \"ry\",\n        \"rz\",\n        \"qyy\",\n        \"qzz\",\n        \"centroid_geom\",\n        \"geometry\",\n        \"y\",\n        \"z\",\n    )\n\n    def __init__(self):\n        pass\n\n    def make_geometry(self, *args, **kwargs):\n        \"\"\"\n        Make a BluemiraFace object for the CrossSection.\n        \"\"\"\n        raise NotImplementedError\n\n    def plot(self, ax=None):\n        \"\"\"\n        Plot the CrossSection\n        \"\"\"\n        self.geometry.plot(ax=ax, points=True)\n\n    def rotate(self, angle: float):\n        \"\"\"\n        Rotate the CrossSection about its centroid.\n\n        Parameters\n        ----------\n        angle:\n            The angle to rotate the CrossSection by [degrees]\n        \"\"\"\n        alpha = np.deg2rad(angle)\n\n        try:  # A CrossSection will either have Inn or EInn properties\n            i_uu, i_vv, i_uv = _transform_properties(\n                self.i_zz, self.i_yy, self.i_zy, alpha\n            )\n            self.i_zz = i_uu\n            self.i_yy = i_vv\n            self.i_zy = i_uv\n        except AttributeError:\n            pass\n\n        try:\n            ei_uu, ei_vv, ei_uv = _transform_properties(\n                self.ei_zz, self.ei_yy, self.ei_zy, alpha\n            )\n            self.ei_zz = ei_uu\n            self.ei_yy = ei_vv\n            self.ei_zy = ei_uv\n        except AttributeError:\n            pass\n\n        if isinstance(self.geometry, list):\n            for geometry in self.geometry:\n                geometry.rotate(base=self.centroid, direction=(1, 0, 0), degree=angle)\n        else:\n            self.geometry.rotate(base=self.centroid, direction=(1, 0, 0), degree=angle)\n\n    def translate(self, vector: np.ndarray):\n        \"\"\"\n        Translate the CrossSection. Should not affect its properties. Note that\n        CrossSections are defined in the y-z plane.\n\n        Parameters\n        ----------\n        vector:\n            The translation vector.\n        \"\"\"\n        self.geometry.translate(vector)\n\n    @property\n    def centroid(self):\n        \"\"\"\n        Centroid of the cross-section geometry\n        \"\"\"\n        return self.geometry.center_of_mass",
  "class RectangularBeam(CrossSection):\n    \"\"\"\n    Rectangular beam cross-section.\n\n    Parameters\n    ----------\n    width:\n        The width of the beam\n    height:\n        The height of the beam\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, width: float, height: float):\n        super().__init__()\n        self.area = width * height\n        self.i_zz = width**3 * height / 12\n        self.i_yy = width * height**3 / 12\n        self.i_zy = 0.0\n        self.j = self.calc_torsion(width, height)\n        self.ry = np.sqrt(self.i_yy / self.area)\n        self.rz = np.sqrt(self.i_zz / self.area)\n        self.qyy = 0  # Centred about (0, 0)\n        self.qzz = 0  # Centred about (0, 0)\n        self.make_geometry(width, height)\n\n    @staticmethod\n    def calc_torsion(width: float, height: float) -> float:\n        \"\"\"\n        Estimate the torsional constant of the rectangular beam.\n\n        Notes\n        -----\n        Young, W and Budynas, R: Roark's Formulas for Stress and Strain\n\n        \\t:math:`J\\\\approx ab^3(\\\\dfrac{16}{3}-3.36\\\\dfrac{b}{a}(1-\\\\dfrac{b^4}{12a^4}))`\n        \"\"\"\n        if width >= height:\n            a = width / 2\n            b = height / 2\n        else:\n            a = height / 2\n            b = width / 2\n\n        return a * b**3 * (16 / 3 - 3.36 * (b / a) * (1 - b**4 / (12 * a**4)))\n\n    def make_geometry(self, width: float, height: float):\n        \"\"\"\n        Make a BluemiraFace for the RectangularBeam cross-section.\n        \"\"\"\n        w = 0.5 * width\n        h = 0.5 * height\n        self.y = np.array([-w, w, w, -w, -w])\n        self.z = np.array([-h, -h, h, h, -h])\n        polygon = BluemiraFace(\n            make_polygon(\n                {\n                    \"x\": 0,\n                    \"y\": self.y,\n                    \"z\": self.z,\n                }\n            )\n        )\n        self.geometry = polygon",
  "class CircularBeam(CrossSection):\n    \"\"\"\n    Circular beam cross-section\n\n    Parameters\n    ----------\n    radius:\n        The radius of the circular cross-section\n    n_discr:\n        Number of points to discretise to when plotting\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, radius: float, n_discr: int = 30):\n        super().__init__()\n        self.area = np.pi * radius**2\n        self.i_zz = np.pi * radius**4 / 4\n        self.i_yy = np.pi * radius**4 / 4\n        self.i_zy = 0.0\n        self.j = np.pi * radius**4 / 2\n        self.ry = radius / 2\n        self.rz = radius / 2\n        self.qyy = 0  # Centred about (0, 0)\n        self.qzz = 0  # Centred about (0, 0)\n        circle = make_circle(radius, center=(0, 0, 0), axis=(1, 0, 0))\n        self.geometry = BluemiraFace(circle)\n        self.y, self.z = circle.discretize(ndiscr=n_discr).yz",
  "class CircularHollowBeam(CrossSection):\n    \"\"\"\n    Circular hollow beam cross-section\n\n    Parameters\n    ----------\n    r_inner:\n        The inner radius of the hollow circular cross-section\n    r_outer:\n        The outer radius of the hollow circular cross-section\n    n_discr:\n        Number of points to discretise to when plotting\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, r_inner: float, r_outer: float, n_discr: int = 30):\n        super().__init__()\n        self.area = np.pi * (r_outer**2 - r_inner**2)\n        self.i_zz = np.pi / 4 * (r_outer**4 - r_inner**4)\n        self.i_yy = np.pi / 4 * (r_outer**4 - r_inner**4)\n        self.i_zy = 0.0\n        self.j = np.pi / 2 * (r_outer**4 - r_inner**4)\n        self.ry = np.sqrt((r_outer**2 + r_inner**2) / 4)\n        self.rz = np.sqrt((r_outer**2 + r_inner**2) / 4)\n        self.qyy = 0  # Centred about (0, 0)\n        self.qzz = 0  # Centred about (0, 0)\n\n        inner = make_circle(r_inner, center=(0, 0, 0), axis=(1, 0, 0))\n        outer = make_circle(r_outer, center=(0, 0, 0), axis=(1, 0, 0))\n        self.geometry = BluemiraFace([outer, inner])\n        self.y, self.z = np.concatenate(\n            [outer.discretize(ndiscr=n_discr).yz, inner.discretize(ndiscr=n_discr).yz],\n            axis=1,\n        )",
  "class IBeam(CrossSection):\n    \"\"\"\n    Generic, symmetric I-beam cross-section\n\n    Parameters\n    ----------\n    base:\n        I-beam base width\n    depth:\n        I-beam depth\n    web:\n        I-beam web thickness\n    flange:\n        I-beam flange thickness\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, base: float, depth: float, flange: float, web: float):\n        super().__init__()\n        self.check_dimensions(base, depth, flange, web)\n        h = depth - 2 * flange\n        b, d, t, s = base, depth, web, flange\n        self.area = b * d - h * (b - t)\n        self.i_yy = (b * d**3 - h**3 * (b - t)) / 12\n        self.i_zz = (2 * s * b**3 + h * t**3) / 12\n        self.i_zy = 0.0\n        self.j = (2 * b * t**3 + (d - s) * t**3) / 3\n        self.ry = np.sqrt(self.i_yy / self.area)\n        self.rz = np.sqrt(self.i_zz / self.area)\n        self.qyy = 0  # Centred about (0, 0)\n        self.qzz = 0  # Centred about (0, 0)\n        self.make_geometry(base, depth, flange, web)\n\n    @staticmethod\n    def check_dimensions(base: float, depth: float, flange: float, web: float):\n        \"\"\"\n        Edge case eradication\n        \"\"\"\n        if (\n            (depth - 2 * flange <= 0)\n            or (base - web <= 0)\n            or (base <= 0)\n            or (depth <= 0)\n            or (flange <= 0)\n            or (web <= 0)\n        ):\n            raise StructuralError(\"I-beam dimensions don't make sense.\")\n\n    def make_geometry(self, base: float, depth: float, flange: float, web: float):\n        \"\"\"\n        Make a BluemiraFace for the IBeam cross-section.\n        \"\"\"\n        b, d, f, w = 0.5 * base, 0.5 * depth, flange, 0.5 * web\n        self.y = np.array([-b, b, b, w, w, b, b, -b, -b, -w, -w, -b, -b])\n        self.z = np.array(\n            [\n                -d,\n                -d,\n                -d + f,\n                -d + f,\n                d - f,\n                d - f,\n                d,\n                d,\n                d - f,\n                d - f,\n                -d + f,\n                -d + f,\n                -d,\n            ]\n        )\n        self.geometry = BluemiraFace(make_polygon({\"x\": 0, \"y\": self.y, \"z\": self.z}))",
  "class AnalyticalCrossSection(CrossSection):\n    \"\"\"\n    Analytical formulation for a polygonal cross-section. Torsional properties\n    less accurate. Faster as based on analytical calculation of cross-sectional\n    properties, as opposed to FE.\n\n    Parameters\n    ----------\n    geometry:\n        The geometry for the polygonal cross-section\n    n_discr:\n        Number of points to discretise to when plotting\n    j_opt_var:\n        Torsional constant estimation parameter from optimisation\n\n    Notes\n    -----\n    All cross-section properties calculated exactly (within reason), except for\n    the torsional constant J, which is approximated using St Venant's approach.\n    The j_opt_var for fitting the J value must be determined based on suitable\n    finite element analyses.\n\n    If the geometry has any holes in it, they will be treated as holes.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(\n        self, geometry: BluemiraFace, n_discr: int = 100, j_opt_var: float = 14.123\n    ):\n        super().__init__()\n        self.geometry = deepcopy(geometry)\n        self.area = area = self.geometry.area\n        self.y, self.z = (\n            self.geometry.boundary[0].discretize(ndiscr=n_discr, byedges=True).yz\n        )\n\n        q_zz_o, q_yy_o, i_zz_o, i_yy_o, i_zy_o = _calculate_properties(self.y, self.z)\n\n        if len(self.geometry.boundary) > 1:\n            # Cut out any holes in the face\n            for wire in self.geometry.boundary[1:]:\n                y, z = wire.discretize(ndiscr=n_discr, byedges=True).yz\n                q_zz_i, q_yy_i, i_zz_i, i_yy_i, i_zy_i = _calculate_properties(y, z)\n\n                q_zz_o -= q_zz_i\n                q_yy_o -= q_yy_i\n                i_zz_o -= i_zz_i\n                i_yy_o -= i_yy_i\n                i_zy_o -= i_zy_i\n                self.y = np.append(self.y, y)\n                self.z = np.append(self.z, z)\n\n        cy = q_zz_o / area\n        cz = q_yy_o / area\n        self.centroid_geom = (cy, cz)\n\n        self.i_yy = i_yy_o - area * cz**2\n        self.i_zz = i_zz_o - area * cy**2\n        self.i_zy = i_zy_o - area * cz * cy\n        self.qyy = q_yy_o\n        self.qzz = q_zz_o\n        self.ry = np.sqrt(self.i_yy / area)\n        self.rz = np.sqrt(self.i_zz / area)\n\n        # OK so there is no cute general polygon form for J... need FE!\n        # St Venant approach\n        self.j = self.area**4 / (j_opt_var * (i_yy_o + i_zz_o))",
  "class AnalyticalCompositeCrossSection(CrossSection):\n    \"\"\"\n    A cross-section object for composite structural beam.\n\n    When making a composite cross-section, we need to add material properties\n    in order to effectively weight the cross-sectional properties.\n\n    Cross-sectional properties are calculated analytical relations, and are\n    therefore much faster than an FE approach. For simple cross-sections, the\n    properties are all identical except for J, where a fitting on similar\n    shapes must be carried out, following St. Venant's method.\n\n    This somewhat modifies the API when getting properties...\n\n    Parameters\n    ----------\n    geometry:\n        The ordered list of geometries making up the cross-section\n    materials:\n        The ordered list of Materials to use for the geometry\n    \"\"\"\n\n    __slots__ = (\"ea\", \"nu\", \"gj\", \"rho\")\n\n    def __init__(self, geometry: BluemiraFace, materials: List[StructuralMaterial]):\n        super().__init__()\n        self.geometry = deepcopy(geometry)\n\n        n = len(geometry.boundary)\n\n        if len(materials) != n:\n            raise StructuralError(f\"Need {n} materials for this geometry.\")\n\n        outer = AnalyticalCrossSection(geometry.boundary)\n        inners = []\n        for wire in geometry.boundary[1:]:\n            face = BluemiraFace(wire)\n            inners.append(AnalyticalCrossSection(face))\n\n        cross_sections = [outer]\n        cross_sections.extend(inners)\n\n        e_values = np.array([mat[\"E\"] for mat in materials])\n        g_values = np.array([mat[\"G\"] for mat in materials])\n        rho_values = np.array([mat[\"rho\"] for mat in materials])\n        areas = np.array([xs.area for xs in cross_sections])\n        i_yy_values = np.array([xs.i_yy for xs in cross_sections])\n        i_zz_values = np.array([xs.i_zz for xs in cross_sections])\n        i_zy_values = np.array([xs.i_zy for xs in cross_sections])\n\n        self.area = np.sum(areas)\n        self.ea = np.dot(e_values, areas)\n        self.ei_yy = np.dot(e_values, i_yy_values)\n        self.ei_zz = np.dot(e_values, i_zz_values)\n        self.ei_zy = np.dot(e_values, i_zy_values)\n        ga = np.dot(g_values, areas)\n        rhoa = np.dot(rho_values, areas)\n\n        self.nu = self.ea / (2 * ga) - 1\n        self.ry = np.sqrt(self.ei_yy / self.ea)\n        self.rz = np.sqrt(self.ei_zz / self.ea)\n\n        self.gj = ga / self.area * n * sum(xs.j for xs in cross_sections)\n        self.rho = rhoa / self.area",
  "def __init__(self):\n        pass",
  "def make_geometry(self, *args, **kwargs):\n        \"\"\"\n        Make a BluemiraFace object for the CrossSection.\n        \"\"\"\n        raise NotImplementedError",
  "def plot(self, ax=None):\n        \"\"\"\n        Plot the CrossSection\n        \"\"\"\n        self.geometry.plot(ax=ax, points=True)",
  "def rotate(self, angle: float):\n        \"\"\"\n        Rotate the CrossSection about its centroid.\n\n        Parameters\n        ----------\n        angle:\n            The angle to rotate the CrossSection by [degrees]\n        \"\"\"\n        alpha = np.deg2rad(angle)\n\n        try:  # A CrossSection will either have Inn or EInn properties\n            i_uu, i_vv, i_uv = _transform_properties(\n                self.i_zz, self.i_yy, self.i_zy, alpha\n            )\n            self.i_zz = i_uu\n            self.i_yy = i_vv\n            self.i_zy = i_uv\n        except AttributeError:\n            pass\n\n        try:\n            ei_uu, ei_vv, ei_uv = _transform_properties(\n                self.ei_zz, self.ei_yy, self.ei_zy, alpha\n            )\n            self.ei_zz = ei_uu\n            self.ei_yy = ei_vv\n            self.ei_zy = ei_uv\n        except AttributeError:\n            pass\n\n        if isinstance(self.geometry, list):\n            for geometry in self.geometry:\n                geometry.rotate(base=self.centroid, direction=(1, 0, 0), degree=angle)\n        else:\n            self.geometry.rotate(base=self.centroid, direction=(1, 0, 0), degree=angle)",
  "def translate(self, vector: np.ndarray):\n        \"\"\"\n        Translate the CrossSection. Should not affect its properties. Note that\n        CrossSections are defined in the y-z plane.\n\n        Parameters\n        ----------\n        vector:\n            The translation vector.\n        \"\"\"\n        self.geometry.translate(vector)",
  "def centroid(self):\n        \"\"\"\n        Centroid of the cross-section geometry\n        \"\"\"\n        return self.geometry.center_of_mass",
  "def __init__(self, width: float, height: float):\n        super().__init__()\n        self.area = width * height\n        self.i_zz = width**3 * height / 12\n        self.i_yy = width * height**3 / 12\n        self.i_zy = 0.0\n        self.j = self.calc_torsion(width, height)\n        self.ry = np.sqrt(self.i_yy / self.area)\n        self.rz = np.sqrt(self.i_zz / self.area)\n        self.qyy = 0  # Centred about (0, 0)\n        self.qzz = 0  # Centred about (0, 0)\n        self.make_geometry(width, height)",
  "def calc_torsion(width: float, height: float) -> float:\n        \"\"\"\n        Estimate the torsional constant of the rectangular beam.\n\n        Notes\n        -----\n        Young, W and Budynas, R: Roark's Formulas for Stress and Strain\n\n        \\t:math:`J\\\\approx ab^3(\\\\dfrac{16}{3}-3.36\\\\dfrac{b}{a}(1-\\\\dfrac{b^4}{12a^4}))`\n        \"\"\"\n        if width >= height:\n            a = width / 2\n            b = height / 2\n        else:\n            a = height / 2\n            b = width / 2\n\n        return a * b**3 * (16 / 3 - 3.36 * (b / a) * (1 - b**4 / (12 * a**4)))",
  "def make_geometry(self, width: float, height: float):\n        \"\"\"\n        Make a BluemiraFace for the RectangularBeam cross-section.\n        \"\"\"\n        w = 0.5 * width\n        h = 0.5 * height\n        self.y = np.array([-w, w, w, -w, -w])\n        self.z = np.array([-h, -h, h, h, -h])\n        polygon = BluemiraFace(\n            make_polygon(\n                {\n                    \"x\": 0,\n                    \"y\": self.y,\n                    \"z\": self.z,\n                }\n            )\n        )\n        self.geometry = polygon",
  "def __init__(self, radius: float, n_discr: int = 30):\n        super().__init__()\n        self.area = np.pi * radius**2\n        self.i_zz = np.pi * radius**4 / 4\n        self.i_yy = np.pi * radius**4 / 4\n        self.i_zy = 0.0\n        self.j = np.pi * radius**4 / 2\n        self.ry = radius / 2\n        self.rz = radius / 2\n        self.qyy = 0  # Centred about (0, 0)\n        self.qzz = 0  # Centred about (0, 0)\n        circle = make_circle(radius, center=(0, 0, 0), axis=(1, 0, 0))\n        self.geometry = BluemiraFace(circle)\n        self.y, self.z = circle.discretize(ndiscr=n_discr).yz",
  "def __init__(self, r_inner: float, r_outer: float, n_discr: int = 30):\n        super().__init__()\n        self.area = np.pi * (r_outer**2 - r_inner**2)\n        self.i_zz = np.pi / 4 * (r_outer**4 - r_inner**4)\n        self.i_yy = np.pi / 4 * (r_outer**4 - r_inner**4)\n        self.i_zy = 0.0\n        self.j = np.pi / 2 * (r_outer**4 - r_inner**4)\n        self.ry = np.sqrt((r_outer**2 + r_inner**2) / 4)\n        self.rz = np.sqrt((r_outer**2 + r_inner**2) / 4)\n        self.qyy = 0  # Centred about (0, 0)\n        self.qzz = 0  # Centred about (0, 0)\n\n        inner = make_circle(r_inner, center=(0, 0, 0), axis=(1, 0, 0))\n        outer = make_circle(r_outer, center=(0, 0, 0), axis=(1, 0, 0))\n        self.geometry = BluemiraFace([outer, inner])\n        self.y, self.z = np.concatenate(\n            [outer.discretize(ndiscr=n_discr).yz, inner.discretize(ndiscr=n_discr).yz],\n            axis=1,\n        )",
  "def __init__(self, base: float, depth: float, flange: float, web: float):\n        super().__init__()\n        self.check_dimensions(base, depth, flange, web)\n        h = depth - 2 * flange\n        b, d, t, s = base, depth, web, flange\n        self.area = b * d - h * (b - t)\n        self.i_yy = (b * d**3 - h**3 * (b - t)) / 12\n        self.i_zz = (2 * s * b**3 + h * t**3) / 12\n        self.i_zy = 0.0\n        self.j = (2 * b * t**3 + (d - s) * t**3) / 3\n        self.ry = np.sqrt(self.i_yy / self.area)\n        self.rz = np.sqrt(self.i_zz / self.area)\n        self.qyy = 0  # Centred about (0, 0)\n        self.qzz = 0  # Centred about (0, 0)\n        self.make_geometry(base, depth, flange, web)",
  "def check_dimensions(base: float, depth: float, flange: float, web: float):\n        \"\"\"\n        Edge case eradication\n        \"\"\"\n        if (\n            (depth - 2 * flange <= 0)\n            or (base - web <= 0)\n            or (base <= 0)\n            or (depth <= 0)\n            or (flange <= 0)\n            or (web <= 0)\n        ):\n            raise StructuralError(\"I-beam dimensions don't make sense.\")",
  "def make_geometry(self, base: float, depth: float, flange: float, web: float):\n        \"\"\"\n        Make a BluemiraFace for the IBeam cross-section.\n        \"\"\"\n        b, d, f, w = 0.5 * base, 0.5 * depth, flange, 0.5 * web\n        self.y = np.array([-b, b, b, w, w, b, b, -b, -b, -w, -w, -b, -b])\n        self.z = np.array(\n            [\n                -d,\n                -d,\n                -d + f,\n                -d + f,\n                d - f,\n                d - f,\n                d,\n                d,\n                d - f,\n                d - f,\n                -d + f,\n                -d + f,\n                -d,\n            ]\n        )\n        self.geometry = BluemiraFace(make_polygon({\"x\": 0, \"y\": self.y, \"z\": self.z}))",
  "def __init__(\n        self, geometry: BluemiraFace, n_discr: int = 100, j_opt_var: float = 14.123\n    ):\n        super().__init__()\n        self.geometry = deepcopy(geometry)\n        self.area = area = self.geometry.area\n        self.y, self.z = (\n            self.geometry.boundary[0].discretize(ndiscr=n_discr, byedges=True).yz\n        )\n\n        q_zz_o, q_yy_o, i_zz_o, i_yy_o, i_zy_o = _calculate_properties(self.y, self.z)\n\n        if len(self.geometry.boundary) > 1:\n            # Cut out any holes in the face\n            for wire in self.geometry.boundary[1:]:\n                y, z = wire.discretize(ndiscr=n_discr, byedges=True).yz\n                q_zz_i, q_yy_i, i_zz_i, i_yy_i, i_zy_i = _calculate_properties(y, z)\n\n                q_zz_o -= q_zz_i\n                q_yy_o -= q_yy_i\n                i_zz_o -= i_zz_i\n                i_yy_o -= i_yy_i\n                i_zy_o -= i_zy_i\n                self.y = np.append(self.y, y)\n                self.z = np.append(self.z, z)\n\n        cy = q_zz_o / area\n        cz = q_yy_o / area\n        self.centroid_geom = (cy, cz)\n\n        self.i_yy = i_yy_o - area * cz**2\n        self.i_zz = i_zz_o - area * cy**2\n        self.i_zy = i_zy_o - area * cz * cy\n        self.qyy = q_yy_o\n        self.qzz = q_zz_o\n        self.ry = np.sqrt(self.i_yy / area)\n        self.rz = np.sqrt(self.i_zz / area)\n\n        # OK so there is no cute general polygon form for J... need FE!\n        # St Venant approach\n        self.j = self.area**4 / (j_opt_var * (i_yy_o + i_zz_o))",
  "def __init__(self, geometry: BluemiraFace, materials: List[StructuralMaterial]):\n        super().__init__()\n        self.geometry = deepcopy(geometry)\n\n        n = len(geometry.boundary)\n\n        if len(materials) != n:\n            raise StructuralError(f\"Need {n} materials for this geometry.\")\n\n        outer = AnalyticalCrossSection(geometry.boundary)\n        inners = []\n        for wire in geometry.boundary[1:]:\n            face = BluemiraFace(wire)\n            inners.append(AnalyticalCrossSection(face))\n\n        cross_sections = [outer]\n        cross_sections.extend(inners)\n\n        e_values = np.array([mat[\"E\"] for mat in materials])\n        g_values = np.array([mat[\"G\"] for mat in materials])\n        rho_values = np.array([mat[\"rho\"] for mat in materials])\n        areas = np.array([xs.area for xs in cross_sections])\n        i_yy_values = np.array([xs.i_yy for xs in cross_sections])\n        i_zz_values = np.array([xs.i_zz for xs in cross_sections])\n        i_zy_values = np.array([xs.i_zy for xs in cross_sections])\n\n        self.area = np.sum(areas)\n        self.ea = np.dot(e_values, areas)\n        self.ei_yy = np.dot(e_values, i_yy_values)\n        self.ei_zz = np.dot(e_values, i_zz_values)\n        self.ei_zy = np.dot(e_values, i_zy_values)\n        ga = np.dot(g_values, areas)\n        rhoa = np.dot(rho_values, areas)\n\n        self.nu = self.ea / (2 * ga) - 1\n        self.ry = np.sqrt(self.ei_yy / self.ea)\n        self.rz = np.sqrt(self.ei_zz / self.ea)\n\n        self.gj = ga / self.area * n * sum(xs.j for xs in cross_sections)\n        self.rho = rhoa / self.area",
  "def annotate_node(ax: Axes, node: Node, text_size: int, color: str):\n    \"\"\"\n    Annotate a node.\n    \"\"\"\n    name = f\"N{node.id_number}\"\n    ax.text(\n        node.x,\n        node.y,\n        node.z,\n        name,\n        fontsize=text_size,\n        color=color,\n    )",
  "def annotate_element(ax: Axes, element: Element, text_size: int, color: str):\n    \"\"\"\n    Annotate an element.\n    \"\"\"\n    name = f\"E{element.id_number}\"\n    ax.text(\n        *element.mid_point,\n        name,\n        size=text_size,\n        color=color,\n    )",
  "def arrow_scale(vector: np.ndarray, max_length: float, max_force: float) -> np.ndarray:\n    \"\"\"\n    Scales an arrow such that, regardless of direction, it has a reasonable\n    size\n\n    Parameters\n    ----------\n    vector:\n        3-D vector of the arrow (3)\n    max_length\n        The maximum length of the arrow\n    max_force:\n        The maximum force value in the model (absolute)\n\n    Returns\n    -------\n    The scaled force arrow (3)\n    \"\"\"\n    v_norm = np.linalg.norm(vector)\n    if v_norm == 0:\n        return vector  # who cares? No numpy warning\n\n    scale = (max_length * np.abs(vector)) / max_force\n\n    return scale * vector / v_norm",
  "def _plot_force(ax: Axes, node: Node, vector: np.ndarray, color: str = \"r\"):\n    \"\"\"\n    Plots a single force arrow in 3-D to indicate a linear load\n\n    Parameters\n    ----------\n    ax:\n        The ax on which to plot\n    node:\n        The node or location at which the force occurs\n    vector:\n        The force direction vector\n    color:\n        The color to plot the force as\n    \"\"\"\n    ax.quiver(\n        node.x - vector[0], node.y - vector[1], node.z - vector[2], *vector, color=color\n    )",
  "def _plot_moment(\n    ax: Axes, node: Node, vector: np.ndarray, color: str = \"r\", support: bool = False\n):\n    \"\"\"\n    Plots a double \"moment\" arrow in 3-D to indicate a moment load. Offset the\n    moment arrows off from the nodes a little, to enable overlaps with forces.\n\n    Parameters\n    ----------\n    ax:\n        The ax on which to plot\n    node:\n        The node or location at which the force occurs\n    vector:\n        The force direction vector\n    color:\n        The color to plot the force as\n    \"\"\"\n    if support:\n        # Offsets the moment arrows a little so we can see overlaps with forces\n        vector *= 2\n        f1 = 0.5\n        f2 = 0.25\n    else:\n        f1 = 1\n        f2 = 0.5\n    ax.quiver(\n        node.x - vector[0],\n        node.y - vector[1],\n        node.z - vector[2],\n        *f1 * vector,\n        color=color,\n    )\n    ax.quiver(\n        node.x - vector[0],\n        node.y - vector[1],\n        node.z - vector[2],\n        *f2 * vector,\n        color=color,\n        arrow_length_ratio=0.6,\n    )",
  "class BasePlotter:\n    \"\"\"\n    Base utility plotting class for structural models\n    \"\"\"\n\n    def __init__(self, geometry: Geometry, ax: Optional[Axes] = None, **kwargs):\n        self.geometry = geometry\n        if ax is None:\n            self.ax = Plot3D()\n        else:\n            self.ax = ax\n\n        self.options = {**DEFAULT_STRUCT_PLOT_OPTIONS, **kwargs}\n\n        # Cached size and plot hints\n        self._unit_length = None\n        self._force_size = None\n        self._size = None\n\n        self.color_normer = None\n\n    @property\n    def unit_length(self) -> float:\n        \"\"\"\n        Calculates a characteristic unit length for the model: the minimum\n        element size\n        \"\"\"\n        if self._unit_length is None:\n            lengths = np.zeros(self.geometry.n_elements)\n            for i, element in enumerate(self.geometry.elements):\n                lengths[i] = element.length\n            self._unit_length = np.min(lengths)\n\n        return self._unit_length\n\n    @property\n    def force_size(self) -> float:\n        \"\"\"\n        Calculates a characteristic force vector length for plotting purposes\n\n        Returns\n        -------\n        The minimum and maximum forces\n        \"\"\"\n        if self._force_size is None:\n            loads = []\n            for element in self.geometry.elements:\n                for load in element.loads:\n                    if load[\"type\"] == \"Element Load\":\n                        loads.append(load[\"Q\"])\n                    elif load[\"type\"] == \"Distributed Load\":\n                        loads.append(load[\"w\"] / element.length)\n\n            for node in self.geometry.nodes:\n                for load in node.loads:\n                    loads.append(load[\"Q\"])\n\n            self._force_size = np.max(np.abs(loads))\n\n        return self._force_size\n\n    @property\n    def size(self) -> float:\n        \"\"\"\n        Calculates the size of the model bounding box\n        \"\"\"\n        if self._size is None:\n            xmax, xmin, ymax, ymin, zmax, zmin = self.geometry.bounds()\n\n            self._size = max([xmax - xmin, ymax - ymin, zmax - zmin])\n\n        return self._size\n\n    @property\n    def text_size(self) -> int:\n        \"\"\"\n        Get a reasonable guess of the font size to use in plotting.\n\n        Returns\n        -------\n        size: float\n            The font size to use in plotting\n        \"\"\"\n        return max(10, self.size // 30)\n\n    def plot_nodes(self):\n        \"\"\"\n        Plots all the Nodes in the Geometry.\n        \"\"\"\n        kwargs = deepcopy(self.options[\"node_options\"])\n        default_color = kwargs.pop(\n            \"color\", DEFAULT_STRUCT_PLOT_OPTIONS[\"node_options\"][\"color\"]\n        )\n\n        for node in self.geometry.nodes:\n            if node.supports.any():\n                color = self.options[\"support_node_color\"]\n            elif node.symmetry:\n                color = self.options[\"symmetry_node_color\"]\n            else:\n                color = default_color\n\n            self.ax.plot([node.x], [node.y], [node.z], color=color, **kwargs)\n\n            if self.options[\"annotate_nodes\"]:\n                annotate_node(self.ax, node, self.text_size, color)\n\n    def plot_supports(self):\n        \"\"\"\n        Plots all supports in the Geometry.\n        \"\"\"\n        lengths = np.array([e.length for e in self.geometry.elements])\n        length = lengths.min() / 5\n        for node in self.geometry.nodes:\n            if node.supports.any():\n                for i, support in enumerate(node.supports):\n                    vector = length * LOAD_INT_VECTORS[i]\n                    if support and i < 3:\n                        # Linear support (single black arrow)\n                        _plot_force(self.ax, node, vector, color=\"k\")\n                    elif support and i >= 3:\n                        # Moment support (double red arrow, offset to enable overlap)\n                        _plot_moment(self.ax, node, vector, support=True, color=\"g\")\n\n    def plot_elements(self):\n        \"\"\"\n        Plots all of the Elements in the Geometry.\n        \"\"\"\n        kwargs = deepcopy(self.options[\"element_options\"])\n        default_color = kwargs.pop(\n            \"color\", DEFAULT_STRUCT_PLOT_OPTIONS[\"element_options\"][\"color\"]\n        )\n\n        for element in self.geometry.elements:\n            x = [element.node_1.x, element.node_2.x]\n            y = [element.node_1.y, element.node_2.y]\n            z = [element.node_1.z, element.node_2.z]\n\n            if self.options[\"show_stress\"] and self.color_normer:\n                color = STRESS_COLOR(self.color_normer(element.max_stress))\n            elif self.options[\"show_deflection\"] and self.color_normer:\n                color = DEFLECT_COLOR(self.color_normer(element.max_displacement))\n            else:\n                color = default_color\n\n            self.ax.plot(x, y, z, marker=None, color=color, **kwargs)\n\n            if self.options[\"annotate_elements\"]:\n                annotate_element(self.ax, element, self.text_size, color=\"k\")\n\n            if self.options[\"interpolate\"]:\n                ls = kwargs.pop(\n                    \"linestyle\",\n                    DEFAULT_STRUCT_PLOT_OPTIONS[\"element_options\"][\"linestyle\"],\n                )\n                self.ax.plot(\n                    *element.shapes, marker=None, linestyle=\"--\", color=color, **kwargs\n                )\n                kwargs[\"linestyle\"] = ls\n\n    def plot_cross_sections(self):\n        \"\"\"\n        Plots the cross-sections for each Element in the Geometry, rotated to\n        the mid-point of the Element.\n        \"\"\"\n        xss = []\n        options = []\n        for element in self.geometry.elements:\n            matrix = np.zeros((4, 4))\n            matrix[:3, :3] = element.lambda_matrix[:3, :3].T\n            matrix[:3, -1] = element.mid_point\n            matrix[-1, :] = [0, 0, 0, 1]\n            placement = BluemiraPlacement.from_matrix(matrix)\n            plot_options = PlotOptions(\n                show_wires=False,\n                show_faces=True,\n                face_options=self.options[\"cross_section_options\"],\n            )\n            options.append(plot_options)\n            xs = element._cross_section.geometry.deepcopy()\n            xs.change_placement(placement)\n            xss.append(xs)\n\n        plot_3d(xss, ax=self.ax, show=False, options=options)\n\n    def plot_loads(self):\n        \"\"\"\n        Plots all of the loads applied to the geometry\n        \"\"\"\n        for node in self.geometry.nodes:\n            if node.loads:\n                for load in node.loads:\n                    self._plot_node_load(node, load)\n\n        for element in self.geometry.elements:\n            for load in element.loads:\n                if load[\"type\"] == \"Element Load\":\n                    self._plot_element_load(element, load)\n                elif load[\"type\"] == \"Distributed Load\":\n                    self._plot_distributed_load(element, load)\n\n    def _plot_node_load(self, node, load):\n        load_value = load[\"Q\"] * LOAD_STR_VECTORS[load[\"sub_type\"]]\n\n        load_value = arrow_scale(load_value, 10 * self.unit_length, self.force_size)\n\n        if \"F\" in load[\"sub_type\"]:\n            _plot_force(self.ax, node, load_value, color=\"r\")\n\n        elif \"M\" in load[\"sub_type\"]:\n            _plot_moment(self.ax, node, load_value, color=\"r\")\n\n    def _plot_element_load(self, element, load):\n        load = load[\"Q\"] * LOAD_STR_VECTORS[load[\"sub_type\"]]\n\n        load = arrow_scale(load, 10 * self.unit_length, self.force_size)\n\n        dcm = element.lambda_matrix[0:3, 0:3]\n        load = load @ dcm\n        point = np.array(\n            [element.node_1.x, element.node_1.y, element.node_1.z], dtype=float\n        )\n        point += (np.array([1.0, 0.0, 0.0]) * np.float(load[\"x\"])) @ dcm\n        self.ax.quiver(*point - load, *load, color=\"r\")\n\n    def _plot_distributed_load(self, element, load):\n        length = element.length\n        n = int(length * 10)\n        dcm = element.lambda_matrix[0:3, 0:3]\n        load = load[\"w\"] * LOAD_STR_VECTORS[load[\"sub_type\"]] / length\n\n        load = arrow_scale(load, 10 * self.unit_length, self.force_size)\n\n        load = load @ dcm\n        load = load * np.ones((3, n)).T\n        load = load.T\n        point = np.array(\n            [element.node_1.x, element.node_1.y, element.node_1.z], dtype=float\n        )\n        point = point * np.ones((3, n)).T\n        point += (\n            np.array([x * np.array([1.0, 0.0, 0.0]) for x in np.linspace(0, length, n)])\n            @ dcm\n        )\n        point = point.T\n        self.ax.quiver(*point - load, *load, color=\"r\")\n\n    def _set_aspect_equal(self):\n        \"\"\"\n        Hack to make matplotlib 3D look good. Draw a white bounding box around\n        the nodes\n        \"\"\"\n        x_bb, y_bb, z_bb = self.geometry.bounding_box()\n\n        x_bb *= self.options[\"bound_scale\"]\n        y_bb *= self.options[\"bound_scale\"]\n        z_bb *= self.options[\"bound_scale\"]\n\n        for x, y, z in zip(x_bb, y_bb, z_bb):\n            self.ax.plot([x], [y], [z], color=\"w\")",
  "class GeometryPlotter(BasePlotter):\n    \"\"\"\n    Utility class for the plotting of structural geometry models\n    \"\"\"\n\n    def __init__(self, geometry: Geometry, ax: Optional[Axes] = None, **kwargs):\n        super().__init__(geometry, ax, **kwargs)\n        self.options = deepcopy(DEFAULT_STRUCT_PLOT_OPTIONS)\n        self.options[\"show_stress\"] = False\n        self.options[\"show_deflection\"] = False\n\n        self.plot_nodes()\n        self.plot_elements()\n        self.plot_supports()\n        self.plot_loads()\n        if self.options[\"show_cross_sections\"]:\n            self.plot_cross_sections()\n        self._set_aspect_equal()",
  "class DeformedGeometryPlotter(BasePlotter):\n    \"\"\"\n    Utility class for the plotting of structural deformed geometry models and\n    overlaying with GeometryPlotters\n    \"\"\"\n\n    def __init__(self, geometry: DeformedGeometry, ax: Optional[Axes] = None, **kwargs):\n        super().__init__(geometry, ax, **kwargs)\n        self.options = deepcopy(DEFAULT_STRUCT_PLOT_OPTIONS)\n        self.options[\"node_options\"][\"color\"] = \"b\"\n        self.options[\"element_options\"][\"color\"] = \"b\"\n        self.options[\"show_stress\"] = False\n        self.options[\"show_deflection\"] = True\n        self.options[\"annotate_nodes\"] = True\n        self.options[\"interpolate\"] = True\n        self.options[\"show_all_nodes\"] = False\n\n        self.plot_nodes()\n        self.plot_elements()\n        self._set_aspect_equal()",
  "class StressDeformedGeometryPlotter(BasePlotter):\n    \"\"\"\n    Utility class for the plotting of structural deformed geometry models and\n    overlaying with GeometryPlotters\n    \"\"\"\n\n    def __init__(\n        self,\n        geometry: DeformedGeometry,\n        ax: Optional[Axes] = None,\n        stress: Optional[np.ndarray] = None,\n        deflection: bool = False,\n        **kwargs,\n    ):\n        super().__init__(geometry, ax, **kwargs)\n        self.options = deepcopy(DEFAULT_STRUCT_PLOT_OPTIONS)\n        self.options[\"node_options\"][\"color\"] = \"b\"\n        self.options[\"element_options\"][\"color\"] = None\n        self.options[\"show_stress\"] = True\n        self.options[\"annotate_nodes\"] = False\n        self.options[\"interpolate\"] = True\n        self.options[\"show_all_nodes\"] = False\n        self.options[\"show_as_grey\"] = False\n\n        self.color_normer = self.make_color_normer(stress, deflection)\n\n        self.plot_nodes()\n        self.plot_elements()\n        self._set_aspect_equal()\n\n    @staticmethod\n    def make_color_normer(stress: np.ndarray, deflection: bool = False):\n        \"\"\"\n        Make a ColorNorm object for the plot based on the stress values.\n        \"\"\"\n        smin, smax = min(stress), max(stress)\n        if smin == smax:\n\n            class SameColour:\n                def __call__(self, value):\n                    return 0.5\n\n            return SameColour()\n\n        centre = 0\n\n        if deflection:\n            # deflections positive when plotting\n            deflections = np.abs(stress)\n            return Normalize(vmin=0, vmax=max(deflections))\n\n        if not smin < 0 < smax:\n            centre = (smin + smax) / 2\n\n        return TwoSlopeNorm(centre, vmin=min(stress), vmax=max(stress))",
  "def __init__(self, geometry: Geometry, ax: Optional[Axes] = None, **kwargs):\n        self.geometry = geometry\n        if ax is None:\n            self.ax = Plot3D()\n        else:\n            self.ax = ax\n\n        self.options = {**DEFAULT_STRUCT_PLOT_OPTIONS, **kwargs}\n\n        # Cached size and plot hints\n        self._unit_length = None\n        self._force_size = None\n        self._size = None\n\n        self.color_normer = None",
  "def unit_length(self) -> float:\n        \"\"\"\n        Calculates a characteristic unit length for the model: the minimum\n        element size\n        \"\"\"\n        if self._unit_length is None:\n            lengths = np.zeros(self.geometry.n_elements)\n            for i, element in enumerate(self.geometry.elements):\n                lengths[i] = element.length\n            self._unit_length = np.min(lengths)\n\n        return self._unit_length",
  "def force_size(self) -> float:\n        \"\"\"\n        Calculates a characteristic force vector length for plotting purposes\n\n        Returns\n        -------\n        The minimum and maximum forces\n        \"\"\"\n        if self._force_size is None:\n            loads = []\n            for element in self.geometry.elements:\n                for load in element.loads:\n                    if load[\"type\"] == \"Element Load\":\n                        loads.append(load[\"Q\"])\n                    elif load[\"type\"] == \"Distributed Load\":\n                        loads.append(load[\"w\"] / element.length)\n\n            for node in self.geometry.nodes:\n                for load in node.loads:\n                    loads.append(load[\"Q\"])\n\n            self._force_size = np.max(np.abs(loads))\n\n        return self._force_size",
  "def size(self) -> float:\n        \"\"\"\n        Calculates the size of the model bounding box\n        \"\"\"\n        if self._size is None:\n            xmax, xmin, ymax, ymin, zmax, zmin = self.geometry.bounds()\n\n            self._size = max([xmax - xmin, ymax - ymin, zmax - zmin])\n\n        return self._size",
  "def text_size(self) -> int:\n        \"\"\"\n        Get a reasonable guess of the font size to use in plotting.\n\n        Returns\n        -------\n        size: float\n            The font size to use in plotting\n        \"\"\"\n        return max(10, self.size // 30)",
  "def plot_nodes(self):\n        \"\"\"\n        Plots all the Nodes in the Geometry.\n        \"\"\"\n        kwargs = deepcopy(self.options[\"node_options\"])\n        default_color = kwargs.pop(\n            \"color\", DEFAULT_STRUCT_PLOT_OPTIONS[\"node_options\"][\"color\"]\n        )\n\n        for node in self.geometry.nodes:\n            if node.supports.any():\n                color = self.options[\"support_node_color\"]\n            elif node.symmetry:\n                color = self.options[\"symmetry_node_color\"]\n            else:\n                color = default_color\n\n            self.ax.plot([node.x], [node.y], [node.z], color=color, **kwargs)\n\n            if self.options[\"annotate_nodes\"]:\n                annotate_node(self.ax, node, self.text_size, color)",
  "def plot_supports(self):\n        \"\"\"\n        Plots all supports in the Geometry.\n        \"\"\"\n        lengths = np.array([e.length for e in self.geometry.elements])\n        length = lengths.min() / 5\n        for node in self.geometry.nodes:\n            if node.supports.any():\n                for i, support in enumerate(node.supports):\n                    vector = length * LOAD_INT_VECTORS[i]\n                    if support and i < 3:\n                        # Linear support (single black arrow)\n                        _plot_force(self.ax, node, vector, color=\"k\")\n                    elif support and i >= 3:\n                        # Moment support (double red arrow, offset to enable overlap)\n                        _plot_moment(self.ax, node, vector, support=True, color=\"g\")",
  "def plot_elements(self):\n        \"\"\"\n        Plots all of the Elements in the Geometry.\n        \"\"\"\n        kwargs = deepcopy(self.options[\"element_options\"])\n        default_color = kwargs.pop(\n            \"color\", DEFAULT_STRUCT_PLOT_OPTIONS[\"element_options\"][\"color\"]\n        )\n\n        for element in self.geometry.elements:\n            x = [element.node_1.x, element.node_2.x]\n            y = [element.node_1.y, element.node_2.y]\n            z = [element.node_1.z, element.node_2.z]\n\n            if self.options[\"show_stress\"] and self.color_normer:\n                color = STRESS_COLOR(self.color_normer(element.max_stress))\n            elif self.options[\"show_deflection\"] and self.color_normer:\n                color = DEFLECT_COLOR(self.color_normer(element.max_displacement))\n            else:\n                color = default_color\n\n            self.ax.plot(x, y, z, marker=None, color=color, **kwargs)\n\n            if self.options[\"annotate_elements\"]:\n                annotate_element(self.ax, element, self.text_size, color=\"k\")\n\n            if self.options[\"interpolate\"]:\n                ls = kwargs.pop(\n                    \"linestyle\",\n                    DEFAULT_STRUCT_PLOT_OPTIONS[\"element_options\"][\"linestyle\"],\n                )\n                self.ax.plot(\n                    *element.shapes, marker=None, linestyle=\"--\", color=color, **kwargs\n                )\n                kwargs[\"linestyle\"] = ls",
  "def plot_cross_sections(self):\n        \"\"\"\n        Plots the cross-sections for each Element in the Geometry, rotated to\n        the mid-point of the Element.\n        \"\"\"\n        xss = []\n        options = []\n        for element in self.geometry.elements:\n            matrix = np.zeros((4, 4))\n            matrix[:3, :3] = element.lambda_matrix[:3, :3].T\n            matrix[:3, -1] = element.mid_point\n            matrix[-1, :] = [0, 0, 0, 1]\n            placement = BluemiraPlacement.from_matrix(matrix)\n            plot_options = PlotOptions(\n                show_wires=False,\n                show_faces=True,\n                face_options=self.options[\"cross_section_options\"],\n            )\n            options.append(plot_options)\n            xs = element._cross_section.geometry.deepcopy()\n            xs.change_placement(placement)\n            xss.append(xs)\n\n        plot_3d(xss, ax=self.ax, show=False, options=options)",
  "def plot_loads(self):\n        \"\"\"\n        Plots all of the loads applied to the geometry\n        \"\"\"\n        for node in self.geometry.nodes:\n            if node.loads:\n                for load in node.loads:\n                    self._plot_node_load(node, load)\n\n        for element in self.geometry.elements:\n            for load in element.loads:\n                if load[\"type\"] == \"Element Load\":\n                    self._plot_element_load(element, load)\n                elif load[\"type\"] == \"Distributed Load\":\n                    self._plot_distributed_load(element, load)",
  "def _plot_node_load(self, node, load):\n        load_value = load[\"Q\"] * LOAD_STR_VECTORS[load[\"sub_type\"]]\n\n        load_value = arrow_scale(load_value, 10 * self.unit_length, self.force_size)\n\n        if \"F\" in load[\"sub_type\"]:\n            _plot_force(self.ax, node, load_value, color=\"r\")\n\n        elif \"M\" in load[\"sub_type\"]:\n            _plot_moment(self.ax, node, load_value, color=\"r\")",
  "def _plot_element_load(self, element, load):\n        load = load[\"Q\"] * LOAD_STR_VECTORS[load[\"sub_type\"]]\n\n        load = arrow_scale(load, 10 * self.unit_length, self.force_size)\n\n        dcm = element.lambda_matrix[0:3, 0:3]\n        load = load @ dcm\n        point = np.array(\n            [element.node_1.x, element.node_1.y, element.node_1.z], dtype=float\n        )\n        point += (np.array([1.0, 0.0, 0.0]) * np.float(load[\"x\"])) @ dcm\n        self.ax.quiver(*point - load, *load, color=\"r\")",
  "def _plot_distributed_load(self, element, load):\n        length = element.length\n        n = int(length * 10)\n        dcm = element.lambda_matrix[0:3, 0:3]\n        load = load[\"w\"] * LOAD_STR_VECTORS[load[\"sub_type\"]] / length\n\n        load = arrow_scale(load, 10 * self.unit_length, self.force_size)\n\n        load = load @ dcm\n        load = load * np.ones((3, n)).T\n        load = load.T\n        point = np.array(\n            [element.node_1.x, element.node_1.y, element.node_1.z], dtype=float\n        )\n        point = point * np.ones((3, n)).T\n        point += (\n            np.array([x * np.array([1.0, 0.0, 0.0]) for x in np.linspace(0, length, n)])\n            @ dcm\n        )\n        point = point.T\n        self.ax.quiver(*point - load, *load, color=\"r\")",
  "def _set_aspect_equal(self):\n        \"\"\"\n        Hack to make matplotlib 3D look good. Draw a white bounding box around\n        the nodes\n        \"\"\"\n        x_bb, y_bb, z_bb = self.geometry.bounding_box()\n\n        x_bb *= self.options[\"bound_scale\"]\n        y_bb *= self.options[\"bound_scale\"]\n        z_bb *= self.options[\"bound_scale\"]\n\n        for x, y, z in zip(x_bb, y_bb, z_bb):\n            self.ax.plot([x], [y], [z], color=\"w\")",
  "def __init__(self, geometry: Geometry, ax: Optional[Axes] = None, **kwargs):\n        super().__init__(geometry, ax, **kwargs)\n        self.options = deepcopy(DEFAULT_STRUCT_PLOT_OPTIONS)\n        self.options[\"show_stress\"] = False\n        self.options[\"show_deflection\"] = False\n\n        self.plot_nodes()\n        self.plot_elements()\n        self.plot_supports()\n        self.plot_loads()\n        if self.options[\"show_cross_sections\"]:\n            self.plot_cross_sections()\n        self._set_aspect_equal()",
  "def __init__(self, geometry: DeformedGeometry, ax: Optional[Axes] = None, **kwargs):\n        super().__init__(geometry, ax, **kwargs)\n        self.options = deepcopy(DEFAULT_STRUCT_PLOT_OPTIONS)\n        self.options[\"node_options\"][\"color\"] = \"b\"\n        self.options[\"element_options\"][\"color\"] = \"b\"\n        self.options[\"show_stress\"] = False\n        self.options[\"show_deflection\"] = True\n        self.options[\"annotate_nodes\"] = True\n        self.options[\"interpolate\"] = True\n        self.options[\"show_all_nodes\"] = False\n\n        self.plot_nodes()\n        self.plot_elements()\n        self._set_aspect_equal()",
  "def __init__(\n        self,\n        geometry: DeformedGeometry,\n        ax: Optional[Axes] = None,\n        stress: Optional[np.ndarray] = None,\n        deflection: bool = False,\n        **kwargs,\n    ):\n        super().__init__(geometry, ax, **kwargs)\n        self.options = deepcopy(DEFAULT_STRUCT_PLOT_OPTIONS)\n        self.options[\"node_options\"][\"color\"] = \"b\"\n        self.options[\"element_options\"][\"color\"] = None\n        self.options[\"show_stress\"] = True\n        self.options[\"annotate_nodes\"] = False\n        self.options[\"interpolate\"] = True\n        self.options[\"show_all_nodes\"] = False\n        self.options[\"show_as_grey\"] = False\n\n        self.color_normer = self.make_color_normer(stress, deflection)\n\n        self.plot_nodes()\n        self.plot_elements()\n        self._set_aspect_equal()",
  "def make_color_normer(stress: np.ndarray, deflection: bool = False):\n        \"\"\"\n        Make a ColorNorm object for the plot based on the stress values.\n        \"\"\"\n        smin, smax = min(stress), max(stress)\n        if smin == smax:\n\n            class SameColour:\n                def __call__(self, value):\n                    return 0.5\n\n            return SameColour()\n\n        centre = 0\n\n        if deflection:\n            # deflections positive when plotting\n            deflections = np.abs(stress)\n            return Normalize(vmin=0, vmax=max(deflections))\n\n        if not smin < 0 < smax:\n            centre = (smin + smax) / 2\n\n        return TwoSlopeNorm(centre, vmin=min(stress), vmax=max(stress))",
  "class SameColour:\n                def __call__(self, value):\n                    return 0.5",
  "def __call__(self, value):\n                    return 0.5",
  "def _direction_cosine_matrix(dx: float, dy: float, dz: float) -> np.ndarray:\n    \"\"\"\n    Calculates the direction cosine (transformation) matrix for an arbitrary\n    vector in space. A number of painful edge cases are handled...\n\n    Works such that the output dcm satisfies the following properties:\n\n    local = dcm @ global\n    global = dcm.T @ local\n\n    Parameters\n    ----------\n    dx:\n        The absolute length of the vector in the x global coordinate\n    dy:\n        The absolute length of the vector in the y global coordinate\n    dz:\n        The absolute length of the vector in the z global coordinate\n\n    Returns\n    -------\n    The direction cosine matrix with reference to the global coordinate\n    system (3, 3)\n    \"\"\"\n    # Please be careful when modifying this function, and instead work on the\n    # debugging version which is tested...\n    length = np.sqrt(dx**2 + dy**2 + dz**2)\n    a = dx / length\n    b = dy / length\n    c = dz / length\n    d = np.hypot(a, b)\n    # TODO: Why does the less intuitive, simpler algebra form work better??\n    # https://ocw.mit.edu/courses/civil-and-environmental-engineering/1-571-structural-analysis-and-control-spring-2004/readings/connor_ch5.pdf  # noqa\n    if np.isclose(a, 0) and np.isclose(b, 0):\n        dcm = np.array(\n            [[0.0, 0.0, -np.sign(c)], [0.0, 1.0, 0.0], [np.sign(c), 0.0, 0.0]]\n        )\n    else:\n        dcm = np.array([[a, -b / d, -a * c / d], [b, a / d, -b * c / d], [c, 0, d]]).T\n\n    return dcm",
  "def _direction_cosine_matrix_debugging(dx, dy, dz, debug=False):\n    \"\"\"\n    Slow, ugly, safe\n    \"\"\"\n    dcm = 0\n    u = np.array([dx, dy, dz])\n    x_local = u / np.linalg.norm(u)\n\n    x_global = np.array([1.0, 0, 0])\n    y_global = np.array([0, 1.0, 0])\n    z_global = np.array([0, 0, 1.0])\n    globa = np.array([x_global, y_global, z_global])\n\n    if x_local[0] == 1:\n        # corresponds to the global coordinate system\n        dcm = np.eye(3)\n        if debug:\n            return dcm, globa\n        else:\n            return dcm\n    if x_local[0] == -1:\n        # corresponds to the mirrored coordinate system\n        dcm = np.eye(3)\n        dcm[0, 0] = -1\n        local = globa.copy()\n        local[0][0] = -1\n        if debug:\n            return dcm, local\n        else:\n            return dcm\n    if abs(x_local[1]) == 1:\n        # corresponds to a local y-vector sitting on the global x-vector\n        # (rotation about z-axis)\n        cos_theta = 0\n        sin_theta = np.sign(x_local[1])\n        dcm = np.array(\n            [[cos_theta, -sin_theta, 0], [sin_theta, cos_theta, 0], [0, 0, 1]]\n        )\n        if debug:\n            local = np.array([[0, sin_theta, 0], [-sin_theta, 0, 0], [0, 0, 1]])\n            return dcm, local\n        else:\n            return dcm\n    if x_local[2] == 1:\n        # corresponds to a local z-vector sitting on the global x-vector\n        # rotation about the y-axis\n        cos_theta = 0\n        sin_theta = -1\n        dcm = np.array(\n            [[cos_theta, 0, sin_theta], [0, 1, 0], [-sin_theta, 0, cos_theta]]\n        )\n        if debug:\n            local = np.array([[0, 0, 1], [0, 1, 0], [-1, 0, 0]])\n            return dcm, local\n        else:\n            return dcm\n\n    y_local = np.array([0, 1.0, 0])\n    y_local -= np.dot(x_local, y_local) * x_local\n    y_local /= np.linalg.norm(y_local)\n    z_local = np.cross(x_local, y_local)\n\n    local = np.array([x_local, y_local, z_local])\n\n    if not isinstance(dcm, int):\n        if debug:\n            return dcm, local\n        else:\n            return dcm\n    c11 = np.dot(x_global, x_local)\n    c12 = np.dot(x_global, y_local)\n    c13 = np.dot(x_global, z_local)\n    c21 = np.dot(y_global, x_local)\n    c22 = np.dot(y_global, y_local)\n    c23 = np.dot(y_global, z_local)\n    c31 = np.dot(z_global, x_local)\n    c32 = np.dot(z_global, y_local)\n    c33 = np.dot(z_global, z_local)\n    dcm = np.array([[c11, c12, c13], [c21, c22, c23], [c31, c32, c33]])\n    if not debug:\n        return dcm\n    else:\n        return dcm, local",
  "def lambda_matrix(dx: float, dy: float, dz: float) -> np.ndarray:\n    \"\"\"\n    3-D transformation matrix, generalised to a 2-node beam.\n    Effectively only handles the tiling of the direction cosine matrix\n    transform.\n\n    Parameters\n    ----------\n    dx:\n        The absolute length of the vector in the x global coordinate\n    dy:\n        The absolute length of the vector in the y global coordinate\n    dz:\n        The absolute length of the vector in the z global coordinate\n\n    Returns\n    -------\n    The transformation matrix (12, 12)\n    \"\"\"\n    dcm = _direction_cosine_matrix(dx, dy, dz)\n    return block_diag(*[dcm] * 4)",
  "def cyclic_pattern(\n    geometry: Geometry,\n    axis: np.ndarray,\n    angle: float,\n    n: int,\n    include_first: bool = True,\n) -> List[Union[Geometry, DeformedGeometry]]:\n    \"\"\"\n    Build a cyclic pattern of a Geometry.\n\n    Parameters\n    ----------\n    geometry:\n        The geometry to pattern\n    axis:\n        The axis vector about which to pattern\n    angle:\n        The pattern angle [degrees]\n    n:\n        The number of sectors to pattern\n    include_first:\n        Whether or not to include the first sector in the result\n\n    Returns\n    -------\n    The patterned and merged geometry\n    \"\"\"\n    # Dodge cyclic import\n    from bluemira.structural.geometry import DeformedGeometry, Geometry\n\n    if include_first:\n        patterned = deepcopy(geometry)\n    else:\n        if isinstance(geometry, DeformedGeometry):\n            patterned = DeformedGeometry(Geometry(), geometry._scale)\n        else:\n            patterned = Geometry()\n\n    for i in range(1, n):\n        sector = deepcopy(geometry)\n        theta = np.deg2rad(i * angle)\n        t_matrix = rotation_matrix(theta, axis)\n        sector.rotate(t_matrix)\n        patterned.merge(sector)\n        del sector  # Save some RAM\n\n    return patterned",
  "class CyclicSymmetry:\n    \"\"\"\n    Utility class for implementing a cyclical symmetry boundary condition in\n    FiniteElementModel\n\n    Parameters\n    ----------\n    geometry:\n        The geometry upon which to apply the cyclic symmetry\n    cycle_sym_ids:\n        The list of left and right DOF ids\n    \"\"\"\n\n    def __init__(self, geometry: Geometry, cycle_sym_ids: List[List[int], List[int]]):\n        self.geometry = geometry\n        self.cycle_sym_ids = cycle_sym_ids\n\n        # Constructors\n        self.t_block = None\n        self.t_matrix = None\n        self.left_nodes = None\n        self.right_nodes = None\n        self.theta = None\n        self.n = None\n        self.axis = None\n        self.selections = None\n\n        if self.cycle_sym_ids:\n            self._prepare_cyclic_symmetry()\n\n    def _prepare_cyclic_symmetry(self):\n        n = []\n        left_nodes = []\n        right_nodes = []\n        for left, right, p1, p2 in self.cycle_sym_ids:\n            left_nodes.append(left)\n            right_nodes.append(right)\n            axis = np.array(p2) - np.array(p1)\n\n            l_point = self.geometry.node_xyz[left]\n            r_point = self.geometry.node_xyz[right]\n\n            pa = project_point_axis(l_point, axis)\n\n            angle = get_angle_between_points(r_point, pa, l_point)\n\n            n.append(2 * np.pi / angle)\n\n        n = np.round(n).astype(np.int32)\n\n        if not np.all(n == n[0]):\n            raise StructuralError(\n                \"CyclicSymmetry: cyclic symmetry boundary condition is \"\n                \"incorrectly specified:\\n\"\n                f\"periodicity is not uniform: {n}\"\n            )\n\n        n = n[0]\n        theta = angle\n        self.t_block = rotation_matrix(theta, axis)\n        self._build_t_matrix(6 * len(left_nodes))\n        self.left_nodes = left_nodes\n        self.right_nodes = right_nodes\n        self.n = n\n        self.axis = axis\n        self.theta = theta\n\n    def _build_t_matrix(self, n):\n        t_m = np.zeros((n, n))\n        for i in range(int(n / 6)):\n            i *= 6\n            t_m[i : i + 3, i : i + 3] = self.t_block\n            t_m[i + 3 : i + 6, i + 3 : i + 6] = self.t_block\n        self.t_matrix = t_m\n\n    def apply_cyclic_symmetry(\n        self, k: np.ndarray, p: np.ndarray\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Apply the cyclic symmetry condition to the matrices.\n\n        Will simply return k and p if no cyclic symmetry is detected in the\n        FiniteElementModel.\n\n        Parameters\n        ----------\n        k:\n            The geometry stiffness matrix\n        p:\n            The model load vector\n\n        Returns\n        -------\n        k:\n            The partitioned block stiffness matrix\n        p:\n            The partitioned block load vector\n        \"\"\"\n        if not self.cycle_sym_ids:\n            # Do nothing\n            return k, p\n\n        k_cyc, p_cyc, self.selections = cyclic_decomposition(\n            k, p, self.left_nodes, self.right_nodes\n        )\n\n        # Unpack the decomposition\n        (k_rr, k_rl, k_ri), (k_lr, k_ll, k_li), (k_ir, k_il, k_ii) = k_cyc\n        p_r, p_l, p_i = p_cyc\n\n        e = 1  # np.exp(1j * self.n * self.theta)\n        en = 1  # np.exp(-1j * self.n * self.theta)\n\n        t_m = self.t_matrix\n\n        # Build block matrix components\n        k_11 = k_rr + t_m @ k_ll @ t_m.T + e * k_rl @ t_m.T + en * t_m @ k_lr\n        k_12 = k_ri + en * t_m @ k_li\n        k_21 = k_ir + e * k_il @ t_m.T\n        k_22 = k_ii\n\n        k = np.block([[k_11, k_12], [k_21, k_22]])\n\n        # This is a hack, is it not? Must get to the bottom of this...\n        # It seems it is a hack...\n        p = np.block([p_r + en * t_m @ p_l, p_i])\n        return k, p\n\n    def reorder(self, u_original: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Re-order the displacement vector correctly, so that the deflections\n        may be applied to the correct nodes.\n\n        If not cyclic symmetry is detected in the FiniteElementModel, simply\n        returns u_original.\n\n        Parameters\n        ----------\n        u_original:\n            The original deflection vector\n\n        Returns\n        -------\n        The re-ordered deflection vector\n        \"\"\"\n        if not self.cycle_sym_ids:\n            # Do nothing\n            return u_original\n\n        u_ordered = np.zeros((6 * self.geometry.n_nodes,))\n        left, right, interior = self.selections\n\n        u_right = u_original[: len(right)]\n        u_left = self.t_matrix.T @ u_right\n        u_interior = u_original[len(right) :]\n\n        u_ordered[interior] = u_interior\n        u_ordered[right] = u_right\n        u_ordered[left] = u_left\n\n        return u_ordered",
  "def __init__(self, geometry: Geometry, cycle_sym_ids: List[List[int], List[int]]):\n        self.geometry = geometry\n        self.cycle_sym_ids = cycle_sym_ids\n\n        # Constructors\n        self.t_block = None\n        self.t_matrix = None\n        self.left_nodes = None\n        self.right_nodes = None\n        self.theta = None\n        self.n = None\n        self.axis = None\n        self.selections = None\n\n        if self.cycle_sym_ids:\n            self._prepare_cyclic_symmetry()",
  "def _prepare_cyclic_symmetry(self):\n        n = []\n        left_nodes = []\n        right_nodes = []\n        for left, right, p1, p2 in self.cycle_sym_ids:\n            left_nodes.append(left)\n            right_nodes.append(right)\n            axis = np.array(p2) - np.array(p1)\n\n            l_point = self.geometry.node_xyz[left]\n            r_point = self.geometry.node_xyz[right]\n\n            pa = project_point_axis(l_point, axis)\n\n            angle = get_angle_between_points(r_point, pa, l_point)\n\n            n.append(2 * np.pi / angle)\n\n        n = np.round(n).astype(np.int32)\n\n        if not np.all(n == n[0]):\n            raise StructuralError(\n                \"CyclicSymmetry: cyclic symmetry boundary condition is \"\n                \"incorrectly specified:\\n\"\n                f\"periodicity is not uniform: {n}\"\n            )\n\n        n = n[0]\n        theta = angle\n        self.t_block = rotation_matrix(theta, axis)\n        self._build_t_matrix(6 * len(left_nodes))\n        self.left_nodes = left_nodes\n        self.right_nodes = right_nodes\n        self.n = n\n        self.axis = axis\n        self.theta = theta",
  "def _build_t_matrix(self, n):\n        t_m = np.zeros((n, n))\n        for i in range(int(n / 6)):\n            i *= 6\n            t_m[i : i + 3, i : i + 3] = self.t_block\n            t_m[i + 3 : i + 6, i + 3 : i + 6] = self.t_block\n        self.t_matrix = t_m",
  "def apply_cyclic_symmetry(\n        self, k: np.ndarray, p: np.ndarray\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Apply the cyclic symmetry condition to the matrices.\n\n        Will simply return k and p if no cyclic symmetry is detected in the\n        FiniteElementModel.\n\n        Parameters\n        ----------\n        k:\n            The geometry stiffness matrix\n        p:\n            The model load vector\n\n        Returns\n        -------\n        k:\n            The partitioned block stiffness matrix\n        p:\n            The partitioned block load vector\n        \"\"\"\n        if not self.cycle_sym_ids:\n            # Do nothing\n            return k, p\n\n        k_cyc, p_cyc, self.selections = cyclic_decomposition(\n            k, p, self.left_nodes, self.right_nodes\n        )\n\n        # Unpack the decomposition\n        (k_rr, k_rl, k_ri), (k_lr, k_ll, k_li), (k_ir, k_il, k_ii) = k_cyc\n        p_r, p_l, p_i = p_cyc\n\n        e = 1  # np.exp(1j * self.n * self.theta)\n        en = 1  # np.exp(-1j * self.n * self.theta)\n\n        t_m = self.t_matrix\n\n        # Build block matrix components\n        k_11 = k_rr + t_m @ k_ll @ t_m.T + e * k_rl @ t_m.T + en * t_m @ k_lr\n        k_12 = k_ri + en * t_m @ k_li\n        k_21 = k_ir + e * k_il @ t_m.T\n        k_22 = k_ii\n\n        k = np.block([[k_11, k_12], [k_21, k_22]])\n\n        # This is a hack, is it not? Must get to the bottom of this...\n        # It seems it is a hack...\n        p = np.block([p_r + en * t_m @ p_l, p_i])\n        return k, p",
  "def reorder(self, u_original: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Re-order the displacement vector correctly, so that the deflections\n        may be applied to the correct nodes.\n\n        If not cyclic symmetry is detected in the FiniteElementModel, simply\n        returns u_original.\n\n        Parameters\n        ----------\n        u_original:\n            The original deflection vector\n\n        Returns\n        -------\n        The re-ordered deflection vector\n        \"\"\"\n        if not self.cycle_sym_ids:\n            # Do nothing\n            return u_original\n\n        u_ordered = np.zeros((6 * self.geometry.n_nodes,))\n        left, right, interior = self.selections\n\n        u_right = u_original[: len(right)]\n        u_left = self.t_matrix.T @ u_right\n        u_interior = u_original[len(right) :]\n\n        u_ordered[interior] = u_interior\n        u_ordered[right] = u_right\n        u_ordered[left] = u_left\n\n        return u_ordered",
  "class StructuralError(BluemiraError):\n    \"\"\"\n    Structural base error\n    \"\"\"\n\n    pass",
  "def hermite_displacement(n: int) -> np.ndarray:\n    \"\"\"\n    \\t:math:`v(x)`\n    \"\"\"\n    x = np.linspace(0, 1, n)\n    matrix = np.zeros((n, 4))\n    matrix[:, 0] = 1 - 3 * x**2 + 2 * x**3\n    matrix[:, 1] = x - 2 * x**2 + x**3\n    matrix[:, 2] = 3 * x**2 - 2 * x**3\n    matrix[:, 3] = -(x**2) + x**3\n    return matrix",
  "def hermite_curvature(n: int) -> np.ndarray:\n    \"\"\"\n    \\t:math:`M = EI\\\\dfrac{\\\\partial^2 v}{\\\\partial^2 x}`\n    \"\"\"\n    x = np.linspace(0, 1, n)\n    matrix = np.zeros((n, 4))\n    matrix[:, 0] = -6 + 12 * x\n    matrix[:, 1] = -4 + 6 * x\n    matrix[:, 2] = 6 - 12 * x\n    matrix[:, 3] = -2 + 6 * x\n    return matrix",
  "def hermite_shear(n: int) -> np.ndarray:\n    \"\"\"\n    \\t:math:`V = EI\\\\dfrac{\\\\partial^3 v}{\\\\partial^3 x}`\n    \"\"\"\n    matrix = np.zeros((n, 4))\n    matrix[:, 0] = 12 * np.ones(n)\n    matrix[:, 1] = 6 * np.ones(n)\n    matrix[:, 2] = -12 * np.ones(n)\n    matrix[:, 3] = 6 * np.ones(n)\n    return matrix",
  "def hermite_polynomials(n: int) -> List[np.ndarray]:\n    \"\"\"\n    Calculate all the base Hermite polynomials\n\n    Parameters\n    ----------\n    n:\n        The number of interpolation points\n    \"\"\"\n    # NOTE: still need [:, 1] and [:, 3] to be multiplied by element length\n    n_1 = hermite_displacement(n)\n    n_2 = hermite_curvature(n)\n    n_3 = hermite_shear(n)\n    return [n_1, n_2, n_3]",
  "class Node:\n    \"\"\"\n    A 3-D node point\n\n    Parameters\n    ----------\n    x:\n        The node global x coordinate\n    y:\n        The node global y coordinate\n    z:\n        The node global z coordinate\n    id_number:\n        The node number in the finite element model\n    \"\"\"\n\n    __slots__ = (\n        \"x\",\n        \"y\",\n        \"z\",\n        \"id_number\",\n        \"displacements\",\n        \"supports\",\n        \"symmetry\",\n        \"loads\",\n        \"reactions\",\n        \"connections\",\n    )\n\n    def __init__(self, x: float, y: float, z: float, id_number: int):\n        self.x = x\n        self.y = y\n        self.z = z\n        self.id_number = id_number\n\n        self.loads = []\n        self.supports = np.zeros(6, dtype=bool)  # Defaults to False\n        self.symmetry = False\n        self.displacements = np.zeros(6, dtype=float)\n        self.reactions = np.zeros(6, dtype=float)\n        self.connections = set()\n\n    @property\n    def xyz(self) -> np.ndarray:\n        \"\"\"\n        Coordinate vector\n\n        Returns\n        -------\n        The x-y-z coordinate vector of the Node (3)\n        \"\"\"\n        return np.array([self.x, self.y, self.z])\n\n    @xyz.setter\n    def xyz(self, xyz: np.ndarray):\n        \"\"\"\n        Sets the Node coordinates\n\n        Parameters\n        ----------\n        xyz:\n            The x-y-z coordinate vector of the Node (3)\n        \"\"\"\n        self.x, self.y, self.z = xyz\n\n    def distance_to_other(self, node) -> float:\n        \"\"\"\n        Calculates the distance to another Node\n\n        Parameters\n        ----------\n        node:\n            The other node\n\n        Returns\n        -------\n        The absolute distance between the two nodes\n        \"\"\"\n        return np.sqrt(\n            (node.x - self.x) ** 2 + (node.y - self.y) ** 2 + (node.z - self.z) ** 2\n        )\n\n    def add_load(self, load: Dict[str, float]):\n        \"\"\"\n        Applies a load to the Node object.\n\n        Parameters\n        ----------\n        load:\n            The dictionary of nodal load values (always in global coordinates)\n        \"\"\"\n        self.loads.append(load)\n\n    def clear_loads(self):\n        \"\"\"\n        Clear all loads and displacements applied to the Node\n        \"\"\"\n        self.loads = []\n        self.displacements = np.zeros(6, dtype=np.float32)\n\n    def clear_supports(self):\n        \"\"\"\n        Clears all supported DOFs applied to the Node\n        \"\"\"\n        self.supports = np.zeros(6, dtype=bool)  # Defaults to False\n\n    def add_support(self, supports: np.ndarray):\n        \"\"\"\n        Define a support condition at the Node\n\n        Parameters\n        ----------\n        supports:\n            A boolean vector of the support DOFs, [dx, dy, dz, rx, ry, rz]:\n                True == supported\n                False == free\n        \"\"\"\n        self.supports = supports\n\n    def add_connection(self, elem_id: int):\n        \"\"\"\n        Add a connection to the Node.\n\n        Parameters\n        ----------\n        elem_id:\n            The Element id_number which is connected to this Node\n        \"\"\"\n        self.connections.add(elem_id)\n\n    def remove_connection(self, elem_id: int):\n        \"\"\"\n        Remove a connection to the Node.\n\n        Parameters\n        ----------\n        elem_id:\n            The Element id_number which is to be disconnected from this Node\n        \"\"\"\n        self.connections.remove(elem_id)\n\n    def p_vector(self) -> np.ndarray:\n        \"\"\"\n        Global nodal force vector\n\n        Returns\n        -------\n        nfv: np.array(6)\n            The global nodal force vector\n        \"\"\"\n        nfv = np.zeros(6)\n        for load in self.loads:\n            if load[\"type\"] == \"Node Load\":\n                nfv += node_load(load[\"Q\"], load[\"sub_type\"])\n            else:\n                raise StructuralError(\n                    f'Cannot apply load type \"{load[\"type\"]}\" to' \" a Node.\"\n                )\n        return nfv\n\n    def __eq__(self, other) -> bool:\n        \"\"\"\n        Checks the Node for equality to another Node.\n\n        In practice this is used to check for Node coincidence.\n\n        Parameters\n        ----------\n        other:\n            The other Node to check for equality\n\n        Returns\n        -------\n        Whether or not the nodes are coincident\n        \"\"\"\n        if isinstance(self, other.__class__):\n            return self.distance_to_other(other) <= D_TOLERANCE\n\n        return False\n\n    __hash__ = None",
  "def get_midpoint(node1: Node, node2: Node) -> Tuple[float, float, float]:\n    \"\"\"\n    Calculates the mid-point between two 3-D nodes\n\n    Parameters\n    ----------\n    node1:\n        First node\n    node2:\n        Second node\n\n    Returns\n    -------\n    The coordinates of the mid-point\n    \"\"\"\n    return (\n        0.5 * (node1.x + node2.x),\n        0.5 * (node1.y + node2.y),\n        0.5 * (node1.z + node2.z),\n    )",
  "def __init__(self, x: float, y: float, z: float, id_number: int):\n        self.x = x\n        self.y = y\n        self.z = z\n        self.id_number = id_number\n\n        self.loads = []\n        self.supports = np.zeros(6, dtype=bool)  # Defaults to False\n        self.symmetry = False\n        self.displacements = np.zeros(6, dtype=float)\n        self.reactions = np.zeros(6, dtype=float)\n        self.connections = set()",
  "def xyz(self) -> np.ndarray:\n        \"\"\"\n        Coordinate vector\n\n        Returns\n        -------\n        The x-y-z coordinate vector of the Node (3)\n        \"\"\"\n        return np.array([self.x, self.y, self.z])",
  "def xyz(self, xyz: np.ndarray):\n        \"\"\"\n        Sets the Node coordinates\n\n        Parameters\n        ----------\n        xyz:\n            The x-y-z coordinate vector of the Node (3)\n        \"\"\"\n        self.x, self.y, self.z = xyz",
  "def distance_to_other(self, node) -> float:\n        \"\"\"\n        Calculates the distance to another Node\n\n        Parameters\n        ----------\n        node:\n            The other node\n\n        Returns\n        -------\n        The absolute distance between the two nodes\n        \"\"\"\n        return np.sqrt(\n            (node.x - self.x) ** 2 + (node.y - self.y) ** 2 + (node.z - self.z) ** 2\n        )",
  "def add_load(self, load: Dict[str, float]):\n        \"\"\"\n        Applies a load to the Node object.\n\n        Parameters\n        ----------\n        load:\n            The dictionary of nodal load values (always in global coordinates)\n        \"\"\"\n        self.loads.append(load)",
  "def clear_loads(self):\n        \"\"\"\n        Clear all loads and displacements applied to the Node\n        \"\"\"\n        self.loads = []\n        self.displacements = np.zeros(6, dtype=np.float32)",
  "def clear_supports(self):\n        \"\"\"\n        Clears all supported DOFs applied to the Node\n        \"\"\"\n        self.supports = np.zeros(6, dtype=bool)",
  "def add_support(self, supports: np.ndarray):\n        \"\"\"\n        Define a support condition at the Node\n\n        Parameters\n        ----------\n        supports:\n            A boolean vector of the support DOFs, [dx, dy, dz, rx, ry, rz]:\n                True == supported\n                False == free\n        \"\"\"\n        self.supports = supports",
  "def add_connection(self, elem_id: int):\n        \"\"\"\n        Add a connection to the Node.\n\n        Parameters\n        ----------\n        elem_id:\n            The Element id_number which is connected to this Node\n        \"\"\"\n        self.connections.add(elem_id)",
  "def remove_connection(self, elem_id: int):\n        \"\"\"\n        Remove a connection to the Node.\n\n        Parameters\n        ----------\n        elem_id:\n            The Element id_number which is to be disconnected from this Node\n        \"\"\"\n        self.connections.remove(elem_id)",
  "def p_vector(self) -> np.ndarray:\n        \"\"\"\n        Global nodal force vector\n\n        Returns\n        -------\n        nfv: np.array(6)\n            The global nodal force vector\n        \"\"\"\n        nfv = np.zeros(6)\n        for load in self.loads:\n            if load[\"type\"] == \"Node Load\":\n                nfv += node_load(load[\"Q\"], load[\"sub_type\"])\n            else:\n                raise StructuralError(\n                    f'Cannot apply load type \"{load[\"type\"]}\" to' \" a Node.\"\n                )\n        return nfv",
  "def __eq__(self, other) -> bool:\n        \"\"\"\n        Checks the Node for equality to another Node.\n\n        In practice this is used to check for Node coincidence.\n\n        Parameters\n        ----------\n        other:\n            The other Node to check for equality\n\n        Returns\n        -------\n        Whether or not the nodes are coincident\n        \"\"\"\n        if isinstance(self, other.__class__):\n            return self.distance_to_other(other) <= D_TOLERANCE\n\n        return False",
  "class Geometry:\n    \"\"\"\n    Abstract object for the collection of nodes and elements in the finite\n    element model\n    \"\"\"\n\n    def __init__(self):\n        self.nodes = []\n        self.node_xyz = []\n        self.elements = []\n\n    @property\n    def n_nodes(self) -> int:\n        \"\"\"\n        The number of Nodes in the Geometry. Used to index Nodes.\n\n        Returns\n        -------\n        The number of Nodes in the Geometry.\n        \"\"\"\n        return len(self.nodes)\n\n    @property\n    def n_elements(self) -> int:\n        \"\"\"\n        The number of Elements in the Geometry. Used to index Elements.\n\n        Returns\n        -------\n        The number of Elements in the Geometry.\n        \"\"\"\n        return len(self.elements)\n\n    def add_node(self, x: float, y: float, z: float) -> int:\n        \"\"\"\n        Add a Node to the Geometry object. Will check if an identical Node is\n        already present.\n\n        Parameters\n        ----------\n        x:\n            The node global x coordinate\n        y:\n            The node global y coordinate\n        z:\n            The node global z coordinate\n\n        Returns\n        -------\n        The ID number of the node that was added\n        \"\"\"\n        node = Node(x, y, z, self.n_nodes)\n\n        # Check that the node isn't already in the geometry\n        for other in self.nodes:  # This could be slow, look to hash and set for speed\n            if node == other:\n                # Do not add new node, instead returning existing node id\n                return other.id_number\n\n        self.nodes.append(node)\n        self.node_xyz.append([x, y, z])\n        return node.id_number\n\n    def find_node(self, x: float, y: float, z: float) -> int:\n        \"\"\"\n        Return the node ID if the node coordinates are in the geometry.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate of the node to find\n        y:\n            The y coordinate of the node to find\n        z:\n            The z coordinate of the node to find\n\n        Returns\n        -------\n        The node ID\n        \"\"\"\n        a = np.array(self.node_xyz)\n        b = np.array([x, y, z])\n        d_array = np.sqrt(np.sum((a - b) ** 2, axis=1))\n\n        arg = np.argmin(d_array)\n\n        if d_array[arg] > D_TOLERANCE:\n            closest = self.nodes[arg].id_number\n            proximity = d_array[arg]\n            raise StructuralError(\n                f\"The node: [{x:.2f}, {y:.2f}, {z:.2f}] was not \"\n                \"found in the model.\\n\"\n                f\"Closest node: {closest} at {proximity:.2f} m away\"\n            )\n\n        else:\n            return self.nodes[arg].id_number\n\n    def move_node(self, node_id: int, dx: float = 0.0, dy: float = 0.0, dz: float = 0.0):\n        \"\"\"\n        Move a Node in the Geometry. If the Node is moved to the position\n        of another Node, its connections are transferred, and the Node is\n        removed.\n\n        Parameters\n        ----------\n        node_id:\n            The id_number of the Node to move\n        dx:\n            The x distance to move the Node\n        dy:\n            The y distance to move the Node\n        dz:\n            The z distance to move the Node\n        \"\"\"\n        if np.sqrt(dx**2 + dy**2 + dz**2) <= D_TOLERANCE:\n            return\n\n        moved_node = deepcopy(self.nodes[node_id])\n        moved_node.x += dx\n        moved_node.y += dy\n        moved_node.z += dz\n        # Check that the new Node is not equal to any other nodes\n        for other in self.nodes:\n            if other == moved_node:\n                # Check if there is an Element between the two Nodes\n                for elem_id in moved_node.connections:\n                    if elem_id in other.connections:\n                        # If there is an Element between the moved Node and its\n                        # duplicate, remove it\n                        self.remove_element(elem_id)\n                        # Make a new local copy\n                        moved_node = deepcopy(self.nodes[node_id])\n\n                # Transfer Node connections\n                # Start again, because of potential renumbering\n                for elem_id in moved_node.connections:\n                    other.add_connection(elem_id)\n                    element = self.elements[elem_id]\n                    if element.node_1.id_number == node_id:\n                        element.node_1 = other\n                    else:\n                        element.node_2 = other\n                    element.clear_cache()\n\n                # Remove Node connections (don't remove any Elements)\n                self.nodes[node_id].connections = set()\n                # Remove Node\n                self.remove_node(node_id)\n                break\n        else:\n            # We can safely move the Node\n            self.nodes[node_id] = moved_node\n            # Clear Element caches (Node has moved)\n            for elem_id in moved_node.connections:\n                element = self.elements[elem_id]\n                if node_id == element.node_1.id_number:\n                    element.node_1 = moved_node\n                else:\n                    element.node_2 = moved_node\n                element.clear_cache()\n\n    def remove_node(self, node_id: int):\n        \"\"\"\n        Remove a Node from the Geometry.\n\n        Parameters\n        ----------\n        node_id:\n            The id_number of the Node to remove\n        \"\"\"\n        # Drop the node information from the Geometry\n        dead_node = self.nodes.pop(node_id)\n        self.node_xyz.pop(node_id)\n        # Re-number the remaining Nodes\n        for node in self.nodes[node_id:]:\n            node.id_number -= 1\n\n        # Remove any Elements connected to the dead node\n        # Cycle backwards to avoid re-numbering\n        for elem_id in sorted(deepcopy(dead_node.connections))[::-1]:\n            self.remove_element(elem_id)\n\n    def add_element(\n        self,\n        node_id1: int,\n        node_id2: int,\n        cross_section: CrossSection,\n        material: Optional[StructuralMaterial] = None,\n    ) -> int:\n        \"\"\"\n        Adds an Element to the Geometry object\n\n        Parameters\n        ----------\n        node_id1:\n            The ID number of the first node\n        node_id2:\n            The ID number of the second node\n        cross_section:\n            The CrossSection property object of the element\n        material:\n            The Material property object of the element\n\n        Returns\n        -------\n        The ID number of the element that was added\n        \"\"\"\n        # Check if there is already an Element specified between the Nodes\n        new_element_nodes = sorted([node_id1, node_id2])\n        for elem in self.elements:\n            e_nodes = sorted([elem.node_1.id_number, elem.node_2.id_number])\n\n            if e_nodes == new_element_nodes:\n                # An element already exists here, update properties\n                elem_id = elem.id_number\n\n                element = Element(\n                    self.nodes[node_id1],\n                    self.nodes[node_id2],\n                    elem_id,\n                    cross_section,\n                    material,\n                )\n\n                self.elements[elem_id] = element\n                return elem_id\n\n        # There is no such Element; add a new one to the model\n        element = Element(\n            self.nodes[node_id1],\n            self.nodes[node_id2],\n            self.n_elements,\n            cross_section,\n            material,\n        )\n        self.elements.append(element)\n        # Keep track of Element connectivity\n        self.nodes[node_id1].add_connection(element.id_number)\n        self.nodes[node_id2].add_connection(element.id_number)\n        return element.id_number\n\n    def remove_element(self, elem_id: int):\n        \"\"\"\n        Remove an Element from the Geometry.\n\n        Parameters\n        ----------\n        elem_id:\n            The Element id_number to remove\n        \"\"\"\n        # Drop the Element information from the Geometry\n        self.elements.pop(elem_id)\n        # Re-number the remaining Elements\n        for element in self.elements[elem_id:]:\n            element.id_number -= 1\n\n        # Re-number node connections\n        for node in self.nodes:\n            connections = sorted(deepcopy(node.connections))\n            new_connections = set()\n            for connection in connections:\n                if connection == elem_id:\n                    # Drop connection to dead Element\n                    pass\n                elif connection > elem_id:\n                    # Re-number connection\n                    new_connections.add(connection - 1)\n                else:\n                    # Preserve connection\n                    new_connections.add(connection)\n            node.connections = new_connections\n\n    def add_coordinates(\n        self,\n        coordinates: Coordinates,\n        cross_section: CrossSection,\n        material: Optional[StructuralMaterial] = None,\n    ):\n        \"\"\"\n        Adds a Coordinates object to the Geometry\n\n        Parameters\n        ----------\n        coordinates:\n            The coordinates to transform into connected Nodes and Elements\n        cross_section:\n            The cross section of all the Elements in the Coordinates\n        material:\n            The material of all the Elements in the Coordinates\n        \"\"\"\n        n_start = self.add_node(*coordinates.points[0])  # Add first Node\n\n        n1 = n_start\n        for point in coordinates.points[1:]:\n            n2 = self.add_node(*point)\n            self.add_element(n1, n2, cross_section, material)\n            n1 = n2\n\n        if coordinates.closed:\n            self.add_element(n2, n_start, cross_section, material)\n\n    def k_matrix(self) -> np.ndarray:\n        \"\"\"\n        Builds the global stiffness matrix K\n\n        Returns\n        -------\n        The global stiffness matrix of the Geometry ((6*n_nodes, 6*n_nodes))\n        \"\"\"\n        # Explore how scipy sparse matrices or numba fares on this\n        k = np.zeros((6 * self.n_nodes, 6 * self.n_nodes))\n        # Loop through elements, adding local stiffness matrices into global\n        for element in self.elements:\n            k_elem = element.k_matrix_glob\n            i = 6 * element.node_1.id_number\n            j = 6 * element.node_2.id_number\n            k[i : i + 6, i : i + 6] += k_elem[:6, :6]\n            k[i : i + 6, j : j + 6] += k_elem[:6, 6:]\n            k[j : j + 6, i : i + 6] += k_elem[6:, :6]\n            k[j : j + 6, j : j + 6] += k_elem[6:, 6:]\n        return k\n\n    def k_matrix_sparse(self) -> lil_matrix:\n        \"\"\"\n        Builds the sparse global stiffness matrix K\n\n        Returns\n        -------\n        The sparse global stiffness matrix of the Geometry ((6*n_nodes, 6*n_nodes))\n        \"\"\"\n        k = lil_matrix((6 * self.n_nodes, 6 * self.n_nodes))\n        # Loop through elements, adding local stiffness matrices into global\n        for element in self.elements:\n            k_elem = element.k_matrix_glob\n            i = 6 * element.node_1.id_number\n            j = 6 * element.node_2.id_number\n            k[i : i + 6, i : i + 6] += k_elem[:6, :6]\n            k[i : i + 6, j : j + 6] += k_elem[:6, 6:]\n            k[j : j + 6, i : i + 6] += k_elem[6:, :6]\n            k[j : j + 6, j : j + 6] += k_elem[6:, 6:]\n        return k\n\n    def bounds(self) -> Tuple[float, float, float, float, float, float]:\n        \"\"\"\n        Calculates the bounds of the geometry\n        \"\"\"\n        x = [node.x for node in self.nodes]\n        y = [node.y for node in self.nodes]\n        z = [node.z for node in self.nodes]\n        return max(x), min(x), max(y), min(y), max(z), min(z)\n\n    def bounding_box(self) -> BoundingBox:\n        \"\"\"\n        Calculates a bounding box for the Geometry object\n\n        Returns\n        -------\n        BoundingBox rectangular cuboid of the geometry\n        \"\"\"\n        x = np.array([node.x for node in self.nodes])\n        y = np.array([node.y for node in self.nodes])\n        z = np.array([node.z for node in self.nodes])\n        return BoundingBox.from_xyz(x, y, z).get_box_arrays()\n\n    def interpolate(self, scale: float = 100.0):\n        \"\"\"\n        Interpolates the geometry model between Nodes\n        \"\"\"\n        for element in self.elements:\n            element.interpolate(scale=scale)\n\n    def rotate(self, t_matrix: np.ndarray):\n        \"\"\"\n        Rotates a geometry by updating the positions of all nodes and their\n        global displacements\n\n        Parameters\n        ----------\n        t_matrix:\n            The rotation matrix to use\n        \"\"\"\n        for node in self.nodes:\n            # Move all the nodes\n            node.xyz = t_matrix @ node.xyz\n\n            # Update their displacements\n            node.displacements[:3] = t_matrix @ node.displacements[:3]\n            node.displacements[3:] = t_matrix @ node.displacements[3:]\n\n        # Reset all the cached lambda matrices in the elements so that they are\n        # re-calculated to account for new node positions\n        for element in self.elements:\n            element._lambda_matrix = None\n\n    def transfer_node(self, node: Node):\n        \"\"\"\n        Transfer a Node into the Geometry, copying all its state.\n\n        Parameters\n        ----------\n        node:\n            The Node to transfer into the geometry\n        \"\"\"\n        id_number = self.add_node(*node.xyz)\n        added_node = self.nodes[id_number]\n        # Transfer node boundary conditions\n        added_node.symmetry = node.symmetry\n        added_node.supports = node.supports\n        # Transfer node loads\n        added_node.loads = node.loads\n        # Transfer node displacements\n        added_node.displacements = node.displacements\n        return id_number\n\n    def merge(self, other: Geometry):\n        \"\"\"\n        Combine geometry object with another\n\n        Parameters\n        ----------\n        other:\n            The geometry to combine with\n\n        Notes\n        -----\n        Will copy across Node and Element loads, BCs, displacements, and\n        stress information\n        \"\"\"\n\n        def transfer_loads(old, new):\n            if old.loads:\n                loads = []\n                for load in old.loads:\n                    load[\"element_id\"] = new.id_number\n                    loads.append(load)\n                new.loads = loads\n\n        # Walk through elements\n        for element in other.elements:\n            # Add nodes (will auto-check for existing nodes and return IDs)\n            id_1 = self.transfer_node(element.node_1)\n            id_2 = self.transfer_node(element.node_2)\n            # Add element\n            self.add_element(id_1, id_2, element._cross_section, element._material)\n            added_element = self.elements[-1]\n            # Transfer element loads\n            transfer_loads(element, added_element)\n            # Transfer element results\n            added_element.shapes = element.shapes\n            added_element.stresses = element.stresses\n            added_element.max_stress = element.max_stress\n            added_element.safety_factor = element.safety_factor\n\n    def plot(self, ax=None, **kwargs):\n        \"\"\"\n        Plot the Geometry.\n\n        Parameters\n        ----------\n        ax: Union[Axes, None]\n            The matplotlib Axes upon which to plot\n        \"\"\"\n        return GeometryPlotter(self, ax=ax, **kwargs)",
  "class DeformedGeometry(Geometry):\n    \"\"\"\n    Abstract object for the collection of nodes and elements in the finite\n    element model, with the ability to be deformed.\n    \"\"\"\n\n    def __init__(self, geometry: Geometry, scale: float):\n        geometry = deepcopy(geometry)\n        self.nodes = geometry.nodes\n        self.node_xyz = geometry.node_xyz\n        self.elements = geometry.elements\n        self._scale = scale\n\n        self.deform()\n        self.interpolate(scale)\n\n    def deform(self):\n        \"\"\"\n        Deform the Geometry by displacing the nodes by their deflections.\n        \"\"\"\n        for node in self.nodes:\n            node.x += node.displacements[0] * self._scale\n            node.y += node.displacements[1] * self._scale\n            node.z += node.displacements[2] * self._scale\n            node.displacements[0] = 0\n            node.displacements[1] = 0\n            node.displacements[2] = 0\n\n    def plot(\n        self, ax: Optional[Axes] = None, stress: Optional[np.ndarray] = None, **kwargs\n    ):\n        \"\"\"\n        Plot the DeformedGeometry.\n\n        Parameters\n        ----------\n        ax:\n            The matplotlib Axes upon which to plot\n        stress:\n            The stress values to use (if any) when plotting\n        \"\"\"\n        if stress is None:\n            return DeformedGeometryPlotter(self, ax=ax, **kwargs)\n        else:\n            return StressDeformedGeometryPlotter(self, ax=ax, stress=stress, **kwargs)",
  "def __init__(self):\n        self.nodes = []\n        self.node_xyz = []\n        self.elements = []",
  "def n_nodes(self) -> int:\n        \"\"\"\n        The number of Nodes in the Geometry. Used to index Nodes.\n\n        Returns\n        -------\n        The number of Nodes in the Geometry.\n        \"\"\"\n        return len(self.nodes)",
  "def n_elements(self) -> int:\n        \"\"\"\n        The number of Elements in the Geometry. Used to index Elements.\n\n        Returns\n        -------\n        The number of Elements in the Geometry.\n        \"\"\"\n        return len(self.elements)",
  "def add_node(self, x: float, y: float, z: float) -> int:\n        \"\"\"\n        Add a Node to the Geometry object. Will check if an identical Node is\n        already present.\n\n        Parameters\n        ----------\n        x:\n            The node global x coordinate\n        y:\n            The node global y coordinate\n        z:\n            The node global z coordinate\n\n        Returns\n        -------\n        The ID number of the node that was added\n        \"\"\"\n        node = Node(x, y, z, self.n_nodes)\n\n        # Check that the node isn't already in the geometry\n        for other in self.nodes:  # This could be slow, look to hash and set for speed\n            if node == other:\n                # Do not add new node, instead returning existing node id\n                return other.id_number\n\n        self.nodes.append(node)\n        self.node_xyz.append([x, y, z])\n        return node.id_number",
  "def find_node(self, x: float, y: float, z: float) -> int:\n        \"\"\"\n        Return the node ID if the node coordinates are in the geometry.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate of the node to find\n        y:\n            The y coordinate of the node to find\n        z:\n            The z coordinate of the node to find\n\n        Returns\n        -------\n        The node ID\n        \"\"\"\n        a = np.array(self.node_xyz)\n        b = np.array([x, y, z])\n        d_array = np.sqrt(np.sum((a - b) ** 2, axis=1))\n\n        arg = np.argmin(d_array)\n\n        if d_array[arg] > D_TOLERANCE:\n            closest = self.nodes[arg].id_number\n            proximity = d_array[arg]\n            raise StructuralError(\n                f\"The node: [{x:.2f}, {y:.2f}, {z:.2f}] was not \"\n                \"found in the model.\\n\"\n                f\"Closest node: {closest} at {proximity:.2f} m away\"\n            )\n\n        else:\n            return self.nodes[arg].id_number",
  "def move_node(self, node_id: int, dx: float = 0.0, dy: float = 0.0, dz: float = 0.0):\n        \"\"\"\n        Move a Node in the Geometry. If the Node is moved to the position\n        of another Node, its connections are transferred, and the Node is\n        removed.\n\n        Parameters\n        ----------\n        node_id:\n            The id_number of the Node to move\n        dx:\n            The x distance to move the Node\n        dy:\n            The y distance to move the Node\n        dz:\n            The z distance to move the Node\n        \"\"\"\n        if np.sqrt(dx**2 + dy**2 + dz**2) <= D_TOLERANCE:\n            return\n\n        moved_node = deepcopy(self.nodes[node_id])\n        moved_node.x += dx\n        moved_node.y += dy\n        moved_node.z += dz\n        # Check that the new Node is not equal to any other nodes\n        for other in self.nodes:\n            if other == moved_node:\n                # Check if there is an Element between the two Nodes\n                for elem_id in moved_node.connections:\n                    if elem_id in other.connections:\n                        # If there is an Element between the moved Node and its\n                        # duplicate, remove it\n                        self.remove_element(elem_id)\n                        # Make a new local copy\n                        moved_node = deepcopy(self.nodes[node_id])\n\n                # Transfer Node connections\n                # Start again, because of potential renumbering\n                for elem_id in moved_node.connections:\n                    other.add_connection(elem_id)\n                    element = self.elements[elem_id]\n                    if element.node_1.id_number == node_id:\n                        element.node_1 = other\n                    else:\n                        element.node_2 = other\n                    element.clear_cache()\n\n                # Remove Node connections (don't remove any Elements)\n                self.nodes[node_id].connections = set()\n                # Remove Node\n                self.remove_node(node_id)\n                break\n        else:\n            # We can safely move the Node\n            self.nodes[node_id] = moved_node\n            # Clear Element caches (Node has moved)\n            for elem_id in moved_node.connections:\n                element = self.elements[elem_id]\n                if node_id == element.node_1.id_number:\n                    element.node_1 = moved_node\n                else:\n                    element.node_2 = moved_node\n                element.clear_cache()",
  "def remove_node(self, node_id: int):\n        \"\"\"\n        Remove a Node from the Geometry.\n\n        Parameters\n        ----------\n        node_id:\n            The id_number of the Node to remove\n        \"\"\"\n        # Drop the node information from the Geometry\n        dead_node = self.nodes.pop(node_id)\n        self.node_xyz.pop(node_id)\n        # Re-number the remaining Nodes\n        for node in self.nodes[node_id:]:\n            node.id_number -= 1\n\n        # Remove any Elements connected to the dead node\n        # Cycle backwards to avoid re-numbering\n        for elem_id in sorted(deepcopy(dead_node.connections))[::-1]:\n            self.remove_element(elem_id)",
  "def add_element(\n        self,\n        node_id1: int,\n        node_id2: int,\n        cross_section: CrossSection,\n        material: Optional[StructuralMaterial] = None,\n    ) -> int:\n        \"\"\"\n        Adds an Element to the Geometry object\n\n        Parameters\n        ----------\n        node_id1:\n            The ID number of the first node\n        node_id2:\n            The ID number of the second node\n        cross_section:\n            The CrossSection property object of the element\n        material:\n            The Material property object of the element\n\n        Returns\n        -------\n        The ID number of the element that was added\n        \"\"\"\n        # Check if there is already an Element specified between the Nodes\n        new_element_nodes = sorted([node_id1, node_id2])\n        for elem in self.elements:\n            e_nodes = sorted([elem.node_1.id_number, elem.node_2.id_number])\n\n            if e_nodes == new_element_nodes:\n                # An element already exists here, update properties\n                elem_id = elem.id_number\n\n                element = Element(\n                    self.nodes[node_id1],\n                    self.nodes[node_id2],\n                    elem_id,\n                    cross_section,\n                    material,\n                )\n\n                self.elements[elem_id] = element\n                return elem_id\n\n        # There is no such Element; add a new one to the model\n        element = Element(\n            self.nodes[node_id1],\n            self.nodes[node_id2],\n            self.n_elements,\n            cross_section,\n            material,\n        )\n        self.elements.append(element)\n        # Keep track of Element connectivity\n        self.nodes[node_id1].add_connection(element.id_number)\n        self.nodes[node_id2].add_connection(element.id_number)\n        return element.id_number",
  "def remove_element(self, elem_id: int):\n        \"\"\"\n        Remove an Element from the Geometry.\n\n        Parameters\n        ----------\n        elem_id:\n            The Element id_number to remove\n        \"\"\"\n        # Drop the Element information from the Geometry\n        self.elements.pop(elem_id)\n        # Re-number the remaining Elements\n        for element in self.elements[elem_id:]:\n            element.id_number -= 1\n\n        # Re-number node connections\n        for node in self.nodes:\n            connections = sorted(deepcopy(node.connections))\n            new_connections = set()\n            for connection in connections:\n                if connection == elem_id:\n                    # Drop connection to dead Element\n                    pass\n                elif connection > elem_id:\n                    # Re-number connection\n                    new_connections.add(connection - 1)\n                else:\n                    # Preserve connection\n                    new_connections.add(connection)\n            node.connections = new_connections",
  "def add_coordinates(\n        self,\n        coordinates: Coordinates,\n        cross_section: CrossSection,\n        material: Optional[StructuralMaterial] = None,\n    ):\n        \"\"\"\n        Adds a Coordinates object to the Geometry\n\n        Parameters\n        ----------\n        coordinates:\n            The coordinates to transform into connected Nodes and Elements\n        cross_section:\n            The cross section of all the Elements in the Coordinates\n        material:\n            The material of all the Elements in the Coordinates\n        \"\"\"\n        n_start = self.add_node(*coordinates.points[0])  # Add first Node\n\n        n1 = n_start\n        for point in coordinates.points[1:]:\n            n2 = self.add_node(*point)\n            self.add_element(n1, n2, cross_section, material)\n            n1 = n2\n\n        if coordinates.closed:\n            self.add_element(n2, n_start, cross_section, material)",
  "def k_matrix(self) -> np.ndarray:\n        \"\"\"\n        Builds the global stiffness matrix K\n\n        Returns\n        -------\n        The global stiffness matrix of the Geometry ((6*n_nodes, 6*n_nodes))\n        \"\"\"\n        # Explore how scipy sparse matrices or numba fares on this\n        k = np.zeros((6 * self.n_nodes, 6 * self.n_nodes))\n        # Loop through elements, adding local stiffness matrices into global\n        for element in self.elements:\n            k_elem = element.k_matrix_glob\n            i = 6 * element.node_1.id_number\n            j = 6 * element.node_2.id_number\n            k[i : i + 6, i : i + 6] += k_elem[:6, :6]\n            k[i : i + 6, j : j + 6] += k_elem[:6, 6:]\n            k[j : j + 6, i : i + 6] += k_elem[6:, :6]\n            k[j : j + 6, j : j + 6] += k_elem[6:, 6:]\n        return k",
  "def k_matrix_sparse(self) -> lil_matrix:\n        \"\"\"\n        Builds the sparse global stiffness matrix K\n\n        Returns\n        -------\n        The sparse global stiffness matrix of the Geometry ((6*n_nodes, 6*n_nodes))\n        \"\"\"\n        k = lil_matrix((6 * self.n_nodes, 6 * self.n_nodes))\n        # Loop through elements, adding local stiffness matrices into global\n        for element in self.elements:\n            k_elem = element.k_matrix_glob\n            i = 6 * element.node_1.id_number\n            j = 6 * element.node_2.id_number\n            k[i : i + 6, i : i + 6] += k_elem[:6, :6]\n            k[i : i + 6, j : j + 6] += k_elem[:6, 6:]\n            k[j : j + 6, i : i + 6] += k_elem[6:, :6]\n            k[j : j + 6, j : j + 6] += k_elem[6:, 6:]\n        return k",
  "def bounds(self) -> Tuple[float, float, float, float, float, float]:\n        \"\"\"\n        Calculates the bounds of the geometry\n        \"\"\"\n        x = [node.x for node in self.nodes]\n        y = [node.y for node in self.nodes]\n        z = [node.z for node in self.nodes]\n        return max(x), min(x), max(y), min(y), max(z), min(z)",
  "def bounding_box(self) -> BoundingBox:\n        \"\"\"\n        Calculates a bounding box for the Geometry object\n\n        Returns\n        -------\n        BoundingBox rectangular cuboid of the geometry\n        \"\"\"\n        x = np.array([node.x for node in self.nodes])\n        y = np.array([node.y for node in self.nodes])\n        z = np.array([node.z for node in self.nodes])\n        return BoundingBox.from_xyz(x, y, z).get_box_arrays()",
  "def interpolate(self, scale: float = 100.0):\n        \"\"\"\n        Interpolates the geometry model between Nodes\n        \"\"\"\n        for element in self.elements:\n            element.interpolate(scale=scale)",
  "def rotate(self, t_matrix: np.ndarray):\n        \"\"\"\n        Rotates a geometry by updating the positions of all nodes and their\n        global displacements\n\n        Parameters\n        ----------\n        t_matrix:\n            The rotation matrix to use\n        \"\"\"\n        for node in self.nodes:\n            # Move all the nodes\n            node.xyz = t_matrix @ node.xyz\n\n            # Update their displacements\n            node.displacements[:3] = t_matrix @ node.displacements[:3]\n            node.displacements[3:] = t_matrix @ node.displacements[3:]\n\n        # Reset all the cached lambda matrices in the elements so that they are\n        # re-calculated to account for new node positions\n        for element in self.elements:\n            element._lambda_matrix = None",
  "def transfer_node(self, node: Node):\n        \"\"\"\n        Transfer a Node into the Geometry, copying all its state.\n\n        Parameters\n        ----------\n        node:\n            The Node to transfer into the geometry\n        \"\"\"\n        id_number = self.add_node(*node.xyz)\n        added_node = self.nodes[id_number]\n        # Transfer node boundary conditions\n        added_node.symmetry = node.symmetry\n        added_node.supports = node.supports\n        # Transfer node loads\n        added_node.loads = node.loads\n        # Transfer node displacements\n        added_node.displacements = node.displacements\n        return id_number",
  "def merge(self, other: Geometry):\n        \"\"\"\n        Combine geometry object with another\n\n        Parameters\n        ----------\n        other:\n            The geometry to combine with\n\n        Notes\n        -----\n        Will copy across Node and Element loads, BCs, displacements, and\n        stress information\n        \"\"\"\n\n        def transfer_loads(old, new):\n            if old.loads:\n                loads = []\n                for load in old.loads:\n                    load[\"element_id\"] = new.id_number\n                    loads.append(load)\n                new.loads = loads\n\n        # Walk through elements\n        for element in other.elements:\n            # Add nodes (will auto-check for existing nodes and return IDs)\n            id_1 = self.transfer_node(element.node_1)\n            id_2 = self.transfer_node(element.node_2)\n            # Add element\n            self.add_element(id_1, id_2, element._cross_section, element._material)\n            added_element = self.elements[-1]\n            # Transfer element loads\n            transfer_loads(element, added_element)\n            # Transfer element results\n            added_element.shapes = element.shapes\n            added_element.stresses = element.stresses\n            added_element.max_stress = element.max_stress\n            added_element.safety_factor = element.safety_factor",
  "def plot(self, ax=None, **kwargs):\n        \"\"\"\n        Plot the Geometry.\n\n        Parameters\n        ----------\n        ax: Union[Axes, None]\n            The matplotlib Axes upon which to plot\n        \"\"\"\n        return GeometryPlotter(self, ax=ax, **kwargs)",
  "def __init__(self, geometry: Geometry, scale: float):\n        geometry = deepcopy(geometry)\n        self.nodes = geometry.nodes\n        self.node_xyz = geometry.node_xyz\n        self.elements = geometry.elements\n        self._scale = scale\n\n        self.deform()\n        self.interpolate(scale)",
  "def deform(self):\n        \"\"\"\n        Deform the Geometry by displacing the nodes by their deflections.\n        \"\"\"\n        for node in self.nodes:\n            node.x += node.displacements[0] * self._scale\n            node.y += node.displacements[1] * self._scale\n            node.z += node.displacements[2] * self._scale\n            node.displacements[0] = 0\n            node.displacements[1] = 0\n            node.displacements[2] = 0",
  "def plot(\n        self, ax: Optional[Axes] = None, stress: Optional[np.ndarray] = None, **kwargs\n    ):\n        \"\"\"\n        Plot the DeformedGeometry.\n\n        Parameters\n        ----------\n        ax:\n            The matplotlib Axes upon which to plot\n        stress:\n            The stress values to use (if any) when plotting\n        \"\"\"\n        if stress is None:\n            return DeformedGeometryPlotter(self, ax=ax, **kwargs)\n        else:\n            return StressDeformedGeometryPlotter(self, ax=ax, stress=stress, **kwargs)",
  "def transfer_loads(old, new):\n            if old.loads:\n                loads = []\n                for load in old.loads:\n                    load[\"element_id\"] = new.id_number\n                    loads.append(load)\n                new.loads = loads",
  "def get_default_options() -> dict:\n    \"\"\"\n    Returns the default display options.\n    \"\"\"\n    return copy.deepcopy(DEFAULT_MESH_OPTIONS)",
  "class MeshOptions:\n    \"\"\"\n    The options that are available for meshing objects.\n    \"\"\"\n\n    def __init__(self, **kwargs):\n        self._options = get_default_options()\n        self.modify(**kwargs)\n\n    @property\n    def lcar(self) -> float:\n        \"\"\"\n        Mesh size of points.\n        \"\"\"\n        return self._options[\"lcar\"]\n\n    @lcar.setter\n    def lcar(self, val: float):\n        self._options[\"lcar\"] = val\n\n    @property\n    def physical_group(self):\n        \"\"\"\n        Definition of physical groups.\n        \"\"\"\n        return self._options[\"physical_group\"]\n\n    @physical_group.setter\n    def physical_group(self, val: float):\n        self._options[\"physical_group\"] = val\n\n    def as_dict(self) -> dict:\n        \"\"\"\n        Returns the instance as a dictionary.\n        \"\"\"\n        return copy.deepcopy(self._options)\n\n    def modify(self, **kwargs):\n        \"\"\"\n        Function to override meshing options.\n        \"\"\"\n        if kwargs:\n            for k in kwargs:\n                if k in self._options:\n                    self._options[k] = kwargs[k]\n\n    def __repr__(self):\n        \"\"\"\n        Representation string of the DisplayOptions.\n        \"\"\"\n        return f\"{self.__class__.__name__}({pprint.pformat(self._options)}\" + \"\\n)\"",
  "class Meshable:\n    \"\"\"Mixin class to make a class meshable\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self._mesh_options = MeshOptions()\n\n    @property\n    def mesh_options(self) -> MeshOptions:\n        \"\"\"\n        The options that will be used to mesh the object.\n        \"\"\"\n        return self._mesh_options\n\n    @mesh_options.setter\n    def mesh_options(self, value: Union[MeshOptions, Dict]):\n        if isinstance(value, MeshOptions):\n            self._mesh_options = value\n        elif isinstance(value, Dict):\n            if self.mesh_options is None:\n                self.mesh_options = MeshOptions()\n            self.mesh_options.modify(**value)\n        else:\n            raise MeshOptionsError(\"Mesh options must be set to a MeshOptions instance.\")",
  "class Mesh:\n    \"\"\"\n    A class for supporting the creation of meshes and writing out those meshes to files.\n    \"\"\"\n\n    def __init__(\n        self,\n        modelname: str = \"Mesh\",\n        terminal: int = 0,\n        meshfile: Optional[Union[str, List[str]]] = None,\n        logfile: str = \"gmsh.log\",\n    ):\n        self.modelname = modelname\n        self.terminal = terminal\n        self.meshfile = (\n            [\"Mesh.geo_unrolled\", \"Mesh.msh\"] if meshfile is None else meshfile\n        )\n        self.logfile = logfile\n\n    def _check_meshfile(self, meshfile: Union[str, list]) -> List[str]:\n        \"\"\"\n        Check the mesh file input.\n        \"\"\"\n        # todo: should be implemented also a check on the file extension. Only a\n        # limited type of file extensions is allowed by gmsh.\n        if isinstance(meshfile, str):\n            meshfile = [meshfile]\n        elif isinstance(meshfile, list):\n            if len(meshfile) < 1:\n                raise ValueError(\"meshfile is an empty list\")\n        else:\n            raise ValueError(\"meshfile must be a string or a list of strings\")\n        return meshfile\n\n    @property\n    def meshfile(self) -> List[str]:\n        \"\"\"\n        The path(s) to the file(s) containing the meshes.\n        \"\"\"\n        return self._meshfile\n\n    @meshfile.setter\n    def meshfile(self, meshfile: Union[str, List[str]]):\n        self._meshfile = self._check_meshfile(meshfile)\n\n    def __call__(self, obj: Union[Component, Meshable], dim: int = 2):\n        \"\"\"\n        Generate the mesh and save it to file.\n        \"\"\"\n        bluemira_print(\"Starting mesh process...\")\n\n        if \"Component\" in [c.__name__ for c in inspect.getmro(type(obj))]:\n            from bluemira.base.tools import create_compound_from_component\n\n            obj = create_compound_from_component(obj)\n\n        if isinstance(obj, Meshable):\n            # gmsh is initialized\n            _FreeCADGmsh._initialize_mesh(self.terminal, self.modelname)\n            # Mesh the object. A dictionary with the geometrical and internal\n            # information that are used by gmsh is returned. In particular,\n            # a gmsh key is added to any meshed entity.\n            buffer = self.__mesh_obj(obj, dim=dim)\n            # Check for possible intersection (only allowed at the boundary to adjust\n            # the gmsh_dictionary\n            Mesh.__iterate_gmsh_dict(buffer, Mesh._check_intersections)\n\n            # Create the physical groups\n            self._apply_physical_group(buffer)\n\n            # apply the mesh size\n            self._apply_mesh_size(buffer)\n\n            # generate the mesh\n            _FreeCADGmsh._generate_mesh()\n\n            # save the mesh file\n            for file in self.meshfile:\n                _FreeCADGmsh._save_mesh(file)\n\n            # close gmsh\n            _FreeCADGmsh._finalize_mesh(self.logfile)\n        else:\n            raise ValueError(\"Only Meshable objects can be meshed\")\n\n        bluemira_print(\"Mesh process completed.\")\n\n        return buffer\n\n    def __mesh_obj(self, obj, dim: int):\n        \"\"\"\n        Function to mesh the object.\n        \"\"\"\n        from bluemira.geometry.tools import serialize_shape\n\n        if not hasattr(obj, \"ismeshed\") or not obj.ismeshed:\n            # object is serialized into a dictionary\n            if obj.__class__.__name__ in SUPPORTED_GEOS:\n                buffer = serialize_shape(obj)\n            else:\n                raise ValueError(\n                    f\"Mesh procedure not implemented for {obj.__class__.__name__} type.\"\n                )\n            # Each object is recreated into gmsh. Here there is a trick: in order to\n            # allow the correct mesh in case of intersection, the procedure\n            # is made meshing the objects with increasing dimension.\n            for d in range(1, dim + 1, 1):\n                self.__convert_item_to_gmsh(buffer, d)\n            obj.ismeshed = True\n        else:\n            bluemira_print(\"Object already meshed\")\n        return buffer\n\n    def __convert_item_to_gmsh(self, buffer: dict, dim: int):\n        for k, v in buffer.items():\n            if k == \"BluemiraWire\":\n                self.__convert_wire_to_gmsh(buffer, dim)\n            if k == \"BluemiraFace\":\n                self.__convert_face_to_gmsh(buffer, dim)\n            if k == \"BluemiraShell\":\n                self.__convert_shell_to_gmsh(buffer, dim)\n            if k == \"BluemiraCompound\":\n                self.__convert_compound_to_gmsh(buffer, dim)\n\n    def _apply_physical_group(self, buffer: dict):\n        \"\"\"\n        Function to apply physical groups\n        \"\"\"\n        dict_dim = {\n            \"BluemiraWire\": 1,\n            \"BluemiraFace\": 2,\n            \"BluemiraShell\": 2,\n            \"BluemiraCompound\": 2,\n        }\n        other_dict = {0: \"points_tag\", 1: \"curve_tag\", 2: \"surface_tag\"}\n        for k, v in buffer.items():\n            if k in dict_dim.keys():\n                if \"physical_group\" in v.keys():\n                    _FreeCADGmsh.add_physical_group(\n                        dict_dim[k],\n                        self.get_gmsh_dict(buffer, \"default\")[other_dict[dict_dim[k]]],\n                        v[\"physical_group\"],\n                    )\n                for o in v[\"boundary\"]:\n                    self._apply_physical_group(o)\n\n    def _apply_mesh_size(self, buffer: dict):\n        \"\"\"\n        Function to apply mesh size.\n        \"\"\"\n        # mesh size is applied not only to the vertexes of the defined geometry,\n        # but also to the intersection points (new vertexes). For this reason,\n        # it is important to do this operation after the completion of the mesh\n        # procedure.\n        points_lcar2 = self.__create_dict_for_mesh_size(buffer)\n        if len(points_lcar2) > 0:\n            for p in points_lcar2:\n                _FreeCADGmsh._set_mesh_size([(0, p[0])], p[1])\n\n    def __create_dict_for_mesh_size(self, buffer: dict):\n        \"\"\"\n        Function to create the correct dictionary format for the\n        application of the mesh size.\n        \"\"\"\n        dict_dim = {\n            \"BluemiraWire\": 1,\n            \"BluemiraFace\": 2,\n            \"BluemiraShell\": 2,\n            \"BluemiraCompound\": 2,\n        }\n        other_dict = {0: \"points_tag\", 1: \"curve_tag\", 2: \"surface_tag\"}\n        points_lcar = []\n        for k, v in buffer.items():\n            if k in dict_dim.keys():\n                if \"lcar\" in v.keys():\n                    if v[\"lcar\"] is not None:\n                        points_tags = self.get_gmsh_dict(buffer, \"gmsh\")[other_dict[0]]\n                        if len(points_tags) > 0:\n                            points_lcar += [(p[1], v[\"lcar\"]) for p in points_tags]\n                for o in v[\"boundary\"]:\n                    points_lcar += self.__create_dict_for_mesh_size(o)\n        points_lcar = sorted(points_lcar, key=lambda element: (element[0], element[1]))\n        points_lcar.reverse()\n        points_lcar = dict(points_lcar)\n        points_lcar = [(k, v) for k, v in points_lcar.items()]\n        return points_lcar\n\n    def __apply_fragment(\n        self,\n        buffer: dict,\n        dim: List[int] = [2, 1, 0],\n        all_ent=None,\n        tools=[],\n        remove_object: bool = True,\n        remove_tool: bool = True,\n    ):\n        \"\"\"\n        Apply the boolean fragment operation.\n        \"\"\"\n        all_ent, oo, oov = _FreeCADGmsh._fragment(\n            dim, all_ent, tools, remove_object, remove_tool\n        )\n        Mesh.__iterate_gmsh_dict(buffer, _FreeCADGmsh._map_mesh_dict, all_ent, oov)\n\n    @staticmethod\n    def _check_intersections(gmsh_dict: dict):\n        \"\"\"\n        Check intersection and add the necessary vertexes to the gmsh dict.\n        \"\"\"\n        if len(gmsh_dict[\"curve_tag\"]) > 0:\n            gmsh_curve_tag = [(1, tag) for tag in gmsh_dict[\"curve_tag\"]]\n            new_points = _FreeCADGmsh._get_boundary(gmsh_curve_tag)\n            new_points = list(set([tag[1] for tag in new_points]))\n            gmsh_dict[\"points_tag\"] = new_points\n\n    @staticmethod\n    def __iterate_gmsh_dict(buffer: dict, function: Callable, *args):\n        \"\"\"\n        Supporting function to iterate over a gmsh dict.\n        \"\"\"\n        if \"BluemiraWire\" in buffer:\n            boundary = buffer[\"BluemiraWire\"][\"boundary\"]\n            if \"gmsh\" in buffer[\"BluemiraWire\"]:\n                function(buffer[\"BluemiraWire\"][\"gmsh\"], *args)\n            for item in boundary:\n                for k, v1 in item.items():\n                    if k == \"BluemiraWire\":\n                        Mesh.__iterate_gmsh_dict(item, function, *args)\n\n        if \"BluemiraFace\" in buffer:\n            boundary = buffer[\"BluemiraFace\"][\"boundary\"]\n            if \"gmsh\" in buffer[\"BluemiraFace\"]:\n                function(buffer[\"BluemiraFace\"][\"gmsh\"], *args)\n            for item in boundary:\n                Mesh.__iterate_gmsh_dict(item, function, *args)\n\n        if \"BluemiraShell\" in buffer:\n            boundary = buffer[\"BluemiraShell\"][\"boundary\"]\n            if \"gmsh\" in buffer[\"BluemiraShell\"]:\n                function(buffer[\"BluemiraShell\"][\"gmsh\"], *args)\n            for item in boundary:\n                Mesh.__iterate_gmsh_dict(item, function, *args)\n\n        if \"BluemiraCompound\" in buffer:\n            boundary = buffer[\"BluemiraCompound\"][\"boundary\"]\n            if \"gmsh\" in buffer[\"BluemiraCompound\"]:\n                function(buffer[\"BluemiraCompound\"][\"gmsh\"], *args)\n            for item in boundary:\n                Mesh.__iterate_gmsh_dict(item, function, *args)\n\n    def __convert_wire_to_gmsh(self, buffer: dict, dim: int):\n        \"\"\"\n        Converts a wire to gmsh. If dim is not equal to 1, wire is not meshed.\n        \"\"\"\n        for type_, value in buffer.items():\n            if type_ == \"BluemiraWire\":\n                boundary = value[\"boundary\"]\n                if dim == 1:\n                    value[\"gmsh\"] = {\n                        \"points_tag\": [],\n                        \"cntrpoints_tag\": [],\n                        \"curve_tag\": [],\n                        \"curveloop_tag\": [],\n                        \"surface_tag\": [],\n                    }\n                    for item in boundary:\n                        for btype_, bvalue in item.items():\n                            if btype_ == \"BluemiraWire\":\n                                self.__convert_wire_to_gmsh(item, dim)\n                            else:\n                                for curve in bvalue:\n                                    curve_gmsh_dict = _FreeCADGmsh.create_gmsh_curve(\n                                        curve\n                                    )\n                                    value[\"gmsh\"][\"points_tag\"] += curve_gmsh_dict[\n                                        \"points_tag\"\n                                    ]\n                                    value[\"gmsh\"][\"cntrpoints_tag\"] += curve_gmsh_dict[\n                                        \"cntrpoints_tag\"\n                                    ]\n                                    value[\"gmsh\"][\"curve_tag\"] += curve_gmsh_dict[\n                                        \"curve_tag\"\n                                    ]\n\n                    # get the dictionary of the BluemiraWire defined in buffer\n                    # as default and gmsh format\n                    dict_gmsh = self.get_gmsh_dict(buffer, \"gmsh\")\n\n                    # fragment points_tag and curves\n                    all_ent = dict_gmsh[\"points_tag\"] + dict_gmsh[\"curve_tag\"]\n                    self.__apply_fragment(buffer, all_ent, [], False, False)\n            else:\n                raise NotImplementedError(f\"Serialization non implemented for {type_}\")\n\n    def __convert_face_to_gmsh(self, buffer: dict, dim: int):\n        \"\"\"\n        Converts a face to gmsh.\n        \"\"\"\n        for type_, value in buffer.items():\n            if type_ == \"BluemiraFace\":\n                boundary = value[\"boundary\"]\n                if dim == 1:\n                    value[\"gmsh\"] = {}\n                    for item in boundary:\n                        for btype_, bvalue in item.items():\n                            if btype_ == \"BluemiraWire\":\n                                self.__convert_wire_to_gmsh(item, dim)\n\n                    # get the dictionary of the BluemiraWire defined in buffer\n                    # as default and gmsh format\n                    dict_gmsh = self.get_gmsh_dict(buffer, \"gmsh\")\n\n                    # fragment points_tag and curves\n                    all_ent = dict_gmsh[\"points_tag\"] + dict_gmsh[\"curve_tag\"]\n                    self.__apply_fragment(buffer, all_ent=all_ent)\n                elif dim == 2:\n                    value[\"gmsh\"][\"curveloop_tag\"] = []\n                    for item in boundary:\n                        dict_curve = self.get_gmsh_dict(item)\n                        value[\"gmsh\"][\"curveloop_tag\"].append(\n                            gmsh.model.occ.addCurveLoop(dict_curve[\"curve_tag\"])\n                        )\n                    gmsh.model.occ.synchronize()\n                    value[\"gmsh\"][\"surface_tag\"] = [\n                        gmsh.model.occ.addPlaneSurface(value[\"gmsh\"][\"curveloop_tag\"])\n                    ]\n                    gmsh.model.occ.synchronize()\n\n    def __convert_shell_to_gmsh(self, buffer: dict, dim: int):\n        \"\"\"\n        Converts a shell to gmsh.\n        \"\"\"\n        for type_, value in buffer.items():\n            if type_ == \"BluemiraShell\":\n                boundary = value[\"boundary\"]\n                if dim == 1:\n                    value[\"gmsh\"] = {}\n                    for item in boundary:\n                        self.__convert_face_to_gmsh(item, dim)\n                        # get the dictionary of the BluemiraShell defined in buffer\n                        # as default and gmsh format\n                        dict_gmsh = self.get_gmsh_dict(buffer, \"gmsh\")\n\n                        # fragment points_tag and curves\n                        all_ent = dict_gmsh[\"points_tag\"] + dict_gmsh[\"curve_tag\"]\n                        self.__apply_fragment(buffer, all_ent=all_ent)\n                elif dim == 2:\n                    for item in boundary:\n                        self.__convert_face_to_gmsh(item, dim)\n\n    def __convert_compound_to_gmsh(self, buffer: dict, dim: int):\n        \"\"\"\n        Converts a compound to gmsh.\n        \"\"\"\n        for type_, value in buffer.items():\n            if type_ == \"BluemiraCompound\":\n                boundary = value[\"boundary\"]\n                if dim == 1:\n                    value[\"gmsh\"] = {}\n                    for item in boundary:\n                        self.__convert_item_to_gmsh(item, dim)\n                        # get the dictionary of the Component defined in buffer\n                        # as default and gmsh format\n                        dict_gmsh = self.get_gmsh_dict(buffer, \"gmsh\")\n\n                        # fragment points_tag and curves\n                        all_ent = dict_gmsh[\"points_tag\"] + dict_gmsh[\"curve_tag\"]\n                        self.__apply_fragment(buffer, all_ent=all_ent)\n                elif dim == 2:\n                    for item in boundary:\n                        self.__convert_item_to_gmsh(item, dim)\n\n    def get_gmsh_dict(self, buffer: dict, format: str = \"default\"):\n        \"\"\"\n        Returns the gmsh dict in a default (only tags) or gmsh (tuple(dim,\n        tag)) format.\n        \"\"\"\n        gmsh_dict = {}\n        output = None\n\n        for d in MESH_DATA:\n            gmsh_dict[d] = []\n\n        def _extract_mesh_from_buffer(buffer, obj_name):\n            if obj_name not in buffer:\n                raise ValueError(f\"No {obj_name} to mesh.\")\n\n            boundary = buffer[obj_name][\"boundary\"]\n            if \"gmsh\" in buffer[obj_name]:\n                for d in MESH_DATA:\n                    if d in buffer[obj_name][\"gmsh\"]:\n                        gmsh_dict[d] += buffer[obj_name][\"gmsh\"][d]\n\n            for item in boundary:\n                if obj_name == \"BluemiraWire\":\n                    for k in item:\n                        if k == obj_name:\n                            temp_dict = self.get_gmsh_dict(item)\n                            for d in MESH_DATA:\n                                gmsh_dict[d] += temp_dict[d]\n                else:\n                    temp_dict = self.get_gmsh_dict(item)\n                    for d in MESH_DATA:\n                        gmsh_dict[d] += temp_dict[d]\n\n        for geo_name in SUPPORTED_GEOS:\n            if geo_name in buffer:\n                _extract_mesh_from_buffer(buffer, geo_name)\n\n        for d in MESH_DATA:\n            gmsh_dict[d] = list(dict.fromkeys(gmsh_dict[d]))\n\n        if format == \"default\":\n            output = gmsh_dict\n        elif format == \"gmsh\":\n            output = {}\n            for d in MESH_DATA:\n                output[d] = [(MESH_DATA[d], tag) for tag in gmsh_dict[d]]\n\n        return output",
  "class _FreeCADGmsh:\n    @staticmethod\n    def _initialize_mesh(terminal: int = 1, modelname: str = \"Mesh\"):\n        # GMSH file generation #######################\n        # Before using any functions in the Python API,\n        # Gmsh must be initialized:\n        gmsh.initialize()\n\n        # By default Gmsh will not print out any messages:\n        # in order to output messages\n        # on the terminal, just set the \"General.Terminal\" option to 1:\n        gmsh.option.setNumber(\"General.Terminal\", terminal)\n\n        gmsh.logger.start()\n\n        # gmsh.option.setNumber(\"Mesh.MshFileVersion\", 2.0)\n\n        # Next we add a new model named \"t1\" (if gmsh.model.add() is\n        # not called a new\n        # unnamed model will be created on the fly, if necessary):\n        gmsh.model.add(modelname)\n\n    @staticmethod\n    def _save_mesh(meshfile: str = \"Mesh.geo_unrolled\"):\n        # ... and save it to disk\n        gmsh.write(meshfile)\n\n    @staticmethod\n    def _finalize_mesh(logfile: str = \"gmsh.log\"):\n        with open(logfile, \"w\") as file_handler:\n            file_handler.write(\"\\n\".join(str(item) for item in gmsh.logger.get()))\n\n        gmsh.logger.stop()\n\n        # This should be called when you are done using the Gmsh Python API:\n        gmsh.finalize()\n\n    @staticmethod\n    def _generate_mesh(mesh_dim: int = 3):\n        # Before it can be meshed, the internal CAD representation must\n        # be synchronized with the Gmsh model, which will create the\n        # relevant Gmsh data structures. This is achieved by the\n        # gmsh.model.occ.synchronize() API call for the built-in\n        # geometry kernel. Synchronizations can be called at any time,\n        # but they involve a non trivial amount of processing;\n        # so while you could synchronize the internal CAD data after\n        # every CAD command, it is usually better to minimize\n        # the number of synchronization points.\n        gmsh.model.occ.synchronize()\n\n        # We can then generate a mesh...\n        gmsh.model.mesh.generate(mesh_dim)\n\n    @staticmethod\n    def create_gmsh_curve(buffer: dict):\n        \"\"\"\n        Function to create gmsh curve from a dictionary (buffer).\n        \"\"\"\n        gmsh_dict = {}\n\n        points_tag = []\n        cntrpoints_tag = []\n        curve_tag = []\n        for type_ in buffer:\n            if type_ == \"LineSegment\":\n                points_tag.extend(\n                    _add_points(buffer[type_][\"StartPoint\"], buffer[type_][\"EndPoint\"])\n                )\n                curve_tag.append(gmsh.model.occ.addLine(points_tag[0], points_tag[1]))\n            elif type_ == \"BezierCurve\":\n                cntrpoints_tag.extend(_add_points(*buffer[type_][\"Poles\"]))\n                curve_tag.append(gmsh.model.occ.addBezier(cntrpoints_tag))\n                points_tag.extend((cntrpoints_tag[0], cntrpoints_tag[-1]))\n            elif type_ == \"BSplineCurve\":\n                cntrpoints_tag.extend(_add_points(*buffer[type_][\"Poles\"]))\n                curve_tag.append(gmsh.model.occ.addBSpline(cntrpoints_tag))\n                points_tag.extend((cntrpoints_tag[0], cntrpoints_tag[-1]))\n            elif type_ == \"ArcOfCircle\":\n                start_tag, end_tag, centre_tag = _add_points(\n                    buffer[type_][\"StartPoint\"],\n                    buffer[type_][\"EndPoint\"],\n                    buffer[type_][\"Center\"],\n                )\n                points_tag.extend((start_tag, end_tag))\n                curve_tag.append(\n                    gmsh.model.occ.addCircleArc(start_tag, centre_tag, end_tag)\n                )\n                cntrpoints_tag.append(centre_tag)\n            elif type_ == \"ArcOfEllipse\":\n                start_tag, end_tag, focus_tag, centre_tag = _add_points(\n                    buffer[type_][\"StartPoint\"],\n                    buffer[type_][\"EndPoint\"],\n                    buffer[type_][\"Focus1\"],\n                    buffer[type_][\"Center\"],\n                )\n                points_tag.extend((start_tag, end_tag))\n                curve_tag.append(\n                    gmsh.model.occ.addEllipseArc(\n                        start_tag, centre_tag, focus_tag, end_tag\n                    )\n                )\n                cntrpoints_tag.extend((centre_tag, focus_tag))\n            else:\n                raise NotImplementedError(\n                    f\"Gmsh curve creation non implemented for {type_}\"\n                )\n\n        gmsh_dict[\"points_tag\"] = points_tag\n        gmsh_dict[\"cntrpoints_tag\"] = cntrpoints_tag\n        gmsh_dict[\"curve_tag\"] = curve_tag\n        gmsh.model.occ.synchronize()\n        return gmsh_dict\n\n    @staticmethod\n    def _fragment(\n        dim: List[int] = [2, 1, 0],\n        all_ent: Optional[List[int]] = None,\n        tools=[],\n        remove_object: bool = True,\n        remove_tool: bool = True,\n    ):\n        if not hasattr(dim, \"__len__\"):\n            dim = [dim]\n        if all_ent is None:\n            all_ent = []\n            for d in dim:\n                all_ent += gmsh.model.getEntities(d)\n        oo = []\n        oov = []\n        if len(all_ent) > 1:\n            oo, oov = gmsh.model.occ.fragment(\n                objectDimTags=all_ent,\n                toolDimTags=tools,\n                removeObject=remove_object,\n                removeTool=remove_tool,\n            )\n            gmsh.model.occ.synchronize()\n\n        return all_ent, oo, oov\n\n    @staticmethod\n    def _map_mesh_dict(mesh_dict: dict, all_ent, oov: list = []):\n        dim_dict = {\n            \"points_tag\": 0,\n            \"cntrpoints_tag\": 0,\n            \"curve_tag\": 1,\n            \"surface_tag\": 2,\n        }\n        new_gmsh_dict = {}\n\n        for key in dim_dict:\n            new_gmsh_dict[key] = []\n\n        for type_, values in mesh_dict.items():\n            if type_ != \"curveloop_tag\":\n                for v in values:\n                    dim = dim_dict[type_]\n                    if (dim, v) in all_ent:\n                        if len(oov) > 0:\n                            for o in oov[all_ent.index((dim, v))]:\n                                new_gmsh_dict[type_].append(o[1])\n                    else:\n                        new_gmsh_dict[type_].append(v)\n\n        for key in dim_dict:\n            mesh_dict[key] = list(dict.fromkeys(new_gmsh_dict[key]))\n\n        return new_gmsh_dict\n\n    @staticmethod\n    def set_mesh_size(dim_tags, size):\n        gmsh.model.occ.mesh.setSize(dim_tags, size)\n        gmsh.model.occ.synchronize()\n\n    @staticmethod\n    def add_physical_group(dim, tags, name: Optional[str] = None):\n        tag = gmsh.model.addPhysicalGroup(dim, tags)\n        if name is not None:\n            gmsh.model.setPhysicalName(dim, tag, name)\n\n    @staticmethod\n    def _set_mesh_size(dim_tags, size):\n        gmsh.model.mesh.setSize(dim_tags, size)\n\n    @staticmethod\n    def _get_boundary(dimtags, combined=False, recursive=False):\n        return gmsh.model.getBoundary(dimtags, combined, recursive)",
  "def _add_points(*point: Iterable) -> List:\n    \"\"\"\n    Add gmsh model points\n    \"\"\"\n    tags = []\n    for p in point:\n        tags.append(gmsh.model.occ.addPoint(p[0], p[1], p[2]))\n    return tags",
  "def __init__(self, **kwargs):\n        self._options = get_default_options()\n        self.modify(**kwargs)",
  "def lcar(self) -> float:\n        \"\"\"\n        Mesh size of points.\n        \"\"\"\n        return self._options[\"lcar\"]",
  "def lcar(self, val: float):\n        self._options[\"lcar\"] = val",
  "def physical_group(self):\n        \"\"\"\n        Definition of physical groups.\n        \"\"\"\n        return self._options[\"physical_group\"]",
  "def physical_group(self, val: float):\n        self._options[\"physical_group\"] = val",
  "def as_dict(self) -> dict:\n        \"\"\"\n        Returns the instance as a dictionary.\n        \"\"\"\n        return copy.deepcopy(self._options)",
  "def modify(self, **kwargs):\n        \"\"\"\n        Function to override meshing options.\n        \"\"\"\n        if kwargs:\n            for k in kwargs:\n                if k in self._options:\n                    self._options[k] = kwargs[k]",
  "def __repr__(self):\n        \"\"\"\n        Representation string of the DisplayOptions.\n        \"\"\"\n        return f\"{self.__class__.__name__}({pprint.pformat(self._options)}\" + \"\\n)\"",
  "def __init__(self):\n        super().__init__()\n        self._mesh_options = MeshOptions()",
  "def mesh_options(self) -> MeshOptions:\n        \"\"\"\n        The options that will be used to mesh the object.\n        \"\"\"\n        return self._mesh_options",
  "def mesh_options(self, value: Union[MeshOptions, Dict]):\n        if isinstance(value, MeshOptions):\n            self._mesh_options = value\n        elif isinstance(value, Dict):\n            if self.mesh_options is None:\n                self.mesh_options = MeshOptions()\n            self.mesh_options.modify(**value)\n        else:\n            raise MeshOptionsError(\"Mesh options must be set to a MeshOptions instance.\")",
  "def __init__(\n        self,\n        modelname: str = \"Mesh\",\n        terminal: int = 0,\n        meshfile: Optional[Union[str, List[str]]] = None,\n        logfile: str = \"gmsh.log\",\n    ):\n        self.modelname = modelname\n        self.terminal = terminal\n        self.meshfile = (\n            [\"Mesh.geo_unrolled\", \"Mesh.msh\"] if meshfile is None else meshfile\n        )\n        self.logfile = logfile",
  "def _check_meshfile(self, meshfile: Union[str, list]) -> List[str]:\n        \"\"\"\n        Check the mesh file input.\n        \"\"\"\n        # todo: should be implemented also a check on the file extension. Only a\n        # limited type of file extensions is allowed by gmsh.\n        if isinstance(meshfile, str):\n            meshfile = [meshfile]\n        elif isinstance(meshfile, list):\n            if len(meshfile) < 1:\n                raise ValueError(\"meshfile is an empty list\")\n        else:\n            raise ValueError(\"meshfile must be a string or a list of strings\")\n        return meshfile",
  "def meshfile(self) -> List[str]:\n        \"\"\"\n        The path(s) to the file(s) containing the meshes.\n        \"\"\"\n        return self._meshfile",
  "def meshfile(self, meshfile: Union[str, List[str]]):\n        self._meshfile = self._check_meshfile(meshfile)",
  "def __call__(self, obj: Union[Component, Meshable], dim: int = 2):\n        \"\"\"\n        Generate the mesh and save it to file.\n        \"\"\"\n        bluemira_print(\"Starting mesh process...\")\n\n        if \"Component\" in [c.__name__ for c in inspect.getmro(type(obj))]:\n            from bluemira.base.tools import create_compound_from_component\n\n            obj = create_compound_from_component(obj)\n\n        if isinstance(obj, Meshable):\n            # gmsh is initialized\n            _FreeCADGmsh._initialize_mesh(self.terminal, self.modelname)\n            # Mesh the object. A dictionary with the geometrical and internal\n            # information that are used by gmsh is returned. In particular,\n            # a gmsh key is added to any meshed entity.\n            buffer = self.__mesh_obj(obj, dim=dim)\n            # Check for possible intersection (only allowed at the boundary to adjust\n            # the gmsh_dictionary\n            Mesh.__iterate_gmsh_dict(buffer, Mesh._check_intersections)\n\n            # Create the physical groups\n            self._apply_physical_group(buffer)\n\n            # apply the mesh size\n            self._apply_mesh_size(buffer)\n\n            # generate the mesh\n            _FreeCADGmsh._generate_mesh()\n\n            # save the mesh file\n            for file in self.meshfile:\n                _FreeCADGmsh._save_mesh(file)\n\n            # close gmsh\n            _FreeCADGmsh._finalize_mesh(self.logfile)\n        else:\n            raise ValueError(\"Only Meshable objects can be meshed\")\n\n        bluemira_print(\"Mesh process completed.\")\n\n        return buffer",
  "def __mesh_obj(self, obj, dim: int):\n        \"\"\"\n        Function to mesh the object.\n        \"\"\"\n        from bluemira.geometry.tools import serialize_shape\n\n        if not hasattr(obj, \"ismeshed\") or not obj.ismeshed:\n            # object is serialized into a dictionary\n            if obj.__class__.__name__ in SUPPORTED_GEOS:\n                buffer = serialize_shape(obj)\n            else:\n                raise ValueError(\n                    f\"Mesh procedure not implemented for {obj.__class__.__name__} type.\"\n                )\n            # Each object is recreated into gmsh. Here there is a trick: in order to\n            # allow the correct mesh in case of intersection, the procedure\n            # is made meshing the objects with increasing dimension.\n            for d in range(1, dim + 1, 1):\n                self.__convert_item_to_gmsh(buffer, d)\n            obj.ismeshed = True\n        else:\n            bluemira_print(\"Object already meshed\")\n        return buffer",
  "def __convert_item_to_gmsh(self, buffer: dict, dim: int):\n        for k, v in buffer.items():\n            if k == \"BluemiraWire\":\n                self.__convert_wire_to_gmsh(buffer, dim)\n            if k == \"BluemiraFace\":\n                self.__convert_face_to_gmsh(buffer, dim)\n            if k == \"BluemiraShell\":\n                self.__convert_shell_to_gmsh(buffer, dim)\n            if k == \"BluemiraCompound\":\n                self.__convert_compound_to_gmsh(buffer, dim)",
  "def _apply_physical_group(self, buffer: dict):\n        \"\"\"\n        Function to apply physical groups\n        \"\"\"\n        dict_dim = {\n            \"BluemiraWire\": 1,\n            \"BluemiraFace\": 2,\n            \"BluemiraShell\": 2,\n            \"BluemiraCompound\": 2,\n        }\n        other_dict = {0: \"points_tag\", 1: \"curve_tag\", 2: \"surface_tag\"}\n        for k, v in buffer.items():\n            if k in dict_dim.keys():\n                if \"physical_group\" in v.keys():\n                    _FreeCADGmsh.add_physical_group(\n                        dict_dim[k],\n                        self.get_gmsh_dict(buffer, \"default\")[other_dict[dict_dim[k]]],\n                        v[\"physical_group\"],\n                    )\n                for o in v[\"boundary\"]:\n                    self._apply_physical_group(o)",
  "def _apply_mesh_size(self, buffer: dict):\n        \"\"\"\n        Function to apply mesh size.\n        \"\"\"\n        # mesh size is applied not only to the vertexes of the defined geometry,\n        # but also to the intersection points (new vertexes). For this reason,\n        # it is important to do this operation after the completion of the mesh\n        # procedure.\n        points_lcar2 = self.__create_dict_for_mesh_size(buffer)\n        if len(points_lcar2) > 0:\n            for p in points_lcar2:\n                _FreeCADGmsh._set_mesh_size([(0, p[0])], p[1])",
  "def __create_dict_for_mesh_size(self, buffer: dict):\n        \"\"\"\n        Function to create the correct dictionary format for the\n        application of the mesh size.\n        \"\"\"\n        dict_dim = {\n            \"BluemiraWire\": 1,\n            \"BluemiraFace\": 2,\n            \"BluemiraShell\": 2,\n            \"BluemiraCompound\": 2,\n        }\n        other_dict = {0: \"points_tag\", 1: \"curve_tag\", 2: \"surface_tag\"}\n        points_lcar = []\n        for k, v in buffer.items():\n            if k in dict_dim.keys():\n                if \"lcar\" in v.keys():\n                    if v[\"lcar\"] is not None:\n                        points_tags = self.get_gmsh_dict(buffer, \"gmsh\")[other_dict[0]]\n                        if len(points_tags) > 0:\n                            points_lcar += [(p[1], v[\"lcar\"]) for p in points_tags]\n                for o in v[\"boundary\"]:\n                    points_lcar += self.__create_dict_for_mesh_size(o)\n        points_lcar = sorted(points_lcar, key=lambda element: (element[0], element[1]))\n        points_lcar.reverse()\n        points_lcar = dict(points_lcar)\n        points_lcar = [(k, v) for k, v in points_lcar.items()]\n        return points_lcar",
  "def __apply_fragment(\n        self,\n        buffer: dict,\n        dim: List[int] = [2, 1, 0],\n        all_ent=None,\n        tools=[],\n        remove_object: bool = True,\n        remove_tool: bool = True,\n    ):\n        \"\"\"\n        Apply the boolean fragment operation.\n        \"\"\"\n        all_ent, oo, oov = _FreeCADGmsh._fragment(\n            dim, all_ent, tools, remove_object, remove_tool\n        )\n        Mesh.__iterate_gmsh_dict(buffer, _FreeCADGmsh._map_mesh_dict, all_ent, oov)",
  "def _check_intersections(gmsh_dict: dict):\n        \"\"\"\n        Check intersection and add the necessary vertexes to the gmsh dict.\n        \"\"\"\n        if len(gmsh_dict[\"curve_tag\"]) > 0:\n            gmsh_curve_tag = [(1, tag) for tag in gmsh_dict[\"curve_tag\"]]\n            new_points = _FreeCADGmsh._get_boundary(gmsh_curve_tag)\n            new_points = list(set([tag[1] for tag in new_points]))\n            gmsh_dict[\"points_tag\"] = new_points",
  "def __iterate_gmsh_dict(buffer: dict, function: Callable, *args):\n        \"\"\"\n        Supporting function to iterate over a gmsh dict.\n        \"\"\"\n        if \"BluemiraWire\" in buffer:\n            boundary = buffer[\"BluemiraWire\"][\"boundary\"]\n            if \"gmsh\" in buffer[\"BluemiraWire\"]:\n                function(buffer[\"BluemiraWire\"][\"gmsh\"], *args)\n            for item in boundary:\n                for k, v1 in item.items():\n                    if k == \"BluemiraWire\":\n                        Mesh.__iterate_gmsh_dict(item, function, *args)\n\n        if \"BluemiraFace\" in buffer:\n            boundary = buffer[\"BluemiraFace\"][\"boundary\"]\n            if \"gmsh\" in buffer[\"BluemiraFace\"]:\n                function(buffer[\"BluemiraFace\"][\"gmsh\"], *args)\n            for item in boundary:\n                Mesh.__iterate_gmsh_dict(item, function, *args)\n\n        if \"BluemiraShell\" in buffer:\n            boundary = buffer[\"BluemiraShell\"][\"boundary\"]\n            if \"gmsh\" in buffer[\"BluemiraShell\"]:\n                function(buffer[\"BluemiraShell\"][\"gmsh\"], *args)\n            for item in boundary:\n                Mesh.__iterate_gmsh_dict(item, function, *args)\n\n        if \"BluemiraCompound\" in buffer:\n            boundary = buffer[\"BluemiraCompound\"][\"boundary\"]\n            if \"gmsh\" in buffer[\"BluemiraCompound\"]:\n                function(buffer[\"BluemiraCompound\"][\"gmsh\"], *args)\n            for item in boundary:\n                Mesh.__iterate_gmsh_dict(item, function, *args)",
  "def __convert_wire_to_gmsh(self, buffer: dict, dim: int):\n        \"\"\"\n        Converts a wire to gmsh. If dim is not equal to 1, wire is not meshed.\n        \"\"\"\n        for type_, value in buffer.items():\n            if type_ == \"BluemiraWire\":\n                boundary = value[\"boundary\"]\n                if dim == 1:\n                    value[\"gmsh\"] = {\n                        \"points_tag\": [],\n                        \"cntrpoints_tag\": [],\n                        \"curve_tag\": [],\n                        \"curveloop_tag\": [],\n                        \"surface_tag\": [],\n                    }\n                    for item in boundary:\n                        for btype_, bvalue in item.items():\n                            if btype_ == \"BluemiraWire\":\n                                self.__convert_wire_to_gmsh(item, dim)\n                            else:\n                                for curve in bvalue:\n                                    curve_gmsh_dict = _FreeCADGmsh.create_gmsh_curve(\n                                        curve\n                                    )\n                                    value[\"gmsh\"][\"points_tag\"] += curve_gmsh_dict[\n                                        \"points_tag\"\n                                    ]\n                                    value[\"gmsh\"][\"cntrpoints_tag\"] += curve_gmsh_dict[\n                                        \"cntrpoints_tag\"\n                                    ]\n                                    value[\"gmsh\"][\"curve_tag\"] += curve_gmsh_dict[\n                                        \"curve_tag\"\n                                    ]\n\n                    # get the dictionary of the BluemiraWire defined in buffer\n                    # as default and gmsh format\n                    dict_gmsh = self.get_gmsh_dict(buffer, \"gmsh\")\n\n                    # fragment points_tag and curves\n                    all_ent = dict_gmsh[\"points_tag\"] + dict_gmsh[\"curve_tag\"]\n                    self.__apply_fragment(buffer, all_ent, [], False, False)\n            else:\n                raise NotImplementedError(f\"Serialization non implemented for {type_}\")",
  "def __convert_face_to_gmsh(self, buffer: dict, dim: int):\n        \"\"\"\n        Converts a face to gmsh.\n        \"\"\"\n        for type_, value in buffer.items():\n            if type_ == \"BluemiraFace\":\n                boundary = value[\"boundary\"]\n                if dim == 1:\n                    value[\"gmsh\"] = {}\n                    for item in boundary:\n                        for btype_, bvalue in item.items():\n                            if btype_ == \"BluemiraWire\":\n                                self.__convert_wire_to_gmsh(item, dim)\n\n                    # get the dictionary of the BluemiraWire defined in buffer\n                    # as default and gmsh format\n                    dict_gmsh = self.get_gmsh_dict(buffer, \"gmsh\")\n\n                    # fragment points_tag and curves\n                    all_ent = dict_gmsh[\"points_tag\"] + dict_gmsh[\"curve_tag\"]\n                    self.__apply_fragment(buffer, all_ent=all_ent)\n                elif dim == 2:\n                    value[\"gmsh\"][\"curveloop_tag\"] = []\n                    for item in boundary:\n                        dict_curve = self.get_gmsh_dict(item)\n                        value[\"gmsh\"][\"curveloop_tag\"].append(\n                            gmsh.model.occ.addCurveLoop(dict_curve[\"curve_tag\"])\n                        )\n                    gmsh.model.occ.synchronize()\n                    value[\"gmsh\"][\"surface_tag\"] = [\n                        gmsh.model.occ.addPlaneSurface(value[\"gmsh\"][\"curveloop_tag\"])\n                    ]\n                    gmsh.model.occ.synchronize()",
  "def __convert_shell_to_gmsh(self, buffer: dict, dim: int):\n        \"\"\"\n        Converts a shell to gmsh.\n        \"\"\"\n        for type_, value in buffer.items():\n            if type_ == \"BluemiraShell\":\n                boundary = value[\"boundary\"]\n                if dim == 1:\n                    value[\"gmsh\"] = {}\n                    for item in boundary:\n                        self.__convert_face_to_gmsh(item, dim)\n                        # get the dictionary of the BluemiraShell defined in buffer\n                        # as default and gmsh format\n                        dict_gmsh = self.get_gmsh_dict(buffer, \"gmsh\")\n\n                        # fragment points_tag and curves\n                        all_ent = dict_gmsh[\"points_tag\"] + dict_gmsh[\"curve_tag\"]\n                        self.__apply_fragment(buffer, all_ent=all_ent)\n                elif dim == 2:\n                    for item in boundary:\n                        self.__convert_face_to_gmsh(item, dim)",
  "def __convert_compound_to_gmsh(self, buffer: dict, dim: int):\n        \"\"\"\n        Converts a compound to gmsh.\n        \"\"\"\n        for type_, value in buffer.items():\n            if type_ == \"BluemiraCompound\":\n                boundary = value[\"boundary\"]\n                if dim == 1:\n                    value[\"gmsh\"] = {}\n                    for item in boundary:\n                        self.__convert_item_to_gmsh(item, dim)\n                        # get the dictionary of the Component defined in buffer\n                        # as default and gmsh format\n                        dict_gmsh = self.get_gmsh_dict(buffer, \"gmsh\")\n\n                        # fragment points_tag and curves\n                        all_ent = dict_gmsh[\"points_tag\"] + dict_gmsh[\"curve_tag\"]\n                        self.__apply_fragment(buffer, all_ent=all_ent)\n                elif dim == 2:\n                    for item in boundary:\n                        self.__convert_item_to_gmsh(item, dim)",
  "def get_gmsh_dict(self, buffer: dict, format: str = \"default\"):\n        \"\"\"\n        Returns the gmsh dict in a default (only tags) or gmsh (tuple(dim,\n        tag)) format.\n        \"\"\"\n        gmsh_dict = {}\n        output = None\n\n        for d in MESH_DATA:\n            gmsh_dict[d] = []\n\n        def _extract_mesh_from_buffer(buffer, obj_name):\n            if obj_name not in buffer:\n                raise ValueError(f\"No {obj_name} to mesh.\")\n\n            boundary = buffer[obj_name][\"boundary\"]\n            if \"gmsh\" in buffer[obj_name]:\n                for d in MESH_DATA:\n                    if d in buffer[obj_name][\"gmsh\"]:\n                        gmsh_dict[d] += buffer[obj_name][\"gmsh\"][d]\n\n            for item in boundary:\n                if obj_name == \"BluemiraWire\":\n                    for k in item:\n                        if k == obj_name:\n                            temp_dict = self.get_gmsh_dict(item)\n                            for d in MESH_DATA:\n                                gmsh_dict[d] += temp_dict[d]\n                else:\n                    temp_dict = self.get_gmsh_dict(item)\n                    for d in MESH_DATA:\n                        gmsh_dict[d] += temp_dict[d]\n\n        for geo_name in SUPPORTED_GEOS:\n            if geo_name in buffer:\n                _extract_mesh_from_buffer(buffer, geo_name)\n\n        for d in MESH_DATA:\n            gmsh_dict[d] = list(dict.fromkeys(gmsh_dict[d]))\n\n        if format == \"default\":\n            output = gmsh_dict\n        elif format == \"gmsh\":\n            output = {}\n            for d in MESH_DATA:\n                output[d] = [(MESH_DATA[d], tag) for tag in gmsh_dict[d]]\n\n        return output",
  "def _initialize_mesh(terminal: int = 1, modelname: str = \"Mesh\"):\n        # GMSH file generation #######################\n        # Before using any functions in the Python API,\n        # Gmsh must be initialized:\n        gmsh.initialize()\n\n        # By default Gmsh will not print out any messages:\n        # in order to output messages\n        # on the terminal, just set the \"General.Terminal\" option to 1:\n        gmsh.option.setNumber(\"General.Terminal\", terminal)\n\n        gmsh.logger.start()\n\n        # gmsh.option.setNumber(\"Mesh.MshFileVersion\", 2.0)\n\n        # Next we add a new model named \"t1\" (if gmsh.model.add() is\n        # not called a new\n        # unnamed model will be created on the fly, if necessary):\n        gmsh.model.add(modelname)",
  "def _save_mesh(meshfile: str = \"Mesh.geo_unrolled\"):\n        # ... and save it to disk\n        gmsh.write(meshfile)",
  "def _finalize_mesh(logfile: str = \"gmsh.log\"):\n        with open(logfile, \"w\") as file_handler:\n            file_handler.write(\"\\n\".join(str(item) for item in gmsh.logger.get()))\n\n        gmsh.logger.stop()\n\n        # This should be called when you are done using the Gmsh Python API:\n        gmsh.finalize()",
  "def _generate_mesh(mesh_dim: int = 3):\n        # Before it can be meshed, the internal CAD representation must\n        # be synchronized with the Gmsh model, which will create the\n        # relevant Gmsh data structures. This is achieved by the\n        # gmsh.model.occ.synchronize() API call for the built-in\n        # geometry kernel. Synchronizations can be called at any time,\n        # but they involve a non trivial amount of processing;\n        # so while you could synchronize the internal CAD data after\n        # every CAD command, it is usually better to minimize\n        # the number of synchronization points.\n        gmsh.model.occ.synchronize()\n\n        # We can then generate a mesh...\n        gmsh.model.mesh.generate(mesh_dim)",
  "def create_gmsh_curve(buffer: dict):\n        \"\"\"\n        Function to create gmsh curve from a dictionary (buffer).\n        \"\"\"\n        gmsh_dict = {}\n\n        points_tag = []\n        cntrpoints_tag = []\n        curve_tag = []\n        for type_ in buffer:\n            if type_ == \"LineSegment\":\n                points_tag.extend(\n                    _add_points(buffer[type_][\"StartPoint\"], buffer[type_][\"EndPoint\"])\n                )\n                curve_tag.append(gmsh.model.occ.addLine(points_tag[0], points_tag[1]))\n            elif type_ == \"BezierCurve\":\n                cntrpoints_tag.extend(_add_points(*buffer[type_][\"Poles\"]))\n                curve_tag.append(gmsh.model.occ.addBezier(cntrpoints_tag))\n                points_tag.extend((cntrpoints_tag[0], cntrpoints_tag[-1]))\n            elif type_ == \"BSplineCurve\":\n                cntrpoints_tag.extend(_add_points(*buffer[type_][\"Poles\"]))\n                curve_tag.append(gmsh.model.occ.addBSpline(cntrpoints_tag))\n                points_tag.extend((cntrpoints_tag[0], cntrpoints_tag[-1]))\n            elif type_ == \"ArcOfCircle\":\n                start_tag, end_tag, centre_tag = _add_points(\n                    buffer[type_][\"StartPoint\"],\n                    buffer[type_][\"EndPoint\"],\n                    buffer[type_][\"Center\"],\n                )\n                points_tag.extend((start_tag, end_tag))\n                curve_tag.append(\n                    gmsh.model.occ.addCircleArc(start_tag, centre_tag, end_tag)\n                )\n                cntrpoints_tag.append(centre_tag)\n            elif type_ == \"ArcOfEllipse\":\n                start_tag, end_tag, focus_tag, centre_tag = _add_points(\n                    buffer[type_][\"StartPoint\"],\n                    buffer[type_][\"EndPoint\"],\n                    buffer[type_][\"Focus1\"],\n                    buffer[type_][\"Center\"],\n                )\n                points_tag.extend((start_tag, end_tag))\n                curve_tag.append(\n                    gmsh.model.occ.addEllipseArc(\n                        start_tag, centre_tag, focus_tag, end_tag\n                    )\n                )\n                cntrpoints_tag.extend((centre_tag, focus_tag))\n            else:\n                raise NotImplementedError(\n                    f\"Gmsh curve creation non implemented for {type_}\"\n                )\n\n        gmsh_dict[\"points_tag\"] = points_tag\n        gmsh_dict[\"cntrpoints_tag\"] = cntrpoints_tag\n        gmsh_dict[\"curve_tag\"] = curve_tag\n        gmsh.model.occ.synchronize()\n        return gmsh_dict",
  "def _fragment(\n        dim: List[int] = [2, 1, 0],\n        all_ent: Optional[List[int]] = None,\n        tools=[],\n        remove_object: bool = True,\n        remove_tool: bool = True,\n    ):\n        if not hasattr(dim, \"__len__\"):\n            dim = [dim]\n        if all_ent is None:\n            all_ent = []\n            for d in dim:\n                all_ent += gmsh.model.getEntities(d)\n        oo = []\n        oov = []\n        if len(all_ent) > 1:\n            oo, oov = gmsh.model.occ.fragment(\n                objectDimTags=all_ent,\n                toolDimTags=tools,\n                removeObject=remove_object,\n                removeTool=remove_tool,\n            )\n            gmsh.model.occ.synchronize()\n\n        return all_ent, oo, oov",
  "def _map_mesh_dict(mesh_dict: dict, all_ent, oov: list = []):\n        dim_dict = {\n            \"points_tag\": 0,\n            \"cntrpoints_tag\": 0,\n            \"curve_tag\": 1,\n            \"surface_tag\": 2,\n        }\n        new_gmsh_dict = {}\n\n        for key in dim_dict:\n            new_gmsh_dict[key] = []\n\n        for type_, values in mesh_dict.items():\n            if type_ != \"curveloop_tag\":\n                for v in values:\n                    dim = dim_dict[type_]\n                    if (dim, v) in all_ent:\n                        if len(oov) > 0:\n                            for o in oov[all_ent.index((dim, v))]:\n                                new_gmsh_dict[type_].append(o[1])\n                    else:\n                        new_gmsh_dict[type_].append(v)\n\n        for key in dim_dict:\n            mesh_dict[key] = list(dict.fromkeys(new_gmsh_dict[key]))\n\n        return new_gmsh_dict",
  "def set_mesh_size(dim_tags, size):\n        gmsh.model.occ.mesh.setSize(dim_tags, size)\n        gmsh.model.occ.synchronize()",
  "def add_physical_group(dim, tags, name: Optional[str] = None):\n        tag = gmsh.model.addPhysicalGroup(dim, tags)\n        if name is not None:\n            gmsh.model.setPhysicalName(dim, tag, name)",
  "def _set_mesh_size(dim_tags, size):\n        gmsh.model.mesh.setSize(dim_tags, size)",
  "def _get_boundary(dimtags, combined=False, recursive=False):\n        return gmsh.model.getBoundary(dimtags, combined, recursive)",
  "def _extract_mesh_from_buffer(buffer, obj_name):\n            if obj_name not in buffer:\n                raise ValueError(f\"No {obj_name} to mesh.\")\n\n            boundary = buffer[obj_name][\"boundary\"]\n            if \"gmsh\" in buffer[obj_name]:\n                for d in MESH_DATA:\n                    if d in buffer[obj_name][\"gmsh\"]:\n                        gmsh_dict[d] += buffer[obj_name][\"gmsh\"][d]\n\n            for item in boundary:\n                if obj_name == \"BluemiraWire\":\n                    for k in item:\n                        if k == obj_name:\n                            temp_dict = self.get_gmsh_dict(item)\n                            for d in MESH_DATA:\n                                gmsh_dict[d] += temp_dict[d]\n                else:\n                    temp_dict = self.get_gmsh_dict(item)\n                    for d in MESH_DATA:\n                        gmsh_dict[d] += temp_dict[d]",
  "class MeshError(BluemiraError):\n    \"\"\"\n    Error class for use in the mesh module.\n    \"\"\"",
  "class MeshOptionsError(MeshError):\n    \"\"\"\n    Error class for use with meshing options.\n    \"\"\"\n\n    pass",
  "class MeshConversionError(MeshError):\n    \"\"\"\n    Error class for use with mesh conversions.\n    \"\"\"\n\n    pass",
  "def msh_to_xdmf(\n    mesh_name: str,\n    dimensions: Union[Tuple[int], int] = (0, 2),\n    directory: str = \".\",\n):\n    \"\"\"\n    Convert a MSH file to an XMDF file.\n\n    Parameters\n    ----------\n    mesh_name: str\n        Name of the MSH file to convert to XDMF\n    dimensions: Union[Tuple[int], int]\n        Dimensions of the mesh (0: x, 1: y, 2: z), defaults to x-z\n        (0, 1, 2) would be a 3-D mesh\n    directory: str\n        Directory in which the MSH file exists and where the XDMF files will be written\n\n    Raises\n    ------\n    MeshConversionError:\n        * If the file does not exist\n        * If the dimensionality != [2, 3]\n        * If no domain physical groups are found\n\n    Notes\n    -----\n    Creates the following files:\n        * DOMAIN_SUFFIX\n        * BOUNDARY_SUFFIX\n        * LINKFILE_SUFFIX\n    \"\"\"\n    dimensions = _check_dimensions(dimensions)\n\n    file_path = os.path.join(directory, mesh_name)\n    if not os.path.exists(file_path):\n        raise MeshConversionError(f\"No such file: {file_path}\")\n\n    file_prefix = mesh_name.split(\".\")[0]\n    mesh = meshio.read(file_path)\n    _export_domain(mesh, file_prefix, directory, dimensions)\n    _export_boundaries(mesh, file_prefix, directory, dimensions)\n    _export_link_file(mesh, file_prefix, directory)",
  "def import_mesh(\n    file_prefix: str = \"mesh\", subdomains: bool = False, directory: str = \".\"\n) -> Tuple[Mesh, MeshFunctionSizet, Optional[MeshFunctionSizet], dict]:\n    \"\"\"\n    Import a dolfin mesh.\n\n    Parameters\n    ----------\n    file_prefix:\n        File prefix to use when importing a mesh (defaults to 'mesh')\n    subdomains:\n        Whether or not to subdomains are present (defaults to False)\n    directory:\n        Directory in which the MSH file and XDMF files exist\n    Returns\n    -------\n    mesh:\n        Dolfin Mesh object containing the domain\n    boundaries_mf:\n        Dolfin MeshFunctionSizet object containing the geometry\n    subdomains_mf:\n        Dolfin MeshFunctionSizet object containing the geometry\n    link_dict:\n        Link dictionary between MSH and XDMF objects\n    \"\"\"\n    domain_file = os.path.join(directory, f\"{file_prefix}_{DOMAIN_SUFFIX}\")\n    boundary_file = os.path.join(directory, f\"{file_prefix}_{BOUNDARY_SUFFIX}\")\n    link_file = os.path.join(directory, f\"{file_prefix}_{LINKFILE_SUFFIX}\")\n    files = [domain_file, boundary_file, link_file]\n    exists = [os.path.exists(file) for file in files]\n\n    if not all(exists):\n        msg = \"\\n\".join([fn for fn, exist in zip(files, exists) if not exist])\n        raise MeshConversionError(f\"No mesh file(s) found:\\n {msg}\")\n\n    mesh = Mesh()\n\n    with XDMFFile(domain_file) as file:\n        file.read(mesh)\n\n    dimension = mesh.topology().dim()\n    boundaries_mvc = MeshValueCollection(\"size_t\", mesh, dim=dimension)\n\n    with XDMFFile(boundary_file) as file:\n        file.read(boundaries_mvc, \"boundaries\")\n\n    boundaries_mf = MeshFunctionSizet(mesh, boundaries_mvc)\n\n    if subdomains:\n        subdomains_mvc = MeshValueCollection(\"size_t\", mesh, dim=dimension)\n        with XDMFFile(domain_file) as file:\n            file.read(subdomains_mvc, \"subdomains\")\n        subdomains_mf = MeshFunctionSizet(mesh, subdomains_mvc)\n    else:\n        subdomains_mf = None\n\n    with open(link_file, \"r\") as file:\n        link_dict = json.load(file)\n\n    return mesh, boundaries_mf, subdomains_mf, link_dict",
  "def _check_dimensions(dimensions: Union[int, List[int]]) -> Tuple[int]:\n    if isinstance(dimensions, int):\n        dimensions = tuple(np.arange(dimensions))\n\n    if len(dimensions) not in [2, 3]:\n        raise MeshConversionError(\n            f\"Length of dimensions must be either 2 or 3, not: {len(dimensions)}\"\n        )\n    for dim in dimensions:\n        if dim not in [0, 1, 2]:\n            raise MeshConversionError(\n                f\"Dimensions tuple must contain integers 0, 1, or 2, not: {dim}\"\n            )\n\n    if len(dimensions) != len(set(dimensions)):\n        raise MeshConversionError(\n            f\"Dimensions tuple cannot have repeated integers: {dimensions}\"\n        )\n    return dimensions",
  "def _export_domain(mesh, file_prefix, directory, dimensions):\n    \"\"\"\n    Export the domain of a mesh to XDMF.\n    \"\"\"\n    dimensions = _check_dimensions(dimensions)\n\n    cell_type = CELL_TYPE_DIM[len(dimensions) + 1]\n    data = _get_data(mesh, cell_type)\n\n    if len(data) == 0:\n        bluemira_warn(f\"No domain physical group found in: {file_prefix}\")\n        return\n\n    if GMSH_PHYS not in mesh.cell_data:\n        raise MeshConversionError(f\"No domain physical group found in: {file_prefix}\")\n\n    cells = _make_cellblocks(data, cell_type)\n\n    subdomains = _get_cells(mesh, cell_type)\n\n    cell_data = {\"subdomains\": [np.concatenate(subdomains)]}\n\n    domain = _make_mesh(mesh, dimensions, cells, cell_data)\n\n    _write_mesh(\n        os.path.join(directory, f\"{file_prefix}_{DOMAIN_SUFFIX}\"),\n        domain,\n    )",
  "def _export_boundaries(mesh, file_prefix, directory, dimensions):\n    \"\"\"\n    Export the boundaries of a mesh to XDMF.\n    \"\"\"\n    dimensions = _check_dimensions(dimensions)\n\n    cell_type = CELL_TYPE_DIM[len(dimensions)]\n    data = _get_data(mesh, cell_type)\n\n    if len(data) == 0:\n        bluemira_warn(f\"No boundary physical group found in: {file_prefix}\")\n        return\n\n    cells = _make_cellblocks(data, cell_type)\n\n    boundaries = _get_cells(mesh, cell_type)\n\n    cell_data = {\"boundaries\": [np.concatenate(boundaries)]}\n\n    boundaries = _make_mesh(mesh, dimensions, cells, cell_data)\n\n    _write_mesh(\n        os.path.join(directory, f\"{file_prefix}_{BOUNDARY_SUFFIX}\"),\n        boundaries,\n    )",
  "def _export_link_file(mesh, file_prefix, directory):\n    \"\"\"\n    Export the association file between MSH and XDMF objects.\n    \"\"\"\n    table = {}\n    for key, arrays in mesh.cell_sets.items():\n        for i, array in enumerate(arrays):\n            if array.size != 0:\n                index = i\n        if key != GMSH_BE:\n            value = mesh.cell_data[GMSH_PHYS][index][0]\n            table[key] = int(value)\n\n    bluemira_debug(\n        tabulate(\n            list(table.items()),\n            headers=[\"GMSH label\", \"MeshFunction value\"],\n            tablefmt=\"simple\",\n        )\n    )\n\n    filename = os.path.join(directory, f\"{file_prefix}_{LINKFILE_SUFFIX}\")\n    with open(filename, \"w\") as file:\n        json.dump(table, file, indent=4)",
  "def _get_data(mesh, cell_type):\n    return [array for (typ, array) in mesh.cells if typ == cell_type]",
  "def _make_cellblocks(data, cell_type):\n    return [meshio.CellBlock(cell_type, np.concatenate(data))]",
  "def _make_mesh(mesh, dimensions, cells, cell_data):\n    return meshio.Mesh(\n        mesh.points[:, list(dimensions)], cells=cells, cell_data=cell_data\n    )",
  "def _get_cells(mesh, cell_type):\n    return [\n        mesh.cell_data[GMSH_PHYS][i]\n        for i, cell in enumerate(mesh.cells)\n        if cell.type == cell_type\n    ]",
  "def _write_mesh(filename, obj):\n    meshio.write(\n        filename,\n        obj,\n        file_format=\"xdmf\",\n    )",
  "class PsiPoint:\n    \"\"\"\n    Abstract object for psi-points with list indexing and point behaviour.\n    \"\"\"\n\n    __slots__ = (\"x\", \"z\", \"psi\")\n\n    def __init__(self, x: float, z: float, psi: float):\n        self.x, self.z = x, z\n        self.psi = psi\n\n    def __iter__(self):\n        \"\"\"\n        Imbue PsiPoint with generator-like behaviour\n        \"\"\"\n        yield self.x\n        yield self.z\n        yield self.psi\n\n    def __getitem__(self, i: int) -> float:\n        \"\"\"\n        Imbue PsiPoint with list-like behaviour\n        \"\"\"\n        return [self.x, self.z, self.psi][i]\n\n    def __str__(self) -> str:\n        \"\"\"\n        A better string representation of the PsiPoint.\n        \"\"\"\n        return (\n            f\"{self.__class__.__name__} x: {self.x:.2f}, z:{self.z:.2f}, \"\n            f\"psi: {self.psi:.2f}\"\n        )",
  "class Xpoint(PsiPoint):\n    \"\"\"\n    X-point class.\n    \"\"\"\n\n    __slots__ = ()",
  "class Opoint(PsiPoint):\n    \"\"\"\n    O-point class.\n    \"\"\"\n\n    __slots__ = ()",
  "class Lpoint(PsiPoint):\n    \"\"\"\n    Limiter point class.\n    \"\"\"\n\n    __slots__ = ()",
  "def find_local_minima(f: np.ndarray) -> np.ndarray.np.ndarray:\n    \"\"\"\n    Finds all local minima in a 2-D function map\n\n    Parameters\n    ----------\n    f:\n        The 2-D field on which to find local minima\n\n    Returns\n    -------\n    i:\n        The radial indices of local minima on the field map\n    j:\n        The vertical indices of local minima on the field map\n\n    Notes\n    -----\n    Cannot find minima on the corners of an array.\n    Cannot find \"plateau\" minima.\n    For our use case, neither limitation is relevant.\n    \"\"\"\n    return np.where(\n        (\n            (f < np.roll(f, 1, 0))\n            & (f < np.roll(f, -1, 0))\n            & (f <= np.roll(f, 0, 1))\n            & (f <= np.roll(f, 0, -1))\n            & (f < np.roll(f, 1, 1))\n            & (f < np.roll(f, -1, 1))\n        )\n    )",
  "def inv_2x2_matrix(a: float, b: float, c: float, d: float) -> np.ndarray:\n    \"\"\"\n    Inverse of a 2 x 2 [[a, b], [c, d]] matrix.\n    \"\"\"\n    return np.array([[d, -b], [-c, a]]) / (a * d - b * c)",
  "def find_local_Bp_minima_cg(\n    f_psi: RectBivariateSpline, x0: float, z0: float, radius: float\n) -> Union[None, Tuple[float, float]]:\n    \"\"\"\n    Find local Bp minima on a grid (precisely) using a local Newton/Powell\n    conjugate gradient search.\n\n    Parameters\n    ----------\n    f_psi:\n        The function handle for psi interpolation\n    x0:\n        The local grid minimum x coordinate\n    z0:\n        The local grid minimum z coordinate\n    radius:\n        The search radius\n\n    Returns\n    -------\n    x:\n        The x coordinate of the minimum. None if the minimum is not valid.\n    z:\n        The z coordinate of the minimum\n    \"\"\"\n    xi, zi = x0, z0\n    count = 0\n    while True:\n        Bx = -f_psi(xi, zi, dy=1, grid=False) / xi\n        Bz = f_psi(xi, zi, dx=1, grid=False) / xi\n        if np.hypot(Bx, Bz) < B_TOLERANCE:\n            return [xi, zi]\n        else:\n            a = -Bx / xi - f_psi(xi, zi, dy=1, dx=1)[0][0] / xi\n            b = -f_psi(xi, zi, dy=2)[0][0] / xi\n            c = -Bz / xi + f_psi(xi, zi, dx=2) / xi\n            d = f_psi(xi, zi, dx=1, dy=1)[0][0] / xi\n            inv_jac = inv_2x2_matrix(float(a), float(b), float(c), float(d))\n            delta = np.dot(inv_jac, [Bx, Bz])\n            xi -= delta[0]\n            zi -= delta[1]\n            count += 1\n            if ((xi - x0) ** 2 + (zi - z0) ** 2 > radius) or (count > 50):\n                return None",
  "def drop_space_duplicates(\n    points: Iterable, tol: float = X_TOLERANCE\n) -> List[np.ndarray]:\n    \"\"\"\n    Drop duplicates from a list of points if closer together than tol\n    \"\"\"\n    stack = []\n    for p1 in points:\n        duplicate = False\n        for p2 in stack:\n            if (p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2 < tol:\n                duplicate = True\n                break\n        if not duplicate:\n            stack.append(p1)\n    return stack",
  "def triage_OX_points(\n    f_psi: RectBivariateSpline, points: List[List[float]]\n) -> Tuple[List[Opoint], List[Xpoint]]:\n    \"\"\"\n    Triage the local Bp minima into O- and X-points: sort the field minima by second\n    derivative.\n\n    Parameters\n    ----------\n    f_psi:\n        The function handle for psi interpolation\n    points:\n\n    Returns\n    -------\n    o_points:\n        The O-point locations\n    x_points:\n        The X-point locations\n\n    Notes\n    -----\n    O-points have a positive 2nd derivative and X-points have a negative one:\n\n    \\t:math:`S=\\\\bigg(\\\\dfrac{{\\\\partial}{\\\\psi}^{2}}{{\\\\partial}X^{2}}\\\\bigg)`\n    \\t:math:`\\\\bigg(\\\\dfrac{{\\\\partial}{\\\\psi}^{2}}{{\\\\partial}Z^{2}}\\\\bigg)`\n    \\t:math:`-\\\\bigg(\\\\dfrac{{\\\\partial}{\\\\psi}^{2}}{{\\\\partial}X{\\\\partial}Z}`\n    \\t:math:`\\\\bigg)^{2}`\n    \"\"\"\n    o_points, x_points = [], []\n    for xi, zi in points:\n        d2dx2 = f_psi(xi, zi, dx=2, grid=False)\n        d2dz2 = f_psi(xi, zi, dy=2, grid=False)\n        d2dxdz = f_psi(xi, zi, dx=1, dy=1, grid=False)\n        s_value = d2dx2 * d2dz2 - d2dxdz**2\n\n        if s_value < 0:\n            x_points.append(Xpoint(xi, zi, f_psi(xi, zi)[0][0]))\n        else:  # Note: Low positive values are usually dubious O-points, and\n            # possibly should be labelled as X-points.\n            o_points.append(Opoint(xi, zi, f_psi(xi, zi)[0][0]))\n\n    return o_points, x_points",
  "def find_OX_points(\n    x: np.ndarray,\n    z: np.ndarray,\n    psi: np.ndarray,\n    limiter: Optional[Limiter] = None,\n    *,\n    field_cut_off: float = 1.0,\n) -> Tuple[List[Opoint], List[Union[Xpoint, Lpoint]]]:  # noqa :N802\n    \"\"\"\n    Finds O-points and X-points by minimising the poloidal field.\n\n    Parameters\n    ----------\n    x:\n        The spatial x coordinates of the grid points [m]\n    z:\n        The spatial z coordinates of the grid points [m]\n    psi:\n        The poloidal magnetic flux map [V.s/rad]\n    limiter:\n        The limiter to use (if any)\n    field_cut_off:\n        The field above which local minima are not searched [T]. Must be > 0.1 T\n\n    Returns\n    -------\n    o_points:\n        The O-points in the psi map\n    x_points: List[Union[Xpoint,LPoint]]\n        The X-points and L-points in the psi map\n\n    Notes\n    -----\n    \\t:math:`\\\\lvert{\\\\nabla}{\\\\psi}{\\\\lvert}^{2} = 0`\n\n    Local minima brute-forced, and subsequent accurate locations of the points\n    found by local optimisation.\n\n    For speed, does this on existing psi map (not exactly at optimum).\n\n    Points are order w.r.t. central grid coordinates.\n    \"\"\"\n    d_x, d_z = x[1, 0] - x[0, 0], z[0, 1] - z[0, 0]  # Grid resolution\n    x_m, z_m = (x[0, 0] + x[-1, 0]) / 2, (z[0, 0] + z[0, -1]) / 2  # Grid centre\n    nx, nz = psi.shape  # Grid shape\n    radius = min(0.5, 2 * np.hypot(d_x, d_z))  # Search radius\n    field_cut_off = max(100 * B_TOLERANCE, field_cut_off)\n\n    # Splines for interpolation\n    f_psi = RectBivariateSpline(x[:, 0], z[0, :], psi)\n\n    def f_Bx(x, z):\n        return -f_psi(x, z, dy=1, grid=False) / x\n\n    def f_Bz(x, z):\n        return f_psi(x, z, dx=1, grid=False) / x\n\n    def f_Bp(x, z):\n        return np.hypot(f_Bx(x, z), f_Bz(x, z))\n\n    Bp2 = f_Bx(x, z) ** 2 + f_Bz(x, z) ** 2\n\n    i_local, j_local = find_local_minima(Bp2)\n\n    points = []\n    for i, j in zip(i_local, j_local):\n        if i > nx - 3 or i < 3 or j > nz - 3 or j < 3:\n            continue  # Edge points uninteresting and mess up S calculation.\n\n        if f_Bp(x[i, j], z[i, j]) > field_cut_off:\n            continue  # Unlikely to be a field null\n\n        point = find_local_Bp_minima_cg(f_psi, x[i, j], z[i, j], radius)\n\n        if point:\n            points.append(point)\n\n    points = drop_space_duplicates(points)\n\n    o_points, x_points = triage_OX_points(f_psi, points)\n\n    if len(o_points) == 0:\n        print(\"\")  # stdout flusher\n        bluemira_warn(\n            \"EQUILIBRIA::find_OX: No O-points found during an iteration. Defaulting to grid centre.\"\n        )\n        o_points = [Opoint(x_m, z_m, f_psi(x_m, z_m))]\n        return o_points, x_points\n\n    # Sort O-points by centrality to the grid\n    o_points.sort(key=lambda o: (o.x - x_m) ** 2 + (o.z - z_m) ** 2)\n\n    if limiter is not None:\n        limit_x = [Lpoint(*lim, f_psi(*lim)[0][0]) for lim in limiter]\n        x_points.extend(limit_x)\n\n    if len(x_points) == 0:\n        # There is an O-point, but no X-points or L-points, so we will take the grid\n        # as a boundary\n        print(\"\")  # stdout flusher\n        bluemira_warn(\n            \"EQUILIBRIA::find_OX: No X-points found during an iteration, using grid boundary to limit the plasma.\"\n        )\n        x_grid_edge = np.concatenate([x[0, :], x[:, 0], x[-1, :], x[:, -1]])\n        z_grid_edge = np.concatenate([z[0, :], z[:, 0], z[-1, :], z[:, -1]])\n        x_points = [\n            Lpoint(xi, zi, f_psi(xi, zi)[0][0])\n            for xi, zi in zip(x_grid_edge, z_grid_edge)\n        ]\n\n    x_op, z_op, psio = o_points[0]  # Primary O-point\n    useful_x, useless_x = [], []\n    for xp in x_points:\n        x_xp, z_xp, psix = xp\n        d_l = np.hypot(x_xp - x_op, z_xp - z_op)\n        n_line = max(2, int(d_l // radius) + 1)\n        xx, zz = np.linspace(x_op, x_xp, n_line), np.linspace(z_op, z_xp, n_line)\n        if psix < psio:\n            psi_ox = -f_psi(xx, zz, grid=False)\n        else:\n            psi_ox = f_psi(xx, zz, grid=False)\n\n        if np.argmin(psi_ox) > 1:\n            useless_x.append(xp)\n            continue  # Check O-point is within 1 gridpoint on line\n\n        if (max(psi_ox) - psi_ox[-1]) / (max(psi_ox) - psi_ox[0]) > 0.025:\n            useless_x.append(xp)\n            continue  # Not monotonic\n\n        useful_x.append(xp)\n\n    # Sort X-points by proximity to O-point psi\n    useful_x.sort(key=lambda x: (x.psi - psio) ** 2)\n    useful_x.extend(useless_x)\n    return o_points, useful_x",
  "def _parse_OXp(x, z, psi, o_points, x_points):  # noqa :N802\n    \"\"\"\n    Handles Op and Xp retrieval, depending on combinations of None/not None\n    \"\"\"\n    if o_points is None and x_points is None:\n        # The plasma is diverted\n        o_points, x_points = find_OX_points(x, z, psi)\n\n    if o_points is None and x_points is not None:\n        # Keep specified Xp\n        o_points, _ = find_OX_points(x, z, psi)\n\n    if o_points is not None and x_points is None:\n        # A circular plasma which is neither divertor nor limited?\n        raise EquilibriaError(\n            \"There are no X-points and the plasma is not limited. Something strange is going on.\"\n        )\n\n    if not isinstance(o_points, list):\n        o_points = [o_points]\n    if not isinstance(x_points, list):\n        x_points = [x_points]\n\n    return o_points, x_points",
  "def get_contours(\n    x: np.ndarray, z: np.ndarray, array: np.ndarray, value: float\n) -> List[np.ndarray]:\n    \"\"\"\n    Get the contours of a value in continuous array.\n\n    Parameters\n    ----------\n    x:\n        The x value array\n    z:\n        The z value array\n    array:\n        The value array\n    value: f\n        The value of the desired contour in the array\n\n    Returns\n    -------\n    The list of arrays of value contour(s) in the array\n    \"\"\"\n    con_gen = contour_generator(\n        x, z, array, name=\"mpl2014\", line_type=LineType.SeparateCode\n    )\n    return con_gen.lines(value)[0]",
  "def find_flux_surfs(\n    x: np.ndarray,\n    z: np.ndarray,\n    psi: np.ndarray,\n    psinorm: float,\n    o_points: Optional[List[Opoint]] = None,\n    x_points: Optional[List[Xpoint]] = None,\n) -> List[np.ndarray]:\n    \"\"\"\n    Finds all flux surfaces with a given normalised psi. If a flux loop goes off\n    the grid, separate sets of coordinates will be produced.\n\n    Parameters\n    ----------\n    x:\n        The spatial x coordinates of the grid points [m]\n    z:\n        The spatial z coordinates of the grid points [m]\n    psi:\n        The poloidal magnetic flux map [V.s/rad]\n    psinorm:\n        The normalised psi value of the desired flux surface [-]\n    o_points:\n        O-points to use to calculate psinorm\n    x_points:\n        X-points to use to calculate psinorm (saves time if you\n        have them)\n\n    Returns\n    -------\n    The coordinates of the loops that was found\n    \"\"\"\n    # NOTE: This may all fall over for multiple psi_norm islands with overlaps\n    # on the grid edges...\n    o_points, x_points = _parse_OXp(x, z, psi, o_points, x_points)\n    xo, zo, psio = o_points[0]\n    __, __, psix = x_points[0]\n    psinormed = psio - psinorm * (psio - psix)\n    return get_contours(x, z, psi, psinormed)",
  "def find_flux_surf(\n    x: np.ndarray,\n    z: np.ndarray,\n    psi: np.ndarray,\n    psinorm: float,\n    o_points: Optional[List[Opoint]] = None,\n    x_points: Optional[List[Xpoint]] = None,\n) -> np.ndarray:\n    \"\"\"\n    Picks a flux surface with a normalised psinorm relative to the separatrix.\n    Uses least squares to retain only the most appropriate flux surface. This\n    is taken to be the surface whose geometric centre is closest to the O-point\n\n    Parameters\n    ----------\n    x:\n        The spatial x coordinates of the grid points [m]\n    z:\n        The spatial z coordinates of the grid points [m]\n    psi:\n        The poloidal magnetic flux map [V.s/rad]\n    psinorm:\n        The normalised psi value of the desired flux surface [-]\n    o_points:\n        O-points to use to calculate psinorm\n    x_points:\n        X-points to use to calculate psinorm (saves time if you\n        have them)\n\n    Returns\n    -------\n    The flux surface coordinate array\n\n    \\t:math:`{\\\\Psi}_{N} = {\\\\psi}_{O}-N({\\\\psi}_{O}-{\\\\psi}_{X})`\n\n    Notes\n    -----\n    Uses matplotlib hacks to pick contour surfaces on psi(X, Z).\n    \"\"\"\n\n    def f_min(x_opt, z_opt):\n        \"\"\"\n        Error function for point clusters relative to.base.O-point\n        \"\"\"\n        return np.sum((np.mean(x_opt) - xo) ** 2 + (np.mean(z_opt) - zo) ** 2)\n\n    o_points, x_points = _parse_OXp(x, z, psi, o_points, x_points)\n    xo, zo, _ = o_points[0]\n    psi_surfs = find_flux_surfs(x, z, psi, psinorm, o_points=o_points, x_points=x_points)\n\n    if not psi_surfs:\n        raise EquilibriaError(f\"No flux surface found for psi_norm = {psinorm:.4f}\")\n\n    err = []\n\n    for group in psi_surfs:  # Choose the most logical flux surface\n        err.append(f_min(*group.T))\n\n    return psi_surfs[np.argmin(err)].T",
  "def find_field_surf(\n    x: np.ndarray, z: np.ndarray, Bp: np.ndarray, field: float\n) -> np.ndarray:\n    \"\"\"\n    Picks a field surface most likely to be the desired breakdown region\n\n    Parameters\n    ----------\n    x:\n        The spatial x coordinates of the grid points [m]\n    z:\n        The spatial z coordinates of the grid points [m]\n    Bp:\n        The field map\n    field:\n        The value of the desired field surfaces\n\n    Returns\n    -------\n    The coordinates of the field surface\n    \"\"\"\n    m, n = x.shape\n    xo, zo = x[m // 2, n // 2], z[m // 2, n // 2]\n\n    def f_min(x_opt, z_opt):\n        \"\"\"\n        Error function for point clusters relative to grid center\n        \"\"\"\n        return np.sum((np.mean(x_opt) - xo) ** 2 + (np.mean(z_opt) - zo) ** 2)\n\n    surfaces = get_contours(x, z, Bp, field)\n    err = []\n    areas = []\n    for group in surfaces:  # Choose the most \"logical\" surface\n        err.append(f_min(*group.T))\n        areas.append(get_area_2d(*group.T))\n\n    if areas:\n        if np.argmax(areas) != np.argmin(err):\n            bluemira_warn(\n                \"The most central field surface is not the largest one. You\"\n                \"need to check that this is what you want.\"\n            )\n        return surfaces[np.argmin(err)].T\n\n    else:\n        bluemira_warn(f\"No field surfaces at {field:.4f} T found.\")\n        return None",
  "def find_flux_surface_through_point(\n    x: np.ndarray,\n    z: np.ndarray,\n    psi: np.ndarray,\n    point_x: float,\n    point_z: float,\n    point_psi: float,\n) -> np.ndarray:\n    \"\"\"\n    Get a flux surface passing through a point.\n\n    Parameters\n    ----------\n    x:\n        The spatial x coordinates of the grid points [m]\n    z:\n        The spatial z coordinates of the grid points [m]\n    psi:\n        The poloidal magnetic flux map [V.s/rad]\n    point_x:\n        The radial coordinate of the point [m]\n    point_z:\n        The vertical coordinate of the point [m]\n    point_psi:\n        The magnetic flux at the point [V.s/rad]\n\n    Returns\n    -------\n    The coordinates of the flux surface\n    \"\"\"\n\n    def f_min(x_opt, z_opt):\n        return np.min(np.hypot(x_opt - point_x, z_opt - point_z))\n\n    flux_contours = get_contours(x, z, psi, point_psi)\n\n    error = [f_min(*group.T) for group in flux_contours]\n\n    return flux_contours[np.argmin(error)].T",
  "def find_LCFS_separatrix(\n    x: np.ndarray,\n    z: np.ndarray,\n    psi: np.ndarray,\n    o_points: Optional[List[Opoint]] = None,\n    x_points: Optional[List[Xpoint]] = None,\n    double_null: bool = False,\n    psi_n_tol: float = 1e-6,\n) -> Tuple[Coordinates, Union[Coordinates, List[Coordinates]]]:\n    \"\"\"\n    Find the \"true\" LCFS and separatrix(-ices) in an Equilibrium.\n\n    Parameters\n    ----------\n    x:\n        The spatial x coordinates of the grid points [m]\n    z:\n        The spatial z coordinates of the grid points [m]\n    psi:\n        The poloidal magnetic flux map [V.s/rad]\n    o_points:\n        The O-points in the psi map\n    x_points:\n        The X-points in the psi map\n    double_null:\n        Whether or not to search for a double null separatrix.\n    psi_n_tol:\n        The normalised psi tolerance to use\n\n    Returns\n    -------\n    lcfs:\n        The last closed flux surface\n    separatrix:\n        The plasma separatrix (first open flux surface). Will return a\n        list of Coordinates for double_null=True, with all four separatrix legs being\n        captured.\n\n    Notes\n    -----\n    We need to find the transition between the LCFS and the first \"open\" flux\n    surface. In theory this would be for psi_norm = 1, however because of grids\n    and interpolation this isn't exactly the case. So we search for the\n    normalised flux value where the flux surface first goes from being open to\n    closed.\n    \"\"\"\n\n    def get_flux_loop(psi_norm):\n        f_s = find_flux_surf(x, z, psi, psi_norm, o_points=o_points, x_points=x_points)\n        return Coordinates({\"x\": f_s[0], \"z\": f_s[1]})\n\n    low = 0.99  # Guaranteed (?) to be a closed flux surface\n    high = 1.01  # Guaranteed (?) to be an open flux surface\n\n    # Speed optimisations (avoid recomputing psi and O, X points)\n    if o_points is None or x_points is None:\n        o_points, x_points = find_OX_points(x, z, psi)\n\n    delta = high - low\n\n    while delta > psi_n_tol:\n        middle = low + delta / 2\n        flux_surface = get_flux_loop(middle)\n\n        if flux_surface.closed:\n            # Middle flux surface is still closed, shift search bounds\n            low = middle\n\n        else:\n            # Middle flux surface is open, shift search bounds\n            high = middle\n\n        delta = high - low\n\n    # NOTE: choosing \"low\" and \"high\" here is always right, and avoids more\n    # \"if\" statements...\n    lcfs = get_flux_loop(low)\n    separatrix = get_flux_loop(high)\n\n    if double_null:\n        # We already have the LCFS, just need to find the two open Coordinates for\n        # the separatrix\n\n        low = high\n        high = low + 0.02\n        delta = high - low\n        # Need to find two open Coordinates, not just the first open one...\n        z_ref = min(abs(min(lcfs.z)), abs(max(lcfs.z)))\n        while delta > psi_n_tol:\n            middle = low + delta / 2\n            flux_surface = get_flux_loop(middle)\n            z_new = min(abs(min(flux_surface.z)), abs(max(flux_surface.z)))\n            if np.isclose(z_new, z_ref, rtol=1e-3):\n                # Flux surface only open at one end\n                low = middle\n            else:\n                # Flux surface open at both ends\n                high = middle\n\n            delta = high - low\n\n        coords = find_flux_surfs(x, z, psi, high, o_points=o_points, x_points=x_points)\n        loops = [Coordinates({\"x\": c.T[0], \"z\": c.T[1]}) for c in coords]\n        loops.sort(key=lambda loop: -loop.length)\n        separatrix = loops[:2]\n    return lcfs, separatrix",
  "def _extract_leg(flux_line, x_cut, z_cut, delta_x, o_point_z):\n    radial_line = Coordinates(\n        {\"x\": [x_cut - delta_x, x_cut + delta_x], \"z\": [z_cut, z_cut]}\n    )\n    arg_inters = join_intersect(flux_line, radial_line, get_arg=True)\n    arg_inters.sort()\n    # Lower null vs upper null\n    func = operator.lt if z_cut < o_point_z else operator.gt\n\n    if len(arg_inters) > 2:\n        EquilibriaError(\n            \"Unexpected number of intersections with the separatrix around the X-point.\"\n        )\n\n    flux_legs = []\n    for arg in arg_inters:\n        if func(flux_line.z[arg + 1], flux_line.z[arg]):\n            leg = Coordinates(flux_line[:, arg:])\n        else:\n            leg = Coordinates(flux_line[:, : arg + 1])\n\n        # Make the leg flow away from the plasma core\n        if leg.argmin((x_cut, 0, z_cut)) > 3:\n            leg.reverse()\n\n        flux_legs.append(leg)\n    if len(flux_legs) == 1:\n        flux_legs = flux_legs[0]\n    return flux_legs",
  "def _extract_offsets(equilibrium, dx_offsets, ref_leg, direction, delta_x, o_point_z):\n    offset_legs = []\n    for dx in dx_offsets:\n        x, z = ref_leg.x[0] + direction * dx, ref_leg.z[0]\n        xl, zl = find_flux_surface_through_point(\n            equilibrium.x,\n            equilibrium.z,\n            equilibrium.psi(),\n            x,\n            z,\n            equilibrium.psi(x, z),\n        )\n        offset_legs.append(\n            _extract_leg(Coordinates({\"x\": xl, \"z\": zl}), x, z, delta_x, o_point_z)\n        )\n    return offset_legs",
  "def get_legs(\n    equilibrium: Equilibrium, n_layers: int = 1, dx_off: float = 0.0\n) -> Dict[str, List[Coordinates]]:\n    \"\"\"\n    Get the legs of a separatrix.\n\n    Parameters\n    ----------\n    equilibrium:\n        Equilibrium for which to find the separatrix legs\n    n_layers:\n        Number of flux surfaces to extract for each leg\n    dx_off:\n        Total span in radial space of the flux surfaces to extract\n\n    Returns\n    -------\n    Dictionary of the legs with each key containing a list of geometries\n\n    Raises\n    ------\n    EquilibriaError: if a strange number of legs would be found for an X-point\n\n    Notes\n    -----\n    Will return two legs in the case of a single null\n    Will return four legs in the case of a double null\n\n    We can't rely on the X-point being contained within the two legs, due to\n    interpolation and local minimum finding tolerances.\n    \"\"\"\n    o_points, x_points = equilibrium.get_OX_points()\n    o_point = o_points[0]\n    x_points = x_points[:2]\n    separatrix = equilibrium.get_separatrix()\n    delta = equilibrium.grid.dx\n    if n_layers == 1:\n        dx_offsets = None\n    else:\n        dx_offsets = np.linspace(0, dx_off, n_layers)[1:]\n\n    if isinstance(separatrix, list):\n        # Double null (sort in/out bottom/top)\n        separatrix.sort(key=lambda half_sep: np.min(half_sep.x))\n        x_points.sort(key=lambda x_point: x_point.z)\n        legs = []\n        for half_sep, direction in zip(separatrix, [-1, 1]):\n            for x_p in x_points:\n                sep_leg = _extract_leg(half_sep, x_p.x, x_p.z, delta, o_point.z)\n                quadrant_legs = [sep_leg]\n                if dx_offsets is not None:\n                    quadrant_legs.extend(\n                        _extract_offsets(\n                            equilibrium, dx_offsets, sep_leg, direction, delta, o_point.z\n                        )\n                    )\n                legs.append(quadrant_legs)\n        leg_dict = {\n            \"lower_inner\": legs[0],\n            \"lower_outer\": legs[2],\n            \"upper_inner\": legs[1],\n            \"upper_outer\": legs[3],\n        }\n    else:\n        # Single null\n        x_point = x_points[0]\n        legs = _extract_leg(separatrix, x_point.x, x_point.z, delta, o_point.z)\n        legs.sort(key=lambda leg: leg.x[0])\n        inner_leg, outer_leg = legs\n        inner_legs, outer_legs = [inner_leg], [outer_leg]\n        if dx_offsets is not None:\n            inner_legs.extend(\n                _extract_offsets(\n                    equilibrium, dx_offsets, inner_leg, -1, delta, o_point.z\n                )\n            )\n            outer_legs.extend(\n                _extract_offsets(equilibrium, dx_offsets, outer_leg, 1, delta, o_point.z)\n            )\n        location = \"lower\" if x_point.z < o_point.z else \"upper\"\n        leg_dict = {\n            f\"{location}_inner\": inner_legs,\n            f\"{location}_outer\": outer_legs,\n        }\n\n    return leg_dict",
  "def grid_2d_contour(x: np.ndarray, z: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Grid a smooth contour and get the outline of the cells it encompasses.\n\n    Parameters\n    ----------\n    x:\n        The closed ccw x coordinates\n    z:\n        The closed ccw z coordinates\n\n    Returns\n    -------\n    x_new:\n        The x coordinates of the grid-coordinates\n    z_new:\n        The z coordinates of the grid-coordinates\n    \"\"\"\n    x_new, z_new = [], []\n    for i, (xi, zi) in enumerate(zip(x[:-1], z[:-1])):\n        x_new.append(xi)\n        z_new.append(zi)\n        if not np.isclose(xi, x[i + 1]) and not np.isclose(zi, z[i + 1]):\n            # Add an intermediate point (ccw)\n            if (x[i + 1] > xi and z[i + 1] < zi) or (x[i + 1] < xi and z[i + 1] > zi):\n                x_new.append(x[i + 1])\n                z_new.append(zi)\n            else:\n                x_new.append(xi)\n                z_new.append(z[i + 1])\n\n    x_new.append(x[0])\n    z_new.append(z[0])\n    return np.array(x_new), np.array(z_new)",
  "def in_plasma(\n    x: np.ndarray,\n    z: np.ndarray,\n    psi: np.ndarray,\n    o_points: Optional[List[Opoint]] = None,\n    x_points: Optional[List[Xpoint]] = None,\n) -> np.ndarray:\n    \"\"\"\n    Get a psi-shaped mask of psi where 1 is inside the plasma, 0 outside.\n\n    Parameters\n    ----------\n    x:\n        The radial coordinates of the grid points\n    z:\n        The vertical coordinates of the grid points\n    psi:\n        The poloidal magnetic flux map [V.s/rad]\n    o_points:\n        O-points to use to calculate psinorm\n    x_points:\n        X-points to use to calculate psinorm (saves time if you\n        have them)\n\n    Returns\n    -------\n    Masking matrix for the location of the plasma [0 outside/1 inside]\n    \"\"\"\n    mask = np.zeros_like(psi)\n    lcfs, _ = find_LCFS_separatrix(x, z, psi, o_points=o_points, x_points=x_points)\n    return _in_plasma(x, z, mask, lcfs.xz.T)",
  "def in_zone(x: np.ndarray, z: np.ndarray, zone: np.ndarray):\n    \"\"\"\n    Get a masking matrix for a specified zone.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates array\n    z:\n        The z coordinates array\n    zone:\n        The array of point coordinates delimiting the zone\n\n    Returns\n    -------\n    The masking array where 1 denotes inside the zone, and 0 outside\n    \"\"\"\n    mask = np.zeros_like(x)\n    return _in_plasma(x, z, mask, zone)",
  "def _in_plasma(\n    x: np.ndarray, z: np.ndarray, mask: np.ndarray, sep: np.ndarray\n) -> np.ndarray:\n    \"\"\"\n    Get a masking matrix for a specified zone. JIT compilation utility.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates matrix\n    z:\n        The z coordinates matrix\n    mask:\n        The masking matrix to populate with 0 or 1 values\n    sep:\n        The array of point coordinates delimiting the zone\n\n    Returns\n    -------\n    The masking array where 1 denotes inside the zone, and 0 outside\n    \"\"\"\n    n, m = x.shape\n    for i in range(n):\n        for j in range(m):\n            if in_polygon(x[i, j], z[i, j], sep):\n                mask[i, j] = 1\n    return mask",
  "def __init__(self, x: float, z: float, psi: float):\n        self.x, self.z = x, z\n        self.psi = psi",
  "def __iter__(self):\n        \"\"\"\n        Imbue PsiPoint with generator-like behaviour\n        \"\"\"\n        yield self.x\n        yield self.z\n        yield self.psi",
  "def __getitem__(self, i: int) -> float:\n        \"\"\"\n        Imbue PsiPoint with list-like behaviour\n        \"\"\"\n        return [self.x, self.z, self.psi][i]",
  "def __str__(self) -> str:\n        \"\"\"\n        A better string representation of the PsiPoint.\n        \"\"\"\n        return (\n            f\"{self.__class__.__name__} x: {self.x:.2f}, z:{self.z:.2f}, \"\n            f\"psi: {self.psi:.2f}\"\n        )",
  "def f_Bx(x, z):\n        return -f_psi(x, z, dy=1, grid=False) / x",
  "def f_Bz(x, z):\n        return f_psi(x, z, dx=1, grid=False) / x",
  "def f_Bp(x, z):\n        return np.hypot(f_Bx(x, z), f_Bz(x, z))",
  "def f_min(x_opt, z_opt):\n        \"\"\"\n        Error function for point clusters relative to.base.O-point\n        \"\"\"\n        return np.sum((np.mean(x_opt) - xo) ** 2 + (np.mean(z_opt) - zo) ** 2)",
  "def f_min(x_opt, z_opt):\n        \"\"\"\n        Error function for point clusters relative to grid center\n        \"\"\"\n        return np.sum((np.mean(x_opt) - xo) ** 2 + (np.mean(z_opt) - zo) ** 2)",
  "def f_min(x_opt, z_opt):\n        return np.min(np.hypot(x_opt - point_x, z_opt - point_z))",
  "def get_flux_loop(psi_norm):\n        f_s = find_flux_surf(x, z, psi, psi_norm, o_points=o_points, x_points=x_points)\n        return Coordinates({\"x\": f_s[0], \"z\": f_s[1]})",
  "class Snapshot:\n    \"\"\"\n    Abstract object for grouping of equilibria objects in a given state.\n\n    Parameters\n    ----------\n    eq:\n        The equilibrium at the snapshot\n    coilset:\n        The coilset at the snapshot\n    opt_problem:\n        The constraints at the snapshot\n    profiles:\n        The profile at the snapshot\n    optimisation_result:\n        The optimisation result\n    limiter:\n        The limiter for the snapshot\n    tfcoil:\n        The PF coil placement boundary\n    \"\"\"\n\n    eq: MHDState\n    coilset: CoilSet\n    constraints: Optional[CoilsetOptimisationProblem] = None\n    profiles: Optional[Profile] = None\n    optimisation_result: Optional[CoilsetOptimiserResult] = None\n    limiter: Optional[Limiter] = None\n    tfcoil: Optional[Coordinates] = None\n\n    def __post_init__(self):\n        \"\"\"Copy some variables on initialisation\"\"\"\n        for fld in fields(type(self)):\n            if (val := getattr(self, fld.name)) is not None and fld.name not in (\n                \"constraints\",\n                \"tfcoil\",\n            ):\n                setattr(self, fld.name, deepcopy(val))",
  "class BreakdownCOPSettings:\n    \"\"\"Breakdown settings for PulsedCoilsetDesign\"\"\"\n\n    problem: Type[BreakdownCOP] = BreakdownCOP\n    strategy: Type[BreakdownZoneStrategy] = CircularZoneStrategy\n    algorithm: AlgorithmType = Algorithm.COBYLA\n    opt_conditions: Dict[str, Union[float, int]] = field(\n        default_factory=lambda: {\"max_eval\": 5000, \"ftol_rel\": 1e-10}\n    )\n    B_stray_con_tol: float = 1e-8\n    n_B_stray_points: int = 20",
  "class EQSettings:\n    \"\"\"Equilibrium settings for PulsedCoilsetDesign\"\"\"\n\n    problem: Type[CoilsetOptimisationProblem] = MinimalCurrentCOP\n    convergence: ConvergenceCriterion = field(\n        default_factory=lambda: DudsonConvergence(1e-2)\n    )\n    algorithm: AlgorithmType = Algorithm.SLSQP\n    opt_conditions: Dict[str, Union[float, int]] = field(\n        default_factory=lambda: {\"max_eval\": 1000, \"ftol_rel\": 1e-6}\n    )\n    opt_parameters: Dict[str, Any] = field(\n        default_factory=lambda: {\"initial_step\": 0.03}\n    )\n    coil_mesh_size: float = 0.3\n    gamma: float = 1e-8\n    relaxation: float = 0.1\n    peak_PF_current_factor: float = 1.5",
  "class PositionSettings:\n    \"\"\"Position optimiser settings\"\"\"\n\n    problem: Type[PulsedNestedPositionCOP] = PulsedNestedPositionCOP\n    algorithm: AlgorithmType = Algorithm.COBYLA\n    opt_conditions: Dict[str, Union[float, int]] = field(\n        default_factory=lambda: {\"max_eval\": 100, \"ftol_rel\": 1e-4}\n    )",
  "class PulsedCoilsetDesignFrame(ParameterFrame):\n    \"\"\"PulsedCoilsetDesign Parameters\"\"\"\n\n    A: Parameter[float]\n    B_premag_stray_max: Parameter[float]\n    C_Ejima: Parameter[float]\n    I_p: Parameter[float]\n    l_i: Parameter[float]\n    R_0: Parameter[float]\n    tau_flattop: Parameter[float]\n    tk_sol_ib: Parameter[float]\n    v_burn: Parameter[float]",
  "class PulsedCoilsetDesign(ABC):\n    \"\"\"\n    Abstract base class for the procedural design of a pulsed tokamak poloidal field\n    coilset.\n\n    Parameters\n    ----------\n    params:\n        Parameter frame with which to perform the problem\n    coilset:\n        PF coilset to use in the equilibrium design\n    grid:\n        Grid to use in the equilibrium design\n    equilibrium_constraints:\n        List of magnetic constraints to use for equilibria. Depending on the optimisation\n        problem, these may be used in the objective function or constraints\n    profiles:\n        Plasma profile object to use when solving equilibria\n    breakdown_strategy_cls:\n        BreakdownZoneStrategy class to use when determining breakdown constraints\n    breakdown_problem_cls:\n        Coilset optimisation problem class for the breakdown phase\n    breakdown_optimiser:\n        Optimiser for the breakdown,\n        default is COBYLA with ftol_rel=1e-10 and max_eval=5000\n    breakdown_settings:\n        Breakdown optimiser settings\n    equilibrium_problem_cls:\n        Coilset optimisation problem class for the equilibria and current vector\n    equilibrium_optimiser:\n        Optimiser for the equilibria and current vector\n        default is SLSQP with ftol_rel=1e-6 and max_eval=1000\n    equilibrium_convergence:\n        Convergence criteria to use when solving equilibria\n        default is 1e-2 DudsonConvergence\n    equilibrium_settings:\n        Settings for the solution of equilibria\n    current_opt_constraints:\n        List of current optimisation constraints for equilibria\n    coil_constraints:\n        List of coil current optimisation constraints for all snapshots (including\n        breakdown)\n    limiter:\n        Limiter to use when solving equilibria\n    \"\"\"\n\n    BREAKDOWN = \"Breakdown\"\n    EQ_REF = \"Reference\"\n    SOF = \"SOF\"\n    EOF = \"EOF\"\n\n    def __init__(\n        self,\n        params: ParameterFrame,\n        coilset: CoilSet,\n        grid: Grid,\n        equilibrium_constraints: List[MagneticConstraint],\n        profiles: Profile,\n        breakdown_settings: Optional[Union[Dict, BreakdownCOPSettings]] = None,\n        equilibrium_settings: Optional[Union[Dict, EQSettings]] = None,\n        # Remove in v2\n        breakdown_strategy_cls: Optional[Type[BreakdownZoneStrategy]] = None,\n        breakdown_problem_cls: Optional[Type[BreakdownCOP]] = None,\n        breakdown_optimiser: Optional[Optimiser] = None,\n        equilibrium_problem_cls: Optional[Type[CoilsetOptimisationProblem]] = None,\n        equilibrium_optimiser: Optional[Optimiser] = None,\n        equilibrium_convergence: Optional[ConvergenceCriterion] = None,\n        # eos\n        current_opt_constraints: Optional[List[UpdateableConstraint]] = None,\n        coil_constraints: Optional[List[UpdateableConstraint]] = None,\n        limiter: Optional[Limiter] = None,\n    ):\n        self.snapshots = {}\n        self.params = PulsedCoilsetDesignFrame.from_frame(params)\n        self.coilset = coilset\n        self.grid = grid\n\n        self._current_opt_cons = current_opt_constraints\n        self.eq_constraints = equilibrium_constraints\n        self.profiles = profiles\n        self.bd_settings = breakdown_settings\n        self.eq_settings = equilibrium_settings\n\n        # Remove in v2\n        warn_string = (\n            f\"Use of {type(self).__name__}'s '{{}}' argument is \"\n            \"deprecated and it will be removed in version 2.0.0.\\n\"\n            \"See \"\n            \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n            \"optimisation.html \"\n            \"for documentation of the new optimisation module.\"\n        )\n        if breakdown_optimiser is not None:\n            warnings.warn(\n                warn_string.format(\"breakdown_optimiser\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            # warn\n            self.bd_settings.opt_conditions = {\n                **(\n                    {}\n                    if breakdown_optimiser.opt_conditions is None\n                    else breakdown_optimiser.opt_conditions\n                ),\n                **self.bd_settings.opt_conditions,\n            }\n\n            self.bd_settings.algorithm = breakdown_optimiser.algorithm_name\n        if breakdown_problem_cls is not None:\n            warnings.warn(\n                warn_string.format(\"breakdown_problem_cls\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.bd_settings.problem = breakdown_problem_cls\n\n        if breakdown_strategy_cls is not None:\n            warnings.warn(\n                warn_string.format(\"breakdown_strategy_cls\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.bd_settings.strategy = breakdown_strategy_cls\n\n        if equilibrium_optimiser is not None:\n            warnings.warn(\n                warn_string.format(\"equilibrium_optimiser\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.eq_settings.opt_conditions = {\n                **(\n                    {}\n                    if equilibrium_optimiser.opt_conditions is None\n                    else equilibrium_optimiser.opt_conditions\n                ),\n                **self.eq_settings.opt_conditions,\n            }\n\n            self.eq_settings.algorithm = equilibrium_optimiser.algorithm_name\n            self.eq_settings.opt_parameters = {\n                **(\n                    {}\n                    if equilibrium_optimiser.opt_parameters is None\n                    else equilibrium_optimiser.opt_parameters\n                ),\n                **self.eq_settings.opt_parameters,\n            }\n\n        if equilibrium_convergence is not None:\n            warnings.warn(\n                warn_string.format(\"equilibrium_convergence\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.eq_settings.convergence = equilibrium_convergence\n        if equilibrium_problem_cls is not None:\n            warnings.warn(\n                warn_string.format(\"equilibrium_problem_cls\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.eq_settings.problem = equilibrium_problem_cls\n        # eos\n\n        self._coil_cons = [] if coil_constraints is None else coil_constraints\n        self.limiter = limiter\n\n    @abstractmethod\n    def optimise(self, *args, **kwargs) -> CoilSet:\n        \"\"\"Run pulsed coilset design optimisation.\"\"\"\n\n    @property\n    def bd_settings(self) -> BreakdownCOPSettings:\n        \"\"\"Breakdown COP settings.\"\"\"\n        return self.__bd_settings\n\n    @property\n    def _bd_settings(self) -> BreakdownCOPSettings:\n        return self.__bd_settings\n\n    @bd_settings.setter\n    def bd_settings(self, value: Optional[Union[Dict, BreakdownCOPSettings]] = None):\n        \"\"\"Breakdown COP settings.\"\"\"\n        if value is None:\n            self.__bd_settings = BreakdownCOPSettings()\n        elif isinstance(value, BreakdownCOPSettings):\n            self.__bd_settings = value\n        else:\n            self.__bd_settings = BreakdownCOPSettings(**value)\n\n    @property\n    def eq_settings(self) -> EQSettings:\n        \"\"\"Equilibrium COP settings.\"\"\"\n        return self.__eq_settings\n\n    @property\n    def _eq_settings(self) -> EQSettings:\n        return self.__eq_settings\n\n    @eq_settings.setter\n    def eq_settings(self, value: Optional[Union[EQSettings, Dict]] = None):\n        \"\"\"Equilibrium COP settings.\"\"\"\n        if value is None:\n            self.__eq_settings = EQSettings()\n        elif isinstance(value, EQSettings):\n            self.__eq_settings = value\n        else:\n            self.__eq_settings = EQSettings(**value)\n\n    def take_snapshot(\n        self,\n        name: str,\n        eq: MHDState,\n        coilset: CoilSet,\n        problem: CoilsetOptimisationProblem,\n        profiles: Optional[Profile] = None,\n    ):\n        \"\"\"Take a snapshot of the pulse.\"\"\"\n        if name in self.snapshots:\n            bluemira_warn(f\"Over-writing snapshot {name}!\")\n\n        self.snapshots[name] = Snapshot(\n            eq, coilset, problem, profiles, limiter=self.limiter\n        )\n\n    def run_premagnetisation(self):\n        \"\"\"Run the breakdown optimisation problem.\"\"\"\n        R_0 = self.params.R_0.value\n        strategy = self.bd_settings.strategy(\n            R_0, self.params.A.value, self.params.tk_sol_ib.value\n        )\n\n        i_max = 30\n        relaxed = all(self.coilset._flag_sizefix)\n        for i in range(i_max):\n            coilset = deepcopy(self.coilset)\n            breakdown = Breakdown(coilset, self.grid)\n            constraints = deepcopy(self._coil_cons)\n\n            if relaxed:\n                max_currents = self.coilset.get_max_current(0)\n            else:\n                max_currents = self.coilset.get_max_current(self.params.I_p.value)\n                coilset.get_control_coils().current = max_currents\n                coilset.discretisation = self.eq_settings.coil_mesh_size\n\n            problem = self.bd_settings.problem(\n                breakdown.coilset,\n                breakdown,\n                strategy,\n                B_stray_max=self.params.B_premag_stray_max.value,\n                B_stray_con_tol=self.bd_settings.B_stray_con_tol,\n                n_B_stray_points=self.bd_settings.n_B_stray_points,\n                max_currents=max_currents,\n                opt_algorithm=self.bd_settings.algorithm,\n                opt_conditions=self.bd_settings.opt_conditions,\n                constraints=constraints,\n            )\n            result = problem.optimise(x0=max_currents, fixed_coils=False)\n            breakdown.set_breakdown_point(*strategy.breakdown_point)\n            psi_premag = breakdown.breakdown_psi\n\n            if i == 0:\n                psi_1 = psi_premag\n            if relaxed or np.isclose(psi_premag, psi_1, rtol=1e-2):\n                break\n\n        else:\n            raise EquilibriaError(\n                \"Unable to relax the breakdown optimisation for coil sizes.\"\n            )\n\n        bluemira_print(f\"Premagnetisation flux = {2*np.pi * psi_premag:.2f} V.s\")\n\n        self._psi_premag = 2 * np.pi * psi_premag\n        self.take_snapshot(self.BREAKDOWN, breakdown, result.coilset, problem)\n\n    def run_reference_equilibrium(self):\n        \"\"\"Run a reference equilibrium.\"\"\"\n        coilset = deepcopy(self.coilset)\n        eq = Equilibrium(\n            coilset,\n            self.grid,\n            self.profiles,\n        )\n        opt_problem = UnconstrainedTikhonovCurrentGradientCOP(\n            coilset,\n            eq,\n            MagneticConstraintSet(self.eq_constraints),\n            gamma=self.eq_settings.gamma,\n        )\n        program = PicardIterator(\n            eq,\n            opt_problem,\n            convergence=self.eq_settings.convergence,\n            relaxation=self.eq_settings.relaxation,\n            fixed_coils=True,\n            plot=False,\n        )\n        program()\n\n        opt_problem = self._make_opt_problem(\n            eq,\n            self._get_max_currents(eq.coilset),\n            current_constraints=None,\n            eq_constraints=[\n                deepcopy(con)\n                for con in self.eq_constraints\n                if not isinstance(con, (PsiConstraint, PsiBoundaryConstraint))\n            ],\n        )\n\n        program = PicardIterator(\n            eq,\n            opt_problem,\n            convergence=self.eq_settings.convergence,\n            relaxation=self.eq_settings.relaxation,\n            fixed_coils=True,\n            plot=False,\n        )\n        program()\n\n        self.take_snapshot(self.EQ_REF, eq, coilset, opt_problem, self.profiles)\n\n    def calculate_sof_eof_fluxes(self, psi_premag: Optional[float] = None):\n        \"\"\"Calculate the SOF and EOF plasma boundary fluxes.\"\"\"\n        if psi_premag is None:\n            if self.BREAKDOWN not in self.snapshots:\n                self.run_premagnetisation()\n            psi_premag = self.snapshots[self.BREAKDOWN].eq.breakdown_psi\n\n        psi_sof = calc_psib(\n            2 * np.pi * psi_premag,\n            self.params.R_0.value,\n            self.params.I_p.value,\n            self.params.l_i.value,\n            self.params.C_Ejima.value,\n        )\n        psi_eof = psi_sof - self.params.tau_flattop.value * self.params.v_burn.value\n        return psi_sof, psi_eof\n\n    def _get_max_currents(self, coilset: CoilSet) -> np.ndarray:\n        return coilset.get_max_current(\n            self.eq_settings.peak_PF_current_factor * self.params.I_p.value\n        )\n\n    def get_sof_eof_opt_problems(\n        self, psi_sof: float, psi_eof: float\n    ) -> List[CoilsetOptimisationProblem]:\n        \"\"\"Get start of flat top and end of flat top optimisation problems.\"\"\"\n        eq_ref = self.snapshots[self.EQ_REF].eq\n        max_currents_pf = self._get_max_currents(self.coilset.get_coiltype(\"PF\"))\n        max_currents = self._get_max_currents(self.coilset)\n\n        opt_problems = []\n        for psi_boundary in [psi_sof, psi_eof]:\n            eq = deepcopy(eq_ref)\n            eq.coilset.get_coiltype(\"PF\").resize(max_currents_pf)\n\n            current_constraints = []\n            if self._current_opt_cons:\n                current_constraints += deepcopy(self._current_opt_cons)\n            if self._coil_cons:\n                current_constraints += deepcopy(self._coil_cons)\n\n            eq_constraints = deepcopy(self.eq_constraints)\n            for constraints in (eq_constraints, current_constraints):\n                for con in constraints:\n                    if isinstance(con, (PsiBoundaryConstraint, PsiConstraint)):\n                        con.target_value = psi_boundary / (2 * np.pi)\n\n            opt_problems.append(\n                self._make_opt_problem(\n                    eq, max_currents, current_constraints, eq_constraints\n                )\n            )\n\n        return opt_problems\n\n    def _make_opt_problem(\n        self,\n        eq: Equilibrium,\n        max_currents: np.ndarray,\n        current_constraints: Optional[List[UpdateableConstraint]],\n        eq_constraints: List[MagneticConstraint],\n    ) -> CoilsetOptimisationProblem:\n        if self.eq_settings.problem == MinimalCurrentCOP:\n            constraints = eq_constraints\n            if current_constraints:\n                constraints += current_constraints\n\n            problem = self.eq_settings.problem(\n                eq.coilset,\n                eq,\n                max_currents=max_currents,\n                opt_conditions=self.eq_settings.opt_conditions,\n                opt_algorithm=self.eq_settings.algorithm,\n                constraints=constraints,\n            )\n        elif self.eq_settings.problem == TikhonovCurrentCOP:\n            problem = self.eq_settings.problem(\n                eq.coilset,\n                eq,\n                MagneticConstraintSet(eq_constraints),\n                gamma=self.eq_settings.gamma,\n                opt_conditions=self.eq_settings.opt_conditions,\n                opt_algorithm=self.eq_settings.algorithm,\n                opt_parameters=self.eq_settings.opt_parameters,\n                max_currents=max_currents,\n                constraints=current_constraints,\n            )\n        else:\n            raise EquilibriaError(\n                \"Only MinimalCurrentCOP and TikhonovCurrentCOP\"\n                \" equilibrium problems supported\"\n            )\n        return problem\n\n    def converge_equilibrium(self, eq: Equilibrium, problem: CoilsetOptimisationProblem):\n        \"\"\"Converge an equilibrium problem from a 'frozen' plasma optimised state.\"\"\"\n        program = PicardIterator(\n            eq,\n            problem,\n            fixed_coils=True,\n            convergence=self._eq_settings.convergence,\n            relaxation=self.eq_settings.relaxation,\n            plot=False,\n        )\n        program()\n\n    def converge_and_snapshot(\n        self,\n        sub_opt_problems: Iterable[CoilsetOptimisationProblem],\n        problem_names: Iterable[str] = (SOF, EOF),\n    ):\n        \"\"\"Converge equilibrium optimisation problems and take snapshots.\"\"\"\n        for snap, problem in zip(problem_names, sub_opt_problems):\n            eq = problem.eq\n            self.converge_equilibrium(eq, problem)\n            self.take_snapshot(snap, eq, eq.coilset, problem, eq.profiles)\n\n    def plot(self):\n        \"\"\"Plot the pulsed equilibrium problem.\"\"\"\n        n_snapshots = len(self.snapshots)\n        if n_snapshots == 0:\n            return None\n\n        f, ax = plt.subplots(1, n_snapshots)\n        for i, (k, snap) in enumerate(self.snapshots.items()):\n            axi = ax[i]\n            snap.eq.plot(ax=axi)\n            snap.coilset.plot(ax=axi)\n            if k == self.BREAKDOWN:\n                psi_name, psi_val = r\"$\\Psi_{bd}$\", snap.eq.breakdown_psi\n            else:\n                psi_name, psi_val = r\"$\\Psi_{b}$\", snap.eq.get_OX_points()[1][0].psi\n\n            axi.set_title(f\"{k} {psi_name}: {2* np.pi * psi_val:.2f} V.s\")\n        return f",
  "class FixedPulsedCoilsetDesign(PulsedCoilsetDesign):\n    \"\"\"Procedural design for a pulsed tokamak with a known, fixed PF coilset.\"\"\"\n\n    def optimise(self) -> CoilSet:\n        \"\"\"Run pulsed coilset design optimisation.\"\"\"\n        self.optimise_currents()\n        return self.coilset\n\n    def optimise_currents(self):\n        \"\"\"Optimise the coil currents at the start and end of the current flat-top.\"\"\"\n        psi_sof, psi_eof = self.calculate_sof_eof_fluxes()\n        if self.EQ_REF not in self.snapshots:\n            self.run_reference_equilibrium()\n\n        self.converge_and_snapshot(self.get_sof_eof_opt_problems(psi_sof, psi_eof))",
  "class OptimisedPulsedCoilsetDesign(PulsedCoilsetDesign):\n    \"\"\"\n    Procedural design for a pulsed tokamak with no prescribed PF coil positions.\n\n    Parameters\n    ----------\n    params:\n        Parameter frame with which to perform the problem\n    coilset:\n        PF coilset to use in the equilibrium design\n    position_mapper:\n        Normalised coil position mapping\n    grid:\n        Grid to use in the equilibrium design\n    equilibrium_constraints:\n        List of magnetic constraints to use for equilibria. Depending on the optimisation\n        problem, these may be used in the objective function or constraints\n    profiles:\n        Plasma profile object to use when solving equilibria\n    breakdown_strategy_cls:\n        BreakdownZoneStrategy class to use when determining breakdown constraints\n    breakdown_problem_cls:\n        Coilset optimisation problem class for the breakdown phase\n    breakdown_optimiser:\n        Optimiser for the breakdown,\n        default is COBYLA with ftol_rel=1e-10 and max_eval=5000\n    breakdown_settings:\n        Breakdown optimiser settings\n    equilibrium_problem_cls:\n        Coilset optimisation problem class for the equilibria and current vector\n    equilibrium_optimiser:\n        Optimiser for the equilibria and current vector\n        default is SLSQP with ftol_rel=1e-6 and max_eval=1000\n    equilibrium_convergence:\n        Convergence criteria to use when solving equilibria\n        default is 1e-2 DudsonConvergence\n    equilibrium_settings:\n        Settings for the solution of equilibria\n    current_opt_constraints:\n        List of current optimisation constraints for equilibria\n    coil_constraints:\n        List of coil current optimisation constraints for all snapshots (including\n        breakdown)\n    limiter:\n        Limiter to use when solving equilibria\n    position_problem_cls:\n        Coilset optimisation problem class for the coil positions\n    position_optimiser:\n        Optimiser for the coil positions\n        default is COBYLA with ftol_rel=1e-4 and max_eval=100\n    \"\"\"\n\n    def __init__(\n        self,\n        params: ParameterFrame,\n        coilset: CoilSet,\n        position_mapper: PositionMapper,\n        grid: Grid,\n        equilibrium_constraints: List[MagneticConstraint],\n        profiles: Profile,\n        breakdown_settings: Optional[Union[Dict, BreakdownCOPSettings]] = None,\n        equilibrium_settings: Optional[Union[Dict, EQSettings]] = None,\n        # Remove in v2\n        breakdown_strategy_cls: Optional[Type[BreakdownZoneStrategy]] = None,\n        breakdown_problem_cls: Optional[Type[BreakdownCOP]] = None,\n        breakdown_optimiser: Optional[Optimiser] = None,\n        equilibrium_problem_cls: Optional[Type[CoilsetOptimisationProblem]] = None,\n        equilibrium_optimiser: Optional[Optimiser] = None,\n        equilibrium_convergence: Optional[ConvergenceCriterion] = None,\n        # eos\n        current_opt_constraints: Optional[List[UpdateableConstraint]] = None,\n        coil_constraints: Optional[List[UpdateableConstraint]] = None,\n        limiter: Optional[Limiter] = None,\n        position_settings: Optional[Union[Dict, PositionSettings]] = None,\n        # Remove in v2\n        position_problem_cls: Optional[Type[PulsedNestedPositionCOP]] = None,\n        position_optimiser: Optional[Optimiser] = None,\n    ):\n        super().__init__(\n            params,\n            coilset,\n            grid,\n            equilibrium_constraints,\n            profiles,\n            breakdown_settings,\n            equilibrium_settings,\n            breakdown_strategy_cls,\n            breakdown_problem_cls,\n            breakdown_optimiser,\n            equilibrium_problem_cls,\n            equilibrium_optimiser,\n            equilibrium_convergence,\n            current_opt_constraints,\n            coil_constraints,\n            limiter,\n        )\n        self.coilset = self._prepare_coilset(self.coilset)\n        self.position_mapper = position_mapper\n\n        self.pos_settings = position_settings\n\n        warn_string = (\n            f\"Use of {type(self).__name__}'s '{{}}' argument is \"\n            \"deprecated and it will be removed in version 2.0.0.\\n\"\n            \"See \"\n            \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n            \"optimisation.html \"\n            \"for documentation of the new optimisation module.\"\n        )\n\n        if position_problem_cls is not None:\n            warnings.warn(\n                warn_string.format(\"position_problem_cls\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.pos_settings.problem = position_problem_cls\n        if position_optimiser is not None:\n            warnings.warn(\n                warn_string.format(\"position_optimiser\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.pos_settings.algorithm = position_optimiser.algorithm_name\n            self.pos_settings.opt_conditions = {\n                **(\n                    {}\n                    if position_optimiser.opt_conditions is None\n                    else position_optimiser.opt_conditions\n                ),\n                **self.pos_settings.opt_conditions,\n            }\n\n    @property\n    def pos_settings(self) -> PositionSettings:\n        \"\"\"Position COP settings.\"\"\"\n        return self._pos_settings\n\n    @pos_settings.setter\n    def pos_settings(self, value: Optional[Union[PositionSettings, Dict]] = None):\n        \"\"\"Position COP settings.\"\"\"\n        if value is None:\n            self._pos_settings = PositionSettings()\n        elif isinstance(value, PositionSettings):\n            self._pos_settings = value\n        else:\n            self._pos_settings = PositionSettings(**value)\n\n    def _prepare_coilset(self, coilset: CoilSet) -> CoilSet:\n        coilset = deepcopy(coilset)\n        coilset.discretisation = np.where(\n            coilset._flag_sizefix,\n            self.eq_settings.coil_mesh_size,\n            coilset.discretisation,\n        )\n        return coilset\n\n    def optimise(self, verbose: bool = False) -> CoilSet:\n        \"\"\"\n        Optimise the coil positions for the start and end of the current flat-top.\n        \"\"\"\n        psi_sof, psi_eof = self.calculate_sof_eof_fluxes()\n        if self.EQ_REF not in self.snapshots:\n            self.run_reference_equilibrium()\n\n        sub_opt_problems = self.get_sof_eof_opt_problems(psi_sof, psi_eof)\n\n        pos_opt_problem = self.pos_settings.problem(\n            sub_opt_problems[0].eq.coilset,\n            self.position_mapper,\n            sub_opt_problems,\n            self.pos_settings.algorithm,\n            self.pos_settings.opt_conditions,\n            constraints=None,\n        )\n        result = pos_opt_problem.optimise(verbose=verbose)\n        optimised_coilset = self._consolidate_coilset(result.coilset, sub_opt_problems)\n\n        self.converge_and_snapshot(sub_opt_problems)\n\n        # Re-run breakdown\n        psi_bd_orig = self._psi_premag\n        self.coilset = optimised_coilset\n        self.run_premagnetisation()\n        if self._psi_premag < psi_bd_orig - 2.0:\n            bluemira_warn(\n                \"Breakdown flux significantly lower with optimised coil positions: \"\n                f\"{self._psi_premag:.2f} < {psi_bd_orig:.2f}\"\n            )\n        return optimised_coilset\n\n    def _consolidate_coilset(\n        self, coilset: CoilSet, sub_opt_problems: Iterable[CoilsetOptimisationProblem]\n    ) -> CoilSet:\n        \"\"\"\n        Set the current bounds on the current optimisation problems, fix coil sizes, and\n        mesh.\n        \"\"\"\n        max_cs_currents = coilset.get_coiltype(\"CS\").get_max_current(0.0)\n        pf_currents = []\n        for problem in sub_opt_problems:\n            pf_coils = problem.eq.coilset.get_coiltype(\"PF\").get_control_coils()\n            pf_currents.append(np.abs(pf_coils.current))\n\n        max_pf_currents = np.max(pf_currents, axis=0)\n        # Relax the max currents a bit to avoid oscillation\n        max_pf_current = self.eq_settings.peak_PF_current_factor * self.params.I_p.value\n        max_pf_currents = np.clip(1.1 * max_pf_currents, 0, max_pf_current)\n\n        for problem in sub_opt_problems:\n            pf_coils = problem.eq.coilset.get_coiltype(\"PF\").get_control_coils()\n            pf_coils.resize(max_pf_currents)\n            pf_coils.fix_sizes()\n            pf_coils.discretisation = self.eq_settings.coil_mesh_size\n            problem.set_current_bounds(\n                np.concatenate([max_pf_currents, max_cs_currents])\n            )\n\n        consolidated_coilset = deepcopy(problem.eq.coilset)\n        consolidated_coilset.fix_sizes()\n        consolidated_coilset.get_control_coils().current = 0\n        return consolidated_coilset",
  "def __post_init__(self):\n        \"\"\"Copy some variables on initialisation\"\"\"\n        for fld in fields(type(self)):\n            if (val := getattr(self, fld.name)) is not None and fld.name not in (\n                \"constraints\",\n                \"tfcoil\",\n            ):\n                setattr(self, fld.name, deepcopy(val))",
  "def __init__(\n        self,\n        params: ParameterFrame,\n        coilset: CoilSet,\n        grid: Grid,\n        equilibrium_constraints: List[MagneticConstraint],\n        profiles: Profile,\n        breakdown_settings: Optional[Union[Dict, BreakdownCOPSettings]] = None,\n        equilibrium_settings: Optional[Union[Dict, EQSettings]] = None,\n        # Remove in v2\n        breakdown_strategy_cls: Optional[Type[BreakdownZoneStrategy]] = None,\n        breakdown_problem_cls: Optional[Type[BreakdownCOP]] = None,\n        breakdown_optimiser: Optional[Optimiser] = None,\n        equilibrium_problem_cls: Optional[Type[CoilsetOptimisationProblem]] = None,\n        equilibrium_optimiser: Optional[Optimiser] = None,\n        equilibrium_convergence: Optional[ConvergenceCriterion] = None,\n        # eos\n        current_opt_constraints: Optional[List[UpdateableConstraint]] = None,\n        coil_constraints: Optional[List[UpdateableConstraint]] = None,\n        limiter: Optional[Limiter] = None,\n    ):\n        self.snapshots = {}\n        self.params = PulsedCoilsetDesignFrame.from_frame(params)\n        self.coilset = coilset\n        self.grid = grid\n\n        self._current_opt_cons = current_opt_constraints\n        self.eq_constraints = equilibrium_constraints\n        self.profiles = profiles\n        self.bd_settings = breakdown_settings\n        self.eq_settings = equilibrium_settings\n\n        # Remove in v2\n        warn_string = (\n            f\"Use of {type(self).__name__}'s '{{}}' argument is \"\n            \"deprecated and it will be removed in version 2.0.0.\\n\"\n            \"See \"\n            \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n            \"optimisation.html \"\n            \"for documentation of the new optimisation module.\"\n        )\n        if breakdown_optimiser is not None:\n            warnings.warn(\n                warn_string.format(\"breakdown_optimiser\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            # warn\n            self.bd_settings.opt_conditions = {\n                **(\n                    {}\n                    if breakdown_optimiser.opt_conditions is None\n                    else breakdown_optimiser.opt_conditions\n                ),\n                **self.bd_settings.opt_conditions,\n            }\n\n            self.bd_settings.algorithm = breakdown_optimiser.algorithm_name\n        if breakdown_problem_cls is not None:\n            warnings.warn(\n                warn_string.format(\"breakdown_problem_cls\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.bd_settings.problem = breakdown_problem_cls\n\n        if breakdown_strategy_cls is not None:\n            warnings.warn(\n                warn_string.format(\"breakdown_strategy_cls\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.bd_settings.strategy = breakdown_strategy_cls\n\n        if equilibrium_optimiser is not None:\n            warnings.warn(\n                warn_string.format(\"equilibrium_optimiser\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.eq_settings.opt_conditions = {\n                **(\n                    {}\n                    if equilibrium_optimiser.opt_conditions is None\n                    else equilibrium_optimiser.opt_conditions\n                ),\n                **self.eq_settings.opt_conditions,\n            }\n\n            self.eq_settings.algorithm = equilibrium_optimiser.algorithm_name\n            self.eq_settings.opt_parameters = {\n                **(\n                    {}\n                    if equilibrium_optimiser.opt_parameters is None\n                    else equilibrium_optimiser.opt_parameters\n                ),\n                **self.eq_settings.opt_parameters,\n            }\n\n        if equilibrium_convergence is not None:\n            warnings.warn(\n                warn_string.format(\"equilibrium_convergence\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.eq_settings.convergence = equilibrium_convergence\n        if equilibrium_problem_cls is not None:\n            warnings.warn(\n                warn_string.format(\"equilibrium_problem_cls\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.eq_settings.problem = equilibrium_problem_cls\n        # eos\n\n        self._coil_cons = [] if coil_constraints is None else coil_constraints\n        self.limiter = limiter",
  "def optimise(self, *args, **kwargs) -> CoilSet:\n        \"\"\"Run pulsed coilset design optimisation.\"\"\"",
  "def bd_settings(self) -> BreakdownCOPSettings:\n        \"\"\"Breakdown COP settings.\"\"\"\n        return self.__bd_settings",
  "def _bd_settings(self) -> BreakdownCOPSettings:\n        return self.__bd_settings",
  "def bd_settings(self, value: Optional[Union[Dict, BreakdownCOPSettings]] = None):\n        \"\"\"Breakdown COP settings.\"\"\"\n        if value is None:\n            self.__bd_settings = BreakdownCOPSettings()\n        elif isinstance(value, BreakdownCOPSettings):\n            self.__bd_settings = value\n        else:\n            self.__bd_settings = BreakdownCOPSettings(**value)",
  "def eq_settings(self) -> EQSettings:\n        \"\"\"Equilibrium COP settings.\"\"\"\n        return self.__eq_settings",
  "def _eq_settings(self) -> EQSettings:\n        return self.__eq_settings",
  "def eq_settings(self, value: Optional[Union[EQSettings, Dict]] = None):\n        \"\"\"Equilibrium COP settings.\"\"\"\n        if value is None:\n            self.__eq_settings = EQSettings()\n        elif isinstance(value, EQSettings):\n            self.__eq_settings = value\n        else:\n            self.__eq_settings = EQSettings(**value)",
  "def take_snapshot(\n        self,\n        name: str,\n        eq: MHDState,\n        coilset: CoilSet,\n        problem: CoilsetOptimisationProblem,\n        profiles: Optional[Profile] = None,\n    ):\n        \"\"\"Take a snapshot of the pulse.\"\"\"\n        if name in self.snapshots:\n            bluemira_warn(f\"Over-writing snapshot {name}!\")\n\n        self.snapshots[name] = Snapshot(\n            eq, coilset, problem, profiles, limiter=self.limiter\n        )",
  "def run_premagnetisation(self):\n        \"\"\"Run the breakdown optimisation problem.\"\"\"\n        R_0 = self.params.R_0.value\n        strategy = self.bd_settings.strategy(\n            R_0, self.params.A.value, self.params.tk_sol_ib.value\n        )\n\n        i_max = 30\n        relaxed = all(self.coilset._flag_sizefix)\n        for i in range(i_max):\n            coilset = deepcopy(self.coilset)\n            breakdown = Breakdown(coilset, self.grid)\n            constraints = deepcopy(self._coil_cons)\n\n            if relaxed:\n                max_currents = self.coilset.get_max_current(0)\n            else:\n                max_currents = self.coilset.get_max_current(self.params.I_p.value)\n                coilset.get_control_coils().current = max_currents\n                coilset.discretisation = self.eq_settings.coil_mesh_size\n\n            problem = self.bd_settings.problem(\n                breakdown.coilset,\n                breakdown,\n                strategy,\n                B_stray_max=self.params.B_premag_stray_max.value,\n                B_stray_con_tol=self.bd_settings.B_stray_con_tol,\n                n_B_stray_points=self.bd_settings.n_B_stray_points,\n                max_currents=max_currents,\n                opt_algorithm=self.bd_settings.algorithm,\n                opt_conditions=self.bd_settings.opt_conditions,\n                constraints=constraints,\n            )\n            result = problem.optimise(x0=max_currents, fixed_coils=False)\n            breakdown.set_breakdown_point(*strategy.breakdown_point)\n            psi_premag = breakdown.breakdown_psi\n\n            if i == 0:\n                psi_1 = psi_premag\n            if relaxed or np.isclose(psi_premag, psi_1, rtol=1e-2):\n                break\n\n        else:\n            raise EquilibriaError(\n                \"Unable to relax the breakdown optimisation for coil sizes.\"\n            )\n\n        bluemira_print(f\"Premagnetisation flux = {2*np.pi * psi_premag:.2f} V.s\")\n\n        self._psi_premag = 2 * np.pi * psi_premag\n        self.take_snapshot(self.BREAKDOWN, breakdown, result.coilset, problem)",
  "def run_reference_equilibrium(self):\n        \"\"\"Run a reference equilibrium.\"\"\"\n        coilset = deepcopy(self.coilset)\n        eq = Equilibrium(\n            coilset,\n            self.grid,\n            self.profiles,\n        )\n        opt_problem = UnconstrainedTikhonovCurrentGradientCOP(\n            coilset,\n            eq,\n            MagneticConstraintSet(self.eq_constraints),\n            gamma=self.eq_settings.gamma,\n        )\n        program = PicardIterator(\n            eq,\n            opt_problem,\n            convergence=self.eq_settings.convergence,\n            relaxation=self.eq_settings.relaxation,\n            fixed_coils=True,\n            plot=False,\n        )\n        program()\n\n        opt_problem = self._make_opt_problem(\n            eq,\n            self._get_max_currents(eq.coilset),\n            current_constraints=None,\n            eq_constraints=[\n                deepcopy(con)\n                for con in self.eq_constraints\n                if not isinstance(con, (PsiConstraint, PsiBoundaryConstraint))\n            ],\n        )\n\n        program = PicardIterator(\n            eq,\n            opt_problem,\n            convergence=self.eq_settings.convergence,\n            relaxation=self.eq_settings.relaxation,\n            fixed_coils=True,\n            plot=False,\n        )\n        program()\n\n        self.take_snapshot(self.EQ_REF, eq, coilset, opt_problem, self.profiles)",
  "def calculate_sof_eof_fluxes(self, psi_premag: Optional[float] = None):\n        \"\"\"Calculate the SOF and EOF plasma boundary fluxes.\"\"\"\n        if psi_premag is None:\n            if self.BREAKDOWN not in self.snapshots:\n                self.run_premagnetisation()\n            psi_premag = self.snapshots[self.BREAKDOWN].eq.breakdown_psi\n\n        psi_sof = calc_psib(\n            2 * np.pi * psi_premag,\n            self.params.R_0.value,\n            self.params.I_p.value,\n            self.params.l_i.value,\n            self.params.C_Ejima.value,\n        )\n        psi_eof = psi_sof - self.params.tau_flattop.value * self.params.v_burn.value\n        return psi_sof, psi_eof",
  "def _get_max_currents(self, coilset: CoilSet) -> np.ndarray:\n        return coilset.get_max_current(\n            self.eq_settings.peak_PF_current_factor * self.params.I_p.value\n        )",
  "def get_sof_eof_opt_problems(\n        self, psi_sof: float, psi_eof: float\n    ) -> List[CoilsetOptimisationProblem]:\n        \"\"\"Get start of flat top and end of flat top optimisation problems.\"\"\"\n        eq_ref = self.snapshots[self.EQ_REF].eq\n        max_currents_pf = self._get_max_currents(self.coilset.get_coiltype(\"PF\"))\n        max_currents = self._get_max_currents(self.coilset)\n\n        opt_problems = []\n        for psi_boundary in [psi_sof, psi_eof]:\n            eq = deepcopy(eq_ref)\n            eq.coilset.get_coiltype(\"PF\").resize(max_currents_pf)\n\n            current_constraints = []\n            if self._current_opt_cons:\n                current_constraints += deepcopy(self._current_opt_cons)\n            if self._coil_cons:\n                current_constraints += deepcopy(self._coil_cons)\n\n            eq_constraints = deepcopy(self.eq_constraints)\n            for constraints in (eq_constraints, current_constraints):\n                for con in constraints:\n                    if isinstance(con, (PsiBoundaryConstraint, PsiConstraint)):\n                        con.target_value = psi_boundary / (2 * np.pi)\n\n            opt_problems.append(\n                self._make_opt_problem(\n                    eq, max_currents, current_constraints, eq_constraints\n                )\n            )\n\n        return opt_problems",
  "def _make_opt_problem(\n        self,\n        eq: Equilibrium,\n        max_currents: np.ndarray,\n        current_constraints: Optional[List[UpdateableConstraint]],\n        eq_constraints: List[MagneticConstraint],\n    ) -> CoilsetOptimisationProblem:\n        if self.eq_settings.problem == MinimalCurrentCOP:\n            constraints = eq_constraints\n            if current_constraints:\n                constraints += current_constraints\n\n            problem = self.eq_settings.problem(\n                eq.coilset,\n                eq,\n                max_currents=max_currents,\n                opt_conditions=self.eq_settings.opt_conditions,\n                opt_algorithm=self.eq_settings.algorithm,\n                constraints=constraints,\n            )\n        elif self.eq_settings.problem == TikhonovCurrentCOP:\n            problem = self.eq_settings.problem(\n                eq.coilset,\n                eq,\n                MagneticConstraintSet(eq_constraints),\n                gamma=self.eq_settings.gamma,\n                opt_conditions=self.eq_settings.opt_conditions,\n                opt_algorithm=self.eq_settings.algorithm,\n                opt_parameters=self.eq_settings.opt_parameters,\n                max_currents=max_currents,\n                constraints=current_constraints,\n            )\n        else:\n            raise EquilibriaError(\n                \"Only MinimalCurrentCOP and TikhonovCurrentCOP\"\n                \" equilibrium problems supported\"\n            )\n        return problem",
  "def converge_equilibrium(self, eq: Equilibrium, problem: CoilsetOptimisationProblem):\n        \"\"\"Converge an equilibrium problem from a 'frozen' plasma optimised state.\"\"\"\n        program = PicardIterator(\n            eq,\n            problem,\n            fixed_coils=True,\n            convergence=self._eq_settings.convergence,\n            relaxation=self.eq_settings.relaxation,\n            plot=False,\n        )\n        program()",
  "def converge_and_snapshot(\n        self,\n        sub_opt_problems: Iterable[CoilsetOptimisationProblem],\n        problem_names: Iterable[str] = (SOF, EOF),\n    ):\n        \"\"\"Converge equilibrium optimisation problems and take snapshots.\"\"\"\n        for snap, problem in zip(problem_names, sub_opt_problems):\n            eq = problem.eq\n            self.converge_equilibrium(eq, problem)\n            self.take_snapshot(snap, eq, eq.coilset, problem, eq.profiles)",
  "def plot(self):\n        \"\"\"Plot the pulsed equilibrium problem.\"\"\"\n        n_snapshots = len(self.snapshots)\n        if n_snapshots == 0:\n            return None\n\n        f, ax = plt.subplots(1, n_snapshots)\n        for i, (k, snap) in enumerate(self.snapshots.items()):\n            axi = ax[i]\n            snap.eq.plot(ax=axi)\n            snap.coilset.plot(ax=axi)\n            if k == self.BREAKDOWN:\n                psi_name, psi_val = r\"$\\Psi_{bd}$\", snap.eq.breakdown_psi\n            else:\n                psi_name, psi_val = r\"$\\Psi_{b}$\", snap.eq.get_OX_points()[1][0].psi\n\n            axi.set_title(f\"{k} {psi_name}: {2* np.pi * psi_val:.2f} V.s\")\n        return f",
  "def optimise(self) -> CoilSet:\n        \"\"\"Run pulsed coilset design optimisation.\"\"\"\n        self.optimise_currents()\n        return self.coilset",
  "def optimise_currents(self):\n        \"\"\"Optimise the coil currents at the start and end of the current flat-top.\"\"\"\n        psi_sof, psi_eof = self.calculate_sof_eof_fluxes()\n        if self.EQ_REF not in self.snapshots:\n            self.run_reference_equilibrium()\n\n        self.converge_and_snapshot(self.get_sof_eof_opt_problems(psi_sof, psi_eof))",
  "def __init__(\n        self,\n        params: ParameterFrame,\n        coilset: CoilSet,\n        position_mapper: PositionMapper,\n        grid: Grid,\n        equilibrium_constraints: List[MagneticConstraint],\n        profiles: Profile,\n        breakdown_settings: Optional[Union[Dict, BreakdownCOPSettings]] = None,\n        equilibrium_settings: Optional[Union[Dict, EQSettings]] = None,\n        # Remove in v2\n        breakdown_strategy_cls: Optional[Type[BreakdownZoneStrategy]] = None,\n        breakdown_problem_cls: Optional[Type[BreakdownCOP]] = None,\n        breakdown_optimiser: Optional[Optimiser] = None,\n        equilibrium_problem_cls: Optional[Type[CoilsetOptimisationProblem]] = None,\n        equilibrium_optimiser: Optional[Optimiser] = None,\n        equilibrium_convergence: Optional[ConvergenceCriterion] = None,\n        # eos\n        current_opt_constraints: Optional[List[UpdateableConstraint]] = None,\n        coil_constraints: Optional[List[UpdateableConstraint]] = None,\n        limiter: Optional[Limiter] = None,\n        position_settings: Optional[Union[Dict, PositionSettings]] = None,\n        # Remove in v2\n        position_problem_cls: Optional[Type[PulsedNestedPositionCOP]] = None,\n        position_optimiser: Optional[Optimiser] = None,\n    ):\n        super().__init__(\n            params,\n            coilset,\n            grid,\n            equilibrium_constraints,\n            profiles,\n            breakdown_settings,\n            equilibrium_settings,\n            breakdown_strategy_cls,\n            breakdown_problem_cls,\n            breakdown_optimiser,\n            equilibrium_problem_cls,\n            equilibrium_optimiser,\n            equilibrium_convergence,\n            current_opt_constraints,\n            coil_constraints,\n            limiter,\n        )\n        self.coilset = self._prepare_coilset(self.coilset)\n        self.position_mapper = position_mapper\n\n        self.pos_settings = position_settings\n\n        warn_string = (\n            f\"Use of {type(self).__name__}'s '{{}}' argument is \"\n            \"deprecated and it will be removed in version 2.0.0.\\n\"\n            \"See \"\n            \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n            \"optimisation.html \"\n            \"for documentation of the new optimisation module.\"\n        )\n\n        if position_problem_cls is not None:\n            warnings.warn(\n                warn_string.format(\"position_problem_cls\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.pos_settings.problem = position_problem_cls\n        if position_optimiser is not None:\n            warnings.warn(\n                warn_string.format(\"position_optimiser\"),\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            self.pos_settings.algorithm = position_optimiser.algorithm_name\n            self.pos_settings.opt_conditions = {\n                **(\n                    {}\n                    if position_optimiser.opt_conditions is None\n                    else position_optimiser.opt_conditions\n                ),\n                **self.pos_settings.opt_conditions,\n            }",
  "def pos_settings(self) -> PositionSettings:\n        \"\"\"Position COP settings.\"\"\"\n        return self._pos_settings",
  "def pos_settings(self, value: Optional[Union[PositionSettings, Dict]] = None):\n        \"\"\"Position COP settings.\"\"\"\n        if value is None:\n            self._pos_settings = PositionSettings()\n        elif isinstance(value, PositionSettings):\n            self._pos_settings = value\n        else:\n            self._pos_settings = PositionSettings(**value)",
  "def _prepare_coilset(self, coilset: CoilSet) -> CoilSet:\n        coilset = deepcopy(coilset)\n        coilset.discretisation = np.where(\n            coilset._flag_sizefix,\n            self.eq_settings.coil_mesh_size,\n            coilset.discretisation,\n        )\n        return coilset",
  "def optimise(self, verbose: bool = False) -> CoilSet:\n        \"\"\"\n        Optimise the coil positions for the start and end of the current flat-top.\n        \"\"\"\n        psi_sof, psi_eof = self.calculate_sof_eof_fluxes()\n        if self.EQ_REF not in self.snapshots:\n            self.run_reference_equilibrium()\n\n        sub_opt_problems = self.get_sof_eof_opt_problems(psi_sof, psi_eof)\n\n        pos_opt_problem = self.pos_settings.problem(\n            sub_opt_problems[0].eq.coilset,\n            self.position_mapper,\n            sub_opt_problems,\n            self.pos_settings.algorithm,\n            self.pos_settings.opt_conditions,\n            constraints=None,\n        )\n        result = pos_opt_problem.optimise(verbose=verbose)\n        optimised_coilset = self._consolidate_coilset(result.coilset, sub_opt_problems)\n\n        self.converge_and_snapshot(sub_opt_problems)\n\n        # Re-run breakdown\n        psi_bd_orig = self._psi_premag\n        self.coilset = optimised_coilset\n        self.run_premagnetisation()\n        if self._psi_premag < psi_bd_orig - 2.0:\n            bluemira_warn(\n                \"Breakdown flux significantly lower with optimised coil positions: \"\n                f\"{self._psi_premag:.2f} < {psi_bd_orig:.2f}\"\n            )\n        return optimised_coilset",
  "def _consolidate_coilset(\n        self, coilset: CoilSet, sub_opt_problems: Iterable[CoilsetOptimisationProblem]\n    ) -> CoilSet:\n        \"\"\"\n        Set the current bounds on the current optimisation problems, fix coil sizes, and\n        mesh.\n        \"\"\"\n        max_cs_currents = coilset.get_coiltype(\"CS\").get_max_current(0.0)\n        pf_currents = []\n        for problem in sub_opt_problems:\n            pf_coils = problem.eq.coilset.get_coiltype(\"PF\").get_control_coils()\n            pf_currents.append(np.abs(pf_coils.current))\n\n        max_pf_currents = np.max(pf_currents, axis=0)\n        # Relax the max currents a bit to avoid oscillation\n        max_pf_current = self.eq_settings.peak_PF_current_factor * self.params.I_p.value\n        max_pf_currents = np.clip(1.1 * max_pf_currents, 0, max_pf_current)\n\n        for problem in sub_opt_problems:\n            pf_coils = problem.eq.coilset.get_coiltype(\"PF\").get_control_coils()\n            pf_coils.resize(max_pf_currents)\n            pf_coils.fix_sizes()\n            pf_coils.discretisation = self.eq_settings.coil_mesh_size\n            problem.set_current_bounds(\n                np.concatenate([max_pf_currents, max_cs_currents])\n            )\n\n        consolidated_coilset = deepcopy(problem.eq.coilset)\n        consolidated_coilset.fix_sizes()\n        consolidated_coilset.get_control_coils().current = 0\n        return consolidated_coilset",
  "def coil_harmonic_amplitude_matrix(\n    input_coils: CoilSet, max_degree: int, r_t: float\n) -> np.ndarray:\n    \"\"\"\n    Construct matrix from harmonic amplitudes at given coil locations.\n\n    To get an array of spherical harmonic amplitudes/coefficients (A_l)\n    which can be used in a spherical harmonic approximation of the\n    vacuum/coil contribution to the poloidal flux (psi) do:\n\n    A_l = matrix harmonic amplitudes @ vector of coil currents\n\n    A_l can be used as constraints in optimisation, see spherical_harmonics_constraint.\n\n    N.B. for a single filament (coil):\n\n    .. math::\n        A_{l} = \\\\frac{1}{2} \\\\mu_{0} I_{f} \\\\sin{\\\\theta_{f}}\n        (\\\\frac{r_{t}}{r_{f}})^l\n        \\\\frac{P_{l} \\\\cos{\\\\theta_{f}}}{\\\\sqrt{l(l+1)}}\n\n    Where l = degree, and :math: P_{l} \\\\cos{\\\\theta_{f}} are the associated\n    Legendre polynomials of degree l and order (m) = 1.\n\n    Parameters\n    ----------\n    input_coils:\n        Bluemira CoilSet\n    max_degree:\n        Maximum degree of harmonic to calculate up to\n    r_t:\n        Typical length scale (e.g. radius at outer midplane)\n\n    Returns\n    -------\n    currents2harmonics:\n        Matrix of harmonic amplitudes\n\n    \"\"\"\n    x_f = input_coils.get_control_coils().x\n    z_f = input_coils.get_control_coils().z\n\n    # Spherical coords\n    r_f = np.sqrt(x_f**2 + z_f**2)\n    theta_f = np.arctan2(x_f, z_f)\n\n    # [number of degrees, number of coils]\n    currents2harmonics = np.zeros([max_degree, np.size(r_f)])\n    # First 'harmonic' is constant (this line avoids Nan issues)\n    currents2harmonics[0, :] = 1  #\n\n    # SH coefficients from function of the current distribution\n    # outside of the sphere containing the LCFS\n    # SH coefficients = currents2harmonics @ coil currents\n    degrees = np.arange(1, max_degree)[:, None]\n    ones = np.ones_like(degrees)\n    currents2harmonics[1:, :] = (\n        0.5\n        * MU_0\n        * (r_t / r_f)[None, :] ** degrees\n        * np.sin(theta_f)[None, :]\n        * lpmv(ones, degrees, np.cos(theta_f)[None, :])\n        / np.sqrt(degrees * (degrees + 1))\n    )\n\n    return currents2harmonics",
  "def harmonic_amplitude_marix(\n    collocation_r: np.ndarray, collocation_theta: np.ndarray, r_t: float\n) -> np.ndarray:\n    \"\"\"\n    Construct matrix from harmonic amplitudes at given points (in spherical coords).\n\n    The matrix is used in a spherical harmonic approximation of the vacuum/coil\n    contribution to the poloidal flux (psi):\n\n    .. math::\n        \\\\psi = \\\\sum{A_{l} \\\\frac{r^{l+1}}{r_{t}^l} \\\\sin{\\\\theta_{f}}\n        \\\\frac{P_{l} \\\\cos{\\\\theta_{f}}}{\\\\sqrt{l(l+1)}}}\n\n    Where l = degree, A_l are the spherical harmonic coefficients/amplitudes,\n    and :math: P_{l} \\\\cos{\\\\theta_{f}} are the associated Legendre polynomials of\n    degree l and order (m) = 1.\n\n    N.B. Vacuum Psi = Total Psi - Plasma Psi.\n\n    Parameters\n    ----------\n    collocation_r:\n        R values of collocation points\n    collocation_theta:\n        Theta values of collocation points\n    r_t:\n        Typical length scale (e.g. radius at outer midplane)\n\n    Returns\n    -------\n    harmonics2collocation: np.array\n        Matrix of harmonic amplitudes (to get spherical harmonic coefficients\n        use matrix @ coefficients = vector psi_vacuum at collocation points)\n    \"\"\"\n    # Maximum degree of harmonic to calculate up to = n_collocation - 1\n    # [number of points, number of degrees]\n    n = len(collocation_r)\n    harmonics2collocation = np.zeros([n, n - 1])\n    # First 'harmonic' is constant (this line avoids Nan issues)\n    harmonics2collocation[:, 0] = 1\n\n    # SH coefficient matrix\n    # SH coefficients = harmonics2collocation \\ vector psi_vacuum at collocation points\n    degrees = np.arange(1, n - 1)[None]\n    ones = np.ones_like(degrees)\n    harmonics2collocation[:, 1:] = (\n        collocation_r[:, None] ** (degrees + 1)\n        * np.sin(collocation_theta)[:, None]\n        * lpmv(ones, degrees, np.cos(collocation_theta)[:, None])\n        / ((r_t**degrees) * np.sqrt(degrees * (degrees + 1)))\n    )\n\n    return harmonics2collocation",
  "class PointType(Enum):\n    \"\"\"\n    Class for use with collocation_points function.\n    User can choose how the collocation points are distributed.\n    \"\"\"\n\n    ARC = auto()\n    ARC_PLUS_EXTREMA = auto()\n    RANDOM = auto()\n    RANDOM_PLUS_EXTREMA = auto()",
  "class Collocation:\n    \"\"\"Dataclass for collocation point locations.\"\"\"\n\n    r: np.ndarray\n    theta: np.ndarray\n    x: np.ndarray\n    z: np.ndarray",
  "def collocation_points(\n    n_points: int, plasma_boundary: np.ndarray, point_type: str\n) -> Collocation:\n    \"\"\"\n    Create a set of collocation points for use wih spherical harmonic\n    approximations. Points are found within the user-supplied\n    boundary and should correspond to the LCFS of a chosen equilibrium.\n    Current functionality is for:\n\n    - equispaced points on an arc of fixed radius,\n    - equispaced points on an arc plus extrema,\n    - random points within a circle enclosed by the LCFS,\n    - random points plus extrema.\n\n    Parameters\n    ----------\n    n_points:\n        Number of points/targets (not including extrema - these are added\n        automatically if relevant).\n    plasma_boundary:\n        XZ coordinates of the plasma boundary\n    point_type:\n        Method for creating a set of points: 'arc', 'arc_plus_extrema',\n        'random', or 'random_plus_extrema'\n\n    Returns\n    -------\n    Collocation:\n        - \"x\" and \"z\" values of collocation points.\n        - \"r\" and \"theta\" values of collocation points.\n\n    \"\"\"\n    point_type = PointType[point_type.upper()]\n    x_bdry = plasma_boundary.x\n    z_bdry = plasma_boundary.z\n\n    if point_type in (PointType.ARC, PointType.ARC_PLUS_EXTREMA):\n        # Hello spherical coordinates\n        theta_bdry = np.arctan2(x_bdry, z_bdry)\n\n        # Equispaced arc\n        collocation_theta = np.linspace(\n            np.amin(theta_bdry), np.amax(theta_bdry), n_points + 2\n        )\n        collocation_theta = collocation_theta[1:-1]\n        collocation_r = 0.9 * np.amax(x_bdry) * np.ones(n_points)\n\n        # Cartesian coordinates\n        collocation_x = collocation_r * np.sin(collocation_theta)\n        collocation_z = collocation_r * np.cos(collocation_theta)\n\n    if point_type in (PointType.RANDOM, PointType.RANDOM_PLUS_EXTREMA):\n        # Random sample within a circle enclosed by the LCFS\n        half_sample_x_range = 0.5 * (np.max(x_bdry) - np.min(x_bdry))\n        sample_r = half_sample_x_range * np.random.rand(n_points)\n        sample_theta = (np.random.rand(n_points) * 2 * np.pi) - np.pi\n\n        # Cartesian coordinates\n        collocation_x = (\n            sample_r * np.sin(sample_theta) + np.min(x_bdry) + half_sample_x_range\n        )\n        collocation_z = sample_r * np.cos(sample_theta) + z_bdry[np.argmax(x_bdry)]\n\n        # Spherical coordinates\n        collocation_r = np.sqrt(collocation_x**2 + collocation_z**2)\n        collocation_theta = np.arctan2(collocation_x, collocation_z)\n\n    if point_type in (PointType.ARC_PLUS_EXTREMA, PointType.RANDOM_PLUS_EXTREMA):\n        # Extrema\n        d = 0.1\n        extrema_x = np.array(\n            [\n                np.amin(x_bdry) + d,\n                np.amax(x_bdry) - d,\n                x_bdry[np.argmax(z_bdry)],\n                x_bdry[np.argmin(z_bdry)],\n            ]\n        )\n        extrema_z = np.array(\n            [\n                0,\n                0,\n                np.amax(z_bdry) - d,\n                np.amin(z_bdry) + d,\n            ]\n        )\n\n        # Equispaced arc + extrema\n        collocation_x = np.concatenate([collocation_x, extrema_x])\n        collocation_z = np.concatenate([collocation_z, extrema_z])\n\n        # Hello again spherical coordinates\n        collocation_r = np.sqrt(collocation_x**2 + collocation_z**2)\n        collocation_theta = np.arctan2(collocation_x, collocation_z)\n\n    return Collocation(collocation_r, collocation_theta, collocation_x, collocation_z)",
  "def lcfs_fit_metric(coords1: np.ndarray, coords2: np.ndarray) -> float:\n    \"\"\"\n    Calculate the value of the metric used for evaluating the SH approximation.\n    This is equal to 1 for non-intersecting LCFSs, and 0 for identical LCFSs.\n\n    Parameters\n    ----------\n    coords1:\n        Coordinates of plasma boundary from input equilibrium state\n    coords2:\n        Coordinates of plasma boundary from approximation equilibrium state\n\n    Returns\n    -------\n    fit_metric_value:\n        Measure of how 'good' the approximation is.\n        fit_metric_value = total area within one but not both LCFSs /\n        (input LCFS area + approximation LCFS area)\n\n    \"\"\"\n    # Test to see if the LCFS for the SH approx is not closed for some reason\n    if not coords2.closed:\n        # If not closed then go back and try again\n        bluemira_print(\n            \"The approximate LCFS is not closed. Trying again with more degrees.\"\n        )\n        return 1\n\n    # If the two LCFSs have identical coordinates then return a perfect fit metric\n    if np.array_equal(coords1.x, coords2.x) and np.array_equal(coords1.z, coords2.z):\n        bluemira_print(\"Perfect match! Original LCFS = SH approx LCFS\")\n        return 0\n\n    # Get area of within the original and the SH approx LCFS\n    area1 = get_area_2d(coords1.x, coords1.z)\n    area2 = get_area_2d(coords2.x, coords2.z)\n\n    # Find intersections of the LCFSs\n    xcross, zcross = get_intersect(coords1.xz, coords2.xz)\n\n    # Check there are an even number of intersections\n    if np.mod(len(xcross), 2) != 0:\n        bluemira_print(\n            \"Odd number of intersections for input and SH approx LCFS: this shouldn''t be possible. Trying again with more degrees.\"\n        )\n        return 1\n\n    # If there are no intersections then...\n    if len(xcross) == 0:\n        # Check if one LCFS is entirely within another\n        test_1_in_2 = polygon_in_polygon(coords2.xz.T, coords1.xz.T)\n        test_2_in_1 = polygon_in_polygon(coords1.xz.T, coords2.xz.T)\n        if all(test_1_in_2) or all(test_2_in_1):\n            # Calculate the metric if one is inside the other\n            return (np.max([area1, area2]) - np.min([area1, area2])) / (area1 + area2)\n        else:\n            # Otherwise they are in entirely different places\n            bluemira_print(\n                \"The approximate LCFS does not overlap with the original. Trying again with more degrees.\"\n            )\n            return 1\n\n    # Calculate the area between the intersections of the two LCFSs,\n    # i.e., area within one but not both LCFSs.\n    c1 = Coordinates({\"x\": coords1.x, \"z\": coords1.z})\n    c2 = Coordinates({\"x\": coords2.x, \"z\": coords2.z})\n    c1_face = BluemiraFace(make_polygon(c1, closed=True))\n    c2_face = BluemiraFace(make_polygon(c2, closed=True))\n    result1 = boolean_cut(c1_face, c2_face)\n    result2 = boolean_cut(c2_face, c1_face)\n\n    #  Calculate metric\n    return (sum([f.area for f in result1]) + sum([f.area for f in result2])) / (\n        c1_face.area + c2_face.area\n    )",
  "def coils_outside_sphere_vacuum_psi(\n    eq: Equilibrium,\n) -> Tuple[np.ndarray, np.ndarray, CoilSet]:\n    \"\"\"\n    Calculate the poloidal flux (psi) contribution from the vacuum/coils\n    located outside of the sphere containing the plasma, i.e., LCFS of\n    equilibrium state. N.B., currents from coilset are not considered here.\n\n    Parameters\n    ----------\n    eq:\n        Starting equilibrium to use for our approximation\n\n    Returns\n    -------\n    vacuum_psi:\n        Psi contribution from control coils\n        (only control coils! - be careful how you use it)\n    plasma_psi:\n        Psi contribution from plasma\n    new_coilset:\n        Coilset with control coils selected appropriately for use of SH approximation\n\n    \"\"\"\n    # Psi contribution from the coils = total - plasma contribution\n    plasma_psi = eq.plasma.psi(eq.grid.x, eq.grid.z)\n    vacuum_psi = eq.psi() - plasma_psi\n\n    # Approximation boundary - sphere must contain\n    # plasma/LCFS for chosen equilibrium.\n    # Are the control coils outside the sphere containing\n    # the last closed flux surface?\n\n    c_names = np.array(eq.coilset.name)\n\n    max_bdry_r = np.max(np.sqrt(eq.get_LCFS().x ** 2 + eq.get_LCFS().z ** 2))\n    coil_r = np.sqrt(np.array(eq.coilset.x) ** 2 + np.array(eq.coilset.z) ** 2)\n\n    if max_bdry_r > np.min(coil_r):\n        too_close_coils = c_names[coil_r <= max_bdry_r]\n        not_too_close_coils = c_names[coil_r > max_bdry_r].tolist()\n        bluemira_print(\n            f\"One or more of your coils is too close to the LCFS to be used in the SH approximation. Coil names: {too_close_coils}.\"\n        )\n\n        # Need a coilset with control coils outside sphere\n        new_coils = []\n        for n in eq.coilset.name:\n            new_coils.append(eq.coilset[n])\n        new_coilset = CoilSet(*new_coils, control_names=not_too_close_coils)\n    else:\n        new_coilset = deepcopy(eq.coilset)\n\n    # If not using all coils in approx (have set control coils)\n    if len(new_coilset.get_control_coils().name) != len(new_coilset.name):\n        # Calculate psi contribution from non-control coils\n        # This shouldn't matter if none of the coil currents have been set\n        non_ccoil_cont = new_coilset.psi(\n            eq.grid.x, eq.grid.z\n        ) - new_coilset.get_control_coils().psi(eq.grid.x, eq.grid.z)\n        # Remove contribution from non-control coils\n        vacuum_psi -= non_ccoil_cont\n\n    return vacuum_psi, plasma_psi, new_coilset",
  "def get_psi_harmonic_amplitudes(\n    vacuum_psi: np.ndarray, grid: Grid, collocation: Collocation, r_t: float\n) -> np.ndarray:\n    \"\"\"\n    Calculate the Spherical Harmonic (SH) amplitudes/coefficients needed to produce\n    a SH approximation of the vacuum (i.e. control coil) contribution to\n    the poloidal flux (psi).The number of degrees used in the approximation is\n    one less than the number of collocation points.\n\n    Parameters\n    ----------\n    vacuum_psi:\n        Psi contribution from coils that we wish to approximate\n    grid:\n        Associated grid\n    collocation:\n        Collocation points\n    r_t:\n        Typical length scale for spherical harmonic approximation\n        (default = maximum x value of LCFS).\n\n    Returns\n    -------\n    psi_harmonic_amplitudes:\n        SH coefficients for given number of degrees\n\n    \"\"\"\n    # Set up interpolation with gridded values\n    psi_func = RectBivariateSpline(grid.x[:, 0], grid.z[0, :], vacuum_psi)\n\n    # Evaluate at collocation points\n    collocation_psivac = psi_func.ev(collocation.x, collocation.z)\n\n    # Construct matrix from SH amplitudes for flux function at collocation points\n    harmonics2collocation = harmonic_amplitude_marix(\n        collocation.r, collocation.theta, r_t\n    )\n\n    # Fit harmonics to match values at collocation points\n    psi_harmonic_amplitudes, residual, rank, s = np.linalg.lstsq(\n        harmonics2collocation, collocation_psivac, rcond=None\n    )\n\n    return psi_harmonic_amplitudes",
  "def spherical_harmonic_approximation(\n    eq: Equilibrium,\n    n_points: int = None,\n    point_type: str = None,\n    acceptable_fit_metric: float = None,\n    r_t: float = None,\n    plot: bool = False,\n    nlevels: int = 50,\n) -> Tuple[CoilSet, float, np.ndarray, int, float, np.ndarray]:\n    \"\"\"\n    Calculate the spherical harmonic (SH) amplitudes/coefficients\n    needed as a reference value for the 'spherical_harmonics_constraint'\n    used in coilset optimisation.\n\n    Use a LCFS fit metric to determine the required number of degrees.\n\n    The number of degrees used in the approximation is one less than\n    the number of collocation points.\n\n    Parameters\n    ----------\n    eq:\n        Equilibria to use as starting point for approximation.\n        We will approximate psi using SHs - the aim is to keep the\n        core plasma contribution fixed (using SH amplitudes as constraints)\n        while being able to vary the vacuum (coil) contribution, so that\n        we do not need to re-solve for the equilibria during optimisation.\n    n_points:\n        Number of desired collocation points (default=8)\n        excluding extrema (always +4 automatically)\n    point_type:\n        Name that determines how the collocation points are selected,\n        (default=\"arc_plus_extrema\"). The following options are\n        available for collocation point distribution:\n        - 'arc' = equispaced points on an arc of fixed radius,\n        - 'arc_plus_extrema' = 'arc' plus the min and max points of the LCFS\n        in the x- and z-directions (4 points total),\n        - 'random',\n        - 'random_plus_extrema'.\n    acceptable_fit_metric:\n        Value between 0 and 1 chosen by user (default=0.01).\n        If the LCFS found using the SH approximation method perfectly matches the\n        LCFS of the input equilibria then the fit metric = 0.\n        A fit metric of 1 means that they do not overlap at all.\n        fit_metric_value = total area within one but not both LCFSs /\n        (input LCFS area + approximation LCFS area)\n    r_t:\n        Typical length scale for spherical harmonic approximation\n        (default = maximum x value of LCFS).\n    extra_info:\n        If False (default), return only the information needed for use in optimisation.\n        If True, return additional information and a plot comparing original psi\n        to the SH approximation.\n\n    Returns\n    -------\n    sh_coilset:\n        Coilset to use with SH approximation\n    r_t:\n        typical length scale for spherical harmonic approximation\n    coil_current_harmonic_amplitudes:\n        SH coefficients/amplitudes for required number of degrees\n    degree:\n        number of degrees required for a SH approx with the desired fit metric\n    fit_metric_value:\n        fit metric achieved\n    approx_total_psi:\n        the total psi obtained using the SH approximation\n    \"\"\"\n    # Default values if not input\n    if acceptable_fit_metric is None:\n        acceptable_fit_metric = 0.01\n    if n_points is None:\n        n_points = 8\n    if point_type is None:\n        point_type = \"arc_plus_extrema\"\n\n    # Get the necessary boundary locations and length scale\n    # for use in spherical harmonic approximations.\n    # Starting LCFS\n    eq_copy = deepcopy(eq)\n    original_LCFS = eq_copy.get_LCFS()\n\n    # Typical length scale default if not chosen by user\n    if r_t is None:\n        r_t = np.amax(original_LCFS.x)\n\n    # Grid keep the same as input equilibrium\n    grid = eq_copy.grid\n\n    # Contribution to psi that we would like to approximate\n    # (and plasma contribution for later), also make sure\n    # control coils are in acceptable locations for approximation\n    vacuum_psi, plasma_psi, sh_coilset = coils_outside_sphere_vacuum_psi(eq_copy)\n\n    # Create the set of collocation points within the LCFS for the SH calculations\n    collocation = collocation_points(\n        n_points,\n        original_LCFS,\n        point_type,\n    )\n\n    # SH amplitudes needed to produce an approximation of vacuum psi contribution\n    psi_harmonic_amplitudes = get_psi_harmonic_amplitudes(\n        vacuum_psi, grid, collocation, r_t\n    )\n\n    # Set min to save some time\n    min_degree = 2\n    max_degree = len(collocation.x) - 1\n\n    for degree in np.arange(min_degree, max_degree + 1):\n        # Construct matrix from harmonic amplitudes for coils\n        currents2harmonics = coil_harmonic_amplitude_matrix(\n            sh_coilset.get_control_coils(), degree, r_t\n        )\n\n        # Calculate necessary coil currents\n        currents, residual, rank, s = np.linalg.lstsq(\n            currents2harmonics, psi_harmonic_amplitudes[:degree], rcond=None\n        )\n\n        # Calculate the coilset SH amplitudes for use in optimisation\n        coil_current_harmonic_amplitudes = currents2harmonics @ currents\n\n        # Set currents in coilset\n        sh_coilset.get_control_coils().current = currents\n\n        # Calculate the approximate Psi contribution from the coils\n        coilset_approx_psi = sh_coilset.psi(grid.x, grid.z)\n\n        # Total\n        approx_total_psi = coilset_approx_psi + plasma_psi\n\n        # Get plasma boundary for comparison to starting equilibrium using fit metric\n        eq_copy.coilset = sh_coilset\n        approx_LCFS = eq_copy.get_LCFS(psi=approx_total_psi)\n\n        # Compare staring equilibrium to new approximate equilibrium\n        fit_metric_value = lcfs_fit_metric(original_LCFS, approx_LCFS)\n\n        if fit_metric_value <= acceptable_fit_metric:\n            bluemira_print(\n                f\"The fit metric value acheived is {fit_metric_value} using {degree} degrees.\"\n            )\n            break\n        elif degree == max_degree:\n            raise BluemiraError(\n                f\"Uh oh, you may need to use more degrees for a fit metric of {acceptable_fit_metric}! Use a greater number of collocation points please.\"\n            )\n\n    # plot comparing original psi to the SH approximation\n    if plot:\n        plot_psi_comparision(\n            grid,\n            eq.psi(grid.x, grid.z),\n            approx_total_psi,\n            eq.coilset.psi(grid.x, grid.z),\n            coilset_approx_psi,\n            nlevels,\n        )\n\n    return (\n        sh_coilset,\n        r_t,\n        coil_current_harmonic_amplitudes,\n        degree,\n        fit_metric_value,\n        approx_total_psi,\n    )",
  "def plot_psi_comparision(\n    grid: Grid,\n    tot_psi_org: np.ndarray,\n    tot_psi_app: np.ndarray,\n    vac_psi_org: np.ndarray,\n    vac_psi_app: np.ndarray,\n    nlevels: int = 50,\n):\n    \"\"\"\n    Create plot comparing an original psi to psi obtained from approximation.\n\n    Parameters\n    ----------\n    grid:\n        Need x and z values to plot psi.\n    tot_psi_org:\n        Original Total Psi\n    tot_psi_app:\n        Approximation Total Psi\n    vac_psi_org:\n        Original Vacuum Psi (contribution from entire coilset)\n    vac_psi_app:\n        Approximation Vacuum Psi (contribution from entire coilset)\n\n    \"\"\"\n    cmap = PLOT_DEFAULTS[\"psi\"][\"cmap\"]\n    clevels = np.linspace(np.amin(tot_psi_org), np.amax(tot_psi_org), nlevels)\n\n    plot1 = plt.subplot2grid((5, 4), (0, 0), rowspan=2, colspan=1)\n    plot1.set_title(\"Original, Total Psi\")\n    plot1.contour(grid.x, grid.z, tot_psi_org, levels=clevels, cmap=cmap, zorder=8)\n    plot2 = plt.subplot2grid((5, 4), (0, 2), rowspan=2, colspan=1)\n    plot2.set_title(\"SH Approximation, Total Psi\")\n    plot2.contour(grid.x, grid.z, tot_psi_app, levels=clevels, cmap=cmap, zorder=8)\n    plot3 = plt.subplot2grid((5, 4), (3, 0), rowspan=2, colspan=1)\n    plot3.set_title(\"Original, Vacuum Psi\")\n    plot3.contour(grid.x, grid.z, vac_psi_org, levels=clevels, cmap=cmap, zorder=8)\n    plot4 = plt.subplot2grid((5, 4), (3, 2), rowspan=2, colspan=1)\n    plot4.set_title(\"SH Approximation, Vacuum Psi\")\n    plot4.contour(grid.x, grid.z, vac_psi_app, levels=clevels, cmap=cmap, zorder=8)",
  "class EQDSKInterface:\n    \"\"\"\n    Container for data from an EQDSK file.\n\n    Inspired by an EQDSK reader originally developed by B. Dudson:\n        https://github.com/bendudson/pyTokamak/blob/master/tokamak/formats/geqdsk.py\n\n    The G-EQDSK file format is described here:\n        https://fusion.gat.com/conferences/snowmass/working/mfe/physics/p3/equilibria/g_eqdsk_s.pdf\n\n    Notes\n    -----\n    G-EQDSK is from the 1980's and EQDSK files should generally only be\n    read and not written. New equilibria should really just be saved as\n    JSON files.\n\n    Poloidal magnetic flux units not enforced here!\n\n    Plasma current direction is not enforced here!\n    \"\"\"\n\n    bcentre: float\n    \"\"\"Magnetic field at the reference radius [T].\"\"\"\n    cplasma: float\n    \"\"\"Plasma current [A].\"\"\"\n    dxc: np.ndarray\n    \"\"\"X half-thicknesses of the coils [m].\"\"\"\n    dzc: np.ndarray\n    \"\"\"Z half-thicknesses of the coils [m].\"\"\"\n    ffprime: np.ndarray\n    \"\"\"FF' function on 1-D flux grid [m.T^2/V.s/rad].\"\"\"\n    fpol: np.ndarray\n    \"\"\"Poloidal current function f = R*B on 1-D flux [T.m].\"\"\"\n    Ic: np.ndarray\n    \"\"\"Coil currents [A].\"\"\"\n    name: str\n    \"\"\"Name of the equilibrium EQDSK [dimensionless].\"\"\"\n    nbdry: int\n    \"\"\"Number of boundary points [dimensionless].\"\"\"\n    ncoil: int\n    \"\"\"Number of coils [dimensionless].\"\"\"\n    nlim: int\n    \"\"\"Number of limiters [dimensionless].\"\"\"\n    nx: int\n    \"\"\"Number of grid points in the radial direction [dimensionless].\"\"\"\n    nz: int\n    \"\"\"Number of grid points in the vertical direction [dimensionless].\"\"\"\n    pprime: np.ndarray\n    \"\"\"P' function on 1-D flux grid [N/m^2/V.s/rad].\"\"\"\n    pressure: np.ndarray\n    \"\"\"Plasma pressure function on 1-D flux grid [N/m^2].\"\"\"\n    psi: np.ndarray\n    \"\"\"Poloidal magnetic flux on the 2-D grid [V.s/rad].\"\"\"\n    psibdry: float\n    \"\"\"Poloidal flux at the magnetic axis [V.s/rad].\"\"\"\n    psimag: float\n    \"\"\"Poloidal flux at the magnetic axis [V.s/rad].\"\"\"\n    xbdry: np.ndarray\n    \"\"\"X coordinates of the plasma boundary [m].\"\"\"\n    xc: np.ndarray\n    \"\"\"X coordinates of the coils [m].\"\"\"\n    xcentre: float\n    \"\"\"Radius of the reference toroidal magnetic  [m].\"\"\"\n    xdim: float\n    \"\"\"Horizontal dimension of the spatial grid [m].\"\"\"\n    xgrid1: float\n    \"\"\"Minimum radius of the spatial grid [m].\"\"\"\n    xlim: np.ndarray\n    \"\"\"X coordinates of the limiters [m].\"\"\"\n    xmag: float\n    \"\"\"Radius of the magnetic axis [m].\"\"\"\n    zbdry: np.ndarray\n    \"\"\"Z coordinates of the plasma boundary [m].\"\"\"\n    zc: np.ndarray\n    \"\"\"Z coordinates of the coils [m].\"\"\"\n    zdim: float\n    \"\"\"Vertical dimension of the spatial grid [m].\"\"\"\n    zlim: np.ndarray\n    \"\"\"Z coordinates of the limiters [m].\"\"\"\n    zmag: float\n    \"\"\"Z coordinate of the magnetic axis [m].\"\"\"\n    zmid: float\n    \"\"\"Z coordinate of the middle of the spatial grid [m].\"\"\"\n    x: Optional[np.ndarray] = None\n    \"\"\"X 1-D vector [m] (calculated if not given).\"\"\"\n    z: Optional[np.ndarray] = None\n    \"\"\"Z 1-D vector [m] (calculated if not given).\"\"\"\n    psinorm: Optional[np.ndarray] = None\n    \"\"\"Normalised psi vector [A] (calculated if not given).\"\"\"\n    qpsi: Optional[np.ndarray] = None\n    \"\"\"Safety factor values on the 1-D flux grid [dimensionless].\"\"\"\n    file_name: Optional[str] = None\n    \"\"\"The EQDSK file the data originates from.\"\"\"\n\n    def __post_init__(self):\n        \"\"\"Calculate derived parameters if they're not given.\"\"\"\n        if self.x is None:\n            self.x = _derive_x(self.xgrid1, self.xdim, self.nx)\n        if self.z is None:\n            self.z = _derive_z(self.zmid, self.zdim, self.nz)\n        if self.psinorm is None:\n            self.psinorm = _derive_psinorm(self.fpol)\n\n    @classmethod\n    def from_file(cls, file_path: str):\n        \"\"\"\n        Create an EQDSKInterface object from a file.\n\n        Parameters\n        ----------\n        file_path:\n            Path to a file of one of the following formats:\n\n                * JSON\n                * eqdsk\n                * eqdsk_out\n                * geqdsk\n\n        Returns\n        -------\n        An instance of this class containing the EQDSK file's data.\n        \"\"\"\n        _, file_extension = os.path.splitext(file_path)\n        file_name = os.path.basename(file_path)\n        if file_extension.lower() in EQDSK_EXTENSIONS:\n            return cls(file_name=file_name, **_read_eqdsk(file_path))\n        if file_extension.lower() == \".json\":\n            return cls(file_name=file_name, **_read_json(file_path))\n        raise ValueError(f\"Unrecognised file format '{file_extension}'.\")\n\n    def to_dict(self) -> Dict:\n        \"\"\"Return a dictionary of the EQDSK data.\"\"\"\n        d = asdict(self)\n        # Remove the file name as this is metadata, not EQDSK data\n        del d[\"file_name\"]\n        return d\n\n    def write(\n        self, file_path: str, format: str = \"json\", json_kwargs: Optional[Dict] = None\n    ):\n        \"\"\"\n        Write the EQDSK data to file in the given format.\n\n        Parameters\n        ----------\n        file_path:\n            Path to where the file should be written.\n        format:\n            The format to save the file in. One of 'json', 'eqdsk', or\n            'geqdsk'.\n        json_kwargs:\n            Key word arguments to pass to the ``json.dump`` call. Only\n            used if ``format`` is 'json'.\n        \"\"\"\n        if format == \"json\":\n            json_kwargs = {} if json_kwargs is None else json_kwargs\n            json_writer(self.to_dict(), file_path, **json_kwargs)\n        elif format in [\"eqdsk\", \"geqdsk\"]:\n            bluemira_warn(\n                \"You are in the 21st century. Are you sure you want to be making an EDQSK in this day and age?\"\n            )\n            _write_eqdsk(file_path, self.to_dict())\n\n    def update(self, eqdsk_data: Dict[str, Any]):\n        \"\"\"\n        Update this object's data with values from a dictionary.\n\n        Parameters\n        ----------\n        eqdsk_data:\n            A dict containing the new eqdsk data.\n\n        Raises\n        ------\n        ValueError\n            If a key in ``eqdsk_data`` does not correspond to an\n            attribute of this class.\n        \"\"\"\n        for key, value in eqdsk_data.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n            else:\n                raise ValueError(\n                    f\"Cannot update EQDSKInterface from dict. Unrecognised key '{key}'.\"\n                )",
  "def _read_json(file) -> Dict[str, Any]:\n    if isinstance(file, str):\n        with open(file, \"r\") as f_h:\n            return _read_json(f_h)\n\n    data = json.load(file)\n    data_has_pnorm = False\n    data_has_psinorm = False\n    for k, value in data.items():\n        if isinstance(value, list):\n            data[k] = np.asarray(value)\n        data_has_pnorm |= k == \"pnorm\"\n        data_has_psinorm |= k == \"psinorm\"\n\n    # For backward compatibility where 'psinorm' was sometimes 'pnorm'\n    if data_has_pnorm:\n        if data_has_psinorm:\n            del data[\"pnorm\"]\n        else:\n            data[\"psinorm\"] = data.pop(\"pnorm\")\n\n    return data",
  "def _read_array(tokens, n, name=\"Unknown\"):\n    data = np.zeros([n])\n    try:\n        for i in np.arange(n):\n            data[i] = float(next(tokens))\n    except StopIteration:\n        raise ValueError(f\"Failed reading array {name} of size {n}\")\n    return data",
  "def _read_2d_array(tokens, n_x, n_y, name=\"Unknown\"):\n    data = np.zeros([n_y, n_x])\n    for i in np.arange(n_y):\n        data[i, :] = _read_array(tokens, n_x, name + \"[\" + str(i) + \"]\")\n    data = np.transpose(data)\n    return data",
  "def _eqdsk_generator(file):\n    \"\"\"\n    Transforms a file object into a generator, following G-EQDSK number\n    conventions\n\n    Parameters\n    ----------\n    file:\n        The file to read\n\n    Returns\n    -------\n    The generator of the file handle being read\n    \"\"\"\n    while True:\n        line = file.readline()\n        if not line:\n            break\n\n        # Distinguish negative/positive numbers from negative/positive exponent\n        if \"E\" in line or \"e\" in line:\n            line = line.replace(\"E-\", \"*\")\n            line = line.replace(\"e-\", \"*\")\n            line = line.replace(\"-\", \" -\")\n            line = line.replace(\"*\", \"e-\")\n            line = line.replace(\"E+\", \"*\")\n            line = line.replace(\"e+\", \"*\")\n            line = line.replace(\"+\", \" \")\n            line = line.replace(\"*\", \"e+\")\n        generator_list = line.split()\n        for obj in generator_list:\n            yield obj",
  "def _read_eqdsk(file) -> Dict:\n    if isinstance(file, str):\n        with open(file, \"r\") as f_handle:\n            return _read_eqdsk(f_handle)\n\n    description = file.readline()\n    if not description:\n        raise IOError(f\"Could not read the file '{file}'.\")\n    description = description.split()\n\n    ints = []\n    for value in description:\n        if is_num(value):\n            ints.append(value)\n    if len(ints) < 3:\n        raise IOError(\n            \"Should be at least 3 numbers in the first line \" f\"of the EQDSK {file}.\"\n        )\n\n    data = {}\n    n_x = int(ints[-2])\n    n_z = int(ints[-1])\n    data[\"name\"] = description[0]\n    data[\"nx\"] = n_x\n    data[\"nz\"] = n_z\n\n    tokens = _eqdsk_generator(file)\n    for name in [\n        \"xdim\",\n        \"zdim\",\n        \"xcentre\",\n        \"xgrid1\",\n        \"zmid\",\n        \"xmag\",\n        \"zmag\",\n        \"psimag\",\n        \"psibdry\",\n        \"bcentre\",\n        \"cplasma\",\n        \"psimag\",\n        None,\n        \"xmag\",\n        None,\n        \"zmag\",\n        None,\n        \"psibdry\",\n        None,\n        None,\n    ]:\n        if name is not None:  # Lots of dummies and duplication\n            data[name] = float(next(tokens))\n        else:\n            next(tokens)  # Dummy\n\n    for name in [\"fpol\", \"pressure\", \"ffprime\", \"pprime\"]:\n        data[name] = _read_array(tokens, n_x, name)\n\n    data[\"psi\"] = _read_2d_array(tokens, n_x, n_z, \"psi\")\n    data[\"qpsi\"] = _read_array(tokens, n_x, \"qpsi\")\n    nbdry = int(next(tokens))\n    nlim = int(next(tokens))\n    data[\"nbdry\"] = nbdry\n    data[\"nlim\"] = nlim\n\n    xbdry = np.zeros(nbdry)\n    zbdry = np.zeros(nbdry)\n    for i in range(nbdry):\n        xbdry[i] = float(next(tokens))\n        zbdry[i] = float(next(tokens))\n    data[\"xbdry\"] = xbdry\n    data[\"zbdry\"] = zbdry\n\n    xlim = np.zeros(nlim)\n    zlim = np.zeros(nlim)\n    for i in range(nlim):\n        xlim[i] = float(next(tokens))\n        zlim[i] = float(next(tokens))\n    data[\"xlim\"] = xlim\n    data[\"zlim\"] = zlim\n\n    try:\n        ncoil = int(next(tokens))\n    except StopIteration:  # No coils in file\n        ncoil = 0\n\n    x_c = np.zeros(ncoil)\n    z_c = np.zeros(ncoil)\n    dxc = np.zeros(ncoil)\n    dzc = np.zeros(ncoil)\n    i_c = np.zeros(ncoil)\n    for i in range(ncoil):\n        x_c[i] = float(next(tokens))\n        z_c[i] = float(next(tokens))\n        dxc[i] = float(next(tokens))\n        dzc[i] = float(next(tokens))\n        i_c[i] = float(next(tokens))\n    data[\"ncoil\"] = ncoil\n    data[\"xc\"] = x_c\n    data[\"zc\"] = z_c\n    data[\"dxc\"] = dxc\n    data[\"dzc\"] = dzc\n    data[\"Ic\"] = i_c\n\n    # Additional utility data\n    data[\"x\"] = _derive_x(data[\"xgrid1\"], data[\"xdim\"], data[\"nx\"])\n    data[\"z\"] = _derive_z(data[\"zmid\"], data[\"zdim\"], data[\"nz\"])\n    data[\"psinorm\"] = _derive_psinorm(data[\"fpol\"])\n    return data",
  "def _derive_x(xgrid1, xdim, nx):\n    return np.linspace(xgrid1, xgrid1 + xdim, nx)",
  "def _derive_z(zmid, zdim, nz):\n    return np.linspace(zmid - zdim / 2, zmid + zdim / 2, nz)",
  "def _derive_psinorm(fpol):\n    return np.linspace(0, 1, len(fpol))",
  "def _write_eqdsk(file: str, data: Dict):\n    \"\"\"\n    Writes data out to a text file in G-EQDSK format.\n\n    Parameters\n    ----------\n    file:\n        The full path string of the file to be created\n    data:\n        Dictionary of EQDSK data.\n    \"\"\"\n    if isinstance(file, str):\n        if not any(file.endswith(ext) for ext in EQDSK_EXTENSIONS):\n            file = os.path.splitext(file)[0] + \".eqdsk\"\n        with open(file, \"w\") as f_handle:\n            return _write_eqdsk(f_handle, data)\n\n    def write_header(\n        fortran_format: ff.FortranRecordWriter, id_string: str, var_list: List[str]\n    ):\n        \"\"\"\n        Writes G-EQDSK header out to file.\n\n        Parameters\n        ----------\n        fortran_format:\n            FortranRecordWriter object for Fortran format edit descriptor\n            to be used for header output.\n        id_string:\n            String containing name of file to be used as identification\n            string. Will be trimmed if length exceeds 39 characters,\n            so it will fit within the permitted header length of the\n            GEQDSK specification when a timestamp is added.\n        var_list:\n            List of names of keys in EQDSKInterface.data identifying\n            variables to add to the header following the id_string.\n            Empty strings will be recorded as 0.\n        \"\"\"\n        line = [id_string]\n        line += [data[v] if v != \"\" else 0 for v in var_list]\n        file.write(fortran_format.write(line))\n        file.write(\"\\n\")\n\n    def write_line(fortran_format: ff.FortranRecordWriter, var_list: List[str]):\n        \"\"\"\n        Writes a line of variable values out to a G-EQDSK file.\n\n        Parameters\n        ----------\n        fortran_format:\n            FortranRecordWriter object for Fortran format edit descriptor\n            to be used for the format of the line output.\n        var_list:\n            List of names of keys in EQDSKInterface.data identifying\n            variables to added to the current line.\n            Empty strings will be recorded as 0.\n        \"\"\"\n        line = [data[v] if v != \"\" else 0 for v in var_list]\n        file.write(fortran_format.write(line))\n        file.write(\"\\n\")\n\n    def write_array(fortran_format: ff.FortranRecordWriter, array: np.ndarray):\n        \"\"\"\n        Writes a numpy array out to a G-EQDSK file.\n\n        Parameters\n        ----------\n        fortran_format:\n            FortranRecordWriter object for Fortran format edit descriptor\n            to be used for the format of the line output.\n        array:\n            Numpy array of variables to be written to file.\n            Array will be flattened in column-major (Fortran)\n            order if is more than one-dimensional.\n        \"\"\"\n        if array.ndim > 1:\n            flat_array = array.flatten(order=\"F\")\n            file.write(fortran_format.write(flat_array))\n        else:\n            file.write(fortran_format.write(array))\n        file.write(\"\\n\")\n\n    # Create id string for file comprising of timestamp and trimmed filename\n    # that fits the 48 character limit of strings in EQDSK headers.\n    timestamp = time.strftime(\"%d%m%Y\")\n    trimmed_name = data[\"name\"][0 : 48 - len(timestamp) - 1]\n    file_id_string = \"_\".join([trimmed_name, timestamp])\n\n    # Define dummy data for qpsi if it has not been previously defined.\n    if data[\"qpsi\"] is None:\n        qpsi = np.zeros(data[\"nx\"])\n    else:\n        qpsi = data[\"qpsi\"]\n\n    # Create array containing coilset information.\n    coil = np.zeros(5 * data[\"ncoil\"])\n    for i, value in enumerate([\"xc\", \"zc\", \"dxc\", \"dzc\", \"Ic\"]):\n        coil[i::5] = data[value]\n\n    # Create FortranRecordWriter objects with the Fortran format\n    # edit descriptors to be used in the G-EQDSK output.\n    f2000 = ff.FortranRecordWriter(\"a48,3i4\")\n    f2020 = ff.FortranRecordWriter(\"5e16.9\")\n    f2022 = ff.FortranRecordWriter(\"2i5\")\n    fCSTM = ff.FortranRecordWriter(\"i5\")\n\n    # Write header in f2000 (6a8,3i4) format.\n    write_header(f2000, file_id_string, [\"\", \"nx\", \"nz\"])\n    # Write out lines containing floats in f2020 (5e16.9) format.\n    write_line(f2020, [\"xdim\", \"zdim\", \"xcentre\", \"xgrid1\", \"zmid\"])\n    write_line(f2020, [\"xmag\", \"zmag\", \"psimag\", \"psibdry\", \"bcentre\"])\n    write_line(f2020, [\"cplasma\", \"psimag\", \"\", \"xmag\", \"\"])\n    write_line(f2020, [\"zmag\", \"\", \"psibdry\", \"\", \"\"])\n    # Write out arrays in in f2020 (5e16.9) format.\n    write_array(f2020, data[\"fpol\"])\n    write_array(f2020, data[\"pressure\"])\n    write_array(f2020, data[\"ffprime\"])\n    write_array(f2020, data[\"pprime\"])\n    write_array(f2020, data[\"psi\"])\n    write_array(f2020, qpsi)\n    # Write out number of boundary points and limiters f2022 (2i5) format.\n    write_line(f2022, [\"nbdry\", \"nlim\"])\n    # Write out boundary point and limiter data as array of ordered pairs.\n    write_array(f2020, np.array([data[\"xbdry\"], data[\"zbdry\"]]))\n    write_array(f2020, np.array([data[\"xlim\"], data[\"zlim\"]]))\n\n    # Output of coilset information. This is an extension to the\n    # regular eqdsk format.\n    write_line(fCSTM, [\"ncoil\"])\n    write_array(f2020, coil)",
  "def __post_init__(self):\n        \"\"\"Calculate derived parameters if they're not given.\"\"\"\n        if self.x is None:\n            self.x = _derive_x(self.xgrid1, self.xdim, self.nx)\n        if self.z is None:\n            self.z = _derive_z(self.zmid, self.zdim, self.nz)\n        if self.psinorm is None:\n            self.psinorm = _derive_psinorm(self.fpol)",
  "def from_file(cls, file_path: str):\n        \"\"\"\n        Create an EQDSKInterface object from a file.\n\n        Parameters\n        ----------\n        file_path:\n            Path to a file of one of the following formats:\n\n                * JSON\n                * eqdsk\n                * eqdsk_out\n                * geqdsk\n\n        Returns\n        -------\n        An instance of this class containing the EQDSK file's data.\n        \"\"\"\n        _, file_extension = os.path.splitext(file_path)\n        file_name = os.path.basename(file_path)\n        if file_extension.lower() in EQDSK_EXTENSIONS:\n            return cls(file_name=file_name, **_read_eqdsk(file_path))\n        if file_extension.lower() == \".json\":\n            return cls(file_name=file_name, **_read_json(file_path))\n        raise ValueError(f\"Unrecognised file format '{file_extension}'.\")",
  "def to_dict(self) -> Dict:\n        \"\"\"Return a dictionary of the EQDSK data.\"\"\"\n        d = asdict(self)\n        # Remove the file name as this is metadata, not EQDSK data\n        del d[\"file_name\"]\n        return d",
  "def write(\n        self, file_path: str, format: str = \"json\", json_kwargs: Optional[Dict] = None\n    ):\n        \"\"\"\n        Write the EQDSK data to file in the given format.\n\n        Parameters\n        ----------\n        file_path:\n            Path to where the file should be written.\n        format:\n            The format to save the file in. One of 'json', 'eqdsk', or\n            'geqdsk'.\n        json_kwargs:\n            Key word arguments to pass to the ``json.dump`` call. Only\n            used if ``format`` is 'json'.\n        \"\"\"\n        if format == \"json\":\n            json_kwargs = {} if json_kwargs is None else json_kwargs\n            json_writer(self.to_dict(), file_path, **json_kwargs)\n        elif format in [\"eqdsk\", \"geqdsk\"]:\n            bluemira_warn(\n                \"You are in the 21st century. Are you sure you want to be making an EDQSK in this day and age?\"\n            )\n            _write_eqdsk(file_path, self.to_dict())",
  "def update(self, eqdsk_data: Dict[str, Any]):\n        \"\"\"\n        Update this object's data with values from a dictionary.\n\n        Parameters\n        ----------\n        eqdsk_data:\n            A dict containing the new eqdsk data.\n\n        Raises\n        ------\n        ValueError\n            If a key in ``eqdsk_data`` does not correspond to an\n            attribute of this class.\n        \"\"\"\n        for key, value in eqdsk_data.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n            else:\n                raise ValueError(\n                    f\"Cannot update EQDSKInterface from dict. Unrecognised key '{key}'.\"\n                )",
  "def write_header(\n        fortran_format: ff.FortranRecordWriter, id_string: str, var_list: List[str]\n    ):\n        \"\"\"\n        Writes G-EQDSK header out to file.\n\n        Parameters\n        ----------\n        fortran_format:\n            FortranRecordWriter object for Fortran format edit descriptor\n            to be used for header output.\n        id_string:\n            String containing name of file to be used as identification\n            string. Will be trimmed if length exceeds 39 characters,\n            so it will fit within the permitted header length of the\n            GEQDSK specification when a timestamp is added.\n        var_list:\n            List of names of keys in EQDSKInterface.data identifying\n            variables to add to the header following the id_string.\n            Empty strings will be recorded as 0.\n        \"\"\"\n        line = [id_string]\n        line += [data[v] if v != \"\" else 0 for v in var_list]\n        file.write(fortran_format.write(line))\n        file.write(\"\\n\")",
  "def write_line(fortran_format: ff.FortranRecordWriter, var_list: List[str]):\n        \"\"\"\n        Writes a line of variable values out to a G-EQDSK file.\n\n        Parameters\n        ----------\n        fortran_format:\n            FortranRecordWriter object for Fortran format edit descriptor\n            to be used for the format of the line output.\n        var_list:\n            List of names of keys in EQDSKInterface.data identifying\n            variables to added to the current line.\n            Empty strings will be recorded as 0.\n        \"\"\"\n        line = [data[v] if v != \"\" else 0 for v in var_list]\n        file.write(fortran_format.write(line))\n        file.write(\"\\n\")",
  "def write_array(fortran_format: ff.FortranRecordWriter, array: np.ndarray):\n        \"\"\"\n        Writes a numpy array out to a G-EQDSK file.\n\n        Parameters\n        ----------\n        fortran_format:\n            FortranRecordWriter object for Fortran format edit descriptor\n            to be used for the format of the line output.\n        array:\n            Numpy array of variables to be written to file.\n            Array will be flattened in column-major (Fortran)\n            order if is more than one-dimensional.\n        \"\"\"\n        if array.ndim > 1:\n            flat_array = array.flatten(order=\"F\")\n            file.write(fortran_format.write(flat_array))\n        else:\n            file.write(fortran_format.write(array))\n        file.write(\"\\n\")",
  "def ad_objective(\n    vector: np.ndarray,\n    grad: np.ndarray,\n    objective: Callable[[np.ndarray], np.ndarray],\n    objective_args: Dict[str, Any],\n    ad_args: Optional[Dict[str, Any]] = None,\n) -> float:\n    \"\"\"\n    Objective function that calculates gradient information via\n    automatic differentiation of the figure of merit returned from a\n    provided objective.\n\n    If the provided objective already provides gradient information,\n    it will be overwritten by the approximated gradient.\n\n    Parameters\n    ----------\n    vector:\n        State vector of the array of coil currents.\n    grad:\n        Local gradient of objective function used by LD NLOPT algorithms.\n        Updated in-place.\n    objective:\n        Objective function for which a numerical approximation for\n        derivative information will be calculated.\n    objective_args:\n        Arguments to pass to objective function during call.\n    ad_args:\n        Optional keyword arguments to pass to derivative approximation\n        function.\n\n    Returns\n    -------\n    Value of objective function (figure of merit).\n    \"\"\"\n    fom = objective(vector, grad, **objective_args)\n    if grad.size > 0:\n        grad[:] = approx_derivative(\n            objective, vector, args=objective_args, f0=fom, **ad_args\n        )\n    bluemira_print_flush(f\"EQUILIBRIA Coilset iteration figure of merit = {fom:.2e}\")\n    return fom",
  "def regularised_lsq_objective(\n    vector: np.ndarray,\n    grad: np.ndarray,\n    scale: float,\n    a_mat: np.ndarray,\n    b_vec: np.ndarray,\n    gamma: float,\n) -> float:\n    \"\"\"\n    Objective function for nlopt optimisation (minimisation),\n    consisting of a least-squares objective with Tikhonov\n    regularisation term, which updates the gradient in-place.\n\n    Parameters\n    ----------\n    vector:\n        State vector of the array of coil currents (m)\n    grad:\n        Local gradient of objective function used by LD NLOPT algorithms\n        Updated in-place (n, m).\n    scale: float\n        Scaling factor for the vector\n    a_mat:\n        The 2-D a_mat control matrix A (n, m)\n    b_vec:\n        The 1-D b vector of target values (n)\n    gamma:\n        The Tikhonov regularisation parameter.\n\n    Returns\n    -------\n    Value of objective function (figure of merit).\n    \"\"\"\n    vector = vector * scale\n    fom, err = regularised_lsq_fom(vector, a_mat, b_vec, gamma)\n    if grad.size > 0:\n        jac = 2 * a_mat.T @ a_mat @ vector / float(len(b_vec))\n        jac -= 2 * a_mat.T @ b_vec / float(len(b_vec))\n        jac += 2 * gamma * gamma * vector\n        grad[:] = scale * jac\n    if fom <= 0:\n        raise EquilibriaError(\n            \"Optimiser least-squares objective function less than zero or nan.\"\n        )\n    return fom",
  "def minimise_coil_currents(vector: np.ndarray, grad: np.ndarray) -> float:\n    \"\"\"\n    Objective function for the minimisation of the sum of coil currents squared\n\n    Parameters\n    ----------\n    vector:\n        State vector of the array of coil currents.\n    grad:\n        Local gradient of objective function used by LD NLOPT algorithms.\n        Updated in-place.\n\n    Returns\n    -------\n    Sum of the currents squared.\n    \"\"\"\n    sum_sq_currents = np.sum(vector**2)\n\n    if grad.size > 0:\n        grad[:] = 2 * vector\n\n    return sum_sq_currents",
  "def maximise_flux(\n    vector: np.ndarray, grad: np.ndarray, c_psi_mat: np.ndarray, scale: float\n) -> float:\n    \"\"\"\n    Objective function to maximise flux\n\n    Parameters\n    ----------\n    vector:\n        State vector of the array of coil currents.\n    grad:\n        Local gradient of objective function used by LD NLOPT algorithms.\n        Updated in-place.\n    c_psi_mat:\n        Response matrix of the coil psi contributions to the point at which the flux\n        should be maximised\n    scale:\n        Scaling factor for the vector\n\n    Returns\n    -------\n    Psi value at the point\n    \"\"\"\n    psi = -scale * c_psi_mat @ vector\n    if grad.size > 0:\n        grad[:] = -scale * c_psi_mat\n\n    return psi",
  "def regularised_lsq_fom(\n    x: np.ndarray, a_mat: np.ndarray, b_vec: np.ndarray, gamma: float\n) -> Tuple[float, np.ndarray]:\n    \"\"\"\n    Figure of merit for the least squares problem Ax = b, with\n    Tikhonov regularisation term. Normalised for the number of\n    targets.\n\n    ||(Ax - b)||\u00b2/ len(b)] + ||\u0393x||\u00b2\n\n    Parameters\n    ----------\n    x :\n        The 1-D x state vector (m)\n    a_mat:\n        The 2-D a_mat control matrix A (n, m)\n    b_vec:\n        The 1-D b vector of target values (n)\n    gamma:\n        The Tikhonov regularisation parameter.\n\n    Returns\n    -------\n    fom:\n        Figure of merit, explicitly given by\n        ||(Ax - b)||\u00b2/ len(b)] + ||\u0393x||\u00b2\n    residual:\n        Residual vector (Ax - b)\n    \"\"\"\n    residual = np.dot(a_mat, x) - b_vec\n    number_of_targets = float(len(residual))\n    fom = residual.T @ residual / number_of_targets + gamma * gamma * x.T @ x\n\n    if fom <= 0:\n        raise EquilibriaError(\"Least-squares objective function less than zero or nan.\")\n    return fom, residual",
  "def calc_psi_norm(\n    psi: Union[float, np.ndarray], opsi: float, xpsi: float\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Calculate normalised magnetic flux.\n\n    Parameters\n    ----------\n    psi:\n        The magnetic flux per radian\n    opsi:\n        The psi value at the O-point\n    xpsi:\n        The psi value at the X-point\n\n    Returns\n    -------\n    The normalised magnetic flux value(s)\n    \"\"\"\n    return (opsi - psi) / (opsi - xpsi)",
  "def calc_psi(\n    psi_norm: Union[float, np.ndarray], opsi: float, xpsi: float\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Calculate the absolute psi values from normalised psi values\n\n    Parameters\n    ----------\n    psi_norm:\n        The normalised psi values\n    opsi:\n        The psi value at the O-point\n    xpsi:\n        The psi value at the X-point\n\n    Returns\n    -------\n    psi:\n        The magnetic flux per radian\n    \"\"\"\n    return opsi - psi_norm * (opsi - xpsi)",
  "def calc_tau_flattop(psi_sof: float, psi_eof: float, v_burn: float) -> float:\n    \"\"\"\n    Calculates the flat-top length\n\n    \\t:math:`\\\\tau_{flat-top}=\\\\dfrac{\\\\psi_{SOF}-\\\\psi_{EOF}}{V_{burn}}`\n\n    Parameters\n    ----------\n    psi_sof:\n        The start of flat-top magnetic flux at the plasma boundary [V.s]\n    psi_eof:\n        The end of flat-top magnetic flux at the plasma boundary [V.s]\n    v_burn:\n        The plasma loop voltage during burn [V]\n\n    Returns\n    -------\n    The duration of the flat-top [s]\n    \"\"\"\n    return (psi_sof - psi_eof) / v_burn",
  "def calc_psib(\n    psi_bd: float, R_0: float, I_p: float, li: float, c_ejima: float = 0.4\n) -> float:\n    \"\"\"\n    Calculates the boundary flux at start of flat-top, after the breakdown\n\n    \\t:math:`\\\\psi_b=\\\\psi(t_{BD})-L_i I_p-\\\\Delta\\\\psi_{res}`\n\n    with:\n    \\t:math:`L_i=\\\\dfrac{\\\\mu_0R_0l_i}{2}`\n\n    \\t:math:`\\\\Delta\\\\psi_{res}=C_{Ejima}\\\\mu_0R_0I_p`\n\n    Parameters\n    ----------\n    psi_bd:\n        The flux at the breakdown [V.s]\n    R_0:\n        The machine major radius [m]\n    I_p:\n        The desired flat-top plasma current [A]\n    li:\n        The normalised plasma inductance\n\n    Returns\n    -------\n    The flux at the boundary at start of flat-top [V.s]\n    \"\"\"\n    return psi_bd - 0.5 * MU_0 * R_0 * li * I_p - c_ejima * MU_0 * R_0 * I_p",
  "def calc_k0(psi_xx0: float, psi_zz0: float) -> float:\n    \"\"\"\n    Calculates the plasma elongation on the plasma axis (rho = 0).\n\n    Parameters\n    ----------\n    psi_xx0:\n        Second derivative of psi in X at the plasma axis (R_0, Z_0)\n    psi_zz0:\n        Second derivative of psi in Z at the plasma axis (R_0, Z_0)\n\n    Returns\n    -------\n    Plasma elongation at the plasma axis\n    \"\"\"\n    return np.sqrt(psi_xx0 / psi_zz0)",
  "def calc_q0(eq: Equilibrium) -> float:\n    \"\"\"\n    Calculates the plasma MHD safety factor on the plasma axis (rho=0).\n    Freidberg, Ideal MHD, eq 6.42, p 134\n\n    Parameters\n    ----------\n    eq:\n        Equilibrium for which to calculate the safety factor on axis\n\n    Returns\n    -------\n    The MHD safety factor on the plasma axis\n    \"\"\"\n    opoint = eq.get_OX_points()[0][0]\n    psi_xx0 = eq.psi_func(opoint.x, opoint.z, dx=2, grid=False)\n    psi_zz0 = eq.psi_func(opoint.x, opoint.z, dy=2, grid=False)\n    b_0 = eq.Bt(opoint.x)\n    jfunc = RectBivariateSpline(eq.x[:, 0], eq.z[0, :], eq._jtor)\n    j_0 = jfunc(opoint.x, opoint.z, grid=False)\n    k_0 = calc_k0(psi_xx0, psi_zz0)\n    return (b_0 / (MU_0 * opoint.x * j_0)) * (1 + k_0**2) / k_0",
  "def calc_dx_sep(eq: Equilibrium) -> float:\n    \"\"\"\n    Calculate the magnitude of the minimum separation between the flux\n    surfaces of null points in the equilibrium at the outboard midplane.\n\n    Parameters\n    ----------\n    eq:\n        Equilibrium for which to calculate dx_sep\n\n    Returns\n    -------\n    Separation distance at the outboard midplane between the active\n    null and the next closest flux surface with a null [m]\n    \"\"\"\n    o_points, x_points = eq.get_OX_points()\n    x, z = eq.get_LCFS().xz\n    lfs = np.argmax(x)\n    lfp = eq.get_midplane(x[lfs], z[lfs], x_points[0].psi)\n    d_x = []\n    count = 0  # Necessary because of retrieval of eqdsks with limiters\n    for xp in x_points:\n        if \"Xpoint\" in xp.__class__.__name__:\n            if count > 0:\n                psinorm = calc_psi_norm(xp.psi, o_points[0].psi, x_points[0].psi)\n                if psinorm > 1:\n                    d_x.append(eq.get_midplane(*lfp, xp.psi)[0])\n            count += 1\n    return np.min(d_x) - lfp[0]",
  "def calc_volume(eq: Equilibrium) -> float:\n    \"\"\"\n    Calculates plasma volume [m^3]\n    \"\"\"\n    lcfs = eq.get_LCFS().xz\n    return revolved_volume(*lcfs)",
  "def calc_energy(eq: Equilibrium) -> float:\n    \"\"\"\n    Calculates the stored poloidal magnetic energy in the plasma [J]\n\n    \\t:math:`W=\\\\dfrac{LI^2}{2}`\n    \"\"\"\n    mask = in_plasma(eq.x, eq.z, eq.psi())\n    Bp = eq.Bp()\n    return volume_integral(Bp**2 * mask, eq.x, eq.dx, eq.dz) / (2 * MU_0)",
  "def calc_Li(eq: Equilibrium) -> float:  # noqa :N802\n    \"\"\"\n    Calculates the internal inductance of the plasma [H]\n\n    \\t:math:`L_i=\\\\dfrac{2W}{I_{p}^{2}}`\n    \"\"\"\n    p_energy = calc_energy(eq)\n    return 2 * p_energy / eq._I_p**2",
  "def calc_li(eq: Equilibrium) -> float:\n    \"\"\"\n    Calculates the normalised internal inductance of the plasma\n\n    \\t:math:`l_i=\\\\dfrac{2L_i}{\\\\mu_{0}R_{0}}`\n    \"\"\"\n    li = calc_Li(eq)\n    return 2 * li / (MU_0 * eq._R_0)",
  "def calc_li3(eq: Equilibrium) -> float:\n    \"\"\"\n    Calculates the normalised internal plasma inductance (ITER approximate\n    calculation)\n\n    see https://iopscience.iop.org/article/10.1088/0029-5515/48/12/125002/meta\n\n    \\t:math:`li(3)=\\\\dfrac{2V\\\\langle B_p^2\\\\rangle}{(\\\\mu_0I_p)^2R_0}`\n\n    with:\n    \\t:math:`\\\\langle B_p^2\\\\rangle=\\\\dfrac{1}{V}\\\\int B_p^2dV`\n\n    where: Bp is the poloidal magnetic field and V is the plasma volume\n    \"\"\"\n    mask = in_plasma(eq.x, eq.z, eq.psi())\n    Bp = eq.Bp()\n    bpavg = volume_integral(Bp**2 * mask, eq.x, eq.dx, eq.dz)\n    return 2 * bpavg / (eq.profiles.R_0 * (MU_0 * eq.profiles.I_p) ** 2)",
  "def calc_li3minargs(\n    x: np.ndarray,\n    z: np.ndarray,\n    psi: np.ndarray,\n    Bp: np.ndarray,\n    R_0: float,\n    I_p: float,\n    dx: float,\n    dz: float,\n    mask: Optional[np.ndarray] = None,\n    o_points: Optional[Iterable[Opoint]] = None,\n    x_points: Optional[Iterable[Xpoint]] = None,\n) -> float:\n    \"\"\"\n    Calculate the normalised plasma internal inductance with arguments only.\n\n    Used in the optimisation of the plasma profiles.\n    \"\"\"\n    if mask is None:\n        mask = in_plasma(x, z, psi, o_points=o_points, x_points=x_points)\n    bpavg = volume_integral(Bp**2 * mask, x, dx, dz)\n    return 2 * bpavg / (R_0 * (MU_0 * I_p) ** 2)",
  "def calc_p_average(eq: Equilibrium) -> float:\n    \"\"\"\n    Calculate the average plasma pressure.\n\n    \\t:math:`\\\\langle p \\\\rangle = \\\\dfrac{1}{V_{p}}\\\\int \\\\mathbf{p}dxdz`:\n\n    Parameters\n    ----------\n    eq:\n        The Equilibrium object for which to calculate p_average\n\n    Returns\n    -------\n    The average plasma pressure [Pa]\n    \"\"\"\n    p = eq.pressure_map()\n    v_plasma = calc_volume(eq)\n    return volume_integral(p, eq.x, eq.dx, eq.dz) / v_plasma",
  "def calc_beta_t(eq: Equilibrium) -> float:\n    \"\"\"\n    Calculate the ratio of plasma pressure to toroidal magnetic pressure.\n\n    \\t:math:`\\\\beta_t = \\\\dfrac{2\\\\mu_0\\\\langle p \\\\rangle}{B_t^2}`\n\n    Parameters\n    ----------\n    eq:\n        The Equilibrium object for which to calculate beta_t\n\n    Returns\n    -------\n    Ratio of plasma to toroidal magnetic pressure\n    \"\"\"\n    p_avg = calc_p_average(eq)\n    return 2 * MU_0 * p_avg / eq._B_0**2",
  "def calc_beta_p(eq: Equilibrium) -> float:\n    \"\"\"\n    Calculate the ratio of plasma pressure to poloidal magnetic pressure\n\n    \\t:math:`\\\\beta_p = \\\\dfrac{2\\\\mu_0\\\\langle p \\\\rangle}{B_p^2}`\n\n    Parameters\n    ----------\n    eq:\n        The Equilibrium object for which to calculate beta_p\n\n    Returns\n    -------\n    Ratio of plasma to magnetic pressure\n    \"\"\"\n    p = eq.pressure_map()\n    mask = eq._get_core_mask()\n    Bp = mask * eq.Bp()\n    p_int = volume_integral(p, eq.x, eq.dx, eq.dz)\n    Bp2_int = volume_integral(Bp**2, eq.x, eq.dx, eq.dz)\n    return 2 * MU_0 * p_int / Bp2_int",
  "def calc_beta_p_approx(eq: Equilibrium) -> float:\n    \"\"\"\n    Calculate the ratio of plasma pressure to magnetic pressure. This is\n    following the definitions of Friedberg, Ideal MHD, pp. 68-69, which is an\n    approximation.\n\n    \\t:math:`\\\\beta_p = \\\\dfrac{2\\\\mu_0\\\\langle p \\\\rangle}{B_p^2}`\n\n    Parameters\n    ----------\n    eq:\n        The Equilibrium object for which to calculate beta_p\n\n    Returns\n    -------\n    Ratio of plasma to poloidal magnetic pressure\n    \"\"\"\n    p_avg = calc_p_average(eq)\n    circumference = eq.get_LCFS().length\n    Bp = MU_0 * eq._I_p / circumference\n    return 2 * MU_0 * p_avg / Bp**2",
  "def calc_summary(eq: Equilibrium) -> Dict[str, float]:\n    \"\"\"\n    Calculates interesting values in one go\n    \"\"\"\n    R_0, I_p = eq.profiles.R_0, eq.profiles.I_p\n    mask = in_plasma(eq.x, eq.z, eq.psi())\n    Bp = eq.Bp()\n    bpavg = volume_integral(Bp**2 * mask, eq.x, eq.dx, eq.dz)\n    energy = bpavg / (2 * MU_0)\n    li_true = 2 * energy / I_p**2\n    li = 2 * li_true / (MU_0 * R_0)\n    li3 = 2 * bpavg / (R_0 * (MU_0 * R_0) ** 2)\n    volume = calc_volume(eq)\n    beta_p = calc_beta_p(eq)\n    return {\n        \"W\": energy,\n        \"Li\": li_true,\n        \"li\": li,\n        \"li(3)\": li3,\n        \"V\": volume,\n        \"beta_p\": beta_p,\n    }",
  "def beta(pressure: np.ndarray, field: float) -> float:\n    \"\"\"\n    The ratio of plasma pressure to magnetic pressure\n\n    \\t:math:`\\\\beta = \\\\dfrac{\\\\langle p \\\\rangle}{B^2/2\\\\mu_0}`\n\n    Parameters\n    ----------\n    pressure:\n        Plasma pressure, from which the mean is to be calculated [Pa]\n    field:\n        Mean total field strength [T]\n\n    Returns\n    -------\n    Ratio of plasma to magnetic pressure\n    \"\"\"\n    return np.mean(pressure) / (field**2 / 2 * MU_0)",
  "def normalise_beta(beta: float, a: float, b_tor: float, I_p: float) -> float:\n    \"\"\"\n    Converts beta to normalised beta\n\n    \\t:math:`\\\\beta_{N} = \\\\beta\\\\dfrac{aB_{T}}{I_{p}}`\n\n    Parameters\n    ----------\n    beta:\n        Ratio of plasma to magnetic pressure\n    a:\n        Plasma minor radius [m]\n    b_tor:\n        Toroidal field [T]\n    I_p:\n        Plasma current [A]\n\n    Returns\n    -------\n    Normalised ratio of plasma to magnetic pressure (Troyon factor)\n    \"\"\"\n    return beta * a * b_tor / I_p",
  "def beta_N_to_beta(  # noqa :N802\n    beta_N: float, a: float, Btor: float, I_p: float  # noqa: N803\n) -> float:\n    \"\"\"\n    Converts normalised beta to beta\n\n    \\t:math:`\\\\beta = \\\\beta_{N}\\\\dfrac{I_{p}}{aB_{T}}`\n\n    Parameters\n    ----------\n    beta_N:\n        Normalised ratio of plasma to magnetic pressure (Troyon factor)\n    a:\n        Plasma minor radius [m]\n    b_tor:\n        Toroidal field [T]\n    I_p:\n        Plasma current [A]\n\n    Returns\n    -------\n    Ratio of plasma to magnetic pressure\n    \"\"\"\n    return beta_N * I_p / (a * Btor)",
  "def calc_infinite_solenoid_flux(r_cs_min: float, r_cs_max: float, B_max: float) -> float:\n    \"\"\"\n    Calculate the maximum flux achievable from an infinite solenoid given a peak field.\n\n    Parameters\n    ----------\n    r_cs_min:\n        Inner radius of the infinite solenoid [m]\n    r_cs_max:\n        Outer radius of the infinite solenoid [m]\n    B_max:\n        Peak allowable field in the solenoid [T]\n\n    Returns\n    -------\n    Maximum achievable flux from an infinite solenoid [V.s]\n    \"\"\"\n    return B_max * np.pi / 3 * (r_cs_max**2 + r_cs_min**2 + r_cs_max * r_cs_min)",
  "class CoilPositioner:\n    \"\"\"\n    Initial coil positioning tools for ab initio equilibrium design\n\n    Parameters\n    ----------\n    R_0:\n        Machine major radius [m]\n    A:\n        Plasma aspect ratio\n    delta:\n        Plasma triangularity\n    kappa:\n        Plasma elongation\n    track:\n        Track along which PF coils are positioned\n    x_cs:\n        Central Solenoid radius\n    tk_cs:\n        Central Solenoid thickness either side\n    n_PF:\n        Number of PF coils\n    n_CS:\n        Number of CS modules\n    csgap:\n        The gap between CS modules [m]\n    rtype:\n        The type of reactor ['ST', 'Normal']. Used for default coil positioning\n    cslayout:\n        The layout of the CS modules ['ITER', 'DEMO']\n    \"\"\"\n\n    def __init__(\n        self,\n        R_0: float,\n        A: float,\n        delta: float,\n        kappa: float,\n        track: Coordinates,\n        x_cs: float,\n        tk_cs: float,\n        n_PF: int,\n        n_CS: int,\n        csgap: float = 0.1,\n        rtype: str = \"Normal\",\n        cslayout: str = \"DEMO\",\n    ):\n        self.ref = [R_0, 0]\n        self.A = A\n        self.R_0 = R_0\n        self.delta = delta\n        self.kappa = kappa\n        self.track = track\n        self.x_cs = x_cs\n        self.tk_cs = tk_cs\n        self.n_PF = n_PF\n        self.n_CS = n_CS\n        self.csgap = csgap\n        self.rtype = rtype\n        self.cslayout = cslayout\n\n    def equispace_PF(self, track: Coordinates, n_PF: int) -> List[Coil]:\n        \"\"\"\n        Equally spaces PF coils around a TF coil boundary track, picking\n        some starting positions for the uppermost and lowermost PF coil\n        based on plasma shape considerations (mirror about X-points)\n        \"\"\"\n        a = np.rad2deg(np.arctan(abs(self.delta) / self.kappa))\n        if self.rtype == \"Normal\":\n            angle_upper = 90 + a * 1.6\n            angle_lower = -90 - a * 1.6\n        elif self.rtype == \"ST\":\n            angle_upper = 90 + a * 1.2\n            angle_lower = -90 - a * 1.0\n\n        angle = np.radians(angle_lower)\n\n        line = Coordinates(\n            {\n                \"x\": [self.ref[0], self.ref[0] + VERY_BIG * np.cos(angle)],\n                \"z\": [self.ref[1], self.ref[1] + VERY_BIG * np.sin(angle)],\n            }\n        )\n\n        arg_lower = join_intersect(track, line, get_arg=True)\n\n        angle = np.radians(angle_upper)\n\n        line = Coordinates(\n            {\n                \"x\": [self.ref[0], self.ref[0] + VERY_BIG * np.cos(angle)],\n                \"z\": [self.ref[1], self.ref[1] + VERY_BIG * np.sin(angle)],\n            }\n        )\n\n        arg_upper = join_intersect(track, line, get_arg=True)\n\n        if arg_lower:\n            arg_lower = arg_lower[0]\n        else:\n            arg_lower = 0\n\n        if arg_upper:\n            arg_upper = arg_upper[0]\n        else:\n            arg_upper = len(track) - 1\n\n        tf_loop = Coordinates(track[:, arg_lower : arg_upper + 1])\n        l_norm = vector_lengthnorm(tf_loop.x, tf_loop.z)\n        pos = np.linspace(0, 1, n_PF)\n        xint, zint = interp1d(l_norm, tf_loop.x)(pos), interp1d(l_norm, tf_loop.z)(pos)\n        return [\n            Coil(xint[i], zint[i], ctype=\"PF\", j_max=NBTI_J_MAX) for i in range(n_PF)\n        ]\n\n    def equispace_CS(\n        self,\n        x_cs: float,\n        tk_cs: float,\n        z_min: float,\n        z_max: float,\n        n_CS: int,\n        j_max: float = NB3SN_J_MAX,\n    ) -> List[Coil]:\n        \"\"\"\n        Defines a Solenoid object with equally spaced nCS modules\n        \"\"\"\n        dz = ((z_max - z_min) - self.csgap * (n_CS - 1)) / n_CS / 2\n        v1 = np.arange(0, n_CS)\n        v2 = np.arange(1, n_CS * 2, 2)\n        zc = z_max - self.csgap * v1 - dz * v2\n\n        return [\n            Coil(\n                x_cs,\n                _zc,\n                current=0,\n                n_turns=1,\n                ctype=\"CS\",\n                j_max=j_max,\n                dx=tk_cs,\n                dz=dz,\n            )\n            for _zc in zc\n        ]\n\n    def demospace_CS(\n        self, x_cs: float, tk_cs: float, z_min: float, z_max: float, n_CS: int\n    ) -> List[Coil]:\n        \"\"\"\n        Defines a Solenoid object with DEMO like layout of nCS modules\n        \"\"\"\n        if n_CS <= 2 or n_CS % 2 == 0:\n            bluemira_warn(\n                \"So was kann ich mit einem DEMO-spacing nicht machen. \"\n                \"Stattdessen gib ich dir einen ITER-spacing CS.\"\n            )\n            return self.equispace_CS(x_cs, tk_cs, z_min, z_max, n_CS)\n        length = ((z_max - z_min) - (n_CS - 1) * self.csgap) / (\n            n_CS + 1\n        )  # Module length\n        a = np.linspace(1, n_CS * 2 - 1, n_CS)\n        a[n_CS // 2 :] += 2\n        a[n_CS // 2] = n_CS + 1  # Central module\n        b = np.linspace(0, n_CS - 1, n_CS)\n        z_cs = z_max * np.ones(n_CS)\n        z_cs -= a * length / 2 + b * self.csgap\n        heights = length / 2 * np.ones(n_CS)\n        heights[n_CS // 2] = length  # Central module\n        return [\n            Coil(\n                x_cs,\n                z_cs[i],\n                dx=tk_cs,\n                dz=heights[i],\n                ctype=\"CS\",\n                j_max=NBTI_J_MAX,\n            )\n            for i in range(n_CS)\n        ]\n\n    def make_coilset(self, d_coil: float = 0.5) -> CoilSet:\n        \"\"\"\n        Returns a CoilSet object\n        \"\"\"\n        coils = self.equispace_PF(self.track, self.n_PF)\n        z_max = max(self.track.z)\n        z_min = -z_max\n        if self.n_CS != 0:\n            if self.cslayout == \"ITER\":\n                coils.append(\n                    self.equispace_CS(self.x_cs, self.tk_cs, z_min, z_max, self.n_CS)\n                )\n            elif self.cslayout == \"DEMO\":\n                coils.extend(\n                    self.demospace_CS(self.x_cs, self.tk_cs, z_min, z_max, self.n_CS)\n                )\n            else:\n                raise ValueError(\n                    f\"Valid options are 'ITER' and 'DEMO', not '{self.cslayout}'\"\n                )\n        cset = CoilSet(*coils)\n        cset.discretisation = d_coil\n        return cset",
  "class XZLMapper:\n    \"\"\"\n    Coil positioning tools for use in optimisation\n\n    Parameters\n    ----------\n    pftrack:\n        Track (x, z) along which PF coils are positioned\n    cs_x:\n        Radius of the centre of the central solenoid [m]\n    cs_zmin:\n        Minimum z location of the CS [m]\n    cs_zmax:\n        Maximum z location of the CS [m]\n    cs_gap:\n        Gap between modules of the CS [m]\n    CS:\n        Whether or not to XL map CS\n    \"\"\"\n\n    def __init__(\n        self,\n        pf_coords: Coordinates,\n        cs_x: float = 1.0,\n        cs_zmin: float = 1.0,\n        cs_zmax: float = 1.0,\n        cs_gap: float = 0.1,\n        CS: bool = False,\n    ):\n        while len(pf_coords) < 4:\n            pf_coords = Coordinates(np.c_[interpolate_midpoints(*pf_coords.xyz)])\n\n        self.pf_coords = deepcopy(pf_coords)  # Stored as loop too\n\n        ln = vector_lengthnorm(pf_coords.x, pf_coords.z)\n\n        x_ius = InterpolatedUnivariateSpline(ln, pf_coords.x)\n        z_ius = InterpolatedUnivariateSpline(ln, pf_coords.z)\n        self.pftrack = {\n            \"x\": x_ius,\n            \"z\": z_ius,\n            \"L\": self.pf_coords.length,\n            \"dx\": x_ius.derivative(),\n            \"dz\": z_ius.derivative(),\n        }\n\n        self.flag_CS = CS\n        if self.flag_CS:\n            self.Xcs = cs_x\n            self.z_min = cs_zmin\n            self.z_max = cs_zmax\n            self.gap = cs_gap\n            self.make_cstrack()\n        else:  # Due diligence\n            self.Xcs = None\n            self.z_min = None\n            self.z_max = None\n            self.gap = None\n            self.cstrack = None\n\n        self.exclusions = None\n        self.excl_zones = []\n        self.excl_loops = None\n        self.incl_loops = None\n        self._coilset = None  # PLotting utility\n\n    def make_cstrack(self):\n        \"\"\"\n        Make a normalised straight segment track for the central solenoid.\n        \"\"\"\n        z = [self.z_max, self.z_min]\n        self.cstrack = {\"L\": interp1d(z, [0, 1]), \"z\": interp1d([0, 1], z)}\n\n    @staticmethod\n    def PFnorm(l_values, coords, point):\n        \"\"\"\n        Optimisation function for the positioning of the coils along the track.\n        \"\"\"\n        return (coords[\"x\"](l_values) - point[0]) ** 2 + (\n            coords[\"z\"](l_values) - point[1]\n        ) ** 2\n\n    def xz_to_L(self, x: float, z: float) -> float:  # noqa :N802\n        \"\"\"\n        Translation of (x-z) coordinates to linear normalised coordinates (L) for the PF\n        coils.\n        \"\"\"\n        return minimize_scalar(\n            self.PFnorm, method=\"bounded\", args=(self.pftrack, [x, z]), bounds=[0, 1]\n        ).x\n\n    def L_to_xz(\n        self, l_values: Union[float, np.ndarray]\n    ) -> Tuple[Union[float, np.ndarray], Union[float, np.ndarray]]:  # noqa :N802\n        \"\"\"\n        Translation of linear normalised coordinates (L) to (x-z) coordinates for the PF\n        coils.\n        \"\"\"\n        return self.pftrack[\"x\"](l_values), self.pftrack[\"z\"](l_values)\n\n    def z_to_L(self, zc_vec):  # noqa :N802\n        \"\"\"\n        Convert z values for the CS in L values of the CS track.\n        \"\"\"\n        zc_vec = np.sort(zc_vec)[::-1]\n        if len(zc_vec) == 1:\n            return np.array([0.5])\n        z_edge = np.zeros(len(zc_vec))\n        z_edge[0] = self.z_max - 2 * abs(self.z_max - zc_vec[0])\n        for i in range(1, len(zc_vec) - 1):\n            z_edge[i] = zc_vec[i] - (z_edge[i - 1] - zc_vec[i] - self.gap)\n        z_edge[len(zc_vec) - 1] = self.z_min\n        return self.cstrack[\"L\"](z_edge)\n\n    def L_to_zdz(self, l_values):\n        \"\"\"\n        Convert L values for the CS track into z and dz values for the CS.\n        \"\"\"\n        l_values = tools.clip(l_values, 0, 1)\n        l_values = np.sort(l_values)\n        z_edge = self.cstrack[\"z\"](l_values)\n        dz, zc = np.zeros(len(l_values)), np.zeros(len(l_values))\n        dz[0] = abs(self.z_max - z_edge[0]) / 2\n        zc[0] = self.z_max - dz[0]\n        for i in range(1, len(l_values)):\n            dz[i] = abs(z_edge[i - 1] - z_edge[i] - self.gap) / 2\n            zc[i] = z_edge[i - 1] - dz[i] - self.gap\n        # dz[-1] = abs(z_edge[-1]-self.Zmin-self.gap)/2\n        # zc[-1] = self.Zmin+dz[-1]\n        return self.Xcs * np.ones(len(l_values)), zc[::-1], dz[::-1]  # Coil numbering\n\n    def get_Lmap(\n        self, coilset: CoilSet, mapping: List[str]\n    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:  # noqa :N802\n        \"\"\"\n        Calculates initial L vector and lb and ub constraints on L vector.\n\n        Parameters\n        ----------\n        coilset:\n            The coilset to map\n        mapping:\n            List of PF coil names on the track\n\n        Returns\n        -------\n        L:\n            The initial position vector for the coilset position optimiser\n        lb:\n            The lower bounds on the L vector to be respected by the optimiser\n        ub:\n            The upper bounds on the L vector to be respected by the optimiser\n        \"\"\"\n        self._coilset = coilset  # for plotting\n        track_coils = len(mapping)\n        l_values = np.zeros(track_coils)\n        lb = np.zeros(track_coils)\n        ub = np.zeros(track_coils)\n        pf_coils = [self._coilset[m] for m in mapping]\n        for i, coil in enumerate(pf_coils):\n            loc = self.xz_to_L(coil.x, coil.z)\n            if self.exclusions is not None:\n                for ex in self.exclusions:\n                    if ex[0] < loc < ex[1]:\n                        back = -(\n                            loc\n                            - ex[0]\n                            + 2 * coil._current_radius / self.pf_coords.length\n                        )\n                        forw = (\n                            ex[1]\n                            - loc\n                            + 2 * coil._current_radius / self.pf_coords.length\n                        )\n                        if abs(back) >= abs(forw):\n                            d_l = forw\n                            break\n                        else:\n                            d_l = back\n                            break\n                    else:\n                        d_l = 0\n                l_values[i] = loc + d_l\n                lb[i], ub[i] = self._get_bounds(l_values[i])\n            else:\n                l_values[i] = loc\n                lb[i], ub[i] = 0, 1\n        lb, ub = self._segment_tracks(lb, ub)\n        # The L vector must be adjusted to its new bounds\n        l_values = tools.clip(l_values, lb, ub)\n        if self.flag_CS:\n            n_CS = coilset.n_coils(\"CS\")\n            z = coilset.get_coiltype(\"CS\").z\n            l_values = np.append(l_values, self.z_to_L(np.sort(z)[::-1]))\n            lb = np.append(lb, np.zeros(n_CS))\n            ub = np.append(ub, np.ones(n_CS))\n        return l_values, lb, ub\n\n    def _get_bounds(self, l_values):\n        \"\"\"\n        Generates an initial set of bounds for L based on the exclusion zones\n        for the PF coils\n        \"\"\"\n        e = [e for b in self.exclusions for e in b]\n        lb, ub = 0, 1\n        for ex in e:\n            if l_values < ex:\n                ub = ex\n                break\n            else:\n                lb = ex\n        return lb, ub\n\n    @staticmethod\n    def _segment_tracks(lb, ub):\n        \"\"\"\n        Applies additional (silent) constraints, effectively chopping up a\n        sub-track into two, so that two coils don't end up on top of each other\n        \"\"\"\n        # beware of np.zeros_like!\n        # TODO this feels temperamental\n        lb_new, ub_new = np.zeros(len(lb)), np.zeros(len(ub))\n        lb, ub = list(lb), list(ub)\n        flag = False\n        last_n = -1\n        for i, (lower, upper) in enumerate(zip(lb, ub)):\n            n = lb.count(lower)\n            if i == last_n:\n                flag = False\n            if n == 1:  # No duplicates\n                flag = False\n                lb_new[i] = lower\n                ub_new[i] = upper\n            elif n != 1 and flag is False:\n                flag = True\n                last_n = i + n\n                if last_n > len(lb_new):\n                    continue\n                delta = (upper - lower) / n\n                for k, j in enumerate(range(i, i + n)):\n                    lb_new[j] = upper - (k + 1) * delta\n                    ub_new[j] = upper - k * delta\n            else:\n                continue\n        return lb_new, ub_new\n\n    def _get_unique_zone(self, zones: List[Coordinates]) -> BluemiraFace:\n        \"\"\"\n        Makes a single \"cutting\" shape. This is a cheap way of avoiding a\n        complicated merging list, checking for overlaps between zones.\n\n        Parameters\n        ----------\n        zones:\n            The list of exclusion zones\n\n        Returns\n        -------\n        The boolean union of all the exclusion zones\n        \"\"\"\n        self.excl_zones.extend(zones)\n\n        offset_coords = offset(*self.pf_coords.xz, -0.0001)\n        joiner = Coordinates({\"x\": offset_coords[0], \"z\": offset_coords[1]})\n        joiner.close()\n\n        joiner = BluemiraFace(make_polygon(joiner.xyz, closed=True))\n        zones = [\n            BluemiraFace(make_polygon(zone.xyz, closed=True)) for zone in self.excl_zones\n        ]\n\n        joiner = boolean_fuse([joiner] + zones)\n\n        return joiner\n\n    def add_exclusion_zones(self, zones: List[Coordinates]):\n        \"\"\"\n        F\u00fcgt der PFspulenbahn Aussschlusszonen hinzu\n\n        Parameters\n        ----------\n        zones:\n            List of Coordinates exclusion zones in x, z coordinates\n        \"\"\"\n        excl_zone = self._get_unique_zone(zones)\n\n        pf_wire = make_polygon(self.pf_coords.xyz, closed=True)\n        incl_wires = boolean_cut(pf_wire, excl_zone)\n        incl_loops = [w.discretize(byedges=True, ndiscr=100) for w in incl_wires]\n\n        outer_wire = offset_wire(excl_zone.boundary[0], 100)\n        negative = BluemiraFace([outer_wire, excl_zone.boundary[0]])\n        excl_wires = boolean_cut(pf_wire, negative)\n        excl_loops = [w.discretize(byedges=True, ndiscr=100) for w in excl_wires]\n        self.incl_loops = incl_loops\n        self.excl_loops = excl_loops\n\n        # Track start and end points\n        p0 = self.pf_coords.xz.T[0]\n        p1 = self.pf_coords.xz.T[-1]\n\n        # Calculate exclusion sections in parametric space\n        exclusions = []\n        for i, excl in enumerate(self.excl_loops):\n            # Check if the start point lies in the exclusion\n            if np.allclose(p0, excl.xz.T[0]) or np.allclose(p0, excl.xz.T[-1]):\n                start = 0\n            else:\n                start = self.xz_to_L(*excl.xz.T[0])\n\n            # Check if the end point lies in the inclusion\n            if np.allclose(p1, excl.xz.T[-1]) or np.allclose(p1, excl.xz.T[0]):\n                stop = 1\n            else:\n                stop = self.xz_to_L(*excl.xz.T[-1])\n\n            exclusions.append(sorted([start, stop]))\n\n        # Sort by order in parametric space\n        self.exclusions = sorted(exclusions, key=lambda x: x[0])\n\n    def plot(self, ax=None):\n        \"\"\"\n        Plot the XZLMapper.\n        \"\"\"\n        return XZLPlotter(self, ax=ax)",
  "class RegionMapper:\n    \"\"\"\n    Coil positioning tools for use in optimisation for regions.\n\n    Parameters\n    ----------\n    pfregions:\n        Regions in which each PF coil resides. The Coordinates objects must be 2-D in\n        x, z.\n    \"\"\"\n\n    def __init__(self, pfregions: Dict[str, Coordinates]):\n        self.pfregions = pfregions\n\n        self.regions = {}\n        self.name_str = \"R_{}\"\n\n        try:\n            for pf_name, loop_reg in self.pfregions.items():\n                self._region_setup(pf_name, loop_reg)\n        except AttributeError:\n            raise EquilibriaError(\"pfregions is not a dictionary\")\n\n        self.no_regions = len(self.regions)\n\n        self.l_values = np.zeros((self.no_regions, 2))\n        self.l_map = self.l_values.flatten()\n\n        self.max_currents = np.zeros(self.no_regions)\n\n    def _region_setup(self, pf_name, loop_reg):\n        if all(loop_reg.y != 0):\n            raise EquilibriaError(\n                \"Coordinates object must be 2D- in x, z for RegionMapper\"\n            )\n\n        region_name = self._name_converter(pf_name, True)\n        self.regions[region_name] = RegionInterpolator(loop_reg)\n\n    def _regionname(self, region):\n        if not isinstance(region, str):\n            return self.name_str.format(region)\n        elif re.match(\"^R_[0-9]+([.][0-9]+)?$\", region):\n            return region\n        elif re.match(\"^PF_[0-9]+([.][0-9]+)?$\", region):\n            return self._name_converter(region, True)\n        else:\n            raise NameError(\"RegionName not valid\")\n\n    def _name_converter(self, regionname, coil_to_region=False):\n        num = int(regionname.split(\"_\")[-1])\n        if coil_to_region:\n            return self.name_str.format(num)\n        else:\n            return f\"PF_{num}\"\n\n    def add_region(self, pfregion: Dict[str, Coordinates]):\n        \"\"\"\n        Add an extra region to map.\n\n        Parameters\n        ----------\n        pfregion:\n            A region where a PF coil will reside\n\n        \"\"\"\n        self.pfregions = {**self.pfregions, **pfregion}\n        name, region = list(pfregion.items())[0]\n        self.no_regions += 1\n        self.l_values = np.zeros((self.no_regions, 2))\n        self.max_currents = np.zeros(self.no_regions)\n        self._region_setup(name, region)\n\n    def L_to_xz(self, region, l_values):\n        \"\"\"\n        Convert L values to x,z values for a given region.\n        \"\"\"\n        reg = self.regions[self._regionname(region)]\n        # l_values = self.region_coil_overlap(l_values)\n        xv, zv = reg.to_xz(l_values)\n        return xv, zv\n\n    def xz_to_L(\n        self, region, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Convert x,z values to L values for a given region.\n        \"\"\"\n        reg = self.regions[self._regionname(region)]\n        l_0, l_1 = reg.to_L(x, z)\n        return l_0, l_1\n\n    def get_Lmap(self, coilset: CoilSet) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Get 1D array of mapped position coordinates from coil positions\n        in a provided coilset, along with mapped position bounds.\n\n        Parameters\n        ----------\n        coilset:\n            A coilset object to map\n        \"\"\"\n        self._coilset = coilset\n\n        for no, region in enumerate(self.regions.keys()):\n            try:\n                coil = coilset[self._name_converter(region)]\n            except KeyError:\n                bluemira_warn(f\"{self._name_converter(region)} not found in coilset\")\n                continue\n\n            self.l_values[no] = self.xz_to_L(region, coil.x, coil.z)\n\n        # Force all initial positions to be within region\n        self.l_map = tools.clip(self.l_values, 0, 1).flatten()\n        return (\n            self.l_map,\n            np.zeros_like(self.l_map),\n            np.ones_like(self.l_map),\n        )\n\n    def set_Lmap(self, l_map):\n        \"\"\"\n        Sets the mapped positions from a provided 1D array.\n        \"\"\"\n        if np.size(l_map) == 2 * self.no_regions:\n            self.l_map = l_map\n            self.l_values = l_map.reshape(-1, 2)\n        else:\n            raise EquilibriaError(\n                \"Provided l_map does not contain exactly one pair of mapped\"\n                \"coordinates for each region in RegionMapper\"\n            )\n\n    def get_xz_arrays(self) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Get arrays containing x and z coordinates for all coils from the position\n        map.\n\n        Returns\n        -------\n        x:\n            Array containing radial positions of all coils in mapped regions,\n            enumerated by region index in self.regions.\n        z:\n            Array containing vertical positions of all coils in mapped regions,\n            enumerated by region index in self.regions.\n\n        \"\"\"\n        x, z = np.zeros(len(self.l_values)), np.zeros(len(self.l_values))\n        for i, region in enumerate(self.regions.keys()):\n            x[i], z[i] = self.L_to_xz(region, self.l_values[i])\n        return x, z\n\n    def get_size_current_limit(self) -> np.ndarray:\n        \"\"\"\n        Get maximum coil current while staying within region boundaries.\n\n        Coils are set up as current per unit area therefore limiting the max current\n        limits the area a coil covers.\n\n        Returns\n        -------\n        Max current for coil location within region\n        \"\"\"\n        for no, (name, region) in enumerate(self.regions.items()):\n            coil = self._coilset[self._name_converter(name)]\n            self.max_currents[no] = get_max_current(\n                *inscribed_rect_in_poly(\n                    region.loop.x, region.loop.z, coil.x, coil.z, coil.dx / coil.dz\n                ),\n                coil.j_max,\n            )\n\n        return self.max_currents\n\n    def plot(self, ax=None):\n        \"\"\"\n        Plot the RegionMapper.\n        \"\"\"\n        return RegionPlotter(self, ax=ax)",
  "class RegionInterpolator:\n    \"\"\"\n    Sets up a region for a PF coil to move within.\n\n    We are treating the region as a flat surface.\n\n    The normalisation occurs by cutting the shape in two axes and\n    normalising over the cut length within the region.\n\n    Currently this is limited to convex polygons (also know as convex hulls).\n    Generalisation to all polygons is possible but unimplemented\n    and possibly quite slow when converting from normalised to real coordinates.\n\n    When the coil position provided is outside the given region the coil will\n    be moved to the closest edge of the region.\n\n    The mapping from outside to the edge of the region is not strictly defined.\n    The only certainty is that the coil will be moved into the region.\n\n    Parameters\n    ----------\n    coords:\n        Region to interpolate within\n    \"\"\"\n\n    def __init__(self, coords: Coordinates):\n        self.x = coords.x\n        self.z = coords.z\n        self.coords = coords\n\n        self.check_loop_feasibility(coords)\n\n        self.coords = coords\n        self.z_min = min(self.coords.z)\n        self.z_max = max(self.coords.z)\n\n    def to_xz(self, l_values: List[float]) -> Tuple[float, float]:\n        \"\"\"\n        Convert L values to x,z values for xy_cut.\n\n        Parameters\n        ----------\n        l_values:\n            Coordinates in normalised space\n\n        Returns\n        -------\n        x:\n            Radial coordinates in real space\n        z:\n            Vertical coordinate in real space\n\n        Raises\n        ------\n        GeometryError\n            When coordinates are not a Convex Hull\n        \"\"\"\n        l_0, l_1 = l_values\n        z = self.z_min + (self.z_max - self.z_min) * l_1\n\n        plane = BluemiraPlane.from_3_points([0, 0, z], [1, 0, z], [0, 1, z])\n\n        intersect = coords_plane_intersect(self.coords, plane)\n        if len(intersect) == 1:\n            x = intersect[0][0]\n        elif len(intersect) == 2:\n            x_min, x_max = sorted([intersect[0][0], intersect[1][0]])\n            x = x_min + (x_max - x_min) * l_0\n        else:\n            raise GeometryError(\"Region must be a Convex Hull\")\n\n        return x, z\n\n    def to_L(self, x: float, z: float) -> Tuple[float, float]:\n        \"\"\"\n        Convert x.z values to L values for xy_cut.\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates in real space\n        z:\n            Vertical coordinate in real space\n\n        Returns\n        -------\n        l_0:\n            Coordinate 1 in normalised space\n        l_1:\n            Coordinate 2 in normalised space\n\n        Raises\n        ------\n        GeometryError\n            When coordinates are not a Convex Hull\n        \"\"\"\n        l_1 = (z - self.z_min) / (self.z_max - self.z_min)\n        l_1 = tools.clip(l_1, 0.0, 1.0)\n\n        plane = BluemiraPlane.from_3_points([x, 0, z], [x + 1, 0, z], [x, 1, z])\n        intersect = coords_plane_intersect(self.coords, plane)\n\n        return self._intersect_filter(x, l_1, intersect)\n\n    def _intersect_filter(\n        self, x: float, l_1: float, intersect: BluemiraPlane\n    ) -> Tuple[float, float]:\n        \"\"\"\n        Checks where points are based on number of intersections\n        with a plane. Should initially be called with a plane involving z.\n\n        No intersection could mean above 1 edge therefore a plane in xy\n        is checked before recalling this function.\n        If there is one intersection point we are on an edge (either bottom or top),\n        if there is two intersection points we are in the region,\n        otherwise the region is not a convex hull.\n\n        Parameters\n        ----------\n        x:\n            x coordinate\n        l_1:\n            Normalised z coordinate\n        intersect:\n            A plane through xz\n\n        Returns\n        -------\n        l_0:\n            Coordinate 1 in normalised space\n        l_1:\n            Coordinate 2 in normalised space\n\n        Raises\n        ------\n        GeometryError\n            When coordinates are not a Convex Hull\n        \"\"\"\n        if intersect is None:\n            plane = BluemiraPlane.from_3_points([x, 0, 0], [x + 1, 0, 0], [x, 1, 0])\n            intersect = coords_plane_intersect(self.coords, plane)\n            l_0, l_1 = self._intersect_filter(\n                x, l_1, [False] if intersect is None else intersect\n            )\n        elif len(intersect) == 2:\n            x_min, x_max = sorted([intersect[0][0], intersect[1][0]])\n            l_0 = tools.clip((x - x_min) / (x_max - x_min), 0.0, 1.0)\n        elif len(intersect) == 1:\n            l_0 = float(l_1 == 1.0)\n        else:\n            raise GeometryError(\"Region must be a Convex Hull\")\n        return l_0, l_1\n\n    @staticmethod\n    def check_loop_feasibility(coords: Coordinates):\n        \"\"\"\n        Checks the provided region is a ConvexHull.\n\n        This is a current limitation of RegionMapper\n        not providing a 'smooth' interpolation surface.\n\n        Parameters\n        ----------\n        coords:\n            Region to check\n\n        Raises\n        ------\n        GeometryError\n            When coordinates are not a Convex Hull\n\n        \"\"\"\n        if not np.allclose(\n            ConvexHull(coords.xz.T).volume, get_area_2d(coords.x, coords.z), atol=EPS\n        ):\n            raise GeometryError(\"Region must be a Convex Hull\")",
  "def __init__(\n        self,\n        R_0: float,\n        A: float,\n        delta: float,\n        kappa: float,\n        track: Coordinates,\n        x_cs: float,\n        tk_cs: float,\n        n_PF: int,\n        n_CS: int,\n        csgap: float = 0.1,\n        rtype: str = \"Normal\",\n        cslayout: str = \"DEMO\",\n    ):\n        self.ref = [R_0, 0]\n        self.A = A\n        self.R_0 = R_0\n        self.delta = delta\n        self.kappa = kappa\n        self.track = track\n        self.x_cs = x_cs\n        self.tk_cs = tk_cs\n        self.n_PF = n_PF\n        self.n_CS = n_CS\n        self.csgap = csgap\n        self.rtype = rtype\n        self.cslayout = cslayout",
  "def equispace_PF(self, track: Coordinates, n_PF: int) -> List[Coil]:\n        \"\"\"\n        Equally spaces PF coils around a TF coil boundary track, picking\n        some starting positions for the uppermost and lowermost PF coil\n        based on plasma shape considerations (mirror about X-points)\n        \"\"\"\n        a = np.rad2deg(np.arctan(abs(self.delta) / self.kappa))\n        if self.rtype == \"Normal\":\n            angle_upper = 90 + a * 1.6\n            angle_lower = -90 - a * 1.6\n        elif self.rtype == \"ST\":\n            angle_upper = 90 + a * 1.2\n            angle_lower = -90 - a * 1.0\n\n        angle = np.radians(angle_lower)\n\n        line = Coordinates(\n            {\n                \"x\": [self.ref[0], self.ref[0] + VERY_BIG * np.cos(angle)],\n                \"z\": [self.ref[1], self.ref[1] + VERY_BIG * np.sin(angle)],\n            }\n        )\n\n        arg_lower = join_intersect(track, line, get_arg=True)\n\n        angle = np.radians(angle_upper)\n\n        line = Coordinates(\n            {\n                \"x\": [self.ref[0], self.ref[0] + VERY_BIG * np.cos(angle)],\n                \"z\": [self.ref[1], self.ref[1] + VERY_BIG * np.sin(angle)],\n            }\n        )\n\n        arg_upper = join_intersect(track, line, get_arg=True)\n\n        if arg_lower:\n            arg_lower = arg_lower[0]\n        else:\n            arg_lower = 0\n\n        if arg_upper:\n            arg_upper = arg_upper[0]\n        else:\n            arg_upper = len(track) - 1\n\n        tf_loop = Coordinates(track[:, arg_lower : arg_upper + 1])\n        l_norm = vector_lengthnorm(tf_loop.x, tf_loop.z)\n        pos = np.linspace(0, 1, n_PF)\n        xint, zint = interp1d(l_norm, tf_loop.x)(pos), interp1d(l_norm, tf_loop.z)(pos)\n        return [\n            Coil(xint[i], zint[i], ctype=\"PF\", j_max=NBTI_J_MAX) for i in range(n_PF)\n        ]",
  "def equispace_CS(\n        self,\n        x_cs: float,\n        tk_cs: float,\n        z_min: float,\n        z_max: float,\n        n_CS: int,\n        j_max: float = NB3SN_J_MAX,\n    ) -> List[Coil]:\n        \"\"\"\n        Defines a Solenoid object with equally spaced nCS modules\n        \"\"\"\n        dz = ((z_max - z_min) - self.csgap * (n_CS - 1)) / n_CS / 2\n        v1 = np.arange(0, n_CS)\n        v2 = np.arange(1, n_CS * 2, 2)\n        zc = z_max - self.csgap * v1 - dz * v2\n\n        return [\n            Coil(\n                x_cs,\n                _zc,\n                current=0,\n                n_turns=1,\n                ctype=\"CS\",\n                j_max=j_max,\n                dx=tk_cs,\n                dz=dz,\n            )\n            for _zc in zc\n        ]",
  "def demospace_CS(\n        self, x_cs: float, tk_cs: float, z_min: float, z_max: float, n_CS: int\n    ) -> List[Coil]:\n        \"\"\"\n        Defines a Solenoid object with DEMO like layout of nCS modules\n        \"\"\"\n        if n_CS <= 2 or n_CS % 2 == 0:\n            bluemira_warn(\n                \"So was kann ich mit einem DEMO-spacing nicht machen. \"\n                \"Stattdessen gib ich dir einen ITER-spacing CS.\"\n            )\n            return self.equispace_CS(x_cs, tk_cs, z_min, z_max, n_CS)\n        length = ((z_max - z_min) - (n_CS - 1) * self.csgap) / (\n            n_CS + 1\n        )  # Module length\n        a = np.linspace(1, n_CS * 2 - 1, n_CS)\n        a[n_CS // 2 :] += 2\n        a[n_CS // 2] = n_CS + 1  # Central module\n        b = np.linspace(0, n_CS - 1, n_CS)\n        z_cs = z_max * np.ones(n_CS)\n        z_cs -= a * length / 2 + b * self.csgap\n        heights = length / 2 * np.ones(n_CS)\n        heights[n_CS // 2] = length  # Central module\n        return [\n            Coil(\n                x_cs,\n                z_cs[i],\n                dx=tk_cs,\n                dz=heights[i],\n                ctype=\"CS\",\n                j_max=NBTI_J_MAX,\n            )\n            for i in range(n_CS)\n        ]",
  "def make_coilset(self, d_coil: float = 0.5) -> CoilSet:\n        \"\"\"\n        Returns a CoilSet object\n        \"\"\"\n        coils = self.equispace_PF(self.track, self.n_PF)\n        z_max = max(self.track.z)\n        z_min = -z_max\n        if self.n_CS != 0:\n            if self.cslayout == \"ITER\":\n                coils.append(\n                    self.equispace_CS(self.x_cs, self.tk_cs, z_min, z_max, self.n_CS)\n                )\n            elif self.cslayout == \"DEMO\":\n                coils.extend(\n                    self.demospace_CS(self.x_cs, self.tk_cs, z_min, z_max, self.n_CS)\n                )\n            else:\n                raise ValueError(\n                    f\"Valid options are 'ITER' and 'DEMO', not '{self.cslayout}'\"\n                )\n        cset = CoilSet(*coils)\n        cset.discretisation = d_coil\n        return cset",
  "def __init__(\n        self,\n        pf_coords: Coordinates,\n        cs_x: float = 1.0,\n        cs_zmin: float = 1.0,\n        cs_zmax: float = 1.0,\n        cs_gap: float = 0.1,\n        CS: bool = False,\n    ):\n        while len(pf_coords) < 4:\n            pf_coords = Coordinates(np.c_[interpolate_midpoints(*pf_coords.xyz)])\n\n        self.pf_coords = deepcopy(pf_coords)  # Stored as loop too\n\n        ln = vector_lengthnorm(pf_coords.x, pf_coords.z)\n\n        x_ius = InterpolatedUnivariateSpline(ln, pf_coords.x)\n        z_ius = InterpolatedUnivariateSpline(ln, pf_coords.z)\n        self.pftrack = {\n            \"x\": x_ius,\n            \"z\": z_ius,\n            \"L\": self.pf_coords.length,\n            \"dx\": x_ius.derivative(),\n            \"dz\": z_ius.derivative(),\n        }\n\n        self.flag_CS = CS\n        if self.flag_CS:\n            self.Xcs = cs_x\n            self.z_min = cs_zmin\n            self.z_max = cs_zmax\n            self.gap = cs_gap\n            self.make_cstrack()\n        else:  # Due diligence\n            self.Xcs = None\n            self.z_min = None\n            self.z_max = None\n            self.gap = None\n            self.cstrack = None\n\n        self.exclusions = None\n        self.excl_zones = []\n        self.excl_loops = None\n        self.incl_loops = None\n        self._coilset = None",
  "def make_cstrack(self):\n        \"\"\"\n        Make a normalised straight segment track for the central solenoid.\n        \"\"\"\n        z = [self.z_max, self.z_min]\n        self.cstrack = {\"L\": interp1d(z, [0, 1]), \"z\": interp1d([0, 1], z)}",
  "def PFnorm(l_values, coords, point):\n        \"\"\"\n        Optimisation function for the positioning of the coils along the track.\n        \"\"\"\n        return (coords[\"x\"](l_values) - point[0]) ** 2 + (\n            coords[\"z\"](l_values) - point[1]\n        ) ** 2",
  "def xz_to_L(self, x: float, z: float) -> float:  # noqa :N802\n        \"\"\"\n        Translation of (x-z) coordinates to linear normalised coordinates (L) for the PF\n        coils.\n        \"\"\"\n        return minimize_scalar(\n            self.PFnorm, method=\"bounded\", args=(self.pftrack, [x, z]), bounds=[0, 1]\n        ).x",
  "def L_to_xz(\n        self, l_values: Union[float, np.ndarray]\n    ) -> Tuple[Union[float, np.ndarray], Union[float, np.ndarray]]:  # noqa :N802\n        \"\"\"\n        Translation of linear normalised coordinates (L) to (x-z) coordinates for the PF\n        coils.\n        \"\"\"\n        return self.pftrack[\"x\"](l_values), self.pftrack[\"z\"](l_values)",
  "def z_to_L(self, zc_vec):  # noqa :N802\n        \"\"\"\n        Convert z values for the CS in L values of the CS track.\n        \"\"\"\n        zc_vec = np.sort(zc_vec)[::-1]\n        if len(zc_vec) == 1:\n            return np.array([0.5])\n        z_edge = np.zeros(len(zc_vec))\n        z_edge[0] = self.z_max - 2 * abs(self.z_max - zc_vec[0])\n        for i in range(1, len(zc_vec) - 1):\n            z_edge[i] = zc_vec[i] - (z_edge[i - 1] - zc_vec[i] - self.gap)\n        z_edge[len(zc_vec) - 1] = self.z_min\n        return self.cstrack[\"L\"](z_edge)",
  "def L_to_zdz(self, l_values):\n        \"\"\"\n        Convert L values for the CS track into z and dz values for the CS.\n        \"\"\"\n        l_values = tools.clip(l_values, 0, 1)\n        l_values = np.sort(l_values)\n        z_edge = self.cstrack[\"z\"](l_values)\n        dz, zc = np.zeros(len(l_values)), np.zeros(len(l_values))\n        dz[0] = abs(self.z_max - z_edge[0]) / 2\n        zc[0] = self.z_max - dz[0]\n        for i in range(1, len(l_values)):\n            dz[i] = abs(z_edge[i - 1] - z_edge[i] - self.gap) / 2\n            zc[i] = z_edge[i - 1] - dz[i] - self.gap\n        # dz[-1] = abs(z_edge[-1]-self.Zmin-self.gap)/2\n        # zc[-1] = self.Zmin+dz[-1]\n        return self.Xcs * np.ones(len(l_values)), zc[::-1], dz[::-1]",
  "def get_Lmap(\n        self, coilset: CoilSet, mapping: List[str]\n    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:  # noqa :N802\n        \"\"\"\n        Calculates initial L vector and lb and ub constraints on L vector.\n\n        Parameters\n        ----------\n        coilset:\n            The coilset to map\n        mapping:\n            List of PF coil names on the track\n\n        Returns\n        -------\n        L:\n            The initial position vector for the coilset position optimiser\n        lb:\n            The lower bounds on the L vector to be respected by the optimiser\n        ub:\n            The upper bounds on the L vector to be respected by the optimiser\n        \"\"\"\n        self._coilset = coilset  # for plotting\n        track_coils = len(mapping)\n        l_values = np.zeros(track_coils)\n        lb = np.zeros(track_coils)\n        ub = np.zeros(track_coils)\n        pf_coils = [self._coilset[m] for m in mapping]\n        for i, coil in enumerate(pf_coils):\n            loc = self.xz_to_L(coil.x, coil.z)\n            if self.exclusions is not None:\n                for ex in self.exclusions:\n                    if ex[0] < loc < ex[1]:\n                        back = -(\n                            loc\n                            - ex[0]\n                            + 2 * coil._current_radius / self.pf_coords.length\n                        )\n                        forw = (\n                            ex[1]\n                            - loc\n                            + 2 * coil._current_radius / self.pf_coords.length\n                        )\n                        if abs(back) >= abs(forw):\n                            d_l = forw\n                            break\n                        else:\n                            d_l = back\n                            break\n                    else:\n                        d_l = 0\n                l_values[i] = loc + d_l\n                lb[i], ub[i] = self._get_bounds(l_values[i])\n            else:\n                l_values[i] = loc\n                lb[i], ub[i] = 0, 1\n        lb, ub = self._segment_tracks(lb, ub)\n        # The L vector must be adjusted to its new bounds\n        l_values = tools.clip(l_values, lb, ub)\n        if self.flag_CS:\n            n_CS = coilset.n_coils(\"CS\")\n            z = coilset.get_coiltype(\"CS\").z\n            l_values = np.append(l_values, self.z_to_L(np.sort(z)[::-1]))\n            lb = np.append(lb, np.zeros(n_CS))\n            ub = np.append(ub, np.ones(n_CS))\n        return l_values, lb, ub",
  "def _get_bounds(self, l_values):\n        \"\"\"\n        Generates an initial set of bounds for L based on the exclusion zones\n        for the PF coils\n        \"\"\"\n        e = [e for b in self.exclusions for e in b]\n        lb, ub = 0, 1\n        for ex in e:\n            if l_values < ex:\n                ub = ex\n                break\n            else:\n                lb = ex\n        return lb, ub",
  "def _segment_tracks(lb, ub):\n        \"\"\"\n        Applies additional (silent) constraints, effectively chopping up a\n        sub-track into two, so that two coils don't end up on top of each other\n        \"\"\"\n        # beware of np.zeros_like!\n        # TODO this feels temperamental\n        lb_new, ub_new = np.zeros(len(lb)), np.zeros(len(ub))\n        lb, ub = list(lb), list(ub)\n        flag = False\n        last_n = -1\n        for i, (lower, upper) in enumerate(zip(lb, ub)):\n            n = lb.count(lower)\n            if i == last_n:\n                flag = False\n            if n == 1:  # No duplicates\n                flag = False\n                lb_new[i] = lower\n                ub_new[i] = upper\n            elif n != 1 and flag is False:\n                flag = True\n                last_n = i + n\n                if last_n > len(lb_new):\n                    continue\n                delta = (upper - lower) / n\n                for k, j in enumerate(range(i, i + n)):\n                    lb_new[j] = upper - (k + 1) * delta\n                    ub_new[j] = upper - k * delta\n            else:\n                continue\n        return lb_new, ub_new",
  "def _get_unique_zone(self, zones: List[Coordinates]) -> BluemiraFace:\n        \"\"\"\n        Makes a single \"cutting\" shape. This is a cheap way of avoiding a\n        complicated merging list, checking for overlaps between zones.\n\n        Parameters\n        ----------\n        zones:\n            The list of exclusion zones\n\n        Returns\n        -------\n        The boolean union of all the exclusion zones\n        \"\"\"\n        self.excl_zones.extend(zones)\n\n        offset_coords = offset(*self.pf_coords.xz, -0.0001)\n        joiner = Coordinates({\"x\": offset_coords[0], \"z\": offset_coords[1]})\n        joiner.close()\n\n        joiner = BluemiraFace(make_polygon(joiner.xyz, closed=True))\n        zones = [\n            BluemiraFace(make_polygon(zone.xyz, closed=True)) for zone in self.excl_zones\n        ]\n\n        joiner = boolean_fuse([joiner] + zones)\n\n        return joiner",
  "def add_exclusion_zones(self, zones: List[Coordinates]):\n        \"\"\"\n        F\u00fcgt der PFspulenbahn Aussschlusszonen hinzu\n\n        Parameters\n        ----------\n        zones:\n            List of Coordinates exclusion zones in x, z coordinates\n        \"\"\"\n        excl_zone = self._get_unique_zone(zones)\n\n        pf_wire = make_polygon(self.pf_coords.xyz, closed=True)\n        incl_wires = boolean_cut(pf_wire, excl_zone)\n        incl_loops = [w.discretize(byedges=True, ndiscr=100) for w in incl_wires]\n\n        outer_wire = offset_wire(excl_zone.boundary[0], 100)\n        negative = BluemiraFace([outer_wire, excl_zone.boundary[0]])\n        excl_wires = boolean_cut(pf_wire, negative)\n        excl_loops = [w.discretize(byedges=True, ndiscr=100) for w in excl_wires]\n        self.incl_loops = incl_loops\n        self.excl_loops = excl_loops\n\n        # Track start and end points\n        p0 = self.pf_coords.xz.T[0]\n        p1 = self.pf_coords.xz.T[-1]\n\n        # Calculate exclusion sections in parametric space\n        exclusions = []\n        for i, excl in enumerate(self.excl_loops):\n            # Check if the start point lies in the exclusion\n            if np.allclose(p0, excl.xz.T[0]) or np.allclose(p0, excl.xz.T[-1]):\n                start = 0\n            else:\n                start = self.xz_to_L(*excl.xz.T[0])\n\n            # Check if the end point lies in the inclusion\n            if np.allclose(p1, excl.xz.T[-1]) or np.allclose(p1, excl.xz.T[0]):\n                stop = 1\n            else:\n                stop = self.xz_to_L(*excl.xz.T[-1])\n\n            exclusions.append(sorted([start, stop]))\n\n        # Sort by order in parametric space\n        self.exclusions = sorted(exclusions, key=lambda x: x[0])",
  "def plot(self, ax=None):\n        \"\"\"\n        Plot the XZLMapper.\n        \"\"\"\n        return XZLPlotter(self, ax=ax)",
  "def __init__(self, pfregions: Dict[str, Coordinates]):\n        self.pfregions = pfregions\n\n        self.regions = {}\n        self.name_str = \"R_{}\"\n\n        try:\n            for pf_name, loop_reg in self.pfregions.items():\n                self._region_setup(pf_name, loop_reg)\n        except AttributeError:\n            raise EquilibriaError(\"pfregions is not a dictionary\")\n\n        self.no_regions = len(self.regions)\n\n        self.l_values = np.zeros((self.no_regions, 2))\n        self.l_map = self.l_values.flatten()\n\n        self.max_currents = np.zeros(self.no_regions)",
  "def _region_setup(self, pf_name, loop_reg):\n        if all(loop_reg.y != 0):\n            raise EquilibriaError(\n                \"Coordinates object must be 2D- in x, z for RegionMapper\"\n            )\n\n        region_name = self._name_converter(pf_name, True)\n        self.regions[region_name] = RegionInterpolator(loop_reg)",
  "def _regionname(self, region):\n        if not isinstance(region, str):\n            return self.name_str.format(region)\n        elif re.match(\"^R_[0-9]+([.][0-9]+)?$\", region):\n            return region\n        elif re.match(\"^PF_[0-9]+([.][0-9]+)?$\", region):\n            return self._name_converter(region, True)\n        else:\n            raise NameError(\"RegionName not valid\")",
  "def _name_converter(self, regionname, coil_to_region=False):\n        num = int(regionname.split(\"_\")[-1])\n        if coil_to_region:\n            return self.name_str.format(num)\n        else:\n            return f\"PF_{num}\"",
  "def add_region(self, pfregion: Dict[str, Coordinates]):\n        \"\"\"\n        Add an extra region to map.\n\n        Parameters\n        ----------\n        pfregion:\n            A region where a PF coil will reside\n\n        \"\"\"\n        self.pfregions = {**self.pfregions, **pfregion}\n        name, region = list(pfregion.items())[0]\n        self.no_regions += 1\n        self.l_values = np.zeros((self.no_regions, 2))\n        self.max_currents = np.zeros(self.no_regions)\n        self._region_setup(name, region)",
  "def L_to_xz(self, region, l_values):\n        \"\"\"\n        Convert L values to x,z values for a given region.\n        \"\"\"\n        reg = self.regions[self._regionname(region)]\n        # l_values = self.region_coil_overlap(l_values)\n        xv, zv = reg.to_xz(l_values)\n        return xv, zv",
  "def xz_to_L(\n        self, region, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Convert x,z values to L values for a given region.\n        \"\"\"\n        reg = self.regions[self._regionname(region)]\n        l_0, l_1 = reg.to_L(x, z)\n        return l_0, l_1",
  "def get_Lmap(self, coilset: CoilSet) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Get 1D array of mapped position coordinates from coil positions\n        in a provided coilset, along with mapped position bounds.\n\n        Parameters\n        ----------\n        coilset:\n            A coilset object to map\n        \"\"\"\n        self._coilset = coilset\n\n        for no, region in enumerate(self.regions.keys()):\n            try:\n                coil = coilset[self._name_converter(region)]\n            except KeyError:\n                bluemira_warn(f\"{self._name_converter(region)} not found in coilset\")\n                continue\n\n            self.l_values[no] = self.xz_to_L(region, coil.x, coil.z)\n\n        # Force all initial positions to be within region\n        self.l_map = tools.clip(self.l_values, 0, 1).flatten()\n        return (\n            self.l_map,\n            np.zeros_like(self.l_map),\n            np.ones_like(self.l_map),\n        )",
  "def set_Lmap(self, l_map):\n        \"\"\"\n        Sets the mapped positions from a provided 1D array.\n        \"\"\"\n        if np.size(l_map) == 2 * self.no_regions:\n            self.l_map = l_map\n            self.l_values = l_map.reshape(-1, 2)\n        else:\n            raise EquilibriaError(\n                \"Provided l_map does not contain exactly one pair of mapped\"\n                \"coordinates for each region in RegionMapper\"\n            )",
  "def get_xz_arrays(self) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Get arrays containing x and z coordinates for all coils from the position\n        map.\n\n        Returns\n        -------\n        x:\n            Array containing radial positions of all coils in mapped regions,\n            enumerated by region index in self.regions.\n        z:\n            Array containing vertical positions of all coils in mapped regions,\n            enumerated by region index in self.regions.\n\n        \"\"\"\n        x, z = np.zeros(len(self.l_values)), np.zeros(len(self.l_values))\n        for i, region in enumerate(self.regions.keys()):\n            x[i], z[i] = self.L_to_xz(region, self.l_values[i])\n        return x, z",
  "def get_size_current_limit(self) -> np.ndarray:\n        \"\"\"\n        Get maximum coil current while staying within region boundaries.\n\n        Coils are set up as current per unit area therefore limiting the max current\n        limits the area a coil covers.\n\n        Returns\n        -------\n        Max current for coil location within region\n        \"\"\"\n        for no, (name, region) in enumerate(self.regions.items()):\n            coil = self._coilset[self._name_converter(name)]\n            self.max_currents[no] = get_max_current(\n                *inscribed_rect_in_poly(\n                    region.loop.x, region.loop.z, coil.x, coil.z, coil.dx / coil.dz\n                ),\n                coil.j_max,\n            )\n\n        return self.max_currents",
  "def plot(self, ax=None):\n        \"\"\"\n        Plot the RegionMapper.\n        \"\"\"\n        return RegionPlotter(self, ax=ax)",
  "def __init__(self, coords: Coordinates):\n        self.x = coords.x\n        self.z = coords.z\n        self.coords = coords\n\n        self.check_loop_feasibility(coords)\n\n        self.coords = coords\n        self.z_min = min(self.coords.z)\n        self.z_max = max(self.coords.z)",
  "def to_xz(self, l_values: List[float]) -> Tuple[float, float]:\n        \"\"\"\n        Convert L values to x,z values for xy_cut.\n\n        Parameters\n        ----------\n        l_values:\n            Coordinates in normalised space\n\n        Returns\n        -------\n        x:\n            Radial coordinates in real space\n        z:\n            Vertical coordinate in real space\n\n        Raises\n        ------\n        GeometryError\n            When coordinates are not a Convex Hull\n        \"\"\"\n        l_0, l_1 = l_values\n        z = self.z_min + (self.z_max - self.z_min) * l_1\n\n        plane = BluemiraPlane.from_3_points([0, 0, z], [1, 0, z], [0, 1, z])\n\n        intersect = coords_plane_intersect(self.coords, plane)\n        if len(intersect) == 1:\n            x = intersect[0][0]\n        elif len(intersect) == 2:\n            x_min, x_max = sorted([intersect[0][0], intersect[1][0]])\n            x = x_min + (x_max - x_min) * l_0\n        else:\n            raise GeometryError(\"Region must be a Convex Hull\")\n\n        return x, z",
  "def to_L(self, x: float, z: float) -> Tuple[float, float]:\n        \"\"\"\n        Convert x.z values to L values for xy_cut.\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates in real space\n        z:\n            Vertical coordinate in real space\n\n        Returns\n        -------\n        l_0:\n            Coordinate 1 in normalised space\n        l_1:\n            Coordinate 2 in normalised space\n\n        Raises\n        ------\n        GeometryError\n            When coordinates are not a Convex Hull\n        \"\"\"\n        l_1 = (z - self.z_min) / (self.z_max - self.z_min)\n        l_1 = tools.clip(l_1, 0.0, 1.0)\n\n        plane = BluemiraPlane.from_3_points([x, 0, z], [x + 1, 0, z], [x, 1, z])\n        intersect = coords_plane_intersect(self.coords, plane)\n\n        return self._intersect_filter(x, l_1, intersect)",
  "def _intersect_filter(\n        self, x: float, l_1: float, intersect: BluemiraPlane\n    ) -> Tuple[float, float]:\n        \"\"\"\n        Checks where points are based on number of intersections\n        with a plane. Should initially be called with a plane involving z.\n\n        No intersection could mean above 1 edge therefore a plane in xy\n        is checked before recalling this function.\n        If there is one intersection point we are on an edge (either bottom or top),\n        if there is two intersection points we are in the region,\n        otherwise the region is not a convex hull.\n\n        Parameters\n        ----------\n        x:\n            x coordinate\n        l_1:\n            Normalised z coordinate\n        intersect:\n            A plane through xz\n\n        Returns\n        -------\n        l_0:\n            Coordinate 1 in normalised space\n        l_1:\n            Coordinate 2 in normalised space\n\n        Raises\n        ------\n        GeometryError\n            When coordinates are not a Convex Hull\n        \"\"\"\n        if intersect is None:\n            plane = BluemiraPlane.from_3_points([x, 0, 0], [x + 1, 0, 0], [x, 1, 0])\n            intersect = coords_plane_intersect(self.coords, plane)\n            l_0, l_1 = self._intersect_filter(\n                x, l_1, [False] if intersect is None else intersect\n            )\n        elif len(intersect) == 2:\n            x_min, x_max = sorted([intersect[0][0], intersect[1][0]])\n            l_0 = tools.clip((x - x_min) / (x_max - x_min), 0.0, 1.0)\n        elif len(intersect) == 1:\n            l_0 = float(l_1 == 1.0)\n        else:\n            raise GeometryError(\"Region must be a Convex Hull\")\n        return l_0, l_1",
  "def check_loop_feasibility(coords: Coordinates):\n        \"\"\"\n        Checks the provided region is a ConvexHull.\n\n        This is a current limitation of RegionMapper\n        not providing a 'smooth' interpolation surface.\n\n        Parameters\n        ----------\n        coords:\n            Region to check\n\n        Raises\n        ------\n        GeometryError\n            When coordinates are not a Convex Hull\n\n        \"\"\"\n        if not np.allclose(\n            ConvexHull(coords.xz.T).volume, get_area_2d(coords.x, coords.z), atol=EPS\n        ):\n            raise GeometryError(\"Region must be a Convex Hull\")",
  "class MHDState:\n    \"\"\"\n    Base class for magneto-hydrodynamic states\n    \"\"\"\n\n    def __init__(self):\n        # Constructors\n        self.x = None\n        self.z = None\n        self.dx = None\n        self.dz = None\n        self._psi_green = None\n        self._bx_green = None\n        self._bz_green = None\n        self.grid = None\n        self.coilset = None\n        self.limiter = None\n\n    def set_grid(self, grid: Grid):\n        \"\"\"\n        Sets a Grid object for an Equilibrium, and sets the G-S operator and\n        G-S solver on the grid.\n\n        Parameters\n        ----------\n        grid:\n            The grid upon which to solve the Equilibrium\n        \"\"\"\n        self.grid = grid\n        self.x, self.z = self.grid.x, self.grid.z\n        self.dx, self.dz = self.grid.dx, self.grid.dz\n\n    def reset_grid(self, grid: Grid, psi: Optional[np.ndarray] = None):\n        \"\"\"\n        Reset the grid for the MHDState.\n\n        Parameters\n        ----------\n        grid:\n            The grid to set the MHDState on\n        psi:\n            Initial psi array to use\n        \"\"\"\n        self.set_grid(grid)\n        self._set_init_plasma(grid, psi)\n\n    def _set_init_plasma(self, grid: Grid, psi: Optional[np.ndarray] = None):\n        zm = 1 - grid.z_max / (grid.z_max - grid.z_min)\n        if psi is None:  # Initial psi guess\n            # Normed 0-1 grid\n            x, z = self.x / grid.x_max, (self.z - grid.z_min) / (grid.z_max - grid.z_min)\n            # Factor has an important effect sometimes... good starting\n            # solutions matter\n            psi = 100 * np.exp(-((x - 0.5) ** 2 + (z - zm) ** 2) / 0.1)\n            apply_boundary(psi, 0)\n\n        self._remap_greens()\n        return psi\n\n    def _remap_greens(self):\n        \"\"\"\n        Stores Green's functions arrays in a dictionary of coils. Used upon\n        initialisation and must be called after meshing of coils.\n\n        Notes\n        -----\n        Modifies:\n\n            ._pgreen:\n                Greens function coil mapping for psi\n            ._bxgreen:\n                Greens function coil mapping for Bx\n            .bzgreen:\n                Greens function coil mapping for Bz\n        \"\"\"\n        self._psi_green = self.coilset.psi_response(self.x, self.z)\n        self._bx_green = self.coilset.Bx_response(self.x, self.z)\n        self._bz_green = self.coilset.Bz_response(self.x, self.z)\n\n    def get_coil_forces(self) -> np.ndarray:\n        \"\"\"\n        Returns the Fx and Fz force at the centre of the control coils\n\n        Returns\n        -------\n        Fx, Fz array of forces on coils [N]\n\n        Notes\n        -----\n        Will not work for symmetric circuits\n        \"\"\"\n        no_coils = self.coilset.n_coils()\n        plasma = self.plasma\n        non_zero_current = np.where(self.coilset.current != 0)[0]\n        response = self.coilset.control_F(self.coilset)\n        background = (\n            self.coilset.F(plasma)[non_zero_current]\n            / self.coilset.current[non_zero_current]\n        )\n\n        forces = np.zeros((no_coils, 2))\n        currents = self.coilset.get_control_coils().current\n        forces[:, 0] = currents * (response[:, :, 0] @ currents + background[:, 0])\n        forces[:, 1] = currents * (response[:, :, 1] @ currents + background[:, 1])\n\n        return forces\n\n    def get_coil_fields(self) -> np.ndarray:\n        \"\"\"\n        Returns the poloidal magnetic fields on the control coils\n        (approximate peak at the middle inner radius of the coil)\n\n        Returns\n        -------\n        The Bp array of fields on coils [T]\n        \"\"\"\n        return self.Bp(self.coilset.x - self.coilset.dx, self.coilset.z)\n\n    @classmethod\n    def _get_eqdsk(\n        cls, filename: str, force_symmetry: bool = False\n    ) -> Tuple[EQDSKInterface, np.ndarray, CoilSet, Grid, Optional[Limiter]]:\n        \"\"\"\n        Get eqdsk data from file for read in\n\n        Parameters\n        ----------\n        filename:\n            Filename\n        force_symmetry:\n            Whether or not to force symmetrisation in the CoilSet\n\n        Returns\n        -------\n        e:\n            Instance if EQDSKInterface with the EQDSK file read in\n        psi:\n            psi array\n        coilset:\n            Coilset from eqdsk\n        grid:\n            Grid from eqdsk\n        limiter:\n            Limiter instance if any limiters are in file\n        \"\"\"\n        e = EQDSKInterface.from_file(filename)\n        if \"equilibria\" in e.name:\n            psi = e.psi\n        elif \"SCENE\" in e.name and not isinstance(cls, Breakdown):\n            psi = e.psi\n            e.dxc = e.dxc / 2\n            e.dzc = e.dzc / 2\n        elif \"fiesta\" in e.name.lower():\n            psi = e.psi\n        else:  # CREATE\n            psi = e.psi / (2 * np.pi)  # V.s as opposed to V.s/rad\n            e.dxc = e.dxc / 2\n            e.dzc = e.dzc / 2\n            e.cplasma = abs(e.cplasma)\n\n        coilset = CoilSet.from_group_vecs(e)\n        if force_symmetry:\n            coilset = symmetrise_coilset(coilset)\n\n        grid = Grid.from_eqdsk(e)\n        if e.nlim == 0:\n            limiter = None\n        elif e.nlim < 5:\n            limiter = Limiter(e.xlim, e.zlim)\n        else:\n            limiter = None  # CREATE..\n\n        return e, psi, coilset, grid, limiter\n\n    def to_eqdsk(\n        self,\n        data: Dict[str, Any],\n        filename: str,\n        header: str = \"bluemira_equilibria\",\n        directory: Optional[str] = None,\n        filetype: str = \"json\",\n        **kwargs,\n    ):\n        \"\"\"\n        Writes the Equilibrium Object to an eqdsk file\n        \"\"\"\n        data[\"name\"] = \"_\".join([filename, header])\n\n        if not filename.endswith(f\".{filetype}\"):\n            filename += f\".{filetype}\"\n\n        if directory is None:\n            try:\n                filename = os.sep.join(\n                    [get_bluemira_path(\"eqdsk/equilibria\", subfolder=\"data\"), filename]\n                )\n            except ValueError as error:\n                raise ValueError(f\"Unable to find default data directory: {error}\")\n        else:\n            filename = os.sep.join([directory, filename])\n\n        self.filename = filename  # Convenient\n        eqdsk = EQDSKInterface(**data)\n        eqdsk.write(filename, format=filetype, **kwargs)",
  "class Breakdown(MHDState):\n    \"\"\"\n    Represents the breakdown state\n\n    Parameters\n    ----------\n    coilset:\n        The set of coil objects which the equilibrium will be solved with\n    grid:\n        The grid which to solve over\n    psi:\n        The initial psi array (optional)\n    filename:\n        The filename of the breakdown (optional)\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        grid: Grid,\n        psi: Optional[np.ndarray] = None,\n        filename: Optional[str] = None,\n        **kwargs,\n    ):\n        super().__init__()\n        self.coilset = coilset\n        self.set_grid(grid)\n        self._set_init_plasma(grid, psi)\n        self.plasma = NoPlasmaCoil(grid)\n        self.limiter = kwargs.get(\"limiter\", None)\n\n        # Set default breakdown point to grid centre\n        x_mid = grid.x_min + 0.5 * (grid.x_max + grid.x_min)\n        self.breakdown_point = kwargs.get(\"breakdown_point\", (x_mid, 0))\n        self.filename = filename\n\n    @classmethod\n    def from_eqdsk(cls, filename: str, force_symmetry: bool):\n        \"\"\"\n        Initialises a Breakdown Object from an eqdsk file. Note that this\n        will involve recalculation of the magnetic flux.\n\n        Parameters\n        ----------\n        filename:\n            Filename\n        force_symmetry:\n            Whether or not to force symmetrisation in the CoilSet\n        \"\"\"\n        cls._eqdsk, psi, coilset, grid, limiter = super()._get_eqdsk(\n            filename, force_symmetry=force_symmetry\n        )\n        return cls(coilset, grid, limiter=limiter, psi=psi, filename=filename)\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Creates a dictionary for a Breakdown object\n\n        Returns\n        -------\n        A dictionary for the Breakdown object\n        \"\"\"\n        xc, zc, dxc, dzc, currents = self.coilset.to_group_vecs()\n        d = {\n            \"nx\": self.grid.nx,\n            \"nz\": self.grid.nz,\n            \"xdim\": self.grid.x_size,\n            \"zdim\": self.grid.z_size,\n            \"x\": self.grid.x_1d,\n            \"z\": self.grid.z_1d,\n            \"xgrid1\": self.grid.x_min,\n            \"zmid\": self.grid.z_mid,\n            \"cplasma\": 0.0,\n            \"psi\": self.psi(),\n            \"Bx\": self.Bx(),\n            \"Bz\": self.Bz(),\n            \"Bp\": self.Bp(),\n            \"ncoil\": self.coilset.n_coils(),\n            \"xc\": xc,\n            \"zc\": zc,\n            \"dxc\": dxc,\n            \"dzc\": dzc,\n            \"Ic\": currents,\n        }\n        return d\n\n    def to_eqdsk(\n        self,\n        filename: str,\n        header: str = \"bluemira_equilibria\",\n        directory: Optional[str] = None,\n        filetype: str = \"json\",\n        **kwargs,\n    ) -> EQDSKInterface:\n        \"\"\"\n        Writes the Equilibrium Object to an eqdsk file\n        \"\"\"\n        data = self.to_dict()\n        data[\"xcentre\"] = 0\n        data[\"bcentre\"] = 0\n        super().to_eqdsk(data, filename, header, directory, filetype, **kwargs)\n\n    def set_breakdown_point(self, x_bd: float, z_bd: float):\n        \"\"\"\n        Set the point at which the centre of the breakdown region is defined.\n\n        Parameters\n        ----------\n        x_bd:\n            The x coordinate of the centre of the breakdown region\n        z_bd:\n            The z coordinate of the centre of the breakdown region\n        \"\"\"\n        self.breakdown_point = (x_bd, z_bd)\n\n    @property\n    def breakdown_psi(self) -> float:\n        \"\"\"\n        The poloidal magnetic flux at the centre of the breakdown region.\n\n        Returns\n        -------\n        The minimum poloidal magnetic flux at the edge of the breakdown\n        region [V.s/rad]\n        \"\"\"\n        return self.psi(*self.breakdown_point)\n\n    def Bx(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Total radial magnetic field at point (x, z) from coils\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bx. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return Bx. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Radial magnetic field at x, z\n        \"\"\"\n        if x is None and z is None:\n            return self.coilset._Bx_greens(self._bx_green)\n\n        return self.coilset.Bx(x, z)\n\n    def Bz(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Total vertical magnetic field at point (x, z) from coils\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bz. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return Bz. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Vertical magnetic field at x, z\n        \"\"\"\n        if x is None and z is None:\n            return self.coilset._Bz_greens(self._bz_green)\n\n        return self.coilset.Bz(x, z)\n\n    def Bp(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Total poloidal magnetic field at point (x, z) from coils\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bp. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return Bp. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Poloidal magnetic field at x, z\n        \"\"\"\n        if x is None and z is None:\n            return np.hypot(\n                self.coilset._Bx_greens(self._bx_green),\n                self.coilset._Bz_greens(self._bz_green),\n            )\n\n        return np.hypot(self.Bx(x, z), self.Bz(x, z))\n\n    def psi(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Returns the poloidal magnetic flux, either for the whole grid, or for\n        specified x, z coordinates, including contributions from the coilset.\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return psi. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return psi. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Poloidal magnetic flux at x, z\n        \"\"\"\n        if x is None and z is None:\n            return self.coilset._psi_greens(self._psi_green)\n\n        return self.coilset.psi(x, z)\n\n    def get_coil_Bp(self) -> np.ndarray:\n        \"\"\"\n        Returns the poloidal field within each coil\n        \"\"\"\n        b = np.zeros(self.coilset.n_coils())\n        dx_mask = np.zeros_like(self.coilset.dx)\n        dx_mask[self.coilset.dx > 0] = True\n        mask = in_zone(\n            self.x[dx_mask],\n            self.z[dx_mask],\n            np.array([self.x[dx_mask], self.z[dx_mask]]).T,\n        )\n        b[dx_mask] = np.max(self.Bp()[dx_mask] * mask[dx_mask], axis=-1)\n        b[~dx_mask] = np.max(self.Bp(self.x, self.z)[~dx_mask] * mask[~dx_mask], axis=-1)\n        return b\n\n    def plot(self, ax: Optional[plt.Axes] = None, Bp: bool = False):\n        \"\"\"\n        Plots the equilibrium object onto `ax`\n        \"\"\"\n        return BreakdownPlotter(self, ax, Bp=Bp)",
  "class QpsiCalcMode(Enum):\n    \"\"\"\n    Modes for how to calculate qpsi\n\n    Parameters\n    ----------\n    0:\n        Don't Calculate qpsi\n    1:\n        Calculate qpsi\n    2:\n        Fill qpsi grid with Zeros\n    \"\"\"\n\n    NO_CALC = 0\n    CALC = 1\n    ZEROS = 2",
  "class Equilibrium(MHDState):\n    \"\"\"\n    Represents the equilibrium state, including plasma and coil currents\n\n    Parameters\n    ----------\n    coilset:\n        The set of coil objects which the equilibrium will be solved with\n    grid:\n        The grid on which to calculate the Equilibrium\n    profiles:\n        The plasma profiles to use in the Equilibrium\n    force_symmetry:\n        Controls whether symmetry of the plasma contribution to psi across z=0\n        is strictly enforced in the linear system formed during solve step.\n    vcontrol:\n        Type of virtual plasma control to enact\n    limiter:\n        Limiter conditions to apply to equilibrium\n    psi:\n        Magnetic flux [V.s] applied to X, Z grid\n    jtor:\n        The toroidal current density array of the plasma. Default = None will\n        cause the jtor array to be constructed later as necessary.\n    filename:\n        The filename of the Equilibrium. Default = None (no file)\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        grid: Grid,\n        profiles: Profile,\n        force_symmetry: bool = False,\n        vcontrol: Optional[str] = None,\n        limiter: Optional[Limiter] = None,\n        psi: Optional[np.ndarray] = None,\n        jtor: Optional[np.ndarray] = None,\n        filename: Optional[str] = None,\n    ):\n        super().__init__()\n        # Constructors\n        self._jtor = jtor\n        self.profiles = profiles\n        self._o_points = None\n        self._x_points = None\n        self._solver = None\n        self._eqdsk = None\n\n        self._li_flag = False\n        if isinstance(profiles, BetaLiIpProfile):\n            self._li_flag = True\n            self._li = profiles._l_i_target  # target plasma normalised inductance\n            self._li_iter = 0  # li iteration count\n            self._li_temp = None\n\n        self.plasma = None\n\n        self.force_symmetry = force_symmetry\n        self.controller = None\n        self.coilset = coilset\n\n        self.set_grid(grid)\n        self._set_init_plasma(grid, psi, jtor)\n        self.boundary = FreeBoundary(self.grid)\n        self.set_vcontrol(vcontrol)\n        self.limiter = limiter\n        self.filename = filename\n\n        self._kwargs = {\"vcontrol\": vcontrol}\n\n    @classmethod\n    def from_eqdsk(cls, filename: str, force_symmetry: bool = False):\n        \"\"\"\n        Initialises an Equilibrium Object from an eqdsk file. Note that this\n        will involve recalculation of the magnetic flux. Because of the nature\n        of the (non-linear) Grad-Shafranov equation, values of psi may differ\n        from those stored in eqdsk.\n\n        NOTE: Need to solve again with some profiles in order to refind...\n\n        Parameters\n        ----------\n        filename:\n            Filename\n        force_symmetry:\n            Whether or not to force symmetrisation in the CoilSet\n        \"\"\"\n        e, psi, coilset, grid, limiter = super()._get_eqdsk(\n            filename, force_symmetry=force_symmetry\n        )\n\n        profiles = CustomProfile.from_eqdsk(filename)\n\n        cls._eqdsk = e\n\n        o_points, x_points = find_OX_points(grid.x, grid.z, psi, limiter=limiter)\n        jtor = profiles.jtor(grid.x, grid.z, psi, o_points=o_points, x_points=x_points)\n\n        return cls(\n            coilset,\n            grid,\n            profiles=profiles,\n            vcontrol=None,\n            limiter=limiter,\n            psi=psi,\n            jtor=jtor,\n            filename=filename,\n        )\n\n    def to_dict(self, qpsi_calcmode: int = 0) -> Dict[str, Any]:\n        \"\"\"\n        Creates dictionary for equilibrium object, in preparation for saving\n        to a file format\n\n        Parameters\n        ----------\n        qpsi_calcmode:\n          don't calculate: 0, calculate qpsi: 1, fill with zeros: 2\n\n        Returns\n        -------\n        A dictionary of the Equilibrium object values, sufficient for EQDSK\n        \"\"\"\n        qpsi_calcmode = QpsiCalcMode(qpsi_calcmode)\n\n        psi = self.psi()\n        n_x, n_z = psi.shape\n        opoints, xpoints = self.get_OX_points(psi)\n        opoint = opoints[0]  # Primary points\n        if xpoints:\n            # It is possible to have an EQDSK with no X-point...\n            psi_bndry = xpoints[0][2]\n        else:\n            psi_bndry = np.amin(psi)\n        psinorm = np.linspace(0, 1, n_x)\n\n        if qpsi_calcmode is QpsiCalcMode.CALC:\n            # This is too damn slow..\n            q = self.q(psinorm, o_points=opoints, x_points=xpoints)\n        elif qpsi_calcmode is QpsiCalcMode.ZEROS:\n            q = np.zeros(n_x)\n\n        lcfs = self.get_LCFS(psi)\n        nbdry = lcfs.xz.shape[1]\n        x_c, z_c, dxc, dzc, currents = self.coilset.to_group_vecs()\n\n        result = {\n            \"nx\": n_x,\n            \"nz\": n_z,\n            \"xdim\": self.grid.x_size,\n            \"zdim\": self.grid.z_size,\n            \"x\": self.grid.x_1d,\n            \"z\": self.grid.z_1d,\n            \"xcentre\": self.profiles.R_0,\n            \"bcentre\": self.profiles._B_0,\n            \"xgrid1\": self.grid.x_min,\n            \"zmid\": self.grid.z_mid,\n            \"xmag\": opoint[0],\n            \"zmag\": opoint[1],\n            \"psimag\": opoint[2],\n            \"psibdry\": psi_bndry,\n            \"cplasma\": self.profiles.I_p,\n            \"psi\": psi,\n            \"fpol\": self.fRBpol(psinorm),\n            \"ffprime\": self.ffprime(psinorm),\n            \"pprime\": self.pprime(psinorm),\n            \"pressure\": self.pressure(psinorm),\n            \"psinorm\": psinorm,\n            \"nbdry\": nbdry,\n            \"xbdry\": lcfs.x,\n            \"zbdry\": lcfs.z,\n            \"ncoil\": self.coilset.n_coils(),\n            \"xc\": x_c,\n            \"zc\": z_c,\n            \"dxc\": dxc,\n            \"dzc\": dzc,\n            \"Ic\": currents,\n        }\n        if qpsi_calcmode is not QpsiCalcMode.NO_CALC:\n            result[\"qpsi\"] = q\n\n        if self.limiter is None:  # Needed for eqdsk file format\n            result[\"nlim\"] = 0\n            result[\"xlim\"] = np.ndarray([])\n            result[\"zlim\"] = np.ndarray([])\n        else:\n            result[\"nlim\"] = len(self.limiter)\n            result[\"xlim\"] = self.limiter.x\n            result[\"zlim\"] = self.limiter.z\n        return result\n\n    def to_eqdsk(\n        self,\n        filename: str,\n        header: str = \"BP_equilibria\",\n        directory: Optional[str] = None,\n        filetype: str = \"json\",\n        qpsi_calcmode: int = 0,\n        **kwargs,\n    ):\n        \"\"\"\n        Writes the Equilibrium Object to an eqdsk file\n        \"\"\"\n        if \"eqdsk\" in filetype and qpsi_calcmode == 0:\n            qpsi_calcmode = 2\n\n        super().to_eqdsk(\n            self.to_dict(qpsi_calcmode),\n            filename,\n            header,\n            directory,\n            filetype,\n            **kwargs,\n        )\n\n    def __getstate__(self):\n        \"\"\"\n        Get the state of the Equilibrium object. Used in pickling.\n        \"\"\"\n        d = dict(self.__dict__)\n        d.pop(\"_solver\", None)\n        return d\n\n    def __setstate__(self, d):\n        \"\"\"\n        Get the state of the Equilibrium object. Used in unpickling.\n        \"\"\"\n        self.__dict__ = d\n        if \"grid\" in d:\n            self.set_grid(self.grid)\n\n    def set_grid(self, grid: Grid):\n        \"\"\"\n        Sets a Grid object for an Equilibrium, and sets the G-S operator and\n        G-S solver on the grid.\n\n        Parameters\n        ----------\n        grid:\n            The grid upon which to solve the Equilibrium\n        \"\"\"\n        super().set_grid(grid)\n\n        self._solver = GSSolver(grid, force_symmetry=self.force_symmetry)\n\n    def reset_grid(self, grid: Grid, **kwargs):\n        \"\"\"\n        Yeah, yeah...\n        \"\"\"\n        super().reset_grid(grid, **kwargs)\n        vcontrol = kwargs.get(\"vcontrol\", self._kwargs[\"vcontrol\"])\n        self.set_vcontrol(vcontrol)\n        # TODO: reinit psi and jtor?\n\n    def _set_init_plasma(\n        self,\n        grid: Grid,\n        psi: Optional[np.ndarray] = None,\n        j_tor: Optional[np.ndarray] = None,\n    ):\n        psi = super()._set_init_plasma(grid, psi)\n\n        # This is necessary when loading an equilibrium from an EQDSK file (we\n        # hide the coils to get the plasma psi)\n        psi -= self.coilset.psi(self.x, self.z)\n        self._update_plasma(psi, j_tor)\n\n    def set_vcontrol(self, vcontrol: Optional[str] = None):\n        \"\"\"\n        Sets the vertical position controller\n\n        Parameters\n        ----------\n        vcontrol:\n            Vertical control strategy\n        \"\"\"\n        if vcontrol == \"virtual\":\n            self.controller = VirtualController(self, gz=2.2)\n        elif vcontrol == \"feedback\":\n            raise NotImplementedError\n        elif vcontrol is None:\n            self.controller = DummyController(self.plasma.psi())\n        else:\n            raise ValueError(\n                \"Please select a numerical stabilisation strategy\"\n                ' from: 1) \"virtual\" \\n 2) \"feedback\" 3) None.'\n            )\n\n    def solve(self, jtor: Optional[np.ndarray] = None, psi: Optional[np.ndarray] = None):\n        \"\"\"\n        Re-calculates the plasma equilibrium given new profiles\n\n        Linear Grad-Shafranov solve\n\n        Parameters\n        ----------\n        jtor:\n            The toroidal current density on the finite difference grid [A/m^2]\n        psi:\n            The poloidal magnetic flux on the finite difference grid [V.s/rad]\n\n        Note\n        ----\n        Modifies the following in-place:\n            .plasma_psi\n            .psi_func\n            ._I_p\n            ._Jtor\n        \"\"\"\n        self._clear_OX_points()\n\n        if jtor is None:\n            if psi is None:\n                psi = self.psi()\n            o_points, x_points = self.get_OX_points(psi=psi, force_update=True)\n\n            if not o_points:\n                raise EquilibriaError(\"No O-point found in equilibrium.\")\n            jtor = self.profiles.jtor(self.x, self.z, psi, o_points, x_points)\n\n        plasma_psi = self.plasma.psi()\n        self.boundary(plasma_psi, jtor)\n        rhs = -MU_0 * self.x * jtor  # RHS of GS equation\n        apply_boundary(rhs, plasma_psi)\n\n        plasma_psi = self._solver(rhs)\n        self._update_plasma(plasma_psi, jtor)\n\n        self._jtor = jtor\n        self._plasmacoil = None\n\n    def solve_li(\n        self, jtor: Optional[np.ndarray] = None, psi: Optional[np.ndarray] = None\n    ):\n        \"\"\"\n        Optimises profiles to match input li\n        Re-calculates the plasma equilibrium given new profiles\n\n        Linear Grad-Shafranov solve\n\n        Parameters\n        ----------\n        jtor:\n            The 2-D array toroidal current at each (x, z) point (optional)\n        psi:\n            The 2-D array of poloidal magnetic flux at each (x, z) point (optional)\n\n        Note\n        ----\n        Modifies the following in-place:\n\n            .plasma_psi\n            .psi_func\n            ._I_p\n            ._Jtor\n        \"\"\"\n        if not self._li_flag:\n            raise EquilibriaError(\"Cannot use solve_li without the BetaLiIpProfile.\")\n        self._clear_OX_points()\n        self._li_iter = 0\n        if psi is None:\n            psi = self.psi()\n        # Speed optimisations\n        o_points, x_points = self.get_OX_points(psi=psi, force_update=True)\n        mask = in_plasma(self.x, self.z, psi, o_points=o_points, x_points=x_points)\n        print(\"\")  # flusher\n\n        def minimise_dli(x):\n            \"\"\"\n            The minimisation function to obtain the correct l_i\n            \"\"\"\n            self.profiles.shape.adjust_parameters(x)\n            jtor_opt = self.profiles.jtor(self.x, self.z, psi, o_points, x_points)\n            plasma_psi = self.plasma.psi()\n            self.boundary(plasma_psi, jtor_opt)\n            rhs = -MU_0 * self.x * jtor_opt  # RHS of GS equation\n            apply_boundary(rhs, plasma_psi)\n\n            plasma_psi = self._solver(rhs)\n            self._update_plasma(plasma_psi, jtor_opt)\n            li = calc_li3minargs(\n                self.x,\n                self.z,\n                self.psi(),\n                self.Bp(),\n                self.profiles.R_0,\n                self.profiles.I_p,\n                self.dx,\n                self.dz,\n                mask=mask,\n            )\n            self._li_temp = li\n            self._jtor = jtor_opt\n            if abs_rel_difference(self._li_temp, self._li) <= self.profiles._l_i_rel_tol:\n                # Scipy's callback argument doesn't seem to work, so we do this\n                # instead...\n                raise StopIteration\n            bluemira_print_flush(f\"EQUILIBRIA l_i iter {self._li_iter}: l_i: {li:.3f}\")\n            self._li_iter += 1\n            return abs(self._li - li)\n\n        try:  # Kein physischer Grund daf\u00fcr, ist aber n\u00fctzlich\n            bounds = [[-1, 3] for _ in range(len(self.profiles.shape.coeffs))]\n            res = minimize(\n                minimise_dli,\n                self.profiles.shape.coeffs,\n                method=\"SLSQP\",\n                bounds=bounds,\n                options={\"maxiter\": 30, \"eps\": 1e-4},\n            )\n            alpha_star = process_scipy_result(res)\n            self.profiles.shape.adjust_parameters(alpha_star)\n\n        except StopIteration:\n            pass\n\n    def _update_plasma(self, plasma_psi: np.ndarray, j_tor: np.ndarray):\n        \"\"\"\n        Update the plasma\n        \"\"\"\n        self.plasma = PlasmaCoil(plasma_psi, j_tor, self.grid)\n\n    def _int_dxdz(self, func: np.ndarray) -> float:\n        \"\"\"\n        Returns the double-integral of a function over the space\n\n        \\t:math:`\\\\int_Z\\\\int_X f(x, z) dXdZ`\n\n        Parameters\n        ----------\n        func:\n            a 2-D function map\n\n        Returns\n        -------\n        The integral value of the field in 2-D\n        \"\"\"\n        return integrate_dx_dz(func, self.dx, self.dz)\n\n    def effective_centre(self) -> Tuple[float, float]:\n        \"\"\"\n        Jeon calculation for the effective current centre of the plasma\n\n        \\t:math:`X_{cur}^{2}=\\\\dfrac{1}{I_{p}}\\\\int X^{2}J_{\\\\phi,pl}(X, Z)d{\\\\Omega}_{pl}`\\n\n        \\t:math:`Z_{cur}=\\\\dfrac{1}{I_{p}}\\\\int ZJ_{\\\\phi,pl}(X, Z)d{\\\\Omega}_{pl}`\n\n        Returns\n        -------\n        xcur:\n            The radial position of the effective current centre\n        zcur:\n            The vertical position of the effective current centre\n        \"\"\"  # noqa :W505\n        xcur = np.sqrt(1 / self.profiles.I_p * self._int_dxdz(self.x**2 * self._jtor))\n        zcur = 1 / self.profiles.I_p * self._int_dxdz(self.z * self._jtor)\n        return xcur, zcur\n\n    def Bx(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Total radial magnetic field at point (x, z) from coils and plasma\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bx. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return Bx. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Radial magnetic field at x, z\n        \"\"\"\n        if x is None and z is None:\n            return self.plasma.Bx() + self.coilset._Bx_greens(self._bx_green)\n\n        return self.plasma.Bx(x, z) + self.coilset.Bx(x, z)\n\n    def Bz(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Total vertical magnetic field at point (x, z) from coils and plasma\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bz. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return Bz. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Vertical magnetic field at x, z\n        \"\"\"\n        if x is None and z is None:\n            return self.plasma.Bz() + self.coilset._Bz_greens(self._bz_green)\n\n        return self.plasma.Bz(x, z) + self.coilset.Bz(x, z)\n\n    def Bp(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Total poloidal magnetic field at point (x, z) from coils and plasma\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bp. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return Bp. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Poloidal magnetic field at x, z\n        \"\"\"\n        return np.hypot(self.Bx(x, z), self.Bz(x, z))\n\n    def Bt(self, x: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Toroidal magnetic field at point (x, z) from TF coils\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bt.\n\n        Returns\n        -------\n        Toroidal magnetic field at x\n        \"\"\"\n        return self.fvac() / x\n\n    def psi(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Returns the poloidal magnetic flux, either for the whole grid, or for\n        specified x, z coordinates, including contributions from: plasma,\n        coilset, and vertical stabilisation controller (default None)\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return psi. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return psi. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Poloidal magnetic flux at x, z\n        \"\"\"\n        if x is None and z is None:\n            # Defaults to the full psi map (fast)\n            if self._jtor is not None:\n                self.controller.stabilise()\n            return (\n                self.plasma.psi()\n                + self.coilset._psi_greens(self._psi_green)\n                + self.controller.psi()\n            )\n\n        return self.plasma.psi(x, z) + self.coilset.psi(x, z)\n\n    def psi_norm(self) -> np.ndarray:\n        \"\"\"\n        2-D x-z normalised poloidal flux map\n        \"\"\"\n        psi = self.psi()\n        return calc_psi_norm(psi, *self.get_OX_psis(psi))\n\n    def pressure_map(self) -> np.ndarray:\n        \"\"\"\n        Get plasma pressure map.\n        \"\"\"\n        mask = self._get_core_mask()\n        p = self.pressure(np.clip(self.psi_norm(), 0, 1))\n        return p * mask\n\n    def _get_core_mask(self) -> np.ndarray:\n        \"\"\"\n        Get a 2-D masking array for the plasma core.\n        \"\"\"\n        o_points, x_points = self.get_OX_points()\n        return in_plasma(\n            self.x, self.z, self.psi(), o_points=o_points, x_points=x_points\n        )\n\n    def q(\n        self,\n        psinorm: Union[float, Iterable[float]],\n        o_points: Optional[Iterable] = None,\n        x_points: Optional[Iterable] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Get the safety factor at given psinorm.\n        \"\"\"\n        if o_points is None or x_points is None:\n            o_points, x_points = self.get_OX_points()\n        if not isinstance(psinorm, Iterable):\n            psinorm = [psinorm]\n        psinorm = sorted(psinorm)\n\n        psi = self.psi()\n        flux_surfaces = []\n        for psi_n in psinorm:\n            if psi_n < PSI_NORM_TOL:\n                psi_n = PSI_NORM_TOL\n            if psi_n > 1 - PSI_NORM_TOL:\n                f_s = ClosedFluxSurface(self.get_LCFS(psi))\n            else:\n                f_s = ClosedFluxSurface(\n                    self.get_flux_surface(\n                        psi_n, psi, o_points=o_points, x_points=x_points\n                    )\n                )\n            flux_surfaces.append(f_s)\n        q = np.array([f_s.safety_factor(self) for f_s in flux_surfaces])\n        if len(q) == 1:\n            q = q[0]\n        return q\n\n    def fRBpol(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Get f = R*Bt at specified values of normalised psi.\n        \"\"\"\n        return self.profiles.fRBpol(psinorm)\n\n    def fvac(self) -> np.ndarray:\n        \"\"\"\n        Get vacuum f = R*Bt.\n        \"\"\"\n        try:\n            return self.profiles.fvac()\n        except AttributeError:  # When loading from eqdsks\n            return self._fvac\n\n    def pprime(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Return p' at given normalised psi\n        \"\"\"\n        return self.profiles.pprime(psinorm)\n\n    def ffprime(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Return ff' at given normalised psi\n        \"\"\"\n        return self.profiles.ffprime(psinorm)\n\n    def pressure(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Returns plasma pressure at specified values of normalised psi\n        \"\"\"\n        return self.profiles.pressure(psinorm)\n\n    def get_flux_surface(\n        self,\n        psi_n: float,\n        psi: Optional[np.ndarray] = None,\n        o_points: Optional[Iterable] = None,\n        x_points: Optional[Iterable] = None,\n    ) -> Coordinates:\n        \"\"\"\n        Get a flux surface Coordinates. NOTE: Continuous surface (bridges grid)\n\n        Parameters\n        ----------\n        psi_n:\n            Normalised flux value of surface\n        psi:\n            Flux map\n\n        Returns\n        -------\n        Flux surface Coordinates\n        \"\"\"\n        if psi is None:\n            psi = self.psi()\n        f = find_flux_surf(\n            self.x, self.z, psi, psi_n, o_points=o_points, x_points=x_points\n        )\n        return Coordinates({\"x\": f[0], \"z\": f[1]})\n\n    def get_LCFS(\n        self, psi: Optional[np.ndarray] = None, psi_n_tol: float = 1e-6\n    ) -> Coordinates:\n        \"\"\"\n        Get the Last Closed FLux Surface (LCFS).\n\n        Parameters\n        ----------\n        psi:\n            The psi field on which to compute the LCFS. Will re-calculate if\n            set to None\n        psi_n_tol:\n            The normalised psi tolerance to use when finding the LCFS\n\n        Returns\n        -------\n        The Coordinates of the LCFS\n        \"\"\"\n        if psi is None:\n            psi = self.psi()\n        o_points, x_points = self.get_OX_points(psi=psi)\n        return find_LCFS_separatrix(\n            self.x, self.z, psi, o_points, x_points, psi_n_tol=psi_n_tol\n        )[0]\n\n    def get_separatrix(\n        self, psi: Optional[np.ndarray] = None, psi_n_tol: float = 1e-6\n    ) -> Union[Coordinates, List[Coordinates]]:\n        \"\"\"\n        Get the plasma separatrix(-ices).\n\n        Parameters\n        ----------\n        psi:\n            The flux array. Will re-calculate if set to None\n        psi_n_tol:\n            The normalised psi tolerance to use when finding the separatrix\n\n        Returns\n        -------\n        The separatrix coordinates (Coordinates for SN, List[Coordinates]] for DN)\n        \"\"\"\n        if psi is None:\n            psi = self.psi()\n        o_points, x_points = self.get_OX_points(psi=psi)\n        return find_LCFS_separatrix(\n            self.x,\n            self.z,\n            psi,\n            o_points,\n            x_points,\n            double_null=self.is_double_null,\n            psi_n_tol=psi_n_tol,\n        )[1]\n\n    def _clear_OX_points(self):  # noqa :N802\n        \"\"\"\n        Speed optimisation for storing OX point searches in a single iteration\n        of the solve. Large grids can cause OX finding to be expensive..\n        \"\"\"\n        self._o_points = None\n        self._x_points = None\n\n    def get_OX_points(\n        self, psi: Optional[np.ndarray] = None, force_update: bool = False\n    ) -> Tuple[Iterable, Iterable]:  # noqa :N802\n        \"\"\"\n        Returns list of [[O-points], [X-points]]\n        \"\"\"\n        if (self._o_points is None and self._x_points is None) or force_update is True:\n            if psi is None:\n                psi = self.psi()\n            self._o_points, self._x_points = find_OX_points(\n                self.x,\n                self.z,\n                psi,\n                limiter=self.limiter,\n            )\n        return self._o_points, self._x_points\n\n    def get_OX_psis(\n        self, psi: Optional[np.ndarray] = None\n    ) -> Tuple[float, float]:  # noqa :N802\n        \"\"\"\n        Returns psi at the.base.O-point and X-point\n        \"\"\"\n        if psi is None:\n            psi = self.psi()\n        o_points, x_points = self.get_OX_points(psi)\n        return o_points[0][2], x_points[0][2]\n\n    def get_midplane(self, x: float, z: float, x_psi: float) -> Tuple[float, float]:\n        \"\"\"\n        Get the position at the midplane for a given psi value.\n\n        Parameters\n        ----------\n        x:\n            Starting x coordinate about which to search for a psi surface\n        z:\n            Starting z coordinate about which to search for a psi surface\n        x_psi:\n            Flux value\n\n        Returns\n        -------\n        xMP:\n            x coordinate of the midplane point with flux value Xpsi\n        zMP:\n            z coordinate of the midplane point with flux value Xpsi\n        \"\"\"\n\n        def psi_err(x_opt, *args):\n            \"\"\"\n            The psi error minimisation objective function.\n            \"\"\"\n            z_opt = args[0]\n            psi = self.psi(x_opt, z_opt)[0]\n            return abs(psi - x_psi)\n\n        res = minimize(\n            psi_err,\n            np.array(x),\n            method=\"Nelder-Mead\",\n            args=(z),\n            options={\"xatol\": 1e-7, \"disp\": False},\n        )\n        return res.x[0], z\n\n    def analyse_core(self, n_points: int = 50, plot: bool = True) -> CoreResults:\n        \"\"\"\n        Analyse the shape and characteristics of the plasma core.\n\n        Parameters\n        ----------\n        n_points:\n            Number of points in normalised psi space to analyse\n\n        Returns\n        -------\n        Result dataclass\n        \"\"\"\n        results = analyse_plasma_core(self, n_points=n_points)\n        if plot:\n            CorePlotter(results)\n        return results\n\n    def analyse_plasma(self) -> Dict[str, float]:\n        \"\"\"\n        Analyse the energetic and magnetic characteristics of the plasma.\n        \"\"\"\n        d = calc_summary(self)\n        f95 = ClosedFluxSurface(self.get_flux_surface(0.95))\n        f100 = ClosedFluxSurface(self.get_LCFS())\n        d[\"q_95\"] = f95.safety_factor(self)\n        if self.is_double_null:\n            d[\"kappa_95\"] = f95.kappa\n            d[\"delta_95\"] = f95.delta\n            d[\"kappa\"] = f100.kappa\n            d[\"delta\"] = f100.delta\n\n        else:\n            d[\"kappa_95\"] = f95.kappa_upper\n            d[\"delta_95\"] = f95.delta_upper\n            d[\"kappa\"] = f100.kappa_upper\n            d[\"delta\"] = f100.delta_upper\n\n        d[\"R_0\"] = f100.major_radius\n        d[\"A\"] = f100.aspect_ratio\n        d[\"a\"] = f100.area\n        # d['dXsep'] = self.calc_dXsep()\n        d[\"Ip\"] = self.profiles.I_p\n        d[\"dx_shaf\"], d[\"dz_shaf\"] = f100.shafranov_shift(self)\n        return d\n\n    def analyse_coils(self) -> Tuple[Dict[str, Any], float, float]:\n        \"\"\"\n        Analyse and summarise the electro-magneto-mechanical characteristics\n        of the equilibrium and coilset.\n        \"\"\"\n        ccoils = self.coilset.get_control_coils()\n        c_names = ccoils.name\n        currents = ccoils.currents\n        fields = self.get_coil_fields()\n        forces = self.get_coil_forces()\n        fz = forces.T[1]\n        fz_cs = fz[self.coilset.n_coils(\"PF\") :]\n        fz_c_stot = sum(fz_cs)\n        fsep = []\n        for j in range(self.coilset.n_coils(\"CS\") - 1):\n            fsep.append(np.sum(fz_cs[j + 1 :]) - np.sum(fz_cs[: j + 1]))\n        fsep = max(fsep)\n        table = {\"I [A]\": currents, \"B [T]\": fields, \"F [N]\": fz}\n        print(\n            tabulate.tabulate(\n                list(table.values()),\n                headers=c_names,\n                floatfmt=\".2f\",\n                showindex=table.keys(),\n            )\n        )\n        return table, fz_c_stot, fsep\n\n    @property\n    def is_double_null(self) -> bool:\n        \"\"\"\n        Whether or not the Equilibrium is a double-null Equilibrium.\n\n        Returns\n        -------\n        Whether or not the Equilibrium is a double-null Equilibrium.\n        \"\"\"\n        _, x_points = self.get_OX_points()\n\n        if len(x_points) < 2:\n            return False\n\n        psi_1 = x_points[0].psi\n        psi_2 = x_points[1].psi\n        return abs(psi_1 - psi_2) < PSI_NORM_TOL\n\n    def plot(\n        self, ax: Optional[plt.Axes] = None, plasma: bool = False, show_ox: bool = True\n    ):\n        \"\"\"\n        Plot the equilibrium magnetic flux surfaces object onto `ax`.\n        \"\"\"\n        return EquilibriumPlotter(self, ax, plasma=plasma, show_ox=show_ox)\n\n    def plot_field(self, ax: Optional[plt.Axes] = None, show_ox: bool = True):\n        \"\"\"\n        Plot the equilibrium field structure onto `ax`.\n        \"\"\"\n        return EquilibriumPlotter(\n            self,\n            ax,\n            plasma=False,\n            show_ox=show_ox,\n            field=True,\n        )\n\n    def plot_core(self):\n        \"\"\"\n        Plot a 1-D section through the magnetic axis.\n        \"\"\"\n        return CorePlotter2(self)",
  "def __init__(self):\n        # Constructors\n        self.x = None\n        self.z = None\n        self.dx = None\n        self.dz = None\n        self._psi_green = None\n        self._bx_green = None\n        self._bz_green = None\n        self.grid = None\n        self.coilset = None\n        self.limiter = None",
  "def set_grid(self, grid: Grid):\n        \"\"\"\n        Sets a Grid object for an Equilibrium, and sets the G-S operator and\n        G-S solver on the grid.\n\n        Parameters\n        ----------\n        grid:\n            The grid upon which to solve the Equilibrium\n        \"\"\"\n        self.grid = grid\n        self.x, self.z = self.grid.x, self.grid.z\n        self.dx, self.dz = self.grid.dx, self.grid.dz",
  "def reset_grid(self, grid: Grid, psi: Optional[np.ndarray] = None):\n        \"\"\"\n        Reset the grid for the MHDState.\n\n        Parameters\n        ----------\n        grid:\n            The grid to set the MHDState on\n        psi:\n            Initial psi array to use\n        \"\"\"\n        self.set_grid(grid)\n        self._set_init_plasma(grid, psi)",
  "def _set_init_plasma(self, grid: Grid, psi: Optional[np.ndarray] = None):\n        zm = 1 - grid.z_max / (grid.z_max - grid.z_min)\n        if psi is None:  # Initial psi guess\n            # Normed 0-1 grid\n            x, z = self.x / grid.x_max, (self.z - grid.z_min) / (grid.z_max - grid.z_min)\n            # Factor has an important effect sometimes... good starting\n            # solutions matter\n            psi = 100 * np.exp(-((x - 0.5) ** 2 + (z - zm) ** 2) / 0.1)\n            apply_boundary(psi, 0)\n\n        self._remap_greens()\n        return psi",
  "def _remap_greens(self):\n        \"\"\"\n        Stores Green's functions arrays in a dictionary of coils. Used upon\n        initialisation and must be called after meshing of coils.\n\n        Notes\n        -----\n        Modifies:\n\n            ._pgreen:\n                Greens function coil mapping for psi\n            ._bxgreen:\n                Greens function coil mapping for Bx\n            .bzgreen:\n                Greens function coil mapping for Bz\n        \"\"\"\n        self._psi_green = self.coilset.psi_response(self.x, self.z)\n        self._bx_green = self.coilset.Bx_response(self.x, self.z)\n        self._bz_green = self.coilset.Bz_response(self.x, self.z)",
  "def get_coil_forces(self) -> np.ndarray:\n        \"\"\"\n        Returns the Fx and Fz force at the centre of the control coils\n\n        Returns\n        -------\n        Fx, Fz array of forces on coils [N]\n\n        Notes\n        -----\n        Will not work for symmetric circuits\n        \"\"\"\n        no_coils = self.coilset.n_coils()\n        plasma = self.plasma\n        non_zero_current = np.where(self.coilset.current != 0)[0]\n        response = self.coilset.control_F(self.coilset)\n        background = (\n            self.coilset.F(plasma)[non_zero_current]\n            / self.coilset.current[non_zero_current]\n        )\n\n        forces = np.zeros((no_coils, 2))\n        currents = self.coilset.get_control_coils().current\n        forces[:, 0] = currents * (response[:, :, 0] @ currents + background[:, 0])\n        forces[:, 1] = currents * (response[:, :, 1] @ currents + background[:, 1])\n\n        return forces",
  "def get_coil_fields(self) -> np.ndarray:\n        \"\"\"\n        Returns the poloidal magnetic fields on the control coils\n        (approximate peak at the middle inner radius of the coil)\n\n        Returns\n        -------\n        The Bp array of fields on coils [T]\n        \"\"\"\n        return self.Bp(self.coilset.x - self.coilset.dx, self.coilset.z)",
  "def _get_eqdsk(\n        cls, filename: str, force_symmetry: bool = False\n    ) -> Tuple[EQDSKInterface, np.ndarray, CoilSet, Grid, Optional[Limiter]]:\n        \"\"\"\n        Get eqdsk data from file for read in\n\n        Parameters\n        ----------\n        filename:\n            Filename\n        force_symmetry:\n            Whether or not to force symmetrisation in the CoilSet\n\n        Returns\n        -------\n        e:\n            Instance if EQDSKInterface with the EQDSK file read in\n        psi:\n            psi array\n        coilset:\n            Coilset from eqdsk\n        grid:\n            Grid from eqdsk\n        limiter:\n            Limiter instance if any limiters are in file\n        \"\"\"\n        e = EQDSKInterface.from_file(filename)\n        if \"equilibria\" in e.name:\n            psi = e.psi\n        elif \"SCENE\" in e.name and not isinstance(cls, Breakdown):\n            psi = e.psi\n            e.dxc = e.dxc / 2\n            e.dzc = e.dzc / 2\n        elif \"fiesta\" in e.name.lower():\n            psi = e.psi\n        else:  # CREATE\n            psi = e.psi / (2 * np.pi)  # V.s as opposed to V.s/rad\n            e.dxc = e.dxc / 2\n            e.dzc = e.dzc / 2\n            e.cplasma = abs(e.cplasma)\n\n        coilset = CoilSet.from_group_vecs(e)\n        if force_symmetry:\n            coilset = symmetrise_coilset(coilset)\n\n        grid = Grid.from_eqdsk(e)\n        if e.nlim == 0:\n            limiter = None\n        elif e.nlim < 5:\n            limiter = Limiter(e.xlim, e.zlim)\n        else:\n            limiter = None  # CREATE..\n\n        return e, psi, coilset, grid, limiter",
  "def to_eqdsk(\n        self,\n        data: Dict[str, Any],\n        filename: str,\n        header: str = \"bluemira_equilibria\",\n        directory: Optional[str] = None,\n        filetype: str = \"json\",\n        **kwargs,\n    ):\n        \"\"\"\n        Writes the Equilibrium Object to an eqdsk file\n        \"\"\"\n        data[\"name\"] = \"_\".join([filename, header])\n\n        if not filename.endswith(f\".{filetype}\"):\n            filename += f\".{filetype}\"\n\n        if directory is None:\n            try:\n                filename = os.sep.join(\n                    [get_bluemira_path(\"eqdsk/equilibria\", subfolder=\"data\"), filename]\n                )\n            except ValueError as error:\n                raise ValueError(f\"Unable to find default data directory: {error}\")\n        else:\n            filename = os.sep.join([directory, filename])\n\n        self.filename = filename  # Convenient\n        eqdsk = EQDSKInterface(**data)\n        eqdsk.write(filename, format=filetype, **kwargs)",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        grid: Grid,\n        psi: Optional[np.ndarray] = None,\n        filename: Optional[str] = None,\n        **kwargs,\n    ):\n        super().__init__()\n        self.coilset = coilset\n        self.set_grid(grid)\n        self._set_init_plasma(grid, psi)\n        self.plasma = NoPlasmaCoil(grid)\n        self.limiter = kwargs.get(\"limiter\", None)\n\n        # Set default breakdown point to grid centre\n        x_mid = grid.x_min + 0.5 * (grid.x_max + grid.x_min)\n        self.breakdown_point = kwargs.get(\"breakdown_point\", (x_mid, 0))\n        self.filename = filename",
  "def from_eqdsk(cls, filename: str, force_symmetry: bool):\n        \"\"\"\n        Initialises a Breakdown Object from an eqdsk file. Note that this\n        will involve recalculation of the magnetic flux.\n\n        Parameters\n        ----------\n        filename:\n            Filename\n        force_symmetry:\n            Whether or not to force symmetrisation in the CoilSet\n        \"\"\"\n        cls._eqdsk, psi, coilset, grid, limiter = super()._get_eqdsk(\n            filename, force_symmetry=force_symmetry\n        )\n        return cls(coilset, grid, limiter=limiter, psi=psi, filename=filename)",
  "def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Creates a dictionary for a Breakdown object\n\n        Returns\n        -------\n        A dictionary for the Breakdown object\n        \"\"\"\n        xc, zc, dxc, dzc, currents = self.coilset.to_group_vecs()\n        d = {\n            \"nx\": self.grid.nx,\n            \"nz\": self.grid.nz,\n            \"xdim\": self.grid.x_size,\n            \"zdim\": self.grid.z_size,\n            \"x\": self.grid.x_1d,\n            \"z\": self.grid.z_1d,\n            \"xgrid1\": self.grid.x_min,\n            \"zmid\": self.grid.z_mid,\n            \"cplasma\": 0.0,\n            \"psi\": self.psi(),\n            \"Bx\": self.Bx(),\n            \"Bz\": self.Bz(),\n            \"Bp\": self.Bp(),\n            \"ncoil\": self.coilset.n_coils(),\n            \"xc\": xc,\n            \"zc\": zc,\n            \"dxc\": dxc,\n            \"dzc\": dzc,\n            \"Ic\": currents,\n        }\n        return d",
  "def to_eqdsk(\n        self,\n        filename: str,\n        header: str = \"bluemira_equilibria\",\n        directory: Optional[str] = None,\n        filetype: str = \"json\",\n        **kwargs,\n    ) -> EQDSKInterface:\n        \"\"\"\n        Writes the Equilibrium Object to an eqdsk file\n        \"\"\"\n        data = self.to_dict()\n        data[\"xcentre\"] = 0\n        data[\"bcentre\"] = 0\n        super().to_eqdsk(data, filename, header, directory, filetype, **kwargs)",
  "def set_breakdown_point(self, x_bd: float, z_bd: float):\n        \"\"\"\n        Set the point at which the centre of the breakdown region is defined.\n\n        Parameters\n        ----------\n        x_bd:\n            The x coordinate of the centre of the breakdown region\n        z_bd:\n            The z coordinate of the centre of the breakdown region\n        \"\"\"\n        self.breakdown_point = (x_bd, z_bd)",
  "def breakdown_psi(self) -> float:\n        \"\"\"\n        The poloidal magnetic flux at the centre of the breakdown region.\n\n        Returns\n        -------\n        The minimum poloidal magnetic flux at the edge of the breakdown\n        region [V.s/rad]\n        \"\"\"\n        return self.psi(*self.breakdown_point)",
  "def Bx(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Total radial magnetic field at point (x, z) from coils\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bx. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return Bx. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Radial magnetic field at x, z\n        \"\"\"\n        if x is None and z is None:\n            return self.coilset._Bx_greens(self._bx_green)\n\n        return self.coilset.Bx(x, z)",
  "def Bz(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Total vertical magnetic field at point (x, z) from coils\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bz. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return Bz. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Vertical magnetic field at x, z\n        \"\"\"\n        if x is None and z is None:\n            return self.coilset._Bz_greens(self._bz_green)\n\n        return self.coilset.Bz(x, z)",
  "def Bp(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Total poloidal magnetic field at point (x, z) from coils\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bp. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return Bp. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Poloidal magnetic field at x, z\n        \"\"\"\n        if x is None and z is None:\n            return np.hypot(\n                self.coilset._Bx_greens(self._bx_green),\n                self.coilset._Bz_greens(self._bz_green),\n            )\n\n        return np.hypot(self.Bx(x, z), self.Bz(x, z))",
  "def psi(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Returns the poloidal magnetic flux, either for the whole grid, or for\n        specified x, z coordinates, including contributions from the coilset.\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return psi. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return psi. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Poloidal magnetic flux at x, z\n        \"\"\"\n        if x is None and z is None:\n            return self.coilset._psi_greens(self._psi_green)\n\n        return self.coilset.psi(x, z)",
  "def get_coil_Bp(self) -> np.ndarray:\n        \"\"\"\n        Returns the poloidal field within each coil\n        \"\"\"\n        b = np.zeros(self.coilset.n_coils())\n        dx_mask = np.zeros_like(self.coilset.dx)\n        dx_mask[self.coilset.dx > 0] = True\n        mask = in_zone(\n            self.x[dx_mask],\n            self.z[dx_mask],\n            np.array([self.x[dx_mask], self.z[dx_mask]]).T,\n        )\n        b[dx_mask] = np.max(self.Bp()[dx_mask] * mask[dx_mask], axis=-1)\n        b[~dx_mask] = np.max(self.Bp(self.x, self.z)[~dx_mask] * mask[~dx_mask], axis=-1)\n        return b",
  "def plot(self, ax: Optional[plt.Axes] = None, Bp: bool = False):\n        \"\"\"\n        Plots the equilibrium object onto `ax`\n        \"\"\"\n        return BreakdownPlotter(self, ax, Bp=Bp)",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        grid: Grid,\n        profiles: Profile,\n        force_symmetry: bool = False,\n        vcontrol: Optional[str] = None,\n        limiter: Optional[Limiter] = None,\n        psi: Optional[np.ndarray] = None,\n        jtor: Optional[np.ndarray] = None,\n        filename: Optional[str] = None,\n    ):\n        super().__init__()\n        # Constructors\n        self._jtor = jtor\n        self.profiles = profiles\n        self._o_points = None\n        self._x_points = None\n        self._solver = None\n        self._eqdsk = None\n\n        self._li_flag = False\n        if isinstance(profiles, BetaLiIpProfile):\n            self._li_flag = True\n            self._li = profiles._l_i_target  # target plasma normalised inductance\n            self._li_iter = 0  # li iteration count\n            self._li_temp = None\n\n        self.plasma = None\n\n        self.force_symmetry = force_symmetry\n        self.controller = None\n        self.coilset = coilset\n\n        self.set_grid(grid)\n        self._set_init_plasma(grid, psi, jtor)\n        self.boundary = FreeBoundary(self.grid)\n        self.set_vcontrol(vcontrol)\n        self.limiter = limiter\n        self.filename = filename\n\n        self._kwargs = {\"vcontrol\": vcontrol}",
  "def from_eqdsk(cls, filename: str, force_symmetry: bool = False):\n        \"\"\"\n        Initialises an Equilibrium Object from an eqdsk file. Note that this\n        will involve recalculation of the magnetic flux. Because of the nature\n        of the (non-linear) Grad-Shafranov equation, values of psi may differ\n        from those stored in eqdsk.\n\n        NOTE: Need to solve again with some profiles in order to refind...\n\n        Parameters\n        ----------\n        filename:\n            Filename\n        force_symmetry:\n            Whether or not to force symmetrisation in the CoilSet\n        \"\"\"\n        e, psi, coilset, grid, limiter = super()._get_eqdsk(\n            filename, force_symmetry=force_symmetry\n        )\n\n        profiles = CustomProfile.from_eqdsk(filename)\n\n        cls._eqdsk = e\n\n        o_points, x_points = find_OX_points(grid.x, grid.z, psi, limiter=limiter)\n        jtor = profiles.jtor(grid.x, grid.z, psi, o_points=o_points, x_points=x_points)\n\n        return cls(\n            coilset,\n            grid,\n            profiles=profiles,\n            vcontrol=None,\n            limiter=limiter,\n            psi=psi,\n            jtor=jtor,\n            filename=filename,\n        )",
  "def to_dict(self, qpsi_calcmode: int = 0) -> Dict[str, Any]:\n        \"\"\"\n        Creates dictionary for equilibrium object, in preparation for saving\n        to a file format\n\n        Parameters\n        ----------\n        qpsi_calcmode:\n          don't calculate: 0, calculate qpsi: 1, fill with zeros: 2\n\n        Returns\n        -------\n        A dictionary of the Equilibrium object values, sufficient for EQDSK\n        \"\"\"\n        qpsi_calcmode = QpsiCalcMode(qpsi_calcmode)\n\n        psi = self.psi()\n        n_x, n_z = psi.shape\n        opoints, xpoints = self.get_OX_points(psi)\n        opoint = opoints[0]  # Primary points\n        if xpoints:\n            # It is possible to have an EQDSK with no X-point...\n            psi_bndry = xpoints[0][2]\n        else:\n            psi_bndry = np.amin(psi)\n        psinorm = np.linspace(0, 1, n_x)\n\n        if qpsi_calcmode is QpsiCalcMode.CALC:\n            # This is too damn slow..\n            q = self.q(psinorm, o_points=opoints, x_points=xpoints)\n        elif qpsi_calcmode is QpsiCalcMode.ZEROS:\n            q = np.zeros(n_x)\n\n        lcfs = self.get_LCFS(psi)\n        nbdry = lcfs.xz.shape[1]\n        x_c, z_c, dxc, dzc, currents = self.coilset.to_group_vecs()\n\n        result = {\n            \"nx\": n_x,\n            \"nz\": n_z,\n            \"xdim\": self.grid.x_size,\n            \"zdim\": self.grid.z_size,\n            \"x\": self.grid.x_1d,\n            \"z\": self.grid.z_1d,\n            \"xcentre\": self.profiles.R_0,\n            \"bcentre\": self.profiles._B_0,\n            \"xgrid1\": self.grid.x_min,\n            \"zmid\": self.grid.z_mid,\n            \"xmag\": opoint[0],\n            \"zmag\": opoint[1],\n            \"psimag\": opoint[2],\n            \"psibdry\": psi_bndry,\n            \"cplasma\": self.profiles.I_p,\n            \"psi\": psi,\n            \"fpol\": self.fRBpol(psinorm),\n            \"ffprime\": self.ffprime(psinorm),\n            \"pprime\": self.pprime(psinorm),\n            \"pressure\": self.pressure(psinorm),\n            \"psinorm\": psinorm,\n            \"nbdry\": nbdry,\n            \"xbdry\": lcfs.x,\n            \"zbdry\": lcfs.z,\n            \"ncoil\": self.coilset.n_coils(),\n            \"xc\": x_c,\n            \"zc\": z_c,\n            \"dxc\": dxc,\n            \"dzc\": dzc,\n            \"Ic\": currents,\n        }\n        if qpsi_calcmode is not QpsiCalcMode.NO_CALC:\n            result[\"qpsi\"] = q\n\n        if self.limiter is None:  # Needed for eqdsk file format\n            result[\"nlim\"] = 0\n            result[\"xlim\"] = np.ndarray([])\n            result[\"zlim\"] = np.ndarray([])\n        else:\n            result[\"nlim\"] = len(self.limiter)\n            result[\"xlim\"] = self.limiter.x\n            result[\"zlim\"] = self.limiter.z\n        return result",
  "def to_eqdsk(\n        self,\n        filename: str,\n        header: str = \"BP_equilibria\",\n        directory: Optional[str] = None,\n        filetype: str = \"json\",\n        qpsi_calcmode: int = 0,\n        **kwargs,\n    ):\n        \"\"\"\n        Writes the Equilibrium Object to an eqdsk file\n        \"\"\"\n        if \"eqdsk\" in filetype and qpsi_calcmode == 0:\n            qpsi_calcmode = 2\n\n        super().to_eqdsk(\n            self.to_dict(qpsi_calcmode),\n            filename,\n            header,\n            directory,\n            filetype,\n            **kwargs,\n        )",
  "def __getstate__(self):\n        \"\"\"\n        Get the state of the Equilibrium object. Used in pickling.\n        \"\"\"\n        d = dict(self.__dict__)\n        d.pop(\"_solver\", None)\n        return d",
  "def __setstate__(self, d):\n        \"\"\"\n        Get the state of the Equilibrium object. Used in unpickling.\n        \"\"\"\n        self.__dict__ = d\n        if \"grid\" in d:\n            self.set_grid(self.grid)",
  "def set_grid(self, grid: Grid):\n        \"\"\"\n        Sets a Grid object for an Equilibrium, and sets the G-S operator and\n        G-S solver on the grid.\n\n        Parameters\n        ----------\n        grid:\n            The grid upon which to solve the Equilibrium\n        \"\"\"\n        super().set_grid(grid)\n\n        self._solver = GSSolver(grid, force_symmetry=self.force_symmetry)",
  "def reset_grid(self, grid: Grid, **kwargs):\n        \"\"\"\n        Yeah, yeah...\n        \"\"\"\n        super().reset_grid(grid, **kwargs)\n        vcontrol = kwargs.get(\"vcontrol\", self._kwargs[\"vcontrol\"])\n        self.set_vcontrol(vcontrol)",
  "def _set_init_plasma(\n        self,\n        grid: Grid,\n        psi: Optional[np.ndarray] = None,\n        j_tor: Optional[np.ndarray] = None,\n    ):\n        psi = super()._set_init_plasma(grid, psi)\n\n        # This is necessary when loading an equilibrium from an EQDSK file (we\n        # hide the coils to get the plasma psi)\n        psi -= self.coilset.psi(self.x, self.z)\n        self._update_plasma(psi, j_tor)",
  "def set_vcontrol(self, vcontrol: Optional[str] = None):\n        \"\"\"\n        Sets the vertical position controller\n\n        Parameters\n        ----------\n        vcontrol:\n            Vertical control strategy\n        \"\"\"\n        if vcontrol == \"virtual\":\n            self.controller = VirtualController(self, gz=2.2)\n        elif vcontrol == \"feedback\":\n            raise NotImplementedError\n        elif vcontrol is None:\n            self.controller = DummyController(self.plasma.psi())\n        else:\n            raise ValueError(\n                \"Please select a numerical stabilisation strategy\"\n                ' from: 1) \"virtual\" \\n 2) \"feedback\" 3) None.'\n            )",
  "def solve(self, jtor: Optional[np.ndarray] = None, psi: Optional[np.ndarray] = None):\n        \"\"\"\n        Re-calculates the plasma equilibrium given new profiles\n\n        Linear Grad-Shafranov solve\n\n        Parameters\n        ----------\n        jtor:\n            The toroidal current density on the finite difference grid [A/m^2]\n        psi:\n            The poloidal magnetic flux on the finite difference grid [V.s/rad]\n\n        Note\n        ----\n        Modifies the following in-place:\n            .plasma_psi\n            .psi_func\n            ._I_p\n            ._Jtor\n        \"\"\"\n        self._clear_OX_points()\n\n        if jtor is None:\n            if psi is None:\n                psi = self.psi()\n            o_points, x_points = self.get_OX_points(psi=psi, force_update=True)\n\n            if not o_points:\n                raise EquilibriaError(\"No O-point found in equilibrium.\")\n            jtor = self.profiles.jtor(self.x, self.z, psi, o_points, x_points)\n\n        plasma_psi = self.plasma.psi()\n        self.boundary(plasma_psi, jtor)\n        rhs = -MU_0 * self.x * jtor  # RHS of GS equation\n        apply_boundary(rhs, plasma_psi)\n\n        plasma_psi = self._solver(rhs)\n        self._update_plasma(plasma_psi, jtor)\n\n        self._jtor = jtor\n        self._plasmacoil = None",
  "def solve_li(\n        self, jtor: Optional[np.ndarray] = None, psi: Optional[np.ndarray] = None\n    ):\n        \"\"\"\n        Optimises profiles to match input li\n        Re-calculates the plasma equilibrium given new profiles\n\n        Linear Grad-Shafranov solve\n\n        Parameters\n        ----------\n        jtor:\n            The 2-D array toroidal current at each (x, z) point (optional)\n        psi:\n            The 2-D array of poloidal magnetic flux at each (x, z) point (optional)\n\n        Note\n        ----\n        Modifies the following in-place:\n\n            .plasma_psi\n            .psi_func\n            ._I_p\n            ._Jtor\n        \"\"\"\n        if not self._li_flag:\n            raise EquilibriaError(\"Cannot use solve_li without the BetaLiIpProfile.\")\n        self._clear_OX_points()\n        self._li_iter = 0\n        if psi is None:\n            psi = self.psi()\n        # Speed optimisations\n        o_points, x_points = self.get_OX_points(psi=psi, force_update=True)\n        mask = in_plasma(self.x, self.z, psi, o_points=o_points, x_points=x_points)\n        print(\"\")  # flusher\n\n        def minimise_dli(x):\n            \"\"\"\n            The minimisation function to obtain the correct l_i\n            \"\"\"\n            self.profiles.shape.adjust_parameters(x)\n            jtor_opt = self.profiles.jtor(self.x, self.z, psi, o_points, x_points)\n            plasma_psi = self.plasma.psi()\n            self.boundary(plasma_psi, jtor_opt)\n            rhs = -MU_0 * self.x * jtor_opt  # RHS of GS equation\n            apply_boundary(rhs, plasma_psi)\n\n            plasma_psi = self._solver(rhs)\n            self._update_plasma(plasma_psi, jtor_opt)\n            li = calc_li3minargs(\n                self.x,\n                self.z,\n                self.psi(),\n                self.Bp(),\n                self.profiles.R_0,\n                self.profiles.I_p,\n                self.dx,\n                self.dz,\n                mask=mask,\n            )\n            self._li_temp = li\n            self._jtor = jtor_opt\n            if abs_rel_difference(self._li_temp, self._li) <= self.profiles._l_i_rel_tol:\n                # Scipy's callback argument doesn't seem to work, so we do this\n                # instead...\n                raise StopIteration\n            bluemira_print_flush(f\"EQUILIBRIA l_i iter {self._li_iter}: l_i: {li:.3f}\")\n            self._li_iter += 1\n            return abs(self._li - li)\n\n        try:  # Kein physischer Grund daf\u00fcr, ist aber n\u00fctzlich\n            bounds = [[-1, 3] for _ in range(len(self.profiles.shape.coeffs))]\n            res = minimize(\n                minimise_dli,\n                self.profiles.shape.coeffs,\n                method=\"SLSQP\",\n                bounds=bounds,\n                options={\"maxiter\": 30, \"eps\": 1e-4},\n            )\n            alpha_star = process_scipy_result(res)\n            self.profiles.shape.adjust_parameters(alpha_star)\n\n        except StopIteration:\n            pass",
  "def _update_plasma(self, plasma_psi: np.ndarray, j_tor: np.ndarray):\n        \"\"\"\n        Update the plasma\n        \"\"\"\n        self.plasma = PlasmaCoil(plasma_psi, j_tor, self.grid)",
  "def _int_dxdz(self, func: np.ndarray) -> float:\n        \"\"\"\n        Returns the double-integral of a function over the space\n\n        \\t:math:`\\\\int_Z\\\\int_X f(x, z) dXdZ`\n\n        Parameters\n        ----------\n        func:\n            a 2-D function map\n\n        Returns\n        -------\n        The integral value of the field in 2-D\n        \"\"\"\n        return integrate_dx_dz(func, self.dx, self.dz)",
  "def effective_centre(self) -> Tuple[float, float]:\n        \"\"\"\n        Jeon calculation for the effective current centre of the plasma\n\n        \\t:math:`X_{cur}^{2}=\\\\dfrac{1}{I_{p}}\\\\int X^{2}J_{\\\\phi,pl}(X, Z)d{\\\\Omega}_{pl}`\\n\n        \\t:math:`Z_{cur}=\\\\dfrac{1}{I_{p}}\\\\int ZJ_{\\\\phi,pl}(X, Z)d{\\\\Omega}_{pl}`\n\n        Returns\n        -------\n        xcur:\n            The radial position of the effective current centre\n        zcur:\n            The vertical position of the effective current centre\n        \"\"\"  # noqa :W505\n        xcur = np.sqrt(1 / self.profiles.I_p * self._int_dxdz(self.x**2 * self._jtor))\n        zcur = 1 / self.profiles.I_p * self._int_dxdz(self.z * self._jtor)\n        return xcur, zcur",
  "def Bx(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Total radial magnetic field at point (x, z) from coils and plasma\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bx. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return Bx. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Radial magnetic field at x, z\n        \"\"\"\n        if x is None and z is None:\n            return self.plasma.Bx() + self.coilset._Bx_greens(self._bx_green)\n\n        return self.plasma.Bx(x, z) + self.coilset.Bx(x, z)",
  "def Bz(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Total vertical magnetic field at point (x, z) from coils and plasma\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bz. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return Bz. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Vertical magnetic field at x, z\n        \"\"\"\n        if x is None and z is None:\n            return self.plasma.Bz() + self.coilset._Bz_greens(self._bz_green)\n\n        return self.plasma.Bz(x, z) + self.coilset.Bz(x, z)",
  "def Bp(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Total poloidal magnetic field at point (x, z) from coils and plasma\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bp. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return Bp. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Poloidal magnetic field at x, z\n        \"\"\"\n        return np.hypot(self.Bx(x, z), self.Bz(x, z))",
  "def Bt(self, x: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Toroidal magnetic field at point (x, z) from TF coils\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return Bt.\n\n        Returns\n        -------\n        Toroidal magnetic field at x\n        \"\"\"\n        return self.fvac() / x",
  "def psi(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Returns the poloidal magnetic flux, either for the whole grid, or for\n        specified x, z coordinates, including contributions from: plasma,\n        coilset, and vertical stabilisation controller (default None)\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates for which to return psi. If None, returns values\n            at all grid points\n        z:\n            Vertical coordinates for which to return psi. If None, returns values\n            at all grid points\n\n        Returns\n        -------\n        Poloidal magnetic flux at x, z\n        \"\"\"\n        if x is None and z is None:\n            # Defaults to the full psi map (fast)\n            if self._jtor is not None:\n                self.controller.stabilise()\n            return (\n                self.plasma.psi()\n                + self.coilset._psi_greens(self._psi_green)\n                + self.controller.psi()\n            )\n\n        return self.plasma.psi(x, z) + self.coilset.psi(x, z)",
  "def psi_norm(self) -> np.ndarray:\n        \"\"\"\n        2-D x-z normalised poloidal flux map\n        \"\"\"\n        psi = self.psi()\n        return calc_psi_norm(psi, *self.get_OX_psis(psi))",
  "def pressure_map(self) -> np.ndarray:\n        \"\"\"\n        Get plasma pressure map.\n        \"\"\"\n        mask = self._get_core_mask()\n        p = self.pressure(np.clip(self.psi_norm(), 0, 1))\n        return p * mask",
  "def _get_core_mask(self) -> np.ndarray:\n        \"\"\"\n        Get a 2-D masking array for the plasma core.\n        \"\"\"\n        o_points, x_points = self.get_OX_points()\n        return in_plasma(\n            self.x, self.z, self.psi(), o_points=o_points, x_points=x_points\n        )",
  "def q(\n        self,\n        psinorm: Union[float, Iterable[float]],\n        o_points: Optional[Iterable] = None,\n        x_points: Optional[Iterable] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Get the safety factor at given psinorm.\n        \"\"\"\n        if o_points is None or x_points is None:\n            o_points, x_points = self.get_OX_points()\n        if not isinstance(psinorm, Iterable):\n            psinorm = [psinorm]\n        psinorm = sorted(psinorm)\n\n        psi = self.psi()\n        flux_surfaces = []\n        for psi_n in psinorm:\n            if psi_n < PSI_NORM_TOL:\n                psi_n = PSI_NORM_TOL\n            if psi_n > 1 - PSI_NORM_TOL:\n                f_s = ClosedFluxSurface(self.get_LCFS(psi))\n            else:\n                f_s = ClosedFluxSurface(\n                    self.get_flux_surface(\n                        psi_n, psi, o_points=o_points, x_points=x_points\n                    )\n                )\n            flux_surfaces.append(f_s)\n        q = np.array([f_s.safety_factor(self) for f_s in flux_surfaces])\n        if len(q) == 1:\n            q = q[0]\n        return q",
  "def fRBpol(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Get f = R*Bt at specified values of normalised psi.\n        \"\"\"\n        return self.profiles.fRBpol(psinorm)",
  "def fvac(self) -> np.ndarray:\n        \"\"\"\n        Get vacuum f = R*Bt.\n        \"\"\"\n        try:\n            return self.profiles.fvac()\n        except AttributeError:  # When loading from eqdsks\n            return self._fvac",
  "def pprime(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Return p' at given normalised psi\n        \"\"\"\n        return self.profiles.pprime(psinorm)",
  "def ffprime(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Return ff' at given normalised psi\n        \"\"\"\n        return self.profiles.ffprime(psinorm)",
  "def pressure(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Returns plasma pressure at specified values of normalised psi\n        \"\"\"\n        return self.profiles.pressure(psinorm)",
  "def get_flux_surface(\n        self,\n        psi_n: float,\n        psi: Optional[np.ndarray] = None,\n        o_points: Optional[Iterable] = None,\n        x_points: Optional[Iterable] = None,\n    ) -> Coordinates:\n        \"\"\"\n        Get a flux surface Coordinates. NOTE: Continuous surface (bridges grid)\n\n        Parameters\n        ----------\n        psi_n:\n            Normalised flux value of surface\n        psi:\n            Flux map\n\n        Returns\n        -------\n        Flux surface Coordinates\n        \"\"\"\n        if psi is None:\n            psi = self.psi()\n        f = find_flux_surf(\n            self.x, self.z, psi, psi_n, o_points=o_points, x_points=x_points\n        )\n        return Coordinates({\"x\": f[0], \"z\": f[1]})",
  "def get_LCFS(\n        self, psi: Optional[np.ndarray] = None, psi_n_tol: float = 1e-6\n    ) -> Coordinates:\n        \"\"\"\n        Get the Last Closed FLux Surface (LCFS).\n\n        Parameters\n        ----------\n        psi:\n            The psi field on which to compute the LCFS. Will re-calculate if\n            set to None\n        psi_n_tol:\n            The normalised psi tolerance to use when finding the LCFS\n\n        Returns\n        -------\n        The Coordinates of the LCFS\n        \"\"\"\n        if psi is None:\n            psi = self.psi()\n        o_points, x_points = self.get_OX_points(psi=psi)\n        return find_LCFS_separatrix(\n            self.x, self.z, psi, o_points, x_points, psi_n_tol=psi_n_tol\n        )[0]",
  "def get_separatrix(\n        self, psi: Optional[np.ndarray] = None, psi_n_tol: float = 1e-6\n    ) -> Union[Coordinates, List[Coordinates]]:\n        \"\"\"\n        Get the plasma separatrix(-ices).\n\n        Parameters\n        ----------\n        psi:\n            The flux array. Will re-calculate if set to None\n        psi_n_tol:\n            The normalised psi tolerance to use when finding the separatrix\n\n        Returns\n        -------\n        The separatrix coordinates (Coordinates for SN, List[Coordinates]] for DN)\n        \"\"\"\n        if psi is None:\n            psi = self.psi()\n        o_points, x_points = self.get_OX_points(psi=psi)\n        return find_LCFS_separatrix(\n            self.x,\n            self.z,\n            psi,\n            o_points,\n            x_points,\n            double_null=self.is_double_null,\n            psi_n_tol=psi_n_tol,\n        )[1]",
  "def _clear_OX_points(self):  # noqa :N802\n        \"\"\"\n        Speed optimisation for storing OX point searches in a single iteration\n        of the solve. Large grids can cause OX finding to be expensive..\n        \"\"\"\n        self._o_points = None\n        self._x_points = None",
  "def get_OX_points(\n        self, psi: Optional[np.ndarray] = None, force_update: bool = False\n    ) -> Tuple[Iterable, Iterable]:  # noqa :N802\n        \"\"\"\n        Returns list of [[O-points], [X-points]]\n        \"\"\"\n        if (self._o_points is None and self._x_points is None) or force_update is True:\n            if psi is None:\n                psi = self.psi()\n            self._o_points, self._x_points = find_OX_points(\n                self.x,\n                self.z,\n                psi,\n                limiter=self.limiter,\n            )\n        return self._o_points, self._x_points",
  "def get_OX_psis(\n        self, psi: Optional[np.ndarray] = None\n    ) -> Tuple[float, float]:  # noqa :N802\n        \"\"\"\n        Returns psi at the.base.O-point and X-point\n        \"\"\"\n        if psi is None:\n            psi = self.psi()\n        o_points, x_points = self.get_OX_points(psi)\n        return o_points[0][2], x_points[0][2]",
  "def get_midplane(self, x: float, z: float, x_psi: float) -> Tuple[float, float]:\n        \"\"\"\n        Get the position at the midplane for a given psi value.\n\n        Parameters\n        ----------\n        x:\n            Starting x coordinate about which to search for a psi surface\n        z:\n            Starting z coordinate about which to search for a psi surface\n        x_psi:\n            Flux value\n\n        Returns\n        -------\n        xMP:\n            x coordinate of the midplane point with flux value Xpsi\n        zMP:\n            z coordinate of the midplane point with flux value Xpsi\n        \"\"\"\n\n        def psi_err(x_opt, *args):\n            \"\"\"\n            The psi error minimisation objective function.\n            \"\"\"\n            z_opt = args[0]\n            psi = self.psi(x_opt, z_opt)[0]\n            return abs(psi - x_psi)\n\n        res = minimize(\n            psi_err,\n            np.array(x),\n            method=\"Nelder-Mead\",\n            args=(z),\n            options={\"xatol\": 1e-7, \"disp\": False},\n        )\n        return res.x[0], z",
  "def analyse_core(self, n_points: int = 50, plot: bool = True) -> CoreResults:\n        \"\"\"\n        Analyse the shape and characteristics of the plasma core.\n\n        Parameters\n        ----------\n        n_points:\n            Number of points in normalised psi space to analyse\n\n        Returns\n        -------\n        Result dataclass\n        \"\"\"\n        results = analyse_plasma_core(self, n_points=n_points)\n        if plot:\n            CorePlotter(results)\n        return results",
  "def analyse_plasma(self) -> Dict[str, float]:\n        \"\"\"\n        Analyse the energetic and magnetic characteristics of the plasma.\n        \"\"\"\n        d = calc_summary(self)\n        f95 = ClosedFluxSurface(self.get_flux_surface(0.95))\n        f100 = ClosedFluxSurface(self.get_LCFS())\n        d[\"q_95\"] = f95.safety_factor(self)\n        if self.is_double_null:\n            d[\"kappa_95\"] = f95.kappa\n            d[\"delta_95\"] = f95.delta\n            d[\"kappa\"] = f100.kappa\n            d[\"delta\"] = f100.delta\n\n        else:\n            d[\"kappa_95\"] = f95.kappa_upper\n            d[\"delta_95\"] = f95.delta_upper\n            d[\"kappa\"] = f100.kappa_upper\n            d[\"delta\"] = f100.delta_upper\n\n        d[\"R_0\"] = f100.major_radius\n        d[\"A\"] = f100.aspect_ratio\n        d[\"a\"] = f100.area\n        # d['dXsep'] = self.calc_dXsep()\n        d[\"Ip\"] = self.profiles.I_p\n        d[\"dx_shaf\"], d[\"dz_shaf\"] = f100.shafranov_shift(self)\n        return d",
  "def analyse_coils(self) -> Tuple[Dict[str, Any], float, float]:\n        \"\"\"\n        Analyse and summarise the electro-magneto-mechanical characteristics\n        of the equilibrium and coilset.\n        \"\"\"\n        ccoils = self.coilset.get_control_coils()\n        c_names = ccoils.name\n        currents = ccoils.currents\n        fields = self.get_coil_fields()\n        forces = self.get_coil_forces()\n        fz = forces.T[1]\n        fz_cs = fz[self.coilset.n_coils(\"PF\") :]\n        fz_c_stot = sum(fz_cs)\n        fsep = []\n        for j in range(self.coilset.n_coils(\"CS\") - 1):\n            fsep.append(np.sum(fz_cs[j + 1 :]) - np.sum(fz_cs[: j + 1]))\n        fsep = max(fsep)\n        table = {\"I [A]\": currents, \"B [T]\": fields, \"F [N]\": fz}\n        print(\n            tabulate.tabulate(\n                list(table.values()),\n                headers=c_names,\n                floatfmt=\".2f\",\n                showindex=table.keys(),\n            )\n        )\n        return table, fz_c_stot, fsep",
  "def is_double_null(self) -> bool:\n        \"\"\"\n        Whether or not the Equilibrium is a double-null Equilibrium.\n\n        Returns\n        -------\n        Whether or not the Equilibrium is a double-null Equilibrium.\n        \"\"\"\n        _, x_points = self.get_OX_points()\n\n        if len(x_points) < 2:\n            return False\n\n        psi_1 = x_points[0].psi\n        psi_2 = x_points[1].psi\n        return abs(psi_1 - psi_2) < PSI_NORM_TOL",
  "def plot(\n        self, ax: Optional[plt.Axes] = None, plasma: bool = False, show_ox: bool = True\n    ):\n        \"\"\"\n        Plot the equilibrium magnetic flux surfaces object onto `ax`.\n        \"\"\"\n        return EquilibriumPlotter(self, ax, plasma=plasma, show_ox=show_ox)",
  "def plot_field(self, ax: Optional[plt.Axes] = None, show_ox: bool = True):\n        \"\"\"\n        Plot the equilibrium field structure onto `ax`.\n        \"\"\"\n        return EquilibriumPlotter(\n            self,\n            ax,\n            plasma=False,\n            show_ox=show_ox,\n            field=True,\n        )",
  "def plot_core(self):\n        \"\"\"\n        Plot a 1-D section through the magnetic axis.\n        \"\"\"\n        return CorePlotter2(self)",
  "def minimise_dli(x):\n            \"\"\"\n            The minimisation function to obtain the correct l_i\n            \"\"\"\n            self.profiles.shape.adjust_parameters(x)\n            jtor_opt = self.profiles.jtor(self.x, self.z, psi, o_points, x_points)\n            plasma_psi = self.plasma.psi()\n            self.boundary(plasma_psi, jtor_opt)\n            rhs = -MU_0 * self.x * jtor_opt  # RHS of GS equation\n            apply_boundary(rhs, plasma_psi)\n\n            plasma_psi = self._solver(rhs)\n            self._update_plasma(plasma_psi, jtor_opt)\n            li = calc_li3minargs(\n                self.x,\n                self.z,\n                self.psi(),\n                self.Bp(),\n                self.profiles.R_0,\n                self.profiles.I_p,\n                self.dx,\n                self.dz,\n                mask=mask,\n            )\n            self._li_temp = li\n            self._jtor = jtor_opt\n            if abs_rel_difference(self._li_temp, self._li) <= self.profiles._l_i_rel_tol:\n                # Scipy's callback argument doesn't seem to work, so we do this\n                # instead...\n                raise StopIteration\n            bluemira_print_flush(f\"EQUILIBRIA l_i iter {self._li_iter}: l_i: {li:.3f}\")\n            self._li_iter += 1\n            return abs(self._li - li)",
  "def psi_err(x_opt, *args):\n            \"\"\"\n            The psi error minimisation objective function.\n            \"\"\"\n            z_opt = args[0]\n            psi = self.psi(x_opt, z_opt)[0]\n            return abs(psi - x_psi)",
  "def _flux_surface_dl(x, z, dx, dz, Bp, Bt):\n    Bp = 0.5 * (Bp[1:] + Bp[:-1])\n    Bt = Bt[:-1] * x[:-1] / (x[:-1] + 0.5 * dx)\n    B_ratio = Bt / Bp\n    return np.sqrt(1 + B_ratio**2) * np.hypot(dx, dz)",
  "class FluxSurface:\n    \"\"\"\n    Flux surface base class.\n\n    Parameters\n    ----------\n    geometry:\n        Flux surface geometry object\n    \"\"\"\n\n    __slots__ = \"coords\"\n\n    def __init__(self, geometry: Coordinates):\n        self.coords = geometry\n\n    @property\n    def x_start(self) -> float:\n        \"\"\"\n        Start radial coordinate of the FluxSurface.\n        \"\"\"\n        return self.coords.x[0]\n\n    @property\n    def z_start(self) -> float:\n        \"\"\"\n        Start vertical coordinate of the FluxSurface.\n        \"\"\"\n        return self.coords.z[0]\n\n    @property\n    def x_end(self) -> float:\n        \"\"\"\n        End radial coordinate of the FluxSurface.\n        \"\"\"\n        return self.coords.x[-1]\n\n    @property\n    def z_end(self) -> float:\n        \"\"\"\n        End vertical coordinate of the FluxSurface.\n        \"\"\"\n        return self.coords.z[-1]\n\n    def _dl(self, eq):\n        x, z = self.coords.x, self.coords.z\n        Bp = eq.Bp(x, z)\n        Bt = eq.Bt(x)\n        return _flux_surface_dl(x, z, np.diff(x), np.diff(z), Bp, Bt)\n\n    def connection_length(self, eq: Equilibrium) -> float:\n        \"\"\"\n        Calculate the parallel connection length along a field line (i.e. flux surface).\n\n        Parameters\n        ----------\n        eq:\n            Equilibrium from which the FluxSurface was extracted\n\n        Returns\n        -------\n        Connection length from the start of the flux surface to the end of the flux\n        surface\n        \"\"\"\n        return np.sum(self._dl(eq))\n\n    def plot(self, ax: Optional[plt.Axes] = None, **kwargs):\n        \"\"\"\n        Plot the FluxSurface.\n        \"\"\"\n        if ax is None:\n            ax = plt.gca()\n\n        kwargs[\"linewidth\"] = kwargs.get(\"linewidth\", 0.05)\n        kwargs[\"color\"] = kwargs.get(\"color\", \"r\")\n\n        self.coords.plot(ax, **kwargs)\n\n    def copy(self):\n        \"\"\"\n        Make a deep copy of the FluxSurface.\n        \"\"\"\n        return deepcopy(self)",
  "class ClosedFluxSurface(FluxSurface):\n    \"\"\"\n    Utility class for closed flux surfaces.\n    \"\"\"\n\n    __slots__ = (\"_p1\", \"_p2\", \"_p3\", \"_p4\", \"_z_centre\")\n\n    def __init__(self, geometry: Coordinates):\n        if not geometry.closed:\n            raise FluxSurfaceError(\n                \"Cannot make a ClosedFluxSurface from an open geometry.\"\n            )\n        super().__init__(geometry)\n        i_p1 = np.argmax(self.coords.x)\n        i_p2 = np.argmax(self.coords.z)\n        i_p3 = np.argmin(self.coords.x)\n        i_p4 = np.argmin(self.coords.z)\n        self._p1 = (self.coords.x[i_p1], self.coords.z[i_p1])\n        self._p2 = (self.coords.x[i_p2], self.coords.z[i_p2])\n        self._p3 = (self.coords.x[i_p3], self.coords.z[i_p3])\n        self._p4 = (self.coords.x[i_p4], self.coords.z[i_p4])\n\n        # Still debatable what convention to follow...\n        self._z_centre = 0.5 * (self.coords.z[i_p1] + self.coords.z[i_p3])\n\n    @property\n    @lru_cache(1)\n    def major_radius(self) -> float:\n        \"\"\"\n        Major radius of the ClosedFluxSurface.\n        \"\"\"\n        return np.min(self.coords.x) + self.minor_radius\n\n    @property\n    @lru_cache(1)\n    def minor_radius(self) -> float:\n        \"\"\"\n        Minor radius of the ClosedFluxSurface.\n        \"\"\"\n        return 0.5 * (np.max(self.coords.x) - np.min(self.coords.x))\n\n    @property\n    @lru_cache(1)\n    def aspect_ratio(self) -> float:\n        \"\"\"\n        Aspect ratio of the ClosedFluxSurface.\n        \"\"\"\n        return self.major_radius / self.minor_radius\n\n    @property\n    @lru_cache(1)\n    def kappa(self) -> float:\n        \"\"\"\n        Average elongation of the ClosedFluxSurface.\n        \"\"\"\n        return 0.5 * (np.max(self.coords.z) - np.min(self.coords.z)) / self.minor_radius\n\n    @property\n    @lru_cache(1)\n    def kappa_upper(self) -> float:\n        \"\"\"\n        Upper elongation of the ClosedFluxSurface.\n        \"\"\"\n        return (np.max(self.coords.z) - self._z_centre) / self.minor_radius\n\n    @property\n    @lru_cache(1)\n    def kappa_lower(self) -> float:\n        \"\"\"\n        Lower elongation of the ClosedFluxSurface.\n        \"\"\"\n        return abs(np.min(self.coords.z) - self._z_centre) / self.minor_radius\n\n    @property\n    @lru_cache(1)\n    def delta(self) -> float:\n        \"\"\"\n        Average triangularity of the ClosedFluxSurface.\n        \"\"\"\n        return 0.5 * (self.delta_upper + self.delta_lower)\n\n    @property\n    @lru_cache(1)\n    def delta_upper(self) -> float:\n        \"\"\"\n        Upper triangularity of the ClosedFluxSurface.\n        \"\"\"\n        return (self.major_radius - self._p2[0]) / self.minor_radius\n\n    @property\n    @lru_cache(1)\n    def delta_lower(self) -> float:\n        \"\"\"\n        Lower triangularity of the ClosedFluxSurface.\n        \"\"\"\n        return (self.major_radius - self._p4[0]) / self.minor_radius\n\n    @property\n    @lru_cache(1)\n    def zeta(self) -> float:\n        \"\"\"\n        Average squareness of the ClosedFluxSurface.\n        \"\"\"\n        return 0.5 * (self.zeta_upper + self.zeta_lower)\n\n    @property\n    @lru_cache(1)\n    def zeta_upper(self) -> float:\n        \"\"\"\n        Outer upper squareness of the ClosedFluxSurface.\n        \"\"\"\n        z_max = np.max(self.coords.z)\n        arg_z_max = np.argmax(self.coords.z)\n        x_z_max = self.coords.x[arg_z_max]\n        x_max = np.max(self.coords.x)\n        arg_x_max = np.argmax(self.coords.x)\n        z_x_max = self.coords.z[arg_x_max]\n\n        a = z_max - z_x_max\n        b = x_max - x_z_max\n        return self._zeta_calc(a, b, x_z_max, z_x_max, x_max, z_max)\n\n    @property\n    @lru_cache(1)\n    def zeta_lower(self) -> float:\n        \"\"\"\n        Outer lower squareness of the ClosedFluxSurface.\n        \"\"\"\n        z_min = np.min(self.coords.z)\n        arg_z_min = np.argmin(self.coords.z)\n        x_z_min = self.coords.x[arg_z_min]\n        x_max = np.max(self.coords.x)\n        arg_x_max = np.argmax(self.coords.x)\n        z_x_max = self.coords.z[arg_x_max]\n\n        a = z_min - z_x_max\n        b = x_max - x_z_min\n\n        return self._zeta_calc(a, b, x_z_min, z_x_max, x_max, z_min)\n\n    def _zeta_calc(self, a, b, xa, za, xd, zd):\n        \"\"\"\n        Actual squareness calculation\n\n        Notes\n        -----\n        Squareness defined here w.r.t an ellipse intersection along a projected line\n        \"\"\"\n        xc = xa + b * np.sqrt(0.5)\n        zc = za + a * np.sqrt(0.5)\n\n        line = Coordinates({\"x\": [xa, xd], \"z\": [za, zd]})\n        xb, zb = get_intersect(self.coords.xz, line.xz)\n        d_ab = np.hypot(xb - xa, zb - za)\n        d_ac = np.hypot(xc - xa, zc - za)\n        d_cd = np.hypot(xd - xc, zd - zc)\n        return float((d_ab - d_ac) / d_cd)\n\n    @property\n    @lru_cache(1)\n    def area(self) -> float:\n        \"\"\"\n        Enclosed area of the ClosedFluxSurface.\n        \"\"\"\n        return get_area_2d(*self.coords.xz)\n\n    @property\n    @lru_cache(1)\n    def volume(self) -> float:\n        \"\"\"\n        Volume of the ClosedFluxSurface.\n        \"\"\"\n        return 2 * np.pi * self.area * self.coords.center_of_mass[0]\n\n    def shafranov_shift(self, eq: Equilibrium) -> Tuple[float, float]:\n        \"\"\"\n        Calculate the Shafranov shift of the ClosedFluxSurface.\n\n        Parameters\n        ----------\n        eq:\n            Equilibrium with which to calculate the safety factor\n\n        Returns\n        -------\n        dx_shaf:\n            Radial Shafranov shift\n        dz_shaf:\n            Vertical Shafranov shift\n        \"\"\"\n        o_point = eq.get_OX_points()[0][0]  # magnetic axis\n        return o_point.x - self.major_radius, o_point.z - self._z_centre\n\n    def safety_factor(self, eq: Equilibrium) -> float:\n        \"\"\"\n        Calculate the cylindrical safety factor of the ClosedFluxSurface. The ratio of\n        toroidal turns to a single full poloidal turn.\n\n        Parameters\n        ----------\n        eq:\n            Equilibrium with which to calculate the safety factor\n\n        Returns\n        -------\n        Cylindrical safety factor of the closed flux surface\n        \"\"\"\n        x, z = self.coords.x, self.coords.z\n        dx, dz = np.diff(x), np.diff(z)\n        x = x[:-1] + 0.5 * dx  # Segment centre-points\n        z = z[:-1] + 0.5 * dz\n        dl = np.hypot(dx, dz)  # Poloidal plane dl\n        Bp = eq.Bp(x, z)\n        Bt = eq.Bt(x)\n        return np.sum(dl * Bt / (Bp * x)) / (2 * np.pi)",
  "class OpenFluxSurface(FluxSurface):\n    \"\"\"\n    Utility class for handling open flux surface geometries.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, coords: Coordinates):\n        if coords.closed:\n            raise FluxSurfaceError(\n                \"OpenFluxSurface cannot be made from a closed geometry.\"\n            )\n        super().__init__(coords)\n\n    def split(\n        self, o_point: PsiPoint, plane: Optional[BluemiraPlane] = None\n    ) -> Tuple[PartialOpenFluxSurface, PartialOpenFluxSurface]:\n        \"\"\"\n        Split an OpenFluxSurface into two separate PartialOpenFluxSurfaces about a\n        horizontal plane.\n\n        Parameters\n        ----------\n        o_point:\n            The magnetic centre of the plasma\n        plane:\n            The x-y cutting plane. Will default to the O-point x-y plane\n\n        Returns\n        -------\n        down:\n            The downwards open flux surfaces from the splitting point\n        up:\n            The upwards open flux surfaces from the splitting point\n        \"\"\"\n\n        def reset_direction(coords):\n            if coords.argmin([x_mp, 0, z_mp]) != 0:\n                coords.reverse()\n            return coords\n\n        if plane is None:\n            plane = BluemiraPlane.from_3_points(\n                [o_point.x, 0, o_point.z],\n                [o_point.x + 1, 0, o_point.z],\n                [o_point.x, 1, o_point.z],\n            )\n\n        ref_coords = deepcopy(self.coords)\n        intersections = coords_plane_intersect(ref_coords, plane)\n        x_inter = intersections.T[0]\n\n        # Pick the first intersection, travelling from the o_point outwards\n        deltas = x_inter - o_point.x\n        arg_inter = np.argmax(deltas > 0)\n        x_mp = x_inter[arg_inter]\n        z_mp = o_point.z\n\n        # Split the flux surface geometry into LFS and HFS geometries\n\n        delta = 1e-1 if o_point.x < x_mp else -1e-1\n        radial_line = Coordinates({\"x\": [o_point.x, x_mp + delta], \"z\": [z_mp, z_mp]})\n        # Add the intersection point to the Coordinates\n        arg_inter = join_intersect(ref_coords, radial_line, get_arg=True)[0]\n\n        # Split the flux surface geometry\n        coords1 = Coordinates(ref_coords[:, : arg_inter + 1])\n        coords2 = Coordinates(ref_coords[:, arg_inter:])\n\n        coords1 = reset_direction(coords1)\n        coords2 = reset_direction(coords2)\n\n        # Sort the segments into down / outboard and up / inboard geometries\n        if coords1.z[1] > z_mp:\n            lfs_coords = coords2\n            hfs_coords = coords1\n        else:\n            lfs_coords = coords1\n            hfs_coords = coords2\n        return PartialOpenFluxSurface(lfs_coords), PartialOpenFluxSurface(hfs_coords)",
  "class PartialOpenFluxSurface(OpenFluxSurface):\n    \"\"\"\n    Utility class for a partial open flux surface, i.e. an open flux surface that has\n    been split at the midplane and only has one intersection with the wall.\n    \"\"\"\n\n    __slots__ = [\"alpha\"]\n\n    def __init__(self, coords: Coordinates):\n        super().__init__(coords)\n\n        self.alpha = None\n\n    def clip(self, first_wall: Coordinates):\n        \"\"\"\n        Clip the PartialOpenFluxSurface to a first wall.\n\n        Parameters\n        ----------\n        first_wall:\n            The geometry of the first wall to clip the OpenFluxSurface to\n        \"\"\"\n        first_wall = deepcopy(first_wall)\n\n        args = join_intersect(self.coords, first_wall, get_arg=True)\n\n        if not args:\n            bluemira_warn(\n                \"No intersection detected between flux surface and first_wall.\"\n            )\n            self.alpha = None\n            return\n\n        # Because we oriented the Coordinates the \"right\" way, the first intersection\n        # is at the smallest argument\n        self.coords = Coordinates(self.coords[:, : min(args) + 1])\n\n        fw_arg = int(first_wall.argmin([self.x_end, 0, self.z_end]))\n\n        if fw_arg + 1 == len(first_wall):\n            pass\n        elif check_linesegment(\n            first_wall.xz.T[fw_arg],\n            first_wall.xz.T[fw_arg + 1],\n            np.array([self.x_end, self.z_end]),\n        ):\n            fw_arg = fw_arg + 1\n\n        # Relying on the fact that first wall is ccw, get the intersection angle\n        self.alpha = get_angle_between_points(\n            self.coords.points[-2], self.coords.points[-1], first_wall.points[fw_arg]\n        )\n\n    def flux_expansion(self, eq: Equilibrium) -> float:\n        \"\"\"\n        Flux expansion of the PartialOpenFluxSurface.\n\n        Parameters\n        ----------\n        eq:\n            Equilibrium with which to calculate the flux expansion\n\n        Returns\n        -------\n        Target flux expansion\n        \"\"\"\n        return (\n            self.x_start\n            * eq.Bp(self.x_start, self.z_start)\n            / (self.x_end * eq.Bp(self.x_end, self.z_end))\n        )",
  "class CoreResults:\n    \"\"\"\n    Dataclass for core results.\n    \"\"\"\n\n    psi_n: Iterable\n    R_0: Iterable\n    a: Iterable\n    A: Iterable\n    area: Iterable\n    V: Iterable\n    kappa: Iterable\n    delta: Iterable\n    zeta: Iterable\n    kappa_upper: Iterable\n    delta_upper: Iterable\n    zeta_upper: Iterable\n    kappa_lower: Iterable\n    delta_lower: Iterable\n    zeta_lower: Iterable\n    q: Iterable\n    Delta_shaf: Iterable",
  "def analyse_plasma_core(eq: Equilibrium, n_points: int = 50) -> CoreResults:\n    \"\"\"\n    Analyse plasma core parameters across the normalised 1-D flux coordinate.\n\n    Returns\n    -------\n    Results dataclass\n    \"\"\"\n    psi_n = np.linspace(PSI_NORM_TOL, 1 - PSI_NORM_TOL, n_points, endpoint=False)\n    coords = [eq.get_flux_surface(pn) for pn in psi_n]\n    coords.append(eq.get_LCFS())\n    psi_n = np.append(psi_n, 1.0)\n    flux_surfaces = [ClosedFluxSurface(coord) for coord in coords]\n    _vars = [\"major_radius\", \"minor_radius\", \"aspect_ratio\", \"area\", \"volume\"]\n    _vars += [\n        f\"{v}{end}\"\n        for end in [\"\", \"_upper\", \"_lower\"]\n        for v in [\"kappa\", \"delta\", \"zeta\"]\n    ]\n    return CoreResults(\n        psi_n,\n        *[[getattr(fs, var) for fs in flux_surfaces] for var in _vars],\n        [fs.safety_factor(eq) for fs in flux_surfaces],\n        [fs.shafranov_shift(eq)[0] for fs in flux_surfaces],\n    )",
  "class FieldLine:\n    \"\"\"\n    Field line object.\n\n    Parameters\n    ----------\n    coords:\n        Geometry of the FieldLine\n    connection_length:\n        Connection length of the FieldLine\n    \"\"\"\n\n    def __init__(self, coords: Coordinates, connection_length: float):\n        self.coords = coords\n        self.connection_length = connection_length\n\n    def plot(self, ax: Optional[plt.Axes] = None, **kwargs):\n        \"\"\"\n        Plot the FieldLine.\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axes onto which to plot\n        \"\"\"\n        self.coords.plot(ax=ax, **kwargs)\n\n    def pointcare_plot(self, ax: Optional[plt.Axes] = None):\n        \"\"\"\n        Pointcar\u00e9 plot of the field line intersections with the half-xz-plane.\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axes onto which to plot\n        \"\"\"\n        if ax is None:\n            ax = plt.gca()\n\n        xz_plane = BluemiraPlane.from_3_points([0, 0, 0], [1, 0, 0], [0, 0, 1])\n        xi, _, zi = coords_plane_intersect(self.coords, xz_plane).T\n        idx = np.where(xi >= 0)\n        xi = xi[idx]\n        zi = zi[idx]\n        ax.plot(xi, zi, linestyle=\"\", marker=\"o\", color=\"r\", ms=5)\n        ax.set_aspect(\"equal\")",
  "class FieldLineTracer:\n    \"\"\"\n    Field line tracing tool.\n\n    Parameters\n    ----------\n    eq:\n        Equilibrium in which to trace a field line\n    first_wall:\n        Boundary at which to stop tracing the field line\n\n    Notes\n    -----\n    Totally pinched some maths from Ben Dudson's FreeGS here... Perhaps one day I can\n    return the favours.\n\n    I needed it to compare the analytical connection length calculation with something,\n    so I nicked this but changed the way the equation is solved.\n\n    Note that this will properly trace field lines through Coils as it doesn't rely on\n    the psi map (which is inaccurate inside Coils).\n    \"\"\"\n\n    class CollisionTerminator:\n        \"\"\"\n        Private Event handling object for solve_ivp\n\n        Parameters\n        ----------\n        boundary: Union[Grid, Coordinates]\n            Boundary at which to stop tracing the field line.\n        \"\"\"\n\n        def __init__(self, boundary: Union[Grid, Coordinates]):\n            self.boundary = boundary\n            self.terminal = True\n\n        def __call__(self, phi, xz, *args):\n            \"\"\"\n            Function handle for the CollisionTerminator\n            \"\"\"\n            if isinstance(self.boundary, Grid):\n                return self._call_grid(xz)\n            else:\n                return self._call_coordinates(xz)\n\n        def _call_grid(self, xz):\n            \"\"\"\n            Function handle for the CollisionTerminator in the case of a Grid.\n            (slight speed improvement)\n            \"\"\"\n            if self.boundary.point_inside(xz[:2]):\n                return np.min(self.boundary.distance_to(xz[:2]))\n            else:\n                return -np.min(self.boundary.distance_to(xz[:2]))\n\n        def _call_coordinates(self, xz):\n            \"\"\"\n            Function handle for the CollisionTerminator in the case of Coordinates.\n            \"\"\"\n            return _signed_distance_2D(xz[:2], self.boundary.xz.T)\n\n    def __init__(\n        self, eq: Equilibrium, first_wall: Optional[Union[Grid, Coordinates]] = None\n    ):\n        self.eq = eq\n        if first_wall is None:\n            first_wall = self.eq.grid\n        elif isinstance(first_wall, Coordinates) and not first_wall.is_planar:\n            raise EquilibriaError(\n                \"When tracing a field line, the coordinates object of the boundary must be planar.\"\n            )\n        self.first_wall = first_wall\n\n    def trace_field_line(\n        self,\n        x: float,\n        z: float,\n        n_points: int = 200,\n        forward: bool = True,\n        n_turns_max: int = 20,\n    ) -> FieldLine:\n        \"\"\"\n        Trace a single field line starting at a point.\n\n        Parameters\n        ----------\n        x:\n            Radial coordinate of the starting point\n        z:\n            Vertical coordinate of the starting point\n        n_points:\n            Number of points along the field line\n        forward:\n            Whether or not to step forward or backward (+B or -B)\n        n_turns_max: Union[int, float]\n            Maximum number of toroidal turns to trace the field line\n\n        Returns\n        -------\n        Resulting field line\n        \"\"\"\n        phi = np.linspace(0, 2 * np.pi * n_turns_max, n_points)\n\n        result = solve_ivp(\n            self._dxzl_dphi,\n            y0=np.array([x, z, 0]),\n            t_span=(0, 2 * np.pi * n_turns_max),\n            t_eval=phi,\n            events=self.CollisionTerminator(self.first_wall),\n            method=\"LSODA\",\n            args=(forward,),\n        )\n        r, z, phi, connection_length = self._process_result(result)\n\n        x = r * np.cos(phi)\n        y = r * np.sin(phi)\n        coords = Coordinates({\"x\": x, \"y\": y, \"z\": z})\n        return FieldLine(coords, connection_length)\n\n    def _dxzl_dphi(self, phi, xz, forward):\n        \"\"\"\n        Credit: Dr. B. Dudson, FreeGS.\n        \"\"\"\n        f = 1.0 if forward is True else -1.0\n        Bx = self.eq.Bx(*xz[:2])\n        Bz = self.eq.Bz(*xz[:2])\n        Bt = self.eq.Bt(xz[0])\n        B = np.sqrt(Bx**2 + Bz**2 + Bt**2)\n        dx, dz, dl = xz[0] / Bt * np.array([f * Bx, f * Bz, B])\n        return np.array([dx, dz, dl])\n\n    @staticmethod\n    def _process_result(result):\n        if len(result[\"y_events\"][0]) != 0:\n            # Field line tracing was terminated by a collision\n            end = len(result[\"y\"][0])\n            r, z = result[\"y\"][0][:end], result[\"y\"][1][:end]\n            phi = result[\"t\"][:end]\n            termination = result[\"y_events\"][0].flatten()\n            r = np.append(r, termination[0])\n            z = np.append(z, termination[1])\n            connection_length = termination[2]\n            phi = np.append(phi, result[\"t_events\"][0][0])\n\n        else:\n            # Field line tracing was not terminated by a collision\n            r, z, length = result[\"y\"][0], result[\"y\"][1], result[\"y\"][2]\n            phi = result[\"t\"]\n            connection_length = length[-1]\n        return r, z, phi, connection_length",
  "def calculate_connection_length_flt(\n    eq: Equilibrium,\n    x: float,\n    z: float,\n    forward: bool = True,\n    first_wall=Optional[Union[Coordinates, Grid]],\n    n_turns_max: int = 50,\n) -> float:\n    \"\"\"\n    Calculate the parallel connection length from a starting point to a flux-intercepting\n    surface using a field line tracer.\n\n    Parameters\n    ----------\n    eq:\n        Equilibrium in which to calculate the connection length\n    x:\n        Radial coordinate of the starting point\n    z:\n        Vertical coordinate of the starting point\n    forward:\n        Whether or not to follow the field line forwards or backwards (+B or -B)\n    first_wall:\n        Flux-intercepting surface. Defaults to the grid of the equilibrium\n    n_turns_max:\n        Maximum number of toroidal turns to trace the field line\n\n    Returns\n    -------\n    Parallel connection length along the field line from the starting point to the\n    intersection point [m]\n\n    Notes\n    -----\n    More mathematically accurate, but needs additional configuration. Will not likely\n    return a very accurate flux interception point. Also works for closed flux surfaces,\n    but can't tell the difference. Not sensitive to equilibrium grid discretisation.\n    Will work correctly for flux surfaces passing through Coils, but really they should\n    be intercepted beforehand!\n    \"\"\"\n    flt = FieldLineTracer(eq, first_wall)\n    field_line = flt.trace_field_line(\n        x, z, forward=forward, n_points=2, n_turns_max=n_turns_max\n    )\n    return field_line.connection_length",
  "def calculate_connection_length_fs(\n    eq: Equilibrium,\n    x: float,\n    z: float,\n    forward: bool = True,\n    first_wall=Optional[Union[Coordinates, Grid]],\n) -> float:\n    \"\"\"\n    Calculate the parallel connection length from a starting point to a flux-intercepting\n    surface using flux surface geometry.\n\n    Parameters\n    ----------\n    eq:\n        Equilibrium in which to calculate the connection length\n    x:\n        Radial coordinate of the starting point\n    z:\n        Vertical coordinate of the starting point\n    forward:\n        Whether or not to follow the field line forwards or backwards\n    first_wall:\n        Flux-intercepting surface. Defaults to the grid of the equilibrium\n\n    Returns\n    -------\n    Parallel connection length along the field line from the starting point to the\n    intersection point [m]\n\n    Raises\n    ------\n    FluxSurfaceError\n        If the flux surface at the point in the equilibrium is not an open flux surface\n\n    Notes\n    -----\n    Less mathematically accurate. Will return exact intersection point. Sensitive to\n    equilibrium grid discretisation. Presently does not correctly work for flux surfaces\n    passing through Coils, but really they should be intercepted beforehand!\n    \"\"\"\n    if first_wall is None:\n        x1, x2 = eq.grid.x_min, eq.grid.x_max\n        z1, z2 = eq.grid.z_min, eq.grid.z_max\n        first_wall = Coordinates({\"x\": [x1, x2, x2, x1, x1], \"z\": [z1, z1, z2, z2, z1]})\n\n    xfs, zfs = find_flux_surface_through_point(eq.x, eq.z, eq.psi(), x, z, eq.psi(x, z))\n    f_s = OpenFluxSurface(Coordinates({\"x\": xfs, \"z\": zfs}))\n\n    class Point:\n        def __init__(self, x, z):\n            self.x = x\n            self.z = z\n\n    lfs, hfs = f_s.split(Point(x=x, z=z))\n    if forward:\n        fs = lfs\n    else:\n        fs = hfs\n\n    fs.clip(first_wall)\n    return fs.connection_length(eq)",
  "def poloidal_angle(Bp_strike: float, Bt_strike: float, gamma: float) -> float:\n    \"\"\"\n    From glancing angle (gamma) to poloidal angle.\n\n    Parameters\n    ----------\n    Bp_strike:\n        Poloidal magnetic field value at the desired point\n    Bt_strike:\n        Toroidal magnetic field value at the desired point\n    gamma:\n        Glancing angle at the strike point [deg]\n\n    Returns\n    -------\n    Poloidal angle at the strike point [deg]\n    \"\"\"\n    # From deg to rad\n    gamma_rad = np.radians(gamma)\n\n    # Total magnetic field\n    Btot = np.sqrt(Bp_strike**2 + Bt_strike**2)\n\n    # Numerator of next operation\n    num = Btot * np.sin(gamma_rad)\n    # Poloidal projection of the glancing angle\n    sin_theta = num / Bp_strike\n\n    return np.rad2deg(np.arcsin(sin_theta))",
  "def __init__(self, geometry: Coordinates):\n        self.coords = geometry",
  "def x_start(self) -> float:\n        \"\"\"\n        Start radial coordinate of the FluxSurface.\n        \"\"\"\n        return self.coords.x[0]",
  "def z_start(self) -> float:\n        \"\"\"\n        Start vertical coordinate of the FluxSurface.\n        \"\"\"\n        return self.coords.z[0]",
  "def x_end(self) -> float:\n        \"\"\"\n        End radial coordinate of the FluxSurface.\n        \"\"\"\n        return self.coords.x[-1]",
  "def z_end(self) -> float:\n        \"\"\"\n        End vertical coordinate of the FluxSurface.\n        \"\"\"\n        return self.coords.z[-1]",
  "def _dl(self, eq):\n        x, z = self.coords.x, self.coords.z\n        Bp = eq.Bp(x, z)\n        Bt = eq.Bt(x)\n        return _flux_surface_dl(x, z, np.diff(x), np.diff(z), Bp, Bt)",
  "def connection_length(self, eq: Equilibrium) -> float:\n        \"\"\"\n        Calculate the parallel connection length along a field line (i.e. flux surface).\n\n        Parameters\n        ----------\n        eq:\n            Equilibrium from which the FluxSurface was extracted\n\n        Returns\n        -------\n        Connection length from the start of the flux surface to the end of the flux\n        surface\n        \"\"\"\n        return np.sum(self._dl(eq))",
  "def plot(self, ax: Optional[plt.Axes] = None, **kwargs):\n        \"\"\"\n        Plot the FluxSurface.\n        \"\"\"\n        if ax is None:\n            ax = plt.gca()\n\n        kwargs[\"linewidth\"] = kwargs.get(\"linewidth\", 0.05)\n        kwargs[\"color\"] = kwargs.get(\"color\", \"r\")\n\n        self.coords.plot(ax, **kwargs)",
  "def copy(self):\n        \"\"\"\n        Make a deep copy of the FluxSurface.\n        \"\"\"\n        return deepcopy(self)",
  "def __init__(self, geometry: Coordinates):\n        if not geometry.closed:\n            raise FluxSurfaceError(\n                \"Cannot make a ClosedFluxSurface from an open geometry.\"\n            )\n        super().__init__(geometry)\n        i_p1 = np.argmax(self.coords.x)\n        i_p2 = np.argmax(self.coords.z)\n        i_p3 = np.argmin(self.coords.x)\n        i_p4 = np.argmin(self.coords.z)\n        self._p1 = (self.coords.x[i_p1], self.coords.z[i_p1])\n        self._p2 = (self.coords.x[i_p2], self.coords.z[i_p2])\n        self._p3 = (self.coords.x[i_p3], self.coords.z[i_p3])\n        self._p4 = (self.coords.x[i_p4], self.coords.z[i_p4])\n\n        # Still debatable what convention to follow...\n        self._z_centre = 0.5 * (self.coords.z[i_p1] + self.coords.z[i_p3])",
  "def major_radius(self) -> float:\n        \"\"\"\n        Major radius of the ClosedFluxSurface.\n        \"\"\"\n        return np.min(self.coords.x) + self.minor_radius",
  "def minor_radius(self) -> float:\n        \"\"\"\n        Minor radius of the ClosedFluxSurface.\n        \"\"\"\n        return 0.5 * (np.max(self.coords.x) - np.min(self.coords.x))",
  "def aspect_ratio(self) -> float:\n        \"\"\"\n        Aspect ratio of the ClosedFluxSurface.\n        \"\"\"\n        return self.major_radius / self.minor_radius",
  "def kappa(self) -> float:\n        \"\"\"\n        Average elongation of the ClosedFluxSurface.\n        \"\"\"\n        return 0.5 * (np.max(self.coords.z) - np.min(self.coords.z)) / self.minor_radius",
  "def kappa_upper(self) -> float:\n        \"\"\"\n        Upper elongation of the ClosedFluxSurface.\n        \"\"\"\n        return (np.max(self.coords.z) - self._z_centre) / self.minor_radius",
  "def kappa_lower(self) -> float:\n        \"\"\"\n        Lower elongation of the ClosedFluxSurface.\n        \"\"\"\n        return abs(np.min(self.coords.z) - self._z_centre) / self.minor_radius",
  "def delta(self) -> float:\n        \"\"\"\n        Average triangularity of the ClosedFluxSurface.\n        \"\"\"\n        return 0.5 * (self.delta_upper + self.delta_lower)",
  "def delta_upper(self) -> float:\n        \"\"\"\n        Upper triangularity of the ClosedFluxSurface.\n        \"\"\"\n        return (self.major_radius - self._p2[0]) / self.minor_radius",
  "def delta_lower(self) -> float:\n        \"\"\"\n        Lower triangularity of the ClosedFluxSurface.\n        \"\"\"\n        return (self.major_radius - self._p4[0]) / self.minor_radius",
  "def zeta(self) -> float:\n        \"\"\"\n        Average squareness of the ClosedFluxSurface.\n        \"\"\"\n        return 0.5 * (self.zeta_upper + self.zeta_lower)",
  "def zeta_upper(self) -> float:\n        \"\"\"\n        Outer upper squareness of the ClosedFluxSurface.\n        \"\"\"\n        z_max = np.max(self.coords.z)\n        arg_z_max = np.argmax(self.coords.z)\n        x_z_max = self.coords.x[arg_z_max]\n        x_max = np.max(self.coords.x)\n        arg_x_max = np.argmax(self.coords.x)\n        z_x_max = self.coords.z[arg_x_max]\n\n        a = z_max - z_x_max\n        b = x_max - x_z_max\n        return self._zeta_calc(a, b, x_z_max, z_x_max, x_max, z_max)",
  "def zeta_lower(self) -> float:\n        \"\"\"\n        Outer lower squareness of the ClosedFluxSurface.\n        \"\"\"\n        z_min = np.min(self.coords.z)\n        arg_z_min = np.argmin(self.coords.z)\n        x_z_min = self.coords.x[arg_z_min]\n        x_max = np.max(self.coords.x)\n        arg_x_max = np.argmax(self.coords.x)\n        z_x_max = self.coords.z[arg_x_max]\n\n        a = z_min - z_x_max\n        b = x_max - x_z_min\n\n        return self._zeta_calc(a, b, x_z_min, z_x_max, x_max, z_min)",
  "def _zeta_calc(self, a, b, xa, za, xd, zd):\n        \"\"\"\n        Actual squareness calculation\n\n        Notes\n        -----\n        Squareness defined here w.r.t an ellipse intersection along a projected line\n        \"\"\"\n        xc = xa + b * np.sqrt(0.5)\n        zc = za + a * np.sqrt(0.5)\n\n        line = Coordinates({\"x\": [xa, xd], \"z\": [za, zd]})\n        xb, zb = get_intersect(self.coords.xz, line.xz)\n        d_ab = np.hypot(xb - xa, zb - za)\n        d_ac = np.hypot(xc - xa, zc - za)\n        d_cd = np.hypot(xd - xc, zd - zc)\n        return float((d_ab - d_ac) / d_cd)",
  "def area(self) -> float:\n        \"\"\"\n        Enclosed area of the ClosedFluxSurface.\n        \"\"\"\n        return get_area_2d(*self.coords.xz)",
  "def volume(self) -> float:\n        \"\"\"\n        Volume of the ClosedFluxSurface.\n        \"\"\"\n        return 2 * np.pi * self.area * self.coords.center_of_mass[0]",
  "def shafranov_shift(self, eq: Equilibrium) -> Tuple[float, float]:\n        \"\"\"\n        Calculate the Shafranov shift of the ClosedFluxSurface.\n\n        Parameters\n        ----------\n        eq:\n            Equilibrium with which to calculate the safety factor\n\n        Returns\n        -------\n        dx_shaf:\n            Radial Shafranov shift\n        dz_shaf:\n            Vertical Shafranov shift\n        \"\"\"\n        o_point = eq.get_OX_points()[0][0]  # magnetic axis\n        return o_point.x - self.major_radius, o_point.z - self._z_centre",
  "def safety_factor(self, eq: Equilibrium) -> float:\n        \"\"\"\n        Calculate the cylindrical safety factor of the ClosedFluxSurface. The ratio of\n        toroidal turns to a single full poloidal turn.\n\n        Parameters\n        ----------\n        eq:\n            Equilibrium with which to calculate the safety factor\n\n        Returns\n        -------\n        Cylindrical safety factor of the closed flux surface\n        \"\"\"\n        x, z = self.coords.x, self.coords.z\n        dx, dz = np.diff(x), np.diff(z)\n        x = x[:-1] + 0.5 * dx  # Segment centre-points\n        z = z[:-1] + 0.5 * dz\n        dl = np.hypot(dx, dz)  # Poloidal plane dl\n        Bp = eq.Bp(x, z)\n        Bt = eq.Bt(x)\n        return np.sum(dl * Bt / (Bp * x)) / (2 * np.pi)",
  "def __init__(self, coords: Coordinates):\n        if coords.closed:\n            raise FluxSurfaceError(\n                \"OpenFluxSurface cannot be made from a closed geometry.\"\n            )\n        super().__init__(coords)",
  "def split(\n        self, o_point: PsiPoint, plane: Optional[BluemiraPlane] = None\n    ) -> Tuple[PartialOpenFluxSurface, PartialOpenFluxSurface]:\n        \"\"\"\n        Split an OpenFluxSurface into two separate PartialOpenFluxSurfaces about a\n        horizontal plane.\n\n        Parameters\n        ----------\n        o_point:\n            The magnetic centre of the plasma\n        plane:\n            The x-y cutting plane. Will default to the O-point x-y plane\n\n        Returns\n        -------\n        down:\n            The downwards open flux surfaces from the splitting point\n        up:\n            The upwards open flux surfaces from the splitting point\n        \"\"\"\n\n        def reset_direction(coords):\n            if coords.argmin([x_mp, 0, z_mp]) != 0:\n                coords.reverse()\n            return coords\n\n        if plane is None:\n            plane = BluemiraPlane.from_3_points(\n                [o_point.x, 0, o_point.z],\n                [o_point.x + 1, 0, o_point.z],\n                [o_point.x, 1, o_point.z],\n            )\n\n        ref_coords = deepcopy(self.coords)\n        intersections = coords_plane_intersect(ref_coords, plane)\n        x_inter = intersections.T[0]\n\n        # Pick the first intersection, travelling from the o_point outwards\n        deltas = x_inter - o_point.x\n        arg_inter = np.argmax(deltas > 0)\n        x_mp = x_inter[arg_inter]\n        z_mp = o_point.z\n\n        # Split the flux surface geometry into LFS and HFS geometries\n\n        delta = 1e-1 if o_point.x < x_mp else -1e-1\n        radial_line = Coordinates({\"x\": [o_point.x, x_mp + delta], \"z\": [z_mp, z_mp]})\n        # Add the intersection point to the Coordinates\n        arg_inter = join_intersect(ref_coords, radial_line, get_arg=True)[0]\n\n        # Split the flux surface geometry\n        coords1 = Coordinates(ref_coords[:, : arg_inter + 1])\n        coords2 = Coordinates(ref_coords[:, arg_inter:])\n\n        coords1 = reset_direction(coords1)\n        coords2 = reset_direction(coords2)\n\n        # Sort the segments into down / outboard and up / inboard geometries\n        if coords1.z[1] > z_mp:\n            lfs_coords = coords2\n            hfs_coords = coords1\n        else:\n            lfs_coords = coords1\n            hfs_coords = coords2\n        return PartialOpenFluxSurface(lfs_coords), PartialOpenFluxSurface(hfs_coords)",
  "def __init__(self, coords: Coordinates):\n        super().__init__(coords)\n\n        self.alpha = None",
  "def clip(self, first_wall: Coordinates):\n        \"\"\"\n        Clip the PartialOpenFluxSurface to a first wall.\n\n        Parameters\n        ----------\n        first_wall:\n            The geometry of the first wall to clip the OpenFluxSurface to\n        \"\"\"\n        first_wall = deepcopy(first_wall)\n\n        args = join_intersect(self.coords, first_wall, get_arg=True)\n\n        if not args:\n            bluemira_warn(\n                \"No intersection detected between flux surface and first_wall.\"\n            )\n            self.alpha = None\n            return\n\n        # Because we oriented the Coordinates the \"right\" way, the first intersection\n        # is at the smallest argument\n        self.coords = Coordinates(self.coords[:, : min(args) + 1])\n\n        fw_arg = int(first_wall.argmin([self.x_end, 0, self.z_end]))\n\n        if fw_arg + 1 == len(first_wall):\n            pass\n        elif check_linesegment(\n            first_wall.xz.T[fw_arg],\n            first_wall.xz.T[fw_arg + 1],\n            np.array([self.x_end, self.z_end]),\n        ):\n            fw_arg = fw_arg + 1\n\n        # Relying on the fact that first wall is ccw, get the intersection angle\n        self.alpha = get_angle_between_points(\n            self.coords.points[-2], self.coords.points[-1], first_wall.points[fw_arg]\n        )",
  "def flux_expansion(self, eq: Equilibrium) -> float:\n        \"\"\"\n        Flux expansion of the PartialOpenFluxSurface.\n\n        Parameters\n        ----------\n        eq:\n            Equilibrium with which to calculate the flux expansion\n\n        Returns\n        -------\n        Target flux expansion\n        \"\"\"\n        return (\n            self.x_start\n            * eq.Bp(self.x_start, self.z_start)\n            / (self.x_end * eq.Bp(self.x_end, self.z_end))\n        )",
  "def __init__(self, coords: Coordinates, connection_length: float):\n        self.coords = coords\n        self.connection_length = connection_length",
  "def plot(self, ax: Optional[plt.Axes] = None, **kwargs):\n        \"\"\"\n        Plot the FieldLine.\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axes onto which to plot\n        \"\"\"\n        self.coords.plot(ax=ax, **kwargs)",
  "def pointcare_plot(self, ax: Optional[plt.Axes] = None):\n        \"\"\"\n        Pointcar\u00e9 plot of the field line intersections with the half-xz-plane.\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axes onto which to plot\n        \"\"\"\n        if ax is None:\n            ax = plt.gca()\n\n        xz_plane = BluemiraPlane.from_3_points([0, 0, 0], [1, 0, 0], [0, 0, 1])\n        xi, _, zi = coords_plane_intersect(self.coords, xz_plane).T\n        idx = np.where(xi >= 0)\n        xi = xi[idx]\n        zi = zi[idx]\n        ax.plot(xi, zi, linestyle=\"\", marker=\"o\", color=\"r\", ms=5)\n        ax.set_aspect(\"equal\")",
  "class CollisionTerminator:\n        \"\"\"\n        Private Event handling object for solve_ivp\n\n        Parameters\n        ----------\n        boundary: Union[Grid, Coordinates]\n            Boundary at which to stop tracing the field line.\n        \"\"\"\n\n        def __init__(self, boundary: Union[Grid, Coordinates]):\n            self.boundary = boundary\n            self.terminal = True\n\n        def __call__(self, phi, xz, *args):\n            \"\"\"\n            Function handle for the CollisionTerminator\n            \"\"\"\n            if isinstance(self.boundary, Grid):\n                return self._call_grid(xz)\n            else:\n                return self._call_coordinates(xz)\n\n        def _call_grid(self, xz):\n            \"\"\"\n            Function handle for the CollisionTerminator in the case of a Grid.\n            (slight speed improvement)\n            \"\"\"\n            if self.boundary.point_inside(xz[:2]):\n                return np.min(self.boundary.distance_to(xz[:2]))\n            else:\n                return -np.min(self.boundary.distance_to(xz[:2]))\n\n        def _call_coordinates(self, xz):\n            \"\"\"\n            Function handle for the CollisionTerminator in the case of Coordinates.\n            \"\"\"\n            return _signed_distance_2D(xz[:2], self.boundary.xz.T)",
  "def __init__(\n        self, eq: Equilibrium, first_wall: Optional[Union[Grid, Coordinates]] = None\n    ):\n        self.eq = eq\n        if first_wall is None:\n            first_wall = self.eq.grid\n        elif isinstance(first_wall, Coordinates) and not first_wall.is_planar:\n            raise EquilibriaError(\n                \"When tracing a field line, the coordinates object of the boundary must be planar.\"\n            )\n        self.first_wall = first_wall",
  "def trace_field_line(\n        self,\n        x: float,\n        z: float,\n        n_points: int = 200,\n        forward: bool = True,\n        n_turns_max: int = 20,\n    ) -> FieldLine:\n        \"\"\"\n        Trace a single field line starting at a point.\n\n        Parameters\n        ----------\n        x:\n            Radial coordinate of the starting point\n        z:\n            Vertical coordinate of the starting point\n        n_points:\n            Number of points along the field line\n        forward:\n            Whether or not to step forward or backward (+B or -B)\n        n_turns_max: Union[int, float]\n            Maximum number of toroidal turns to trace the field line\n\n        Returns\n        -------\n        Resulting field line\n        \"\"\"\n        phi = np.linspace(0, 2 * np.pi * n_turns_max, n_points)\n\n        result = solve_ivp(\n            self._dxzl_dphi,\n            y0=np.array([x, z, 0]),\n            t_span=(0, 2 * np.pi * n_turns_max),\n            t_eval=phi,\n            events=self.CollisionTerminator(self.first_wall),\n            method=\"LSODA\",\n            args=(forward,),\n        )\n        r, z, phi, connection_length = self._process_result(result)\n\n        x = r * np.cos(phi)\n        y = r * np.sin(phi)\n        coords = Coordinates({\"x\": x, \"y\": y, \"z\": z})\n        return FieldLine(coords, connection_length)",
  "def _dxzl_dphi(self, phi, xz, forward):\n        \"\"\"\n        Credit: Dr. B. Dudson, FreeGS.\n        \"\"\"\n        f = 1.0 if forward is True else -1.0\n        Bx = self.eq.Bx(*xz[:2])\n        Bz = self.eq.Bz(*xz[:2])\n        Bt = self.eq.Bt(xz[0])\n        B = np.sqrt(Bx**2 + Bz**2 + Bt**2)\n        dx, dz, dl = xz[0] / Bt * np.array([f * Bx, f * Bz, B])\n        return np.array([dx, dz, dl])",
  "def _process_result(result):\n        if len(result[\"y_events\"][0]) != 0:\n            # Field line tracing was terminated by a collision\n            end = len(result[\"y\"][0])\n            r, z = result[\"y\"][0][:end], result[\"y\"][1][:end]\n            phi = result[\"t\"][:end]\n            termination = result[\"y_events\"][0].flatten()\n            r = np.append(r, termination[0])\n            z = np.append(z, termination[1])\n            connection_length = termination[2]\n            phi = np.append(phi, result[\"t_events\"][0][0])\n\n        else:\n            # Field line tracing was not terminated by a collision\n            r, z, length = result[\"y\"][0], result[\"y\"][1], result[\"y\"][2]\n            phi = result[\"t\"]\n            connection_length = length[-1]\n        return r, z, phi, connection_length",
  "class Point:\n        def __init__(self, x, z):\n            self.x = x\n            self.z = z",
  "def reset_direction(coords):\n            if coords.argmin([x_mp, 0, z_mp]) != 0:\n                coords.reverse()\n            return coords",
  "def __init__(self, boundary: Union[Grid, Coordinates]):\n            self.boundary = boundary\n            self.terminal = True",
  "def __call__(self, phi, xz, *args):\n            \"\"\"\n            Function handle for the CollisionTerminator\n            \"\"\"\n            if isinstance(self.boundary, Grid):\n                return self._call_grid(xz)\n            else:\n                return self._call_coordinates(xz)",
  "def _call_grid(self, xz):\n            \"\"\"\n            Function handle for the CollisionTerminator in the case of a Grid.\n            (slight speed improvement)\n            \"\"\"\n            if self.boundary.point_inside(xz[:2]):\n                return np.min(self.boundary.distance_to(xz[:2]))\n            else:\n                return -np.min(self.boundary.distance_to(xz[:2]))",
  "def _call_coordinates(self, xz):\n            \"\"\"\n            Function handle for the CollisionTerminator in the case of Coordinates.\n            \"\"\"\n            return _signed_distance_2D(xz[:2], self.boundary.xz.T)",
  "def __init__(self, x, z):\n            self.x = x\n            self.z = z",
  "def _get_dummy_equilibrium(equilibrium: Equilibrium):\n    \"\"\"\n    Get a dummy equilibrium for current optimisation where the background response is\n    solely due to the plasma and passive coils.\n\n    Notes\n    -----\n    When we do dI (current gradient) optimisation, the background vector includes the\n    contributions from the whole coilset (including active coils).\n\n    When we do I (current vector) optimisation, the background vector only includes\n    contributions from the passive coils (plasma).\n    \"\"\"\n    # TODO: Add passive coil contributions here\n    dummy = equilibrium.plasma\n    dummy.coilset = deepcopy(equilibrium.coilset)\n    return dummy",
  "class UpdateableConstraint(ABC):\n    \"\"\"\n    Abstract base mixin class for an equilibrium optimisation constraint that is\n    updateable.\n    \"\"\"\n\n    @abstractmethod\n    def prepare(self, equilibrium: Equilibrium, I_not_dI=False, fixed_coils=False):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def control_response(self, coilset: CoilSet):\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def evaluate(self, equilibrium: Equilibrium):\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        pass",
  "class FieldConstraints(UpdateableConstraint, OptimisationConstraint):\n    \"\"\"\n    Inequality constraints for the poloidal field at certain locations.\n\n    Parameters\n    ----------\n    x:\n        Radial coordinate(s) at which to constrain the poloidal field\n    z:\n        Vertical coordinate(s) at which to constrain the poloidal field\n    B_max:\n        Maximum poloidal field value(s) at location(s)\n    tolerance:\n        Tolerance with which the constraint(s) will be met\n    constraint_type:\n        Type of constraint\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        B_max: Union[float, np.ndarray],\n        tolerance: Union[float, np.ndarray] = 1.0e-6,\n        constraint_type: str = \"inequality\",\n    ):\n        if is_num(x):\n            x = np.array([x])\n        if is_num(z):\n            z = np.array([z])\n\n        if is_num(B_max):\n            B_max = B_max * np.ones(len(x))\n        if len(B_max) != len(x):\n            raise ValueError(\n                \"Maximum field vector length not equal to the number of points.\"\n            )\n\n        if is_num(tolerance):\n            tolerance = tolerance * np.ones(len(x))\n        if len(tolerance) != len(x):\n            raise ValueError(\"Tolerance vector length not equal to the number of coils.\")\n\n        self.x = x\n        self.z = z\n        super().__init__(\n            f_constraint=field_constraints,\n            f_constraint_args={\n                \"ax_mat\": None,\n                \"az_mat\": None,\n                \"bxp_vec\": None,\n                \"bzp_vec\": None,\n                \"B_max\": B_max,\n                \"scale\": 1.0,\n            },\n            tolerance=tolerance,\n            constraint_type=constraint_type,\n        )\n\n    def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"ax_mat\"] is None):\n            ax_mat, az_mat = self.control_response(equilibrium.coilset)\n            self._args[\"ax_mat\"] = ax_mat\n            self._args[\"az_mat\"] = az_mat\n\n        bxp_vec, bzp_vec = self.evaluate(equilibrium)\n        self._args[\"bxp_vec\"] = bxp_vec\n        self._args[\"bzp_vec\"] = bzp_vec\n\n    def control_response(self, coilset: CoilSet) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return (\n            coilset.Bx_response(self.x, self.z, control=True),\n            coilset.Bz_response(self.x, self.z, control=True),\n        )\n\n    def evaluate(self, equilibrium: Equilibrium) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        Bx, Bz = np.zeros(len(self)), np.zeros(len(self))\n        Bx = equilibrium.Bx(self.x, self.z)\n        Bz = equilibrium.Bz(self.x, self.z)\n        return Bx, Bz\n\n    def __len__(self) -> int:\n        \"\"\"\n        Length of field constraints.\n        \"\"\"\n        return len(self.x)",
  "class CoilFieldConstraints(FieldConstraints):\n    \"\"\"\n    Inequality constraints on the poloidal field at the middle of the inside edge\n    of the coils, where the field is usually highest.\n\n    Parameters\n    ----------\n    coilset:\n        Coilset for which to constrain the fields in the coils\n    B_max:\n        Maximum field allowed in the coils\n    tolerance:\n        Tolerance with which the inequality constraints will be met\n\n    Notes\n    -----\n    This is a fast approximation constraint, and does not solve for the peak field\n    at all points in the coils. Use with caution.\n    TODO: Presently only handles CoilSets with Coils (SymmetricCircuits not yet\n    supported)\n    TODO: Presently only accounts for poloidal field contributions from PF coils and\n    plasma (TF from TF coils not accounted for if PF coils are inside the TF coils.)\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        B_max: Union[float, np.ndarray],\n        tolerance: Union[float, np.ndarray] = 1.0e-6,\n    ):\n        n_coils = coilset.n_coils()\n        if is_num(B_max):\n            B_max = B_max * np.ones(n_coils)\n        if len(B_max) != n_coils:\n            raise ValueError(\n                \"Maximum field vector length not equal to the number of coils.\"\n            )\n\n        if is_num(tolerance):\n            tolerance = tolerance * np.ones(n_coils)\n        if len(tolerance) != n_coils:\n            raise ValueError(\"Tolerance vector length not equal to the number of coils.\")\n\n        x, z = self._get_constraint_points(coilset)\n\n        super().__init__(x, z, B_max, tolerance=tolerance, constraint_type=\"inequality\")\n\n    @staticmethod\n    def _get_constraint_points(coilset):\n        return coilset.x - coilset.dx, coilset.z\n\n    def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"ax_mat\"] is None):\n            # Update the target points for the constraints (the coils may be moving)\n            self.x, self.z = self._get_constraint_points(equilibrium.coilset)\n            ax_mat, az_mat = self.control_response(equilibrium.coilset)\n            self._args[\"ax_mat\"] = ax_mat\n            self._args[\"az_mat\"] = az_mat\n\n        bxp_vec, bzp_vec = self.evaluate(equilibrium)\n        self._args[\"bxp_vec\"] = bxp_vec\n        self._args[\"bzp_vec\"] = bzp_vec",
  "class CoilForceConstraints(UpdateableConstraint, OptimisationConstraint):\n    \"\"\"\n    Inequality constraints on the vertical forces in the PF and CS coils.\n\n    Parameters\n    ----------\n    coilset:\n        Coilset for which to constrain the fields in the coils\n    PF_Fz_max:\n        Maximum absolute vertical force in a PF coil [MN]\n    CS_Fz_sum_max:\n        Maximum absolute vertical force sum in the CS stack [MN]\n    CS_Fz_sep_max:\n        Maximum separation vertical force between two CS modules [MN]\n    tolerance:\n        Tolerance with which the inequality constraints will be met\n\n    Notes\n    -----\n    TODO: Presently only handles CoilSets with Coils (SymmetricCircuits not yet\n    supported)\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        PF_Fz_max: float,\n        CS_Fz_sum_max: float,\n        CS_Fz_sep_max: float,\n        tolerance: Union[float, np.ndarray] = 1.0e-6,\n    ):\n        n_PF = coilset.n_coils(\"PF\")\n        n_CS = coilset.n_coils(\"CS\")\n        n_f_constraints = n_PF + n_CS\n\n        if is_num(tolerance):\n            tolerance = tolerance * np.ones(n_f_constraints)\n        elif len(tolerance) != n_f_constraints:\n            raise ValueError(f\"Tolerance vector not of length {n_f_constraints}\")\n\n        super().__init__(\n            f_constraint=coil_force_constraints,\n            f_constraint_args={\n                \"a_mat\": None,\n                \"b_vec\": None,\n                \"scale\": 1.0,\n                \"PF_Fz_max\": PF_Fz_max,\n                \"CS_Fz_sum_max\": CS_Fz_sum_max,\n                \"CS_Fz_sep_max\": CS_Fz_sep_max,\n                \"n_PF\": n_PF,\n                \"n_CS\": n_CS,\n            },\n            tolerance=tolerance,\n        )\n\n    def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"a_mat\"] is None):\n            self._args[\"a_mat\"] = self.control_response(equilibrium.coilset)\n\n        self._args[\"b_vec\"] = self.evaluate(equilibrium)\n\n    def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.control_F(coilset)\n\n    def evaluate(self, equilibrium: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        fp = np.zeros((equilibrium.coilset.n_coils(), 2))\n        current = equilibrium.coilset.current\n        non_zero = np.where(current != 0)[0]\n        if non_zero.size:\n            fp[non_zero] = (\n                equilibrium.coilset.F(equilibrium)[non_zero] / current[non_zero][:, None]\n            )\n        return fp",
  "class MagneticConstraint(UpdateableConstraint, OptimisationConstraint):\n    \"\"\"\n    Abstract base class for a magnetic optimisation constraint.\n\n    Can be used as a standalone constraint for use in an optimisation problem. In which\n    case the constraint is of the form: ||(Ax - b)||\u00b2 < target_value\n\n    Can be used in a MagneticConstraintSet\n    \"\"\"\n\n    def __init__(\n        self,\n        target_value: float = 0.0,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n        f_constraint: Callable[[np.ndarray], np.ndarray] = L2_norm_constraint,\n        constraint_type: str = \"inequality\",\n    ):\n        self.target_value = target_value * np.ones(len(self))\n        if is_num(tolerance):\n            if f_constraint == L2_norm_constraint:\n                tolerance = tolerance * np.ones(1)\n            else:\n                tolerance = tolerance * np.ones(len(self))\n        self.weights = weights\n        args = {\"a_mat\": None, \"b_vec\": None, \"value\": 0.0, \"scale\": 1.0}\n        super().__init__(\n            f_constraint=f_constraint,\n            f_constraint_args=args,\n            tolerance=tolerance,\n            constraint_type=constraint_type,\n        )\n\n    def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):  # noqa :N803\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"a_mat\"] is None):\n            self._args[\"a_mat\"] = self.control_response(equilibrium.coilset)\n\n        self.update_target(equilibrium)\n        self._args[\"b_vec\"] = self.target_value - self.evaluate(equilibrium)\n\n    def update_target(self, equilibrium: Equilibrium):\n        \"\"\"\n        Update the target value of the magnetic constraint.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        pass\n\n    def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint.\n\n        Notes\n        -----\n        Length of the array if an array is specified, otherwise 1 for a float.\n        \"\"\"\n        return len(self.x) if hasattr(self.x, \"__len__\") else 1",
  "class AbsoluteMagneticConstraint(MagneticConstraint):\n    \"\"\"\n    Abstract base class for absolute magnetic constraints, where the target\n    value is prescribed in absolute terms.\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        target_value: float,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n        f_constraint: Callable[[np.ndarray], np.ndarray] = Ax_b_constraint,\n        constraint_type: str = \"equality\",\n    ):\n        self.x = x\n        self.z = z\n        super().__init__(\n            target_value,\n            weights,\n            tolerance=tolerance,\n            f_constraint=f_constraint,\n            constraint_type=constraint_type,\n        )",
  "class RelativeMagneticConstraint(MagneticConstraint):\n    \"\"\"\n    Abstract base class for relative magnetic constraints, where the target\n    value is prescribed with respect to a reference point.\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        ref_x: float,\n        ref_z: float,\n        constraint_value: float = 0.0,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n        f_constraint: Callable[[np.ndarray], np.ndarray] = L2_norm_constraint,\n        constraint_type: str = \"inequality\",\n    ):\n        self.x = x\n        self.z = z\n        self.ref_x = ref_x\n        self.ref_z = ref_z\n        super().__init__(\n            0.0,\n            weights,\n            tolerance=tolerance,\n            f_constraint=f_constraint,\n            constraint_type=constraint_type,\n        )\n        self._args[\"value\"] = constraint_value\n\n    @abstractmethod\n    def update_target(self, equilibrium: Equilibrium):\n        \"\"\"\n        Update the target value of the magnetic constraint.\n        \"\"\"\n        pass",
  "class FieldNullConstraint(AbsoluteMagneticConstraint):\n    \"\"\"\n    Magnetic field null constraint. In practice sets the Bx and Bz field components\n    to be 0 at the specified location.\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: float = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            target_value=0.0,\n            weights=weights,\n            tolerance=tolerance,\n            constraint_type=\"inequality\",\n            f_constraint=L2_norm_constraint,\n        )\n\n    def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return np.vstack(\n            [\n                coilset.Bx_response(self.x, self.z, control=True),\n                coilset.Bz_response(self.x, self.z, control=True),\n            ]\n        )\n\n    def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return np.array([eq.Bx(self.x, self.z), eq.Bz(self.x, self.z)])\n\n    def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\n            \"marker\": \"X\",\n            \"color\": \"b\",\n            \"markersize\": 10,\n            \"zorder\": 45,\n            \"linestyle\": \"None\",\n        }\n        ax.plot(self.x, self.z, **kwargs)\n\n    def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint.\n        \"\"\"\n        return 2",
  "class PsiConstraint(AbsoluteMagneticConstraint):\n    \"\"\"\n    Absolute psi value constraint.\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        target_value: float,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            target_value,\n            weights=weights,\n            tolerance=tolerance,\n            f_constraint=Ax_b_constraint,\n            constraint_type=\"equality\",\n        )\n\n    def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.psi_response(self.x, self.z, control=True)\n\n    def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return eq.psi(self.x, self.z)\n\n    def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\"marker\": \"s\", \"markersize\": 8, \"color\": \"b\", \"linestyle\": \"None\"}\n        ax.plot(self.x, self.z, **kwargs)",
  "class IsofluxConstraint(RelativeMagneticConstraint):\n    \"\"\"\n    Isoflux constraint for a set of points relative to a reference point.\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        ref_x: float,\n        ref_z: float,\n        constraint_value: float = 0.0,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: float = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            ref_x,\n            ref_z,\n            constraint_value,\n            weights=weights,\n            f_constraint=L2_norm_constraint,\n            tolerance=tolerance,\n            constraint_type=\"inequality\",\n        )\n\n    def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.psi_response(self.x, self.z, control=True) - coilset.psi_response(\n            self.ref_x, self.ref_z, control=True\n        )\n\n    def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return eq.psi(self.x, self.z)\n\n    def update_target(self, eq: Equilibrium):\n        \"\"\"\n        We need to update the target value, as it is a relative constraint.\n        \"\"\"\n        self.target_value = float(eq.psi(self.ref_x, self.ref_z))\n\n    def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\n            \"marker\": \"o\",\n            \"markeredgewidth\": 3,\n            \"markeredgecolor\": \"b\",\n            \"markersize\": 10,\n            \"linestyle\": \"None\",\n            \"markerfacecolor\": \"None\",\n            \"zorder\": 45,\n        }\n        ax.plot(self.x, self.z, **kwargs)\n        kwargs[\"markeredgewidth\"] = 5\n        ax.plot(self.ref_x, self.ref_z, **kwargs)",
  "class PsiBoundaryConstraint(AbsoluteMagneticConstraint):\n    \"\"\"\n    Absolute psi value constraint on the plasma boundary. Gets updated when\n    the plasma boundary flux value is changed.\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        target_value: float,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            target_value,\n            weights,\n            tolerance,\n            f_constraint=L2_norm_constraint,\n            constraint_type=\"inequality\",\n        )\n\n    def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.psi_response(self.x, self.z, control=True)\n\n    def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return eq.psi(self.x, self.z)\n\n    def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\"marker\": \"o\", \"markersize\": 8, \"color\": \"b\", \"linestyle\": \"None\"}\n        ax.plot(self.x, self.z, **kwargs)",
  "class MagneticConstraintSet(ABC):\n    \"\"\"\n    A set of magnetic constraints to be applied to an equilibrium. The optimisation\n    problem is of the form:\n\n        [A][x] = [b]\n\n    where:\n\n        [b] = [target] - [background]\n\n    The target vector is the vector of desired values. The background vector\n    is the vector of values due to uncontrolled current terms (plasma and passive\n    coils).\n\n\n    Use of class:\n\n        - Inherit from this class\n        - Add a __init__(args) method\n        - Populate constraints with super().__init__(List[MagneticConstraint])\n    \"\"\"\n\n    __slots__ = [\"constraints\", \"eq\", \"coilset\", \"A\", \"w\", \"target\", \"background\"]\n\n    def __init__(self, constraints: List[MagneticConstraint]):\n        self.constraints = constraints\n        self.eq = None\n        self.A = None\n        self.target = None\n        self.background = None\n\n    def __call__(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):  # noqa :N803\n        \"\"\"\n        Update the MagneticConstraintSet\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        self.eq = equilibrium\n        self.coilset = equilibrium.coilset\n\n        # Update relative magnetic constraints without updating A matrix\n        for constraint in self.constraints:\n            if isinstance(constraint, RelativeMagneticConstraint):\n                constraint.update_target(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self.A is None):\n            self.build_control_matrix()\n            self.build_target()\n\n        self.build_background()\n        self.build_weight_matrix()\n\n    def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint set.\n        \"\"\"\n        return sum([len(c) for c in self.constraints])\n\n    def get_weighted_arrays(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Get [A] and [b] scaled by weight matrix.\n        Weight matrix assumed to be diagonal.\n        \"\"\"\n        weights = self.w\n        weighted_a = weights[:, np.newaxis] * self.A\n        weighted_b = weights * self.b\n        return weights, weighted_a, weighted_b\n\n    def build_weight_matrix(self):\n        \"\"\"\n        Build the weight matrix used in optimisation.\n        Assumed to be diagonal.\n        \"\"\"\n        self.w = np.zeros(len(self))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.w[i : i + n] = constraint.weights\n            i += n\n\n    def build_control_matrix(self):\n        \"\"\"\n        Build the control response matrix used in optimisation.\n        \"\"\"\n        self.A = np.zeros((len(self), len(self.coilset.control)))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.A[i : i + n, :] = constraint.control_response(self.coilset)\n            i += n\n\n    def build_target(self):\n        \"\"\"\n        Build the target value vector.\n        \"\"\"\n        self.target = np.zeros(len(self))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.target[i : i + n] = constraint.target_value * np.ones(n)\n            i += n\n\n    def build_background(self):\n        \"\"\"\n        Build the background value vector.\n        \"\"\"\n        self.background = np.zeros(len(self))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.background[i : i + n] = constraint.evaluate(self.eq)\n            i += n\n\n    @property\n    def b(self) -> np.ndarray:\n        \"\"\"\n        The b vector of target - background values.\n        \"\"\"\n        return self.target - self.background\n\n    def update_psi_boundary(self, psi_bndry: float):\n        \"\"\"\n        Update the target value for all PsiBoundaryConstraints.\n\n        Parameters\n        ----------\n        psi_bndry:\n            The target psi boundary value [V.s/rad]\n        \"\"\"\n        for constraint in self.constraints:\n            if isinstance(constraint, PsiBoundaryConstraint):\n                constraint.target_value = psi_bndry\n        self.build_target()\n\n    def plot(self, ax=None):\n        \"\"\"\n        Plots constraints\n        \"\"\"\n        return ConstraintPlotter(self, ax=ax)",
  "class AutoConstraints(MagneticConstraintSet):\n    \"\"\"\n    Utility class for crude reconstruction of magnetic constraints from a\n    specified LCFS set of coordinates.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates of the LCFS\n    z:\n        The z coordinates of the LCFS\n    psi_boundary:\n        The psi boundary value to use as a constraint. If None, an\n        isoflux constraint is used.\n    n_points:\n        The number of interpolated points to use\n    \"\"\"\n\n    def __init__(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        psi_boundary: Optional[float] = None,\n        n_points: int = 40,\n    ):\n        x = np.array(x)\n        z = np.array(z)\n        z_max = max(z)\n        z_min = min(z)\n        x_z_max = x[np.argmax(z)]\n        x_z_min = x[np.argmin(z)]\n\n        # Determine if we are dealing with SN or DN\n        single_null = abs_rel_difference(abs(z_min), z_max) > 0.05\n\n        if single_null:\n            # Determine if it is an upper or lower SN\n            lower = abs(z_min) > z_max\n\n            if lower:\n                constraints = [FieldNullConstraint(x_z_min, z_min)]\n            else:\n                constraints = [FieldNullConstraint(x_z_max, z_max)]\n\n        else:\n            constraints = [\n                FieldNullConstraint(x_z_min, z_min),\n                FieldNullConstraint(x_z_max, z_max),\n            ]\n\n        # Interpolate some points on the LCFS\n        x_boundary, _, z_boundary = interpolate_points(x, np.zeros_like[x], z, n_points)\n\n        # Apply an appropriate constraint on the LCFS\n        if psi_boundary is None:\n            arg_inner = np.argmin(x_boundary**2 + z_boundary**2)\n            ref_x = x_boundary[arg_inner]\n            ref_z = z_boundary[arg_inner]\n\n            constraints.append(IsofluxConstraint(x_boundary, z_boundary, ref_x, ref_z))\n\n        else:\n            constraints.append(\n                PsiBoundaryConstraint(x_boundary, z_boundary, psi_boundary)\n            )\n        super().__init__(constraints)",
  "def prepare(self, equilibrium: Equilibrium, I_not_dI=False, fixed_coils=False):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        pass",
  "def control_response(self, coilset: CoilSet):\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        pass",
  "def evaluate(self, equilibrium: Equilibrium):\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        pass",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        B_max: Union[float, np.ndarray],\n        tolerance: Union[float, np.ndarray] = 1.0e-6,\n        constraint_type: str = \"inequality\",\n    ):\n        if is_num(x):\n            x = np.array([x])\n        if is_num(z):\n            z = np.array([z])\n\n        if is_num(B_max):\n            B_max = B_max * np.ones(len(x))\n        if len(B_max) != len(x):\n            raise ValueError(\n                \"Maximum field vector length not equal to the number of points.\"\n            )\n\n        if is_num(tolerance):\n            tolerance = tolerance * np.ones(len(x))\n        if len(tolerance) != len(x):\n            raise ValueError(\"Tolerance vector length not equal to the number of coils.\")\n\n        self.x = x\n        self.z = z\n        super().__init__(\n            f_constraint=field_constraints,\n            f_constraint_args={\n                \"ax_mat\": None,\n                \"az_mat\": None,\n                \"bxp_vec\": None,\n                \"bzp_vec\": None,\n                \"B_max\": B_max,\n                \"scale\": 1.0,\n            },\n            tolerance=tolerance,\n            constraint_type=constraint_type,\n        )",
  "def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"ax_mat\"] is None):\n            ax_mat, az_mat = self.control_response(equilibrium.coilset)\n            self._args[\"ax_mat\"] = ax_mat\n            self._args[\"az_mat\"] = az_mat\n\n        bxp_vec, bzp_vec = self.evaluate(equilibrium)\n        self._args[\"bxp_vec\"] = bxp_vec\n        self._args[\"bzp_vec\"] = bzp_vec",
  "def control_response(self, coilset: CoilSet) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return (\n            coilset.Bx_response(self.x, self.z, control=True),\n            coilset.Bz_response(self.x, self.z, control=True),\n        )",
  "def evaluate(self, equilibrium: Equilibrium) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        Bx, Bz = np.zeros(len(self)), np.zeros(len(self))\n        Bx = equilibrium.Bx(self.x, self.z)\n        Bz = equilibrium.Bz(self.x, self.z)\n        return Bx, Bz",
  "def __len__(self) -> int:\n        \"\"\"\n        Length of field constraints.\n        \"\"\"\n        return len(self.x)",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        B_max: Union[float, np.ndarray],\n        tolerance: Union[float, np.ndarray] = 1.0e-6,\n    ):\n        n_coils = coilset.n_coils()\n        if is_num(B_max):\n            B_max = B_max * np.ones(n_coils)\n        if len(B_max) != n_coils:\n            raise ValueError(\n                \"Maximum field vector length not equal to the number of coils.\"\n            )\n\n        if is_num(tolerance):\n            tolerance = tolerance * np.ones(n_coils)\n        if len(tolerance) != n_coils:\n            raise ValueError(\"Tolerance vector length not equal to the number of coils.\")\n\n        x, z = self._get_constraint_points(coilset)\n\n        super().__init__(x, z, B_max, tolerance=tolerance, constraint_type=\"inequality\")",
  "def _get_constraint_points(coilset):\n        return coilset.x - coilset.dx, coilset.z",
  "def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"ax_mat\"] is None):\n            # Update the target points for the constraints (the coils may be moving)\n            self.x, self.z = self._get_constraint_points(equilibrium.coilset)\n            ax_mat, az_mat = self.control_response(equilibrium.coilset)\n            self._args[\"ax_mat\"] = ax_mat\n            self._args[\"az_mat\"] = az_mat\n\n        bxp_vec, bzp_vec = self.evaluate(equilibrium)\n        self._args[\"bxp_vec\"] = bxp_vec\n        self._args[\"bzp_vec\"] = bzp_vec",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        PF_Fz_max: float,\n        CS_Fz_sum_max: float,\n        CS_Fz_sep_max: float,\n        tolerance: Union[float, np.ndarray] = 1.0e-6,\n    ):\n        n_PF = coilset.n_coils(\"PF\")\n        n_CS = coilset.n_coils(\"CS\")\n        n_f_constraints = n_PF + n_CS\n\n        if is_num(tolerance):\n            tolerance = tolerance * np.ones(n_f_constraints)\n        elif len(tolerance) != n_f_constraints:\n            raise ValueError(f\"Tolerance vector not of length {n_f_constraints}\")\n\n        super().__init__(\n            f_constraint=coil_force_constraints,\n            f_constraint_args={\n                \"a_mat\": None,\n                \"b_vec\": None,\n                \"scale\": 1.0,\n                \"PF_Fz_max\": PF_Fz_max,\n                \"CS_Fz_sum_max\": CS_Fz_sum_max,\n                \"CS_Fz_sep_max\": CS_Fz_sep_max,\n                \"n_PF\": n_PF,\n                \"n_CS\": n_CS,\n            },\n            tolerance=tolerance,\n        )",
  "def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"a_mat\"] is None):\n            self._args[\"a_mat\"] = self.control_response(equilibrium.coilset)\n\n        self._args[\"b_vec\"] = self.evaluate(equilibrium)",
  "def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.control_F(coilset)",
  "def evaluate(self, equilibrium: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        fp = np.zeros((equilibrium.coilset.n_coils(), 2))\n        current = equilibrium.coilset.current\n        non_zero = np.where(current != 0)[0]\n        if non_zero.size:\n            fp[non_zero] = (\n                equilibrium.coilset.F(equilibrium)[non_zero] / current[non_zero][:, None]\n            )\n        return fp",
  "def __init__(\n        self,\n        target_value: float = 0.0,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n        f_constraint: Callable[[np.ndarray], np.ndarray] = L2_norm_constraint,\n        constraint_type: str = \"inequality\",\n    ):\n        self.target_value = target_value * np.ones(len(self))\n        if is_num(tolerance):\n            if f_constraint == L2_norm_constraint:\n                tolerance = tolerance * np.ones(1)\n            else:\n                tolerance = tolerance * np.ones(len(self))\n        self.weights = weights\n        args = {\"a_mat\": None, \"b_vec\": None, \"value\": 0.0, \"scale\": 1.0}\n        super().__init__(\n            f_constraint=f_constraint,\n            f_constraint_args=args,\n            tolerance=tolerance,\n            constraint_type=constraint_type,\n        )",
  "def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):  # noqa :N803\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"a_mat\"] is None):\n            self._args[\"a_mat\"] = self.control_response(equilibrium.coilset)\n\n        self.update_target(equilibrium)\n        self._args[\"b_vec\"] = self.target_value - self.evaluate(equilibrium)",
  "def update_target(self, equilibrium: Equilibrium):\n        \"\"\"\n        Update the target value of the magnetic constraint.\n        \"\"\"\n        pass",
  "def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        pass",
  "def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint.\n\n        Notes\n        -----\n        Length of the array if an array is specified, otherwise 1 for a float.\n        \"\"\"\n        return len(self.x) if hasattr(self.x, \"__len__\") else 1",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        target_value: float,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n        f_constraint: Callable[[np.ndarray], np.ndarray] = Ax_b_constraint,\n        constraint_type: str = \"equality\",\n    ):\n        self.x = x\n        self.z = z\n        super().__init__(\n            target_value,\n            weights,\n            tolerance=tolerance,\n            f_constraint=f_constraint,\n            constraint_type=constraint_type,\n        )",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        ref_x: float,\n        ref_z: float,\n        constraint_value: float = 0.0,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n        f_constraint: Callable[[np.ndarray], np.ndarray] = L2_norm_constraint,\n        constraint_type: str = \"inequality\",\n    ):\n        self.x = x\n        self.z = z\n        self.ref_x = ref_x\n        self.ref_z = ref_z\n        super().__init__(\n            0.0,\n            weights,\n            tolerance=tolerance,\n            f_constraint=f_constraint,\n            constraint_type=constraint_type,\n        )\n        self._args[\"value\"] = constraint_value",
  "def update_target(self, equilibrium: Equilibrium):\n        \"\"\"\n        Update the target value of the magnetic constraint.\n        \"\"\"\n        pass",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: float = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            target_value=0.0,\n            weights=weights,\n            tolerance=tolerance,\n            constraint_type=\"inequality\",\n            f_constraint=L2_norm_constraint,\n        )",
  "def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return np.vstack(\n            [\n                coilset.Bx_response(self.x, self.z, control=True),\n                coilset.Bz_response(self.x, self.z, control=True),\n            ]\n        )",
  "def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return np.array([eq.Bx(self.x, self.z), eq.Bz(self.x, self.z)])",
  "def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\n            \"marker\": \"X\",\n            \"color\": \"b\",\n            \"markersize\": 10,\n            \"zorder\": 45,\n            \"linestyle\": \"None\",\n        }\n        ax.plot(self.x, self.z, **kwargs)",
  "def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint.\n        \"\"\"\n        return 2",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        target_value: float,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            target_value,\n            weights=weights,\n            tolerance=tolerance,\n            f_constraint=Ax_b_constraint,\n            constraint_type=\"equality\",\n        )",
  "def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.psi_response(self.x, self.z, control=True)",
  "def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return eq.psi(self.x, self.z)",
  "def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\"marker\": \"s\", \"markersize\": 8, \"color\": \"b\", \"linestyle\": \"None\"}\n        ax.plot(self.x, self.z, **kwargs)",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        ref_x: float,\n        ref_z: float,\n        constraint_value: float = 0.0,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: float = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            ref_x,\n            ref_z,\n            constraint_value,\n            weights=weights,\n            f_constraint=L2_norm_constraint,\n            tolerance=tolerance,\n            constraint_type=\"inequality\",\n        )",
  "def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.psi_response(self.x, self.z, control=True) - coilset.psi_response(\n            self.ref_x, self.ref_z, control=True\n        )",
  "def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return eq.psi(self.x, self.z)",
  "def update_target(self, eq: Equilibrium):\n        \"\"\"\n        We need to update the target value, as it is a relative constraint.\n        \"\"\"\n        self.target_value = float(eq.psi(self.ref_x, self.ref_z))",
  "def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\n            \"marker\": \"o\",\n            \"markeredgewidth\": 3,\n            \"markeredgecolor\": \"b\",\n            \"markersize\": 10,\n            \"linestyle\": \"None\",\n            \"markerfacecolor\": \"None\",\n            \"zorder\": 45,\n        }\n        ax.plot(self.x, self.z, **kwargs)\n        kwargs[\"markeredgewidth\"] = 5\n        ax.plot(self.ref_x, self.ref_z, **kwargs)",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        target_value: float,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            target_value,\n            weights,\n            tolerance,\n            f_constraint=L2_norm_constraint,\n            constraint_type=\"inequality\",\n        )",
  "def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.psi_response(self.x, self.z, control=True)",
  "def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return eq.psi(self.x, self.z)",
  "def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\"marker\": \"o\", \"markersize\": 8, \"color\": \"b\", \"linestyle\": \"None\"}\n        ax.plot(self.x, self.z, **kwargs)",
  "def __init__(self, constraints: List[MagneticConstraint]):\n        self.constraints = constraints\n        self.eq = None\n        self.A = None\n        self.target = None\n        self.background = None",
  "def __call__(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):  # noqa :N803\n        \"\"\"\n        Update the MagneticConstraintSet\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        self.eq = equilibrium\n        self.coilset = equilibrium.coilset\n\n        # Update relative magnetic constraints without updating A matrix\n        for constraint in self.constraints:\n            if isinstance(constraint, RelativeMagneticConstraint):\n                constraint.update_target(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self.A is None):\n            self.build_control_matrix()\n            self.build_target()\n\n        self.build_background()\n        self.build_weight_matrix()",
  "def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint set.\n        \"\"\"\n        return sum([len(c) for c in self.constraints])",
  "def get_weighted_arrays(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Get [A] and [b] scaled by weight matrix.\n        Weight matrix assumed to be diagonal.\n        \"\"\"\n        weights = self.w\n        weighted_a = weights[:, np.newaxis] * self.A\n        weighted_b = weights * self.b\n        return weights, weighted_a, weighted_b",
  "def build_weight_matrix(self):\n        \"\"\"\n        Build the weight matrix used in optimisation.\n        Assumed to be diagonal.\n        \"\"\"\n        self.w = np.zeros(len(self))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.w[i : i + n] = constraint.weights\n            i += n",
  "def build_control_matrix(self):\n        \"\"\"\n        Build the control response matrix used in optimisation.\n        \"\"\"\n        self.A = np.zeros((len(self), len(self.coilset.control)))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.A[i : i + n, :] = constraint.control_response(self.coilset)\n            i += n",
  "def build_target(self):\n        \"\"\"\n        Build the target value vector.\n        \"\"\"\n        self.target = np.zeros(len(self))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.target[i : i + n] = constraint.target_value * np.ones(n)\n            i += n",
  "def build_background(self):\n        \"\"\"\n        Build the background value vector.\n        \"\"\"\n        self.background = np.zeros(len(self))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.background[i : i + n] = constraint.evaluate(self.eq)\n            i += n",
  "def b(self) -> np.ndarray:\n        \"\"\"\n        The b vector of target - background values.\n        \"\"\"\n        return self.target - self.background",
  "def update_psi_boundary(self, psi_bndry: float):\n        \"\"\"\n        Update the target value for all PsiBoundaryConstraints.\n\n        Parameters\n        ----------\n        psi_bndry:\n            The target psi boundary value [V.s/rad]\n        \"\"\"\n        for constraint in self.constraints:\n            if isinstance(constraint, PsiBoundaryConstraint):\n                constraint.target_value = psi_bndry\n        self.build_target()",
  "def plot(self, ax=None):\n        \"\"\"\n        Plots constraints\n        \"\"\"\n        return ConstraintPlotter(self, ax=ax)",
  "def __init__(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        psi_boundary: Optional[float] = None,\n        n_points: int = 40,\n    ):\n        x = np.array(x)\n        z = np.array(z)\n        z_max = max(z)\n        z_min = min(z)\n        x_z_max = x[np.argmax(z)]\n        x_z_min = x[np.argmin(z)]\n\n        # Determine if we are dealing with SN or DN\n        single_null = abs_rel_difference(abs(z_min), z_max) > 0.05\n\n        if single_null:\n            # Determine if it is an upper or lower SN\n            lower = abs(z_min) > z_max\n\n            if lower:\n                constraints = [FieldNullConstraint(x_z_min, z_min)]\n            else:\n                constraints = [FieldNullConstraint(x_z_max, z_max)]\n\n        else:\n            constraints = [\n                FieldNullConstraint(x_z_min, z_min),\n                FieldNullConstraint(x_z_max, z_max),\n            ]\n\n        # Interpolate some points on the LCFS\n        x_boundary, _, z_boundary = interpolate_points(x, np.zeros_like[x], z, n_points)\n\n        # Apply an appropriate constraint on the LCFS\n        if psi_boundary is None:\n            arg_inner = np.argmin(x_boundary**2 + z_boundary**2)\n            ref_x = x_boundary[arg_inner]\n            ref_z = z_boundary[arg_inner]\n\n            constraints.append(IsofluxConstraint(x_boundary, z_boundary, ref_x, ref_z))\n\n        else:\n            constraints.append(\n                PsiBoundaryConstraint(x_boundary, z_boundary, psi_boundary)\n            )\n        super().__init__(constraints)",
  "class Limiter:\n    \"\"\"\n    A set of discrete limiter points.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates of the limiter points\n    z:\n        The z coordinates of the limiter points\n    \"\"\"\n\n    __slots__ = [\"x\", \"z\", \"xz\", \"_i\"]\n\n    def __init__(self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]):\n        self.x = x\n        self.z = z\n        self.xz = cycle(np.array([x, z]).T)\n        self._i = 0\n\n    def __iter__(self):\n        \"\"\"\n        Hacky phoenix iterator\n        \"\"\"\n        i = 0\n        while i < len(self):\n            yield next(self.xz)\n            i += 1\n\n    def __len__(self) -> int:\n        \"\"\"\n        The length of the limiter.\n        \"\"\"\n        return len(self.x)\n\n    def __next__(self):\n        \"\"\"\n        Hacky phoenix iterator\n        \"\"\"\n        if self._i >= len(self):\n            raise StopIteration\n        self._i += 1\n        return next(self.xz[self._i - 1])\n\n    def plot(self, ax: Optional[Axes] = None):\n        \"\"\"\n        Plots the Limiter object\n        \"\"\"\n        return LimiterPlotter(self, ax)",
  "def __init__(self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]):\n        self.x = x\n        self.z = z\n        self.xz = cycle(np.array([x, z]).T)\n        self._i = 0",
  "def __iter__(self):\n        \"\"\"\n        Hacky phoenix iterator\n        \"\"\"\n        i = 0\n        while i < len(self):\n            yield next(self.xz)\n            i += 1",
  "def __len__(self) -> int:\n        \"\"\"\n        The length of the limiter.\n        \"\"\"\n        return len(self.x)",
  "def __next__(self):\n        \"\"\"\n        Hacky phoenix iterator\n        \"\"\"\n        if self._i >= len(self):\n            raise StopIteration\n        self._i += 1\n        return next(self.xz[self._i - 1])",
  "def plot(self, ax: Optional[Axes] = None):\n        \"\"\"\n        Plots the Limiter object\n        \"\"\"\n        return LimiterPlotter(self, ax)",
  "class FreeBoundary:\n    \"\"\"\n    Object representing a free boundary condition, accounting for only the\n    plasma psi\n\n    Parameters\n    ----------\n    grid:\n        The grid upon which to apply the free Dirichlet boundary condition\n    \"\"\"\n\n    __slots__ = [\"dx\", \"dz\", \"edges\", \"f_greens\"]\n\n    def __init__(self, grid: Grid):\n        x, z = grid.x, grid.z\n        self.dx, self.dz = grid.dx, grid.dz\n        self.edges = grid.edges\n\n        values = np.zeros((len(self.edges), grid.nx, grid.nz))\n        for i, (j, k) in enumerate(self.edges):\n            g = greens_psi(x, z, x[j, k], z[j, k])\n            g[j, k] = 0  # Drop NaNs\n            values[i] = g\n        self.f_greens = values\n\n    def __call__(self, psi: np.ndarray, jtor: np.ndarray):\n        \"\"\"\n        Applies a free boundary (Dirichlet) condition using Green's functions\n\n        Parameters\n        ----------\n        psi:\n            The poloidal magnetic flux [V.s/rad]\n        jtor:\n            The toroidal current density in the plasma [A/m^2]\n\n        Note\n        ----\n        Modifies psi in-place\n        \"\"\"\n        for i, (j, k) in enumerate(self.edges):\n            psi[j, k] = integrate_dx_dz(self.f_greens[i] * jtor, self.dx, self.dz)",
  "def apply_boundary(rhs: np.ndarray, lhs: Union[float, np.ndarray]):\n    \"\"\"\n    Applies a boundary constraint to the boundaries of an array for use on finite\n    difference grids.\n\n    Parameters\n    ----------\n    rhs:\n        The right-hand-side of the equality\n    lhs:\n        The left-hand-side of the equality\n        If 0, will apply a fixed boundary condition of 0 to the rhs\n\n    Note\n    ----\n    Modified rhs in-place; applying lhs boundary condition\n    \"\"\"\n    if is_num(lhs):\n        # Usually used to apply a 0 boundary condition\n        rhs[0, :] = lhs\n        rhs[:, 0] = lhs\n        rhs[-1, :] = lhs\n        rhs[:, -1] = lhs\n    else:\n        rhs[0, :] = lhs[0, :]\n        rhs[:, 0] = lhs[:, 0]\n        rhs[-1, :] = lhs[-1, :]\n        rhs[:, -1] = lhs[:, -1]",
  "def __init__(self, grid: Grid):\n        x, z = grid.x, grid.z\n        self.dx, self.dz = grid.dx, grid.dz\n        self.edges = grid.edges\n\n        values = np.zeros((len(self.edges), grid.nx, grid.nz))\n        for i, (j, k) in enumerate(self.edges):\n            g = greens_psi(x, z, x[j, k], z[j, k])\n            g[j, k] = 0  # Drop NaNs\n            values[i] = g\n        self.f_greens = values",
  "def __call__(self, psi: np.ndarray, jtor: np.ndarray):\n        \"\"\"\n        Applies a free boundary (Dirichlet) condition using Green's functions\n\n        Parameters\n        ----------\n        psi:\n            The poloidal magnetic flux [V.s/rad]\n        jtor:\n            The toroidal current density in the plasma [A/m^2]\n\n        Note\n        ----\n        Modifies psi in-place\n        \"\"\"\n        for i, (j, k) in enumerate(self.edges):\n            psi[j, k] = integrate_dx_dz(self.f_greens[i] * jtor, self.dx, self.dz)",
  "class DummyController:\n    \"\"\"\n    Dummy control object to enable calculations to take place with no numerical\n    vertical control scheme.\n\n    psi() returns np.zeros(eq.psi.shape)\n    \"\"\"\n\n    def __init__(self, psi: np.ndarray):\n        self._shape = psi.shape\n\n    def stabilise(self, *args):\n        \"\"\"\n        Dummy method to retain procedures with no effect on the equilibria.\n        \"\"\"\n        pass\n\n    def psi(self) -> np.ndarray:\n        \"\"\"\n        Dummy method to retain procedures with no effect on the equilibria.\n        \"\"\"\n        return np.zeros(self._shape)\n\n    def Bx(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Dummy method to retain procedures with no effect on the equilibria.\n        \"\"\"\n        try:\n            float(x)\n            return 0.0\n        except TypeError:\n            return np.zeros_like(x)\n\n    def Bz(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Dummy method to retain procedures with no effect on the equilibria.\n        \"\"\"\n        try:\n            float(x)\n            return 0.0\n        except TypeError:\n            return np.zeros_like(x)",
  "class VirtualController(CoilGroup):\n    \"\"\"\n    Represents a pair of virtual coils for the numerical vertical control of\n    the plasma, as described in Jeon, 2015: https://link.springer.com/10.3938/jkps.67.843\n\n    It does work to some extent (perhaps I've implemented it incorrectly). It\n    seems to fall over for large numerical instabilities.\n    \"\"\"\n\n    def __init__(self, eq: Equilibrium, gz: float = 1.5):\n        self.eq = eq\n        self.coilset = eq.coilset\n        self.Xc = (self.eq.grid.x_min + self.eq.grid.x_max) / 2\n        self.Zc = self.eq.grid.z_max + 2  # outside computational domain\n        self.gz = gz\n        self._pgreen = self.psi_response(self.eq.x, self.eq.z)\n        super().__init__(\n            Coil(self.Xc, self.Zc, current=1, name=\"V1\", ctype=\"NONE\"),\n            Coil(self.Xc, -self.Zc, current=1, name=\"V2\", ctype=\"NONE\"),\n        )\n\n    def feedback_current(self) -> np.ndarray:\n        \"\"\"\n        Calculate feedback currents to compensate for a radial field at the\n        centre of the plasma. (Vertical stability)\n\n        \\t:math:`I_{feedback}=-g_{z}\\\\dfrac{B_{X,vac}}{B_{X,feedback}}`\n        \\t:math:`\\\\Bigr|_{\\\\substack{X_{cur}, Z_{cur}}}`\n        \"\"\"\n        xcur, zcur = self.eq.effective_centre()\n\n        return -self.gz * self.coilset.Bx(xcur, zcur) / self.control_Bx(xcur, zcur)\n\n    def adjust_currents(self, d_current: float):\n        \"\"\"\n        Adjust the currents in the virtual control coils.\n        \"\"\"\n        self.current = self.current + d_current\n\n    def stabilise(self):\n        \"\"\"\n        Stabilise the equilibrium, calculating the feedback currents and applying\n        them to the control coils.\n        \"\"\"\n        currents = self.feedback_current()\n        self.adjust_currents(currents)\n\n    def psi(self) -> np.ndarray:\n        \"\"\"\n        Get the psi array of the VirtualController\n        \"\"\"\n        return self.current * self._pgreen",
  "def __init__(self, psi: np.ndarray):\n        self._shape = psi.shape",
  "def stabilise(self, *args):\n        \"\"\"\n        Dummy method to retain procedures with no effect on the equilibria.\n        \"\"\"\n        pass",
  "def psi(self) -> np.ndarray:\n        \"\"\"\n        Dummy method to retain procedures with no effect on the equilibria.\n        \"\"\"\n        return np.zeros(self._shape)",
  "def Bx(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Dummy method to retain procedures with no effect on the equilibria.\n        \"\"\"\n        try:\n            float(x)\n            return 0.0\n        except TypeError:\n            return np.zeros_like(x)",
  "def Bz(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Dummy method to retain procedures with no effect on the equilibria.\n        \"\"\"\n        try:\n            float(x)\n            return 0.0\n        except TypeError:\n            return np.zeros_like(x)",
  "def __init__(self, eq: Equilibrium, gz: float = 1.5):\n        self.eq = eq\n        self.coilset = eq.coilset\n        self.Xc = (self.eq.grid.x_min + self.eq.grid.x_max) / 2\n        self.Zc = self.eq.grid.z_max + 2  # outside computational domain\n        self.gz = gz\n        self._pgreen = self.psi_response(self.eq.x, self.eq.z)\n        super().__init__(\n            Coil(self.Xc, self.Zc, current=1, name=\"V1\", ctype=\"NONE\"),\n            Coil(self.Xc, -self.Zc, current=1, name=\"V2\", ctype=\"NONE\"),\n        )",
  "def feedback_current(self) -> np.ndarray:\n        \"\"\"\n        Calculate feedback currents to compensate for a radial field at the\n        centre of the plasma. (Vertical stability)\n\n        \\t:math:`I_{feedback}=-g_{z}\\\\dfrac{B_{X,vac}}{B_{X,feedback}}`\n        \\t:math:`\\\\Bigr|_{\\\\substack{X_{cur}, Z_{cur}}}`\n        \"\"\"\n        xcur, zcur = self.eq.effective_centre()\n\n        return -self.gz * self.coilset.Bx(xcur, zcur) / self.control_Bx(xcur, zcur)",
  "def adjust_currents(self, d_current: float):\n        \"\"\"\n        Adjust the currents in the virtual control coils.\n        \"\"\"\n        self.current = self.current + d_current",
  "def stabilise(self):\n        \"\"\"\n        Stabilise the equilibrium, calculating the feedback currents and applying\n        them to the control coils.\n        \"\"\"\n        currents = self.feedback_current()\n        self.adjust_currents(currents)",
  "def psi(self) -> np.ndarray:\n        \"\"\"\n        Get the psi array of the VirtualController\n        \"\"\"\n        return self.current * self._pgreen",
  "class Plotter:\n    \"\"\"\n    Utility plotter abstract object\n    \"\"\"\n\n    def __init__(self, ax=None, **kwargs):\n        for kwarg in kwargs:\n            if kwarg not in PLOT_DEFAULTS:\n                bluemira_warn(f\"Unrecognised plot kwarg: {kwarg}\")\n\n        if ax is None:\n            f, self.ax = plt.subplots()\n        else:\n            self.ax = ax\n        self.ax.set_xlabel(\"$x$ [m]\")\n        self.ax.set_ylabel(\"$z$ [m]\")\n        self.ax.set_aspect(\"equal\")",
  "class GridPlotter(Plotter):\n    \"\"\"\n    Utility class for plotting Grid objects\n    \"\"\"\n\n    def __init__(self, grid, ax=None, edge=False, **kwargs):\n        super().__init__(ax)\n        self.grid = grid\n        self.plot_grid(**kwargs)\n        if edge:\n            self.plot_edge(**kwargs)\n\n    def plot_grid(self, **kwargs):\n        \"\"\"\n        Plots the gridlines of the grid\n        \"\"\"\n        lw = kwargs.get(\"linewidth\", PLOT_DEFAULTS[\"grid\"][\"linewidth\"])\n        color = kwargs.get(\"color\", PLOT_DEFAULTS[\"grid\"][\"color\"])\n        for i in self.grid.x_1d:\n            self.ax.plot([i, i], [self.grid.z_min, self.grid.z_max], color, linewidth=lw)\n        for i in self.grid.z_1d:\n            self.ax.plot([self.grid.x_min, self.grid.x_max], [i, i], color, linewidth=lw)\n\n    def plot_edge(self, **kwargs):\n        \"\"\"\n        Plots a thicker boundary edge for the grid\n        \"\"\"\n        lw = kwargs.get(\"edgewidth\", PLOT_DEFAULTS[\"grid\"][\"edgewidth\"])\n        color = kwargs.get(\"color\", PLOT_DEFAULTS[\"grid\"][\"color\"])\n        self.ax.plot(*self.grid.bounds, color, linewidth=lw)",
  "class ConstraintPlotter(Plotter):\n    \"\"\"\n    Utility class for Constraint plotting.\n    \"\"\"\n\n    def __init__(self, constraint_set, ax=None):\n        super().__init__(ax)\n        self.constraint_set = constraint_set\n\n        for constraint in self.constraint_set.constraints:\n            constraint.plot(self.ax)",
  "class LimiterPlotter(Plotter):\n    \"\"\"\n    Utility class for plotting Limiter objects\n    \"\"\"\n\n    def __init__(self, limiter, ax=None, **kwargs):\n        super().__init__(ax)\n        self.limiter = limiter\n        self.plot_limiter(**kwargs)\n\n    def plot_limiter(self, **kwargs):\n        \"\"\"\n        Plot the limiter onto the Axes.\n        \"\"\"\n        color = kwargs.get(\"color\", PLOT_DEFAULTS[\"limiter\"][\"color\"])\n        marker = kwargs.get(\"marker\", PLOT_DEFAULTS[\"limiter\"][\"marker\"])\n        self.ax.plot(self.limiter.x, self.limiter.z, \"s\", color=color, marker=marker)",
  "class CoilGroupPlotter(Plotter):\n    \"\"\"\n    Utility class for plotting individual Coils (for checking / testing only)\n\n    Parameters\n    ----------\n    coil: CoilGroup\n        The Coil to be plotted\n    ax: Matplotlib axis object\n        The ax on which to plot the Coil. (plt.gca() default)\n    subcoil: bool\n        Whether or not to plot the Coil subcoils\n    label: bool\n        Whether or not to plot labels on the coils\n    force: None or np.array((1, 2))\n        Whether to plot force vectors, and if so the array of force vectors\n    \"\"\"\n\n    def __init__(self, coil, ax=None, subcoil=True, label=False, force=None, **kwargs):\n        super().__init__(ax)\n        self._cg = coil\n        self.colors = kwargs.pop(\"facecolor\", None)\n        self.linewidth = kwargs.pop(\"linewidth\", PLOT_DEFAULTS[\"coil\"][\"linewidth\"])\n        self.edgecolor = kwargs.pop(\"edgecolor\", PLOT_DEFAULTS[\"coil\"][\"edgecolor\"])\n        if \"alpha\" in kwargs:\n            # Alpha can be provided as a list or cycle to other systems, so make sure we\n            # support that here.\n            alpha = kwargs[\"alpha\"]\n            if isinstance(alpha, cycle):\n                kwargs[\"alpha\"] = next(alpha)\n            if isinstance(kwargs[\"alpha\"], list):\n                kwargs[\"alpha\"] = alpha[0]\n\n        self.plot_coil(subcoil=subcoil, label=label, force=force, **kwargs)\n        if label:  # Margins and labels fighting\n            self.ax.set_xlim(left=-2)\n            ymin, ymax = self.ax.get_ylim()\n            self.ax.set_ylim(bottom=ymin - 1)\n            self.ax.set_ylim(top=ymax + 1)\n\n    def plot_coil(self, subcoil, label=False, force=None, **kwargs):\n        \"\"\"\n        Plot a coil onto the Axes.\n        \"\"\"\n        centre, *arrays = self._plotting_array_shaping()\n\n        if subcoil:\n            qb = self._cg._quad_boundary\n            if isinstance(qb, tuple):\n                qb = [qb]\n\n        if force is not None:\n            d_fx, d_fz = force / M_PER_MN\n\n        for i, (x, z, dx, x_b, z_b, ct, n, cur, ctrl) in enumerate(zip(*arrays)):\n            if ctrl:\n                if self.colors is not None:\n                    if ct.name == \"PF\":\n                        kwargs[\"facecolor\"] = self.colors[0]\n                    elif ct.name == \"CS\":\n                        kwargs[\"facecolor\"] = self.colors[1]\n\n                self._plot_coil(\n                    x_b,\n                    z_b,\n                    ct,\n                    color=self.edgecolor,\n                    linewidth=self.linewidth,\n                    **kwargs,\n                )\n                if subcoil:\n                    _qx_b, _qz_b = qb[i]\n                    for ind in range(_qx_b.shape[0]):\n                        self._plot_coil(_qx_b[ind], _qz_b[ind], ct, fill=False, **kwargs)\n                if label:\n                    self._annotate_coil(x, z, dx, n, cur, ct, force=force, centre=centre)\n                if force is not None:\n                    self.ax.arrow(x, z, 0, d_fz[i], color=\"r\", width=0.1)\n            else:\n                self._plot_coil(x_b, z_b, ct, **kwargs)\n\n    def _plotting_array_shaping(self):\n        \"\"\"\n        Shape arrays to account for single coils or groups of coils\n        \"\"\"\n        xx = np.atleast_1d(self._cg.x)\n        control_ind = np.zeros_like(xx, dtype=bool)\n\n        if hasattr(self._cg, \"_control_ind\"):\n            control = self._cg._control_ind\n            centre = self._get_centre()\n        else:\n            control = slice(None)\n            centre = None\n\n        control_ind[control] = True\n\n        return (\n            centre,\n            xx,\n            np.atleast_1d(self._cg.z),\n            np.atleast_1d(self._cg.dx),\n            np.atleast_2d(self._cg.x_boundary),\n            np.atleast_2d(self._cg.z_boundary),\n            np.atleast_1d(self._cg.ctype).tolist(),\n            np.atleast_1d(self._cg.name).tolist(),\n            np.atleast_1d(self._cg.current),\n            control_ind,\n        )\n\n    def _get_centre(self):\n        \"\"\"\n        Get a \"centre\" position for the coils to arrange the labels.\n        \"\"\"\n        try:\n            x, z = self._cg.get_control_coils().position\n            xc = (max(x) + min(x)) / 2\n            zc = (max(z) + min(z)) / 2\n            return xc, zc\n        except AttributeError:\n            # Not a coilset\n            return None\n\n    def _annotate_coil(self, x, z, dx, name, current, ctype, force=None, centre=None):\n        \"\"\"\n        Single coil annotation utility function\n        \"\"\"\n        off = max(0.2, dx + 0.02)\n        if ctype.name == \"CS\":\n            drs = -1.5 * off\n            ha = \"right\"\n        else:\n            drs = 2 * off\n            ha = \"left\"\n        text = \"\\n\".join([str_to_latex(name), f\"{raw_uc(current, 'A', 'MA'):.2f} MA\"])\n        if force is not None:\n            text = \"\\n\".join([text, f\"{raw_uc(force[1], 'N', 'MN'):.2f} MN\"])\n        x = float(x) + drs\n        z = float(z)\n        if centre is not None and ctype.name == \"PF\":\n            v = np.array([x - centre[0], z - centre[1]])\n            v /= np.sqrt(sum(v**2))\n            d = 1 + np.sqrt(2) * dx\n            x += d * v[0] - drs * 1.5\n            z += d * v[1]\n        self.ax.text(\n            x,\n            z,\n            text,\n            fontsize=PLOT_DEFAULTS[\"coil\"][\"fontsize\"],\n            ha=ha,\n            va=\"center\",\n            color=\"k\",\n            backgroundcolor=\"white\",\n            bbox={\n                \"boxstyle\": \"round\",\n                \"facecolor\": \"white\",\n                \"linewidth\": 1,\n                \"edgecolor\": \"k\",\n            },\n        )\n\n    def _plot_coil(self, x_boundary, z_boundary, ctype, fill=True, **kwargs):\n        \"\"\"\n        Single coil plot utility\n        \"\"\"\n        mask = kwargs.pop(\"mask\", True)\n\n        fcolor = kwargs.pop(\"facecolor\", PLOT_DEFAULTS[\"coil\"][\"facecolor\"][ctype.name])\n\n        color = kwargs.pop(\"edgecolor\", PLOT_DEFAULTS[\"coil\"][\"edgecolor\"])\n        linewidth = kwargs.pop(\"linewidth\", PLOT_DEFAULTS[\"coil\"][\"linewidth\"])\n        alpha = kwargs.pop(\"alpha\", PLOT_DEFAULTS[\"coil\"][\"alpha\"])\n\n        x = np.append(x_boundary, x_boundary[0])\n        z = np.append(z_boundary, z_boundary[0])\n\n        self.ax.plot(x, z, zorder=11, color=color, linewidth=linewidth)\n        if fill:\n            if mask:\n                self.ax.fill(x, z, color=\"w\", zorder=10, alpha=1)\n\n            self.ax.fill(x, z, zorder=10, color=fcolor, alpha=alpha)",
  "class PlasmaCoilPlotter(Plotter):\n    \"\"\"\n    Utility class for plotting PlasmaCoils\n\n    Parameters\n    ----------\n    plasma_coil: PlasmaCoil\n        The PlasmaCoil to be plotted\n    ax: Matplotlib axis object\n        The ax on which to plot the PlasmaCoil. (plt.gca() default)\n    \"\"\"\n\n    def __init__(self, plasma_coil, ax=None, **kwargs):\n        super().__init__(ax)\n        self.plasma_coil = plasma_coil\n        if self.plasma_coil._j_tor is None:\n            # No coils to plot\n            pass\n        else:\n            contour = get_contours(\n                self.plasma_coil._grid.x,\n                self.plasma_coil._grid.z,\n                self.plasma_coil._j_tor,\n                J_TOR_MIN,\n            )\n            x, z = contour[0].T\n            sq_x, sq_z = grid_2d_contour(x, z)\n\n            nlevels = kwargs.pop(\"nlevels\", PLOT_DEFAULTS[\"current\"][\"nlevels\"])\n            cmap = kwargs.pop(\"cmap\", PLOT_DEFAULTS[\"current\"][\"cmap\"])\n\n            levels = np.linspace(J_TOR_MIN, np.amax(self.plasma_coil._j_tor), nlevels)\n            self.ax.contourf(\n                self.plasma_coil._grid.x,\n                self.plasma_coil._grid.z,\n                self.plasma_coil._j_tor,\n                cmap=cmap,\n                levels=levels,\n            )\n            self.ax.plot(sq_x, sq_z, linewidth=1.5, color=\"k\")",
  "class EquilibriumPlotter(Plotter):\n    \"\"\"\n    Utility class for Equilibrium plotting\n    \"\"\"\n\n    def __init__(\n        self,\n        equilibrium,\n        ax=None,\n        plasma=False,\n        show_ox=True,\n        field=False,\n    ):\n        super().__init__(ax)\n        self.eq = equilibrium\n\n        # Do some housework\n        self.psi = self.eq.psi()\n\n        self.o_points, self.x_points = self.eq.get_OX_points(self.psi, force_update=True)\n\n        if self.x_points:\n            self.xp_psi = self.x_points[0][2]  # Psi at separatrix\n        else:\n            bluemira_warn(\n                \"No X-point found in plotted equilibrium. Cannot normalise psi.\"\n            )\n            self.xp_psi = np.amax(self.psi)\n\n        if self.o_points:\n            self.op_psi = self.o_points[0][2]  # Psi at O-point\n        else:\n            bluemira_warn(\n                \"No O-point found in plotted equilibrium. Cannot normalise psi.\"\n            )\n            self.op_psi = np.amin(self.psi)\n\n        if not field:\n            self.plot_plasma_current()\n            self.plot_psi()\n        else:\n            self.plot_Bp()\n\n        if self.o_points and self.x_points:\n            # Only plot if we can normalise psi\n            self.plot_separatrix()\n            self.plot_flux_surface(1.05, \"pink\")\n\n        if show_ox:\n            self.plot_X_points()\n            self.plot_O_points()\n\n        if plasma:\n            self.plot_plasma_coil()\n\n    def plot_Bp(self, **kwargs):\n        \"\"\"\n        Plots the poloidal field onto the Axes.\n        \"\"\"\n        nlevels = kwargs.pop(\"nlevels\", PLOT_DEFAULTS[\"field\"][\"nlevels\"])\n        cmap = kwargs.pop(\"cmap\", PLOT_DEFAULTS[\"field\"][\"cmap\"])\n\n        Bp = self.eq.Bp()\n        levels = np.linspace(1e-36, np.amax(Bp), nlevels)\n        c = self.ax.contourf(self.eq.x, self.eq.z, Bp, levels=levels, cmap=cmap)\n        cbar = plt.colorbar(c)\n        cbar.set_label(\"$B_{p}$ [T]\")\n\n    def plot_psi(self, **kwargs):\n        \"\"\"\n        Plot flux surfaces\n        \"\"\"\n        nlevels = kwargs.pop(\"nlevels\", PLOT_DEFAULTS[\"psi\"][\"nlevels\"])\n        cmap = kwargs.pop(\"cmap\", PLOT_DEFAULTS[\"psi\"][\"cmap\"])\n\n        levels = np.linspace(np.amin(self.psi), np.amax(self.psi), nlevels)\n        self.ax.contour(\n            self.eq.x, self.eq.z, self.psi, levels=levels, cmap=cmap, zorder=8\n        )\n\n    def plot_plasma_current(self, **kwargs):\n        \"\"\"\n        Plots flux surfaces inside plasma\n        \"\"\"\n        if self.eq._jtor is None:\n            return\n\n        nlevels = kwargs.pop(\"nlevels\", PLOT_DEFAULTS[\"current\"][\"nlevels\"])\n        cmap = kwargs.pop(\"cmap\", PLOT_DEFAULTS[\"current\"][\"cmap\"])\n\n        levels = np.linspace(J_TOR_MIN, np.amax(self.eq._jtor), nlevels)\n        self.ax.contourf(\n            self.eq.x, self.eq.z, self.eq._jtor, levels=levels, cmap=cmap, zorder=7\n        )\n\n    def plot_flux_surface(self, psi_norm, color=\"k\"):\n        \"\"\"\n        Plots a normalised flux surface relative to the separatrix with\n        increasing values going outwards from plasma core.\n        \"\"\"\n        psi = calc_psi(psi_norm, self.op_psi, self.xp_psi)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            self.ax.contour(\n                self.eq.x, self.eq.z, self.psi, levels=[psi], colors=color, zorder=9\n            )\n\n    def plot_separatrix(self):\n        \"\"\"\n        Plot the separatrix.\n        \"\"\"\n        try:\n            separatrix = self.eq.get_separatrix()\n        except Exception:\n            bluemira_warn(\"Unable to plot separatrix\")\n            return\n\n        if isinstance(separatrix, list):\n            coords = separatrix\n        else:\n            coords = [separatrix]\n\n        for coord in coords:\n            x, z = coord.xz\n            self.ax.plot(\n                x,\n                z,\n                color=PLOT_DEFAULTS[\"separatrix\"][\"color\"],\n                linewidth=PLOT_DEFAULTS[\"separatrix\"][\"linewidth\"],\n                zorder=9,\n            )\n\n    def plot_X_points(self):  # noqa :N802\n        \"\"\"\n        Plot X-points.\n        \"\"\"\n        for p in self.x_points:\n            if isinstance(p, Xpoint):\n                self.ax.plot(\n                    p.x,\n                    p.z,\n                    marker=PLOT_DEFAULTS[\"xpoint\"][\"marker\"],\n                    color=PLOT_DEFAULTS[\"xpoint\"][\"color\"],\n                    zorder=10,\n                )\n\n    def plot_O_points(self):  # noqa :N802\n        \"\"\"\n        Plot O-points.\n        \"\"\"\n        for p in self.o_points:\n            self.ax.plot(\n                p.x,\n                p.z,\n                marker=PLOT_DEFAULTS[\"opoint\"][\"marker\"],\n                color=PLOT_DEFAULTS[\"opoint\"][\"color\"],\n                zorder=10,\n            )\n\n    def plot_plasma_coil(self):\n        \"\"\"\n        Plot the plasma coil.\n        \"\"\"\n        PlasmaCoilPlotter(self.ax, self.eq.plasma_coil())",
  "class BreakdownPlotter(Plotter):\n    \"\"\"\n    Utility class for Breakdown plotting\n    \"\"\"\n\n    def __init__(self, breakdown, ax=None, Bp=False, B_breakdown=0.003):\n        super().__init__(ax)\n        self.bd = breakdown\n\n        self.psi = self.bd.psi()\n        self.psi_bd = self.bd.breakdown_psi\n        self.Bp = self.bd.Bp(self.bd.x, self.bd.z)\n\n        self.plot_contour()\n        self.plot_zone(B_breakdown)\n        if Bp:\n            self.plot_Bp()\n\n    def plot_contour(self):\n        \"\"\"\n        Plot flux surfaces.\n        \"\"\"\n        levels = np.linspace(self.psi_bd - 0.1, self.psi_bd, 3)\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            self.ax.contour(self.bd.x, self.bd.z, self.psi, levels=levels, colors=\"r\")\n\n    def plot_Bp(self, **kwargs):\n        \"\"\"\n        Plots the poloidal field onto the Axes.\n        \"\"\"\n        nlevels = kwargs.pop(\"nlevels\", PLOT_DEFAULTS[\"field\"][\"nlevels\"])\n        cmap = kwargs.pop(\"cmap\", PLOT_DEFAULTS[\"field\"][\"cmap\"])\n        levels = np.linspace(1e-36, np.amax(self.Bp), nlevels)\n        c = self.ax.contourf(self.bd.x, self.bd.z, self.Bp, levels=levels, cmap=cmap)\n        cbar = plt.colorbar(c)\n        cbar.set_label(\"$B_{p}$ [T]\")\n\n    def plot_zone(self, field):\n        \"\"\"\n        Plot the low field zones with a dashed line.\n        \"\"\"\n        colors = [\"b\"]\n        self.ax.contour(\n            self.bd.x,\n            self.bd.z,\n            self.Bp,\n            levels=[field],\n            colors=colors,\n            linestyles=\"dashed\",\n        )\n\n        if self.psi_bd is not None:\n            self.ax.set_title(\"$\\\\psi_{b}$ = \" + f\"{2*np.pi*self.psi_bd:.2f} V.s\")",
  "class XZLPlotter(Plotter):\n    \"\"\"\n    Utility class for plotting L constraints\n    \"\"\"\n\n    def __init__(self, xzl_mapper, ax=None):\n        super().__init__(ax)\n        self.xzl = xzl_mapper\n\n        for coords in self.xzl.excl_zones:\n            plot_coordinates(\n                coords, self.ax, fill=True, alpha=0.2, facecolor=\"r\", edgecolor=\"r\"\n            )\n\n        for coords in self.xzl.excl_loops:\n            plot_coordinates(\n                coords, self.ax, fill=False, edgecolor=\"r\", zorder=1, linestyle=\"--\"\n            )\n\n        for coords in self.xzl.incl_loops:\n            plot_coordinates(\n                coords, self.ax, fill=False, edgecolor=\"k\", zorder=1, linestyle=\"--\"\n            )",
  "class RegionPlotter(Plotter):\n    \"\"\"\n    Utility class for plotting 2-D L constraints\n    \"\"\"\n\n    def __init__(self, region_mapper, ax=None):\n        super().__init__(ax)\n        self.rmp = region_mapper\n\n        for intpltr in self.rmp.regions.values():\n            plot_coordinates(\n                intpltr.coords,\n                self.ax,\n                fill=True,\n                alpha=0.2,\n                zorder=1,\n                facecolor=\"g\",\n                edgecolor=\"g\",\n            )",
  "class CorePlotter(Plotter):\n    \"\"\"\n    Utility class for plotting equilibrium normalised radius characteristic\n    profiles.\n    \"\"\"\n\n    def __init__(self, results):\n        r, c = int((len(results.__dict__) - 1) / 2) + 1, 2\n        gs = GridSpec(r, c)\n        self.ax = [plt.subplot(gs[i]) for i in range(r * c)]\n        ccycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])\n        for i, (k, v) in enumerate(results.__dict__.items()):\n            color = next(ccycle)\n            self.ax[i].plot(results.psi_n, v, label=str_to_latex(k), color=color)\n            self.ax[i].legend()",
  "class CorePlotter2(Plotter):\n    \"\"\"\n    Utility class for plotting plasma equilibrium cross-core profiles.\n    \"\"\"\n\n    def __init__(self, eq):\n        jfunc = RectBivariateSpline(eq.x[:, 0], eq.z[0, :], eq._jtor)\n        p = eq.pressure_map()\n        pfunc = RectBivariateSpline(eq.x[:, 0], eq.z[0, :], p)\n        o_points, _ = eq.get_OX_points()\n        xmag, zmag = o_points[0].x, o_points[0].z\n        psia, psib = eq.get_OX_psis()\n        n = 50\n        xx = np.linspace(eq.grid.x_min, eq.grid.x_max, n)\n        zz = np.linspace(zmag, zmag, n)\n        gs = GridSpec(3, 1)\n        ccycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])\n\n        psi = eq.psi(xx, zz) * 2 * np.pi\n        self.ax = [plt.subplot(gs[i]) for i in range(3)]\n        self.ax[0].plot(xx, pfunc(xx, zz, grid=False), color=next(ccycle))\n        self.ax[0].annotate(\"$p$\", xy=[0.05, 0.8], xycoords=\"axes fraction\")\n        self.ax[0].set_ylabel(\"[Pa]\")\n        self.ax[1].plot(xx, jfunc(xx, zz, grid=False), color=next(ccycle))\n        self.ax[1].set_ylabel(\"[A/m^2]\")\n        self.ax[1].annotate(\"$J_{\\\\phi}$\", xy=[0.05, 0.8], xycoords=\"axes fraction\")\n        self.ax[2].plot(xx, psi, color=next(ccycle))\n        self.ax[2].set_ylabel(\"[V.s]\")\n        self.ax[2].annotate(\"$\\\\psi$\", xy=[0.05, 0.8], xycoords=\"axes fraction\")\n        self.ax[2].axhline(psib * 2 * np.pi, color=\"r\", linestyle=\"--\")\n        for ax in self.ax:\n            ax.axvline(xmag, color=\"r\")",
  "class ProfilePlotter(Plotter):\n    \"\"\"\n    Utility class for plotting profile objects\n    \"\"\"\n\n    def __init__(self, profiles, ax=None):\n        super().__init__(ax)\n        self.prof = profiles\n        self.plot_profiles()\n\n    def plot_profiles(self, n=50):\n        \"\"\"\n        Plot the plasma profiles.\n        \"\"\"\n        x = np.linspace(0, 1, n)\n        self.ax.plot(x, self.prof.shape(x), label=\"shape function\")\n        self.ax.plot(x, self.prof.fRBpol(x) / max(self.prof.fRBpol(x)), label=\"fRBpol\")\n        self.ax.plot(\n            x, self.prof.ffprime(x) / max(abs(self.prof.ffprime(x))), label=\"FFprime\"\n        )\n        self.ax.plot(\n            x, self.prof.pprime(x) / max(abs(self.prof.pprime(x))), label=\"pprime\"\n        )\n        self.ax.plot(\n            x, self.prof.pressure(x) / max(abs(self.prof.pressure(x))), label=\"pressure\"\n        )\n        self.ax.legend()",
  "def __init__(self, ax=None, **kwargs):\n        for kwarg in kwargs:\n            if kwarg not in PLOT_DEFAULTS:\n                bluemira_warn(f\"Unrecognised plot kwarg: {kwarg}\")\n\n        if ax is None:\n            f, self.ax = plt.subplots()\n        else:\n            self.ax = ax\n        self.ax.set_xlabel(\"$x$ [m]\")\n        self.ax.set_ylabel(\"$z$ [m]\")\n        self.ax.set_aspect(\"equal\")",
  "def __init__(self, grid, ax=None, edge=False, **kwargs):\n        super().__init__(ax)\n        self.grid = grid\n        self.plot_grid(**kwargs)\n        if edge:\n            self.plot_edge(**kwargs)",
  "def plot_grid(self, **kwargs):\n        \"\"\"\n        Plots the gridlines of the grid\n        \"\"\"\n        lw = kwargs.get(\"linewidth\", PLOT_DEFAULTS[\"grid\"][\"linewidth\"])\n        color = kwargs.get(\"color\", PLOT_DEFAULTS[\"grid\"][\"color\"])\n        for i in self.grid.x_1d:\n            self.ax.plot([i, i], [self.grid.z_min, self.grid.z_max], color, linewidth=lw)\n        for i in self.grid.z_1d:\n            self.ax.plot([self.grid.x_min, self.grid.x_max], [i, i], color, linewidth=lw)",
  "def plot_edge(self, **kwargs):\n        \"\"\"\n        Plots a thicker boundary edge for the grid\n        \"\"\"\n        lw = kwargs.get(\"edgewidth\", PLOT_DEFAULTS[\"grid\"][\"edgewidth\"])\n        color = kwargs.get(\"color\", PLOT_DEFAULTS[\"grid\"][\"color\"])\n        self.ax.plot(*self.grid.bounds, color, linewidth=lw)",
  "def __init__(self, constraint_set, ax=None):\n        super().__init__(ax)\n        self.constraint_set = constraint_set\n\n        for constraint in self.constraint_set.constraints:\n            constraint.plot(self.ax)",
  "def __init__(self, limiter, ax=None, **kwargs):\n        super().__init__(ax)\n        self.limiter = limiter\n        self.plot_limiter(**kwargs)",
  "def plot_limiter(self, **kwargs):\n        \"\"\"\n        Plot the limiter onto the Axes.\n        \"\"\"\n        color = kwargs.get(\"color\", PLOT_DEFAULTS[\"limiter\"][\"color\"])\n        marker = kwargs.get(\"marker\", PLOT_DEFAULTS[\"limiter\"][\"marker\"])\n        self.ax.plot(self.limiter.x, self.limiter.z, \"s\", color=color, marker=marker)",
  "def __init__(self, coil, ax=None, subcoil=True, label=False, force=None, **kwargs):\n        super().__init__(ax)\n        self._cg = coil\n        self.colors = kwargs.pop(\"facecolor\", None)\n        self.linewidth = kwargs.pop(\"linewidth\", PLOT_DEFAULTS[\"coil\"][\"linewidth\"])\n        self.edgecolor = kwargs.pop(\"edgecolor\", PLOT_DEFAULTS[\"coil\"][\"edgecolor\"])\n        if \"alpha\" in kwargs:\n            # Alpha can be provided as a list or cycle to other systems, so make sure we\n            # support that here.\n            alpha = kwargs[\"alpha\"]\n            if isinstance(alpha, cycle):\n                kwargs[\"alpha\"] = next(alpha)\n            if isinstance(kwargs[\"alpha\"], list):\n                kwargs[\"alpha\"] = alpha[0]\n\n        self.plot_coil(subcoil=subcoil, label=label, force=force, **kwargs)\n        if label:  # Margins and labels fighting\n            self.ax.set_xlim(left=-2)\n            ymin, ymax = self.ax.get_ylim()\n            self.ax.set_ylim(bottom=ymin - 1)\n            self.ax.set_ylim(top=ymax + 1)",
  "def plot_coil(self, subcoil, label=False, force=None, **kwargs):\n        \"\"\"\n        Plot a coil onto the Axes.\n        \"\"\"\n        centre, *arrays = self._plotting_array_shaping()\n\n        if subcoil:\n            qb = self._cg._quad_boundary\n            if isinstance(qb, tuple):\n                qb = [qb]\n\n        if force is not None:\n            d_fx, d_fz = force / M_PER_MN\n\n        for i, (x, z, dx, x_b, z_b, ct, n, cur, ctrl) in enumerate(zip(*arrays)):\n            if ctrl:\n                if self.colors is not None:\n                    if ct.name == \"PF\":\n                        kwargs[\"facecolor\"] = self.colors[0]\n                    elif ct.name == \"CS\":\n                        kwargs[\"facecolor\"] = self.colors[1]\n\n                self._plot_coil(\n                    x_b,\n                    z_b,\n                    ct,\n                    color=self.edgecolor,\n                    linewidth=self.linewidth,\n                    **kwargs,\n                )\n                if subcoil:\n                    _qx_b, _qz_b = qb[i]\n                    for ind in range(_qx_b.shape[0]):\n                        self._plot_coil(_qx_b[ind], _qz_b[ind], ct, fill=False, **kwargs)\n                if label:\n                    self._annotate_coil(x, z, dx, n, cur, ct, force=force, centre=centre)\n                if force is not None:\n                    self.ax.arrow(x, z, 0, d_fz[i], color=\"r\", width=0.1)\n            else:\n                self._plot_coil(x_b, z_b, ct, **kwargs)",
  "def _plotting_array_shaping(self):\n        \"\"\"\n        Shape arrays to account for single coils or groups of coils\n        \"\"\"\n        xx = np.atleast_1d(self._cg.x)\n        control_ind = np.zeros_like(xx, dtype=bool)\n\n        if hasattr(self._cg, \"_control_ind\"):\n            control = self._cg._control_ind\n            centre = self._get_centre()\n        else:\n            control = slice(None)\n            centre = None\n\n        control_ind[control] = True\n\n        return (\n            centre,\n            xx,\n            np.atleast_1d(self._cg.z),\n            np.atleast_1d(self._cg.dx),\n            np.atleast_2d(self._cg.x_boundary),\n            np.atleast_2d(self._cg.z_boundary),\n            np.atleast_1d(self._cg.ctype).tolist(),\n            np.atleast_1d(self._cg.name).tolist(),\n            np.atleast_1d(self._cg.current),\n            control_ind,\n        )",
  "def _get_centre(self):\n        \"\"\"\n        Get a \"centre\" position for the coils to arrange the labels.\n        \"\"\"\n        try:\n            x, z = self._cg.get_control_coils().position\n            xc = (max(x) + min(x)) / 2\n            zc = (max(z) + min(z)) / 2\n            return xc, zc\n        except AttributeError:\n            # Not a coilset\n            return None",
  "def _annotate_coil(self, x, z, dx, name, current, ctype, force=None, centre=None):\n        \"\"\"\n        Single coil annotation utility function\n        \"\"\"\n        off = max(0.2, dx + 0.02)\n        if ctype.name == \"CS\":\n            drs = -1.5 * off\n            ha = \"right\"\n        else:\n            drs = 2 * off\n            ha = \"left\"\n        text = \"\\n\".join([str_to_latex(name), f\"{raw_uc(current, 'A', 'MA'):.2f} MA\"])\n        if force is not None:\n            text = \"\\n\".join([text, f\"{raw_uc(force[1], 'N', 'MN'):.2f} MN\"])\n        x = float(x) + drs\n        z = float(z)\n        if centre is not None and ctype.name == \"PF\":\n            v = np.array([x - centre[0], z - centre[1]])\n            v /= np.sqrt(sum(v**2))\n            d = 1 + np.sqrt(2) * dx\n            x += d * v[0] - drs * 1.5\n            z += d * v[1]\n        self.ax.text(\n            x,\n            z,\n            text,\n            fontsize=PLOT_DEFAULTS[\"coil\"][\"fontsize\"],\n            ha=ha,\n            va=\"center\",\n            color=\"k\",\n            backgroundcolor=\"white\",\n            bbox={\n                \"boxstyle\": \"round\",\n                \"facecolor\": \"white\",\n                \"linewidth\": 1,\n                \"edgecolor\": \"k\",\n            },\n        )",
  "def _plot_coil(self, x_boundary, z_boundary, ctype, fill=True, **kwargs):\n        \"\"\"\n        Single coil plot utility\n        \"\"\"\n        mask = kwargs.pop(\"mask\", True)\n\n        fcolor = kwargs.pop(\"facecolor\", PLOT_DEFAULTS[\"coil\"][\"facecolor\"][ctype.name])\n\n        color = kwargs.pop(\"edgecolor\", PLOT_DEFAULTS[\"coil\"][\"edgecolor\"])\n        linewidth = kwargs.pop(\"linewidth\", PLOT_DEFAULTS[\"coil\"][\"linewidth\"])\n        alpha = kwargs.pop(\"alpha\", PLOT_DEFAULTS[\"coil\"][\"alpha\"])\n\n        x = np.append(x_boundary, x_boundary[0])\n        z = np.append(z_boundary, z_boundary[0])\n\n        self.ax.plot(x, z, zorder=11, color=color, linewidth=linewidth)\n        if fill:\n            if mask:\n                self.ax.fill(x, z, color=\"w\", zorder=10, alpha=1)\n\n            self.ax.fill(x, z, zorder=10, color=fcolor, alpha=alpha)",
  "def __init__(self, plasma_coil, ax=None, **kwargs):\n        super().__init__(ax)\n        self.plasma_coil = plasma_coil\n        if self.plasma_coil._j_tor is None:\n            # No coils to plot\n            pass\n        else:\n            contour = get_contours(\n                self.plasma_coil._grid.x,\n                self.plasma_coil._grid.z,\n                self.plasma_coil._j_tor,\n                J_TOR_MIN,\n            )\n            x, z = contour[0].T\n            sq_x, sq_z = grid_2d_contour(x, z)\n\n            nlevels = kwargs.pop(\"nlevels\", PLOT_DEFAULTS[\"current\"][\"nlevels\"])\n            cmap = kwargs.pop(\"cmap\", PLOT_DEFAULTS[\"current\"][\"cmap\"])\n\n            levels = np.linspace(J_TOR_MIN, np.amax(self.plasma_coil._j_tor), nlevels)\n            self.ax.contourf(\n                self.plasma_coil._grid.x,\n                self.plasma_coil._grid.z,\n                self.plasma_coil._j_tor,\n                cmap=cmap,\n                levels=levels,\n            )\n            self.ax.plot(sq_x, sq_z, linewidth=1.5, color=\"k\")",
  "def __init__(\n        self,\n        equilibrium,\n        ax=None,\n        plasma=False,\n        show_ox=True,\n        field=False,\n    ):\n        super().__init__(ax)\n        self.eq = equilibrium\n\n        # Do some housework\n        self.psi = self.eq.psi()\n\n        self.o_points, self.x_points = self.eq.get_OX_points(self.psi, force_update=True)\n\n        if self.x_points:\n            self.xp_psi = self.x_points[0][2]  # Psi at separatrix\n        else:\n            bluemira_warn(\n                \"No X-point found in plotted equilibrium. Cannot normalise psi.\"\n            )\n            self.xp_psi = np.amax(self.psi)\n\n        if self.o_points:\n            self.op_psi = self.o_points[0][2]  # Psi at O-point\n        else:\n            bluemira_warn(\n                \"No O-point found in plotted equilibrium. Cannot normalise psi.\"\n            )\n            self.op_psi = np.amin(self.psi)\n\n        if not field:\n            self.plot_plasma_current()\n            self.plot_psi()\n        else:\n            self.plot_Bp()\n\n        if self.o_points and self.x_points:\n            # Only plot if we can normalise psi\n            self.plot_separatrix()\n            self.plot_flux_surface(1.05, \"pink\")\n\n        if show_ox:\n            self.plot_X_points()\n            self.plot_O_points()\n\n        if plasma:\n            self.plot_plasma_coil()",
  "def plot_Bp(self, **kwargs):\n        \"\"\"\n        Plots the poloidal field onto the Axes.\n        \"\"\"\n        nlevels = kwargs.pop(\"nlevels\", PLOT_DEFAULTS[\"field\"][\"nlevels\"])\n        cmap = kwargs.pop(\"cmap\", PLOT_DEFAULTS[\"field\"][\"cmap\"])\n\n        Bp = self.eq.Bp()\n        levels = np.linspace(1e-36, np.amax(Bp), nlevels)\n        c = self.ax.contourf(self.eq.x, self.eq.z, Bp, levels=levels, cmap=cmap)\n        cbar = plt.colorbar(c)\n        cbar.set_label(\"$B_{p}$ [T]\")",
  "def plot_psi(self, **kwargs):\n        \"\"\"\n        Plot flux surfaces\n        \"\"\"\n        nlevels = kwargs.pop(\"nlevels\", PLOT_DEFAULTS[\"psi\"][\"nlevels\"])\n        cmap = kwargs.pop(\"cmap\", PLOT_DEFAULTS[\"psi\"][\"cmap\"])\n\n        levels = np.linspace(np.amin(self.psi), np.amax(self.psi), nlevels)\n        self.ax.contour(\n            self.eq.x, self.eq.z, self.psi, levels=levels, cmap=cmap, zorder=8\n        )",
  "def plot_plasma_current(self, **kwargs):\n        \"\"\"\n        Plots flux surfaces inside plasma\n        \"\"\"\n        if self.eq._jtor is None:\n            return\n\n        nlevels = kwargs.pop(\"nlevels\", PLOT_DEFAULTS[\"current\"][\"nlevels\"])\n        cmap = kwargs.pop(\"cmap\", PLOT_DEFAULTS[\"current\"][\"cmap\"])\n\n        levels = np.linspace(J_TOR_MIN, np.amax(self.eq._jtor), nlevels)\n        self.ax.contourf(\n            self.eq.x, self.eq.z, self.eq._jtor, levels=levels, cmap=cmap, zorder=7\n        )",
  "def plot_flux_surface(self, psi_norm, color=\"k\"):\n        \"\"\"\n        Plots a normalised flux surface relative to the separatrix with\n        increasing values going outwards from plasma core.\n        \"\"\"\n        psi = calc_psi(psi_norm, self.op_psi, self.xp_psi)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            self.ax.contour(\n                self.eq.x, self.eq.z, self.psi, levels=[psi], colors=color, zorder=9\n            )",
  "def plot_separatrix(self):\n        \"\"\"\n        Plot the separatrix.\n        \"\"\"\n        try:\n            separatrix = self.eq.get_separatrix()\n        except Exception:\n            bluemira_warn(\"Unable to plot separatrix\")\n            return\n\n        if isinstance(separatrix, list):\n            coords = separatrix\n        else:\n            coords = [separatrix]\n\n        for coord in coords:\n            x, z = coord.xz\n            self.ax.plot(\n                x,\n                z,\n                color=PLOT_DEFAULTS[\"separatrix\"][\"color\"],\n                linewidth=PLOT_DEFAULTS[\"separatrix\"][\"linewidth\"],\n                zorder=9,\n            )",
  "def plot_X_points(self):  # noqa :N802\n        \"\"\"\n        Plot X-points.\n        \"\"\"\n        for p in self.x_points:\n            if isinstance(p, Xpoint):\n                self.ax.plot(\n                    p.x,\n                    p.z,\n                    marker=PLOT_DEFAULTS[\"xpoint\"][\"marker\"],\n                    color=PLOT_DEFAULTS[\"xpoint\"][\"color\"],\n                    zorder=10,\n                )",
  "def plot_O_points(self):  # noqa :N802\n        \"\"\"\n        Plot O-points.\n        \"\"\"\n        for p in self.o_points:\n            self.ax.plot(\n                p.x,\n                p.z,\n                marker=PLOT_DEFAULTS[\"opoint\"][\"marker\"],\n                color=PLOT_DEFAULTS[\"opoint\"][\"color\"],\n                zorder=10,\n            )",
  "def plot_plasma_coil(self):\n        \"\"\"\n        Plot the plasma coil.\n        \"\"\"\n        PlasmaCoilPlotter(self.ax, self.eq.plasma_coil())",
  "def __init__(self, breakdown, ax=None, Bp=False, B_breakdown=0.003):\n        super().__init__(ax)\n        self.bd = breakdown\n\n        self.psi = self.bd.psi()\n        self.psi_bd = self.bd.breakdown_psi\n        self.Bp = self.bd.Bp(self.bd.x, self.bd.z)\n\n        self.plot_contour()\n        self.plot_zone(B_breakdown)\n        if Bp:\n            self.plot_Bp()",
  "def plot_contour(self):\n        \"\"\"\n        Plot flux surfaces.\n        \"\"\"\n        levels = np.linspace(self.psi_bd - 0.1, self.psi_bd, 3)\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            self.ax.contour(self.bd.x, self.bd.z, self.psi, levels=levels, colors=\"r\")",
  "def plot_Bp(self, **kwargs):\n        \"\"\"\n        Plots the poloidal field onto the Axes.\n        \"\"\"\n        nlevels = kwargs.pop(\"nlevels\", PLOT_DEFAULTS[\"field\"][\"nlevels\"])\n        cmap = kwargs.pop(\"cmap\", PLOT_DEFAULTS[\"field\"][\"cmap\"])\n        levels = np.linspace(1e-36, np.amax(self.Bp), nlevels)\n        c = self.ax.contourf(self.bd.x, self.bd.z, self.Bp, levels=levels, cmap=cmap)\n        cbar = plt.colorbar(c)\n        cbar.set_label(\"$B_{p}$ [T]\")",
  "def plot_zone(self, field):\n        \"\"\"\n        Plot the low field zones with a dashed line.\n        \"\"\"\n        colors = [\"b\"]\n        self.ax.contour(\n            self.bd.x,\n            self.bd.z,\n            self.Bp,\n            levels=[field],\n            colors=colors,\n            linestyles=\"dashed\",\n        )\n\n        if self.psi_bd is not None:\n            self.ax.set_title(\"$\\\\psi_{b}$ = \" + f\"{2*np.pi*self.psi_bd:.2f} V.s\")",
  "def __init__(self, xzl_mapper, ax=None):\n        super().__init__(ax)\n        self.xzl = xzl_mapper\n\n        for coords in self.xzl.excl_zones:\n            plot_coordinates(\n                coords, self.ax, fill=True, alpha=0.2, facecolor=\"r\", edgecolor=\"r\"\n            )\n\n        for coords in self.xzl.excl_loops:\n            plot_coordinates(\n                coords, self.ax, fill=False, edgecolor=\"r\", zorder=1, linestyle=\"--\"\n            )\n\n        for coords in self.xzl.incl_loops:\n            plot_coordinates(\n                coords, self.ax, fill=False, edgecolor=\"k\", zorder=1, linestyle=\"--\"\n            )",
  "def __init__(self, region_mapper, ax=None):\n        super().__init__(ax)\n        self.rmp = region_mapper\n\n        for intpltr in self.rmp.regions.values():\n            plot_coordinates(\n                intpltr.coords,\n                self.ax,\n                fill=True,\n                alpha=0.2,\n                zorder=1,\n                facecolor=\"g\",\n                edgecolor=\"g\",\n            )",
  "def __init__(self, results):\n        r, c = int((len(results.__dict__) - 1) / 2) + 1, 2\n        gs = GridSpec(r, c)\n        self.ax = [plt.subplot(gs[i]) for i in range(r * c)]\n        ccycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])\n        for i, (k, v) in enumerate(results.__dict__.items()):\n            color = next(ccycle)\n            self.ax[i].plot(results.psi_n, v, label=str_to_latex(k), color=color)\n            self.ax[i].legend()",
  "def __init__(self, eq):\n        jfunc = RectBivariateSpline(eq.x[:, 0], eq.z[0, :], eq._jtor)\n        p = eq.pressure_map()\n        pfunc = RectBivariateSpline(eq.x[:, 0], eq.z[0, :], p)\n        o_points, _ = eq.get_OX_points()\n        xmag, zmag = o_points[0].x, o_points[0].z\n        psia, psib = eq.get_OX_psis()\n        n = 50\n        xx = np.linspace(eq.grid.x_min, eq.grid.x_max, n)\n        zz = np.linspace(zmag, zmag, n)\n        gs = GridSpec(3, 1)\n        ccycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])\n\n        psi = eq.psi(xx, zz) * 2 * np.pi\n        self.ax = [plt.subplot(gs[i]) for i in range(3)]\n        self.ax[0].plot(xx, pfunc(xx, zz, grid=False), color=next(ccycle))\n        self.ax[0].annotate(\"$p$\", xy=[0.05, 0.8], xycoords=\"axes fraction\")\n        self.ax[0].set_ylabel(\"[Pa]\")\n        self.ax[1].plot(xx, jfunc(xx, zz, grid=False), color=next(ccycle))\n        self.ax[1].set_ylabel(\"[A/m^2]\")\n        self.ax[1].annotate(\"$J_{\\\\phi}$\", xy=[0.05, 0.8], xycoords=\"axes fraction\")\n        self.ax[2].plot(xx, psi, color=next(ccycle))\n        self.ax[2].set_ylabel(\"[V.s]\")\n        self.ax[2].annotate(\"$\\\\psi$\", xy=[0.05, 0.8], xycoords=\"axes fraction\")\n        self.ax[2].axhline(psib * 2 * np.pi, color=\"r\", linestyle=\"--\")\n        for ax in self.ax:\n            ax.axvline(xmag, color=\"r\")",
  "def __init__(self, profiles, ax=None):\n        super().__init__(ax)\n        self.prof = profiles\n        self.plot_profiles()",
  "def plot_profiles(self, n=50):\n        \"\"\"\n        Plot the plasma profiles.\n        \"\"\"\n        x = np.linspace(0, 1, n)\n        self.ax.plot(x, self.prof.shape(x), label=\"shape function\")\n        self.ax.plot(x, self.prof.fRBpol(x) / max(self.prof.fRBpol(x)), label=\"fRBpol\")\n        self.ax.plot(\n            x, self.prof.ffprime(x) / max(abs(self.prof.ffprime(x))), label=\"FFprime\"\n        )\n        self.ax.plot(\n            x, self.prof.pprime(x) / max(abs(self.prof.pprime(x))), label=\"pprime\"\n        )\n        self.ax.plot(\n            x, self.prof.pressure(x) / max(abs(self.prof.pressure(x))), label=\"pressure\"\n        )\n        self.ax.legend()",
  "def treat_xz_array(func):\n    \"\"\"\n    Decorator for handling array calls to PlasmaCoil methods.\n    \"\"\"\n\n    def wrapper(self, x=None, z=None):\n        if x is None or z is None:\n            if z is None and x is None:\n                return func(self, x, z)\n            else:\n                raise EquilibriaError(\"Only one of x and z specified.\")\n\n        x = np.array(x)\n        z = np.array(z)\n        if x.shape != z.shape:\n            raise EquilibriaError(\"x and z arrays of different dimension.\")\n\n        values = np.zeros(x.size)\n\n        for i, (xx, zz) in enumerate(zip(x.flat, z.flat)):\n            values[i] = func(self, xx, zz)\n\n        return values.reshape(x.shape)\n\n    return wrapper",
  "class PlasmaCoil:\n    \"\"\"\n    PlasmaCoil object for finite difference representation of toroidal current\n    carrying plasma.\n\n    Parameters\n    ----------\n    plasma_psi:\n        Psi contribution from the plasma on the grid\n    j_tor:\n        Toroidal current density distribution from the plasma on the grid\n    grid:\n        Grid object on which the finite difference representation of the plasma should be\n        constructed\n\n    Notes\n    -----\n    Uses direct summing of Green's functions to avoid SIGKILL and MemoryErrors\n    when using very dense grids (e.g. CREATE).\n    \"\"\"\n\n    def __init__(self, plasma_psi: np.ndarray, j_tor: Optional[np.ndarray], grid: Grid):\n        self._grid = grid\n        self._set_j_tor(j_tor)\n        self._set_funcs(plasma_psi)\n\n    def _set_j_tor(self, j_tor: Optional[np.ndarray]):\n        self._j_tor = j_tor\n        if j_tor is not None:\n            self._ii, self._jj = np.where(j_tor > J_TOR_MIN)\n        else:\n            self._ii, self._jj = None, None\n\n    def _set_funcs(self, plasma_psi: np.ndarray):\n        self._plasma_psi = plasma_psi\n        self._psi_func = RectBivariateSpline(\n            self._grid.x[:, 0], self._grid.z[0, :], plasma_psi\n        )\n        self._plasma_Bx = self._Bx_func(self._grid.x, self._grid.z)\n        self._plasma_Bz = self._Bz_func(self._grid.x, self._grid.z)\n        self._plasma_Bp = np.hypot(self._plasma_Bx, self._plasma_Bz)\n\n    def _Bx_func(self, x, z):\n        return -self._psi_func(x, z, dy=1, grid=False) / x\n\n    def _Bz_func(self, x, z):\n        return self._psi_func(x, z, dx=1, grid=False) / x\n\n    def _check_in_grid(self, x, z):\n        return self._grid.point_inside(x, z)\n\n    def _convolve(self, func, x, z):\n        \"\"\"\n        Map a Green's function across the grid at a point, without crashing or\n        running out of memory.\n        \"\"\"\n        if self._j_tor is None:\n            raise EquilibriaError(\n                \"Cannot calculate value off grid; there is no known toroidal current distribution.\"\n            )\n\n        array = np.zeros_like(x, dtype=float)\n        for i, j in zip(self._ii, self._jj):\n            current = self._j_tor[i, j] * self._grid.dx * self._grid.dz\n            array += current * func(self._grid.x[i, j], self._grid.z[i, j], x, z)\n        return array\n\n    @treat_xz_array\n    def psi(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Poloidal magnetic flux at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Poloidal magnetic flux at the points [V.s/rad]\n        \"\"\"\n        if x is None and z is None:\n            return self._plasma_psi\n\n        if not self._check_in_grid(x, z):\n            return self._convolve(greens_psi, x, z)\n        else:\n            return self._psi_func(x, z)\n\n    @treat_xz_array\n    def Bx(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Radial magnetic field at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Radial magnetic field at the points [T]\n        \"\"\"\n        if x is None and z is None:\n            return self._plasma_Bx\n\n        if not self._check_in_grid(x, z):\n            return self._convolve(greens_Bx, x, z)\n        else:\n            return self._Bx_func(x, z)\n\n    @treat_xz_array\n    def Bz(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Vertical magnetic field at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Vertical magnetic field at the points [T]\n        \"\"\"\n        if x is None and z is None:\n            return self._plasma_Bz\n\n        if not self._check_in_grid(x, z):\n            return self._convolve(greens_Bz, x, z)\n        else:\n            return self._Bz_func(x, z)\n\n    def Bp(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Poloidal magnetic field at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Poloidal magnetic field at the points [T]\n        \"\"\"\n        if x is None and z is None:\n            return self._plasma_Bp\n        else:\n            return np.hypot(self.Bx(x, z), self.Bz(x, z))\n\n    def plot(self, ax=None):\n        \"\"\"\n        Plot the PlasmaCoil.\n\n        Parameters\n        ----------\n        ax:\n            The matplotlib axes on which to plot the PlasmaCoil\n        \"\"\"\n        return PlasmaCoilPlotter(self, ax=ax)\n\n    def __repr__(self):\n        \"\"\"\n        Get a simple string representation of the PlasmaCoil.\n        \"\"\"\n        n_filaments = len(np.where(self._j_tor > 0)[0])\n        return f\"{self.__class__.__name__}: {n_filaments} filaments\"",
  "class NoPlasmaCoil:\n    \"\"\"\n    NoPlasmaCoil object for dummy representation of a plasma-less state.\n\n    Parameters\n    ----------\n    grid:\n        Grid object on which the finite difference representation of the plasma should be\n        constructed\n    \"\"\"\n\n    def __init__(self, grid: Grid):\n        self.grid = grid\n\n    def psi(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Poloidal magnetic flux at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Poloidal magnetic flux at the points [V.s/rad]\n        \"\"\"\n        return self._return_zeros(x, z)\n\n    def Bx(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Radial magnetic field at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Radial magnetic field at the points [T]\n        \"\"\"\n        return self._return_zeros(x, z)\n\n    def Bz(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Vertical magnetic field at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Vertical magnetic field at the points [T]\n        \"\"\"\n        return self._return_zeros(x, z)\n\n    def Bp(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Poloidal magnetic field at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Poloidal magnetic field at the points [T]\n        \"\"\"\n        return self._return_zeros(x, z)\n\n    def _return_zeros(self, x, z):\n        if x is None and z is None:\n            return np.zeros_like(self.grid.x)\n\n        return np.zeros_like(x)",
  "def wrapper(self, x=None, z=None):\n        if x is None or z is None:\n            if z is None and x is None:\n                return func(self, x, z)\n            else:\n                raise EquilibriaError(\"Only one of x and z specified.\")\n\n        x = np.array(x)\n        z = np.array(z)\n        if x.shape != z.shape:\n            raise EquilibriaError(\"x and z arrays of different dimension.\")\n\n        values = np.zeros(x.size)\n\n        for i, (xx, zz) in enumerate(zip(x.flat, z.flat)):\n            values[i] = func(self, xx, zz)\n\n        return values.reshape(x.shape)",
  "def __init__(self, plasma_psi: np.ndarray, j_tor: Optional[np.ndarray], grid: Grid):\n        self._grid = grid\n        self._set_j_tor(j_tor)\n        self._set_funcs(plasma_psi)",
  "def _set_j_tor(self, j_tor: Optional[np.ndarray]):\n        self._j_tor = j_tor\n        if j_tor is not None:\n            self._ii, self._jj = np.where(j_tor > J_TOR_MIN)\n        else:\n            self._ii, self._jj = None, None",
  "def _set_funcs(self, plasma_psi: np.ndarray):\n        self._plasma_psi = plasma_psi\n        self._psi_func = RectBivariateSpline(\n            self._grid.x[:, 0], self._grid.z[0, :], plasma_psi\n        )\n        self._plasma_Bx = self._Bx_func(self._grid.x, self._grid.z)\n        self._plasma_Bz = self._Bz_func(self._grid.x, self._grid.z)\n        self._plasma_Bp = np.hypot(self._plasma_Bx, self._plasma_Bz)",
  "def _Bx_func(self, x, z):\n        return -self._psi_func(x, z, dy=1, grid=False) / x",
  "def _Bz_func(self, x, z):\n        return self._psi_func(x, z, dx=1, grid=False) / x",
  "def _check_in_grid(self, x, z):\n        return self._grid.point_inside(x, z)",
  "def _convolve(self, func, x, z):\n        \"\"\"\n        Map a Green's function across the grid at a point, without crashing or\n        running out of memory.\n        \"\"\"\n        if self._j_tor is None:\n            raise EquilibriaError(\n                \"Cannot calculate value off grid; there is no known toroidal current distribution.\"\n            )\n\n        array = np.zeros_like(x, dtype=float)\n        for i, j in zip(self._ii, self._jj):\n            current = self._j_tor[i, j] * self._grid.dx * self._grid.dz\n            array += current * func(self._grid.x[i, j], self._grid.z[i, j], x, z)\n        return array",
  "def psi(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Poloidal magnetic flux at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Poloidal magnetic flux at the points [V.s/rad]\n        \"\"\"\n        if x is None and z is None:\n            return self._plasma_psi\n\n        if not self._check_in_grid(x, z):\n            return self._convolve(greens_psi, x, z)\n        else:\n            return self._psi_func(x, z)",
  "def Bx(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Radial magnetic field at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Radial magnetic field at the points [T]\n        \"\"\"\n        if x is None and z is None:\n            return self._plasma_Bx\n\n        if not self._check_in_grid(x, z):\n            return self._convolve(greens_Bx, x, z)\n        else:\n            return self._Bx_func(x, z)",
  "def Bz(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Vertical magnetic field at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Vertical magnetic field at the points [T]\n        \"\"\"\n        if x is None and z is None:\n            return self._plasma_Bz\n\n        if not self._check_in_grid(x, z):\n            return self._convolve(greens_Bz, x, z)\n        else:\n            return self._Bz_func(x, z)",
  "def Bp(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Poloidal magnetic field at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Poloidal magnetic field at the points [T]\n        \"\"\"\n        if x is None and z is None:\n            return self._plasma_Bp\n        else:\n            return np.hypot(self.Bx(x, z), self.Bz(x, z))",
  "def plot(self, ax=None):\n        \"\"\"\n        Plot the PlasmaCoil.\n\n        Parameters\n        ----------\n        ax:\n            The matplotlib axes on which to plot the PlasmaCoil\n        \"\"\"\n        return PlasmaCoilPlotter(self, ax=ax)",
  "def __repr__(self):\n        \"\"\"\n        Get a simple string representation of the PlasmaCoil.\n        \"\"\"\n        n_filaments = len(np.where(self._j_tor > 0)[0])\n        return f\"{self.__class__.__name__}: {n_filaments} filaments\"",
  "def __init__(self, grid: Grid):\n        self.grid = grid",
  "def psi(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Poloidal magnetic flux at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Poloidal magnetic flux at the points [V.s/rad]\n        \"\"\"\n        return self._return_zeros(x, z)",
  "def Bx(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Radial magnetic field at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Radial magnetic field at the points [T]\n        \"\"\"\n        return self._return_zeros(x, z)",
  "def Bz(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Vertical magnetic field at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Vertical magnetic field at the points [T]\n        \"\"\"\n        return self._return_zeros(x, z)",
  "def Bp(\n        self,\n        x: Optional[Union[float, np.ndarray]] = None,\n        z: Optional[Union[float, np.ndarray]] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Poloidal magnetic field at x, z\n\n        Parameters\n        ----------\n        x:\n            Radial coordinates at which to calculate\n        z:\n            Vertical coordinates at which to calculate.\n\n        Notes\n        -----\n        If both x and z are None, defaults to the full map on the grid.\n\n        Returns\n        -------\n        Poloidal magnetic field at the points [T]\n        \"\"\"\n        return self._return_zeros(x, z)",
  "def _return_zeros(self, x, z):\n        if x is None and z is None:\n            return np.zeros_like(self.grid.x)\n\n        return np.zeros_like(x)",
  "class GSOperator:\n    \"\"\"\n    Calculates sparse matrix for the Grad-Shafranov operator\n\n    Parameters\n    ----------\n    x_min:\n        Minimum X value on which to calculate the G-S operator\n    x_max:\n        Maximum X value on which to calculate the G-S operator\n    z_min:\n        Minimum Z value on which to calculate the G-S operator\n    z_max:\n        Maximum Z value on which to calculate the G-S operator\n    force_symmetry:\n        If true, the G-S operator will be constructed for the\n        lower half space Z<=0 with symmetry conditions imposed\n        at Z=0.\n\n    \\t:math:`{\\\\Delta}^{*} = X^{2}{\\\\nabla}{\\\\cdot}\\\\dfrac{1}{X^2}{\\\\nabla}`\n\n    \\t:math:`\\\\dfrac{1}{(\\\\Delta Z)^2}\\\\psi_{i-1, j}+\\\\bigg(\\\\dfrac{1}{(\\\\Delta X)^2}+\\\\dfrac{1}{2X_j(\\\\Delta X)}\\\\bigg)\\\\psi_{i, j-1}`\n    \\t:math:`+\\\\Bigg[2\\\\Bigg(\\\\dfrac{1}{(\\\\Delta X)^2}+\\\\dfrac{1}{(\\\\Delta Z)^2}\\\\Bigg)\\\\Bigg]\\\\psi_{i, j}`\n    \\t:math:`+\\\\bigg(\\\\dfrac{1}{(\\\\Delta X)^2}-\\\\dfrac{1}{2X_j(\\\\Delta X)}\\\\bigg)\\\\psi_{i, j+1}`\n    \\t:math:`+\\\\dfrac{1}{(\\\\Delta Z)^2}\\\\psi_{i+1, j}=-\\\\mu_0 X_j J_{\\\\phi_{i, j}}`\n    \"\"\"  # noqa :W505\n\n    def __init__(\n        self,\n        x_min: float,\n        x_max: float,\n        z_min: float,\n        z_max: float,\n        force_symmetry: bool = False,\n    ):\n        self.x_min = x_min\n        self.x_max = x_max\n        self.z_min = z_min\n        self.z_max = z_max\n        self.force_symmetry = force_symmetry\n\n    def __call__(self, nx: int, nz: int) -> csr_matrix:\n        \"\"\"\n        Create a sparse matrix with given resolution\n\n        Parameters\n        ----------\n        nx:\n            The discretisation of the 2-D field in X\n        nz:\n            The discretisation of the 2-D field in Z\n        \"\"\"\n        d_x = (self.x_max - self.x_min) / (nx - 1)\n        d_z = (self.z_max - self.z_min) / (nz - 1)\n        half_xdx = 0.5 / (np.linspace(self.x_min, self.x_max, nx) * d_x)\n        inv_dx_2, inv_dz_2 = 1 / d_x**2, 1 / d_z**2\n\n        if self.force_symmetry:\n            # Check if applied grid is symmetric\n            if not np.isclose(self.z_min, -self.z_max):\n                raise EquilibriaError(\n                    \"Symmetry is being forced, but underlying limits are not symmetric about z=0.\"\n                )\n            # Replace nz with number of rows in lower half space of system\n            # (including midplane)\n            nz = np.floor_divide(nz + 1, 2)\n\n        A = lil_matrix((nx * nz, nx * nz))\n        A.setdiag(1)\n\n        i, j = np.meshgrid(np.arange(1, nx - 1), np.arange(1, nz - 1), indexing=\"ij\")\n        i = i.ravel()\n        j = j.ravel()\n        ind = i * nz + j\n\n        A[ind, ind] = -2 * (inv_dx_2 + inv_dz_2)  # j, l\n        A[ind, ind + nz] = inv_dx_2 - half_xdx[i]  # j, l-1\n        A[ind, ind - nz] = inv_dx_2 + half_xdx[i]  # j, l+1\n        A[ind, ind + 1] = inv_dz_2  # j-1, l\n        A[ind, ind - 1] = inv_dz_2  # j+1, l\n\n        # Apply symmetry boundary if desired\n        if self.force_symmetry:\n            # Apply ghost point method to apply symmetry to (d/dz^2) operator\n            # contributions close to symmetry plane.\n            # If symmetry boundary is centred halfway between cells,\n            # d(psi)/dz = 0 across midplane,\n            # else if symmetry boundary is centred on cells, d(psi)/dz\n            # is equal either side of midplane but reverses sign.\n            ind = i * nz + nz - 1\n            ghost_factor = 1 + nz % 2\n\n            A[ind, ind] = -2 * inv_dx_2 - ghost_factor * inv_dz_2\n            A[ind, ind - 1] = ghost_factor * inv_dz_2\n            A[ind, ind + nz] = inv_dx_2 - half_xdx[i]  # j, l-1\n            A[ind, ind - nz] = inv_dx_2 + half_xdx[i]  # j, l+1\n        return A.tocsr()",
  "class DirectSolver:\n    \"\"\"\n    Direct solver applying lower-upper decomposition to solver\n    the linear system A x = b.\n\n    Parameters\n    ----------\n    A:\n        Linear operator on LHS of equation system, in csr format.\n    \"\"\"\n\n    def __init__(self, A: csr_matrix):\n        self.solve = factorized(A.tocsc())\n\n    def __call__(self, b: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Solve the matrix problem by LU decomposition.\n\n        Parameters\n        ----------\n        b:\n            Numpy array containing RHS of equation system.\n            Converted to 1D before linear solve applied..\n        \"\"\"\n        b1d = np.reshape(b, -1)\n        x = self.solve(b1d)\n        if np.any(np.isnan(x)):\n            raise EquilibriaError(\"Matrix inversion problem in GS solver.\")\n        return np.reshape(x, b.shape)",
  "class GSSolver(DirectSolver):\n    \"\"\"\n    Solver for the Grad-Shafranov system.\n    Uses lower-upper decomposition during linear solve.\n\n    Parameters\n    ----------\n    grid:\n        The grid upon which to solve the G-S equation.\n    force_symmetry:\n        If true, the G-S operator will be constructed for the\n        lower half space Z<=0 with symmetry conditions imposed\n        at Z=0.\n    \"\"\"\n\n    def __init__(self, grid: Grid, force_symmetry: bool = False):\n        self.grid = grid\n        self.force_symmetry = force_symmetry\n\n        gsoperator = GSOperator(\n            self.grid.x_min,\n            self.grid.x_max,\n            self.grid.z_min,\n            self.grid.z_max,\n            force_symmetry=self.force_symmetry,\n        )\n\n        super().__init__(gsoperator(self.grid.nx, self.grid.nz))\n\n    def __call__(self, b: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Solves the linear system Ax=b using LU decomposition,\n        If the G-S operator is in symmetric form, problem symmetry\n        is explicitly enforced.\n\n        Parameters\n        ----------\n        b: np.array(nx, nz)\n            2-D X, Z map of the RHS of the G-S equation.\n        \"\"\"\n        if self.force_symmetry:\n            nz = self.grid.nz\n\n            # Trim RHS vector to half vector containing unique values\n            half_nz = np.floor_divide(nz + 1, 2)\n            b_half = b[:, 0:half_nz]\n\n            # Solve linear system\n            x_half = super().__call__(b_half)\n\n            # Create full-length vector by symmetry\n            x = np.zeros(np.shape(b))\n            x[:, 0:half_nz] = x_half\n            x[:, half_nz:] = np.flip(x_half, axis=1)[:, nz % 2 :]\n\n        else:\n            # Solve linear system with no symmetry assumptions.\n            x = super().__call__(b)\n\n        return x",
  "def __init__(\n        self,\n        x_min: float,\n        x_max: float,\n        z_min: float,\n        z_max: float,\n        force_symmetry: bool = False,\n    ):\n        self.x_min = x_min\n        self.x_max = x_max\n        self.z_min = z_min\n        self.z_max = z_max\n        self.force_symmetry = force_symmetry",
  "def __call__(self, nx: int, nz: int) -> csr_matrix:\n        \"\"\"\n        Create a sparse matrix with given resolution\n\n        Parameters\n        ----------\n        nx:\n            The discretisation of the 2-D field in X\n        nz:\n            The discretisation of the 2-D field in Z\n        \"\"\"\n        d_x = (self.x_max - self.x_min) / (nx - 1)\n        d_z = (self.z_max - self.z_min) / (nz - 1)\n        half_xdx = 0.5 / (np.linspace(self.x_min, self.x_max, nx) * d_x)\n        inv_dx_2, inv_dz_2 = 1 / d_x**2, 1 / d_z**2\n\n        if self.force_symmetry:\n            # Check if applied grid is symmetric\n            if not np.isclose(self.z_min, -self.z_max):\n                raise EquilibriaError(\n                    \"Symmetry is being forced, but underlying limits are not symmetric about z=0.\"\n                )\n            # Replace nz with number of rows in lower half space of system\n            # (including midplane)\n            nz = np.floor_divide(nz + 1, 2)\n\n        A = lil_matrix((nx * nz, nx * nz))\n        A.setdiag(1)\n\n        i, j = np.meshgrid(np.arange(1, nx - 1), np.arange(1, nz - 1), indexing=\"ij\")\n        i = i.ravel()\n        j = j.ravel()\n        ind = i * nz + j\n\n        A[ind, ind] = -2 * (inv_dx_2 + inv_dz_2)  # j, l\n        A[ind, ind + nz] = inv_dx_2 - half_xdx[i]  # j, l-1\n        A[ind, ind - nz] = inv_dx_2 + half_xdx[i]  # j, l+1\n        A[ind, ind + 1] = inv_dz_2  # j-1, l\n        A[ind, ind - 1] = inv_dz_2  # j+1, l\n\n        # Apply symmetry boundary if desired\n        if self.force_symmetry:\n            # Apply ghost point method to apply symmetry to (d/dz^2) operator\n            # contributions close to symmetry plane.\n            # If symmetry boundary is centred halfway between cells,\n            # d(psi)/dz = 0 across midplane,\n            # else if symmetry boundary is centred on cells, d(psi)/dz\n            # is equal either side of midplane but reverses sign.\n            ind = i * nz + nz - 1\n            ghost_factor = 1 + nz % 2\n\n            A[ind, ind] = -2 * inv_dx_2 - ghost_factor * inv_dz_2\n            A[ind, ind - 1] = ghost_factor * inv_dz_2\n            A[ind, ind + nz] = inv_dx_2 - half_xdx[i]  # j, l-1\n            A[ind, ind - nz] = inv_dx_2 + half_xdx[i]  # j, l+1\n        return A.tocsr()",
  "def __init__(self, A: csr_matrix):\n        self.solve = factorized(A.tocsc())",
  "def __call__(self, b: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Solve the matrix problem by LU decomposition.\n\n        Parameters\n        ----------\n        b:\n            Numpy array containing RHS of equation system.\n            Converted to 1D before linear solve applied..\n        \"\"\"\n        b1d = np.reshape(b, -1)\n        x = self.solve(b1d)\n        if np.any(np.isnan(x)):\n            raise EquilibriaError(\"Matrix inversion problem in GS solver.\")\n        return np.reshape(x, b.shape)",
  "def __init__(self, grid: Grid, force_symmetry: bool = False):\n        self.grid = grid\n        self.force_symmetry = force_symmetry\n\n        gsoperator = GSOperator(\n            self.grid.x_min,\n            self.grid.x_max,\n            self.grid.z_min,\n            self.grid.z_max,\n            force_symmetry=self.force_symmetry,\n        )\n\n        super().__init__(gsoperator(self.grid.nx, self.grid.nz))",
  "def __call__(self, b: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Solves the linear system Ax=b using LU decomposition,\n        If the G-S operator is in symmetric form, problem symmetry\n        is explicitly enforced.\n\n        Parameters\n        ----------\n        b: np.array(nx, nz)\n            2-D X, Z map of the RHS of the G-S equation.\n        \"\"\"\n        if self.force_symmetry:\n            nz = self.grid.nz\n\n            # Trim RHS vector to half vector containing unique values\n            half_nz = np.floor_divide(nz + 1, 2)\n            b_half = b[:, 0:half_nz]\n\n            # Solve linear system\n            x_half = super().__call__(b_half)\n\n            # Create full-length vector by symmetry\n            x = np.zeros(np.shape(b))\n            x[:, 0:half_nz] = x_half\n            x[:, half_nz:] = np.flip(x_half, axis=1)[:, nz % 2 :]\n\n        else:\n            # Solve linear system with no symmetry assumptions.\n            x = super().__call__(b)\n\n        return x",
  "def _generate_theta(n: int) -> np.ndarray:\n    \"\"\"\n    Generate a poloidal angle vector that encompasses all extrema\n    \"\"\"\n    quart_values = np.array([0, 0.5 * np.pi, np.pi, 1.5 * np.pi, 2 * np.pi])\n    if n <= 4:\n        return quart_values[:n]\n\n    n_leftover = n % 4\n    n_chunk = n // 4\n\n    thetas = []\n    for i in range(0, 4):\n        if n_leftover != 0:\n            n_quart = n_chunk + 1\n            n_leftover -= 1\n        else:\n            n_quart = n_chunk\n        if n_quart > 1:\n            if i != 3:\n                theta = np.linspace(\n                    quart_values[i], quart_values[i + 1], n_quart + 1, endpoint=True\n                )[:-1]\n            else:\n                theta = np.linspace(\n                    quart_values[i], quart_values[i + 1], n_quart, endpoint=False\n                )[:-1]\n        else:\n            theta = np.array([quart_values[i]])\n        thetas.append(theta)\n    if n > 7:\n        thetas.append(np.array([2 * np.pi]))\n    return np.concatenate(thetas)",
  "def flux_surface_hirshman(\n    r_0: float, z_0: float, a: float, kappa: float, n: int = 20\n) -> Coordinates:\n    \"\"\"\n    Hirshman and Neilson flux surface parameterisation.\n\n    Parameters\n    ----------\n    r_0:\n        Plasma magnetic axis radius [m]\n    z_0:\n        Plasma magnetic axis height [m]\n    a:\n        Plasma geometric minor radius [m]\n    kappa:\n        Plasma elongation\n    n:\n        Number of points\n\n    Returns\n    -------\n    Plasma flux surface shape\n\n    Notes\n    -----\n    Hirshman and Neilson, 1986\n    https://pubs.aip.org/aip/pfl/article/29/3/790/944223/External-inductance-of-an-axisymmetric-plasma\n    \"\"\"\n    t = _generate_theta(n)\n    eps = a / r_0\n    x = r_0 * (1 + eps * np.cos(t))\n    z = z_0 + r_0 * eps * kappa * np.sin(t)\n    return Coordinates({\"x\": x, \"z\": z})",
  "def flux_surface_zakharov(\n    r_0: float, z_0: float, a: float, kappa: float, delta: float, n: int = 20\n) -> Coordinates:\n    \"\"\"\n    As featured in Zakharov's EMEQ\n\n    Parameters\n    ----------\n    r_0:\n        Plasma magnetic axis radius [m]\n    z_0:\n        Plasma magnetic axis height [m]\n    a:\n        Plasma geometric minor radius [m]\n    kappa:\n        Plasma elongation\n    delta:\n        Plasma triangularity\n    n:\n        Number of points\n\n    Returns\n    -------\n    Plasma flux surface shape\n\n    Notes\n    -----\n        https://inis.iaea.org/collection/NCLCollectionStore/_Public/17/074/17074881.pdf?r=1\n\n        Shafranov shift should be included in the r_0 parameter, as R_0 is\n        defined in the above as the magnetic axis. The Shafranov shift is\n        not subtracted to the r coordinates, contrary to the above equation\n        (4). This is because benchmarking with EMEQ shows this does not\n        appear to occur.\n    \"\"\"\n    t = _generate_theta(n)\n    x = r_0 + a * np.cos(t) - a * (delta) * np.sin(t) ** 2\n    z = z_0 + a * kappa * np.sin(t)\n    return Coordinates({\"x\": x, \"z\": z})",
  "class ZakharovLCFSOptVariables(OptVariablesFrame):\n    r_0: OptVariable = ov(\n        \"r_0\", 9, lower_bound=0, upper_bound=np.inf, description=\"Major radius\"\n    )\n    z_0: OptVariable = ov(\n        \"z_0\",\n        0,\n        lower_bound=-np.inf,\n        upper_bound=np.inf,\n        description=\"Vertical coordinate at geometry centroid\",\n    )\n    a: OptVariable = ov(\n        \"a\", 3, lower_bound=0, upper_bound=np.inf, description=\"Minor radius\"\n    )\n    kappa: OptVariable = ov(\n        \"kappa\", 1.5, lower_bound=1.0, upper_bound=np.inf, description=\"Elongation\"\n    )\n    delta: OptVariable = ov(\n        \"delta\",\n        0.4,\n        lower_bound=0.0,\n        upper_bound=1.0,\n        description=\"Triangularity\",\n    )",
  "class ZakharovLCFS(GeometryParameterisation[ZakharovLCFSOptVariables]):\n    \"\"\"\n    Zakharov last closed flux surface geometry parameterisation.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = ZakharovLCFSOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)\n\n    def create_shape(self, label: str = \"LCFS\", n_points: int = 1000) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the Zakharov LCFS.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n        n_points:\n            Number of points to use when creating the Bspline representation\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        coordinates = flux_surface_zakharov(\n            self.variables.r_0.value,\n            self.variables.z_0.value,\n            self.variables.a.value,\n            self.variables.kappa.value,\n            self.variables.delta.value,\n            n=n_points,\n        )\n        return interpolate_bspline(coordinates.xyz, closed=True, label=label)",
  "def flux_surface_cunningham(\n    r_0: float,\n    z_0: float,\n    a: float,\n    kappa: float,\n    delta: float,\n    delta2: float = 0.0,\n    n: int = 20,\n) -> Coordinates:\n    \"\"\"\n    As featured in Geof Cunningham's FIESTA (shape_fun)\n\n    Parameters\n    ----------\n    r_0:\n        Plasma geometric major radius [m]\n    z_0:\n        Plasma geometric vertical height [m]\n    a:\n        Plasma geometric minor radius [m]\n    kappa:\n        Plasma elongation\n    delta:\n        Plasma triangularity\n    delta2:\n        Plasma \"delta2\" curliness?\n    n:\n        Number of points\n\n    Returns\n    -------\n    Plasma flux surface shape\n\n    Notes\n    -----\n    This parameterisation does not appear to match delta perfectly for\n    abs(delta) > 0 and delta2=0.\n    \"\"\"\n    t = _generate_theta(n)\n    x = r_0 + a * np.cos(t + delta * np.sin(t) + delta2 * np.sin(2 * t))\n    z = z_0 + a * kappa * np.sin(t)\n    return Coordinates({\"x\": x, \"z\": z})",
  "class CunninghamLCFSOptVariables(OptVariablesFrame):\n    r_0: OptVariable = ov(\n        \"r_0\", 9, lower_bound=0, upper_bound=np.inf, description=\"Major radius\"\n    )\n    z_0: OptVariable = ov(\n        \"z_0\",\n        0,\n        lower_bound=-np.inf,\n        upper_bound=np.inf,\n        description=\"Vertical coordinate at geometry centroid\",\n    )\n    a: OptVariable = ov(\n        \"a\", 3, lower_bound=0, upper_bound=np.inf, description=\"Minor radius\"\n    )\n    kappa: OptVariable = ov(\n        \"kappa\", 1.5, lower_bound=1.0, upper_bound=np.inf, description=\"Elongation\"\n    )\n    delta: OptVariable = ov(\n        \"delta\",\n        0.4,\n        lower_bound=0.0,\n        upper_bound=1.0,\n        description=\"Triangularity\",\n    )\n    delta2: OptVariable = ov(\n        \"delta2\",\n        0.0,\n        lower_bound=0.0,\n        upper_bound=1.0,\n        description=\"Curliness\",\n    )",
  "class CunninghamLCFS(GeometryParameterisation[CunninghamLCFSOptVariables]):\n    \"\"\"\n    Cunningham last closed flux surface geometry parameterisation.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = CunninghamLCFSOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)\n\n    def create_shape(self, label: str = \"LCFS\", n_points: int = 1000) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the Cunningham LCFS.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n        n_points:\n            Number of points to use when creating the Bspline representation\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        coordinates = flux_surface_cunningham(\n            self.variables.r_0.value,\n            self.variables.z_0.value,\n            self.variables.a.value,\n            self.variables.kappa.value,\n            self.variables.delta.value,\n            self.variables.delta2.value,\n            n=n_points,\n        )\n        return interpolate_bspline(coordinates.xyz, closed=True, label=label)",
  "def flux_surface_manickam(\n    r_0: float,\n    z_0: float,\n    a: float,\n    kappa: float = 1.0,\n    delta: float = 0.0,\n    indent: float = 0.0,\n    n: int = 20,\n) -> Coordinates:\n    \"\"\"\n    J. Manickam, Nucl. Fusion 24 595 (1984)\n\n    Parameters\n    ----------\n    r_0:\n        Plasma geometric major radius [m]\n    z_0:\n        Plasma geometric vertical height [m]\n    a:\n        Plasma geometric minor radius [m]\n    kappa:\n        Plasma elongation\n    delta:\n        Plasma triangularity\n    indent:\n        Plasma indentation (beaniness)\n    n:\n        Number of points\n\n    Returns\n    -------\n    Plasma flux surface shape\n\n    Notes\n    -----\n    This parameterisation does not appear to match delta perfectly for\n    abs(delta) > 0 and indent=0.\n    \"\"\"\n    t = _generate_theta(n)\n    x = r_0 - indent + (a + indent * np.cos(t)) * np.cos(t + delta * np.sin(t))\n    z = z_0 + kappa * a * np.sin(t)\n    return Coordinates({\"x\": x, \"z\": z})",
  "class ManickamLCFSOptVariables(OptVariablesFrame):\n    r_0: OptVariable = ov(\n        \"r_0\", 9, lower_bound=0, upper_bound=np.inf, description=\"Major radius\"\n    )\n    z_0: OptVariable = ov(\n        \"z_0\",\n        0,\n        lower_bound=-np.inf,\n        upper_bound=np.inf,\n        description=\"Vertical coordinate at geometry centroid\",\n    )\n    a: OptVariable = ov(\n        \"a\", 3, lower_bound=0, upper_bound=np.inf, description=\"Minor radius\"\n    )\n    kappa: OptVariable = ov(\n        \"kappa\", 1.5, lower_bound=1.0, upper_bound=np.inf, description=\"Elongation\"\n    )\n    delta: OptVariable = ov(\n        \"delta\",\n        0.4,\n        lower_bound=0.0,\n        upper_bound=1.0,\n        description=\"Triangularity\",\n    )\n    indent: OptVariable = ov(\n        \"indent\",\n        0.0,\n        lower_bound=0.0,\n        upper_bound=1.0,\n        description=\"Indentation\",\n    )",
  "class ManickamLCFS(GeometryParameterisation[ManickamLCFSOptVariables]):\n    \"\"\"\n    Manickam last closed flux surface geometry parameterisation.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = ManickamLCFSOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)\n\n    def create_shape(self, label: str = \"LCFS\", n_points: int = 1000) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the Manickam LCFS.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n        n_points:\n            Number of points to use when creating the Bspline representation\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        coordinates = flux_surface_manickam(\n            self.variables.r_0.value,\n            self.variables.z_0.value,\n            self.variables.a.value,\n            self.variables.kappa.value,\n            self.variables.delta.value,\n            self.variables.indent.value,\n            n=n_points,\n        )\n        return interpolate_bspline(coordinates.xyz, closed=True, label=label)",
  "def flux_surface_kuiroukidis_quadrants(\n    r_0: float,\n    z_0: float,\n    a: float,\n    kappa_u: float,\n    kappa_l: float,\n    delta_u: float,\n    delta_l: float,\n    n_power: int = 8,\n    n_points: int = 100,\n) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n    \"\"\"\n    Kuiroukidis flux surface individual quadrants\n\n    please see :func:flux_surface_kuiroukidis for more information\n    \"\"\"\n    if delta_u < 0:\n        delta_u *= -1\n        upper_negative = True\n    else:\n        upper_negative = False\n    if delta_l < 0:\n        delta_l *= -1\n        lower_negative = True\n    else:\n        lower_negative = False\n\n    n_quart = n_points // 4\n    e_0 = a / r_0  # inverse aspect ratio\n\n    # upper part\n    theta_delta = np.pi - np.arctan(kappa_u / delta_u)\n    denom = np.pi * theta_delta**n_power - theta_delta**2 * np.pi ** (n_power - 1)\n    t_0 = (theta_delta**n_power - 0.5 * np.pi**n_power) / denom\n    t_1 = (-(theta_delta**2) + 0.5 * np.pi**2) / denom\n    theta_up_right = np.linspace(0, theta_delta, n_quart)\n    tau_up_right = t_0 * theta_up_right**2 + t_1 * theta_up_right**n_power\n\n    # The theta -> tau conversion approach seems flawed, and overshoots np.pi so we have\n    # to adjust\n    theta_up_left = np.linspace(theta_delta, np.pi, n_quart)\n    tau_up_left = t_0 * theta_up_left**2 + t_1 * theta_up_left**n_power\n\n    tau_up_left = np.clip(tau_up_left, None, np.pi)\n    clip_arg = np.where(tau_up_left == np.pi)[0][0]\n    tau_up_left = tau_up_left[: clip_arg + 1]\n\n    x_upper_right = r_0 * (\n        1 + e_0 * np.cos(tau_up_right + np.arcsin(delta_u) * np.sin(tau_up_right))\n    )\n    z_upper_right = r_0 * kappa_u * e_0 * np.sin(tau_up_right)\n\n    x_upper_left = r_0 * (\n        1 + e_0 * np.cos(tau_up_left + np.arcsin(delta_u) * np.sin(tau_up_left))\n    )\n    z_upper_left = r_0 * kappa_u * e_0 * np.sin(tau_up_left)\n    x_upper_left, _, z_upper_left = interpolate_points(\n        x_upper_left, np.zeros(len(x_upper_left)), z_upper_left, n_quart\n    )\n\n    # lower left\n    theta_delta_lower = np.pi - np.arctan(kappa_l / delta_l)\n    p_1 = (kappa_l * e_0) ** 2 / (2 * e_0 * (1 + np.cos(theta_delta_lower)))\n    theta = np.linspace(np.pi, 2 * np.pi - theta_delta_lower, n_quart)\n\n    x_left = r_0 * (1 + e_0 * np.cos(theta))\n    z_left = -r_0 * np.sqrt(2 * p_1 * e_0 * (1 + np.cos(theta)))\n\n    # lower right\n    p_2 = (kappa_l * e_0) ** 2 / (2 * e_0 * (1 - np.cos(theta_delta_lower)))\n    theta = np.linspace(2 * np.pi - theta_delta_lower, 2 * np.pi, n_quart)\n\n    x_right = r_0 * (1 + e_0 * np.cos(theta))\n    z_right = -r_0 * np.sqrt(2 * p_2 * e_0 * (1 - np.cos(theta)))\n\n    x_x_true = r_0 - delta_l * a\n    x_x_actual = r_0 * (1 + e_0 * np.cos(theta_delta_lower))\n\n    # The lower X-point does not match up with the input kappa_l and delta_l...\n    corr_ratio = x_x_true / x_x_actual\n    corr_power = 2\n    if corr_ratio == 1.0:\n        # For good measure, but the maths is wrong...\n        correction = np.ones(n_quart)\n    elif corr_ratio < 1.0:\n        correction = (\n            1\n            - np.linspace(0, (1 - corr_ratio) ** (1 / corr_power), n_quart) ** corr_power\n        )\n    elif corr_ratio > 1.0:\n        correction = (\n            1\n            + np.linspace(0, (corr_ratio - 1) ** (1 / corr_power), n_quart) ** corr_power\n        )\n\n    x_left *= correction\n    x_right *= correction[::-1]\n\n    if upper_negative:\n        x_upper_right = -x_upper_right + 2 * r_0\n        x_upper_left = -x_upper_left + 2 * r_0\n        x_upper_left, x_upper_right = x_upper_right[::-1], x_upper_left[::-1]\n        z_upper_left, z_upper_right = z_upper_right[::-1], z_upper_left[::-1]\n\n    if lower_negative:\n        x_left = -x_left + 2 * r_0\n        x_right = -x_right + 2 * r_0\n        x_left, x_right = x_right[::-1], x_left[::-1]\n        z_left, z_right = z_right[::-1], z_left[::-1]\n\n    return (\n        np.array([x_upper_right, x_upper_left, x_left, x_right]),\n        np.array([z_upper_right, z_upper_left, z_left, z_right]) + z_0,\n    )",
  "def flux_surface_kuiroukidis(\n    r_0: float,\n    z_0: float,\n    a: float,\n    kappa_u: float,\n    kappa_l: float,\n    delta_u: float,\n    delta_l: float,\n    n_power: int = 8,\n    n_points: int = 100,\n) -> Coordinates:\n    \"\"\"\n    Make an up-down asymmetric flux surface with a lower X-point.\n\n    Ap. Kuiroukidis and G. N. Throumoulopoulos, Plasma Phys. Control. Fusion 57  (2015)\n    078001\n\n    DOI: 10.1088/0741-3335/57/7/078001\n\n    Parameters\n    ----------\n    r_0:\n        Plasma geometric major radius [m]\n    z_0:\n        Plasma geometric vertical height [m]\n    a:\n        Plasma geometric minor radius [m]\n    kappa_u:\n        Upper plasma elongation\n    kappa_l:\n        Lower plasma elongation\n    delta_u:\n        Upper plasma triangularity\n    delta_l:\n        Lower plasma triangularity\n    n_power:\n        Exponent related to the steepness of the triangularity\n    n_points:\n        Number of points\n\n    Returns\n    -------\n    Plasma flux surface shape\n\n    Notes\n    -----\n    As far as I can tell, the reference parameterisation is either flawed in two places\n    or is insufficiently specified to reproduce properly. I've included two workarounds\n    here, which actually result in a very decent shape description.\n    Furthermore, the grad_rho term does not appear to behave as described, given that it\n    is just an offset. The key may lie in understand what \"relative to the X-point\" means\n    but it's not enough for me to go on at the moment.\n    \"\"\"\n    x_quadrants, z_quadrants = flux_surface_kuiroukidis_quadrants(\n        r_0,\n        z_0,\n        a,\n        kappa_u,\n        kappa_l,\n        delta_u,\n        delta_l,\n        n_power,\n        n_points,\n    )\n\n    return Coordinates(\n        {\"x\": np.concatenate(x_quadrants), \"z\": np.concatenate(z_quadrants)}\n    )",
  "class KuiroukidisLCFSOptVariables(OptVariablesFrame):\n    r_0: OptVariable = ov(\n        \"r_0\",\n        9,\n        lower_bound=0,\n        upper_bound=np.inf,\n        description=\"Major radius\",\n    )\n    z_0: OptVariable = ov(\n        \"z_0\",\n        0,\n        lower_bound=-np.inf,\n        upper_bound=np.inf,\n        description=\"Vertical coordinate at geometry centroid\",\n    )\n    a: OptVariable = ov(\n        \"a\", 3, lower_bound=0, upper_bound=np.inf, description=\"Minor radius\"\n    )\n    kappa_u: OptVariable = ov(\n        \"kappa_u\",\n        1.6,\n        lower_bound=1.0,\n        upper_bound=np.inf,\n        description=\"Upper elongation\",\n    )\n    kappa_l: OptVariable = ov(\n        \"kappa_l\",\n        1.8,\n        lower_bound=1.0,\n        upper_bound=np.inf,\n        description=\"Lower elongation\",\n    )\n    delta_u: OptVariable = ov(\n        \"delta_u\",\n        0.4,\n        lower_bound=0.0,\n        upper_bound=1.0,\n        description=\"Upper triangularity\",\n    )\n    delta_l: OptVariable = ov(\n        \"delta_l\",\n        0.4,\n        lower_bound=0.0,\n        upper_bound=1.0,\n        description=\"Lower triangularity\",\n    )\n    n_power: OptVariable = ov(\n        \"n_power\",\n        8,\n        lower_bound=2,\n        upper_bound=10,\n        description=\"Exponent power\",\n    )",
  "class KuiroukidisLCFS(GeometryParameterisation[KuiroukidisLCFSOptVariables]):\n    \"\"\"\n    Kuiroukidis last closed flux surface geometry parameterisation (adjusted).\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = KuiroukidisLCFSOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)\n\n    def create_shape(self, label: str = \"LCFS\", n_points: int = 1000) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the Kuiroukidis LCFS.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n        n_points:\n            Number of points to use when creating the Bspline representation\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        x_quadrants, z_quadrants = flux_surface_kuiroukidis_quadrants(\n            self.variables.r_0.value,\n            self.variables.z_0.value,\n            self.variables.a.value,\n            self.variables.kappa_u.value,\n            self.variables.kappa_l.value,\n            self.variables.delta_u.value,\n            self.variables.delta_l.value,\n            int(self.variables.n_power.value),\n            n_points=n_points,\n        )\n\n        labels = [\"upper_outer\", \"upper_inner\", \"lower_inner\", \"lower_outer\"]\n        return BluemiraWire(\n            [\n                interpolate_bspline(\n                    np.array([x_q, np.zeros(len(x_q)), z_q]).T, label=lab\n                )\n                for x_q, z_q, lab in zip(x_quadrants, z_quadrants, labels)\n            ],\n            label=label,\n        )",
  "def calc_t_neg(delta, kappa, phi_neg):\n    return np.tan(phi_neg) * (1 - delta) / kappa",
  "def calc_t_pos(delta, kappa, phi_pos):\n    return np.tan(phi_pos) * (1 + delta) / kappa",
  "def calc_angles_neg_below(delta, kappa, t_neg):\n    alpha_0_neg = -(delta - (1 + delta) * t_neg) / (1 - 2 * t_neg)\n    alpha_neg = (1 - delta) * (1 - t_neg) / (1 - 2 * t_neg)\n    beta_neg = kappa * (1 - t_neg) / np.sqrt(1 - 2 * t_neg)\n    return alpha_0_neg, alpha_neg, beta_neg",
  "def calc_angles_neg_above(delta, kappa, t_neg):\n    alpha_0_neg = -((1 + delta) * t_neg - delta) / (2 * t_neg - 1)\n    alpha_neg = (1 - delta) * (1 - t_neg) / (2 * t_neg - 1)\n    beta_neg = kappa * (1 - t_neg) / np.sqrt(2 * t_neg - 1)\n    return alpha_0_neg, alpha_neg, beta_neg",
  "def calc_angles_pos_below(delta, kappa, t_pos):\n    alpha_0_pos = -(delta + (1 - delta) * t_pos) / (1 - 2 * t_pos)\n    alpha_pos = (1 + delta) * (1 - t_pos) / (1 - 2 * t_pos)\n    beta_pos = kappa * (1 - t_pos) / np.sqrt(1 - 2 * t_pos)\n    return alpha_0_pos, alpha_pos, beta_pos",
  "def calc_angles_pos_above(delta, kappa, t_pos):\n    alpha_0_pos = ((1 - delta) * t_pos + delta) / (2 * t_pos - 1)\n    alpha_pos = -(1 + delta) * (1 - t_pos) / (2 * t_pos - 1)\n    beta_pos = kappa * (1 - t_pos) / np.sqrt(2 * t_pos - 1)\n    return alpha_0_pos, alpha_pos, beta_pos",
  "class _UpLow(Enum):\n    UPPER = auto()\n    LOWER = auto()",
  "class _InOut(Enum):\n    INNER = auto()\n    OUTER = auto()",
  "def _johner_quadrant(\n    delta: float, kappa: float, psi: float, n_pts: int, ul: _UpLow, io: _InOut\n) -> Tuple[float, float]:\n    calc_t = calc_t_neg if io is _InOut.INNER else calc_t_pos\n    t = calc_t(delta, kappa, psi)\n    if t < 0.5:\n        calc_angles = (\n            calc_angles_neg_below if io is _InOut.INNER else calc_angles_pos_below\n        )\n        alpha_0, alpha, beta = calc_angles(delta, kappa, t)\n\n        theta = np.arcsin(np.sqrt(1 - 2 * t) / (1 - t))\n        ls = (0, theta) if ul is _UpLow.UPPER else (-theta, 0)\n        theta = np.linspace(*ls, n_pts)\n\n        x = (\n            (alpha_0 - alpha * np.cos(theta))\n            if io is _InOut.INNER\n            else (alpha_0 + alpha * np.cos(theta))\n        )\n        z = beta * np.sin(theta)\n\n    elif t == 0.5:\n        ls = (0, kappa) if ul is _UpLow.UPPER else (-kappa, 0)\n        z = np.linspace(*ls, n_pts)\n        x = (\n            -1 + z**2 * (1 - delta) / kappa**2\n            if io is _InOut.INNER\n            else -1 - z**2 * (1 + delta) / kappa**2\n        )\n\n    elif t == 1:\n        ls = (0, kappa) if ul is _UpLow.UPPER else (-kappa, 0)\n        z = np.linspace(*ls, n_pts)\n        x = (\n            -1 + z * (1 - delta) / kappa\n            if io is _InOut.INNER\n            else 1 - z * (1 + delta) / kappa\n        )\n    elif t > 0.5:\n        calc_angles = (\n            calc_angles_neg_above if io is _InOut.INNER else calc_angles_pos_above\n        )\n\n        alpha_0, alpha, beta = calc_angles(delta, kappa, t)\n        phi = np.arcsinh(np.sqrt(2 * t - 1) / (1 - t))\n        ls = (0, phi) if ul is _UpLow.UPPER else (-phi, 0)\n        phi = np.linspace(*ls, n_pts)\n\n        x = alpha_0 + alpha * np.cosh(phi)\n        z = beta * np.sinh(phi)\n    else:\n        raise ValueError(\"Something is wrong with the Johner parameterisation.\")\n    return x, z",
  "def flux_surface_johner_quadrants(\n    r_0: float,\n    z_0: float,\n    a: float,\n    kappa_u: float,\n    kappa_l: float,\n    delta_u: float,\n    delta_l: float,\n    psi_u_neg: float,\n    psi_u_pos: float,\n    psi_l_neg: float,\n    psi_l_pos: float,\n    n: int = 100,\n) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n    \"\"\"\n    Initial plasma shape parametrerisation from HELIOS author\n    J. Johner (CEA). Sets initial separatrix shape for the plasma core\n    (does not handle divertor target points or legs).\n    Can handle:\n    - DN (positive, negative delta) [TESTED]\n    - SN (positive, negative delta) (upper, lower) [TESTED]\n\n    Parameters\n    ----------\n    r_0:\n        Major radius [m]\n    z_0:\n        Vertical position of major radius [m]\n    a:\n        Minor radius [m]\n    kappa_u:\n        Upper elongation at the plasma edge (psi_n=1)\n    kappa_l:\n        Lower elongation at the plasma edge (psi_n=1)\n    delta_u:\n        Upper triangularity at the plasma edge (psi_n=1)\n    delta_l:\n        Lower triangularity at the plasma edge (psi_n=1)\n    psi_u_neg:\n        Upper inner angle [\u00b0]\n    psi_u_pos:\n        Upper outer angle [\u00b0]\n    psi_l_neg:\n        Lower inner angle [\u00b0]\n    psi_l_pos:\n        Lower outer angle [\u00b0]\n    n: i\n        Number of point to generate on the flux surface\n\n    Returns\n    -------\n    x_quadrants:\n        Plasma flux surface shape x quadrants\n    z_quadrants:\n        Plasma flux surface shape z quadrants\n    \"\"\"\n    # Careful of bad angles or invalid plasma shape parameters\n    if delta_u < 0 and delta_l < 0:\n        delta_u *= -1\n        delta_l *= -1\n        negative = True\n    else:\n        negative = False\n    psi_u_neg, psi_u_pos, psi_l_neg, psi_l_pos = [\n        np.deg2rad(i) for i in [psi_u_neg, psi_u_pos, psi_l_neg, psi_l_pos]\n    ]\n\n    n_pts = int(n / 4)\n    # inner upper\n    x_ui, z_ui = _johner_quadrant(\n        delta_u, kappa_u, psi_u_neg, n_pts, ul=_UpLow.UPPER, io=_InOut.INNER\n    )\n    # inner lower\n    x_li, z_li = _johner_quadrant(\n        delta_l, kappa_l, psi_l_neg, n_pts, ul=_UpLow.LOWER, io=_InOut.INNER\n    )\n    # outer upper\n    x_uo, z_uo = _johner_quadrant(\n        delta_u, kappa_u, psi_u_pos, n_pts, ul=_UpLow.UPPER, io=_InOut.OUTER\n    )\n    # outer lower\n    x_lo, z_lo = _johner_quadrant(\n        delta_l, kappa_l, psi_l_pos, n_pts, ul=_UpLow.LOWER, io=_InOut.OUTER\n    )\n\n    x_quadrants = [x_ui, x_uo[::-1], x_lo[::-1], x_li]\n    z_quadrants = [z_ui, z_uo[::-1], z_lo[::-1], z_li]\n    x_quadrants = [a * xq + r_0 for xq in x_quadrants]\n    z_quadrants = [a * zq for zq in z_quadrants]\n    if negative:\n        x_quadrants = [-(xq - 2 * r_0) for xq in x_quadrants]\n\n    z_quadrants = [zq + z_0 for zq in z_quadrants]\n    return x_quadrants, z_quadrants",
  "def flux_surface_johner(\n    r_0: float,\n    z_0: float,\n    a: float,\n    kappa_u: float,\n    kappa_l: float,\n    delta_u: float,\n    delta_l: float,\n    psi_u_neg: float,\n    psi_u_pos: float,\n    psi_l_neg: float,\n    psi_l_pos: float,\n    n: int = 100,\n) -> Coordinates:\n    \"\"\"\n    Initial plasma shape parametrerisation from HELIOS author\n    J. Johner (CEA). Sets initial separatrix shape for the plasma core\n    (does not handle divertor target points or legs).\n    Can handle:\n    - DN (positive, negative delta) [TESTED]\n    - SN (positive, negative delta) (upper, lower) [TESTED]\n\n    Parameters\n    ----------\n    r_0:\n        Major radius [m]\n    z_0:\n        Vertical position of major radius [m]\n    a:\n        Minor radius [m]\n    kappa_u:\n        Upper elongation at the plasma edge (psi_n=1)\n    kappa_l:\n        Lower elongation at the plasma edge (psi_n=1)\n    delta_u:\n        Upper triangularity at the plasma edge (psi_n=1)\n    delta_l:\n        Lower triangularity at the plasma edge (psi_n=1)\n    psi_u_neg:\n        Upper inner angle [\u00b0]\n    psi_u_pos:\n        Upper outer angle [\u00b0]\n    psi_l_neg:\n        Lower inner angle [\u00b0]\n    psi_l_pos:\n        Lower outer angle [\u00b0]\n    n:\n        Number of point to generate on the flux surface\n\n    Returns\n    -------\n    Plasma flux surface shape\n    \"\"\"\n    x_quadrants, z_quadrants = flux_surface_johner_quadrants(\n        r_0,\n        z_0,\n        a,\n        kappa_u,\n        kappa_l,\n        delta_u,\n        delta_l,\n        psi_u_neg,\n        psi_u_pos,\n        psi_l_neg,\n        psi_l_pos,\n        n=n,\n    )\n\n    return Coordinates(\n        {\"x\": np.concatenate(x_quadrants), \"z\": np.concatenate(z_quadrants)}\n    )",
  "class JohnerLCFSOptVariables(OptVariablesFrame):\n    r_0: OptVariable = ov(\n        \"r_0\", 9, lower_bound=6, upper_bound=12, description=\"Major radius\"\n    )\n    z_0: OptVariable = ov(\n        \"z_0\",\n        0,\n        lower_bound=-1,\n        upper_bound=1,\n        description=\"Vertical coordinate at geometry centroid\",\n    )\n    a: OptVariable = ov(\"a\", 6, lower_bound=1, upper_bound=6, description=\"Minor radius\")\n    kappa_u: OptVariable = ov(\n        \"kappa_u\",\n        1.6,\n        lower_bound=1.0,\n        upper_bound=3.0,\n        description=\"Upper elongation\",\n    )\n    kappa_l: OptVariable = ov(\n        \"kappa_l\",\n        1.8,\n        lower_bound=1.0,\n        upper_bound=3.0,\n        description=\"Lower elongation\",\n    )\n    delta_u: OptVariable = ov(\n        \"delta_u\",\n        0.4,\n        lower_bound=0.0,\n        upper_bound=1.0,\n        description=\"Upper triangularity\",\n    )\n    delta_l: OptVariable = ov(\n        \"delta_l\",\n        0.4,\n        lower_bound=0.0,\n        upper_bound=1.0,\n        description=\"Lower triangularity\",\n    )\n    phi_u_neg: OptVariable = ov(\n        \"phi_u_neg\",\n        180,\n        lower_bound=0,\n        upper_bound=190,\n        description=\"Upper inner angle [\u00b0]\",\n    )\n    phi_u_pos: OptVariable = ov(\n        \"phi_u_pos\",\n        10,\n        lower_bound=0,\n        upper_bound=20,\n        description=\"Upper outer angle [\u00b0]\",\n    )\n    phi_l_neg: OptVariable = ov(\n        \"phi_l_neg\",\n        -120,\n        lower_bound=-130,\n        upper_bound=45,\n        description=\"Lower inner angle [\u00b0]\",\n    )\n    phi_l_pos: OptVariable = ov(\n        \"phi_l_pos\",\n        30,\n        lower_bound=0,\n        upper_bound=45,\n        description=\"Lower outer angle [\u00b0]\",\n    )",
  "class JohnerLCFS(GeometryParameterisation[JohnerLCFSOptVariables]):\n    \"\"\"\n    Johner last closed flux surface geometry parameterisation.\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = JohnerLCFSOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)\n\n    def create_shape(self, label: str = \"LCFS\", n_points: int = 1000) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the Johner LCFS.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n        n_points:\n            Number of points to use when creating the Bspline representation\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        x_quadrants, z_quadrants = flux_surface_johner_quadrants(\n            *self.variables.values, n=n_points\n        )\n\n        wires = []\n        labels = [\"upper_inner\", \"upper_outer\", \"lower_outer\", \"lower_inner\"]\n        for x_q, z_q, lab in zip(x_quadrants, z_quadrants, labels):\n            wires.append(\n                interpolate_bspline(\n                    np.array([x_q, np.zeros(len(x_q)), z_q]).T, label=lab\n                )\n            )\n\n        return BluemiraWire(wires, label=label)",
  "def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = ZakharovLCFSOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)",
  "def create_shape(self, label: str = \"LCFS\", n_points: int = 1000) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the Zakharov LCFS.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n        n_points:\n            Number of points to use when creating the Bspline representation\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        coordinates = flux_surface_zakharov(\n            self.variables.r_0.value,\n            self.variables.z_0.value,\n            self.variables.a.value,\n            self.variables.kappa.value,\n            self.variables.delta.value,\n            n=n_points,\n        )\n        return interpolate_bspline(coordinates.xyz, closed=True, label=label)",
  "def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = CunninghamLCFSOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)",
  "def create_shape(self, label: str = \"LCFS\", n_points: int = 1000) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the Cunningham LCFS.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n        n_points:\n            Number of points to use when creating the Bspline representation\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        coordinates = flux_surface_cunningham(\n            self.variables.r_0.value,\n            self.variables.z_0.value,\n            self.variables.a.value,\n            self.variables.kappa.value,\n            self.variables.delta.value,\n            self.variables.delta2.value,\n            n=n_points,\n        )\n        return interpolate_bspline(coordinates.xyz, closed=True, label=label)",
  "def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = ManickamLCFSOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)",
  "def create_shape(self, label: str = \"LCFS\", n_points: int = 1000) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the Manickam LCFS.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n        n_points:\n            Number of points to use when creating the Bspline representation\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        coordinates = flux_surface_manickam(\n            self.variables.r_0.value,\n            self.variables.z_0.value,\n            self.variables.a.value,\n            self.variables.kappa.value,\n            self.variables.delta.value,\n            self.variables.indent.value,\n            n=n_points,\n        )\n        return interpolate_bspline(coordinates.xyz, closed=True, label=label)",
  "def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = KuiroukidisLCFSOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)",
  "def create_shape(self, label: str = \"LCFS\", n_points: int = 1000) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the Kuiroukidis LCFS.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n        n_points:\n            Number of points to use when creating the Bspline representation\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        x_quadrants, z_quadrants = flux_surface_kuiroukidis_quadrants(\n            self.variables.r_0.value,\n            self.variables.z_0.value,\n            self.variables.a.value,\n            self.variables.kappa_u.value,\n            self.variables.kappa_l.value,\n            self.variables.delta_u.value,\n            self.variables.delta_l.value,\n            int(self.variables.n_power.value),\n            n_points=n_points,\n        )\n\n        labels = [\"upper_outer\", \"upper_inner\", \"lower_inner\", \"lower_outer\"]\n        return BluemiraWire(\n            [\n                interpolate_bspline(\n                    np.array([x_q, np.zeros(len(x_q)), z_q]).T, label=lab\n                )\n                for x_q, z_q, lab in zip(x_quadrants, z_quadrants, labels)\n            ],\n            label=label,\n        )",
  "def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = JohnerLCFSOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)",
  "def create_shape(self, label: str = \"LCFS\", n_points: int = 1000) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the Johner LCFS.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n        n_points:\n            Number of points to use when creating the Bspline representation\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        x_quadrants, z_quadrants = flux_surface_johner_quadrants(\n            *self.variables.values, n=n_points\n        )\n\n        wires = []\n        labels = [\"upper_inner\", \"upper_outer\", \"lower_outer\", \"lower_inner\"]\n        for x_q, z_q, lab in zip(x_quadrants, z_quadrants, labels):\n            wires.append(\n                interpolate_bspline(\n                    np.array([x_q, np.zeros(len(x_q)), z_q]).T, label=lab\n                )\n            )\n\n        return BluemiraWire(wires, label=label)",
  "class EquilibriaError(BluemiraError):\n    \"\"\"\n    Base class for equilibria errors.\n    \"\"\"\n\n    pass",
  "class FluxSurfaceError(EquilibriaError):\n    \"\"\"\n    Error class for FluxSurfaces.\n    \"\"\"\n\n    pass",
  "class Grid:\n    \"\"\"\n    A rectangular Grid object with regular rectangular cells for use in finite\n    difference calculations.\n\n    Parameters\n    ----------\n    x_min: float > 0\n        Minimum x grid coordinate [m]\n    x_max: float\n        Maximum x grid coordinate [m]\n    z_min: float\n        Minimum z grid coordinate [m]\n    z_max: float\n        Maximum z grid coordinate [m]\n    nx: int\n        Number of x grid points\n    nz: int\n        Number of z grid points\n    \"\"\"\n\n    __slots__ = [\n        \"x_min\",\n        \"x_max\",\n        \"x_size\",\n        \"x_mid\",\n        \"x_1d\",\n        \"x\",\n        \"z_min\",\n        \"z_max\",\n        \"z_size\",\n        \"z_mid\",\n        \"z_1d\",\n        \"z\",\n        \"dx\",\n        \"dz\",\n        \"nx\",\n        \"nz\",\n        \"bounds\",\n        \"edges\",\n    ]\n\n    def __init__(self, x_min, x_max, z_min, z_max, nx, nz):\n        if x_min == x_max or z_min == z_max:\n            raise EquilibriaError(\"Invalid Grid dimensions specified.\")\n\n        if x_min > x_max:\n            print(\"\")  # stdout flusher\n            bluemira_warn(\n                f\"x_min should be < x_max {x_min:.2f} > {x_max:.2f}. Switching x_min and x_max.\"\n            )\n            x_min, x_max = x_max, x_min\n\n        if z_min > z_max:\n            print(\"\")  # stdout flusher\n            bluemira_warn(\n                f\"z_min should be < z_max {z_min:.2f} > {z_max:.2f}. Switching z_min and z_max.\"\n            )\n            z_min, z_max = z_max, z_min\n\n        if x_min <= 0:  # Cannot calculate flux on machine axis - (divide by 0)\n            x_min = X_AXIS_MIN\n\n        if nx < MIN_N_DISCR:\n            print(\"\")  # stdout flusher\n            bluemira_warn(\n                f\"Insufficient nx discretisation: {nx}, setting to {MIN_N_DISCR}.\"\n            )\n            nx = MIN_N_DISCR\n\n        if nz < MIN_N_DISCR:\n            print(\"\")  # stdout flusher\n            bluemira_warn(\n                f\"Insufficient nx discretisation: {nz}, setting to {MIN_N_DISCR}.\"\n            )\n            nz = MIN_N_DISCR\n\n        self.x_min = x_min\n        self.x_max = x_max\n        self.x_size = x_max - x_min\n        self.x_mid = (x_max - x_min) / 2\n        self.z_min = z_min\n        self.z_max = z_max\n        self.z_size = abs(z_max) + abs(z_min)\n        self.z_mid = z_min + (z_max - z_min) / 2\n        self.x_1d = np.linspace(x_min, x_max, nx)\n        self.z_1d = np.linspace(z_min, z_max, nz)\n        self.x, self.z = np.meshgrid(self.x_1d, self.z_1d, indexing=\"ij\")\n        self.dx = np.diff(self.x_1d[:2])[0]  # Grid sizes\n        self.dz = np.diff(self.z_1d[:2])[0]\n        self.nx, self.nz = nx, nz\n        self.bounds = [\n            [x_min, x_max, x_max, x_min, x_min],  # Grid corners\n            [z_min, z_min, z_max, z_max, z_min],\n        ]\n        self.edges = np.concatenate(\n            [\n                [(x, 0) for x in range(nx)],  # Grid edges\n                [(x, nz - 1) for x in range(nx)],\n                [(0, z) for z in range(nz)],\n                [(nx - 1, z) for z in range(nz)],\n            ]\n        )\n\n    @classmethod\n    def from_eqdict(cls, e):\n        \"\"\"\n        Initialise a Grid object from an EQDSK dictionary.\n\n        Parameters\n        ----------\n        e: dict\n            EQDSK dictionary\n        \"\"\"\n        return cls(\n            e[\"xgrid1\"],\n            e[\"xgrid1\"] + e[\"xdim\"],\n            e[\"zmid\"] - 0.5 * e[\"zdim\"],\n            e[\"zmid\"] + 0.5 * e[\"zdim\"],\n            e[\"nx\"],\n            e[\"nz\"],\n        )\n\n    @classmethod\n    def from_eqdsk(cls, e):\n        \"\"\"\n        Initialise a Grid object from an EQDSKInterface.\n\n        Parameters\n        ----------\n        e: EQDSKInterface\n\n        \"\"\"\n        return cls(\n            e.xgrid1,\n            e.xgrid1 + e.xdim,\n            e.zmid - 0.5 * e.zdim,\n            e.zmid + 0.5 * e.zdim,\n            e.nx,\n            e.nz,\n        )\n\n    def point_inside(self, x, z=None):\n        \"\"\"\n        Determine if a point is inside the rectangular grid (includes edges).\n\n        Parameters\n        ----------\n        x: Union[float, Iterable]\n            The x coordinate of the point. Or the 2-D point.\n        z: Optional[float]\n            The z coordinate of the point\n\n        Returns\n        -------\n        inside: bool\n            Whether or not the point is inside the grid\n        \"\"\"\n        if z is None:\n            x, z = x\n        return (\n            (x >= self.x_min)\n            and (x <= self.x_max)\n            and (z >= self.z_min)\n            and (z <= self.z_max)\n        )\n\n    def distance_to(self, x, z=None):\n        \"\"\"\n        Get the distances of a point to the edges of the Grid.\n\n        Parameters\n        ----------\n        x: Union[float, Iterable]\n            The x coordinate of the point. Or the 2-D point.\n        z: Optional[float]\n            The z coordinate of the point\n\n        Returns\n        -------\n        distances: np.ndarray\n            Distances to the edges of the Grid.\n        \"\"\"\n        if z is None:\n            x, z = x\n        return np.abs(\n            [\n                x - self.x_min,\n                x - self.x_max,\n                z - self.z_min,\n                z - self.z_max,\n            ]\n        )\n\n    def plot(self, ax=None, **kwargs):\n        \"\"\"\n        Plot the Grid object onto an ax.\n        \"\"\"\n        from bluemira.equilibria.plotting import GridPlotter  # noqa (circular import)\n\n        return GridPlotter(self, ax=ax, **kwargs)",
  "def integrate_dx_dz(func, d_x, d_z):\n    \"\"\"\n    Get the double-integral of a function over the space.\n\n    \\t:math:`\\\\int_Z\\\\int_X f(x, z) dXdZ`\n\n    Parameters\n    ----------\n    func: np.array(N, M)\n        A 2-D function map\n    d_x: float\n        The discretisation size in the X coordinate\n    d_z: float\n        The discretisation size in the Z coordinate\n\n    Returns\n    -------\n    integral: float\n        The integral value of the field in 2-D\n    \"\"\"\n    return np.trapz(np.trapz(func)) * d_x * d_z",
  "def volume_integral(func, x, d_x, d_z):\n    \"\"\"\n    Calculate the volume integral of a field in quasi-cylindrical coordinates.\n\n    Parameters\n    ----------\n    func: 2-D np.array\n        Field to volume integrate\n    x: 2-D np.array\n        X coordinate grid\n    d_x: float\n        Grid X cell size\n    d_z: float\n        Grid Z cell size\n\n    Returns\n    -------\n    integral: float\n        The integral value of the field in 3-D space\n    \"\"\"\n    return 2 * np.pi * integrate_dx_dz(func * x, d_x, d_z)",
  "def revolved_volume(x, z):\n    \"\"\"\n    Calculate the revolved volume of a set of x, z coordinates. Revolution about\n    [0, 0, 1].\n\n    Parameters\n    ----------\n    x: np.array\n        The x coordinates\n    z: np.array\n        The z coordinates\n\n    Returns\n    -------\n    volume: float\n        The volume of the revolved x, z coordinates\n    \"\"\"\n    area = get_area_2d(x, z)\n    cx, _ = get_centroid_2d(x, z)\n    return 2 * np.pi * cx * area",
  "def __init__(self, x_min, x_max, z_min, z_max, nx, nz):\n        if x_min == x_max or z_min == z_max:\n            raise EquilibriaError(\"Invalid Grid dimensions specified.\")\n\n        if x_min > x_max:\n            print(\"\")  # stdout flusher\n            bluemira_warn(\n                f\"x_min should be < x_max {x_min:.2f} > {x_max:.2f}. Switching x_min and x_max.\"\n            )\n            x_min, x_max = x_max, x_min\n\n        if z_min > z_max:\n            print(\"\")  # stdout flusher\n            bluemira_warn(\n                f\"z_min should be < z_max {z_min:.2f} > {z_max:.2f}. Switching z_min and z_max.\"\n            )\n            z_min, z_max = z_max, z_min\n\n        if x_min <= 0:  # Cannot calculate flux on machine axis - (divide by 0)\n            x_min = X_AXIS_MIN\n\n        if nx < MIN_N_DISCR:\n            print(\"\")  # stdout flusher\n            bluemira_warn(\n                f\"Insufficient nx discretisation: {nx}, setting to {MIN_N_DISCR}.\"\n            )\n            nx = MIN_N_DISCR\n\n        if nz < MIN_N_DISCR:\n            print(\"\")  # stdout flusher\n            bluemira_warn(\n                f\"Insufficient nx discretisation: {nz}, setting to {MIN_N_DISCR}.\"\n            )\n            nz = MIN_N_DISCR\n\n        self.x_min = x_min\n        self.x_max = x_max\n        self.x_size = x_max - x_min\n        self.x_mid = (x_max - x_min) / 2\n        self.z_min = z_min\n        self.z_max = z_max\n        self.z_size = abs(z_max) + abs(z_min)\n        self.z_mid = z_min + (z_max - z_min) / 2\n        self.x_1d = np.linspace(x_min, x_max, nx)\n        self.z_1d = np.linspace(z_min, z_max, nz)\n        self.x, self.z = np.meshgrid(self.x_1d, self.z_1d, indexing=\"ij\")\n        self.dx = np.diff(self.x_1d[:2])[0]  # Grid sizes\n        self.dz = np.diff(self.z_1d[:2])[0]\n        self.nx, self.nz = nx, nz\n        self.bounds = [\n            [x_min, x_max, x_max, x_min, x_min],  # Grid corners\n            [z_min, z_min, z_max, z_max, z_min],\n        ]\n        self.edges = np.concatenate(\n            [\n                [(x, 0) for x in range(nx)],  # Grid edges\n                [(x, nz - 1) for x in range(nx)],\n                [(0, z) for z in range(nz)],\n                [(nx - 1, z) for z in range(nz)],\n            ]\n        )",
  "def from_eqdict(cls, e):\n        \"\"\"\n        Initialise a Grid object from an EQDSK dictionary.\n\n        Parameters\n        ----------\n        e: dict\n            EQDSK dictionary\n        \"\"\"\n        return cls(\n            e[\"xgrid1\"],\n            e[\"xgrid1\"] + e[\"xdim\"],\n            e[\"zmid\"] - 0.5 * e[\"zdim\"],\n            e[\"zmid\"] + 0.5 * e[\"zdim\"],\n            e[\"nx\"],\n            e[\"nz\"],\n        )",
  "def from_eqdsk(cls, e):\n        \"\"\"\n        Initialise a Grid object from an EQDSKInterface.\n\n        Parameters\n        ----------\n        e: EQDSKInterface\n\n        \"\"\"\n        return cls(\n            e.xgrid1,\n            e.xgrid1 + e.xdim,\n            e.zmid - 0.5 * e.zdim,\n            e.zmid + 0.5 * e.zdim,\n            e.nx,\n            e.nz,\n        )",
  "def point_inside(self, x, z=None):\n        \"\"\"\n        Determine if a point is inside the rectangular grid (includes edges).\n\n        Parameters\n        ----------\n        x: Union[float, Iterable]\n            The x coordinate of the point. Or the 2-D point.\n        z: Optional[float]\n            The z coordinate of the point\n\n        Returns\n        -------\n        inside: bool\n            Whether or not the point is inside the grid\n        \"\"\"\n        if z is None:\n            x, z = x\n        return (\n            (x >= self.x_min)\n            and (x <= self.x_max)\n            and (z >= self.z_min)\n            and (z <= self.z_max)\n        )",
  "def distance_to(self, x, z=None):\n        \"\"\"\n        Get the distances of a point to the edges of the Grid.\n\n        Parameters\n        ----------\n        x: Union[float, Iterable]\n            The x coordinate of the point. Or the 2-D point.\n        z: Optional[float]\n            The z coordinate of the point\n\n        Returns\n        -------\n        distances: np.ndarray\n            Distances to the edges of the Grid.\n        \"\"\"\n        if z is None:\n            x, z = x\n        return np.abs(\n            [\n                x - self.x_min,\n                x - self.x_max,\n                z - self.z_min,\n                z - self.z_max,\n            ]\n        )",
  "def plot(self, ax=None, **kwargs):\n        \"\"\"\n        Plot the Grid object onto an ax.\n        \"\"\"\n        from bluemira.equilibria.plotting import GridPlotter  # noqa (circular import)\n\n        return GridPlotter(self, ax=ax, **kwargs)",
  "def objective_constraint(\n    constraint: np.ndarray,\n    vector: np.ndarray,\n    grad: np.ndarray,\n    objective_function: Callable[[np.ndarray], np.ndarray],\n    maximum_fom: float = 1.0,\n) -> np.ndarray:\n    \"\"\"\n    Constraint function to constrain the maximum value of an NLOpt objective\n    function provided\n\n    Parameters\n    ----------\n    constraint:\n        Constraint vector (modified in place)\n    vector:\n        Variable vector with which to evaluate the objective function\n    grad:\n        Constraint Jacobian\n    objective_function:\n        Objective function to use in constraint\n    maximum_fom:\n        Value to constrain the objective function by during optimisation\n\n    Returns\n    -------\n    Updated constraint vector\n    \"\"\"\n    constraint[:] = objective_function(vector, grad) - maximum_fom\n    return constraint",
  "def Ax_b_constraint(  # noqa: N802\n    constraint: np.ndarray,\n    vector: np.ndarray,\n    grad: np.ndarray,\n    a_mat: np.ndarray,\n    b_vec: np.ndarray,\n    value: float,\n    scale: float,\n) -> np.ndarray:\n    \"\"\"\n    Constraint function of the form:\n        A.x - b < value\n\n    Parameters\n    ----------\n    constraint:\n        Constraint array (modified in place)\n    vector:\n        Variable vector\n    grad:\n        Constraint Jacobian (modified in place)\n    a_mat:\n        Response matrix\n    b_vec:\n        Target value vector\n    value:\n        Target constraint value\n    scale:\n        Current scale with which to calculate the constraints\n\n    Returns\n    -------\n    Updated constraint vector\n    \"\"\"\n    constraint[:] = a_mat @ (scale * vector) - b_vec - value\n    if grad.size > 0:\n        grad[:] = scale * a_mat\n    return constraint",
  "def L2_norm_constraint(  # noqa: N802\n    constraint: np.ndarray,\n    vector: np.ndarray,\n    grad: np.ndarray,\n    a_mat: np.ndarray,\n    b_vec: np.ndarray,\n    value: float,\n    scale: float,\n) -> np.ndarray:\n    \"\"\"\n    Constrain the L2 norm of an Ax-b system of equations.\n    ||(Ax - b)||\u00b2 < value\n\n    Parameters\n    ----------\n    constraint:\n        Constraint array (modified in place)\n    vector:\n        Variable vector\n    grad:\n        Constraint Jacobian (modified in place)\n    A_mat:\n        Response matrix\n    b_vec:\n        Target value vector\n    scale:\n        Current scale with which to calculate the constraints\n\n    Returns\n    -------\n    Updated constraint vector\n    \"\"\"\n    vector = scale * vector\n    residual = a_mat @ vector - b_vec\n    constraint[:] = residual.T @ residual - value\n\n    if grad.size > 0:\n        grad[:] = 2 * scale * (a_mat.T @ a_mat @ vector - a_mat.T @ b_vec)\n\n    return constraint",
  "def current_midplane_constraint(\n    constraint: np.ndarray,\n    vector: np.ndarray,\n    grad: np.ndarray,\n    eq: Equilibrium,\n    radius: float,\n    scale: float,\n    inboard: bool = True,\n) -> np.ndarray:\n    \"\"\"\n    Constraint function to constrain the inboard or outboard midplane\n    of the plasma during optimisation.\n\n    Parameters\n    ----------\n    constraint:\n        Constraint array (modified in place)\n    vector:\n        Current vector\n    grad:\n        Constraint Jacobian (modified in place)\n    eq:\n        Equilibrium to use to fetch last closed flux surface from.\n    radius:\n        Toroidal radius at which to constrain the plasma midplane.\n    scale:\n        Current scale with which to calculate the constraints\n    inboard:\n        Boolean controlling whether to constrain the inboard (if True) or\n        outboard (if False) side of the plasma midplane.\n\n    Returns\n    -------\n    Updated constraint vector\n    \"\"\"\n    eq.coilset.get_control_coils().current = vector * scale\n    lcfs = eq.get_LCFS()\n    if inboard:\n        constraint[:] = radius - min(lcfs.x)\n    else:\n        constraint[:] = max(lcfs.x) - radius\n    return constraint",
  "def coil_force_constraints(\n    constraint: np.ndarray,\n    vector: np.ndarray,\n    grad: np.ndarray,\n    a_mat: np.ndarray,\n    b_vec: np.ndarray,\n    n_PF: int,\n    n_CS: int,\n    PF_Fz_max: float,\n    CS_Fz_sum_max: float,\n    CS_Fz_sep_max: float,\n    scale: float,\n) -> np.ndarray:\n    \"\"\"\n    Current optimisation force constraints on coils\n\n    Parameters\n    ----------\n    constraint:\n        Constraint array (modified in place)\n    vector:\n        Current vector\n    grad:\n        Constraint Jacobian (modified in place)\n    a_mat:\n        Response matrix block for Fx and Fz\n    b_vec:\n        Background value vector block for Fx and Fz\n    n_PF:\n        Number of PF coils\n    n_CS:\n        Number of CS coils\n    PF_Fz_max:\n        Maximum vertical force on each PF coil [N]\n    CS_Fz_sum_max:\n        Maximum total vertical force on the CS stack [N]\n    CS_Fz_sep_max:\n        Maximum vertical separation force in the CS stack [N]\n    scale:\n        Current scale with which to calculate the constraints\n\n    Returns\n    -------\n    Updated constraint vector\n    \"\"\"\n    n_coils = len(vector)\n    currents = scale * vector\n\n    # get coil force and jacobian\n    F = np.zeros((n_coils, 2))\n    PF_Fz_max /= scale\n    CS_Fz_sep_max /= scale\n    CS_Fz_sum_max /= scale\n\n    for i in range(2):  # coil force\n        # NOTE: * Hadamard matrix product\n        F[:, i] = currents * (a_mat[:, :, i] @ currents + b_vec[:, i])\n\n    F /= scale  # Scale down to MN\n\n    # Absolute vertical force constraint on PF coils\n    constraint[:n_PF] = F[:n_PF, 1] ** 2 - PF_Fz_max**2\n\n    if n_CS != 0:\n        # vertical forces on CS coils\n        cs_fz = F[n_PF:, 1]\n        # vertical force on CS stack\n        cs_z_sum = np.sum(cs_fz)\n        # Absolute sum of vertical force constraint on entire CS stack\n        constraint[n_PF] = cs_z_sum**2 - CS_Fz_sum_max**2\n        for i in range(n_CS - 1):  # evaluate each gap in CS stack\n            # CS separation constraints\n            f_sep = np.sum(cs_fz[: i + 1]) - np.sum(cs_fz[i + 1 :])\n            constraint[n_PF + 1 + i] = f_sep - CS_Fz_sep_max\n\n    # calculate constraint jacobian\n    if grad.size > 0:\n        dF = np.zeros((n_coils, n_coils, 2))  # noqa: N806\n        im = currents.reshape(-1, 1) @ np.ones((1, n_coils))  # current matrix\n        for i in range(2):\n            dF[:, :, i] = im * a_mat[:, :, i]\n            diag = (\n                a_mat[:, :, i] @ currents\n                + currents * np.diag(a_mat[:, :, i])\n                + b_vec[:, i]\n            )\n            np.fill_diagonal(dF[:, :, i], diag)\n\n        # Absolute vertical force constraint on PF coils\n        grad[:n_PF] = 2 * dF[:n_PF, :, 1]\n\n        if n_CS != 0:\n            # Absolute sum of vertical force constraint on entire CS stack\n            grad[n_PF] = 2 * np.sum(dF[n_PF:, :, 1], axis=0)\n\n            for i in range(n_CS - 1):  # evaluate each gap in CS stack\n                # CS separation constraint Jacobians\n                f_up = np.sum(dF[n_PF : n_PF + i + 1, :, 1], axis=0)\n                f_down = np.sum(dF[n_PF + i + 1 :, :, 1], axis=0)\n                grad[n_PF + 1 + i] = f_up - f_down\n    return constraint",
  "def field_constraints(\n    constraint: np.ndarray,\n    vector: np.ndarray,\n    grad: np.ndarray,\n    ax_mat: np.ndarray,\n    az_mat: np.ndarray,\n    bxp_vec: np.ndarray,\n    bzp_vec: np.ndarray,\n    B_max: np.ndarray,\n    scale: float,\n) -> np.ndarray:\n    \"\"\"\n    Current optimisation poloidal field constraints at prescribed locations\n\n    Parameters\n    ----------\n    constraint:\n        Constraint array (modified in place)\n    vector:\n        Current vector\n    grad:\n        Constraint Jacobian (modified in place)\n    ax_mat:\n        Response matrix for Bx (active coil contributions)\n    az_mat:\n        Response matrix for Bz (active coil contributions)\n    bxp_vec:\n        Background vector for Bx (passive coil contributions)\n    bzp_vec:\n        Background vector for Bz (passive coil contributions)\n    B_max:\n        Maximum fields inside the coils\n    scale:\n        Current scale with which to calculate the constraints\n\n    Returns\n    -------\n    Updated constraint vector\n    \"\"\"\n    currents = scale * vector\n    Bx_a = ax_mat @ currents\n    Bz_a = az_mat @ currents\n\n    B = np.hypot(Bx_a + bxp_vec, Bz_a + bzp_vec)\n    if grad.size > 0:\n        grad[:] = (\n            Bx_a * (Bx_a @ currents + bxp_vec) + Bz_a * (Bz_a @ currents + bzp_vec)\n        ) / (B * scale**2)\n\n    constraint[:] = B - B_max\n    return constraint",
  "def spherical_harmonics_constraint(\n    constraint: np.ndarray,\n    vector: np.ndarray,\n    grad: np.ndarray,\n    ref_harmonics: np.ndarray,\n    scale: float,\n    eq: Equilibrium,\n    r_t: float,\n    max_degree: int,\n) -> np.ndarray:\n    \"\"\"\n    Constraint function to constrain spherical harmonics starting from initial\n    coil currents and associated core plasma.\n\n    Parameters\n    ----------\n    constraint:\n        Constraint array (modified in place)\n    vector:\n        Current vector\n    grad:\n        Constraint Jacobian (modified in place)\n    ref_harmonics:\n        Initial harmonic amplitudes obtained from desired core plasma\n    scale:\n        Current scale with which to calculate the constraints\n    eq:\n        Equilibrium used to for coilset.\n    r_t: float\n        Typical length scale of the problem (e.g. radius at outer midplane)\n    max_degree:\n        Maximum degree of spherical harmonics desired to constrain\n    \"\"\"\n    currents = scale * vector\n\n    vector_harmonics_matrix = harmonics.coil_harmonic_amplitude_matrix(\n        eq.coilset, max_degree, r_t\n    )\n\n    # SH coefficients from function of the current distribution outside of the sphere\n    # containing the plasma, i.e., LCFS (r_lcfs)\n    # N.B., cannot use coil located within r_lcfs as part of this method.\n    vector_harmonics = vector_harmonics_matrix @ currents\n    constraint[:] = vector_harmonics - ref_harmonics\n\n    # calculate constraint jacobian\n    if grad.size > 0:\n        grad[:] = scale * vector_harmonics_matrix\n\n    return constraint",
  "class CoilsetOptimisationProblem(OptimisationProblem):\n    \"\"\"\n    Abstract base class for OptimisationProblems for the coilset.\n    Provides helper methods and utilities for OptimisationProblems\n    using a coilset as their parameterisation object.\n\n    Subclasses should provide an optimise() method that\n    returns an optimised coilset object, optimised according\n    to a specific objective function for that subclass.\n\n    Parameters\n    ----------\n    coilset: Coilset\n        Coilset to be optimised.\n    optimiser: bluemira.utilities.optimiser.Optimiser (default: None)\n        Optimiser object to use for constrained optimisation.\n        Does not need to be provided if not used by\n        optimise(), such as for purely unconstrained\n        optimisation.\n    objective: OptimisationObjective (default: None)\n        OptimisationObjective storing objective information to\n        provide to the Optimiser.\n    constraints: List[OptimisationConstraint] (default: None)\n        Optional list of OptimisationConstraint objects storing\n        information about constraints that must be satisfied\n        during the coilset optimisation, to be provided to the\n        Optimiser.\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        optimiser: Optimiser = None,\n        objective: OptimisationObjective = None,\n        constraints: List[OptimisationConstraint] = None,\n    ):\n        super().__init__(coilset, optimiser, objective, constraints)\n        self.scale = 1e6  # current_scale\n        self.initial_state, self.substates = self.read_coilset_state(\n            self.coilset, self.scale\n        )\n        self.x0, self.z0, self.I0 = np.array_split(self.initial_state, self.substates)\n\n    @property\n    def coilset(self):\n        return self._parameterisation\n\n    @coilset.setter\n    def coilset(self, value: CoilSet):\n        self._parameterisation = value\n\n    @staticmethod\n    def read_coilset_state(coilset, current_scale):\n        \"\"\"\n        Reads the input coilset and generates the state vector as an array to represent\n        it.\n\n        Parameters\n        ----------\n        coilset: Coilset\n            Coilset to be read into the state vector.\n        current_scale: float\n            Factor to scale coilset currents down by for population of coilset_state.\n            Used to minimise round-off errors in optimisation.\n\n        Returns\n        -------\n        coilset_state: np.array\n            State vector containing substate (position and current)\n            information for each coil.\n        substates: int\n            Number of substates (blocks) in the state vector.\n        \"\"\"\n        substates = 3\n        x, z = coilset.position\n        currents = coilset.current / current_scale\n\n        coilset_state = np.concatenate((x, z, currents))\n        return coilset_state, substates\n\n    @staticmethod\n    def set_coilset_state(coilset, coilset_state, current_scale):\n        \"\"\"\n        Set the optimiser coilset from a provided state vector.\n\n        Parameters\n        ----------\n        coilset: Coilset\n            Coilset to set from state vector.\n        coilset_state: np.array\n            State vector representing degrees of freedom of the coilset,\n            to be used to update the coilset.\n        current_scale: float\n            Factor to scale state vector currents up by when setting\n            coilset currents.\n            Used to minimise round-off errors in optimisation.\n        \"\"\"\n        x, z, currents = np.array_split(coilset_state, 3)\n\n        coilset.x = x\n        coilset.z = z\n        coilset.current = currents * current_scale\n\n    @staticmethod\n    def get_state_bounds(x_bounds, z_bounds, current_bounds):\n        \"\"\"\n        Get bounds on the state vector from provided bounds on the substates.\n\n        Parameters\n        ----------\n        x_bounds: tuple\n            Tuple containing lower and upper bounds on the radial coil positions.\n        z_bounds: tuple\n            Tuple containing lower and upper bounds on the vertical coil positions.\n        current_bounds: tuple\n            Tuple containing bounds on the coil currents.\n\n        Returns\n        -------\n        bounds: np.array\n            Array containing state vectors representing lower and upper bounds\n            for coilset state degrees of freedom.\n        \"\"\"\n        lower_bounds = np.concatenate((x_bounds[0], z_bounds[0], current_bounds[0]))\n        upper_bounds = np.concatenate((x_bounds[1], z_bounds[1], current_bounds[1]))\n        bounds = np.array([lower_bounds, upper_bounds])\n        return bounds\n\n    @staticmethod\n    def get_current_bounds(coilset, max_currents, current_scale):\n        \"\"\"\n        Gets the scaled current vector bounds. Must be called prior to optimise.\n\n        Parameters\n        ----------\n        coilset: Coilset\n            Coilset to fetch current bounds for.\n        max_currents: float or np.ndarray\n            Maximum magnitude of currents in each coil [A] permitted during optimisation.\n            If max_current is supplied as a float, the float will be set as the\n            maximum allowed current magnitude for all coils.\n            If the coils have current density limits that are more restrictive than these\n            coil currents, the smaller current limit of the two will be used for each\n            coil.\n        current_scale: float\n            Factor to scale coilset currents down when returning scaled current limits.\n\n        Returns\n        -------\n        current_bounds: (np.narray, np.narray)\n            Tuple of arrays containing lower and upper bounds for currents\n            permitted in each control coil.\n        \"\"\"\n        n_control_currents = len(coilset.current[coilset._control_ind])\n        scaled_input_current_limits = np.inf * np.ones(n_control_currents)\n\n        if max_currents is not None:\n            input_current_limits = np.asarray(max_currents)\n            input_size = np.size(np.asarray(input_current_limits))\n            if input_size == 1 or input_size == n_control_currents:\n                scaled_input_current_limits = input_current_limits / current_scale\n            else:\n                raise EquilibriaError(\n                    \"Length of max_currents array provided to optimiser is not\"\n                    \"equal to the number of control currents present.\"\n                )\n\n        # Get the current limits from coil current densities\n        coilset_current_limits = np.infty * np.ones(n_control_currents)\n        coilset_current_limits[coilset._flag_sizefix] = coilset.get_max_current()[\n            coilset._flag_sizefix\n        ]\n\n        # Limit the control current magnitude by the smaller of the two limits\n        control_current_limits = np.minimum(\n            scaled_input_current_limits, coilset_current_limits\n        )\n        current_bounds = (-control_current_limits, control_current_limits)\n\n        return current_bounds\n\n    def set_current_bounds(self, max_currents: np.ndarray):\n        \"\"\"\n        Set the current bounds on a CoilsetOptimisationProblem\n\n        Parameters\n        ----------\n        max_currents:\n            Vector of maximum currents [A]\n        \"\"\"\n        n_control_currents = len(self.coilset.current[self.coilset._control_ind])\n        if len(max_currents) != n_control_currents:\n            raise ValueError(\n                \"Length of maximum current vector must be equal to the number of controls.\"\n            )\n\n        upper_bounds = np.abs(max_currents) / self.scale\n        lower_bounds = -upper_bounds\n        self.opt.set_lower_bounds(lower_bounds)\n        self.opt.set_upper_bounds(upper_bounds)\n\n    def update_magnetic_constraints(\n        self, I_not_dI: bool = True, fixed_coils: bool = True\n    ):\n        \"\"\"\n        Update the magnetic optimisation constraints with the state of the Equilibrium\n        \"\"\"\n        if self._constraints is not None:\n            for constraint in self._constraints:\n                if isinstance(constraint, UpdateableConstraint):\n                    constraint.prepare(\n                        self.eq, I_not_dI=I_not_dI, fixed_coils=fixed_coils\n                    )\n                if \"scale\" in constraint._args:\n                    constraint._args[\"scale\"] = self.scale",
  "class CoilsetPositionCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Coilset OptimisationProblem for coil currents and positions\n    subject to maximum current bounds and positions bounded within\n    a provided region.\n\n    Coil currents and positions are optimised simultaneously.\n\n    Parameters\n    ----------\n    coilset:\n        Coilset to optimise.\n    eq: Equilibrium\n        Equilibrium object used to update magnetic field targets.\n    targets:\n        Set of magnetic field targets to use in objective function.\n    pfregions:\n        Dictionary of Coordinates that specify convex hull regions inside which\n        each PF control coil position is to be optimised.\n        The Coordinates must be 2d in x,z in units of [m].\n    max_currents:\n        Maximum allowed current for each independent coil current in coilset [A].\n        If specified as a float, the float will set the maximum allowed current\n        for all coils.\n    gamma:\n        Tikhonov regularisation parameter in units of [A\u207b\u00b9].\n    optimiser:\n        Optimiser object to use for constrained optimisation.\n    constraints:\n        Optional list of OptimisationConstraint objects storing\n        information about constraints that must be satisfied\n        during the coilset optimisation, to be provided to the\n        optimiser.\n\n    Notes\n    -----\n    Setting stopval and maxeval is the most reliable way to stop optimisation\n    at the desired figure of merit and number of iterations respectively.\n    Some NLOpt optimisers display unexpected behaviour when setting xtol and\n    ftol, and may not terminate as expected when those criteria are reached.\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        pfregions: dict,\n        max_currents=None,\n        gamma=1e-8,\n        optimiser=Optimiser(\n            algorithm_name=\"SBPLX\",\n            opt_conditions={\n                \"stop_val\": 1.0,\n                \"max_eval\": 100,\n            },\n        ),\n        constraints=None,\n    ):\n        # noqa :N803\n\n        # Create region map\n        self.region_mapper = RegionMapper(pfregions)\n\n        # Store inputs (optional, but useful for constraints)\n        self.eq = eq\n        self.targets = targets\n\n        # Set objective function for this OptimisationProblem,\n        # and initialise\n        objective = OptimisationObjective(\n            objectives.ad_objective,\n            {\"objective\": self.get_state_figure_of_merit, \"objective_args\": {}},\n        )\n        super().__init__(coilset, optimiser, objective, constraints)\n\n        # Set up bounds\n        bounds = self.get_mapped_state_bounds(self.region_mapper, max_currents)\n        # Add bounds information to help automatic differentiation of objective\n        self._objective._args[\"ad_args\"] = {\"bounds\": bounds}\n        self._objective._args[\"objective_args\"] = {\n            \"coilset\": coilset,\n            \"eq\": eq,\n            \"targets\": targets,\n            \"region_mapper\": self.region_mapper,\n            \"current_scale\": self.scale,\n            \"gamma\": gamma,\n        }\n\n        # Set up optimiser\n        dimension = len(bounds[0])\n        self.set_up_optimiser(dimension, bounds)\n\n    def get_mapped_state_bounds(self, region_mapper: RegionMapper, max_currents):\n        \"\"\"\n        Get mapped bounds on the coilset state vector from the coil regions and\n        maximum coil currents.\n\n        Parameters\n        ----------\n        region_mapper: RegionMapper\n            RegionMapper mapping coil positions within the allowed optimisation\n            regions.\n        max_currents Union[float, np.ndarray] (default = None)\n            Maximum allowed current for each independent coil current in coilset [A].\n            If specified as a float, the float will set the maximum allowed current\n            for all coils.\n\n        Returns\n        -------\n        bounds: np.array\n            Array containing state vectors representing lower and upper bounds\n            for coilset state degrees of freedom.\n        \"\"\"\n        # Get mapped position bounds from RegionMapper\n        _, lower_lmap_bounds, upper_lmap_bounds = region_mapper.get_Lmap(self.coilset)\n        current_bounds = self.get_current_bounds(self.coilset, max_currents, self.scale)\n\n        lower_bounds = np.concatenate((lower_lmap_bounds, current_bounds[0]))\n        upper_bounds = np.concatenate((upper_lmap_bounds, current_bounds[1]))\n        bounds = (lower_bounds, upper_bounds)\n        return bounds\n\n    def optimise(self):\n        \"\"\"\n        Optimiser handle. Used in __call__\n\n        Returns\n        -------\n        self.coilset: CoilSet\n            Optimised CoilSet object.\n        \"\"\"\n        # Get initial state and apply region mapping to coil positions.\n        initial_state, _ = self.read_coilset_state(self.coilset, self.scale)\n        _, _, initial_currents = np.array_split(initial_state, self.substates)\n        initial_mapped_positions, _, _ = self.region_mapper.get_Lmap(self.coilset)\n        initial_mapped_state = np.concatenate(\n            (initial_mapped_positions, initial_currents)\n        )\n\n        # Optimise\n        state = self.opt.optimise(initial_mapped_state)\n\n        # Call objective function final time on optimised state\n        # to set coilset.\n        # Necessary as optimised state may not always be the final\n        # one evaluated by optimiser.\n        self._objective(state, np.empty(shape=(0, 0)))\n        return self.coilset\n\n    @staticmethod\n    def get_state_figure_of_merit(\n        vector,\n        grad,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        region_mapper: RegionMapper,\n        current_scale: float,\n        gamma: float,\n    ):\n        \"\"\"\n        Calculates figure of merit from objective function,\n        consisting of a least-squares objective with Tikhonov\n        regularisation term, which updates the gradient in-place.\n\n        Parameters\n        ----------\n        vector:\n            State vector. Numpy array formed by concatenation of coil radial\n            coordinates, coil vertical coordinates, and (scaled) coil currents.\n        grad:\n            Dummy variable for NLOpt calls. Not updated.\n        coilset:\n            CoilSet to update using state vector.\n        eq:\n            Equilibrium object used to update magnetic field targets.\n        targets:\n            Set of magnetic field targets to optimise Equilibrium towards,\n            using least-squares objective with Tikhonov regularisation.\n        region_mapper\n            RegionMapper mapping coil positions within the allowed optimisation\n            regions.\n        current_scale:\n            Scale factor to scale currents in state vector up by to\n            give currents in [A].\n        gamma:\n            Tikhonov regularisation parameter in units of [A\u207b\u00b9].\n\n        Returns\n        -------\n        fom: float\n            Value of objective function (figure of merit).\n        \"\"\"\n        mapped_x, mapped_z, currents = np.array_split(vector, 3)\n        mapped_positions = np.concatenate((mapped_x, mapped_z))\n        region_mapper.set_Lmap(mapped_positions)\n        x_vals, z_vals = region_mapper.get_xz_arrays()\n        coilset_state = np.concatenate((x_vals, z_vals, currents))\n\n        CoilsetOptimisationProblem.set_coilset_state(\n            coilset, coilset_state, current_scale\n        )\n\n        # Update target\n        eq._remap_greens()\n\n        # Set up data needed in FoM evaluation.\n        # Scale the control matrix and constraint vector by weights.\n        targets(eq, I_not_dI=True, fixed_coils=False)\n        _, a_mat, b_vec = targets.get_weighted_arrays()\n\n        # Calculate objective function\n        fom, err = regularised_lsq_fom(currents * current_scale, a_mat, b_vec, gamma)\n        return fom",
  "class NestedCoilsetPositionCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Coilset OptimisationProblem for coil currents and positions\n    subject to maximum current bounds and positions bounded within\n    a provided region. Performs a nested optimisation for coil\n    currents within each position optimisation function call.\n\n    Parameters\n    ----------\n    sub_opt:\n        Coilset OptimisationProblem to use for the optimisation of\n        coil currents at each trial set of coil positions.\n        sub_opt.coilset must exist, and will be modified\n        during the optimisation.\n    eq:\n        Equilibrium object used to update magnetic field targets.\n    targets:\n        Set of magnetic field targets to use in objective function.\n    pfregions:\n        Dictionary of Coordinates that specify convex hull regions inside which\n        each PF control coil position is to be optimised.\n        The Coordinates must be 2d in x,z in units of [m].\n    optimiser:\n        Optimiser object to use for constrained optimisation.\n    constraints:\n        Optional list of OptimisationConstraint objects storing\n        information about constraints that must be satisfied\n        during the coilset optimisation, to be provided to the\n        optimiser.\n\n    Notes\n    -----\n    Setting stopval and maxeval is the most reliable way to stop optimisation\n    at the desired figure of merit and number of iterations respectively.\n    Some NLOpt optimisers display unexpected behaviour when setting xtol and\n    ftol, and may not terminate as expected when those criteria are reached.\n    \"\"\"\n\n    def __init__(\n        self,\n        sub_opt: CoilsetOptimisationProblem,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        pfregions: dict,\n        optimiser=Optimiser(\n            algorithm_name=\"SBPLX\",\n            opt_conditions={\n                \"stop_val\": 1.0,\n                \"max_eval\": 100,\n            },\n        ),\n        constraints: List[OptimisationConstraint] = None,\n    ):\n        # noqa :N803\n\n        # Create region map\n        self.region_mapper = RegionMapper(pfregions)\n\n        # Store inputs (optional, but useful for constraints)\n        self.eq = eq\n        self.targets = targets\n\n        # Set objective function for this OptimisationProblem,\n        # and initialise\n        objective = OptimisationObjective(\n            objectives.ad_objective,\n            {\"objective\": self.get_state_figure_of_merit, \"objective_args\": {}},\n        )\n        super().__init__(sub_opt.coilset, optimiser, objective, constraints)\n\n        # Set up bounds\n        _, lower_bounds, upper_bounds = self.region_mapper.get_Lmap(self.coilset)\n        bounds = (lower_bounds, upper_bounds)\n        # Add bounds information to help automatic differentiation of objective\n        self._objective._args[\"ad_args\"] = {\"bounds\": bounds}\n        self._objective._args[\"objective_args\"] = {\n            \"coilset\": self.coilset,\n            \"eq\": eq,\n            \"targets\": targets,\n            \"region_mapper\": self.region_mapper,\n            \"current_scale\": self.scale,\n            \"initial_currents\": self.I0,\n            \"sub_opt\": sub_opt,\n        }\n        # Set up optimiser\n        dimension = len(bounds[0])\n        self.set_up_optimiser(dimension, bounds)\n\n    def optimise(self):\n        \"\"\"\n        Optimiser handle. Used in __call__\n\n        Returns\n        -------\n        self.coilset: CoilSet\n            Optimised CoilSet object.\n        \"\"\"\n        # Get initial currents, and trim to within current bounds.\n        initial_state, substates = self.read_coilset_state(self.coilset, self.scale)\n        _, _, initial_currents = np.array_split(initial_state, substates)\n        intial_mapped_positions, _, _ = self.region_mapper.get_Lmap(self.coilset)\n\n        # Optimise\n        self._objective._args[\"objective_args\"][\"initial_currents\"] = initial_currents\n        positions = self.opt.optimise(intial_mapped_positions)\n\n        # Call objective function final time on optimised state\n        # to set coilset.\n        # Necessary as optimised state may not always be the final\n        # one evaluated by optimiser.\n        self._objective(positions, np.empty(shape=(0, 0)))\n        return self.coilset\n\n    @staticmethod\n    def get_state_figure_of_merit(\n        vector,\n        grad,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        region_mapper: RegionMapper,\n        current_scale: float,\n        initial_currents,\n        sub_opt: CoilsetOptimisationProblem,\n    ):\n        \"\"\"\n        Calculates figure of merit, returned from the current\n        optimiser at each trial coil position.\n\n        Parameters\n        ----------\n        vector:\n            State vector of the array of coil positions.\n        grad:\n            Dummy variable for NLOpt calls. Not updated.\n        coilset: CoilSet\n            CoilSet to update using state vector.\n        eq:\n            Equilibrium object used to update magnetic field targets.\n        targets:\n            Set of magnetic field targets to update for use in sub_opt.\n        region_mapper:\n            RegionMapper mapping coil positions within the allowed optimisation\n            regions.\n        current_scale:\n            Scale factor to scale currents in state vector up by to\n            give currents in [A].\n        initial_currents:\n            Array containing initial (scaled) coil currents prior to passing\n            to sub_opt\n        sub_opt:\n            Coilset OptimisationProblem used to optimise the array of coil\n            currents at each trial position.\n\n        Returns\n        -------\n        fom:\n            Value of objective function (figure of merit).\n        \"\"\"\n        region_mapper.set_Lmap(vector)\n        x_vals, z_vals = region_mapper.get_xz_arrays()\n        positions = np.concatenate((x_vals, z_vals))\n        coilset_state = np.concatenate((positions, initial_currents))\n        CoilsetOptimisationProblem.set_coilset_state(\n            coilset, coilset_state, current_scale\n        )\n\n        # Update targets\n        eq._remap_greens()\n        targets(eq, I_not_dI=True, fixed_coils=False)\n\n        # Calculate objective function\n        sub_opt()\n        fom = sub_opt.opt.optimum_value\n        return fom",
  "class UnconstrainedTikhonovCurrentGradientCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Unbounded, unconstrained, analytically optimised current gradient vector for minimal\n    error to the L2-norm of a set of magnetic constraints (used here as targets).\n\n    This is useful for getting a preliminary Equilibrium\n\n    Parameters\n    ----------\n    coilset:\n        CoilSet object to optimise with\n    eq:\n        Equilibrium object to optimise for\n    targets:\n        Set of magnetic constraints to minimise the error for\n    gamma:\n        Tikhonov regularisation parameter [1/A]\n    \"\"\"\n\n    def __init__(self, coilset, eq, targets, gamma):\n        self.eq = eq\n        self.targets = targets\n        self.gamma = gamma\n\n        super().__init__(coilset)\n\n    def optimise(self, *args, **kwargs):\n        \"\"\"\n        Optimise the prescribed problem.\n\n        Notes\n        -----\n        The weight vector is used to scale the response matrix and\n        constraint vector. The weights are assumed to be uncorrelated, such that the\n        weight matrix W_ij used to define (for example) the least-squares objective\n        function (Ax - b)\u1d40 W (Ax - b), is diagonal, such that\n        weights[i] = w[i] = sqrt(W[i,i]).\n        \"\"\"\n        # Scale the control matrix and magnetic field targets vector by weights.\n        self.targets(self.eq, I_not_dI=False)\n        _, a_mat, b_vec = self.targets.get_weighted_arrays()\n\n        # Optimise currents using analytic expression for optimum.\n        current_adjustment = tikhonov(a_mat, b_vec, self.gamma)\n\n        # Update parameterisation (coilset).\n        self.coilset.current = self.coilset.current + current_adjustment\n        return self.coilset",
  "class TikhonovCurrentCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Coilset OptimisationProblem for coil currents subject to maximum current bounds.\n\n    Coilset currents optimised using objectives.regularised_lsq_objective as\n    objective function.\n\n    Parameters\n    ----------\n    coilset:\n        Coilset to optimise.\n    eq: Equilibrium\n        Equilibrium object used to update magnetic field targets.\n    targets:\n        Set of magnetic field targets to use in objective function.\n    gamma:\n        Tikhonov regularisation parameter in units of [A\u207b\u00b9].\n    max_currents Union[float, np.ndarray] (default = None)\n        Maximum allowed current for each independent coil current in coilset [A].\n        If specified as a float, the float will set the maximum allowed current\n        for all coils.\n    optimiser:\n        Optimiser object to use for constrained optimisation.\n    constraints:\n        Optional list of OptimisationConstraint objects storing\n        information about constraints that must be satisfied\n        during the coilset optimisation, to be provided to the\n        optimiser.\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset,\n        eq,\n        targets,\n        gamma,\n        optimiser: Optimiser = Optimiser(\n            algorithm_name=\"SLSQP\",\n            opt_conditions={\n                \"xtol_rel\": 1e-4,\n                \"xtol_abs\": 1e-4,\n                \"ftol_rel\": 1e-4,\n                \"ftol_abs\": 1e-4,\n                \"max_eval\": 100,\n            },\n            opt_parameters={\"initial_step\": 0.03},\n        ),\n        max_currents=None,\n        constraints=None,\n    ):\n        self.eq = eq\n        self.targets = targets\n        objective = OptimisationObjective(\n            objectives.regularised_lsq_objective, f_objective_args={\"gamma\": gamma}\n        )\n\n        super().__init__(coilset, optimiser, objective, constraints=constraints)\n\n        bounds = self.get_current_bounds(self.coilset, max_currents, self.scale)\n        dimension = len(bounds[0])\n        self.set_up_optimiser(dimension, bounds)\n\n    def optimise(self, x0=None, fixed_coils=True):\n        \"\"\"\n        Solve the optimisation problem\n\n        Parameters\n        ----------\n        fixed_coils: True\n            Whether or not to update to coilset response matrices\n\n        Returns\n        -------\n        coilset: CoilSet\n            Optimised CoilSet\n        \"\"\"\n        # Scale the control matrix and magnetic field targets vector by weights.\n        self.targets(self.eq, I_not_dI=True, fixed_coils=fixed_coils)\n        _, a_mat, b_vec = self.targets.get_weighted_arrays()\n\n        self._objective._args[\"scale\"] = self.scale\n        self._objective._args[\"a_mat\"] = a_mat\n        self._objective._args[\"b_vec\"] = b_vec\n        self._objective.apply_objective(self)\n\n        self.update_magnetic_constraints(I_not_dI=True, fixed_coils=fixed_coils)\n\n        if x0 is None:\n            initial_state, n_states = self.read_coilset_state(self.coilset, self.scale)\n            _, _, initial_currents = np.array_split(initial_state, n_states)\n\n            x0 = np.clip(initial_currents, self.opt.lower_bounds, self.opt.upper_bounds)\n        currents = self.opt.optimise(x0=x0)\n        self.coilset.get_control_coils().current = currents * self.scale\n        return self.coilset",
  "class MinimalCurrentCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Bounded, constrained, minimal current optimisation problem.\n\n    Parameters\n    ----------\n    eq: Equilibrium\n        Equilibrium object to optimise the currents for\n    optimiser: bluemira.utilities.optimiser.Optimiser\n        Optimiser object to use\n    max_currents: np.ndarray\n        Current bounds vector [A]\n    constraints: Optional[List[OptimisationConstraint]]\n        List of optimisation constraints to apply to the optimisation problem\n    \"\"\"\n\n    def __init__(self, coilset, eq, optimiser, max_currents=None, constraints=None):\n        self.eq = eq\n        objective = OptimisationObjective(\n            objectives.minimise_coil_currents, f_objective_args={}\n        )\n        super().__init__(coilset, optimiser, objective, constraints)\n\n        bounds = self.get_current_bounds(self.coilset, max_currents, self.scale)\n        dimension = len(bounds[0])\n        self.set_up_optimiser(dimension, bounds)\n\n    def optimise(self, x0=None, fixed_coils=True):\n        \"\"\"\n        Solve the optimisation problem\n\n        Parameters\n        ----------\n        fixed_coils: True\n            Whether or not to update to coilset response matrices\n\n        Returns\n        -------\n        coilset: CoilSet\n            Optimised CoilSet\n        \"\"\"\n        self.update_magnetic_constraints(I_not_dI=True, fixed_coils=fixed_coils)\n\n        if x0 is None:\n            initial_state, n_states = self.read_coilset_state(\n                self.eq.coilset, self.scale\n            )\n            _, _, initial_currents = np.array_split(initial_state, n_states)\n\n            x0 = np.clip(initial_currents, self.opt.lower_bounds, self.opt.upper_bounds)\n\n        currents = self.opt.optimise(x0=x0)\n        self.coilset.get_control_coils().current = currents * self.scale\n        return self.coilset",
  "class PulsedNestedPositionCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Coilset position optimisation problem for multiple sub-optimisation problems.\n\n    Parameters\n    ----------\n    coilset: Coilset\n        Coilset for which to optimise positions\n    position_mapper: PositionMapper\n        Position mapper tool to parameterise coil positions\n    sub_opt_problems: List[CoilsetOptimisationProblem]\n        The list of sub-optimisation problems to solve\n    optimiser: bluemira.utilities.optimiser.Optimiser\n        Optimiser object to use\n    constraints: Optional[List[OptimisationConstraint]]\n        Constraints to use. Note these should be applicable to the parametric position\n        vector\n    initial_currents: Optional[np.ndarray]\n        Initial currents to use when solving the current sub-optimisation problems\n    debug: bool\n        Whether or not to run in debug mode (will affect run-time noticeably)\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        position_mapper: PositionMapper,\n        sub_opt_problems: List[CoilsetOptimisationProblem],\n        optimiser: Optimiser = Optimiser(\n            \"COBYLA\", opt_conditions={\"max_eval\": 100, \"ftol_rel\": 1e-6}\n        ),\n        constraints=None,\n        initial_currents=None,\n        debug=False,\n    ):\n        self.position_mapper = position_mapper\n        self.sub_opt_probs = sub_opt_problems\n\n        if initial_currents:\n            self._initial_currents = initial_currents / self.sub_opt_probs[0].scale\n        else:\n            self._initial_currents = np.zeros(coilset.get_control_coils().n_coils())\n        self._debug = {0: debug}\n        self._iter = {0: 0.0}\n\n        objective = OptimisationObjective(\n            f_objective=self.get_state_fom,\n            f_objective_args={\n                \"coilset\": coilset,\n                \"sub_opt_problems\": sub_opt_problems,\n                \"position_mapper\": position_mapper,\n                \"initial_currents\": self._initial_currents,\n                \"itern\": self._iter,\n                \"debug\": self._debug,\n                \"verbose\": False,\n            },\n        )\n        super().__init__(coilset, optimiser, objective, constraints)\n\n        dimension = self.position_mapper.dimension\n        bounds = (np.zeros(dimension), np.ones(dimension))\n        self.set_up_optimiser(dimension, bounds)\n\n    @staticmethod\n    def _run_reporting(itern, max_fom, verbose):\n        \"\"\"\n        Keep track of objective function value over iterations.\n        \"\"\"\n        i = max(list(itern.keys())) + 1\n        itern[i] = max_fom\n\n        if verbose:\n            bluemira_print_flush(f\"Coil position iteration {i} FOM value: {max_fom:.6e}\")\n\n    @staticmethod\n    def _run_diagnostics(debug, sub_opt_prob):\n        \"\"\"\n        In debug mode, store the LCFS at each iteration for each of the sub-optimisation\n        problems.\n\n        Notes\n        -----\n        This can significantly impact run-time.\n        \"\"\"\n        if debug[0]:\n            entry = max(list(debug.keys()))\n            value = sub_opt_prob.opt.optimum_value\n            sub_opt_prob.eq._remap_greens()\n            sub_opt_prob.eq._clear_OX_points()\n            lcfs = sub_opt_prob.eq.get_LCFS()\n            debug[entry].append([lcfs, value])\n\n    @staticmethod\n    def get_sub_opt_foms(\n        vector,\n        coilset,\n        position_mapper,\n        sub_opt_problems,\n        initial_currents,\n        itern,\n        verbose,\n        debug,\n    ):\n        \"\"\"\n        Run the sub-optimisation problems for a given position vector and return the\n        objective function values\n        \"\"\"\n        positions = position_mapper.to_xz_dict(vector)\n\n        if debug[0]:\n            # Increment debug dictionary\n            i = max(list(debug.keys())) + 1\n            debug[i] = []\n\n        fom_values = []\n        for sub_opt_prob in sub_opt_problems:\n            for coil, position in positions.items():\n                sub_opt_prob.coilset[coil].position = position\n            sub_opt_prob.optimise(x0=initial_currents, fixed_coils=False)\n            PulsedNestedPositionCOP._run_diagnostics(debug, sub_opt_prob)\n            fom_values.append(sub_opt_prob.opt.optimum_value)\n        max_fom = max(fom_values)\n\n        PulsedNestedPositionCOP._run_reporting(itern, max_fom, verbose)\n\n        return max_fom\n\n    @staticmethod\n    def get_state_fom(\n        vector,\n        grad,\n        coilset,\n        sub_opt_problems,\n        position_mapper,\n        initial_currents,\n        itern,\n        verbose,\n        debug,\n    ):\n        \"\"\"\n        Get the figure of merit for a single sub-optimisation problem.\n        \"\"\"\n        fom_value = PulsedNestedPositionCOP.get_sub_opt_foms(\n            vector,\n            coilset,\n            position_mapper,\n            sub_opt_problems,\n            initial_currents,\n            itern,\n            verbose,\n            debug,\n        )\n\n        if grad.size > 0:\n            grad[:] = approx_derivative(\n                PulsedNestedPositionCOP.get_sub_opt_foms,\n                vector,\n                f0=fom_value,\n            )\n\n        return fom_value\n\n    def _get_initial_vector(self):\n        \"\"\"\n        Get a vector representation of the initial coilset state from the PositionMapper.\n        \"\"\"\n        x, z = [], []\n        for name in self.position_mapper.interpolators:\n            x.append(self.coilset[name].x)\n            z.append(self.coilset[name].z)\n        return self.position_mapper.to_L(x, z)\n\n    def optimise(self, x0=None, verbose=False):\n        \"\"\"\n        Run the PulsedNestedPositionCOP\n\n        Parameters\n        ----------\n        x0: Optional[np.ndarray]\n            Initial solution vector (parameterised positions)\n        verbose: bool\n            Whether or not to print progress information\n\n        Returns\n        -------\n        coilset: CoilSet\n            Optimised CoilSet\n        \"\"\"\n        self._objective._args[\"verbose\"] = verbose\n\n        if x0 is None:\n            x0 = self._get_initial_vector()\n        optimal_positions = self.opt.optimise(x0=x0)\n        # Call the objective one last time\n        self.get_sub_opt_foms(\n            optimal_positions,\n            self.coilset,\n            self.position_mapper,\n            self.sub_opt_probs,\n            self._initial_currents,\n            itern=self._iter,\n            verbose=verbose,\n            debug=self._debug,\n        )\n\n        # Clean up state of Equilibrium objects\n        for sub_opt in self.sub_opt_probs:\n            sub_opt.eq._remap_greens()\n            sub_opt.eq._clear_OX_points()\n        return self.coilset",
  "class BreakdownZoneStrategy(abc.ABC):\n    \"\"\"\n    Abstract base class for the definition of a breakdown zone strategy.\n\n    Parameters\n    ----------\n    R_0: float\n        Major radius of the reference plasma\n    A: float\n        Aspect ratio of the reference plasma\n    tk_sol: float\n        Thickness of the scrape-off layer\n    \"\"\"\n\n    def __init__(self, R_0, A, tk_sol, **kwargs):\n        self.R_0 = R_0\n        self.A = A\n        self.tk_sol = tk_sol\n\n    @abc.abstractproperty\n    def breakdown_point(self) -> Tuple[float]:\n        \"\"\"\n        The location of the breakdown point.\n\n        Returns\n        -------\n        x_c: float\n            Radial coordinate of the breakdown point\n        z_c: float\n            Vertical coordinate of the breakdown point\n        \"\"\"\n        pass\n\n    @abc.abstractproperty\n    def breakdown_radius(self) -> float:\n        \"\"\"\n        The radius of the breakdown zone.\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def calculate_zone_points(self, n_points: int) -> Tuple[np.ndarray]:\n        \"\"\"\n        Calculate the discretised set of points representing the breakdown zone.\n        \"\"\"\n        pass",
  "class CircularZoneStrategy(BreakdownZoneStrategy):\n    \"\"\"\n    Circular breakdown zone strategy.\n    \"\"\"\n\n    def calculate_zone_points(self, n_points: int) -> Tuple[np.ndarray]:\n        \"\"\"\n        Calculate the discretised set of points representing the breakdown zone.\n        \"\"\"\n        x_c, z_c = self.breakdown_point\n        r_c = self.breakdown_radius\n        theta = np.linspace(0, 2 * np.pi, n_points - 1, endpoint=False)\n        x = x_c + r_c * np.cos(theta)\n        z = z_c + r_c * np.sin(theta)\n        x = np.append(x, x_c)\n        z = np.append(z, z_c)\n        return x, z",
  "class InboardBreakdownZoneStrategy(CircularZoneStrategy):\n    \"\"\"\n    Inboard breakdown zone strategy.\n    \"\"\"\n\n    @property\n    def breakdown_point(self) -> Tuple[float]:\n        r_c = self.breakdown_radius\n        x_c = self.R_0 - self.R_0 / self.A - self.tk_sol + r_c\n        z_c = 0.0\n        return x_c, z_c\n\n    @property\n    def breakdown_radius(self) -> float:\n        return 0.5 * self.R_0 / self.A",
  "class OutboardBreakdownZoneStrategy(CircularZoneStrategy):\n    \"\"\"\n    Outboard breakdown zone strategy.\n    \"\"\"\n\n    @property\n    def breakdown_point(self) -> Tuple[float]:\n        r_c = self.breakdown_radius\n        x_c = self.R_0 + self.R_0 / self.A + self.tk_sol - r_c\n        z_c = 0.0\n        return x_c, z_c\n\n    @property\n    def breakdown_radius(self) -> float:\n        return 0.7 * self.R_0 / self.A",
  "class InputBreakdownZoneStrategy(CircularZoneStrategy):\n    \"\"\"\n    User input breakdown zone strategy.\n    \"\"\"\n\n    def __call__(self, *args, **kwargs):\n        return self\n\n    def __init__(self, x_c, z_c, r_c):\n        self.x_c = x_c\n        self.z_c = z_c\n        self.r_c = r_c\n\n    @property\n    def breakdown_point(self) -> Tuple[float]:\n        return self.x_c, self.z_c\n\n    @property\n    def breakdown_radius(self) -> float:\n        return self.r_c",
  "class BreakdownCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Coilset optimisation problem for the pre-magnetisation / breakdown phase.\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        breakdown: Breakdown,\n        breakdown_strategy: BreakdownZoneStrategy,\n        B_stray_max,\n        B_stray_con_tol,\n        n_B_stray_points,\n        optimiser: Optimiser = None,\n        max_currents=None,\n        constraints: List[OptimisationConstraint] = None,\n    ):\n        self.eq = breakdown\n        self.scale = 1e6  # current_scale\n\n        objective = OptimisationObjective(\n            objectives.maximise_flux,\n            f_objective_args={\n                \"c_psi_mat\": np.array(\n                    coilset.psi_response(*breakdown_strategy.breakdown_point)\n                ),\n                \"scale\": self.scale,\n            },\n        )\n\n        x_zone, z_zone = breakdown_strategy.calculate_zone_points(n_B_stray_points)\n\n        stray_field_cons = FieldConstraints(\n            x_zone, z_zone, B_max=B_stray_max, tolerance=B_stray_con_tol\n        )\n\n        if constraints:\n            constraints.append(stray_field_cons)\n        else:\n            constraints = [stray_field_cons]\n\n        super().__init__(coilset, optimiser, objective, constraints)\n\n        # Set up optimiser\n        bounds = (-max_currents / self.scale, max_currents / self.scale)\n        dimension = len(bounds[0])\n        self.set_up_optimiser(dimension, bounds)\n\n    def optimise(self, x0=None, fixed_coils=True):\n        \"\"\"\n        Solve the optimisation problem.\n        \"\"\"\n        self.update_magnetic_constraints(I_not_dI=True, fixed_coils=fixed_coils)\n\n        initial_state, n_states = self.read_coilset_state(self.coilset, self.scale)\n        _, _, initial_currents = np.array_split(initial_state, n_states)\n\n        initial_currents = np.clip(\n            initial_currents, self.opt.lower_bounds, self.opt.upper_bounds\n        )\n        currents = self.opt.optimise(x0=initial_currents)\n        self.coilset.get_control_coils().current = currents * self.scale\n        return self.coilset",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        optimiser: Optimiser = None,\n        objective: OptimisationObjective = None,\n        constraints: List[OptimisationConstraint] = None,\n    ):\n        super().__init__(coilset, optimiser, objective, constraints)\n        self.scale = 1e6  # current_scale\n        self.initial_state, self.substates = self.read_coilset_state(\n            self.coilset, self.scale\n        )\n        self.x0, self.z0, self.I0 = np.array_split(self.initial_state, self.substates)",
  "def coilset(self):\n        return self._parameterisation",
  "def coilset(self, value: CoilSet):\n        self._parameterisation = value",
  "def read_coilset_state(coilset, current_scale):\n        \"\"\"\n        Reads the input coilset and generates the state vector as an array to represent\n        it.\n\n        Parameters\n        ----------\n        coilset: Coilset\n            Coilset to be read into the state vector.\n        current_scale: float\n            Factor to scale coilset currents down by for population of coilset_state.\n            Used to minimise round-off errors in optimisation.\n\n        Returns\n        -------\n        coilset_state: np.array\n            State vector containing substate (position and current)\n            information for each coil.\n        substates: int\n            Number of substates (blocks) in the state vector.\n        \"\"\"\n        substates = 3\n        x, z = coilset.position\n        currents = coilset.current / current_scale\n\n        coilset_state = np.concatenate((x, z, currents))\n        return coilset_state, substates",
  "def set_coilset_state(coilset, coilset_state, current_scale):\n        \"\"\"\n        Set the optimiser coilset from a provided state vector.\n\n        Parameters\n        ----------\n        coilset: Coilset\n            Coilset to set from state vector.\n        coilset_state: np.array\n            State vector representing degrees of freedom of the coilset,\n            to be used to update the coilset.\n        current_scale: float\n            Factor to scale state vector currents up by when setting\n            coilset currents.\n            Used to minimise round-off errors in optimisation.\n        \"\"\"\n        x, z, currents = np.array_split(coilset_state, 3)\n\n        coilset.x = x\n        coilset.z = z\n        coilset.current = currents * current_scale",
  "def get_state_bounds(x_bounds, z_bounds, current_bounds):\n        \"\"\"\n        Get bounds on the state vector from provided bounds on the substates.\n\n        Parameters\n        ----------\n        x_bounds: tuple\n            Tuple containing lower and upper bounds on the radial coil positions.\n        z_bounds: tuple\n            Tuple containing lower and upper bounds on the vertical coil positions.\n        current_bounds: tuple\n            Tuple containing bounds on the coil currents.\n\n        Returns\n        -------\n        bounds: np.array\n            Array containing state vectors representing lower and upper bounds\n            for coilset state degrees of freedom.\n        \"\"\"\n        lower_bounds = np.concatenate((x_bounds[0], z_bounds[0], current_bounds[0]))\n        upper_bounds = np.concatenate((x_bounds[1], z_bounds[1], current_bounds[1]))\n        bounds = np.array([lower_bounds, upper_bounds])\n        return bounds",
  "def get_current_bounds(coilset, max_currents, current_scale):\n        \"\"\"\n        Gets the scaled current vector bounds. Must be called prior to optimise.\n\n        Parameters\n        ----------\n        coilset: Coilset\n            Coilset to fetch current bounds for.\n        max_currents: float or np.ndarray\n            Maximum magnitude of currents in each coil [A] permitted during optimisation.\n            If max_current is supplied as a float, the float will be set as the\n            maximum allowed current magnitude for all coils.\n            If the coils have current density limits that are more restrictive than these\n            coil currents, the smaller current limit of the two will be used for each\n            coil.\n        current_scale: float\n            Factor to scale coilset currents down when returning scaled current limits.\n\n        Returns\n        -------\n        current_bounds: (np.narray, np.narray)\n            Tuple of arrays containing lower and upper bounds for currents\n            permitted in each control coil.\n        \"\"\"\n        n_control_currents = len(coilset.current[coilset._control_ind])\n        scaled_input_current_limits = np.inf * np.ones(n_control_currents)\n\n        if max_currents is not None:\n            input_current_limits = np.asarray(max_currents)\n            input_size = np.size(np.asarray(input_current_limits))\n            if input_size == 1 or input_size == n_control_currents:\n                scaled_input_current_limits = input_current_limits / current_scale\n            else:\n                raise EquilibriaError(\n                    \"Length of max_currents array provided to optimiser is not\"\n                    \"equal to the number of control currents present.\"\n                )\n\n        # Get the current limits from coil current densities\n        coilset_current_limits = np.infty * np.ones(n_control_currents)\n        coilset_current_limits[coilset._flag_sizefix] = coilset.get_max_current()[\n            coilset._flag_sizefix\n        ]\n\n        # Limit the control current magnitude by the smaller of the two limits\n        control_current_limits = np.minimum(\n            scaled_input_current_limits, coilset_current_limits\n        )\n        current_bounds = (-control_current_limits, control_current_limits)\n\n        return current_bounds",
  "def set_current_bounds(self, max_currents: np.ndarray):\n        \"\"\"\n        Set the current bounds on a CoilsetOptimisationProblem\n\n        Parameters\n        ----------\n        max_currents:\n            Vector of maximum currents [A]\n        \"\"\"\n        n_control_currents = len(self.coilset.current[self.coilset._control_ind])\n        if len(max_currents) != n_control_currents:\n            raise ValueError(\n                \"Length of maximum current vector must be equal to the number of controls.\"\n            )\n\n        upper_bounds = np.abs(max_currents) / self.scale\n        lower_bounds = -upper_bounds\n        self.opt.set_lower_bounds(lower_bounds)\n        self.opt.set_upper_bounds(upper_bounds)",
  "def update_magnetic_constraints(\n        self, I_not_dI: bool = True, fixed_coils: bool = True\n    ):\n        \"\"\"\n        Update the magnetic optimisation constraints with the state of the Equilibrium\n        \"\"\"\n        if self._constraints is not None:\n            for constraint in self._constraints:\n                if isinstance(constraint, UpdateableConstraint):\n                    constraint.prepare(\n                        self.eq, I_not_dI=I_not_dI, fixed_coils=fixed_coils\n                    )\n                if \"scale\" in constraint._args:\n                    constraint._args[\"scale\"] = self.scale",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        pfregions: dict,\n        max_currents=None,\n        gamma=1e-8,\n        optimiser=Optimiser(\n            algorithm_name=\"SBPLX\",\n            opt_conditions={\n                \"stop_val\": 1.0,\n                \"max_eval\": 100,\n            },\n        ),\n        constraints=None,\n    ):\n        # noqa :N803\n\n        # Create region map\n        self.region_mapper = RegionMapper(pfregions)\n\n        # Store inputs (optional, but useful for constraints)\n        self.eq = eq\n        self.targets = targets\n\n        # Set objective function for this OptimisationProblem,\n        # and initialise\n        objective = OptimisationObjective(\n            objectives.ad_objective,\n            {\"objective\": self.get_state_figure_of_merit, \"objective_args\": {}},\n        )\n        super().__init__(coilset, optimiser, objective, constraints)\n\n        # Set up bounds\n        bounds = self.get_mapped_state_bounds(self.region_mapper, max_currents)\n        # Add bounds information to help automatic differentiation of objective\n        self._objective._args[\"ad_args\"] = {\"bounds\": bounds}\n        self._objective._args[\"objective_args\"] = {\n            \"coilset\": coilset,\n            \"eq\": eq,\n            \"targets\": targets,\n            \"region_mapper\": self.region_mapper,\n            \"current_scale\": self.scale,\n            \"gamma\": gamma,\n        }\n\n        # Set up optimiser\n        dimension = len(bounds[0])\n        self.set_up_optimiser(dimension, bounds)",
  "def get_mapped_state_bounds(self, region_mapper: RegionMapper, max_currents):\n        \"\"\"\n        Get mapped bounds on the coilset state vector from the coil regions and\n        maximum coil currents.\n\n        Parameters\n        ----------\n        region_mapper: RegionMapper\n            RegionMapper mapping coil positions within the allowed optimisation\n            regions.\n        max_currents Union[float, np.ndarray] (default = None)\n            Maximum allowed current for each independent coil current in coilset [A].\n            If specified as a float, the float will set the maximum allowed current\n            for all coils.\n\n        Returns\n        -------\n        bounds: np.array\n            Array containing state vectors representing lower and upper bounds\n            for coilset state degrees of freedom.\n        \"\"\"\n        # Get mapped position bounds from RegionMapper\n        _, lower_lmap_bounds, upper_lmap_bounds = region_mapper.get_Lmap(self.coilset)\n        current_bounds = self.get_current_bounds(self.coilset, max_currents, self.scale)\n\n        lower_bounds = np.concatenate((lower_lmap_bounds, current_bounds[0]))\n        upper_bounds = np.concatenate((upper_lmap_bounds, current_bounds[1]))\n        bounds = (lower_bounds, upper_bounds)\n        return bounds",
  "def optimise(self):\n        \"\"\"\n        Optimiser handle. Used in __call__\n\n        Returns\n        -------\n        self.coilset: CoilSet\n            Optimised CoilSet object.\n        \"\"\"\n        # Get initial state and apply region mapping to coil positions.\n        initial_state, _ = self.read_coilset_state(self.coilset, self.scale)\n        _, _, initial_currents = np.array_split(initial_state, self.substates)\n        initial_mapped_positions, _, _ = self.region_mapper.get_Lmap(self.coilset)\n        initial_mapped_state = np.concatenate(\n            (initial_mapped_positions, initial_currents)\n        )\n\n        # Optimise\n        state = self.opt.optimise(initial_mapped_state)\n\n        # Call objective function final time on optimised state\n        # to set coilset.\n        # Necessary as optimised state may not always be the final\n        # one evaluated by optimiser.\n        self._objective(state, np.empty(shape=(0, 0)))\n        return self.coilset",
  "def get_state_figure_of_merit(\n        vector,\n        grad,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        region_mapper: RegionMapper,\n        current_scale: float,\n        gamma: float,\n    ):\n        \"\"\"\n        Calculates figure of merit from objective function,\n        consisting of a least-squares objective with Tikhonov\n        regularisation term, which updates the gradient in-place.\n\n        Parameters\n        ----------\n        vector:\n            State vector. Numpy array formed by concatenation of coil radial\n            coordinates, coil vertical coordinates, and (scaled) coil currents.\n        grad:\n            Dummy variable for NLOpt calls. Not updated.\n        coilset:\n            CoilSet to update using state vector.\n        eq:\n            Equilibrium object used to update magnetic field targets.\n        targets:\n            Set of magnetic field targets to optimise Equilibrium towards,\n            using least-squares objective with Tikhonov regularisation.\n        region_mapper\n            RegionMapper mapping coil positions within the allowed optimisation\n            regions.\n        current_scale:\n            Scale factor to scale currents in state vector up by to\n            give currents in [A].\n        gamma:\n            Tikhonov regularisation parameter in units of [A\u207b\u00b9].\n\n        Returns\n        -------\n        fom: float\n            Value of objective function (figure of merit).\n        \"\"\"\n        mapped_x, mapped_z, currents = np.array_split(vector, 3)\n        mapped_positions = np.concatenate((mapped_x, mapped_z))\n        region_mapper.set_Lmap(mapped_positions)\n        x_vals, z_vals = region_mapper.get_xz_arrays()\n        coilset_state = np.concatenate((x_vals, z_vals, currents))\n\n        CoilsetOptimisationProblem.set_coilset_state(\n            coilset, coilset_state, current_scale\n        )\n\n        # Update target\n        eq._remap_greens()\n\n        # Set up data needed in FoM evaluation.\n        # Scale the control matrix and constraint vector by weights.\n        targets(eq, I_not_dI=True, fixed_coils=False)\n        _, a_mat, b_vec = targets.get_weighted_arrays()\n\n        # Calculate objective function\n        fom, err = regularised_lsq_fom(currents * current_scale, a_mat, b_vec, gamma)\n        return fom",
  "def __init__(\n        self,\n        sub_opt: CoilsetOptimisationProblem,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        pfregions: dict,\n        optimiser=Optimiser(\n            algorithm_name=\"SBPLX\",\n            opt_conditions={\n                \"stop_val\": 1.0,\n                \"max_eval\": 100,\n            },\n        ),\n        constraints: List[OptimisationConstraint] = None,\n    ):\n        # noqa :N803\n\n        # Create region map\n        self.region_mapper = RegionMapper(pfregions)\n\n        # Store inputs (optional, but useful for constraints)\n        self.eq = eq\n        self.targets = targets\n\n        # Set objective function for this OptimisationProblem,\n        # and initialise\n        objective = OptimisationObjective(\n            objectives.ad_objective,\n            {\"objective\": self.get_state_figure_of_merit, \"objective_args\": {}},\n        )\n        super().__init__(sub_opt.coilset, optimiser, objective, constraints)\n\n        # Set up bounds\n        _, lower_bounds, upper_bounds = self.region_mapper.get_Lmap(self.coilset)\n        bounds = (lower_bounds, upper_bounds)\n        # Add bounds information to help automatic differentiation of objective\n        self._objective._args[\"ad_args\"] = {\"bounds\": bounds}\n        self._objective._args[\"objective_args\"] = {\n            \"coilset\": self.coilset,\n            \"eq\": eq,\n            \"targets\": targets,\n            \"region_mapper\": self.region_mapper,\n            \"current_scale\": self.scale,\n            \"initial_currents\": self.I0,\n            \"sub_opt\": sub_opt,\n        }\n        # Set up optimiser\n        dimension = len(bounds[0])\n        self.set_up_optimiser(dimension, bounds)",
  "def optimise(self):\n        \"\"\"\n        Optimiser handle. Used in __call__\n\n        Returns\n        -------\n        self.coilset: CoilSet\n            Optimised CoilSet object.\n        \"\"\"\n        # Get initial currents, and trim to within current bounds.\n        initial_state, substates = self.read_coilset_state(self.coilset, self.scale)\n        _, _, initial_currents = np.array_split(initial_state, substates)\n        intial_mapped_positions, _, _ = self.region_mapper.get_Lmap(self.coilset)\n\n        # Optimise\n        self._objective._args[\"objective_args\"][\"initial_currents\"] = initial_currents\n        positions = self.opt.optimise(intial_mapped_positions)\n\n        # Call objective function final time on optimised state\n        # to set coilset.\n        # Necessary as optimised state may not always be the final\n        # one evaluated by optimiser.\n        self._objective(positions, np.empty(shape=(0, 0)))\n        return self.coilset",
  "def get_state_figure_of_merit(\n        vector,\n        grad,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        region_mapper: RegionMapper,\n        current_scale: float,\n        initial_currents,\n        sub_opt: CoilsetOptimisationProblem,\n    ):\n        \"\"\"\n        Calculates figure of merit, returned from the current\n        optimiser at each trial coil position.\n\n        Parameters\n        ----------\n        vector:\n            State vector of the array of coil positions.\n        grad:\n            Dummy variable for NLOpt calls. Not updated.\n        coilset: CoilSet\n            CoilSet to update using state vector.\n        eq:\n            Equilibrium object used to update magnetic field targets.\n        targets:\n            Set of magnetic field targets to update for use in sub_opt.\n        region_mapper:\n            RegionMapper mapping coil positions within the allowed optimisation\n            regions.\n        current_scale:\n            Scale factor to scale currents in state vector up by to\n            give currents in [A].\n        initial_currents:\n            Array containing initial (scaled) coil currents prior to passing\n            to sub_opt\n        sub_opt:\n            Coilset OptimisationProblem used to optimise the array of coil\n            currents at each trial position.\n\n        Returns\n        -------\n        fom:\n            Value of objective function (figure of merit).\n        \"\"\"\n        region_mapper.set_Lmap(vector)\n        x_vals, z_vals = region_mapper.get_xz_arrays()\n        positions = np.concatenate((x_vals, z_vals))\n        coilset_state = np.concatenate((positions, initial_currents))\n        CoilsetOptimisationProblem.set_coilset_state(\n            coilset, coilset_state, current_scale\n        )\n\n        # Update targets\n        eq._remap_greens()\n        targets(eq, I_not_dI=True, fixed_coils=False)\n\n        # Calculate objective function\n        sub_opt()\n        fom = sub_opt.opt.optimum_value\n        return fom",
  "def __init__(self, coilset, eq, targets, gamma):\n        self.eq = eq\n        self.targets = targets\n        self.gamma = gamma\n\n        super().__init__(coilset)",
  "def optimise(self, *args, **kwargs):\n        \"\"\"\n        Optimise the prescribed problem.\n\n        Notes\n        -----\n        The weight vector is used to scale the response matrix and\n        constraint vector. The weights are assumed to be uncorrelated, such that the\n        weight matrix W_ij used to define (for example) the least-squares objective\n        function (Ax - b)\u1d40 W (Ax - b), is diagonal, such that\n        weights[i] = w[i] = sqrt(W[i,i]).\n        \"\"\"\n        # Scale the control matrix and magnetic field targets vector by weights.\n        self.targets(self.eq, I_not_dI=False)\n        _, a_mat, b_vec = self.targets.get_weighted_arrays()\n\n        # Optimise currents using analytic expression for optimum.\n        current_adjustment = tikhonov(a_mat, b_vec, self.gamma)\n\n        # Update parameterisation (coilset).\n        self.coilset.current = self.coilset.current + current_adjustment\n        return self.coilset",
  "def __init__(\n        self,\n        coilset,\n        eq,\n        targets,\n        gamma,\n        optimiser: Optimiser = Optimiser(\n            algorithm_name=\"SLSQP\",\n            opt_conditions={\n                \"xtol_rel\": 1e-4,\n                \"xtol_abs\": 1e-4,\n                \"ftol_rel\": 1e-4,\n                \"ftol_abs\": 1e-4,\n                \"max_eval\": 100,\n            },\n            opt_parameters={\"initial_step\": 0.03},\n        ),\n        max_currents=None,\n        constraints=None,\n    ):\n        self.eq = eq\n        self.targets = targets\n        objective = OptimisationObjective(\n            objectives.regularised_lsq_objective, f_objective_args={\"gamma\": gamma}\n        )\n\n        super().__init__(coilset, optimiser, objective, constraints=constraints)\n\n        bounds = self.get_current_bounds(self.coilset, max_currents, self.scale)\n        dimension = len(bounds[0])\n        self.set_up_optimiser(dimension, bounds)",
  "def optimise(self, x0=None, fixed_coils=True):\n        \"\"\"\n        Solve the optimisation problem\n\n        Parameters\n        ----------\n        fixed_coils: True\n            Whether or not to update to coilset response matrices\n\n        Returns\n        -------\n        coilset: CoilSet\n            Optimised CoilSet\n        \"\"\"\n        # Scale the control matrix and magnetic field targets vector by weights.\n        self.targets(self.eq, I_not_dI=True, fixed_coils=fixed_coils)\n        _, a_mat, b_vec = self.targets.get_weighted_arrays()\n\n        self._objective._args[\"scale\"] = self.scale\n        self._objective._args[\"a_mat\"] = a_mat\n        self._objective._args[\"b_vec\"] = b_vec\n        self._objective.apply_objective(self)\n\n        self.update_magnetic_constraints(I_not_dI=True, fixed_coils=fixed_coils)\n\n        if x0 is None:\n            initial_state, n_states = self.read_coilset_state(self.coilset, self.scale)\n            _, _, initial_currents = np.array_split(initial_state, n_states)\n\n            x0 = np.clip(initial_currents, self.opt.lower_bounds, self.opt.upper_bounds)\n        currents = self.opt.optimise(x0=x0)\n        self.coilset.get_control_coils().current = currents * self.scale\n        return self.coilset",
  "def __init__(self, coilset, eq, optimiser, max_currents=None, constraints=None):\n        self.eq = eq\n        objective = OptimisationObjective(\n            objectives.minimise_coil_currents, f_objective_args={}\n        )\n        super().__init__(coilset, optimiser, objective, constraints)\n\n        bounds = self.get_current_bounds(self.coilset, max_currents, self.scale)\n        dimension = len(bounds[0])\n        self.set_up_optimiser(dimension, bounds)",
  "def optimise(self, x0=None, fixed_coils=True):\n        \"\"\"\n        Solve the optimisation problem\n\n        Parameters\n        ----------\n        fixed_coils: True\n            Whether or not to update to coilset response matrices\n\n        Returns\n        -------\n        coilset: CoilSet\n            Optimised CoilSet\n        \"\"\"\n        self.update_magnetic_constraints(I_not_dI=True, fixed_coils=fixed_coils)\n\n        if x0 is None:\n            initial_state, n_states = self.read_coilset_state(\n                self.eq.coilset, self.scale\n            )\n            _, _, initial_currents = np.array_split(initial_state, n_states)\n\n            x0 = np.clip(initial_currents, self.opt.lower_bounds, self.opt.upper_bounds)\n\n        currents = self.opt.optimise(x0=x0)\n        self.coilset.get_control_coils().current = currents * self.scale\n        return self.coilset",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        position_mapper: PositionMapper,\n        sub_opt_problems: List[CoilsetOptimisationProblem],\n        optimiser: Optimiser = Optimiser(\n            \"COBYLA\", opt_conditions={\"max_eval\": 100, \"ftol_rel\": 1e-6}\n        ),\n        constraints=None,\n        initial_currents=None,\n        debug=False,\n    ):\n        self.position_mapper = position_mapper\n        self.sub_opt_probs = sub_opt_problems\n\n        if initial_currents:\n            self._initial_currents = initial_currents / self.sub_opt_probs[0].scale\n        else:\n            self._initial_currents = np.zeros(coilset.get_control_coils().n_coils())\n        self._debug = {0: debug}\n        self._iter = {0: 0.0}\n\n        objective = OptimisationObjective(\n            f_objective=self.get_state_fom,\n            f_objective_args={\n                \"coilset\": coilset,\n                \"sub_opt_problems\": sub_opt_problems,\n                \"position_mapper\": position_mapper,\n                \"initial_currents\": self._initial_currents,\n                \"itern\": self._iter,\n                \"debug\": self._debug,\n                \"verbose\": False,\n            },\n        )\n        super().__init__(coilset, optimiser, objective, constraints)\n\n        dimension = self.position_mapper.dimension\n        bounds = (np.zeros(dimension), np.ones(dimension))\n        self.set_up_optimiser(dimension, bounds)",
  "def _run_reporting(itern, max_fom, verbose):\n        \"\"\"\n        Keep track of objective function value over iterations.\n        \"\"\"\n        i = max(list(itern.keys())) + 1\n        itern[i] = max_fom\n\n        if verbose:\n            bluemira_print_flush(f\"Coil position iteration {i} FOM value: {max_fom:.6e}\")",
  "def _run_diagnostics(debug, sub_opt_prob):\n        \"\"\"\n        In debug mode, store the LCFS at each iteration for each of the sub-optimisation\n        problems.\n\n        Notes\n        -----\n        This can significantly impact run-time.\n        \"\"\"\n        if debug[0]:\n            entry = max(list(debug.keys()))\n            value = sub_opt_prob.opt.optimum_value\n            sub_opt_prob.eq._remap_greens()\n            sub_opt_prob.eq._clear_OX_points()\n            lcfs = sub_opt_prob.eq.get_LCFS()\n            debug[entry].append([lcfs, value])",
  "def get_sub_opt_foms(\n        vector,\n        coilset,\n        position_mapper,\n        sub_opt_problems,\n        initial_currents,\n        itern,\n        verbose,\n        debug,\n    ):\n        \"\"\"\n        Run the sub-optimisation problems for a given position vector and return the\n        objective function values\n        \"\"\"\n        positions = position_mapper.to_xz_dict(vector)\n\n        if debug[0]:\n            # Increment debug dictionary\n            i = max(list(debug.keys())) + 1\n            debug[i] = []\n\n        fom_values = []\n        for sub_opt_prob in sub_opt_problems:\n            for coil, position in positions.items():\n                sub_opt_prob.coilset[coil].position = position\n            sub_opt_prob.optimise(x0=initial_currents, fixed_coils=False)\n            PulsedNestedPositionCOP._run_diagnostics(debug, sub_opt_prob)\n            fom_values.append(sub_opt_prob.opt.optimum_value)\n        max_fom = max(fom_values)\n\n        PulsedNestedPositionCOP._run_reporting(itern, max_fom, verbose)\n\n        return max_fom",
  "def get_state_fom(\n        vector,\n        grad,\n        coilset,\n        sub_opt_problems,\n        position_mapper,\n        initial_currents,\n        itern,\n        verbose,\n        debug,\n    ):\n        \"\"\"\n        Get the figure of merit for a single sub-optimisation problem.\n        \"\"\"\n        fom_value = PulsedNestedPositionCOP.get_sub_opt_foms(\n            vector,\n            coilset,\n            position_mapper,\n            sub_opt_problems,\n            initial_currents,\n            itern,\n            verbose,\n            debug,\n        )\n\n        if grad.size > 0:\n            grad[:] = approx_derivative(\n                PulsedNestedPositionCOP.get_sub_opt_foms,\n                vector,\n                f0=fom_value,\n            )\n\n        return fom_value",
  "def _get_initial_vector(self):\n        \"\"\"\n        Get a vector representation of the initial coilset state from the PositionMapper.\n        \"\"\"\n        x, z = [], []\n        for name in self.position_mapper.interpolators:\n            x.append(self.coilset[name].x)\n            z.append(self.coilset[name].z)\n        return self.position_mapper.to_L(x, z)",
  "def optimise(self, x0=None, verbose=False):\n        \"\"\"\n        Run the PulsedNestedPositionCOP\n\n        Parameters\n        ----------\n        x0: Optional[np.ndarray]\n            Initial solution vector (parameterised positions)\n        verbose: bool\n            Whether or not to print progress information\n\n        Returns\n        -------\n        coilset: CoilSet\n            Optimised CoilSet\n        \"\"\"\n        self._objective._args[\"verbose\"] = verbose\n\n        if x0 is None:\n            x0 = self._get_initial_vector()\n        optimal_positions = self.opt.optimise(x0=x0)\n        # Call the objective one last time\n        self.get_sub_opt_foms(\n            optimal_positions,\n            self.coilset,\n            self.position_mapper,\n            self.sub_opt_probs,\n            self._initial_currents,\n            itern=self._iter,\n            verbose=verbose,\n            debug=self._debug,\n        )\n\n        # Clean up state of Equilibrium objects\n        for sub_opt in self.sub_opt_probs:\n            sub_opt.eq._remap_greens()\n            sub_opt.eq._clear_OX_points()\n        return self.coilset",
  "def __init__(self, R_0, A, tk_sol, **kwargs):\n        self.R_0 = R_0\n        self.A = A\n        self.tk_sol = tk_sol",
  "def breakdown_point(self) -> Tuple[float]:\n        \"\"\"\n        The location of the breakdown point.\n\n        Returns\n        -------\n        x_c: float\n            Radial coordinate of the breakdown point\n        z_c: float\n            Vertical coordinate of the breakdown point\n        \"\"\"\n        pass",
  "def breakdown_radius(self) -> float:\n        \"\"\"\n        The radius of the breakdown zone.\n        \"\"\"\n        pass",
  "def calculate_zone_points(self, n_points: int) -> Tuple[np.ndarray]:\n        \"\"\"\n        Calculate the discretised set of points representing the breakdown zone.\n        \"\"\"\n        pass",
  "def calculate_zone_points(self, n_points: int) -> Tuple[np.ndarray]:\n        \"\"\"\n        Calculate the discretised set of points representing the breakdown zone.\n        \"\"\"\n        x_c, z_c = self.breakdown_point\n        r_c = self.breakdown_radius\n        theta = np.linspace(0, 2 * np.pi, n_points - 1, endpoint=False)\n        x = x_c + r_c * np.cos(theta)\n        z = z_c + r_c * np.sin(theta)\n        x = np.append(x, x_c)\n        z = np.append(z, z_c)\n        return x, z",
  "def breakdown_point(self) -> Tuple[float]:\n        r_c = self.breakdown_radius\n        x_c = self.R_0 - self.R_0 / self.A - self.tk_sol + r_c\n        z_c = 0.0\n        return x_c, z_c",
  "def breakdown_radius(self) -> float:\n        return 0.5 * self.R_0 / self.A",
  "def breakdown_point(self) -> Tuple[float]:\n        r_c = self.breakdown_radius\n        x_c = self.R_0 + self.R_0 / self.A + self.tk_sol - r_c\n        z_c = 0.0\n        return x_c, z_c",
  "def breakdown_radius(self) -> float:\n        return 0.7 * self.R_0 / self.A",
  "def __call__(self, *args, **kwargs):\n        return self",
  "def __init__(self, x_c, z_c, r_c):\n        self.x_c = x_c\n        self.z_c = z_c\n        self.r_c = r_c",
  "def breakdown_point(self) -> Tuple[float]:\n        return self.x_c, self.z_c",
  "def breakdown_radius(self) -> float:\n        return self.r_c",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        breakdown: Breakdown,\n        breakdown_strategy: BreakdownZoneStrategy,\n        B_stray_max,\n        B_stray_con_tol,\n        n_B_stray_points,\n        optimiser: Optimiser = None,\n        max_currents=None,\n        constraints: List[OptimisationConstraint] = None,\n    ):\n        self.eq = breakdown\n        self.scale = 1e6  # current_scale\n\n        objective = OptimisationObjective(\n            objectives.maximise_flux,\n            f_objective_args={\n                \"c_psi_mat\": np.array(\n                    coilset.psi_response(*breakdown_strategy.breakdown_point)\n                ),\n                \"scale\": self.scale,\n            },\n        )\n\n        x_zone, z_zone = breakdown_strategy.calculate_zone_points(n_B_stray_points)\n\n        stray_field_cons = FieldConstraints(\n            x_zone, z_zone, B_max=B_stray_max, tolerance=B_stray_con_tol\n        )\n\n        if constraints:\n            constraints.append(stray_field_cons)\n        else:\n            constraints = [stray_field_cons]\n\n        super().__init__(coilset, optimiser, objective, constraints)\n\n        # Set up optimiser\n        bounds = (-max_currents / self.scale, max_currents / self.scale)\n        dimension = len(bounds[0])\n        self.set_up_optimiser(dimension, bounds)",
  "def optimise(self, x0=None, fixed_coils=True):\n        \"\"\"\n        Solve the optimisation problem.\n        \"\"\"\n        self.update_magnetic_constraints(I_not_dI=True, fixed_coils=fixed_coils)\n\n        initial_state, n_states = self.read_coilset_state(self.coilset, self.scale)\n        _, _, initial_currents = np.array_split(initial_state, n_states)\n\n        initial_currents = np.clip(\n            initial_currents, self.opt.lower_bounds, self.opt.upper_bounds\n        )\n        currents = self.opt.optimise(x0=initial_currents)\n        self.coilset.get_control_coils().current = currents * self.scale\n        return self.coilset",
  "class ConvergenceCriterion(ABC):\n    \"\"\"\n    Convergence criterion base class\n\n    Parameters\n    ----------\n    limit:\n        The limit at which the convergence criterion is met.\n    \"\"\"\n\n    flag_psi = True\n\n    def __init__(self, limit: float):\n        self.limit = limit\n        self.progress = []\n        self.math_string = NotImplemented\n\n    @abstractmethod\n    def __call__(\n        self, old_val: np.ndarray, new_val: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        old_val:\n            The value from the previous iteration.\n        new_val:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        pass\n\n    def check_converged(self, value: float) -> bool:\n        \"\"\"\n        Check for convergence.\n\n        Parameters\n        ----------\n        value:\n            The value of the convergence criterion\n\n        Returns\n        -------\n        Whether or not convergence has been reached\n        \"\"\"\n        self.progress.append(value)\n        if value <= self.limit:\n            return True\n        return False\n\n    def plot(self, ax: Optional[plt.Axes] = None):\n        \"\"\"\n        Plot the convergence behaviour.\n\n        Parameters\n        ----------\n        ax:\n            The matplotlib axes onto which to plot\n        \"\"\"\n        if ax is None:\n            f, ax = plt.subplots()\n        ax.semilogy(self.progress)\n        ax.set_xlabel(\"Iterations [n]\")\n        ax.set_ylabel(self.math_string)",
  "class DudsonConvergence(ConvergenceCriterion):\n    \"\"\"\n    FreeGS convergence criterion\n\n    Parameters\n    ----------\n    limit:\n        The limit at which the convergence criterion is met.\n    \"\"\"\n\n    def __init__(self, limit: float = PSI_REL_TOL):\n        super().__init__(limit)\n        self.math_string = \"$\\\\dfrac{max|\\\\Delta\\\\psi|}{max(\\\\psi)-min(\\\\psi)}$\"\n\n    def __call__(\n        self, psi_old: np.ndarray, psi: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        psi_old:\n            The value from the previous iteration.\n        psi:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        dpsi = psi_old - psi\n        dpsi_max = np.amax(abs(dpsi))\n        dpsi_rel = dpsi_max / (np.amax(psi) - np.amin(psi))\n        if print_status:\n            bluemira_print_flush(\n                f\"EQUILIBRIA G-S iter {i}: relative delta_psi: {100*dpsi_rel:.2f} %\"\n            )\n        return self.check_converged(dpsi_rel)",
  "class JrelConvergence(ConvergenceCriterion):\n    \"\"\"\n    FreeGS convergence criterion\n\n    Parameters\n    ----------\n    limit:\n        The limit at which the convergence criterion is met.\n    \"\"\"\n\n    flag_psi = False\n\n    def __init__(self, limit: float = 1e-2):\n        super().__init__(limit)\n        self.math_string = \"$\\\\dfrac{max|\\\\Delta J|}{max(J)-min(J)}$\"\n\n    def __call__(\n        self, j_old: np.ndarray, j_new: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        j_old:\n            The value from the previous iteration.\n        j_new:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        d_j = j_old - j_new\n        d_j_max = np.amax(abs(d_j))\n        d_j_rel = d_j_max / (np.amax(j_new) - np.amin(j_new))\n        if print_status:\n            bluemira_print_flush(\n                f\"EQUILIBRIA G-S iter {i}: relative delta_J: {100*d_j_rel:.2f} %\"\n            )\n        return self.check_converged(d_j_rel)",
  "class LacknerConvergence(ConvergenceCriterion):\n    \"\"\"\n    Karl Lackner's convergence criterion (< 10E-4)\n    (Lackner, Computation of ideal MHD equilibria, 1976)\n\n    Parameters\n    ----------\n    limit:\n        The limit at which the convergence criterion is met.\n    \"\"\"\n\n    def __init__(self, limit: float = 10e-4):\n        super().__init__(limit)\n        self.math_string = \"$max\\\\dfrac{|\\\\Delta\\\\psi|}{\\\\psi}$\"\n\n    def __call__(\n        self, psi_old: np.ndarray, psi: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        psi_old:\n            The value from the previous iteration.\n        psi:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        conv = np.amax(np.abs((psi - psi_old) / psi))\n        if print_status:\n            bluemira_print_flush(f\"EQUILIBRIA G-S iter {i}: psi convergence: {conv:e}\")\n        return self.check_converged(conv)",
  "class JeonConvergence(ConvergenceCriterion):\n    \"\"\"\n    TES convergence criterion\n\n    Parameters\n    ----------\n    limit:\n        The limit at which the convergence criterion is met.\n    \"\"\"\n\n    def __init__(self, limit: float = 1e-4):\n        super().__init__(limit)\n        self.math_string = \"$||\\\\Delta\\\\psi||$\"\n\n    def __call__(\n        self, psi_old: np.ndarray, psi: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        psi_old:\n            The value from the previous iteration.\n        psi:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        conv = np.linalg.norm(psi_old - psi)\n        if print_status:\n            bluemira_print_flush(\n                f\"EQUILIBRIA G-S iter {i}: psi norm convergence: {conv:e}\"\n            )\n        return self.check_converged(conv)",
  "class CunninghamConvergence(ConvergenceCriterion):\n    \"\"\"\n    FIESTA convergence criterion\n\n    Parameters\n    ----------\n    limit:\n        The limit at which the convergence criterion is met.\n    \"\"\"\n\n    flag_psi = False\n\n    def __init__(self, limit: float = 1e-7):\n        super().__init__(limit)\n        self.math_string = \"$\\\\dfrac{\\\\sum{\\\\Delta J_{n}^{2}}}{\\\\sum{J_{n+1}^{2}}}$\"\n\n    def __call__(\n        self, j_old: np.ndarray, j_new: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        j_old:\n            The value from the previous iteration.\n        j_new:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        d_j = j_old - j_new\n        conv = np.sum(d_j**2) / np.sum(j_new**2)\n        if print_status:\n            bluemira_print_flush(\n                f\"EQUILIBRIA G-S iter {i}: J_phi source convergence: {conv:e}\"\n            )\n        self._conv = conv\n        return self.check_converged(conv)",
  "class JsourceConvergence(ConvergenceCriterion):\n    \"\"\"\n    Plasma current source convergence criterion.\n\n    Parameters\n    ----------\n    limit:\n        The limit at which the convergence criterion is met.\n    \"\"\"\n\n    flag_psi = False\n\n    def __init__(self, limit: float = 1e-4):\n        super().__init__(limit)\n        self.math_string = \"$||\\\\Delta J||$\"\n\n    def __call__(\n        self, j_old: np.ndarray, j_new: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        j_old:\n            The value from the previous iteration.\n        j_new:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        conv = np.linalg.norm(j_old - j_new)\n        if print_status:\n            # Format convergence\n            bluemira_print_flush(\n                f\"EQUILIBRIA G-S iter {i}: ||J_phi_old-J_phi|| convergence: {conv:e}\"\n            )\n        return self.check_converged(conv)",
  "class PicardIterator:\n    \"\"\"A Picard iterative solver.\n\n    Child classes must provide a __call__ method which carries out the\n    iteration process(es)\n\n    Parameters\n    ----------\n    eq:\n        The equilibrium to solve for\n    optimisation_problem:\n        The optimisation problem to use when iterating\n    convergence:\n        The convergence criterion to use (defaults to Dudson)\n    fixed_coils:\n        Whether or not the coil positions are fixed\n    relaxation:\n        The relaxation parameter to use between iterations\n    maxiter:\n        The maximum number of iterations\n    plot:\n        Whether or not to plot\n    gif:\n        Whether or not to make a GIF\n    figure_folder:\n        The path where figures will be saved. If the input value is None (e.g. default)\n        then this will be reinterpreted as the path data/plots/equilibria under the\n        bluemira root folder, if that path is available.\n    plot_name:\n        GIF plot file base-name\n    \"\"\"\n\n    def __init__(\n        self,\n        eq: Equilibrium,\n        optimisation_problem: CoilsetOptimisationProblem,\n        convergence: Optional[ConvergenceCriterion] = None,\n        fixed_coils: bool = False,\n        relaxation: float = 0,\n        maxiter: int = 30,\n        plot: bool = True,\n        gif: bool = False,\n        figure_folder: Optional[str] = None,\n        plot_name: str = \"default_0\",\n    ):\n        self.eq = eq\n        self.coilset = self.eq.coilset\n        self.opt_prob = optimisation_problem\n        if isinstance(convergence, ConvergenceCriterion):\n            self.convergence = convergence\n        elif convergence is None:\n            self.convergence = DudsonConvergence()\n        else:\n            raise ValueError(\n                \"Optimiser convergence specification must be a sub-class of ConvergenceCriterion.\"\n            )\n        self.fixed_coils = fixed_coils\n\n        self.relaxation = relaxation\n        self.maxiter = maxiter\n        self.plot_flag = plot or (gif and not plot)\n        self.gif_flag = gif\n        if figure_folder is None:\n            figure_folder = try_get_bluemira_path(\n                \"\", subfolder=\"generated_data\", allow_missing=not self.gif_flag\n            )\n        self.figure_folder = figure_folder\n        self.store = []\n        self.i = 0\n        if self.plot_flag:\n            self.pname = plot_name\n            self.f, self.ax = plt.subplots()\n\n    def _optimise_coilset(self):\n        try:\n            result = self.opt_prob.optimise(fixed_coils=self.fixed_coils)\n            try:\n                coilset = result.coilset\n            except AttributeError:\n                coilset = result\n            self.store.append(coilset)\n        except ExternalOptError:\n            coilset = self.store[-1]\n        self.result = result\n        self.coilset = coilset\n\n    @property\n    def psi(self) -> np.ndarray:\n        \"\"\"\n        Get the magnetic flux array.\n        \"\"\"\n        return self._psi\n\n    @property\n    def j_tor(self) -> np.ndarray:\n        \"\"\"\n        Get the toroidal current density array.\n        \"\"\"\n        return self._j_tor\n\n    def __call__(self) -> CoilsetOptimiserResult:\n        \"\"\"\n        The iteration object call handle.\n        \"\"\"\n        iterator = iter(self)\n        while self.i < self.maxiter:\n            try:\n                next(iterator)\n            except StopIteration:\n                print()\n                bluemira_print(\"EQUILIBRIA G-S converged value found.\")\n                break\n        else:\n            print()\n            bluemira_warn(\n                f\"EQUILIBRIA G-S unable to find converged value after {self.i} iterations.\"\n            )\n        self._teardown()\n        return self.result\n\n    def __iter__(self) -> Iterator:\n        \"\"\"\n        Make the class a Python iterator.\n\n        Returns\n        -------\n        The current instance as an iterator.\n        \"\"\"\n        self._setup()\n        return self\n\n    def __next__(self):\n        \"\"\"\n        Perform an interation of the solver.\n        \"\"\"\n        if not hasattr(self, \"_psi\"):\n            self._setup()\n\n        if self.i > 0 and self.check_converged(print_status=False):\n            raise StopIteration\n\n        self._psi_old = self.psi.copy()\n        self._j_tor_old = self.j_tor.copy()\n        self._solve()\n        self._psi = self.eq.psi()\n        self._j_tor = self.eq._jtor\n        check = self.check_converged()\n        if self.plot_flag:\n            self.update_fig()\n        if check:\n            if self.gif_flag:\n                make_gif(self.figure_folder, self.pname)\n            raise StopIteration\n        self._optimise_coilset()\n        self._psi = (\n            1 - self.relaxation\n        ) * self.eq.psi() + self.relaxation * self._psi_old\n        self.i += 1\n\n    def iterate_once(self) -> CoilsetOptimiserResult:\n        \"\"\"\n        Perform a single iteration and handle convergence.\n        \"\"\"\n        try:\n            next(self)\n        except StopIteration:\n            bluemira_print(\"EQUILIBRIA G-S converged value found, nothing to do.\")\n            self._teardown()\n        return self.result\n\n    def check_converged(self, print_status: bool = True) -> bool:\n        \"\"\"\n        Check if the iterator has converged.\n\n        Parameters\n        ----------\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        if self.convergence.flag_psi:\n            return self.convergence(\n                self._psi_old, self.psi, self.i, print_status=print_status\n            )\n\n        return self.convergence(\n            self._j_tor_old, self.j_tor, self.i, print_status=print_status\n        )\n\n    def update_fig(self):\n        \"\"\"\n        Updates the figure if plotting is used\n        \"\"\"\n        self.ax.clear()\n        self.eq.plot(ax=self.ax)\n        plt.pause(PLT_PAUSE)\n        save_figure(\n            self.f,\n            self.pname + str(self.i),\n            save=self.gif_flag,\n            folder=self.figure_folder,\n            dpi=DPI_GIF,\n        )\n\n    def _solve(self):\n        \"\"\"\n        Solve for this iteration.\n        \"\"\"\n        if self.eq._li_flag and self.i > self.eq.profiles._l_i_min_iter:\n            self.eq.solve_li(psi=self.psi)\n        else:\n            self.eq.solve(psi=self.psi)\n\n    def _initial_optimise_coilset(self, **kwargs):\n        self._optimise_coilset(**kwargs)\n\n    def _setup(self):\n        \"\"\"\n        Initialise psi and toroidal current values.\n        \"\"\"\n        self._initial_optimise_coilset()\n        self._psi = self.eq.psi()\n        self._j_tor = self.eq._jtor\n        if self._j_tor is None:\n            self._j_tor = np.zeros((self.eq.grid.nx, self.eq.grid.nz))\n\n    def _teardown(self):\n        \"\"\"Final clean-up for consistency between psi and jtor.\n\n        In the case of converged equilibria, slight (artificial) improvement\n        in consistency. In the case of unconverged equilibria, gives a more\n        reasonable understanding of the final state.\n        \"\"\"\n        o_points, x_points = self.eq.get_OX_points(force_update=True)\n        self.eq._jtor = self.eq.profiles.jtor(\n            self.eq.x, self.eq.z, self.eq.psi(), o_points, x_points\n        )",
  "def __init__(self, limit: float):\n        self.limit = limit\n        self.progress = []\n        self.math_string = NotImplemented",
  "def __call__(\n        self, old_val: np.ndarray, new_val: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        old_val:\n            The value from the previous iteration.\n        new_val:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        pass",
  "def check_converged(self, value: float) -> bool:\n        \"\"\"\n        Check for convergence.\n\n        Parameters\n        ----------\n        value:\n            The value of the convergence criterion\n\n        Returns\n        -------\n        Whether or not convergence has been reached\n        \"\"\"\n        self.progress.append(value)\n        if value <= self.limit:\n            return True\n        return False",
  "def plot(self, ax: Optional[plt.Axes] = None):\n        \"\"\"\n        Plot the convergence behaviour.\n\n        Parameters\n        ----------\n        ax:\n            The matplotlib axes onto which to plot\n        \"\"\"\n        if ax is None:\n            f, ax = plt.subplots()\n        ax.semilogy(self.progress)\n        ax.set_xlabel(\"Iterations [n]\")\n        ax.set_ylabel(self.math_string)",
  "def __init__(self, limit: float = PSI_REL_TOL):\n        super().__init__(limit)\n        self.math_string = \"$\\\\dfrac{max|\\\\Delta\\\\psi|}{max(\\\\psi)-min(\\\\psi)}$\"",
  "def __call__(\n        self, psi_old: np.ndarray, psi: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        psi_old:\n            The value from the previous iteration.\n        psi:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        dpsi = psi_old - psi\n        dpsi_max = np.amax(abs(dpsi))\n        dpsi_rel = dpsi_max / (np.amax(psi) - np.amin(psi))\n        if print_status:\n            bluemira_print_flush(\n                f\"EQUILIBRIA G-S iter {i}: relative delta_psi: {100*dpsi_rel:.2f} %\"\n            )\n        return self.check_converged(dpsi_rel)",
  "def __init__(self, limit: float = 1e-2):\n        super().__init__(limit)\n        self.math_string = \"$\\\\dfrac{max|\\\\Delta J|}{max(J)-min(J)}$\"",
  "def __call__(\n        self, j_old: np.ndarray, j_new: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        j_old:\n            The value from the previous iteration.\n        j_new:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        d_j = j_old - j_new\n        d_j_max = np.amax(abs(d_j))\n        d_j_rel = d_j_max / (np.amax(j_new) - np.amin(j_new))\n        if print_status:\n            bluemira_print_flush(\n                f\"EQUILIBRIA G-S iter {i}: relative delta_J: {100*d_j_rel:.2f} %\"\n            )\n        return self.check_converged(d_j_rel)",
  "def __init__(self, limit: float = 10e-4):\n        super().__init__(limit)\n        self.math_string = \"$max\\\\dfrac{|\\\\Delta\\\\psi|}{\\\\psi}$\"",
  "def __call__(\n        self, psi_old: np.ndarray, psi: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        psi_old:\n            The value from the previous iteration.\n        psi:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        conv = np.amax(np.abs((psi - psi_old) / psi))\n        if print_status:\n            bluemira_print_flush(f\"EQUILIBRIA G-S iter {i}: psi convergence: {conv:e}\")\n        return self.check_converged(conv)",
  "def __init__(self, limit: float = 1e-4):\n        super().__init__(limit)\n        self.math_string = \"$||\\\\Delta\\\\psi||$\"",
  "def __call__(\n        self, psi_old: np.ndarray, psi: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        psi_old:\n            The value from the previous iteration.\n        psi:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        conv = np.linalg.norm(psi_old - psi)\n        if print_status:\n            bluemira_print_flush(\n                f\"EQUILIBRIA G-S iter {i}: psi norm convergence: {conv:e}\"\n            )\n        return self.check_converged(conv)",
  "def __init__(self, limit: float = 1e-7):\n        super().__init__(limit)\n        self.math_string = \"$\\\\dfrac{\\\\sum{\\\\Delta J_{n}^{2}}}{\\\\sum{J_{n+1}^{2}}}$\"",
  "def __call__(\n        self, j_old: np.ndarray, j_new: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        j_old:\n            The value from the previous iteration.\n        j_new:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        d_j = j_old - j_new\n        conv = np.sum(d_j**2) / np.sum(j_new**2)\n        if print_status:\n            bluemira_print_flush(\n                f\"EQUILIBRIA G-S iter {i}: J_phi source convergence: {conv:e}\"\n            )\n        self._conv = conv\n        return self.check_converged(conv)",
  "def __init__(self, limit: float = 1e-4):\n        super().__init__(limit)\n        self.math_string = \"$||\\\\Delta J||$\"",
  "def __call__(\n        self, j_old: np.ndarray, j_new: np.ndarray, i: int, print_status: bool = True\n    ) -> bool:\n        \"\"\"\n        Carry out convergence check.\n\n        Parameters\n        ----------\n        j_old:\n            The value from the previous iteration.\n        j_new:\n            The value from the current iteration.\n        i:\n            The index of the iteration.\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        conv = np.linalg.norm(j_old - j_new)\n        if print_status:\n            # Format convergence\n            bluemira_print_flush(\n                f\"EQUILIBRIA G-S iter {i}: ||J_phi_old-J_phi|| convergence: {conv:e}\"\n            )\n        return self.check_converged(conv)",
  "def __init__(\n        self,\n        eq: Equilibrium,\n        optimisation_problem: CoilsetOptimisationProblem,\n        convergence: Optional[ConvergenceCriterion] = None,\n        fixed_coils: bool = False,\n        relaxation: float = 0,\n        maxiter: int = 30,\n        plot: bool = True,\n        gif: bool = False,\n        figure_folder: Optional[str] = None,\n        plot_name: str = \"default_0\",\n    ):\n        self.eq = eq\n        self.coilset = self.eq.coilset\n        self.opt_prob = optimisation_problem\n        if isinstance(convergence, ConvergenceCriterion):\n            self.convergence = convergence\n        elif convergence is None:\n            self.convergence = DudsonConvergence()\n        else:\n            raise ValueError(\n                \"Optimiser convergence specification must be a sub-class of ConvergenceCriterion.\"\n            )\n        self.fixed_coils = fixed_coils\n\n        self.relaxation = relaxation\n        self.maxiter = maxiter\n        self.plot_flag = plot or (gif and not plot)\n        self.gif_flag = gif\n        if figure_folder is None:\n            figure_folder = try_get_bluemira_path(\n                \"\", subfolder=\"generated_data\", allow_missing=not self.gif_flag\n            )\n        self.figure_folder = figure_folder\n        self.store = []\n        self.i = 0\n        if self.plot_flag:\n            self.pname = plot_name\n            self.f, self.ax = plt.subplots()",
  "def _optimise_coilset(self):\n        try:\n            result = self.opt_prob.optimise(fixed_coils=self.fixed_coils)\n            try:\n                coilset = result.coilset\n            except AttributeError:\n                coilset = result\n            self.store.append(coilset)\n        except ExternalOptError:\n            coilset = self.store[-1]\n        self.result = result\n        self.coilset = coilset",
  "def psi(self) -> np.ndarray:\n        \"\"\"\n        Get the magnetic flux array.\n        \"\"\"\n        return self._psi",
  "def j_tor(self) -> np.ndarray:\n        \"\"\"\n        Get the toroidal current density array.\n        \"\"\"\n        return self._j_tor",
  "def __call__(self) -> CoilsetOptimiserResult:\n        \"\"\"\n        The iteration object call handle.\n        \"\"\"\n        iterator = iter(self)\n        while self.i < self.maxiter:\n            try:\n                next(iterator)\n            except StopIteration:\n                print()\n                bluemira_print(\"EQUILIBRIA G-S converged value found.\")\n                break\n        else:\n            print()\n            bluemira_warn(\n                f\"EQUILIBRIA G-S unable to find converged value after {self.i} iterations.\"\n            )\n        self._teardown()\n        return self.result",
  "def __iter__(self) -> Iterator:\n        \"\"\"\n        Make the class a Python iterator.\n\n        Returns\n        -------\n        The current instance as an iterator.\n        \"\"\"\n        self._setup()\n        return self",
  "def __next__(self):\n        \"\"\"\n        Perform an interation of the solver.\n        \"\"\"\n        if not hasattr(self, \"_psi\"):\n            self._setup()\n\n        if self.i > 0 and self.check_converged(print_status=False):\n            raise StopIteration\n\n        self._psi_old = self.psi.copy()\n        self._j_tor_old = self.j_tor.copy()\n        self._solve()\n        self._psi = self.eq.psi()\n        self._j_tor = self.eq._jtor\n        check = self.check_converged()\n        if self.plot_flag:\n            self.update_fig()\n        if check:\n            if self.gif_flag:\n                make_gif(self.figure_folder, self.pname)\n            raise StopIteration\n        self._optimise_coilset()\n        self._psi = (\n            1 - self.relaxation\n        ) * self.eq.psi() + self.relaxation * self._psi_old\n        self.i += 1",
  "def iterate_once(self) -> CoilsetOptimiserResult:\n        \"\"\"\n        Perform a single iteration and handle convergence.\n        \"\"\"\n        try:\n            next(self)\n        except StopIteration:\n            bluemira_print(\"EQUILIBRIA G-S converged value found, nothing to do.\")\n            self._teardown()\n        return self.result",
  "def check_converged(self, print_status: bool = True) -> bool:\n        \"\"\"\n        Check if the iterator has converged.\n\n        Parameters\n        ----------\n        print_status:\n            If True then prints the status of the convergence, by default True.\n\n        Returns\n        -------\n        True if the convergence criterion is met, else False.\n        \"\"\"\n        if self.convergence.flag_psi:\n            return self.convergence(\n                self._psi_old, self.psi, self.i, print_status=print_status\n            )\n\n        return self.convergence(\n            self._j_tor_old, self.j_tor, self.i, print_status=print_status\n        )",
  "def update_fig(self):\n        \"\"\"\n        Updates the figure if plotting is used\n        \"\"\"\n        self.ax.clear()\n        self.eq.plot(ax=self.ax)\n        plt.pause(PLT_PAUSE)\n        save_figure(\n            self.f,\n            self.pname + str(self.i),\n            save=self.gif_flag,\n            folder=self.figure_folder,\n            dpi=DPI_GIF,\n        )",
  "def _solve(self):\n        \"\"\"\n        Solve for this iteration.\n        \"\"\"\n        if self.eq._li_flag and self.i > self.eq.profiles._l_i_min_iter:\n            self.eq.solve_li(psi=self.psi)\n        else:\n            self.eq.solve(psi=self.psi)",
  "def _initial_optimise_coilset(self, **kwargs):\n        self._optimise_coilset(**kwargs)",
  "def _setup(self):\n        \"\"\"\n        Initialise psi and toroidal current values.\n        \"\"\"\n        self._initial_optimise_coilset()\n        self._psi = self.eq.psi()\n        self._j_tor = self.eq._jtor\n        if self._j_tor is None:\n            self._j_tor = np.zeros((self.eq.grid.nx, self.eq.grid.nz))",
  "def _teardown(self):\n        \"\"\"Final clean-up for consistency between psi and jtor.\n\n        In the case of converged equilibria, slight (artificial) improvement\n        in consistency. In the case of unconverged equilibria, gives a more\n        reasonable understanding of the final state.\n        \"\"\"\n        o_points, x_points = self.eq.get_OX_points(force_update=True)\n        self.eq._jtor = self.eq.profiles.jtor(\n            self.eq.x, self.eq.z, self.eq.psi(), o_points, x_points\n        )",
  "def fitfunc(\n    func: Callable[[float], float], data: np.ndarray, order: Optional[int] = None\n) -> np.ndarray:\n    \"\"\"\n    Uses scipy's curve_fit to fit 1-D data to a custom function\n\n    Parameters\n    ----------\n    func:\n        Function parameterisation to use in the fit\n    data:\n        Data to fit\n    order:\n        Order of function callable (if user defined)\n\n    Returns\n    -------\n    Optimised fitting parameters\n    \"\"\"\n    x = np.linspace(0, 1, len(data))\n    if order is None:\n        p0 = None\n    else:\n        p0 = [1] * order\n    popt, _ = curve_fit(func, x, data, p0=p0)\n    return popt",
  "def singlepowerfunc(x: float, *args) -> float:\n    \"\"\"\n    Single power shape function defined e.g. CREATE stuff\n\n    \\t:math:`g(x)=(1-x^{n})`\n    \"\"\"\n    n = args[0]\n    return 1 - x**n",
  "def doublepowerfunc(x: float, *args) -> float:\n    \"\"\"\n    Double power shape function defined e.g. in Lao 1985\n        https://iopscience.iop.org/article/10.1088/0029-5515/25/11/007/pdf \\n\n    \\t:math:`g(x)=(1-x^{m})^{n}`\n    \"\"\"\n    # sign tweak needed to avoid runtimewarnings in np\n    m, n = args\n    f = 1 - np.sign(x) * np.abs(x) ** m\n    return np.sign(f) * (np.abs(f)) ** n",
  "def pshape(\n    shape: Callable[[float], float], psinorm: float, psio: float, psix: float\n) -> float:\n    \"\"\"\n    Integral of jtorshape to calculate pressure\n    NOTE: factor to convert from normalised psi integral\n    \"\"\"\n    si = quad(shape, psinorm, 1, limit=100)[0]\n    si *= psix - psio\n    return si",
  "def speedy_pressure(\n    psi_norm: np.ndarray, psio: float, psix: float, shape: Callable[[float], float]\n) -> np.ndarray:\n    \"\"\"\n    Calculate the pressure map on the psi_norm array without any masking because\n    the plasma is not clearly bounded.\n\n    Parameters\n    ----------\n    psi_norm:\n        The normalised poloidal magnetic flux array\n    psio:\n        The psi value at the centre of the plasma (O-point)\n    psix:\n        The psi value at the edge of the plasma (X-point)\n    shape:\n        The shape function to use when calculating the pressure at each point\n\n    Returns\n    -------\n    The pressure on the grid\n    \"\"\"\n    nx, nz = psi_norm.shape\n    pfunc = np.zeros((nx, nz))\n    for i in range(1, nx - 1):\n        for j in range(1, nz - 1):\n            if (psi_norm[i, j] >= 0) and (psi_norm[i, j] < 1):\n                pfunc[i, j] = pshape(shape, psi_norm[i, j], psio, psix)\n    return pfunc",
  "def speedy_pressure_mask(\n    ii: np.ndarray,\n    jj: np.ndarray,\n    psi_norm: np.ndarray,\n    psio: float,\n    psix: float,\n    shape: Callable[[float], float],\n) -> np.ndarray:\n    \"\"\"\n    Calculate the pressure map on the psi_norm array without any masking because\n    the plasma is not clearly bounded.\n\n    Parameters\n    ----------\n    ii:\n        The i indices of the array to populate (dtype=int)\n    jj:\n        The j indices of the array to populate (dtype=int)\n    psi_norm:\n        The normalised poloidal magnetic flux array\n    psio:\n        The psi value at the centre of the plasma (O-point)\n    psix:\n        The psi value at the edge of the plasma (X-point)\n    shape:\n        The shape function to use when calculating the pressure at each point\n\n    Returns\n    -------\n    The pressure on the grid\n    \"\"\"\n    nx, nz = psi_norm.shape\n    pfunc = np.zeros((nx, nz))\n    for i, j in zip(ii, jj):\n        pfunc[i, j] = pshape(shape, psi_norm[i, j], psio, psix)\n    return pfunc",
  "def laopoly(x: float, *args) -> float:\n    \"\"\"\n    Polynomial shape function defined in Lao 1985\n        https://iopscience.iop.org/article/10.1088/0029-5515/25/11/007/pdf \\n\n    \\t:math:`g(x)=\\\\sum_{n=0}^{n_F} \\\\alpha_{n}x^{n}-`\n    \\t:math:`x^{n_F+1}\\\\sum_{n=0}^{n_F} \\\\alpha_{n}`\n    \"\"\"\n    res = np.zeros_like(x)\n    for i in range(len(args)):\n        res += args[i] * x ** int(i)\n    res -= sum(args) * x ** (len(args) + 1)\n    return res",
  "def luxonexp(x: float, *args) -> float:\n    \"\"\"\n    Exponential shape function defined in Luxon 1984\n        https://iopscience.iop.org/article/10.1088/0029-5515/22/6/009/meta\n    \\t:math:`g(x)=\\\\text{exp}\\\\big(-\\\\alpha^2x^2\\\\big)`\n    \"\"\"\n    alpha = args[0]\n    return np.exp(-(x**2) * alpha**2)",
  "class ShapeFunction:\n    \"\"\"\n    Shape function object\n    \"\"\"\n\n    @classmethod\n    def from_datafit(cls, data: np.ndarray, order: Optional[int] = None):\n        \"\"\"\n        Defines function from a dataset, fit using scipy curve_fit\n        \"\"\"\n        if order is None:\n            order = cls._order\n        # Normalise data here\n        data /= max(data)\n        coeffs = fitfunc(cls._dfunc, data, order=order)\n        cls.data = data\n        return cls(coeffs)\n\n    def _func(self, x: float) -> float:\n        return self._dfunc(x, *self.coeffs)\n\n    def __call__(self, x: float) -> float:\n        \"\"\"\n        Calculate the value of the ShapeFunction for given x.\n        \"\"\"\n        return self._fact * self._func(x)\n\n    def adjust_parameters(self, coeffs: np.ndarray):\n        \"\"\"\n        Adjust the coefficients of the ShapeFunction\n        \"\"\"\n        self.coeffs = coeffs\n\n    def plot(self):\n        \"\"\"\n        Plot the ShapeFunction\n        \"\"\"\n        f, ax = plt.subplots()\n        x = np.linspace(0, 1)\n        ax.plot(x, self(x), label=\"Shape function - fitted\")\n        if hasattr(self, \"data\"):\n            xd = np.linspace(0, 1, len(self.data))\n            ax.plot(xd, self.data, label=\"Shape function - actual\")\n        ax.legend()\n        f.show()\n\n    def __mul__(self, a: float):\n        \"\"\"\n        Multiply the ShapeFunction (adjust factor)\n        \"\"\"\n        self._fact = a\n        return self\n\n    def __rmul__(self, a: float):\n        \"\"\"\n        Multiply the ShapeFunction (adjust factor)\n        \"\"\"\n        self._fact = a\n        return self",
  "class SinglePowerFunc(ShapeFunction):\n    \"\"\"\n    Function object for a single power profile\n    \"\"\"\n\n    _order = 1\n    _fact = 1\n\n    def __init__(self, args):\n        if len(args) != self._order:\n            raise ValueError(f\"Function coefficients {len(args)} != {self._order}\")\n        self.coeffs = args\n\n    @staticmethod\n    def _dfunc(x: float, *args) -> float:\n        return singlepowerfunc(x, *args)",
  "class DoublePowerFunc(ShapeFunction):\n    \"\"\"\n    Function object for a double power profile\n    \"\"\"\n\n    _order = 2\n    _fact = 1\n\n    def __init__(self, args):\n        if len(args) != self._order:\n            raise ValueError(f\"Function coefficients {len(args)} != {self._order}\")\n        self.coeffs = args\n\n    @staticmethod\n    def _dfunc(x: float, *args) -> float:\n        return doublepowerfunc(x, *args)",
  "class LaoPolynomialFunc(ShapeFunction):\n    \"\"\"\n    Function object for a Lao polynomial profile\n    \"\"\"\n\n    _fact = 1\n    _order = 3\n\n    def __init__(self, coeffs: Union[float, np.ndarray]):\n        if not hasattr(coeffs, \"__len__\"):\n            self.n = 0\n        self.n = len(coeffs) - 1\n        self.coeffs = coeffs\n\n    @staticmethod\n    def _dfunc(x: float, *args) -> float:\n        return laopoly(x, *args)",
  "class LuxonExpFunc(ShapeFunction):\n    \"\"\"\n    Function object for a Luxon exponential profile\n    \"\"\"\n\n    _fact = 1\n    _order = 1\n\n    def __init__(self, coeffs: Union[float, np.ndarray]):\n        if not hasattr(coeffs, \"__len__\"):\n            self.n = 1\n            self.coeffs = [coeffs]\n        else:\n            raise ValueError(\"The Luxon function only has one coefficient.\")\n\n    @staticmethod\n    def _dfunc(x: float, *args) -> float:\n        return luxonexp(x, *args)",
  "class Profile:\n    \"\"\"\n    Profile base class\n\n    following some implementation in B. Dudson, FreeGS:\n        https://github.com/bendudson/freegs\n    \"\"\"\n\n    def _scalar_denorm(self, prime, norm):\n        \"\"\"\n        Convert from integral in psi_norm to integral in psi\n        \"\"\"\n        val = quad(prime, norm, 1)[0]\n        return val * (self.psiax - self.psisep)\n\n    @staticmethod\n    def _reshape(psinorm):\n        \"\"\"\n        Reshaping and array dimensioning utility\n        \"\"\"\n        out = np.zeros_like(psinorm)\n        p_vals = np.reshape(psinorm, -1)\n        o_vals = np.reshape(out, -1)\n        return p_vals, o_vals\n\n    def pressure(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Return p as a function of normalised psi by integrating pprime\n        \"\"\"\n        if not isinstance(psinorm, np.ndarray):\n            return self._scalar_denorm(self.pprime, psinorm)\n\n        p_vals, o_vals = self._reshape(psinorm)\n        for i in range(len(p_vals)):\n            o_vals[i] = self._scalar_denorm(self.pprime, p_vals[i])\n        return np.reshape(o_vals, psinorm.shape)\n\n    def fRBpol(\n        self, psinorm: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:  # noqa :N802\n        \"\"\"\n        Return f as a function of normalised psi\n\n        \\t:math:`FF^{'} = \\\\dfrac{1}{2}\\\\dfrac{F^{2}}{d\\\\psi}`\n\n        Apply a boundary condition:\n            \\t:math:`FF^{'}|_{\\\\substack{\\\\psi_{N}=1}} = (R_{0}B_{T,0})^{2}`\n        \"\"\"\n        fvacuum = self.fvac()\n        if not isinstance(psinorm, np.ndarray):\n            val = self._scalar_denorm(self.ffprime, psinorm)\n            return np.sqrt(2 * val + fvacuum**2)\n\n        p_vals, o_vals = self._reshape(psinorm)\n\n        for i in range(len(p_vals)):\n            val = self._scalar_denorm(self.ffprime, p_vals[i])\n            o_vals[i] = np.sqrt(2 * val + fvacuum**2)\n        return np.reshape(o_vals, psinorm.shape)\n\n    @staticmethod\n    def _jtor(\n        x: np.ndarray,\n        z: np.ndarray,\n        psi: np.ndarray,\n        o_points: List[Opoint],\n        x_points: List[Xpoint],\n    ) -> Tuple[float, float, np.ndarray]:\n        \"\"\"\n        Do-not-repeat-yourself utility\n\n        Parameters\n        ----------\n        x:\n            The grid of x coordinates\n        z:\n            The grid of z coordinates\n        psi:\n            The psi array\n        o_points:\n            The list of O-points\n        x_points:\n            The list of X-points\n\n        Returns\n        -------\n        psix:\n            The plasma separatrix psi\n        psio:\n            The plasma central psi\n        mask:\n            The numpy array of 0/1 denoting the out/in points of the plasma in\n            the grid\n        \"\"\"\n        if not o_points:\n            f, ax = plt.subplots()\n            ax.contour(x, z, psi, cmap=\"viridis\")\n            # TODO: Handle this better, with perhaps some alternatives\n            # e.g.\n            # nx, nz = psi.shape\n            # psio = psi[nx//2, nz//2]\n            raise EquilibriaError(\"No O-points found!\")\n        else:\n            psio = o_points[0][2]\n        if x_points:\n            psix = x_points[0][2]\n            mask = in_plasma(x, z, psi, o_points, x_points)\n        else:\n            psix = psi[0, 0]\n            mask = None\n        return psix, psio, mask\n\n    def fvac(self) -> float:\n        \"\"\"\n        Vacuum field function handle\n        \"\"\"\n        try:\n            return self._fvac\n        except AttributeError:\n            raise NotImplementedError(\"Please specify ._fvac as vacuum R*B.\")\n\n    def int2d(self, func2d: np.ndarray) -> float:\n        \"\"\"\n        Returns the integral of a 2-D function map (numpy 2-D array) over the\n        domain space (X, Z)\n        \"\"\"\n        return integrate_dx_dz(func2d, self.dx, self.dz)\n\n    def plot(self, ax=None):\n        \"\"\"\n        Plot the Profile object\n        \"\"\"\n        return ProfilePlotter(self, ax=ax)",
  "class BetaIpProfile(Profile):\n    \"\"\"\n    Constrain poloidal Beta and plasma current following logic as laid out in\n    Jeon, 2015: https://link.springer.com/article/10.3938/jkps.67.843 and\n    following some implementation in B. Dudson, FreeGS:\n    https://github.com/bendudson/freegs\n\n    Parameters\n    ----------\n    betap:\n        Plasma poloidal beta constraint\n    I_p:\n        Plasma current constraint [A]\n    R_0:\n        Reactor major radius [m] (used in p' and ff' components)\n    B_0:\n        Toroidal field at reactor major radius [T]\n    shape:\n        Shape parameterisation to use\n\n    Notes\n    -----\n    \\t:math:`J_{\\\\phi} = {\\\\lambda}\\\\bigg({\\\\beta}_{0}\\\\dfrac{X}{R_{0}}+`\n    \\t:math:`(1-\\\\beta_{0})\\\\dfrac{R_{0}}{X}\\\\bigg)j_{\\\\phi_{shape}}(m, n, ..)`\n\n    \\t:math:`I_{p}=\\\\int_{{\\\\Omega}_{pl}} J_{{\\\\phi},pl}({\\\\lambda},{\\\\beta_{0}})`\n    \\t:math:`d{\\\\Omega}`\\n\n\n    \\t:math:`{\\\\beta}_{p}=\\\\dfrac{\\\\langle p({\\\\beta_{0}})\\\\rangle}{\\\\langle B_{p}^{2}\\\\rangle_{\\\\psi_{a}}/2\\\\mu_{0}}`\n    \"\"\"  # noqa :W505\n\n    # NOTE: For high betap >= 2, this can lead to there being no plasma current\n    # on the high field side...\n    def __init__(\n        self,\n        betap: float,\n        I_p: float,\n        R_0: float,\n        B_0: float,\n        shape: Optional[ShapeFunction] = None,\n    ):\n        self.betap = betap\n        self.I_p = I_p\n        self._fvac = R_0 * B_0\n        self.R_0 = R_0\n        self._B_0 = B_0  # Store for eqdsk only\n        self.scale = 1.0\n\n        if shape is None:\n            self.shape = DoublePowerFunc([1, 0.8])\n        else:\n            self.shape = shape\n        if I_p < 0:  # Reverse I_p\n            self.shape *= -1\n\n    def jtor(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        psi: np.ndarray,\n        o_points: List[Opoint],\n        x_points: List[Xpoint],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate toroidal plasma current array.\n\n        \\t:math:`I_{p} =\\\\int\\\\int {\\\\lambda}\\\\bigg({\\\\beta}_{0}\\\\dfrac{X}{R_{0}}j_{\\\\phi_{shape}}+`\n        \\t:math:`(1-\\\\beta_{0})\\\\dfrac{R_{0}}{X}j_{\\\\phi_{shape}}\\\\bigg)`\n\n        \\t:math:`{\\\\beta}_{p}=\\\\dfrac{8\\\\pi}{{\\\\mu}_{0}{I_{p}^{2}}}\\\\int\\\\int pdXdZ`\n        \\t:math:`= -\\\\dfrac{8\\\\pi}{{\\\\mu}_{0}{I_{p}^{2}}}\\\\dfrac{\\\\lambda{\\\\beta}_{0}}{R_{0}}\\\\int\\\\int p_{shape}dXdZ`\n\n        \\t:math:`p(\\\\psi_{N})=-\\\\dfrac{\\\\lambda\\\\beta_{0}}{R_{0}}p_{shape}(\\\\psi_{N})`\n\n        \\t:math:`\\\\lambda{\\\\beta_{0}}=-\\\\dfrac{\\\\beta_{p}I_{p}^{2}R_{0}\\\\mu_{0}}{8\\\\pi \\\\int\\\\int p_{shape}}`\n\n        \\t:math:`\\\\lambda=\\\\dfrac{I_{p}-\\\\lambda{\\\\beta_{0}}\\\\bigg(\\\\int\\\\int\\\\dfrac{X}{R_{0}}f+\\\\int\\\\int\\\\dfrac{R_{0}}{X}f\\\\bigg)}{\\\\int\\\\int\\\\dfrac{R_{0}}{X}f}`\n\n        Derivation: book 10, p 120\n        \"\"\"  # noqa :W505\n        self.dx = x[1, 0] - x[0, 0]\n        self.dz = z[0, 1] - z[0, 0]\n        psix, psio, mask = self._jtor(x, z, psi, o_points, x_points)\n        psi_norm = (psi - psio) / (psix - psio)\n        self.psisep = psix\n        self.psiax = psio\n        jtorshape = self.shape(psi_norm)\n\n        # Calculate pressure function in plasma including separatrix masking\n        if mask is None:\n            pfunc = speedy_pressure(psi_norm, psio, psix, self.shape)\n        else:\n            ii, jj = np.where(mask != 0)\n            jtorshape *= mask\n            pfunc = speedy_pressure_mask(\n                iter(ii), iter(jj), psi_norm, psio, psix, self.shape\n            )\n\n        if x_points != []:  # NOTE: Necessary unpythonic formulation\n            # More accurate beta_p constraint calculation\n            # This is the Freidberg approximation\n            lcfs, _ = find_LCFS_separatrix(\n                x, z, psi, o_points=o_points, x_points=x_points\n            )\n            v_plasma = revolved_volume(*lcfs.xz)\n            Bp = MU_0 * self.I_p / lcfs.length\n            p_avg = volume_integral(pfunc, x, self.dx, self.dz) / v_plasma\n            beta_p_actual = 2 * MU_0 * p_avg / Bp**2\n\n            lambd_beta0 = -self.betap / beta_p_actual * self.R_0\n\n        else:\n            # If there are no X-points, use less accurate beta_p constraint\n            lambd_beta0 = (\n                -self.betap\n                * self.I_p**2\n                * self.R_0\n                * MU_0\n                / (8 * np.pi)\n                / self.int2d(pfunc)\n            )\n\n        part_a = self.int2d(jtorshape * x / self.R_0)\n        part_b = self.int2d(jtorshape * self.R_0 / x)\n        lambd = (self.I_p + lambd_beta0 * (part_b - part_a)) / part_b\n        beta0 = lambd_beta0 / lambd\n        jtor = lambd * (beta0 * x / self.R_0 + (1 - beta0) * self.R_0 / x) * jtorshape\n        self.lambd = lambd\n        self.beta0 = beta0\n        return jtor\n\n    def pprime(self, pn: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        dp/dpsi as a function of normalised psi\n        \"\"\"\n        return self.lambd * self.beta0 / self.R_0 * self.shape(pn)\n\n    def ffprime(self, pn: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        f*df/dpsi as a function of normalised psi\n        \"\"\"\n        return MU_0 * self.lambd * (1 - self.beta0) * self.R_0 * self.shape(pn)",
  "class BetaLiIpProfile(BetaIpProfile):\n    \"\"\"\n    Profile is what BLUEPRINT used to do, and Fabrizio told me he had done\n    something similar in MIRA, at one point.\n\n    Parameters\n    ----------\n    betap:\n        Plasma poloidal beta constraint\n    l_i:\n        Normalised internal inductance constraint\n    I_p:\n        Plasma current constraint [Amps]\n    R_0:\n        Reactor major radius [m] (used in p' and ff' components)\n    B_0:\n        Toroidal field [T]\n    shape:\n        The shape function to use for the flux functions\n    li_rel_tol:\n        Absolute relative tolerance for the internal inductance constraint\n    li_min_iter:\n        Iteration at which the profile optimisation should start to be\n        carried out. Usually best not to start solving the equilibrium\n        with the profile constraint, and fold it in later, when the plasma\n        shape is more representative.\n    \"\"\"\n\n    def __init__(\n        self,\n        betap: float,\n        l_i: float,\n        I_p: float,\n        R_0: float,\n        B_0: float,\n        shape: Optional[ShapeFunction] = None,\n        li_rel_tol: float = 0.015,\n        li_min_iter: int = 5,\n    ):\n        super().__init__(betap, I_p, R_0, B_0, shape=shape)\n        self._l_i_target = l_i\n        self._l_i_rel_tol = li_rel_tol\n        self._l_i_min_iter = li_min_iter",
  "class CustomProfile(Profile):\n    \"\"\"\n    User-specified profile functions p'(psi), ff'(psi)\n    jtor = R*p' + ff'/(R*MU_0)\n\n    Parameters\n    ----------\n    pprime_func:\n        Pressure prime profile - dp/dpsi(psi_N)\n    ffprime_func:\n        Force-Force prime profile f*df/dpsi(psi_N)\n    R_0:\n        Reactor major radius [m]\n    B_0:\n        Field at major radius [T]\n    I_p:\n        Plasma current [A]. If None, the plasma current will be calculated\n        from p' and ff'.\n    \"\"\"\n\n    def __init__(\n        self,\n        pprime_func: Union[np.ndarray, Callable[[float]], float],\n        ffprime_func: Union[np.ndarray, Callable[[float]], float],\n        R_0: float,\n        B_0: float,\n        p_func: Optional[Union[np.ndarray, Callable[[float]], float]] = None,\n        f_func: Optional[Union[np.ndarray, Callable[[float]], float]] = None,\n        I_p: Optional[float] = None,\n    ):\n        self._pprime_in = self.parse_to_callable(pprime_func)\n        self._ffprime_in = self.parse_to_callable(ffprime_func)\n        self.p_func = self.parse_to_callable(p_func)\n        self.f_func = self.parse_to_callable(f_func)\n        self._fvac = R_0 * B_0\n        self.R_0 = R_0\n        self._B_0 = B_0\n        self.I_p = I_p\n        self.scale = 1.0\n\n        # Fit a shape function to the pprime profile (mostly for plotting)\n        x = np.linspace(0, 1, 50)\n        self.shape = LaoPolynomialFunc.from_datafit(self.pprime(x))\n\n    @staticmethod\n    def parse_to_callable(unknown):\n        \"\"\"\n        Make a callable out of an unknown input type\n        \"\"\"\n        if callable(unknown):\n            return unknown\n        elif isinstance(unknown, np.ndarray):\n            return interp1d(np.linspace(0, 1, len(unknown)), unknown)\n        elif unknown is None:\n            return None\n        else:\n            raise TypeError(\"Could not make input object a callable function.\")\n\n    def pprime(self, pn: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        dp/dpsi as a function of normalised psi\n        \"\"\"\n        return abs(self.scale) * self._pprime_in(pn)\n\n    def ffprime(self, pn: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        f*df/dpsi as a function of normalised psi\n        \"\"\"\n        return abs(self.scale) * self._ffprime_in(pn)\n\n    def jtor(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        psi: np.ndarray,\n        o_points: List[Opoint],\n        x_points: List[Xpoint],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate toroidal plasma current\n\n        \\t:math:`J_{\\\\phi}=Xp^{'}+\\\\dfrac{FF^{'}}{\\\\mu_{0}X}`\n        \"\"\"\n        self.dx = x[1, 0] - x[0, 0]\n        self.dz = z[0, 1] - z[0, 0]\n        psisep, psiax, mask = self._jtor(x, z, psi, o_points, x_points)\n        self.psisep = psisep\n        self.psiax = psiax\n        psi_norm = np.clip((psi - psiax) / (psisep - psiax), 0, 1)\n        jtor = x * self._pprime_in(psi_norm) + self._ffprime_in(psi_norm) / (x * MU_0)\n        if mask is not None:\n            jtor *= mask\n        if self.I_p is not None:\n            # This is a simple way to prescribe the plasma current\n            I_p = self.int2d(jtor)\n            if I_p != 0.0:\n                self.scale = self.I_p / I_p\n                jtor *= self.scale\n        return jtor\n\n    def pressure(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Return pressure [Pa] at given value(s) of normalised psi\n        \"\"\"\n        if self.p_func is not None:\n            return abs(self.scale) * self.p_func(psinorm)\n        return super().pressure(psinorm)\n\n    def fRBpol(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Return f=R*Bt at given value(s) of normalised psi\n        \"\"\"\n        if self.f_func is not None:\n            return abs(self.scale) * self.f_func(psinorm)\n        return super().fRBpol(psinorm)\n\n    @classmethod\n    def from_eqdsk(cls, filename: str):\n        \"\"\"\n        Initialises a CustomProfile object from an eqdsk file\n        \"\"\"\n        e = EQDSKInterface.from_file(filename)\n        return cls(\n            e.pprime,\n            e.ffprime,\n            R_0=e.xcentre,\n            B_0=abs(e.bcentre),\n            p_func=e.pressure,\n            f_func=e.fpol,\n            I_p=abs(e.cplasma),\n        )",
  "def from_datafit(cls, data: np.ndarray, order: Optional[int] = None):\n        \"\"\"\n        Defines function from a dataset, fit using scipy curve_fit\n        \"\"\"\n        if order is None:\n            order = cls._order\n        # Normalise data here\n        data /= max(data)\n        coeffs = fitfunc(cls._dfunc, data, order=order)\n        cls.data = data\n        return cls(coeffs)",
  "def _func(self, x: float) -> float:\n        return self._dfunc(x, *self.coeffs)",
  "def __call__(self, x: float) -> float:\n        \"\"\"\n        Calculate the value of the ShapeFunction for given x.\n        \"\"\"\n        return self._fact * self._func(x)",
  "def adjust_parameters(self, coeffs: np.ndarray):\n        \"\"\"\n        Adjust the coefficients of the ShapeFunction\n        \"\"\"\n        self.coeffs = coeffs",
  "def plot(self):\n        \"\"\"\n        Plot the ShapeFunction\n        \"\"\"\n        f, ax = plt.subplots()\n        x = np.linspace(0, 1)\n        ax.plot(x, self(x), label=\"Shape function - fitted\")\n        if hasattr(self, \"data\"):\n            xd = np.linspace(0, 1, len(self.data))\n            ax.plot(xd, self.data, label=\"Shape function - actual\")\n        ax.legend()\n        f.show()",
  "def __mul__(self, a: float):\n        \"\"\"\n        Multiply the ShapeFunction (adjust factor)\n        \"\"\"\n        self._fact = a\n        return self",
  "def __rmul__(self, a: float):\n        \"\"\"\n        Multiply the ShapeFunction (adjust factor)\n        \"\"\"\n        self._fact = a\n        return self",
  "def __init__(self, args):\n        if len(args) != self._order:\n            raise ValueError(f\"Function coefficients {len(args)} != {self._order}\")\n        self.coeffs = args",
  "def _dfunc(x: float, *args) -> float:\n        return singlepowerfunc(x, *args)",
  "def __init__(self, args):\n        if len(args) != self._order:\n            raise ValueError(f\"Function coefficients {len(args)} != {self._order}\")\n        self.coeffs = args",
  "def _dfunc(x: float, *args) -> float:\n        return doublepowerfunc(x, *args)",
  "def __init__(self, coeffs: Union[float, np.ndarray]):\n        if not hasattr(coeffs, \"__len__\"):\n            self.n = 0\n        self.n = len(coeffs) - 1\n        self.coeffs = coeffs",
  "def _dfunc(x: float, *args) -> float:\n        return laopoly(x, *args)",
  "def __init__(self, coeffs: Union[float, np.ndarray]):\n        if not hasattr(coeffs, \"__len__\"):\n            self.n = 1\n            self.coeffs = [coeffs]\n        else:\n            raise ValueError(\"The Luxon function only has one coefficient.\")",
  "def _dfunc(x: float, *args) -> float:\n        return luxonexp(x, *args)",
  "def _scalar_denorm(self, prime, norm):\n        \"\"\"\n        Convert from integral in psi_norm to integral in psi\n        \"\"\"\n        val = quad(prime, norm, 1)[0]\n        return val * (self.psiax - self.psisep)",
  "def _reshape(psinorm):\n        \"\"\"\n        Reshaping and array dimensioning utility\n        \"\"\"\n        out = np.zeros_like(psinorm)\n        p_vals = np.reshape(psinorm, -1)\n        o_vals = np.reshape(out, -1)\n        return p_vals, o_vals",
  "def pressure(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Return p as a function of normalised psi by integrating pprime\n        \"\"\"\n        if not isinstance(psinorm, np.ndarray):\n            return self._scalar_denorm(self.pprime, psinorm)\n\n        p_vals, o_vals = self._reshape(psinorm)\n        for i in range(len(p_vals)):\n            o_vals[i] = self._scalar_denorm(self.pprime, p_vals[i])\n        return np.reshape(o_vals, psinorm.shape)",
  "def fRBpol(\n        self, psinorm: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:  # noqa :N802\n        \"\"\"\n        Return f as a function of normalised psi\n\n        \\t:math:`FF^{'} = \\\\dfrac{1}{2}\\\\dfrac{F^{2}}{d\\\\psi}`\n\n        Apply a boundary condition:\n            \\t:math:`FF^{'}|_{\\\\substack{\\\\psi_{N}=1}} = (R_{0}B_{T,0})^{2}`\n        \"\"\"\n        fvacuum = self.fvac()\n        if not isinstance(psinorm, np.ndarray):\n            val = self._scalar_denorm(self.ffprime, psinorm)\n            return np.sqrt(2 * val + fvacuum**2)\n\n        p_vals, o_vals = self._reshape(psinorm)\n\n        for i in range(len(p_vals)):\n            val = self._scalar_denorm(self.ffprime, p_vals[i])\n            o_vals[i] = np.sqrt(2 * val + fvacuum**2)\n        return np.reshape(o_vals, psinorm.shape)",
  "def _jtor(\n        x: np.ndarray,\n        z: np.ndarray,\n        psi: np.ndarray,\n        o_points: List[Opoint],\n        x_points: List[Xpoint],\n    ) -> Tuple[float, float, np.ndarray]:\n        \"\"\"\n        Do-not-repeat-yourself utility\n\n        Parameters\n        ----------\n        x:\n            The grid of x coordinates\n        z:\n            The grid of z coordinates\n        psi:\n            The psi array\n        o_points:\n            The list of O-points\n        x_points:\n            The list of X-points\n\n        Returns\n        -------\n        psix:\n            The plasma separatrix psi\n        psio:\n            The plasma central psi\n        mask:\n            The numpy array of 0/1 denoting the out/in points of the plasma in\n            the grid\n        \"\"\"\n        if not o_points:\n            f, ax = plt.subplots()\n            ax.contour(x, z, psi, cmap=\"viridis\")\n            # TODO: Handle this better, with perhaps some alternatives\n            # e.g.\n            # nx, nz = psi.shape\n            # psio = psi[nx//2, nz//2]\n            raise EquilibriaError(\"No O-points found!\")\n        else:\n            psio = o_points[0][2]\n        if x_points:\n            psix = x_points[0][2]\n            mask = in_plasma(x, z, psi, o_points, x_points)\n        else:\n            psix = psi[0, 0]\n            mask = None\n        return psix, psio, mask",
  "def fvac(self) -> float:\n        \"\"\"\n        Vacuum field function handle\n        \"\"\"\n        try:\n            return self._fvac\n        except AttributeError:\n            raise NotImplementedError(\"Please specify ._fvac as vacuum R*B.\")",
  "def int2d(self, func2d: np.ndarray) -> float:\n        \"\"\"\n        Returns the integral of a 2-D function map (numpy 2-D array) over the\n        domain space (X, Z)\n        \"\"\"\n        return integrate_dx_dz(func2d, self.dx, self.dz)",
  "def plot(self, ax=None):\n        \"\"\"\n        Plot the Profile object\n        \"\"\"\n        return ProfilePlotter(self, ax=ax)",
  "def __init__(\n        self,\n        betap: float,\n        I_p: float,\n        R_0: float,\n        B_0: float,\n        shape: Optional[ShapeFunction] = None,\n    ):\n        self.betap = betap\n        self.I_p = I_p\n        self._fvac = R_0 * B_0\n        self.R_0 = R_0\n        self._B_0 = B_0  # Store for eqdsk only\n        self.scale = 1.0\n\n        if shape is None:\n            self.shape = DoublePowerFunc([1, 0.8])\n        else:\n            self.shape = shape\n        if I_p < 0:  # Reverse I_p\n            self.shape *= -1",
  "def jtor(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        psi: np.ndarray,\n        o_points: List[Opoint],\n        x_points: List[Xpoint],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate toroidal plasma current array.\n\n        \\t:math:`I_{p} =\\\\int\\\\int {\\\\lambda}\\\\bigg({\\\\beta}_{0}\\\\dfrac{X}{R_{0}}j_{\\\\phi_{shape}}+`\n        \\t:math:`(1-\\\\beta_{0})\\\\dfrac{R_{0}}{X}j_{\\\\phi_{shape}}\\\\bigg)`\n\n        \\t:math:`{\\\\beta}_{p}=\\\\dfrac{8\\\\pi}{{\\\\mu}_{0}{I_{p}^{2}}}\\\\int\\\\int pdXdZ`\n        \\t:math:`= -\\\\dfrac{8\\\\pi}{{\\\\mu}_{0}{I_{p}^{2}}}\\\\dfrac{\\\\lambda{\\\\beta}_{0}}{R_{0}}\\\\int\\\\int p_{shape}dXdZ`\n\n        \\t:math:`p(\\\\psi_{N})=-\\\\dfrac{\\\\lambda\\\\beta_{0}}{R_{0}}p_{shape}(\\\\psi_{N})`\n\n        \\t:math:`\\\\lambda{\\\\beta_{0}}=-\\\\dfrac{\\\\beta_{p}I_{p}^{2}R_{0}\\\\mu_{0}}{8\\\\pi \\\\int\\\\int p_{shape}}`\n\n        \\t:math:`\\\\lambda=\\\\dfrac{I_{p}-\\\\lambda{\\\\beta_{0}}\\\\bigg(\\\\int\\\\int\\\\dfrac{X}{R_{0}}f+\\\\int\\\\int\\\\dfrac{R_{0}}{X}f\\\\bigg)}{\\\\int\\\\int\\\\dfrac{R_{0}}{X}f}`\n\n        Derivation: book 10, p 120\n        \"\"\"  # noqa :W505\n        self.dx = x[1, 0] - x[0, 0]\n        self.dz = z[0, 1] - z[0, 0]\n        psix, psio, mask = self._jtor(x, z, psi, o_points, x_points)\n        psi_norm = (psi - psio) / (psix - psio)\n        self.psisep = psix\n        self.psiax = psio\n        jtorshape = self.shape(psi_norm)\n\n        # Calculate pressure function in plasma including separatrix masking\n        if mask is None:\n            pfunc = speedy_pressure(psi_norm, psio, psix, self.shape)\n        else:\n            ii, jj = np.where(mask != 0)\n            jtorshape *= mask\n            pfunc = speedy_pressure_mask(\n                iter(ii), iter(jj), psi_norm, psio, psix, self.shape\n            )\n\n        if x_points != []:  # NOTE: Necessary unpythonic formulation\n            # More accurate beta_p constraint calculation\n            # This is the Freidberg approximation\n            lcfs, _ = find_LCFS_separatrix(\n                x, z, psi, o_points=o_points, x_points=x_points\n            )\n            v_plasma = revolved_volume(*lcfs.xz)\n            Bp = MU_0 * self.I_p / lcfs.length\n            p_avg = volume_integral(pfunc, x, self.dx, self.dz) / v_plasma\n            beta_p_actual = 2 * MU_0 * p_avg / Bp**2\n\n            lambd_beta0 = -self.betap / beta_p_actual * self.R_0\n\n        else:\n            # If there are no X-points, use less accurate beta_p constraint\n            lambd_beta0 = (\n                -self.betap\n                * self.I_p**2\n                * self.R_0\n                * MU_0\n                / (8 * np.pi)\n                / self.int2d(pfunc)\n            )\n\n        part_a = self.int2d(jtorshape * x / self.R_0)\n        part_b = self.int2d(jtorshape * self.R_0 / x)\n        lambd = (self.I_p + lambd_beta0 * (part_b - part_a)) / part_b\n        beta0 = lambd_beta0 / lambd\n        jtor = lambd * (beta0 * x / self.R_0 + (1 - beta0) * self.R_0 / x) * jtorshape\n        self.lambd = lambd\n        self.beta0 = beta0\n        return jtor",
  "def pprime(self, pn: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        dp/dpsi as a function of normalised psi\n        \"\"\"\n        return self.lambd * self.beta0 / self.R_0 * self.shape(pn)",
  "def ffprime(self, pn: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        f*df/dpsi as a function of normalised psi\n        \"\"\"\n        return MU_0 * self.lambd * (1 - self.beta0) * self.R_0 * self.shape(pn)",
  "def __init__(\n        self,\n        betap: float,\n        l_i: float,\n        I_p: float,\n        R_0: float,\n        B_0: float,\n        shape: Optional[ShapeFunction] = None,\n        li_rel_tol: float = 0.015,\n        li_min_iter: int = 5,\n    ):\n        super().__init__(betap, I_p, R_0, B_0, shape=shape)\n        self._l_i_target = l_i\n        self._l_i_rel_tol = li_rel_tol\n        self._l_i_min_iter = li_min_iter",
  "def __init__(\n        self,\n        pprime_func: Union[np.ndarray, Callable[[float]], float],\n        ffprime_func: Union[np.ndarray, Callable[[float]], float],\n        R_0: float,\n        B_0: float,\n        p_func: Optional[Union[np.ndarray, Callable[[float]], float]] = None,\n        f_func: Optional[Union[np.ndarray, Callable[[float]], float]] = None,\n        I_p: Optional[float] = None,\n    ):\n        self._pprime_in = self.parse_to_callable(pprime_func)\n        self._ffprime_in = self.parse_to_callable(ffprime_func)\n        self.p_func = self.parse_to_callable(p_func)\n        self.f_func = self.parse_to_callable(f_func)\n        self._fvac = R_0 * B_0\n        self.R_0 = R_0\n        self._B_0 = B_0\n        self.I_p = I_p\n        self.scale = 1.0\n\n        # Fit a shape function to the pprime profile (mostly for plotting)\n        x = np.linspace(0, 1, 50)\n        self.shape = LaoPolynomialFunc.from_datafit(self.pprime(x))",
  "def parse_to_callable(unknown):\n        \"\"\"\n        Make a callable out of an unknown input type\n        \"\"\"\n        if callable(unknown):\n            return unknown\n        elif isinstance(unknown, np.ndarray):\n            return interp1d(np.linspace(0, 1, len(unknown)), unknown)\n        elif unknown is None:\n            return None\n        else:\n            raise TypeError(\"Could not make input object a callable function.\")",
  "def pprime(self, pn: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        dp/dpsi as a function of normalised psi\n        \"\"\"\n        return abs(self.scale) * self._pprime_in(pn)",
  "def ffprime(self, pn: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        f*df/dpsi as a function of normalised psi\n        \"\"\"\n        return abs(self.scale) * self._ffprime_in(pn)",
  "def jtor(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        psi: np.ndarray,\n        o_points: List[Opoint],\n        x_points: List[Xpoint],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate toroidal plasma current\n\n        \\t:math:`J_{\\\\phi}=Xp^{'}+\\\\dfrac{FF^{'}}{\\\\mu_{0}X}`\n        \"\"\"\n        self.dx = x[1, 0] - x[0, 0]\n        self.dz = z[0, 1] - z[0, 0]\n        psisep, psiax, mask = self._jtor(x, z, psi, o_points, x_points)\n        self.psisep = psisep\n        self.psiax = psiax\n        psi_norm = np.clip((psi - psiax) / (psisep - psiax), 0, 1)\n        jtor = x * self._pprime_in(psi_norm) + self._ffprime_in(psi_norm) / (x * MU_0)\n        if mask is not None:\n            jtor *= mask\n        if self.I_p is not None:\n            # This is a simple way to prescribe the plasma current\n            I_p = self.int2d(jtor)\n            if I_p != 0.0:\n                self.scale = self.I_p / I_p\n                jtor *= self.scale\n        return jtor",
  "def pressure(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Return pressure [Pa] at given value(s) of normalised psi\n        \"\"\"\n        if self.p_func is not None:\n            return abs(self.scale) * self.p_func(psinorm)\n        return super().pressure(psinorm)",
  "def fRBpol(self, psinorm: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n        \"\"\"\n        Return f=R*Bt at given value(s) of normalised psi\n        \"\"\"\n        if self.f_func is not None:\n            return abs(self.scale) * self.f_func(psinorm)\n        return super().fRBpol(psinorm)",
  "def from_eqdsk(cls, filename: str):\n        \"\"\"\n        Initialises a CustomProfile object from an eqdsk file\n        \"\"\"\n        e = EQDSKInterface.from_file(filename)\n        return cls(\n            e.pprime,\n            e.ffprime,\n            R_0=e.xcentre,\n            B_0=abs(e.bcentre),\n            p_func=e.pressure,\n            f_func=e.fpol,\n            I_p=abs(e.cplasma),\n        )",
  "class ObjectiveFunction(abc.ABC):\n    \"\"\"\n    Base class for ObjectiveFunctions\n\n    Notes\n    -----\n    Optionally the function 'df_objective' can be implemented on any child\n    classes to calculate the gradient of the objective function.\n    The function should take an `npt.NDArray` as its only argument and\n    return only an `npt.NDArray`.\n    If the `df_objective` function is not provided and the optimisation algorithm\n    is gradient based the approximate derivate is calculated.\n    \"\"\"\n\n    @abc.abstractmethod\n    def f_objective(self, vector: npt.NDArray) -> float:\n        \"\"\"Objective function for an optimisation.\"\"\"",
  "class RegularisedLsqObjective(ObjectiveFunction):\n    \"\"\"\n    Least-squares objective with Tikhonov regularisation term.\n\n    Parameters\n    ----------\n    scale:\n        Scaling factor for the vector\n    a_mat:\n        The 2-D a_mat control matrix A (n, m)\n    b_vec:\n        The 1-D b vector of target values (n)\n    gamma:\n        The Tikhonov regularisation parameter.\n    \"\"\"\n\n    def __init__(\n        self,\n        scale: float,\n        a_mat: npt.NDArray,\n        b_vec: npt.NDArray,\n        gamma: float,\n    ) -> None:\n        self.scale = scale\n        self.a_mat = a_mat\n        self.b_vec = b_vec\n        self.gamma = gamma\n\n    def f_objective(self, x: npt.NDArray) -> float:\n        \"\"\"Objective function for an optimisation.\"\"\"\n        x = x * self.scale\n        fom, _ = regularised_lsq_fom(x, self.a_mat, self.b_vec, self.gamma)\n        if fom <= 0:\n            raise EquilibriaError(\n                \"Optimiser least-squares objective function less than zero or nan.\"\n            )\n        return fom\n\n    def df_objective(self, x: npt.NDArray) -> npt.NDArray:\n        \"\"\"Gradient of the objective function for an optimisation.\"\"\"\n        x = x * self.scale\n        jac = 2 * self.a_mat.T @ self.a_mat @ x / float(len(self.b_vec))\n        jac -= 2 * self.a_mat.T @ self.b_vec / float(len(self.b_vec))\n        jac += 2 * self.gamma * self.gamma * x\n        return self.scale * jac",
  "class CoilCurrentsObjective(ObjectiveFunction):\n    \"\"\"Objective function for the minimisation of the sum of coil currents squared.\"\"\"\n\n    def f_objective(self, vector: npt.NDArray) -> float:\n        \"\"\"Objective function for an optimisation.\"\"\"\n        return np.sum(vector**2)\n\n    def df_objective(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Gradient of the objective function for an optimisation.\"\"\"\n        return 2 * vector",
  "class MaximiseFluxObjective(ObjectiveFunction):\n    \"\"\"\n    Objective function to maximise flux\n\n    Parameters\n    ----------\n    c_psi_mat:\n        Response matrix of the coil psi contributions to the point at which the flux\n        should be maximised\n    scale:\n        Scaling factor for the vector\n    \"\"\"\n\n    def __init__(self, c_psi_mat: npt.NDArray, scale: float):\n        self.c_psi_mat = c_psi_mat\n        self.scale = scale\n\n    def f_objective(self, vector: npt.NDArray) -> float:\n        \"\"\"Objective function for an optimisation.\"\"\"\n        return -self.scale * self.c_psi_mat @ vector\n\n    def df_objective(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Gradient of the objective function for an optimisation.\"\"\"\n        return -self.scale * self.c_psi_mat",
  "def tikhonov(a_mat: np.ndarray, b_vec: np.ndarray, gamma: float) -> np.ndarray:\n    \"\"\"\n    Tikhonov regularisation of Ax-b problem.\n\n    \\t:math:`\\\\textrm{minimise} || Ax - b ||^2 + ||{\\\\gamma} \\\\cdot x ||^2`\\n\n    \\t:math:`x = (A^T A + {\\\\gamma}^2 I)^{-1}A^T b`\n\n    Parameters\n    ----------\n    a_mat:\n        The 2-D A matrix of responses\n    b_vec:\n        The 1-D b vector of values\n    gamma: float\n        The Tikhonov regularisation parameter\n\n    Returns\n    -------\n    x:\n        The result vector\n    \"\"\"\n    try:\n        return np.dot(\n            np.linalg.inv(np.dot(a_mat.T, a_mat) + gamma**2 * np.eye(a_mat.shape[1])),\n            np.dot(a_mat.T, b_vec),\n        )\n    except np.linalg.LinAlgError:\n        bluemira_warn(\"Tikhonov singular matrix..!\")\n        return np.dot(\n            np.linalg.pinv(np.dot(a_mat.T, a_mat) + gamma**2 * np.eye(a_mat.shape[1])),\n            np.dot(a_mat.T, b_vec),\n        )",
  "def regularised_lsq_fom(\n    x: np.ndarray, a_mat: np.ndarray, b_vec: np.ndarray, gamma: float\n) -> Tuple[float, np.ndarray]:\n    \"\"\"\n    Figure of merit for the least squares problem Ax = b, with\n    Tikhonov regularisation term. Normalised for the number of\n    targets.\n\n    ||(Ax - b)||\u00b2/ len(b)] + ||\u0393x||\u00b2\n\n    Parameters\n    ----------\n    x :\n        The 1-D x state vector (m)\n    a_mat:\n        The 2-D a_mat control matrix A (n, m)\n    b_vec:\n        The 1-D b vector of target values (n)\n    gamma:\n        The Tikhonov regularisation parameter.\n\n    Returns\n    -------\n    fom:\n        Figure of merit, explicitly given by\n        ||(Ax - b)||\u00b2/ len(b)] + ||\u0393x||\u00b2\n    residual:\n        Residual vector (Ax - b)\n    \"\"\"\n    residual = np.dot(a_mat, x) - b_vec\n    number_of_targets = float(len(residual))\n    fom = residual.T @ residual / number_of_targets + gamma * gamma * x.T @ x\n\n    if fom <= 0:\n        raise EquilibriaError(\"Least-squares objective function less than zero or nan.\")\n    return fom, residual",
  "def f_objective(self, vector: npt.NDArray) -> float:\n        \"\"\"Objective function for an optimisation.\"\"\"",
  "def __init__(\n        self,\n        scale: float,\n        a_mat: npt.NDArray,\n        b_vec: npt.NDArray,\n        gamma: float,\n    ) -> None:\n        self.scale = scale\n        self.a_mat = a_mat\n        self.b_vec = b_vec\n        self.gamma = gamma",
  "def f_objective(self, x: npt.NDArray) -> float:\n        \"\"\"Objective function for an optimisation.\"\"\"\n        x = x * self.scale\n        fom, _ = regularised_lsq_fom(x, self.a_mat, self.b_vec, self.gamma)\n        if fom <= 0:\n            raise EquilibriaError(\n                \"Optimiser least-squares objective function less than zero or nan.\"\n            )\n        return fom",
  "def df_objective(self, x: npt.NDArray) -> npt.NDArray:\n        \"\"\"Gradient of the objective function for an optimisation.\"\"\"\n        x = x * self.scale\n        jac = 2 * self.a_mat.T @ self.a_mat @ x / float(len(self.b_vec))\n        jac -= 2 * self.a_mat.T @ self.b_vec / float(len(self.b_vec))\n        jac += 2 * self.gamma * self.gamma * x\n        return self.scale * jac",
  "def f_objective(self, vector: npt.NDArray) -> float:\n        \"\"\"Objective function for an optimisation.\"\"\"\n        return np.sum(vector**2)",
  "def df_objective(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Gradient of the objective function for an optimisation.\"\"\"\n        return 2 * vector",
  "def __init__(self, c_psi_mat: npt.NDArray, scale: float):\n        self.c_psi_mat = c_psi_mat\n        self.scale = scale",
  "def f_objective(self, vector: npt.NDArray) -> float:\n        \"\"\"Objective function for an optimisation.\"\"\"\n        return -self.scale * self.c_psi_mat @ vector",
  "def df_objective(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Gradient of the objective function for an optimisation.\"\"\"\n        return -self.scale * self.c_psi_mat",
  "def _get_dummy_equilibrium(equilibrium: Equilibrium):\n    \"\"\"\n    Get a dummy equilibrium for current optimisation where the background response is\n    solely due to the plasma and passive coils.\n\n    Notes\n    -----\n    When we do dI (current gradient) optimisation, the background vector includes the\n    contributions from the whole coilset (including active coils).\n\n    When we do I (current vector) optimisation, the background vector only includes\n    contributions from the passive coils (plasma).\n    \"\"\"\n    # TODO: Add passive coil contributions here\n    dummy = equilibrium.plasma\n    dummy.coilset = deepcopy(equilibrium.coilset)\n    return dummy",
  "class UpdateableConstraint(ABC):\n    \"\"\"\n    Abstract base mixin class for an equilibrium optimisation constraint that is\n    updateable.\n    \"\"\"\n\n    @abstractmethod\n    def prepare(self, equilibrium: Equilibrium, I_not_dI=False, fixed_coils=False):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def control_response(self, coilset: CoilSet):\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def evaluate(self, equilibrium: Equilibrium):\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def f_constraint(self) -> ConstraintFunction:\n        \"\"\"The numerical non-linear part of the constraint.\"\"\"\n        pass",
  "class FieldConstraints(UpdateableConstraint):\n    \"\"\"\n    Inequality constraints for the poloidal field at certain locations.\n\n    Parameters\n    ----------\n    x:\n        Radial coordinate(s) at which to constrain the poloidal field\n    z:\n        Vertical coordinate(s) at which to constrain the poloidal field\n    B_max:\n        Maximum poloidal field value(s) at location(s)\n    tolerance:\n        Tolerance with which the constraint(s) will be met\n    constraint_type:\n        Type of constraint\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        B_max: Union[float, np.ndarray],\n        tolerance: Union[float, np.ndarray] = 1.0e-6,\n        constraint_type: str = \"inequality\",\n    ):\n        if is_num(x):\n            x = np.array([x])\n        if is_num(z):\n            z = np.array([z])\n\n        if is_num(B_max):\n            B_max = B_max * np.ones(len(x))\n        if len(B_max) != len(x):\n            raise ValueError(\n                \"Maximum field vector length not equal to the number of points.\"\n            )\n\n        if is_num(tolerance):\n            tolerance = tolerance * np.ones(len(x))\n        if len(tolerance) != len(x):\n            raise ValueError(\"Tolerance vector length not equal to the number of coils.\")\n\n        self.x = x\n        self.z = z\n        self._args = {\n            \"ax_mat\": None,\n            \"az_mat\": None,\n            \"bxp_vec\": None,\n            \"bzp_vec\": None,\n            \"B_max\": B_max,\n            \"scale\": 1.0,\n        }\n        self.tolerance = tolerance\n        self.f_constraint_type = constraint_type\n\n    def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"ax_mat\"] is None):\n            ax_mat, az_mat = self.control_response(equilibrium.coilset)\n            self._args[\"ax_mat\"] = ax_mat\n            self._args[\"az_mat\"] = az_mat\n\n        bxp_vec, bzp_vec = self.evaluate(equilibrium)\n        self._args[\"bxp_vec\"] = bxp_vec\n        self._args[\"bzp_vec\"] = bzp_vec\n\n    def control_response(self, coilset: CoilSet) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return (\n            coilset.Bx_response(self.x, self.z, control=True),\n            coilset.Bz_response(self.x, self.z, control=True),\n        )\n\n    def evaluate(self, equilibrium: Equilibrium) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        Bx = np.atleast_1d(equilibrium.Bx(self.x, self.z))\n        Bz = np.atleast_1d(equilibrium.Bz(self.x, self.z))\n        return Bx, Bz\n\n    def f_constraint(self) -> FieldConstraintFunction:\n        \"\"\"Calculate the constraint function\"\"\"\n        f_constraint = FieldConstraintFunction(**self._args)\n        f_constraint.constraint_type = self.f_constraint_type\n        return f_constraint\n\n    def __len__(self) -> int:\n        \"\"\"\n        Length of field constraints.\n        \"\"\"\n        return len(self.x)",
  "class CoilFieldConstraints(FieldConstraints):\n    \"\"\"\n    Inequality constraints on the poloidal field at the middle of the inside edge\n    of the coils, where the field is usually highest.\n\n    Parameters\n    ----------\n    coilset:\n        Coilset for which to constrain the fields in the coils\n    B_max:\n        Maximum field allowed in the coils\n    tolerance:\n        Tolerance with which the inequality constraints will be met\n\n    Notes\n    -----\n    This is a fast approximation constraint, and does not solve for the peak field\n    at all points in the coils. Use with caution.\n    TODO: Presently only handles CoilSets with Coils (SymmetricCircuits not yet\n    supported)\n    TODO: Presently only accounts for poloidal field contributions from PF coils and\n    plasma (TF from TF coils not accounted for if PF coils are inside the TF coils.)\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        B_max: Union[float, np.ndarray],\n        tolerance: Union[float, np.ndarray] = 1.0e-6,\n    ):\n        n_coils = coilset.n_coils()\n        if is_num(B_max):\n            B_max = B_max * np.ones(n_coils)\n        if len(B_max) != n_coils:\n            raise ValueError(\n                \"Maximum field vector length not equal to the number of coils.\"\n            )\n\n        if is_num(tolerance):\n            tolerance = tolerance * np.ones(n_coils)\n        if len(tolerance) != n_coils:\n            raise ValueError(\"Tolerance vector length not equal to the number of coils.\")\n\n        x, z = self._get_constraint_points(coilset)\n\n        super().__init__(x, z, B_max, tolerance=tolerance, constraint_type=\"inequality\")\n\n    @staticmethod\n    def _get_constraint_points(coilset):\n        return coilset.x - coilset.dx, coilset.z\n\n    def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"ax_mat\"] is None):\n            # Update the target points for the constraints (the coils may be moving)\n            self.x, self.z = self._get_constraint_points(equilibrium.coilset)\n            ax_mat, az_mat = self.control_response(equilibrium.coilset)\n            self._args[\"ax_mat\"] = ax_mat\n            self._args[\"az_mat\"] = az_mat\n\n        bxp_vec, bzp_vec = self.evaluate(equilibrium)\n        self._args[\"bxp_vec\"] = bxp_vec\n        self._args[\"bzp_vec\"] = bzp_vec",
  "class CoilForceConstraints(UpdateableConstraint):\n    \"\"\"\n    Inequality constraints on the vertical forces in the PF and CS coils.\n\n    Parameters\n    ----------\n    coilset:\n        Coilset for which to constrain the fields in the coils\n    PF_Fz_max:\n        Maximum absolute vertical force in a PF coil [MN]\n    CS_Fz_sum_max:\n        Maximum absolute vertical force sum in the CS stack [MN]\n    CS_Fz_sep_max:\n        Maximum separation vertical force between two CS modules [MN]\n    tolerance:\n        Tolerance with which the inequality constraints will be met\n\n    Notes\n    -----\n    TODO: Presently only handles CoilSets with Coils (SymmetricCircuits not yet\n    supported)\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        PF_Fz_max: float,\n        CS_Fz_sum_max: float,\n        CS_Fz_sep_max: float,\n        tolerance: Union[float, np.ndarray] = 1.0e-6,\n    ):\n        n_PF = coilset.n_coils(\"PF\")\n        n_CS = coilset.n_coils(\"CS\")\n        n_f_constraints = n_PF + n_CS\n\n        if is_num(tolerance):\n            tolerance = tolerance * np.ones(n_f_constraints)\n        elif len(tolerance) != n_f_constraints:\n            raise ValueError(f\"Tolerance vector not of length {n_f_constraints}\")\n\n        self._args = {\n            \"a_mat\": None,\n            \"b_vec\": None,\n            \"scale\": 1.0,\n            \"PF_Fz_max\": PF_Fz_max,\n            \"CS_Fz_sum_max\": CS_Fz_sum_max,\n            \"CS_Fz_sep_max\": CS_Fz_sep_max,\n            \"n_PF\": n_PF,\n            \"n_CS\": n_CS,\n        }\n        self.tolerance = tolerance\n\n    def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"a_mat\"] is None):\n            self._args[\"a_mat\"] = self.control_response(equilibrium.coilset)\n\n        self._args[\"b_vec\"] = self.evaluate(equilibrium)\n\n    def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.control_F(coilset)\n\n    def evaluate(self, equilibrium: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        fp = np.zeros((equilibrium.coilset.n_coils(), 2))\n        current = equilibrium.coilset.current\n        non_zero = np.where(current != 0)[0]\n        if non_zero.size:\n            fp[non_zero] = (\n                equilibrium.coilset.F(equilibrium)[non_zero] / current[non_zero][:, None]\n            )\n        return fp\n\n    def f_constraint(self) -> CoilForceConstraintFunction:\n        \"\"\"Calculate the constraint function\"\"\"\n        return CoilForceConstraintFunction(**self._args)",
  "class MagneticConstraint(UpdateableConstraint):\n    \"\"\"\n    Abstract base class for a magnetic optimisation constraint.\n\n    Can be used as a standalone constraint for use in an optimisation problem. In which\n    case the constraint is of the form: ||(Ax - b)||\u00b2 < target_value\n\n    Can be used in a MagneticConstraintSet\n    \"\"\"\n\n    def __init__(\n        self,\n        target_value: float = 0.0,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n        f_constraint: Type[ConstraintFunction] = L2NormConstraint,\n        constraint_type: str = \"inequality\",\n    ):\n        self.target_value = target_value * np.ones(len(self))\n        if is_num(tolerance):\n            if f_constraint == L2NormConstraint:\n                tolerance = tolerance * np.ones(1)\n            else:\n                tolerance = tolerance * np.ones(len(self))\n        self.weights = weights\n        self._f_constraint = f_constraint\n        self._args = {\"a_mat\": None, \"b_vec\": None, \"value\": 0.0, \"scale\": 1.0}\n        self.tolerance = tolerance\n        self.constraint_type = constraint_type\n\n    def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):  # noqa :N803\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"a_mat\"] is None):\n            self._args[\"a_mat\"] = self.control_response(equilibrium.coilset)\n\n        self.update_target(equilibrium)\n        self._args[\"b_vec\"] = self.target_value - self.evaluate(equilibrium)\n\n    def update_target(self, equilibrium: Equilibrium):\n        \"\"\"\n        Update the target value of the magnetic constraint.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        pass\n\n    def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint.\n\n        Notes\n        -----\n        Length of the array if an array is specified, otherwise 1 for a float.\n        \"\"\"\n        return len(self.x) if hasattr(self.x, \"__len__\") else 1\n\n    def f_constraint(self) -> ConstraintFunction:\n        \"\"\"Return the non-linear, numerical, part of the constraint.\"\"\"\n        f_constraint = self._f_constraint(**self._args)\n        f_constraint.constraint_type = self.constraint_type\n        return f_constraint",
  "class SphericalHarmonicsConstraint(MagneticConstraint):\n    \"\"\"\n    Constraint function to constrain spherical harmonics starting from initial\n    coil currents and associated core plasma.\n\n    Parameters\n    ----------\n    r_t:\n        Typical length scale of the problem (e.g. radius at outer midplane)\n    ref_coil_psi_amplitudes:\n        Initial harmonic amplitudes obtained from desired core plasma\n    max_degree:\n        Maximum degree of spherical harmonics desired to constrain.\n    \"\"\"\n\n    def __init__(\n        self,\n        r_t: float,\n        ref_coil_psi_amplitudes: npt.NDArray,\n        max_degree: int,\n        target_value: float = 0.0,\n        weights: Union[float, npt.NDArray] = 1.0,\n        tolerance: Union[float, npt.NDArray] = 1e-6,\n        f_constraint: Type[ConstraintFunction] = AxBConstraint,\n        constraint_type: str = \"inequality\",\n    ):\n        super().__init__(\n            target_value,\n            weights,\n            tolerance=tolerance,\n            f_constraint=f_constraint,\n            constraint_type=constraint_type,\n        )\n        self.max_degree = max_degree\n        self.r_t = r_t\n        self.ref_coil_psi_amplitudes = ref_coil_psi_amplitudes\n\n    def control_response(self, coilset: CoilSet) -> npt.NDArray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coil_harmonic_amplitude_matrix(coilset, self.max_degree, self.r_t)\n\n    def evaluate(self, _: Equilibrium) -> npt.NDArray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return self.ref_coil_psi_amplitudes\n\n    def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint.\n        \"\"\"\n        return len(self.ref_coil_psi_amplitudes)\n\n    def plot(self, ax=None):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        if ax is None:\n            _, ax = plt.subplots()\n\n        ax.add_patch(patch.Circle((0, 0), self.r_t, ec=\"orange\", fill=True, fc=\"orange\"))",
  "class AbsoluteMagneticConstraint(MagneticConstraint):\n    \"\"\"\n    Abstract base class for absolute magnetic constraints, where the target\n    value is prescribed in absolute terms.\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        target_value: float,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n        f_constraint: Type[ConstraintFunction] = AxBConstraint,\n        constraint_type: str = \"equality\",\n    ):\n        self.x = x\n        self.z = z\n        super().__init__(\n            target_value,\n            weights,\n            tolerance=tolerance,\n            f_constraint=f_constraint,\n            constraint_type=constraint_type,\n        )",
  "class RelativeMagneticConstraint(MagneticConstraint):\n    \"\"\"\n    Abstract base class for relative magnetic constraints, where the target\n    value is prescribed with respect to a reference point.\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        ref_x: float,\n        ref_z: float,\n        constraint_value: float = 0.0,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n        f_constraint: Type[ConstraintFunction] = L2NormConstraint,\n        constraint_type: str = \"inequality\",\n    ):\n        self.x = x\n        self.z = z\n        self.ref_x = ref_x\n        self.ref_z = ref_z\n        super().__init__(\n            0.0,\n            weights,\n            tolerance=tolerance,\n            f_constraint=f_constraint,\n            constraint_type=constraint_type,\n        )\n        self._args[\"value\"] = constraint_value\n\n    @abstractmethod\n    def update_target(self, equilibrium: Equilibrium):\n        \"\"\"\n        Update the target value of the magnetic constraint.\n        \"\"\"\n        pass",
  "class FieldNullConstraint(AbsoluteMagneticConstraint):\n    \"\"\"\n    Magnetic field null constraint. In practice sets the Bx and Bz field components\n    to be 0 at the specified location.\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: float = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            target_value=0.0,\n            weights=weights,\n            tolerance=tolerance,\n            constraint_type=\"inequality\",\n            f_constraint=L2NormConstraint,\n        )\n\n    def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return np.vstack(\n            [\n                coilset.Bx_response(self.x, self.z, control=True),\n                coilset.Bz_response(self.x, self.z, control=True),\n            ]\n        )\n\n    def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return np.array([eq.Bx(self.x, self.z), eq.Bz(self.x, self.z)])\n\n    def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\n            \"marker\": \"X\",\n            \"color\": \"b\",\n            \"markersize\": 10,\n            \"zorder\": 45,\n            \"linestyle\": \"None\",\n        }\n        ax.plot(self.x, self.z, **kwargs)\n\n    def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint.\n        \"\"\"\n        return 2",
  "class PsiConstraint(AbsoluteMagneticConstraint):\n    \"\"\"\n    Absolute psi value constraint.\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        target_value: float,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            target_value,\n            weights=weights,\n            tolerance=tolerance,\n            f_constraint=AxBConstraint,\n            constraint_type=\"equality\",\n        )\n\n    def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.psi_response(self.x, self.z, control=True)\n\n    def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return eq.psi(self.x, self.z)\n\n    def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\"marker\": \"s\", \"markersize\": 8, \"color\": \"b\", \"linestyle\": \"None\"}\n        ax.plot(self.x, self.z, **kwargs)",
  "class IsofluxConstraint(RelativeMagneticConstraint):\n    \"\"\"\n    Isoflux constraint for a set of points relative to a reference point.\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        ref_x: float,\n        ref_z: float,\n        constraint_value: float = 0.0,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: float = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            ref_x,\n            ref_z,\n            constraint_value,\n            weights=weights,\n            f_constraint=L2NormConstraint,\n            tolerance=tolerance,\n            constraint_type=\"inequality\",\n        )\n\n    def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.psi_response(self.x, self.z, control=True) - coilset.psi_response(\n            self.ref_x, self.ref_z, control=True\n        )\n\n    def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return eq.psi(self.x, self.z)\n\n    def update_target(self, eq: Equilibrium):\n        \"\"\"\n        We need to update the target value, as it is a relative constraint.\n        \"\"\"\n        self.target_value = float(eq.psi(self.ref_x, self.ref_z))\n\n    def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\n            \"marker\": \"o\",\n            \"markeredgewidth\": 3,\n            \"markeredgecolor\": \"b\",\n            \"markersize\": 10,\n            \"linestyle\": \"None\",\n            \"markerfacecolor\": \"None\",\n            \"zorder\": 45,\n        }\n        ax.plot(self.x, self.z, **kwargs)\n        kwargs[\"markeredgewidth\"] = 5\n        ax.plot(self.ref_x, self.ref_z, **kwargs)",
  "class PsiBoundaryConstraint(AbsoluteMagneticConstraint):\n    \"\"\"\n    Absolute psi value constraint on the plasma boundary. Gets updated when\n    the plasma boundary flux value is changed.\n    \"\"\"\n\n    def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        target_value: float,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            target_value,\n            weights,\n            tolerance,\n            f_constraint=L2NormConstraint,\n            constraint_type=\"inequality\",\n        )\n\n    def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.psi_response(self.x, self.z, control=True)\n\n    def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return eq.psi(self.x, self.z)\n\n    def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\"marker\": \"o\", \"markersize\": 8, \"color\": \"b\", \"linestyle\": \"None\"}\n        ax.plot(self.x, self.z, **kwargs)",
  "class MagneticConstraintSet(ABC):\n    \"\"\"\n    A set of magnetic constraints to be applied to an equilibrium. The optimisation\n    problem is of the form:\n\n        [A][x] = [b]\n\n    where:\n\n        [b] = [target] - [background]\n\n    The target vector is the vector of desired values. The background vector\n    is the vector of values due to uncontrolled current terms (plasma and passive\n    coils).\n\n\n    Use of class:\n\n        - Inherit from this class\n        - Add a __init__(args) method\n        - Populate constraints with super().__init__(List[MagneticConstraint])\n    \"\"\"\n\n    __slots__ = [\"constraints\", \"eq\", \"coilset\", \"A\", \"w\", \"target\", \"background\"]\n\n    def __init__(self, constraints: List[MagneticConstraint]):\n        self.constraints = constraints\n        self.eq = None\n        self.A = None\n        self.target = None\n        self.background = None\n\n    def __call__(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Update the MagneticConstraintSet\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        self.eq = equilibrium\n        self.coilset = equilibrium.coilset\n\n        # Update relative magnetic constraints without updating A matrix\n        for constraint in self.constraints:\n            if isinstance(constraint, RelativeMagneticConstraint):\n                constraint.update_target(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self.A is None):\n            self.build_control_matrix()\n            self.build_target()\n\n        self.build_background()\n        self.build_weight_matrix()\n\n    def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint set.\n        \"\"\"\n        return sum([len(c) for c in self.constraints])\n\n    def get_weighted_arrays(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Get [A] and [b] scaled by weight matrix.\n        Weight matrix assumed to be diagonal.\n        \"\"\"\n        weights = self.w\n        weighted_a = weights[:, np.newaxis] * self.A\n        weighted_b = weights * self.b\n        return weights, weighted_a, weighted_b\n\n    def build_weight_matrix(self):\n        \"\"\"\n        Build the weight matrix used in optimisation.\n        Assumed to be diagonal.\n        \"\"\"\n        self.w = np.zeros(len(self))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.w[i : i + n] = constraint.weights\n            i += n\n\n    def build_control_matrix(self):\n        \"\"\"\n        Build the control response matrix used in optimisation.\n        \"\"\"\n        self.A = np.zeros((len(self), len(self.coilset.control)))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.A[i : i + n, :] = constraint.control_response(self.coilset)\n            i += n\n\n    def build_target(self):\n        \"\"\"\n        Build the target value vector.\n        \"\"\"\n        self.target = np.zeros(len(self))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.target[i : i + n] = constraint.target_value * np.ones(n)\n            i += n\n\n    def build_background(self):\n        \"\"\"\n        Build the background value vector.\n        \"\"\"\n        self.background = np.zeros(len(self))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.background[i : i + n] = constraint.evaluate(self.eq)\n            i += n\n\n    @property\n    def b(self) -> np.ndarray:\n        \"\"\"\n        The b vector of target - background values.\n        \"\"\"\n        return self.target - self.background\n\n    def update_psi_boundary(self, psi_bndry: float):\n        \"\"\"\n        Update the target value for all PsiBoundaryConstraints.\n\n        Parameters\n        ----------\n        psi_bndry:\n            The target psi boundary value [V.s/rad]\n        \"\"\"\n        for constraint in self.constraints:\n            if isinstance(constraint, PsiBoundaryConstraint):\n                constraint.target_value = psi_bndry\n        self.build_target()\n\n    def plot(self, ax=None):\n        \"\"\"\n        Plots constraints\n        \"\"\"\n        return ConstraintPlotter(self, ax=ax)",
  "class AutoConstraints(MagneticConstraintSet):\n    \"\"\"\n    Utility class for crude reconstruction of magnetic constraints from a\n    specified LCFS set of coordinates.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates of the LCFS\n    z:\n        The z coordinates of the LCFS\n    psi_boundary:\n        The psi boundary value to use as a constraint. If None, an\n        isoflux constraint is used.\n    n_points:\n        The number of interpolated points to use\n    \"\"\"\n\n    def __init__(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        psi_boundary: Optional[float] = None,\n        n_points: int = 40,\n    ):\n        x = np.array(x)\n        z = np.array(z)\n        z_max = max(z)\n        z_min = min(z)\n        x_z_max = x[np.argmax(z)]\n        x_z_min = x[np.argmin(z)]\n\n        # Determine if we are dealing with SN or DN\n        single_null = abs_rel_difference(abs(z_min), z_max) > 0.05\n\n        if single_null:\n            # Determine if it is an upper or lower SN\n            lower = abs(z_min) > z_max\n\n            if lower:\n                constraints = [FieldNullConstraint(x_z_min, z_min)]\n            else:\n                constraints = [FieldNullConstraint(x_z_max, z_max)]\n\n        else:\n            constraints = [\n                FieldNullConstraint(x_z_min, z_min),\n                FieldNullConstraint(x_z_max, z_max),\n            ]\n\n        # Interpolate some points on the LCFS\n        x_boundary, _, z_boundary = interpolate_points(x, np.zeros_like[x], z, n_points)\n\n        # Apply an appropriate constraint on the LCFS\n        if psi_boundary is None:\n            arg_inner = np.argmin(x_boundary**2 + z_boundary**2)\n            ref_x = x_boundary[arg_inner]\n            ref_z = z_boundary[arg_inner]\n\n            constraints.append(IsofluxConstraint(x_boundary, z_boundary, ref_x, ref_z))\n\n        else:\n            constraints.append(\n                PsiBoundaryConstraint(x_boundary, z_boundary, psi_boundary)\n            )\n        super().__init__(constraints)",
  "def prepare(self, equilibrium: Equilibrium, I_not_dI=False, fixed_coils=False):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        pass",
  "def control_response(self, coilset: CoilSet):\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        pass",
  "def evaluate(self, equilibrium: Equilibrium):\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        pass",
  "def f_constraint(self) -> ConstraintFunction:\n        \"\"\"The numerical non-linear part of the constraint.\"\"\"\n        pass",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        B_max: Union[float, np.ndarray],\n        tolerance: Union[float, np.ndarray] = 1.0e-6,\n        constraint_type: str = \"inequality\",\n    ):\n        if is_num(x):\n            x = np.array([x])\n        if is_num(z):\n            z = np.array([z])\n\n        if is_num(B_max):\n            B_max = B_max * np.ones(len(x))\n        if len(B_max) != len(x):\n            raise ValueError(\n                \"Maximum field vector length not equal to the number of points.\"\n            )\n\n        if is_num(tolerance):\n            tolerance = tolerance * np.ones(len(x))\n        if len(tolerance) != len(x):\n            raise ValueError(\"Tolerance vector length not equal to the number of coils.\")\n\n        self.x = x\n        self.z = z\n        self._args = {\n            \"ax_mat\": None,\n            \"az_mat\": None,\n            \"bxp_vec\": None,\n            \"bzp_vec\": None,\n            \"B_max\": B_max,\n            \"scale\": 1.0,\n        }\n        self.tolerance = tolerance\n        self.f_constraint_type = constraint_type",
  "def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"ax_mat\"] is None):\n            ax_mat, az_mat = self.control_response(equilibrium.coilset)\n            self._args[\"ax_mat\"] = ax_mat\n            self._args[\"az_mat\"] = az_mat\n\n        bxp_vec, bzp_vec = self.evaluate(equilibrium)\n        self._args[\"bxp_vec\"] = bxp_vec\n        self._args[\"bzp_vec\"] = bzp_vec",
  "def control_response(self, coilset: CoilSet) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return (\n            coilset.Bx_response(self.x, self.z, control=True),\n            coilset.Bz_response(self.x, self.z, control=True),\n        )",
  "def evaluate(self, equilibrium: Equilibrium) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        Bx = np.atleast_1d(equilibrium.Bx(self.x, self.z))\n        Bz = np.atleast_1d(equilibrium.Bz(self.x, self.z))\n        return Bx, Bz",
  "def f_constraint(self) -> FieldConstraintFunction:\n        \"\"\"Calculate the constraint function\"\"\"\n        f_constraint = FieldConstraintFunction(**self._args)\n        f_constraint.constraint_type = self.f_constraint_type\n        return f_constraint",
  "def __len__(self) -> int:\n        \"\"\"\n        Length of field constraints.\n        \"\"\"\n        return len(self.x)",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        B_max: Union[float, np.ndarray],\n        tolerance: Union[float, np.ndarray] = 1.0e-6,\n    ):\n        n_coils = coilset.n_coils()\n        if is_num(B_max):\n            B_max = B_max * np.ones(n_coils)\n        if len(B_max) != n_coils:\n            raise ValueError(\n                \"Maximum field vector length not equal to the number of coils.\"\n            )\n\n        if is_num(tolerance):\n            tolerance = tolerance * np.ones(n_coils)\n        if len(tolerance) != n_coils:\n            raise ValueError(\"Tolerance vector length not equal to the number of coils.\")\n\n        x, z = self._get_constraint_points(coilset)\n\n        super().__init__(x, z, B_max, tolerance=tolerance, constraint_type=\"inequality\")",
  "def _get_constraint_points(coilset):\n        return coilset.x - coilset.dx, coilset.z",
  "def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"ax_mat\"] is None):\n            # Update the target points for the constraints (the coils may be moving)\n            self.x, self.z = self._get_constraint_points(equilibrium.coilset)\n            ax_mat, az_mat = self.control_response(equilibrium.coilset)\n            self._args[\"ax_mat\"] = ax_mat\n            self._args[\"az_mat\"] = az_mat\n\n        bxp_vec, bzp_vec = self.evaluate(equilibrium)\n        self._args[\"bxp_vec\"] = bxp_vec\n        self._args[\"bzp_vec\"] = bzp_vec",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        PF_Fz_max: float,\n        CS_Fz_sum_max: float,\n        CS_Fz_sep_max: float,\n        tolerance: Union[float, np.ndarray] = 1.0e-6,\n    ):\n        n_PF = coilset.n_coils(\"PF\")\n        n_CS = coilset.n_coils(\"CS\")\n        n_f_constraints = n_PF + n_CS\n\n        if is_num(tolerance):\n            tolerance = tolerance * np.ones(n_f_constraints)\n        elif len(tolerance) != n_f_constraints:\n            raise ValueError(f\"Tolerance vector not of length {n_f_constraints}\")\n\n        self._args = {\n            \"a_mat\": None,\n            \"b_vec\": None,\n            \"scale\": 1.0,\n            \"PF_Fz_max\": PF_Fz_max,\n            \"CS_Fz_sum_max\": CS_Fz_sum_max,\n            \"CS_Fz_sep_max\": CS_Fz_sep_max,\n            \"n_PF\": n_PF,\n            \"n_CS\": n_CS,\n        }\n        self.tolerance = tolerance",
  "def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"a_mat\"] is None):\n            self._args[\"a_mat\"] = self.control_response(equilibrium.coilset)\n\n        self._args[\"b_vec\"] = self.evaluate(equilibrium)",
  "def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.control_F(coilset)",
  "def evaluate(self, equilibrium: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        fp = np.zeros((equilibrium.coilset.n_coils(), 2))\n        current = equilibrium.coilset.current\n        non_zero = np.where(current != 0)[0]\n        if non_zero.size:\n            fp[non_zero] = (\n                equilibrium.coilset.F(equilibrium)[non_zero] / current[non_zero][:, None]\n            )\n        return fp",
  "def f_constraint(self) -> CoilForceConstraintFunction:\n        \"\"\"Calculate the constraint function\"\"\"\n        return CoilForceConstraintFunction(**self._args)",
  "def __init__(\n        self,\n        target_value: float = 0.0,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n        f_constraint: Type[ConstraintFunction] = L2NormConstraint,\n        constraint_type: str = \"inequality\",\n    ):\n        self.target_value = target_value * np.ones(len(self))\n        if is_num(tolerance):\n            if f_constraint == L2NormConstraint:\n                tolerance = tolerance * np.ones(1)\n            else:\n                tolerance = tolerance * np.ones(len(self))\n        self.weights = weights\n        self._f_constraint = f_constraint\n        self._args = {\"a_mat\": None, \"b_vec\": None, \"value\": 0.0, \"scale\": 1.0}\n        self.tolerance = tolerance\n        self.constraint_type = constraint_type",
  "def prepare(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):  # noqa :N803\n        \"\"\"\n        Prepare the constraint for use in an equilibrium optimisation problem.\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self._args[\"a_mat\"] is None):\n            self._args[\"a_mat\"] = self.control_response(equilibrium.coilset)\n\n        self.update_target(equilibrium)\n        self._args[\"b_vec\"] = self.target_value - self.evaluate(equilibrium)",
  "def update_target(self, equilibrium: Equilibrium):\n        \"\"\"\n        Update the target value of the magnetic constraint.\n        \"\"\"\n        pass",
  "def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        pass",
  "def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint.\n\n        Notes\n        -----\n        Length of the array if an array is specified, otherwise 1 for a float.\n        \"\"\"\n        return len(self.x) if hasattr(self.x, \"__len__\") else 1",
  "def f_constraint(self) -> ConstraintFunction:\n        \"\"\"Return the non-linear, numerical, part of the constraint.\"\"\"\n        f_constraint = self._f_constraint(**self._args)\n        f_constraint.constraint_type = self.constraint_type\n        return f_constraint",
  "def __init__(\n        self,\n        r_t: float,\n        ref_coil_psi_amplitudes: npt.NDArray,\n        max_degree: int,\n        target_value: float = 0.0,\n        weights: Union[float, npt.NDArray] = 1.0,\n        tolerance: Union[float, npt.NDArray] = 1e-6,\n        f_constraint: Type[ConstraintFunction] = AxBConstraint,\n        constraint_type: str = \"inequality\",\n    ):\n        super().__init__(\n            target_value,\n            weights,\n            tolerance=tolerance,\n            f_constraint=f_constraint,\n            constraint_type=constraint_type,\n        )\n        self.max_degree = max_degree\n        self.r_t = r_t\n        self.ref_coil_psi_amplitudes = ref_coil_psi_amplitudes",
  "def control_response(self, coilset: CoilSet) -> npt.NDArray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coil_harmonic_amplitude_matrix(coilset, self.max_degree, self.r_t)",
  "def evaluate(self, _: Equilibrium) -> npt.NDArray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return self.ref_coil_psi_amplitudes",
  "def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint.\n        \"\"\"\n        return len(self.ref_coil_psi_amplitudes)",
  "def plot(self, ax=None):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        if ax is None:\n            _, ax = plt.subplots()\n\n        ax.add_patch(patch.Circle((0, 0), self.r_t, ec=\"orange\", fill=True, fc=\"orange\"))",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        target_value: float,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n        f_constraint: Type[ConstraintFunction] = AxBConstraint,\n        constraint_type: str = \"equality\",\n    ):\n        self.x = x\n        self.z = z\n        super().__init__(\n            target_value,\n            weights,\n            tolerance=tolerance,\n            f_constraint=f_constraint,\n            constraint_type=constraint_type,\n        )",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        ref_x: float,\n        ref_z: float,\n        constraint_value: float = 0.0,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n        f_constraint: Type[ConstraintFunction] = L2NormConstraint,\n        constraint_type: str = \"inequality\",\n    ):\n        self.x = x\n        self.z = z\n        self.ref_x = ref_x\n        self.ref_z = ref_z\n        super().__init__(\n            0.0,\n            weights,\n            tolerance=tolerance,\n            f_constraint=f_constraint,\n            constraint_type=constraint_type,\n        )\n        self._args[\"value\"] = constraint_value",
  "def update_target(self, equilibrium: Equilibrium):\n        \"\"\"\n        Update the target value of the magnetic constraint.\n        \"\"\"\n        pass",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: float = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            target_value=0.0,\n            weights=weights,\n            tolerance=tolerance,\n            constraint_type=\"inequality\",\n            f_constraint=L2NormConstraint,\n        )",
  "def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return np.vstack(\n            [\n                coilset.Bx_response(self.x, self.z, control=True),\n                coilset.Bz_response(self.x, self.z, control=True),\n            ]\n        )",
  "def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return np.array([eq.Bx(self.x, self.z), eq.Bz(self.x, self.z)])",
  "def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\n            \"marker\": \"X\",\n            \"color\": \"b\",\n            \"markersize\": 10,\n            \"zorder\": 45,\n            \"linestyle\": \"None\",\n        }\n        ax.plot(self.x, self.z, **kwargs)",
  "def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint.\n        \"\"\"\n        return 2",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        target_value: float,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            target_value,\n            weights=weights,\n            tolerance=tolerance,\n            f_constraint=AxBConstraint,\n            constraint_type=\"equality\",\n        )",
  "def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.psi_response(self.x, self.z, control=True)",
  "def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return eq.psi(self.x, self.z)",
  "def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\"marker\": \"s\", \"markersize\": 8, \"color\": \"b\", \"linestyle\": \"None\"}\n        ax.plot(self.x, self.z, **kwargs)",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        ref_x: float,\n        ref_z: float,\n        constraint_value: float = 0.0,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: float = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            ref_x,\n            ref_z,\n            constraint_value,\n            weights=weights,\n            f_constraint=L2NormConstraint,\n            tolerance=tolerance,\n            constraint_type=\"inequality\",\n        )",
  "def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.psi_response(self.x, self.z, control=True) - coilset.psi_response(\n            self.ref_x, self.ref_z, control=True\n        )",
  "def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return eq.psi(self.x, self.z)",
  "def update_target(self, eq: Equilibrium):\n        \"\"\"\n        We need to update the target value, as it is a relative constraint.\n        \"\"\"\n        self.target_value = float(eq.psi(self.ref_x, self.ref_z))",
  "def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\n            \"marker\": \"o\",\n            \"markeredgewidth\": 3,\n            \"markeredgecolor\": \"b\",\n            \"markersize\": 10,\n            \"linestyle\": \"None\",\n            \"markerfacecolor\": \"None\",\n            \"zorder\": 45,\n        }\n        ax.plot(self.x, self.z, **kwargs)\n        kwargs[\"markeredgewidth\"] = 5\n        ax.plot(self.ref_x, self.ref_z, **kwargs)",
  "def __init__(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        target_value: float,\n        weights: Union[float, np.ndarray] = 1.0,\n        tolerance: Union[float, np.ndarray] = 1e-6,\n    ):\n        super().__init__(\n            x,\n            z,\n            target_value,\n            weights,\n            tolerance,\n            f_constraint=L2NormConstraint,\n            constraint_type=\"inequality\",\n        )",
  "def control_response(self, coilset: CoilSet) -> np.ndarray:\n        \"\"\"\n        Calculate control response of a CoilSet to the constraint.\n        \"\"\"\n        return coilset.psi_response(self.x, self.z, control=True)",
  "def evaluate(self, eq: Equilibrium) -> np.ndarray:\n        \"\"\"\n        Calculate the value of the constraint in an Equilibrium.\n        \"\"\"\n        return eq.psi(self.x, self.z)",
  "def plot(self, ax):\n        \"\"\"\n        Plot the constraint onto an Axes.\n        \"\"\"\n        kwargs = {\"marker\": \"o\", \"markersize\": 8, \"color\": \"b\", \"linestyle\": \"None\"}\n        ax.plot(self.x, self.z, **kwargs)",
  "def __init__(self, constraints: List[MagneticConstraint]):\n        self.constraints = constraints\n        self.eq = None\n        self.A = None\n        self.target = None\n        self.background = None",
  "def __call__(\n        self, equilibrium: Equilibrium, I_not_dI: bool = False, fixed_coils: bool = False\n    ):\n        \"\"\"\n        Update the MagneticConstraintSet\n        \"\"\"\n        if I_not_dI:\n            equilibrium = _get_dummy_equilibrium(equilibrium)\n\n        self.eq = equilibrium\n        self.coilset = equilibrium.coilset\n\n        # Update relative magnetic constraints without updating A matrix\n        for constraint in self.constraints:\n            if isinstance(constraint, RelativeMagneticConstraint):\n                constraint.update_target(equilibrium)\n\n        # Re-build control response matrix\n        if not fixed_coils or (fixed_coils and self.A is None):\n            self.build_control_matrix()\n            self.build_target()\n\n        self.build_background()\n        self.build_weight_matrix()",
  "def __len__(self) -> int:\n        \"\"\"\n        The mathematical size of the constraint set.\n        \"\"\"\n        return sum([len(c) for c in self.constraints])",
  "def get_weighted_arrays(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Get [A] and [b] scaled by weight matrix.\n        Weight matrix assumed to be diagonal.\n        \"\"\"\n        weights = self.w\n        weighted_a = weights[:, np.newaxis] * self.A\n        weighted_b = weights * self.b\n        return weights, weighted_a, weighted_b",
  "def build_weight_matrix(self):\n        \"\"\"\n        Build the weight matrix used in optimisation.\n        Assumed to be diagonal.\n        \"\"\"\n        self.w = np.zeros(len(self))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.w[i : i + n] = constraint.weights\n            i += n",
  "def build_control_matrix(self):\n        \"\"\"\n        Build the control response matrix used in optimisation.\n        \"\"\"\n        self.A = np.zeros((len(self), len(self.coilset.control)))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.A[i : i + n, :] = constraint.control_response(self.coilset)\n            i += n",
  "def build_target(self):\n        \"\"\"\n        Build the target value vector.\n        \"\"\"\n        self.target = np.zeros(len(self))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.target[i : i + n] = constraint.target_value * np.ones(n)\n            i += n",
  "def build_background(self):\n        \"\"\"\n        Build the background value vector.\n        \"\"\"\n        self.background = np.zeros(len(self))\n\n        i = 0\n        for constraint in self.constraints:\n            n = len(constraint)\n            self.background[i : i + n] = constraint.evaluate(self.eq)\n            i += n",
  "def b(self) -> np.ndarray:\n        \"\"\"\n        The b vector of target - background values.\n        \"\"\"\n        return self.target - self.background",
  "def update_psi_boundary(self, psi_bndry: float):\n        \"\"\"\n        Update the target value for all PsiBoundaryConstraints.\n\n        Parameters\n        ----------\n        psi_bndry:\n            The target psi boundary value [V.s/rad]\n        \"\"\"\n        for constraint in self.constraints:\n            if isinstance(constraint, PsiBoundaryConstraint):\n                constraint.target_value = psi_bndry\n        self.build_target()",
  "def plot(self, ax=None):\n        \"\"\"\n        Plots constraints\n        \"\"\"\n        return ConstraintPlotter(self, ax=ax)",
  "def __init__(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        psi_boundary: Optional[float] = None,\n        n_points: int = 40,\n    ):\n        x = np.array(x)\n        z = np.array(z)\n        z_max = max(z)\n        z_min = min(z)\n        x_z_max = x[np.argmax(z)]\n        x_z_min = x[np.argmin(z)]\n\n        # Determine if we are dealing with SN or DN\n        single_null = abs_rel_difference(abs(z_min), z_max) > 0.05\n\n        if single_null:\n            # Determine if it is an upper or lower SN\n            lower = abs(z_min) > z_max\n\n            if lower:\n                constraints = [FieldNullConstraint(x_z_min, z_min)]\n            else:\n                constraints = [FieldNullConstraint(x_z_max, z_max)]\n\n        else:\n            constraints = [\n                FieldNullConstraint(x_z_min, z_min),\n                FieldNullConstraint(x_z_max, z_max),\n            ]\n\n        # Interpolate some points on the LCFS\n        x_boundary, _, z_boundary = interpolate_points(x, np.zeros_like[x], z, n_points)\n\n        # Apply an appropriate constraint on the LCFS\n        if psi_boundary is None:\n            arg_inner = np.argmin(x_boundary**2 + z_boundary**2)\n            ref_x = x_boundary[arg_inner]\n            ref_z = z_boundary[arg_inner]\n\n            constraints.append(IsofluxConstraint(x_boundary, z_boundary, ref_x, ref_z))\n\n        else:\n            constraints.append(\n                PsiBoundaryConstraint(x_boundary, z_boundary, psi_boundary)\n            )\n        super().__init__(constraints)",
  "class ConstraintFunction(abc.ABC):\n    \"\"\"Override to define a numerical constraint for a coilset optimisation.\"\"\"\n\n    @abc.abstractmethod\n    def f_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"The constraint function.\"\"\"\n\n    @property\n    def constraint_type(self) -> Literal[\"inequality\", \"equality\"]:\n        \"\"\"The type of constraint\"\"\"\n        try:\n            return self._constraint_type\n        except AttributeError:\n            return \"inequality\"\n\n    @constraint_type.setter\n    def constraint_type(self, constraint_t: Literal[\"inequality\", \"equality\"]) -> None:\n        if constraint_t not in [\"inequality\", \"equality\"]:\n            bluemira_warn(\n                f\"Unknown nonlinear constraint type '{constraint_t}', \"\n                \"defaulting to 'inequality'.\"\n            )\n        self._constraint_type = constraint_t",
  "class AxBConstraint(ConstraintFunction):\n    \"\"\"\n    Constraint function of the form:\n        A.x - b < value\n\n    Parameters\n    ----------\n    a_mat:\n        Response matrix\n    b_vec:\n        Target value vector\n    value:\n        Target constraint value\n    scale:\n        Current scale with which to calculate the constraints\n    \"\"\"\n\n    def __init__(\n        self, a_mat: np.ndarray, b_vec: np.ndarray, value: float, scale: float\n    ) -> None:\n        self.a_mat = a_mat\n        self.b_vec = b_vec\n        self.value = value\n        self.scale = scale\n\n    def f_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint function\"\"\"\n        return self.a_mat @ (self.scale * vector) - self.b_vec - self.value\n\n    def df_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint derivative\"\"\"\n        return self.scale * self.a_mat",
  "class L2NormConstraint(ConstraintFunction):\n    \"\"\"\n    Constrain the L2 norm of an Ax = b system of equations.\n\n    ||(Ax - b)||\u00b2 < value\n\n    Parameters\n    ----------\n    a_mat:\n        Response matrix\n    b_vec:\n        Target value vector\n    scale:\n        Current scale with which to calculate the constraints\n    \"\"\"\n\n    def __init__(\n        self,\n        a_mat: npt.NDArray,\n        b_vec: npt.NDArray,\n        value: float,\n        scale: float,\n    ) -> None:\n        self.a_mat = a_mat\n        self.b_vec = b_vec\n        self.value = value\n        self.scale = scale\n\n    def f_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint function\"\"\"\n        vector = self.scale * vector\n        residual = self.a_mat @ vector - self.b_vec\n        return residual.T @ residual - self.value\n\n    def df_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint derivative\"\"\"\n        vector = self.scale * vector\n        df = 2 * (self.a_mat.T @ self.a_mat @ vector - self.a_mat.T @ self.b_vec)\n        return df * self.scale",
  "class FieldConstraintFunction(ConstraintFunction):\n    \"\"\"\n    Current optimisation poloidal field constraints at prescribed locations\n\n    Parameters\n    ----------\n    ax_mat:\n        Response matrix for Bx (active coil contributions)\n    az_mat:\n        Response matrix for Bz (active coil contributions)\n    bxp_vec:\n        Background vector for Bx (passive coil contributions)\n    bzp_vec:\n        Background vector for Bz (passive coil contributions)\n    B_max:\n        Maximum fields inside the coils\n    scale:\n        Current scale with which to calculate the constraints\n    \"\"\"\n\n    def __init__(\n        self,\n        ax_mat: np.ndarray,\n        az_mat: np.ndarray,\n        bxp_vec: np.ndarray,\n        bzp_vec: np.ndarray,\n        B_max: np.ndarray,\n        scale: float,\n    ):\n        self.ax_mat = ax_mat\n        self.az_mat = az_mat\n        self.bxp_vec = bxp_vec\n        self.bzp_vec = bzp_vec\n        self.B_max = B_max\n        self.scale = scale\n\n    def f_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint function\"\"\"\n        currents = self.scale * vector\n        Bx_a = self.ax_mat @ currents\n        Bz_a = self.az_mat @ currents\n\n        B = np.hypot(Bx_a + self.bxp_vec, Bz_a + self.bzp_vec)\n        return B - self.B_max\n\n    def df_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint derivative\"\"\"\n        currents = self.scale * vector\n        Bx_a = self.ax_mat @ currents\n        Bz_a = self.az_mat @ currents\n        B = np.hypot(Bx_a + self.bxp_vec, Bz_a + self.bzp_vec)\n        return (\n            Bx_a * (Bx_a @ currents + self.bxp_vec)\n            + Bz_a * (Bz_a @ currents + self.bzp_vec)\n        ) / (B * self.scale**2)",
  "class CurrentMidplanceConstraint(ConstraintFunction):\n    \"\"\"\n    Constraint function to constrain the inboard or outboard midplane\n    of the plasma during optimisation.\n\n    Parameters\n    ----------\n    eq:\n        Equilibrium to use to fetch last closed flux surface from.\n    radius:\n        Toroidal radius at which to constrain the plasma midplane.\n    scale:\n        Current scale with which to calculate the constraints\n    inboard:\n        Boolean controlling whether to constrain the inboard (if True) or\n        outboard (if False) side of the plasma midplane.\n    \"\"\"\n\n    def __init__(\n        self,\n        eq: Equilibrium,\n        radius: float,\n        scale: float,\n        inboard: bool,\n    ) -> None:\n        self.eq = eq\n        self.radius = radius\n        self.scale = scale\n        self.inboard = inboard\n\n    def f_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint function\"\"\"\n        self.eq.coilset.get_control_coils().current = vector * self.scale\n        lcfs = self.eq.get_LCFS()\n        if self.inboard:\n            return self.radius - min(lcfs.x)\n        return max(lcfs.x) - self.radius",
  "class CoilForceConstraint(ConstraintFunction):\n    \"\"\"\n    Constraint function to constrain the force applied to the coils\n\n    Parameters\n    ----------\n    a_mat:\n        Response matrix\n    b_vec:\n        Target value vector\n    n_PF:\n        Number of PF coils\n    n_CS:\n        Number of CS coils\n    PF_Fz_max:\n        The maximum force in the z direction for a PF coil\n    CS_Fz_sum_max:\n        The total maximum force in the z direction for the CS coils\n    CS_Fz_sep_max:\n        The individual maximum force in the z direction for the CS coils\n    scale:\n        Current scale with which to calculate the constraints\n    \"\"\"\n\n    def __init__(\n        self,\n        a_mat: np.ndarray,\n        b_vec: np.ndarray,\n        n_PF: int,\n        n_CS: int,\n        PF_Fz_max: float,\n        CS_Fz_sum_max: float,\n        CS_Fz_sep_max: float,\n        scale: float,\n    ) -> None:\n        self.a_mat = a_mat\n        self.b_vec = b_vec\n        self.n_PF = n_PF\n        self.n_CS = n_CS\n        self.PF_Fz_max = PF_Fz_max\n        self.CS_Fz_sum_max = CS_Fz_sum_max\n        self.CS_Fz_sep_max = CS_Fz_sep_max\n        self.scale = scale\n\n    def f_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint function\"\"\"\n        n_coils = len(vector)\n        currents = self.scale * vector\n        constraint = np.zeros(n_coils)\n\n        # get coil force and jacobian\n        F = np.zeros((n_coils, 2))\n        PF_Fz_max = self.PF_Fz_max / self.scale\n        CS_Fz_sep_max = self.CS_Fz_sep_max / self.scale\n        CS_Fz_sum_max = self.CS_Fz_sum_max / self.scale\n\n        for i in range(2):  # coil force\n            # NOTE: * Hadamard matrix product\n            F[:, i] = currents * (self.a_mat[:, :, i] @ currents + self.b_vec[:, i])\n\n        F /= self.scale  # Scale down to MN\n\n        # Absolute vertical force constraint on PF coils\n        constraint[: self.n_PF] = F[: self.n_PF, 1] ** 2 - PF_Fz_max**2\n\n        if self.n_CS != 0:\n            # vertical forces on CS coils\n            cs_fz = F[self.n_PF :, 1]\n            # vertical force on CS stack\n            cs_z_sum = np.sum(cs_fz)\n            # Absolute sum of vertical force constraint on entire CS stack\n            constraint[self.n_PF] = cs_z_sum**2 - CS_Fz_sum_max**2\n            for i in range(self.n_CS - 1):  # evaluate each gap in CS stack\n                # CS separation constraints\n                f_sep = np.sum(cs_fz[: i + 1]) - np.sum(cs_fz[i + 1 :])\n                constraint[self.n_PF + 1 + i] = f_sep - CS_Fz_sep_max\n        return constraint\n\n    def df_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint derivative\"\"\"\n        n_coils = vector.size\n        grad = np.zeros((n_coils, n_coils))\n        dF = np.zeros((n_coils, n_coils, 2))  # noqa: N806\n        currents = self.scale * vector\n\n        im = currents.reshape(-1, 1) @ np.ones((1, n_coils))  # current matrix\n        for i in range(2):\n            dF[:, :, i] = im * self.a_mat[:, :, i]\n            diag = (\n                self.a_mat[:, :, i] @ currents\n                + currents * np.diag(self.a_mat[:, :, i])\n                + self.b_vec[:, i]\n            )\n            np.fill_diagonal(dF[:, :, i], diag)\n\n        # Absolute vertical force constraint on PF coils\n        grad[: self.n_PF] = 2 * dF[: self.n_PF, :, 1]\n\n        if self.n_CS != 0:\n            # Absolute sum of vertical force constraint on entire CS stack\n            grad[self.n_PF] = 2 * np.sum(dF[self.n_PF :, :, 1], axis=0)\n\n            for i in range(self.n_CS - 1):  # evaluate each gap in CS stack\n                # CS separation constraint Jacobians\n                f_up = np.sum(dF[self.n_PF : self.n_PF + i + 1, :, 1], axis=0)\n                f_down = np.sum(dF[self.n_PF + i + 1 :, :, 1], axis=0)\n                grad[self.n_PF + 1 + i] = f_up - f_down\n        return grad",
  "def f_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"The constraint function.\"\"\"",
  "def constraint_type(self) -> Literal[\"inequality\", \"equality\"]:\n        \"\"\"The type of constraint\"\"\"\n        try:\n            return self._constraint_type\n        except AttributeError:\n            return \"inequality\"",
  "def constraint_type(self, constraint_t: Literal[\"inequality\", \"equality\"]) -> None:\n        if constraint_t not in [\"inequality\", \"equality\"]:\n            bluemira_warn(\n                f\"Unknown nonlinear constraint type '{constraint_t}', \"\n                \"defaulting to 'inequality'.\"\n            )\n        self._constraint_type = constraint_t",
  "def __init__(\n        self, a_mat: np.ndarray, b_vec: np.ndarray, value: float, scale: float\n    ) -> None:\n        self.a_mat = a_mat\n        self.b_vec = b_vec\n        self.value = value\n        self.scale = scale",
  "def f_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint function\"\"\"\n        return self.a_mat @ (self.scale * vector) - self.b_vec - self.value",
  "def df_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint derivative\"\"\"\n        return self.scale * self.a_mat",
  "def __init__(\n        self,\n        a_mat: npt.NDArray,\n        b_vec: npt.NDArray,\n        value: float,\n        scale: float,\n    ) -> None:\n        self.a_mat = a_mat\n        self.b_vec = b_vec\n        self.value = value\n        self.scale = scale",
  "def f_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint function\"\"\"\n        vector = self.scale * vector\n        residual = self.a_mat @ vector - self.b_vec\n        return residual.T @ residual - self.value",
  "def df_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint derivative\"\"\"\n        vector = self.scale * vector\n        df = 2 * (self.a_mat.T @ self.a_mat @ vector - self.a_mat.T @ self.b_vec)\n        return df * self.scale",
  "def __init__(\n        self,\n        ax_mat: np.ndarray,\n        az_mat: np.ndarray,\n        bxp_vec: np.ndarray,\n        bzp_vec: np.ndarray,\n        B_max: np.ndarray,\n        scale: float,\n    ):\n        self.ax_mat = ax_mat\n        self.az_mat = az_mat\n        self.bxp_vec = bxp_vec\n        self.bzp_vec = bzp_vec\n        self.B_max = B_max\n        self.scale = scale",
  "def f_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint function\"\"\"\n        currents = self.scale * vector\n        Bx_a = self.ax_mat @ currents\n        Bz_a = self.az_mat @ currents\n\n        B = np.hypot(Bx_a + self.bxp_vec, Bz_a + self.bzp_vec)\n        return B - self.B_max",
  "def df_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint derivative\"\"\"\n        currents = self.scale * vector\n        Bx_a = self.ax_mat @ currents\n        Bz_a = self.az_mat @ currents\n        B = np.hypot(Bx_a + self.bxp_vec, Bz_a + self.bzp_vec)\n        return (\n            Bx_a * (Bx_a @ currents + self.bxp_vec)\n            + Bz_a * (Bz_a @ currents + self.bzp_vec)\n        ) / (B * self.scale**2)",
  "def __init__(\n        self,\n        eq: Equilibrium,\n        radius: float,\n        scale: float,\n        inboard: bool,\n    ) -> None:\n        self.eq = eq\n        self.radius = radius\n        self.scale = scale\n        self.inboard = inboard",
  "def f_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint function\"\"\"\n        self.eq.coilset.get_control_coils().current = vector * self.scale\n        lcfs = self.eq.get_LCFS()\n        if self.inboard:\n            return self.radius - min(lcfs.x)\n        return max(lcfs.x) - self.radius",
  "def __init__(\n        self,\n        a_mat: np.ndarray,\n        b_vec: np.ndarray,\n        n_PF: int,\n        n_CS: int,\n        PF_Fz_max: float,\n        CS_Fz_sum_max: float,\n        CS_Fz_sep_max: float,\n        scale: float,\n    ) -> None:\n        self.a_mat = a_mat\n        self.b_vec = b_vec\n        self.n_PF = n_PF\n        self.n_CS = n_CS\n        self.PF_Fz_max = PF_Fz_max\n        self.CS_Fz_sum_max = CS_Fz_sum_max\n        self.CS_Fz_sep_max = CS_Fz_sep_max\n        self.scale = scale",
  "def f_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint function\"\"\"\n        n_coils = len(vector)\n        currents = self.scale * vector\n        constraint = np.zeros(n_coils)\n\n        # get coil force and jacobian\n        F = np.zeros((n_coils, 2))\n        PF_Fz_max = self.PF_Fz_max / self.scale\n        CS_Fz_sep_max = self.CS_Fz_sep_max / self.scale\n        CS_Fz_sum_max = self.CS_Fz_sum_max / self.scale\n\n        for i in range(2):  # coil force\n            # NOTE: * Hadamard matrix product\n            F[:, i] = currents * (self.a_mat[:, :, i] @ currents + self.b_vec[:, i])\n\n        F /= self.scale  # Scale down to MN\n\n        # Absolute vertical force constraint on PF coils\n        constraint[: self.n_PF] = F[: self.n_PF, 1] ** 2 - PF_Fz_max**2\n\n        if self.n_CS != 0:\n            # vertical forces on CS coils\n            cs_fz = F[self.n_PF :, 1]\n            # vertical force on CS stack\n            cs_z_sum = np.sum(cs_fz)\n            # Absolute sum of vertical force constraint on entire CS stack\n            constraint[self.n_PF] = cs_z_sum**2 - CS_Fz_sum_max**2\n            for i in range(self.n_CS - 1):  # evaluate each gap in CS stack\n                # CS separation constraints\n                f_sep = np.sum(cs_fz[: i + 1]) - np.sum(cs_fz[i + 1 :])\n                constraint[self.n_PF + 1 + i] = f_sep - CS_Fz_sep_max\n        return constraint",
  "def df_constraint(self, vector: npt.NDArray) -> npt.NDArray:\n        \"\"\"Constraint derivative\"\"\"\n        n_coils = vector.size\n        grad = np.zeros((n_coils, n_coils))\n        dF = np.zeros((n_coils, n_coils, 2))  # noqa: N806\n        currents = self.scale * vector\n\n        im = currents.reshape(-1, 1) @ np.ones((1, n_coils))  # current matrix\n        for i in range(2):\n            dF[:, :, i] = im * self.a_mat[:, :, i]\n            diag = (\n                self.a_mat[:, :, i] @ currents\n                + currents * np.diag(self.a_mat[:, :, i])\n                + self.b_vec[:, i]\n            )\n            np.fill_diagonal(dF[:, :, i], diag)\n\n        # Absolute vertical force constraint on PF coils\n        grad[: self.n_PF] = 2 * dF[: self.n_PF, :, 1]\n\n        if self.n_CS != 0:\n            # Absolute sum of vertical force constraint on entire CS stack\n            grad[self.n_PF] = 2 * np.sum(dF[self.n_PF :, :, 1], axis=0)\n\n            for i in range(self.n_CS - 1):  # evaluate each gap in CS stack\n                # CS separation constraint Jacobians\n                f_up = np.sum(dF[self.n_PF : self.n_PF + i + 1, :, 1], axis=0)\n                f_down = np.sum(dF[self.n_PF + i + 1 :, :, 1], axis=0)\n                grad[self.n_PF + 1 + i] = f_up - f_down\n        return grad",
  "class CoilsetOptimiserResult:\n    \"\"\"Coilset optimisation result object\"\"\"\n\n    coilset: CoilSet\n    \"\"\"The optimised coilset.\"\"\"\n    f_x: float\n    \"\"\"The evaluation of the optimised parameterisation.\"\"\"\n    n_evals: int\n    \"\"\"The number of evaluations of the objective function in the optimisation.\"\"\"\n    history: List[Tuple[np.ndarray, float]] = field(repr=False)\n    \"\"\"\n    The history of the parametrisation at each iteration.\n\n    The first element of each tuple is the parameterisation (x), the\n    second is the evaluation of the objective function at x (f(x)).\n    \"\"\"\n    constraints_satisfied: Union[bool, None] = None\n    \"\"\"\n    Whether all constraints have been satisfied to within the required tolerance.\n\n    Is ``None`` if constraints have not been checked.\n    \"\"\"\n\n    @classmethod\n    def from_opt_result(\n        cls, coilset: CoilSet, opt_result: OptimiserResult\n    ) -> CoilsetOptimiserResult:\n        \"\"\"Make a coilset optimisation result from a normal optimisation result.\"\"\"\n        return cls(\n            coilset=coilset,\n            f_x=opt_result.f_x,\n            n_evals=opt_result.n_evals,\n            history=opt_result.history,\n            constraints_satisfied=opt_result.constraints_satisfied,\n        )",
  "class CoilsetOptimisationProblem(abc.ABC):\n    \"\"\"\n    Abstract base class for coilset optimisation problems.\n\n    Subclasses should provide an optimise() method that\n    returns an optimised coilset object, optimised according\n    to a specific objective function for that subclass.\n    \"\"\"\n\n    def _opt_condition_defaults(\n        self, default_cond=Dict[str, Union[float, int]]\n    ) -> Dict[str, Union[float, int]]:\n        algorithm = (\n            Algorithm[self.opt_algorithm]\n            if not isinstance(self.opt_algorithm, Algorithm)\n            else self.opt_algorithm\n        )\n\n        return {\n            **getattr(AlgorithmDefaultConditions(), algorithm.name).to_dict(),\n            **default_cond,\n        }\n\n    @abc.abstractmethod\n    def optimise(self, **kwargs) -> CoilsetOptimiserResult:\n        \"\"\"Run the coilset optimisation.\"\"\"\n\n    @property\n    def coilset(self) -> CoilSet:\n        \"\"\"The optimisation problem coilset\"\"\"\n        return self._coilset\n\n    @coilset.setter\n    def coilset(self, value: CoilSet):\n        self._coilset = value\n\n    @staticmethod\n    def read_coilset_state(\n        coilset: CoilSet, current_scale: float\n    ) -> Tuple[npt.NDArray, int]:\n        \"\"\"\n        Reads the input coilset and generates the state vector as an array to represent\n        it.\n\n        Parameters\n        ----------\n        coilset: Coilset\n            Coilset to be read into the state vector.\n        current_scale: float\n            Factor to scale coilset currents down by for population of coilset_state.\n            Used to minimise round-off errors in optimisation.\n\n        Returns\n        -------\n        State vector containing substate (position and current)\n        information for each coil.\n\n        Number of substates (blocks) in the state vector.\n        \"\"\"\n        substates = 3\n        x, z = coilset.position\n        currents = coilset.current / current_scale\n\n        coilset_state = np.concatenate((x, z, currents))\n        return coilset_state, substates\n\n    @staticmethod\n    def set_coilset_state(\n        coilset: CoilSet, coilset_state: npt.NDArray, current_scale: float\n    ):\n        \"\"\"\n        Set the optimiser coilset from a provided state vector.\n\n        Parameters\n        ----------\n        coilset:\n            Coilset to set from state vector.\n        coilset_state:\n            State vector representing degrees of freedom of the coilset,\n            to be used to update the coilset.\n        current_scale:\n            Factor to scale state vector currents up by when setting\n            coilset currents.\n            Used to minimise round-off errors in optimisation.\n        \"\"\"\n        x, z, currents = np.array_split(coilset_state, 3)\n\n        coilset.x = x\n        coilset.z = z\n        coilset.current = currents * current_scale\n\n    @staticmethod\n    def get_state_bounds(\n        x_bounds: Tuple[npt.NDArray, npt.NDArray],\n        z_bounds: Tuple[npt.NDArray, npt.NDArray],\n        current_bounds: Tuple[npt.NDArray, npt.NDArray],\n    ) -> Tuple[npt.NDArray, npt.NDArray]:\n        \"\"\"\n        Get bounds on the state vector from provided bounds on the substates.\n\n        Parameters\n        ----------\n        x_bounds:\n            Tuple containing lower and upper bounds on the radial coil positions.\n        z_bounds:\n            Tuple containing lower and upper bounds on the vertical coil positions.\n        current_bounds:\n            Tuple containing bounds on the coil currents.\n\n        Returns\n        -------\n        Array containing state vectors representing lower and upper bounds\n        for coilset state degrees of freedom.\n        \"\"\"\n        lower_bounds = np.concatenate((x_bounds[0], z_bounds[0], current_bounds[0]))\n        upper_bounds = np.concatenate((x_bounds[1], z_bounds[1], current_bounds[1]))\n        bounds = np.array([lower_bounds, upper_bounds])\n        return bounds\n\n    @staticmethod\n    def get_current_bounds(\n        coilset: CoilSet, max_currents: npt.ArrayLike, current_scale: float\n    ):\n        \"\"\"\n        Gets the scaled current vector bounds. Must be called prior to optimise.\n\n        Parameters\n        ----------\n        coilset:\n            Coilset to fetch current bounds for.\n        max_currents:\n            Maximum magnitude of currents in each coil [A] permitted during optimisation.\n            If max_current is supplied as a float, the float will be set as the\n            maximum allowed current magnitude for all coils.\n            If the coils have current density limits that are more restrictive than these\n            coil currents, the smaller current limit of the two will be used for each\n            coil.\n        current_scale:\n            Factor to scale coilset currents down when returning scaled current limits.\n\n        Returns\n        -------\n        current_bounds: (np.narray, np.narray)\n            Tuple of arrays containing lower and upper bounds for currents\n            permitted in each control coil.\n        \"\"\"\n        n_control_currents = len(coilset.current[coilset._control_ind])\n        scaled_input_current_limits = np.inf * np.ones(n_control_currents)\n\n        if max_currents is not None:\n            input_current_limits = np.asarray(max_currents)\n            input_size = np.size(np.asarray(input_current_limits))\n            if input_size == 1 or input_size == n_control_currents:\n                scaled_input_current_limits = input_current_limits / current_scale\n            else:\n                raise EquilibriaError(\n                    \"Length of max_currents array provided to optimiser is not\"\n                    \"equal to the number of control currents present.\"\n                )\n\n        # Get the current limits from coil current densities\n        coilset_current_limits = np.infty * np.ones(n_control_currents)\n        coilset_current_limits[coilset._flag_sizefix] = coilset.get_max_current()[\n            coilset._flag_sizefix\n        ]\n\n        # Limit the control current magnitude by the smaller of the two limits\n        control_current_limits = np.minimum(\n            scaled_input_current_limits, coilset_current_limits\n        )\n        current_bounds = (-control_current_limits, control_current_limits)\n\n        return current_bounds\n\n    def set_current_bounds(self, max_currents: npt.NDArray) -> None:\n        \"\"\"\n        Set the current bounds on this instance.\n\n        Parameters\n        ----------\n        max_currents:\n            Vector of maximum currents [A]\n        \"\"\"\n        n_control_currents = len(self.coilset.current[self.coilset._control_ind])\n        if len(max_currents) != n_control_currents:\n            raise ValueError(\n                \"Length of maximum current vector must be equal to the number of controls.\"\n            )\n\n        # TODO: sort out this interface\n        upper_bounds = np.abs(max_currents) / self.scale\n        lower_bounds = -upper_bounds\n        self.bounds = (lower_bounds, upper_bounds)\n\n    def update_magnetic_constraints(\n        self, I_not_dI: bool = True, fixed_coils: bool = True\n    ):\n        \"\"\"\n        Update the magnetic optimisation constraints with the state of the Equilibrium\n        \"\"\"\n        if not hasattr(self, \"_constraints\"):\n            return\n        for constraint in self._constraints:\n            if isinstance(constraint, UpdateableConstraint):\n                constraint.prepare(self.eq, I_not_dI=I_not_dI, fixed_coils=fixed_coils)\n            if \"scale\" in constraint._args:\n                constraint._args[\"scale\"] = self.scale\n\n    def _make_numerical_constraints(\n        self,\n    ) -> Tuple[List[ConstraintT], List[ConstraintT]]:\n        \"\"\"Build the numerical equality and inequality constraint dictionaries.\"\"\"\n        if (constraints := getattr(self, \"_constraints\", None)) is None:\n            return [], []\n        equality = []\n        inequality = []\n        for constraint in constraints:\n            f_constraint = constraint.f_constraint()\n            d: ConstraintT = {\n                \"f_constraint\": f_constraint.f_constraint,\n                \"df_constraint\": getattr(f_constraint, \"df_constraint\", None),\n                \"tolerance\": constraint.tolerance,\n            }\n            # TODO: tidy this up, so the interface guarantees this works!\n            if getattr(constraint, \"constraint_type\", \"inequality\") == \"equality\":\n                equality.append(d)\n            else:\n                inequality.append(d)\n        return equality, inequality\n\n    @property\n    def scale(self) -> float:\n        \"\"\"Problem scaling value\"\"\"\n        return 1e6",
  "def from_opt_result(\n        cls, coilset: CoilSet, opt_result: OptimiserResult\n    ) -> CoilsetOptimiserResult:\n        \"\"\"Make a coilset optimisation result from a normal optimisation result.\"\"\"\n        return cls(\n            coilset=coilset,\n            f_x=opt_result.f_x,\n            n_evals=opt_result.n_evals,\n            history=opt_result.history,\n            constraints_satisfied=opt_result.constraints_satisfied,\n        )",
  "def _opt_condition_defaults(\n        self, default_cond=Dict[str, Union[float, int]]\n    ) -> Dict[str, Union[float, int]]:\n        algorithm = (\n            Algorithm[self.opt_algorithm]\n            if not isinstance(self.opt_algorithm, Algorithm)\n            else self.opt_algorithm\n        )\n\n        return {\n            **getattr(AlgorithmDefaultConditions(), algorithm.name).to_dict(),\n            **default_cond,\n        }",
  "def optimise(self, **kwargs) -> CoilsetOptimiserResult:\n        \"\"\"Run the coilset optimisation.\"\"\"",
  "def coilset(self) -> CoilSet:\n        \"\"\"The optimisation problem coilset\"\"\"\n        return self._coilset",
  "def coilset(self, value: CoilSet):\n        self._coilset = value",
  "def read_coilset_state(\n        coilset: CoilSet, current_scale: float\n    ) -> Tuple[npt.NDArray, int]:\n        \"\"\"\n        Reads the input coilset and generates the state vector as an array to represent\n        it.\n\n        Parameters\n        ----------\n        coilset: Coilset\n            Coilset to be read into the state vector.\n        current_scale: float\n            Factor to scale coilset currents down by for population of coilset_state.\n            Used to minimise round-off errors in optimisation.\n\n        Returns\n        -------\n        State vector containing substate (position and current)\n        information for each coil.\n\n        Number of substates (blocks) in the state vector.\n        \"\"\"\n        substates = 3\n        x, z = coilset.position\n        currents = coilset.current / current_scale\n\n        coilset_state = np.concatenate((x, z, currents))\n        return coilset_state, substates",
  "def set_coilset_state(\n        coilset: CoilSet, coilset_state: npt.NDArray, current_scale: float\n    ):\n        \"\"\"\n        Set the optimiser coilset from a provided state vector.\n\n        Parameters\n        ----------\n        coilset:\n            Coilset to set from state vector.\n        coilset_state:\n            State vector representing degrees of freedom of the coilset,\n            to be used to update the coilset.\n        current_scale:\n            Factor to scale state vector currents up by when setting\n            coilset currents.\n            Used to minimise round-off errors in optimisation.\n        \"\"\"\n        x, z, currents = np.array_split(coilset_state, 3)\n\n        coilset.x = x\n        coilset.z = z\n        coilset.current = currents * current_scale",
  "def get_state_bounds(\n        x_bounds: Tuple[npt.NDArray, npt.NDArray],\n        z_bounds: Tuple[npt.NDArray, npt.NDArray],\n        current_bounds: Tuple[npt.NDArray, npt.NDArray],\n    ) -> Tuple[npt.NDArray, npt.NDArray]:\n        \"\"\"\n        Get bounds on the state vector from provided bounds on the substates.\n\n        Parameters\n        ----------\n        x_bounds:\n            Tuple containing lower and upper bounds on the radial coil positions.\n        z_bounds:\n            Tuple containing lower and upper bounds on the vertical coil positions.\n        current_bounds:\n            Tuple containing bounds on the coil currents.\n\n        Returns\n        -------\n        Array containing state vectors representing lower and upper bounds\n        for coilset state degrees of freedom.\n        \"\"\"\n        lower_bounds = np.concatenate((x_bounds[0], z_bounds[0], current_bounds[0]))\n        upper_bounds = np.concatenate((x_bounds[1], z_bounds[1], current_bounds[1]))\n        bounds = np.array([lower_bounds, upper_bounds])\n        return bounds",
  "def get_current_bounds(\n        coilset: CoilSet, max_currents: npt.ArrayLike, current_scale: float\n    ):\n        \"\"\"\n        Gets the scaled current vector bounds. Must be called prior to optimise.\n\n        Parameters\n        ----------\n        coilset:\n            Coilset to fetch current bounds for.\n        max_currents:\n            Maximum magnitude of currents in each coil [A] permitted during optimisation.\n            If max_current is supplied as a float, the float will be set as the\n            maximum allowed current magnitude for all coils.\n            If the coils have current density limits that are more restrictive than these\n            coil currents, the smaller current limit of the two will be used for each\n            coil.\n        current_scale:\n            Factor to scale coilset currents down when returning scaled current limits.\n\n        Returns\n        -------\n        current_bounds: (np.narray, np.narray)\n            Tuple of arrays containing lower and upper bounds for currents\n            permitted in each control coil.\n        \"\"\"\n        n_control_currents = len(coilset.current[coilset._control_ind])\n        scaled_input_current_limits = np.inf * np.ones(n_control_currents)\n\n        if max_currents is not None:\n            input_current_limits = np.asarray(max_currents)\n            input_size = np.size(np.asarray(input_current_limits))\n            if input_size == 1 or input_size == n_control_currents:\n                scaled_input_current_limits = input_current_limits / current_scale\n            else:\n                raise EquilibriaError(\n                    \"Length of max_currents array provided to optimiser is not\"\n                    \"equal to the number of control currents present.\"\n                )\n\n        # Get the current limits from coil current densities\n        coilset_current_limits = np.infty * np.ones(n_control_currents)\n        coilset_current_limits[coilset._flag_sizefix] = coilset.get_max_current()[\n            coilset._flag_sizefix\n        ]\n\n        # Limit the control current magnitude by the smaller of the two limits\n        control_current_limits = np.minimum(\n            scaled_input_current_limits, coilset_current_limits\n        )\n        current_bounds = (-control_current_limits, control_current_limits)\n\n        return current_bounds",
  "def set_current_bounds(self, max_currents: npt.NDArray) -> None:\n        \"\"\"\n        Set the current bounds on this instance.\n\n        Parameters\n        ----------\n        max_currents:\n            Vector of maximum currents [A]\n        \"\"\"\n        n_control_currents = len(self.coilset.current[self.coilset._control_ind])\n        if len(max_currents) != n_control_currents:\n            raise ValueError(\n                \"Length of maximum current vector must be equal to the number of controls.\"\n            )\n\n        # TODO: sort out this interface\n        upper_bounds = np.abs(max_currents) / self.scale\n        lower_bounds = -upper_bounds\n        self.bounds = (lower_bounds, upper_bounds)",
  "def update_magnetic_constraints(\n        self, I_not_dI: bool = True, fixed_coils: bool = True\n    ):\n        \"\"\"\n        Update the magnetic optimisation constraints with the state of the Equilibrium\n        \"\"\"\n        if not hasattr(self, \"_constraints\"):\n            return\n        for constraint in self._constraints:\n            if isinstance(constraint, UpdateableConstraint):\n                constraint.prepare(self.eq, I_not_dI=I_not_dI, fixed_coils=fixed_coils)\n            if \"scale\" in constraint._args:\n                constraint._args[\"scale\"] = self.scale",
  "def _make_numerical_constraints(\n        self,\n    ) -> Tuple[List[ConstraintT], List[ConstraintT]]:\n        \"\"\"Build the numerical equality and inequality constraint dictionaries.\"\"\"\n        if (constraints := getattr(self, \"_constraints\", None)) is None:\n            return [], []\n        equality = []\n        inequality = []\n        for constraint in constraints:\n            f_constraint = constraint.f_constraint()\n            d: ConstraintT = {\n                \"f_constraint\": f_constraint.f_constraint,\n                \"df_constraint\": getattr(f_constraint, \"df_constraint\", None),\n                \"tolerance\": constraint.tolerance,\n            }\n            # TODO: tidy this up, so the interface guarantees this works!\n            if getattr(constraint, \"constraint_type\", \"inequality\") == \"equality\":\n                equality.append(d)\n            else:\n                inequality.append(d)\n        return equality, inequality",
  "def scale(self) -> float:\n        \"\"\"Problem scaling value\"\"\"\n        return 1e6",
  "class CoilsetPositionCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Coilset OptimisationProblem for coil currents and positions\n    subject to maximum current bounds and positions bounded within\n    a provided region.\n\n    Coil currents and positions are optimised simultaneously.\n\n    Parameters\n    ----------\n    coilset:\n        Coilset to optimise.\n    eq:\n        Equilibrium object used to update magnetic field targets.\n    targets:\n        Set of magnetic field targets to use in objective function.\n    position_mapper:\n        Position mappings of coil regions\n    max_currents:\n        Maximum allowed current for each independent coil current in coilset [A].\n        If specified as a float, the float will set the maximum allowed current\n        for all coils.\n    gamma:\n        Tikhonov regularisation parameter in units of [A\u207b\u00b9].\n    opt_algorithm:\n        The optimisation algorithm to use (e.g. SLSQP)\n    opt_conditions:\n        The stopping conditions for the optimiser.\n        for defaults see\n        :class:`~bluemira.optimisation._algorithm.AlgorithDefaultTolerances`\n        along with `max_eval=100`\n\n    constraints:\n        contraints on the problem\n\n    Notes\n    -----\n    Setting stopval and maxeval is the most reliable way to stop optimisation\n    at the desired figure of merit and number of iterations respectively.\n    Some NLOpt optimisers display unexpected behaviour when setting xtol and\n    ftol, and may not terminate as expected when those criteria are reached.\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        position_mapper: PositionMapper,\n        max_currents: Optional[npt.ArrayLike] = None,\n        gamma=1e-8,\n        opt_algorithm: AlgorithmType = Algorithm.SBPLX,\n        opt_conditions: Optional[Dict[str, float]] = None,\n        constraints: Optional[List[UpdateableConstraint]] = None,\n    ):\n        self.coilset = coilset\n        self.eq = eq\n        self.targets = targets\n        self.position_mapper = position_mapper\n        self.bounds = self.get_mapped_state_bounds(max_currents)\n        self.gamma = gamma\n        self.opt_algorithm = opt_algorithm\n        self.opt_conditions = opt_conditions or self._opt_condition_defaults(\n            {\"max_eval\": 100}\n        )\n        self._constraints = [] if constraints is None else constraints\n\n    def optimise(self, **_) -> CoilsetOptimiserResult:\n        \"\"\"\n        Run the optimisation.\n\n        Returns\n        -------\n        The result of the optimisation.\n        \"\"\"\n        # Get initial state and apply region mapping to coil positions.\n        initial_state, _ = self.read_coilset_state(self.coilset, self.scale)\n        initial_x, initial_z, initial_currents = np.array_split(initial_state, 3)\n        initial_mapped_positions = self.position_mapper.to_L(initial_x, initial_z)\n        eq_constraints, ineq_constraints = self._make_numerical_constraints()\n        opt_result = optimise(\n            f_objective=self.objective,\n            x0=np.concatenate((initial_mapped_positions, initial_currents)),\n            opt_conditions=self.opt_conditions,\n            algorithm=self.opt_algorithm,\n            eq_constraints=eq_constraints,\n            ineq_constraints=ineq_constraints,\n        )\n        self.set_coilset_state(self.coilset, opt_result.x, self.scale)\n        return CoilsetOptimiserResult.from_opt_result(self.coilset, opt_result)\n\n    def objective(self, vector: npt.NDArray) -> float:\n        \"\"\"\n        Least-squares objective with Tikhonov regularisation term.\n\n        Parameters\n        ----------\n        vector:\n            The new coilset state vector.\n\n        Returns\n        -------\n        The figure of merit being minimised.\n        \"\"\"\n        # Update the coilset with the new state vector\n        mapped_x, mapped_z, currents = np.array_split(vector, 3)\n        mapped_positions = np.concatenate((mapped_x, mapped_z))\n        x_vals, z_vals = self.position_mapper.to_xz(mapped_positions)\n        coilset_state = np.concatenate((x_vals, z_vals, currents))\n        self.set_coilset_state(self.coilset, coilset_state, self.scale)\n\n        # Update target\n        self.eq._remap_greens()\n\n        # Scale the control matrix and constraint vector by weights.\n        self.targets(self.eq, I_not_dI=True, fixed_coils=False)\n        _, a_mat, b_vec = self.targets.get_weighted_arrays()\n\n        return regularised_lsq_fom(currents * self.scale, a_mat, b_vec, self.gamma)[0]\n\n    def get_mapped_state_bounds(self, max_currents: Optional[npt.ArrayLike] = None):\n        \"\"\"\n        Get mapped bounds on the coilset state vector from the coil regions and\n        maximum coil currents.\n\n        Parameters\n        ----------\n        region_mapper:\n            RegionMapper mapping coil positions within the allowed optimisation\n            regions.\n        max_currents:\n            Maximum allowed current for each independent coil current in coilset [A].\n            If specified as a float, the float will set the maximum allowed current\n            for all coils.\n\n        Returns\n        -------\n        bounds: np.array\n            Array containing state vectors representing lower and upper bounds\n            for coilset state degrees of freedom.\n        \"\"\"\n        # Get mapped position bounds from RegionMapper\n        opt_dimension = self.position_mapper.dimension\n        lower_pos_bounds, upper_pos_bounds = (\n            np.zeros(opt_dimension),\n            np.ones(opt_dimension),\n        )\n        current_bounds = self.get_current_bounds(self.coilset, max_currents, self.scale)\n\n        return (\n            np.concatenate((lower_pos_bounds, current_bounds[0])),\n            np.concatenate((upper_pos_bounds, current_bounds[1])),\n        )",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        position_mapper: PositionMapper,\n        max_currents: Optional[npt.ArrayLike] = None,\n        gamma=1e-8,\n        opt_algorithm: AlgorithmType = Algorithm.SBPLX,\n        opt_conditions: Optional[Dict[str, float]] = None,\n        constraints: Optional[List[UpdateableConstraint]] = None,\n    ):\n        self.coilset = coilset\n        self.eq = eq\n        self.targets = targets\n        self.position_mapper = position_mapper\n        self.bounds = self.get_mapped_state_bounds(max_currents)\n        self.gamma = gamma\n        self.opt_algorithm = opt_algorithm\n        self.opt_conditions = opt_conditions or self._opt_condition_defaults(\n            {\"max_eval\": 100}\n        )\n        self._constraints = [] if constraints is None else constraints",
  "def optimise(self, **_) -> CoilsetOptimiserResult:\n        \"\"\"\n        Run the optimisation.\n\n        Returns\n        -------\n        The result of the optimisation.\n        \"\"\"\n        # Get initial state and apply region mapping to coil positions.\n        initial_state, _ = self.read_coilset_state(self.coilset, self.scale)\n        initial_x, initial_z, initial_currents = np.array_split(initial_state, 3)\n        initial_mapped_positions = self.position_mapper.to_L(initial_x, initial_z)\n        eq_constraints, ineq_constraints = self._make_numerical_constraints()\n        opt_result = optimise(\n            f_objective=self.objective,\n            x0=np.concatenate((initial_mapped_positions, initial_currents)),\n            opt_conditions=self.opt_conditions,\n            algorithm=self.opt_algorithm,\n            eq_constraints=eq_constraints,\n            ineq_constraints=ineq_constraints,\n        )\n        self.set_coilset_state(self.coilset, opt_result.x, self.scale)\n        return CoilsetOptimiserResult.from_opt_result(self.coilset, opt_result)",
  "def objective(self, vector: npt.NDArray) -> float:\n        \"\"\"\n        Least-squares objective with Tikhonov regularisation term.\n\n        Parameters\n        ----------\n        vector:\n            The new coilset state vector.\n\n        Returns\n        -------\n        The figure of merit being minimised.\n        \"\"\"\n        # Update the coilset with the new state vector\n        mapped_x, mapped_z, currents = np.array_split(vector, 3)\n        mapped_positions = np.concatenate((mapped_x, mapped_z))\n        x_vals, z_vals = self.position_mapper.to_xz(mapped_positions)\n        coilset_state = np.concatenate((x_vals, z_vals, currents))\n        self.set_coilset_state(self.coilset, coilset_state, self.scale)\n\n        # Update target\n        self.eq._remap_greens()\n\n        # Scale the control matrix and constraint vector by weights.\n        self.targets(self.eq, I_not_dI=True, fixed_coils=False)\n        _, a_mat, b_vec = self.targets.get_weighted_arrays()\n\n        return regularised_lsq_fom(currents * self.scale, a_mat, b_vec, self.gamma)[0]",
  "def get_mapped_state_bounds(self, max_currents: Optional[npt.ArrayLike] = None):\n        \"\"\"\n        Get mapped bounds on the coilset state vector from the coil regions and\n        maximum coil currents.\n\n        Parameters\n        ----------\n        region_mapper:\n            RegionMapper mapping coil positions within the allowed optimisation\n            regions.\n        max_currents:\n            Maximum allowed current for each independent coil current in coilset [A].\n            If specified as a float, the float will set the maximum allowed current\n            for all coils.\n\n        Returns\n        -------\n        bounds: np.array\n            Array containing state vectors representing lower and upper bounds\n            for coilset state degrees of freedom.\n        \"\"\"\n        # Get mapped position bounds from RegionMapper\n        opt_dimension = self.position_mapper.dimension\n        lower_pos_bounds, upper_pos_bounds = (\n            np.zeros(opt_dimension),\n            np.ones(opt_dimension),\n        )\n        current_bounds = self.get_current_bounds(self.coilset, max_currents, self.scale)\n\n        return (\n            np.concatenate((lower_pos_bounds, current_bounds[0])),\n            np.concatenate((upper_pos_bounds, current_bounds[1])),\n        )",
  "class TikhonovCurrentCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Coilset OptimisationProblem for coil currents subject to maximum current bounds.\n\n    Coilset currents optimised using objectives.regularised_lsq_objective as\n    objective function.\n\n    Parameters\n    ----------\n    coilset:\n        Coilset to optimise.\n    eq:\n        Equilibrium object used to update magnetic field targets.\n    targets:\n        Set of magnetic field targets to use in objective function.\n    gamma:\n        Tikhonov regularisation parameter in units of [A\u207b\u00b9].\n    opt_algorithm:\n        Optimiser algorithm\n    opt_conditions:\n        optimiser conditions\n        for defaults see\n        :class:`~bluemira.optimisation._algorithm.AlgorithDefaultTolerances`\n        along with `max_eval=100`\n    opt_parameters:\n        optimisation parameters\n    max_currents:\n        Maximum allowed current for each independent coil current in coilset [A].\n        If specified as a float, the float will set the maximum allowed current\n        for all coils.\n    constraints:\n        Optional list of UpdatableConstraint objects storing\n        information about constraints that must be satisfied\n        during the coilset optimisation, to be provided to the\n        optimiser.\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        gamma: float,\n        opt_algorithm: AlgorithmType = Algorithm.SLSQP,\n        opt_conditions: Optional[Dict[str, Union[float, int]]] = None,\n        opt_parameters: Optional[Dict[str, float]] = None,\n        max_currents: Optional[npt.ArrayLike] = None,\n        constraints: Optional[List[UpdateableConstraint]] = None,\n    ):\n        self.coilset = coilset\n        self.eq = eq\n        self.targets = targets\n        self.gamma = gamma\n        self.bounds = self.get_current_bounds(self.coilset, max_currents, self.scale)\n        self.opt_algorithm = opt_algorithm\n        self.opt_conditions = opt_conditions or self._opt_condition_defaults(\n            {\"max_eval\": 100}\n        )\n        self.opt_parameters = (\n            {\"initial_step\": 0.03} if opt_parameters is None else opt_parameters\n        )\n        self._constraints = [] if constraints is None else constraints\n\n    def optimise(self, x0=None, fixed_coils=True) -> CoilsetOptimiserResult:\n        \"\"\"\n        Solve the optimisation problem\n\n        Parameters\n        ----------\n        fixed_coils:\n            Whether or not to update to coilset response matrices\n\n        Returns\n        -------\n        coilset:\n            Optimised CoilSet\n        \"\"\"\n        # Scale the control matrix and magnetic field targets vector by weights.\n        self.targets(self.eq, I_not_dI=True, fixed_coils=fixed_coils)\n        _, a_mat, b_vec = self.targets.get_weighted_arrays()\n        self.update_magnetic_constraints(I_not_dI=True, fixed_coils=fixed_coils)\n\n        if x0 is None:\n            initial_state, n_states = self.read_coilset_state(self.coilset, self.scale)\n            _, _, initial_currents = np.array_split(initial_state, n_states)\n            x0 = np.clip(initial_currents, *self.bounds)\n\n        objective = RegularisedLsqObjective(\n            scale=self.scale,\n            a_mat=a_mat,\n            b_vec=b_vec,\n            gamma=self.gamma,\n        )\n        eq_constraints, ineq_constraints = self._make_numerical_constraints()\n        opt_result = optimise(\n            f_objective=objective.f_objective,\n            df_objective=getattr(objective, \"df_objective\", None),\n            x0=x0,\n            bounds=self.bounds,\n            opt_conditions=self.opt_conditions,\n            algorithm=self.opt_algorithm,\n            opt_parameters=self.opt_parameters,\n            eq_constraints=eq_constraints,\n            ineq_constraints=ineq_constraints,\n        )\n        currents = opt_result.x\n        self.coilset.get_control_coils().current = currents * self.scale\n        return CoilsetOptimiserResult.from_opt_result(self.coilset, opt_result)",
  "class UnconstrainedTikhonovCurrentGradientCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Unbounded, unconstrained, analytically optimised current gradient vector for minimal\n    error to the L2-norm of a set of magnetic constraints (used here as targets).\n\n    This is useful for getting a preliminary Equilibrium\n\n    Parameters\n    ----------\n    coilset:\n        CoilSet object to optimise with\n    eq:\n        Equilibrium object to optimise for\n    targets:\n        Set of magnetic constraints to minimise the error for\n    gamma:\n        Tikhonov regularisation parameter [1/A]\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        gamma: float,\n    ):\n        self.coilset = coilset\n        self.eq = eq\n        self.targets = targets\n        self.gamma = gamma\n\n    def optimise(self, **_) -> CoilsetOptimiserResult:\n        \"\"\"\n        Optimise the prescribed problem.\n\n        Notes\n        -----\n        The weight vector is used to scale the response matrix and\n        constraint vector. The weights are assumed to be uncorrelated, such that the\n        weight matrix W_ij used to define (for example) the least-squares objective\n        function (Ax - b)\u1d40 W (Ax - b), is diagonal, such that\n        weights[i] = w[i] = sqrt(W[i,i]).\n        \"\"\"\n        # Scale the control matrix and magnetic field targets vector by weights.\n        self.targets(self.eq, I_not_dI=False)\n        _, a_mat, b_vec = self.targets.get_weighted_arrays()\n\n        # Optimise currents using analytic expression for optimum.\n        current_adjustment = tikhonov(a_mat, b_vec, self.gamma)\n\n        # Update parameterisation (coilset).\n        self.coilset.current = self.coilset.current + current_adjustment\n        return CoilsetOptimiserResult(\n            coilset=self.coilset,\n            f_x=self.coilset.current,\n            n_evals=0,\n            history=[],\n            constraints_satisfied=True,\n        )",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        gamma: float,\n        opt_algorithm: AlgorithmType = Algorithm.SLSQP,\n        opt_conditions: Optional[Dict[str, Union[float, int]]] = None,\n        opt_parameters: Optional[Dict[str, float]] = None,\n        max_currents: Optional[npt.ArrayLike] = None,\n        constraints: Optional[List[UpdateableConstraint]] = None,\n    ):\n        self.coilset = coilset\n        self.eq = eq\n        self.targets = targets\n        self.gamma = gamma\n        self.bounds = self.get_current_bounds(self.coilset, max_currents, self.scale)\n        self.opt_algorithm = opt_algorithm\n        self.opt_conditions = opt_conditions or self._opt_condition_defaults(\n            {\"max_eval\": 100}\n        )\n        self.opt_parameters = (\n            {\"initial_step\": 0.03} if opt_parameters is None else opt_parameters\n        )\n        self._constraints = [] if constraints is None else constraints",
  "def optimise(self, x0=None, fixed_coils=True) -> CoilsetOptimiserResult:\n        \"\"\"\n        Solve the optimisation problem\n\n        Parameters\n        ----------\n        fixed_coils:\n            Whether or not to update to coilset response matrices\n\n        Returns\n        -------\n        coilset:\n            Optimised CoilSet\n        \"\"\"\n        # Scale the control matrix and magnetic field targets vector by weights.\n        self.targets(self.eq, I_not_dI=True, fixed_coils=fixed_coils)\n        _, a_mat, b_vec = self.targets.get_weighted_arrays()\n        self.update_magnetic_constraints(I_not_dI=True, fixed_coils=fixed_coils)\n\n        if x0 is None:\n            initial_state, n_states = self.read_coilset_state(self.coilset, self.scale)\n            _, _, initial_currents = np.array_split(initial_state, n_states)\n            x0 = np.clip(initial_currents, *self.bounds)\n\n        objective = RegularisedLsqObjective(\n            scale=self.scale,\n            a_mat=a_mat,\n            b_vec=b_vec,\n            gamma=self.gamma,\n        )\n        eq_constraints, ineq_constraints = self._make_numerical_constraints()\n        opt_result = optimise(\n            f_objective=objective.f_objective,\n            df_objective=getattr(objective, \"df_objective\", None),\n            x0=x0,\n            bounds=self.bounds,\n            opt_conditions=self.opt_conditions,\n            algorithm=self.opt_algorithm,\n            opt_parameters=self.opt_parameters,\n            eq_constraints=eq_constraints,\n            ineq_constraints=ineq_constraints,\n        )\n        currents = opt_result.x\n        self.coilset.get_control_coils().current = currents * self.scale\n        return CoilsetOptimiserResult.from_opt_result(self.coilset, opt_result)",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        gamma: float,\n    ):\n        self.coilset = coilset\n        self.eq = eq\n        self.targets = targets\n        self.gamma = gamma",
  "def optimise(self, **_) -> CoilsetOptimiserResult:\n        \"\"\"\n        Optimise the prescribed problem.\n\n        Notes\n        -----\n        The weight vector is used to scale the response matrix and\n        constraint vector. The weights are assumed to be uncorrelated, such that the\n        weight matrix W_ij used to define (for example) the least-squares objective\n        function (Ax - b)\u1d40 W (Ax - b), is diagonal, such that\n        weights[i] = w[i] = sqrt(W[i,i]).\n        \"\"\"\n        # Scale the control matrix and magnetic field targets vector by weights.\n        self.targets(self.eq, I_not_dI=False)\n        _, a_mat, b_vec = self.targets.get_weighted_arrays()\n\n        # Optimise currents using analytic expression for optimum.\n        current_adjustment = tikhonov(a_mat, b_vec, self.gamma)\n\n        # Update parameterisation (coilset).\n        self.coilset.current = self.coilset.current + current_adjustment\n        return CoilsetOptimiserResult(\n            coilset=self.coilset,\n            f_x=self.coilset.current,\n            n_evals=0,\n            history=[],\n            constraints_satisfied=True,\n        )",
  "class NestedCoilsetPositionCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Coilset OptimisationProblem for coil currents and positions\n    subject to maximum current bounds and positions bounded within\n    a provided region. Performs a nested optimisation for coil\n    currents within each position optimisation function call.\n\n    Parameters\n    ----------\n    sub_opt:\n        Coilset OptimisationProblem to use for the optimisation of\n        coil currents at each trial set of coil positions.\n        sub_opt.coilset must exist, and will be modified\n        during the optimisation.\n    eq:\n        Equilibrium object used to update magnetic field targets.\n    targets:\n        Set of magnetic field targets to use in objective function.\n    position_mapper:\n        position mapper object of the regions to optimise the coil positions within\n    opt_algorithm:\n        The optimisation algorithm to use (e.g. SLSQP)\n    opt_conditions:\n        The stopping conditions for the optimiser.\n        for defaults see\n        :class:`~bluemira.optimisation._algorithm.AlgorithDefaultTolerances`\n        along with `max_eval=100`\n\n\n    Notes\n    -----\n    Setting stopval and maxeval is the most reliable way to stop optimisation\n    at the desired figure of merit and number of iterations respectively.\n    Some NLOpt optimisers display unexpected behaviour when setting xtol and\n    ftol, and may not terminate as expected when those criteria are reached.\n    \"\"\"\n\n    def __init__(\n        self,\n        sub_opt: CoilsetOptimisationProblem,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        position_mapper: PositionMapper,\n        opt_algorithm: AlgorithmType = Algorithm.SBPLX,\n        opt_conditions: Optional[Dict[str, float]] = None,\n        constraints: Optional[List[UpdateableConstraint]] = None,\n    ):\n        self.eq = eq\n        self.targets = targets\n        self.position_mapper = position_mapper\n\n        opt_dimension = self.position_mapper.dimension\n        self.bounds = (np.zeros(opt_dimension), np.ones(opt_dimension))\n        self.coilset = sub_opt.coilset\n        self.sub_opt = sub_opt\n        self.opt_algorithm = opt_algorithm\n        self.opt_conditions = opt_conditions or self._opt_condition_defaults(\n            {\"max_eval\": 100}\n        )\n        self._constraints = [] if constraints is None else constraints\n\n        self.initial_state, self.substates = self.read_coilset_state(\n            self.coilset, self.scale\n        )\n        self.I0 = np.array_split(self.initial_state, self.substates)[2]\n\n    def optimise(self, **_):\n        \"\"\"\n        Run the optimisation.\n\n        Returns\n        -------\n        Optimised CoilSet object.\n        \"\"\"\n        # Get initial currents, and trim to within current bounds.\n        initial_state, substates = self.read_coilset_state(self.coilset, self.scale)\n        _, _, initial_currents = np.array_split(initial_state, substates)\n        initial_mapped_positions = self.position_mapper.to_L(\n            self.coilset.x, self.coilset.z\n        )\n\n        # TODO: find more explicit way of passing this to objective?\n        self.I0 = initial_currents\n        eq_constraints, ineq_constraints = self._make_numerical_constraints()\n        opt_result = optimise(\n            f_objective=self.objective,\n            x0=initial_mapped_positions,\n            algorithm=self.opt_algorithm,\n            opt_conditions=self.opt_conditions,\n            eq_constraints=eq_constraints,\n            ineq_constraints=ineq_constraints,\n        )\n        self.set_coilset_state(self.coilset, opt_result.x, self.scale)\n        return CoilsetOptimiserResult.from_opt_result(self.coilset, opt_result)\n\n    def objective(self, vector: npt.NDArray) -> float:\n        \"\"\"Objective function to minimise.\"\"\"\n        coilset_state = np.concatenate((self.position_mapper.to_xz(vector), self.I0))\n        self.set_coilset_state(self.coilset, coilset_state, self.scale)\n\n        # Update targets\n        self.eq._remap_greens()\n        self.targets(self.eq, I_not_dI=True, fixed_coils=False)\n\n        # Run the sub-optimisation\n        sub_opt_result = self.sub_opt.optimise()\n        return sub_opt_result.f_x",
  "class PulsedNestedPositionCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Coilset position optimisation problem for multiple sub-optimisation problems.\n\n    Parameters\n    ----------\n    coilset:\n        Coilset for which to optimise positions\n    position_mapper:\n        Position mapper tool to parameterise coil positions\n    sub_opt_problems:\n        The list of sub-optimisation problems to solve\n    opt_algorithm:\n        The optimisation algorithm to use (e.g. SLSQP)\n    opt_conditions:\n        The stopping conditions for the optimiser.\n        for defaults see\n        :class:`~bluemira.optimisation._algorithm.AlgorithDefaultTolerances`\n        along with `max_eval=100`\n    constraints:\n        Constraints to use. Note these should be applicable to the parametric position\n        vector\n    initial_currents:\n        Initial currents to use when solving the current sub-optimisation problems\n    debug:\n        Whether or not to run in debug mode (will affect run-time noticeably)\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        position_mapper: PositionMapper,\n        sub_opt_problems: List[CoilsetOptimisationProblem],\n        opt_algorithm: AlgorithmType = Algorithm.COBYLA,\n        opt_conditions: Optional[Dict[str, float]] = None,\n        constraints=None,\n        initial_currents=None,\n        debug: bool = False,\n    ):\n        self.coilset = coilset\n        self.position_mapper = position_mapper\n        self.sub_opt_problems = sub_opt_problems\n        self.opt_algorithm = opt_algorithm\n        self.opt_conditions = opt_conditions or self._opt_condition_defaults(\n            {\"max_eval\": 100}\n        )\n        self._constraints = constraints\n\n        if initial_currents:\n            self.initial_currents = initial_currents / self.sub_opt_problems[0].scale\n        else:\n            self.initial_currents = np.zeros(coilset.get_control_coils().n_coils())\n        self.debug = {0: debug}\n        self.iter = {0: 0.0}\n        opt_dimension = self.position_mapper.dimension\n        self.bounds = (np.zeros(opt_dimension), np.ones(opt_dimension))\n\n    @staticmethod\n    def _run_reporting(itern, max_fom, verbose):\n        \"\"\"\n        Keep track of objective function value over iterations.\n        \"\"\"\n        i = max(list(itern.keys())) + 1\n        itern[i] = max_fom\n\n        if verbose:\n            bluemira_print_flush(f\"Coil position iteration {i} FOM value: {max_fom:.6e}\")\n\n    @staticmethod\n    def _run_diagnostics(\n        debug,\n        sub_opt_prob: CoilsetOptimisationProblem,\n        opt_result: CoilsetOptimiserResult,\n    ):\n        \"\"\"\n        In debug mode, store the LCFS at each iteration for each of the sub-optimisation\n        problems.\n\n        Notes\n        -----\n        This can significantly impact run-time.\n        \"\"\"\n        if debug[0]:\n            entry = max(list(debug.keys()))\n            value = opt_result.f_x\n            sub_opt_prob.eq._remap_greens()\n            sub_opt_prob.eq._clear_OX_points()\n            lcfs = sub_opt_prob.eq.get_LCFS()\n            debug[entry].append([lcfs, value])\n\n    def sub_opt_objective(self, vector: npt.NDArray, verbose: bool = False) -> float:\n        \"\"\"Run the sub-optimisations and return the largest figure of merit.\"\"\"\n        positions = self.position_mapper.to_xz_dict(vector)\n\n        if self.debug[0]:\n            # Increment debug dictionary\n            i = max(list(self.debug.keys())) + 1\n            self.debug[i] = []\n\n        fom_values = []\n        for sub_opt_prob in self.sub_opt_problems:\n            for coil, position in positions.items():\n                sub_opt_prob.coilset[coil].position = position\n            result = sub_opt_prob.optimise(x0=self.initial_currents, fixed_coils=False)\n            self._run_diagnostics(self.debug, sub_opt_prob, result)\n            fom_values.append(result.f_x)\n        max_fom = max(fom_values)\n\n        self._run_reporting(self.iter, max_fom, verbose)\n        return max_fom\n\n    def objective(self, vector: npt.NDArray, verbose: bool = False) -> float:\n        \"\"\"The objective function of the parent optimisation.\"\"\"\n        return self.sub_opt_objective(vector, verbose=verbose)\n\n    def _get_initial_vector(self) -> npt.NDArray:\n        \"\"\"\n        Get a vector representation of the initial coilset state from the PositionMapper.\n        \"\"\"\n        x, z = [], []\n        for name in self.position_mapper.interpolators:\n            x.append(self.coilset[name].x)\n            z.append(self.coilset[name].z)\n        return self.position_mapper.to_L(x, z)\n\n    def optimise(\n        self, x0: Optional[npt.NDArray] = None, verbose: bool = False\n    ) -> CoilsetOptimiserResult:\n        \"\"\"\n        Run the PulsedNestedPositionCOP\n\n        Parameters\n        ----------\n        x0:\n            Initial solution vector (parameterised positions)\n        verbose:\n            Whether or not to print progress information\n\n        Returns\n        -------\n        coilset:\n            Optimised CoilSet\n        \"\"\"\n        if x0 is None:\n            x0 = self._get_initial_vector()\n\n        eq_constraints, ineq_constraints = self._make_numerical_constraints()\n        opt_result = optimise(\n            f_objective=lambda x: self.objective(x, verbose=verbose),\n            x0=x0,\n            df_objective=None,  # use a numerical approximation if needed\n            algorithm=self.opt_algorithm,\n            opt_conditions=self.opt_conditions,\n            bounds=self.bounds,\n            eq_constraints=eq_constraints,\n            ineq_constraints=ineq_constraints,\n        )\n        optimal_positions = opt_result.x\n        # Call the objective one last time\n        self.sub_opt_objective(optimal_positions)\n\n        # Clean up state of Equilibrium objects\n        for sub_opt in self.sub_opt_problems:\n            sub_opt.eq._remap_greens()\n            sub_opt.eq._clear_OX_points()\n        return CoilsetOptimiserResult.from_opt_result(self.coilset, opt_result)",
  "def __init__(\n        self,\n        sub_opt: CoilsetOptimisationProblem,\n        eq: Equilibrium,\n        targets: MagneticConstraintSet,\n        position_mapper: PositionMapper,\n        opt_algorithm: AlgorithmType = Algorithm.SBPLX,\n        opt_conditions: Optional[Dict[str, float]] = None,\n        constraints: Optional[List[UpdateableConstraint]] = None,\n    ):\n        self.eq = eq\n        self.targets = targets\n        self.position_mapper = position_mapper\n\n        opt_dimension = self.position_mapper.dimension\n        self.bounds = (np.zeros(opt_dimension), np.ones(opt_dimension))\n        self.coilset = sub_opt.coilset\n        self.sub_opt = sub_opt\n        self.opt_algorithm = opt_algorithm\n        self.opt_conditions = opt_conditions or self._opt_condition_defaults(\n            {\"max_eval\": 100}\n        )\n        self._constraints = [] if constraints is None else constraints\n\n        self.initial_state, self.substates = self.read_coilset_state(\n            self.coilset, self.scale\n        )\n        self.I0 = np.array_split(self.initial_state, self.substates)[2]",
  "def optimise(self, **_):\n        \"\"\"\n        Run the optimisation.\n\n        Returns\n        -------\n        Optimised CoilSet object.\n        \"\"\"\n        # Get initial currents, and trim to within current bounds.\n        initial_state, substates = self.read_coilset_state(self.coilset, self.scale)\n        _, _, initial_currents = np.array_split(initial_state, substates)\n        initial_mapped_positions = self.position_mapper.to_L(\n            self.coilset.x, self.coilset.z\n        )\n\n        # TODO: find more explicit way of passing this to objective?\n        self.I0 = initial_currents\n        eq_constraints, ineq_constraints = self._make_numerical_constraints()\n        opt_result = optimise(\n            f_objective=self.objective,\n            x0=initial_mapped_positions,\n            algorithm=self.opt_algorithm,\n            opt_conditions=self.opt_conditions,\n            eq_constraints=eq_constraints,\n            ineq_constraints=ineq_constraints,\n        )\n        self.set_coilset_state(self.coilset, opt_result.x, self.scale)\n        return CoilsetOptimiserResult.from_opt_result(self.coilset, opt_result)",
  "def objective(self, vector: npt.NDArray) -> float:\n        \"\"\"Objective function to minimise.\"\"\"\n        coilset_state = np.concatenate((self.position_mapper.to_xz(vector), self.I0))\n        self.set_coilset_state(self.coilset, coilset_state, self.scale)\n\n        # Update targets\n        self.eq._remap_greens()\n        self.targets(self.eq, I_not_dI=True, fixed_coils=False)\n\n        # Run the sub-optimisation\n        sub_opt_result = self.sub_opt.optimise()\n        return sub_opt_result.f_x",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        position_mapper: PositionMapper,\n        sub_opt_problems: List[CoilsetOptimisationProblem],\n        opt_algorithm: AlgorithmType = Algorithm.COBYLA,\n        opt_conditions: Optional[Dict[str, float]] = None,\n        constraints=None,\n        initial_currents=None,\n        debug: bool = False,\n    ):\n        self.coilset = coilset\n        self.position_mapper = position_mapper\n        self.sub_opt_problems = sub_opt_problems\n        self.opt_algorithm = opt_algorithm\n        self.opt_conditions = opt_conditions or self._opt_condition_defaults(\n            {\"max_eval\": 100}\n        )\n        self._constraints = constraints\n\n        if initial_currents:\n            self.initial_currents = initial_currents / self.sub_opt_problems[0].scale\n        else:\n            self.initial_currents = np.zeros(coilset.get_control_coils().n_coils())\n        self.debug = {0: debug}\n        self.iter = {0: 0.0}\n        opt_dimension = self.position_mapper.dimension\n        self.bounds = (np.zeros(opt_dimension), np.ones(opt_dimension))",
  "def _run_reporting(itern, max_fom, verbose):\n        \"\"\"\n        Keep track of objective function value over iterations.\n        \"\"\"\n        i = max(list(itern.keys())) + 1\n        itern[i] = max_fom\n\n        if verbose:\n            bluemira_print_flush(f\"Coil position iteration {i} FOM value: {max_fom:.6e}\")",
  "def _run_diagnostics(\n        debug,\n        sub_opt_prob: CoilsetOptimisationProblem,\n        opt_result: CoilsetOptimiserResult,\n    ):\n        \"\"\"\n        In debug mode, store the LCFS at each iteration for each of the sub-optimisation\n        problems.\n\n        Notes\n        -----\n        This can significantly impact run-time.\n        \"\"\"\n        if debug[0]:\n            entry = max(list(debug.keys()))\n            value = opt_result.f_x\n            sub_opt_prob.eq._remap_greens()\n            sub_opt_prob.eq._clear_OX_points()\n            lcfs = sub_opt_prob.eq.get_LCFS()\n            debug[entry].append([lcfs, value])",
  "def sub_opt_objective(self, vector: npt.NDArray, verbose: bool = False) -> float:\n        \"\"\"Run the sub-optimisations and return the largest figure of merit.\"\"\"\n        positions = self.position_mapper.to_xz_dict(vector)\n\n        if self.debug[0]:\n            # Increment debug dictionary\n            i = max(list(self.debug.keys())) + 1\n            self.debug[i] = []\n\n        fom_values = []\n        for sub_opt_prob in self.sub_opt_problems:\n            for coil, position in positions.items():\n                sub_opt_prob.coilset[coil].position = position\n            result = sub_opt_prob.optimise(x0=self.initial_currents, fixed_coils=False)\n            self._run_diagnostics(self.debug, sub_opt_prob, result)\n            fom_values.append(result.f_x)\n        max_fom = max(fom_values)\n\n        self._run_reporting(self.iter, max_fom, verbose)\n        return max_fom",
  "def objective(self, vector: npt.NDArray, verbose: bool = False) -> float:\n        \"\"\"The objective function of the parent optimisation.\"\"\"\n        return self.sub_opt_objective(vector, verbose=verbose)",
  "def _get_initial_vector(self) -> npt.NDArray:\n        \"\"\"\n        Get a vector representation of the initial coilset state from the PositionMapper.\n        \"\"\"\n        x, z = [], []\n        for name in self.position_mapper.interpolators:\n            x.append(self.coilset[name].x)\n            z.append(self.coilset[name].z)\n        return self.position_mapper.to_L(x, z)",
  "def optimise(\n        self, x0: Optional[npt.NDArray] = None, verbose: bool = False\n    ) -> CoilsetOptimiserResult:\n        \"\"\"\n        Run the PulsedNestedPositionCOP\n\n        Parameters\n        ----------\n        x0:\n            Initial solution vector (parameterised positions)\n        verbose:\n            Whether or not to print progress information\n\n        Returns\n        -------\n        coilset:\n            Optimised CoilSet\n        \"\"\"\n        if x0 is None:\n            x0 = self._get_initial_vector()\n\n        eq_constraints, ineq_constraints = self._make_numerical_constraints()\n        opt_result = optimise(\n            f_objective=lambda x: self.objective(x, verbose=verbose),\n            x0=x0,\n            df_objective=None,  # use a numerical approximation if needed\n            algorithm=self.opt_algorithm,\n            opt_conditions=self.opt_conditions,\n            bounds=self.bounds,\n            eq_constraints=eq_constraints,\n            ineq_constraints=ineq_constraints,\n        )\n        optimal_positions = opt_result.x\n        # Call the objective one last time\n        self.sub_opt_objective(optimal_positions)\n\n        # Clean up state of Equilibrium objects\n        for sub_opt in self.sub_opt_problems:\n            sub_opt.eq._remap_greens()\n            sub_opt.eq._clear_OX_points()\n        return CoilsetOptimiserResult.from_opt_result(self.coilset, opt_result)",
  "class MinimalCurrentCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Bounded, constrained, minimal current optimisation problem.\n\n    Parameters\n    ----------\n    coilset:\n        Coilset to optimise\n    eq:\n        Equilibrium object to optimise the currents for\n    max_currents:\n        Current bounds vector [A]\n    opt_conditions:\n        Optimiser conditions\n    opt_algorithm:\n        optimiser algorithm\n    constraints:\n        List of optimisation constraints to apply to the optimisation problem\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        max_currents: Optional[npt.ArrayLike] = None,\n        opt_conditions: Optional[Dict[str, float]] = None,\n        opt_algorithm: AlgorithmType = Algorithm.SLSQP,\n        constraints: Optional[List[UpdateableConstraint]] = None,\n    ):\n        self.coilset = coilset\n        self.eq = eq\n        self.bounds = self.get_current_bounds(self.coilset, max_currents, self.scale)\n        self.opt_conditions = opt_conditions\n        self.opt_algorithm = opt_algorithm\n        self._constraints = [] if constraints is None else constraints\n\n    def optimise(self, x0: Optional[npt.NDArray] = None, fixed_coils: bool = True):\n        \"\"\"\n        Run the optimisation problem\n\n        Parameters\n        ----------\n        fixed_coils:\n            Whether or not to update to coilset response matrices\n\n        Returns\n        -------\n        coilset: CoilSet\n            Optimised CoilSet\n        \"\"\"\n        self.update_magnetic_constraints(I_not_dI=True, fixed_coils=fixed_coils)\n\n        if x0 is None:\n            initial_state, n_states = self.read_coilset_state(\n                self.eq.coilset, self.scale\n            )\n            _, _, initial_currents = np.array_split(initial_state, n_states)\n            x0 = np.clip(initial_currents, *self.bounds)\n\n        objective = CoilCurrentsObjective()\n        eq_constraints, ineq_constraints = self._make_numerical_constraints()\n        opt_result = optimise(\n            f_objective=objective.f_objective,\n            df_objective=objective.df_objective,\n            x0=x0,\n            algorithm=self.opt_algorithm,\n            opt_conditions=self.opt_conditions,\n            eq_constraints=eq_constraints,\n            ineq_constraints=ineq_constraints,\n        )\n        currents = opt_result.x\n        self.coilset.get_control_coils().current = currents * self.scale\n        return CoilsetOptimiserResult.from_opt_result(self.coilset, opt_result)",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        eq: Equilibrium,\n        max_currents: Optional[npt.ArrayLike] = None,\n        opt_conditions: Optional[Dict[str, float]] = None,\n        opt_algorithm: AlgorithmType = Algorithm.SLSQP,\n        constraints: Optional[List[UpdateableConstraint]] = None,\n    ):\n        self.coilset = coilset\n        self.eq = eq\n        self.bounds = self.get_current_bounds(self.coilset, max_currents, self.scale)\n        self.opt_conditions = opt_conditions\n        self.opt_algorithm = opt_algorithm\n        self._constraints = [] if constraints is None else constraints",
  "def optimise(self, x0: Optional[npt.NDArray] = None, fixed_coils: bool = True):\n        \"\"\"\n        Run the optimisation problem\n\n        Parameters\n        ----------\n        fixed_coils:\n            Whether or not to update to coilset response matrices\n\n        Returns\n        -------\n        coilset: CoilSet\n            Optimised CoilSet\n        \"\"\"\n        self.update_magnetic_constraints(I_not_dI=True, fixed_coils=fixed_coils)\n\n        if x0 is None:\n            initial_state, n_states = self.read_coilset_state(\n                self.eq.coilset, self.scale\n            )\n            _, _, initial_currents = np.array_split(initial_state, n_states)\n            x0 = np.clip(initial_currents, *self.bounds)\n\n        objective = CoilCurrentsObjective()\n        eq_constraints, ineq_constraints = self._make_numerical_constraints()\n        opt_result = optimise(\n            f_objective=objective.f_objective,\n            df_objective=objective.df_objective,\n            x0=x0,\n            algorithm=self.opt_algorithm,\n            opt_conditions=self.opt_conditions,\n            eq_constraints=eq_constraints,\n            ineq_constraints=ineq_constraints,\n        )\n        currents = opt_result.x\n        self.coilset.get_control_coils().current = currents * self.scale\n        return CoilsetOptimiserResult.from_opt_result(self.coilset, opt_result)",
  "class BreakdownZoneStrategy(abc.ABC):\n    \"\"\"\n    Abstract base class for the definition of a breakdown zone strategy.\n\n    Parameters\n    ----------\n    R_0:\n        Major radius of the reference plasma\n    A:\n        Aspect ratio of the reference plasma\n    tk_sol:\n        Thickness of the scrape-off layer\n    \"\"\"\n\n    def __init__(self, R_0, A, tk_sol, **kwargs):\n        self.R_0 = R_0\n        self.A = A\n        self.tk_sol = tk_sol\n\n    @abc.abstractproperty\n    def breakdown_point(self) -> Tuple[float, float]:\n        \"\"\"\n        The location of the breakdown point.\n\n        Returns\n        -------\n        x_c:\n            Radial coordinate of the breakdown point\n        z_c:\n            Vertical coordinate of the breakdown point\n        \"\"\"\n        pass\n\n    @abc.abstractproperty\n    def breakdown_radius(self) -> float:\n        \"\"\"\n        The radius of the breakdown zone.\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def calculate_zone_points(self, n_points: int) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate the discretised set of points representing the breakdown zone.\n        \"\"\"\n        pass",
  "class CircularZoneStrategy(BreakdownZoneStrategy):\n    \"\"\"\n    Circular breakdown zone strategy.\n    \"\"\"\n\n    def calculate_zone_points(self, n_points: int) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate the discretised set of points representing the breakdown zone.\n        \"\"\"\n        x_c, z_c = self.breakdown_point\n        r_c = self.breakdown_radius\n        theta = np.linspace(0, 2 * np.pi, n_points - 1, endpoint=False)\n        x = x_c + r_c * np.cos(theta)\n        z = z_c + r_c * np.sin(theta)\n        x = np.append(x, x_c)\n        z = np.append(z, z_c)\n        return x, z",
  "class InboardBreakdownZoneStrategy(CircularZoneStrategy):\n    \"\"\"\n    Inboard breakdown zone strategy.\n    \"\"\"\n\n    @property\n    def breakdown_point(self) -> Tuple[float, float]:\n        \"\"\"\n        The location of the breakdown point.\n\n        Returns\n        -------\n        x_c:\n            Radial coordinate of the breakdown point\n        z_c:\n            Vertical coordinate of the breakdown point\n        \"\"\"\n        r_c = self.breakdown_radius\n        x_c = self.R_0 - self.R_0 / self.A - self.tk_sol + r_c\n        z_c = 0.0\n        return x_c, z_c\n\n    @property\n    def breakdown_radius(self) -> float:\n        \"\"\"\n        The radius of the breakdown zone.\n        \"\"\"\n        return 0.5 * self.R_0 / self.A",
  "class OutboardBreakdownZoneStrategy(CircularZoneStrategy):\n    \"\"\"\n    Outboard breakdown zone strategy.\n    \"\"\"\n\n    @property\n    def breakdown_point(self) -> Tuple[float, float]:\n        \"\"\"\n        The location of the breakdown point.\n\n        Returns\n        -------\n        x_c:\n            Radial coordinate of the breakdown point\n        z_c:\n            Vertical coordinate of the breakdown point\n        \"\"\"\n        r_c = self.breakdown_radius\n        x_c = self.R_0 + self.R_0 / self.A + self.tk_sol - r_c\n        z_c = 0.0\n        return x_c, z_c\n\n    @property\n    def breakdown_radius(self) -> float:\n        \"\"\"\n        The radius of the breakdown zone.\n        \"\"\"\n        return 0.7 * self.R_0 / self.A",
  "class InputBreakdownZoneStrategy(CircularZoneStrategy):\n    \"\"\"\n    User input breakdown zone strategy.\n    \"\"\"\n\n    def __init__(self, x_c, z_c, r_c):\n        self.x_c = x_c\n        self.z_c = z_c\n        self.r_c = r_c\n\n    @property\n    def breakdown_point(self) -> Tuple[float, float]:\n        \"\"\"\n        The location of the breakdown point.\n\n        Returns\n        -------\n        x_c:\n            Radial coordinate of the breakdown point\n        z_c:\n            Vertical coordinate of the breakdown point\n        \"\"\"\n        return self.x_c, self.z_c\n\n    @property\n    def breakdown_radius(self) -> float:\n        \"\"\"\n        The radius of the breakdown zone.\n        \"\"\"\n        return self.r_c",
  "class BreakdownCOP(CoilsetOptimisationProblem):\n    \"\"\"\n    Coilset optimisation problem for the premagnetisation / breakdown phase.\n    \"\"\"\n\n    def __init__(\n        self,\n        coilset: CoilSet,\n        breakdown: Breakdown,\n        breakdown_strategy: BreakdownZoneStrategy,\n        B_stray_max: float,\n        B_stray_con_tol: float,\n        n_B_stray_points: int,\n        max_currents: npt.ArrayLike,\n        opt_algorithm: AlgorithmType = Algorithm.SLSQP,\n        opt_conditions: Optional[Dict[str, Union[float, int]]] = None,\n        constraints: Optional[List[UpdateableConstraint]] = None,\n    ):\n        self.coilset = coilset\n        self.eq = breakdown\n        self.opt_algorithm = opt_algorithm\n        self.opt_conditions = opt_conditions\n\n        self._args = {\n            \"c_psi_mat\": np.array(\n                coilset.psi_response(*breakdown_strategy.breakdown_point)\n            ),\n            \"scale\": self.scale,\n        }\n        x_zone, z_zone = breakdown_strategy.calculate_zone_points(n_B_stray_points)\n        stray_field_cons = FieldConstraints(\n            x_zone, z_zone, B_max=B_stray_max, tolerance=B_stray_con_tol\n        )\n\n        self._constraints = constraints\n        if self._constraints is not None:\n            self._constraints.append(stray_field_cons)\n        else:\n            self._constraints = [stray_field_cons]\n\n        max_currents = np.atleast_1d(max_currents)\n        self.bounds = (-max_currents / self.scale, max_currents / self.scale)\n\n    def optimise(self, x0=None, fixed_coils=True):\n        \"\"\"\n        Solve the optimisation problem.\n        \"\"\"\n        self.update_magnetic_constraints(I_not_dI=True, fixed_coils=fixed_coils)\n\n        initial_state, n_states = self.read_coilset_state(self.coilset, self.scale)\n        _, _, initial_currents = np.array_split(initial_state, n_states)\n        initial_currents = np.clip(initial_currents, *self.bounds)\n\n        objective = MaximiseFluxObjective(**self._args)\n        eq_constraints, ineq_constraints = self._make_numerical_constraints()\n        opt_result = optimise(\n            f_objective=objective.f_objective,\n            df_objective=objective.df_objective,\n            x0=initial_currents,\n            algorithm=self.opt_algorithm,\n            opt_conditions=self.opt_conditions,\n            bounds=self.bounds,\n            eq_constraints=eq_constraints,\n            ineq_constraints=ineq_constraints,\n        )\n        currents = opt_result.x\n        self.coilset.get_control_coils().current = currents * self.scale\n        return CoilsetOptimiserResult.from_opt_result(self.coilset, opt_result)",
  "def __init__(self, R_0, A, tk_sol, **kwargs):\n        self.R_0 = R_0\n        self.A = A\n        self.tk_sol = tk_sol",
  "def breakdown_point(self) -> Tuple[float, float]:\n        \"\"\"\n        The location of the breakdown point.\n\n        Returns\n        -------\n        x_c:\n            Radial coordinate of the breakdown point\n        z_c:\n            Vertical coordinate of the breakdown point\n        \"\"\"\n        pass",
  "def breakdown_radius(self) -> float:\n        \"\"\"\n        The radius of the breakdown zone.\n        \"\"\"\n        pass",
  "def calculate_zone_points(self, n_points: int) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate the discretised set of points representing the breakdown zone.\n        \"\"\"\n        pass",
  "def calculate_zone_points(self, n_points: int) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate the discretised set of points representing the breakdown zone.\n        \"\"\"\n        x_c, z_c = self.breakdown_point\n        r_c = self.breakdown_radius\n        theta = np.linspace(0, 2 * np.pi, n_points - 1, endpoint=False)\n        x = x_c + r_c * np.cos(theta)\n        z = z_c + r_c * np.sin(theta)\n        x = np.append(x, x_c)\n        z = np.append(z, z_c)\n        return x, z",
  "def breakdown_point(self) -> Tuple[float, float]:\n        \"\"\"\n        The location of the breakdown point.\n\n        Returns\n        -------\n        x_c:\n            Radial coordinate of the breakdown point\n        z_c:\n            Vertical coordinate of the breakdown point\n        \"\"\"\n        r_c = self.breakdown_radius\n        x_c = self.R_0 - self.R_0 / self.A - self.tk_sol + r_c\n        z_c = 0.0\n        return x_c, z_c",
  "def breakdown_radius(self) -> float:\n        \"\"\"\n        The radius of the breakdown zone.\n        \"\"\"\n        return 0.5 * self.R_0 / self.A",
  "def breakdown_point(self) -> Tuple[float, float]:\n        \"\"\"\n        The location of the breakdown point.\n\n        Returns\n        -------\n        x_c:\n            Radial coordinate of the breakdown point\n        z_c:\n            Vertical coordinate of the breakdown point\n        \"\"\"\n        r_c = self.breakdown_radius\n        x_c = self.R_0 + self.R_0 / self.A + self.tk_sol - r_c\n        z_c = 0.0\n        return x_c, z_c",
  "def breakdown_radius(self) -> float:\n        \"\"\"\n        The radius of the breakdown zone.\n        \"\"\"\n        return 0.7 * self.R_0 / self.A",
  "def __init__(self, x_c, z_c, r_c):\n        self.x_c = x_c\n        self.z_c = z_c\n        self.r_c = r_c",
  "def breakdown_point(self) -> Tuple[float, float]:\n        \"\"\"\n        The location of the breakdown point.\n\n        Returns\n        -------\n        x_c:\n            Radial coordinate of the breakdown point\n        z_c:\n            Vertical coordinate of the breakdown point\n        \"\"\"\n        return self.x_c, self.z_c",
  "def breakdown_radius(self) -> float:\n        \"\"\"\n        The radius of the breakdown zone.\n        \"\"\"\n        return self.r_c",
  "def __init__(\n        self,\n        coilset: CoilSet,\n        breakdown: Breakdown,\n        breakdown_strategy: BreakdownZoneStrategy,\n        B_stray_max: float,\n        B_stray_con_tol: float,\n        n_B_stray_points: int,\n        max_currents: npt.ArrayLike,\n        opt_algorithm: AlgorithmType = Algorithm.SLSQP,\n        opt_conditions: Optional[Dict[str, Union[float, int]]] = None,\n        constraints: Optional[List[UpdateableConstraint]] = None,\n    ):\n        self.coilset = coilset\n        self.eq = breakdown\n        self.opt_algorithm = opt_algorithm\n        self.opt_conditions = opt_conditions\n\n        self._args = {\n            \"c_psi_mat\": np.array(\n                coilset.psi_response(*breakdown_strategy.breakdown_point)\n            ),\n            \"scale\": self.scale,\n        }\n        x_zone, z_zone = breakdown_strategy.calculate_zone_points(n_B_stray_points)\n        stray_field_cons = FieldConstraints(\n            x_zone, z_zone, B_max=B_stray_max, tolerance=B_stray_con_tol\n        )\n\n        self._constraints = constraints\n        if self._constraints is not None:\n            self._constraints.append(stray_field_cons)\n        else:\n            self._constraints = [stray_field_cons]\n\n        max_currents = np.atleast_1d(max_currents)\n        self.bounds = (-max_currents / self.scale, max_currents / self.scale)",
  "def optimise(self, x0=None, fixed_coils=True):\n        \"\"\"\n        Solve the optimisation problem.\n        \"\"\"\n        self.update_magnetic_constraints(I_not_dI=True, fixed_coils=fixed_coils)\n\n        initial_state, n_states = self.read_coilset_state(self.coilset, self.scale)\n        _, _, initial_currents = np.array_split(initial_state, n_states)\n        initial_currents = np.clip(initial_currents, *self.bounds)\n\n        objective = MaximiseFluxObjective(**self._args)\n        eq_constraints, ineq_constraints = self._make_numerical_constraints()\n        opt_result = optimise(\n            f_objective=objective.f_objective,\n            df_objective=objective.df_objective,\n            x0=initial_currents,\n            algorithm=self.opt_algorithm,\n            opt_conditions=self.opt_conditions,\n            bounds=self.bounds,\n            eq_constraints=eq_constraints,\n            ineq_constraints=ineq_constraints,\n        )\n        currents = opt_result.x\n        self.coilset.get_control_coils().current = currents * self.scale\n        return CoilsetOptimiserResult.from_opt_result(self.coilset, opt_result)",
  "def _pressure_profile(pprime, psi_norm, psi_mag):\n    pressure = np.zeros(len(psi_norm))\n    for i in range(len(psi_norm)):\n        pressure[i] = quad(pprime, psi_norm[i], 1.0, limit=500)[0] * psi_mag\n    return pressure",
  "def _fpol_profile(ffprime, psi_norm, psi_mag, fvac):\n    fpol = np.zeros(len(psi_norm))\n    for i in range(len(psi_norm)):\n        fpol[i] = np.sqrt(\n            2\n            * quadrature(ffprime, psi_norm[i], 1.0, maxiter=500, rtol=1e-6, tol=1e-6)[0]\n            * psi_mag\n            + fvac**2\n        )\n    return fpol",
  "def save_fixed_boundary_to_file(\n    file_path: str,\n    file_header_name: str,\n    equilibrium: FixedBoundaryEquilibrium,\n    nx: int,\n    nz: int,\n    file_format: str = \"json\",\n    json_kwargs: Optional[Dict] = None,\n    **kwargs,\n):\n    \"\"\"\n    Save a fixed boundary equilibrium to a file.\n\n    Parameters\n    ----------\n    file_path:\n        File path to save the file to\n    file_header_name:\n        File header name to use in the the file\n    equilibrium:\n        Equilibrium object to save to file\n    nx:\n        Number of radial points to use in the psi map\n    nz:\n        Number of vertical points to use in the psi map\n    file_format:\n        Format of the file\n    json_kwargs:\n        kwargs to use if saving to JSON\n    \"\"\"\n    if kw_formatt := kwargs.pop(\"formatt\", None):\n        warn(\n            \"Using kwarg 'formatt' is no longer supported. Use file_format instead.\",\n            category=DeprecationWarning,\n        )\n        file_format = kw_formatt\n\n    xbdry, zbdry = get_mesh_boundary(equilibrium.mesh)\n    xbdry = np.append(xbdry, xbdry[0])\n    zbdry = np.append(zbdry, zbdry[0])\n    nbdry = len(xbdry)\n\n    x_mag, z_mag = find_magnetic_axis(equilibrium.psi, equilibrium.mesh)\n    psi_mag = equilibrium.psi(x_mag, z_mag)\n\n    # Make a minimum grid\n    x_min = np.min(xbdry)\n    x_max = np.max(xbdry)\n    z_min = np.min(zbdry)\n    z_max = np.max(zbdry)\n    grid = Grid(x_min, x_max, z_min, z_max, nx=nx, nz=nz)\n\n    psi = np.zeros((nx, nz))\n    for i, xi in enumerate(grid.x_1d):\n        for j, zj in enumerate(grid.z_1d):\n            psi[i, j] = equilibrium.psi([xi, zj])\n\n    p_prime = equilibrium.p_prime\n    ff_prime = equilibrium.ff_prime\n    psi_norm = np.linspace(0, 1, len(ff_prime))\n\n    p_prime_func = _interpolate_profile(psi_norm, p_prime)\n    ff_prime_func = _interpolate_profile(psi_norm, ff_prime)\n\n    if equilibrium.R_0 is None:\n        bluemira_warn(\n            \"No explicit R_0 information provided when saving fixed boundary equilibrium \"\n            \"to file. Taking the average of the boundary radial coordinate extrema.\"\n        )\n        R_0 = grid.x_mid\n    else:\n        R_0 = equilibrium.R_0\n    if equilibrium.B_0 is None:\n        bluemira_warn(\n            \"No explicit B_0 information provided when saving fixed boundary equilibrium \"\n            \"to file. Setting to 0!\"\n        )\n        B_0 = 0.0\n    else:\n        B_0 = equilibrium.B_0\n\n    fvac = R_0 * B_0\n    psi_vector = psi_norm * psi_mag\n    pressure = _pressure_profile(p_prime_func, psi_vector, psi_mag)\n    fpol = _fpol_profile(ff_prime_func, psi_norm, psi_mag, fvac)\n\n    data = EQDSKInterface(\n        bcentre=B_0,\n        cplasma=equilibrium.I_p,\n        dxc=np.array([]),\n        dzc=np.array([]),\n        ffprime=ff_prime,\n        fpol=fpol,\n        Ic=np.array([]),\n        name=file_header_name,\n        nbdry=nbdry,\n        ncoil=0,\n        nlim=0,\n        nx=nx,\n        nz=nz,\n        pressure=pressure,\n        pprime=p_prime,\n        psi=psi,\n        psibdry=np.zeros(nbdry),\n        psimag=psi_mag,\n        xbdry=xbdry,\n        xc=np.array([]),\n        xcentre=grid.x_mid,\n        xdim=grid.x_size,\n        xgrid1=grid.x_min,\n        xlim=np.array([]),\n        xmag=x_mag,\n        zbdry=zbdry,\n        zc=np.array([]),\n        zdim=grid.z_size,\n        zlim=np.array([]),\n        zmag=z_mag,\n        zmid=grid.z_mid,\n        x=grid.x_1d,\n        z=grid.z_1d,\n        psinorm=psi_norm,\n        qpsi=np.array([]),\n    )\n    data.write(file_path, format=file_format, json_kwargs=json_kwargs)\n    return data",
  "def _parse_to_callable(profile_data: Union[None, np.ndarray]):\n    if isinstance(profile_data, np.ndarray):\n        x = np.linspace(0, 1, len(profile_data))\n        return _interpolate_profile(x, profile_data)\n    elif profile_data is None:\n        return None",
  "class FixedBoundaryEquilibrium:\n    \"\"\"\n    Simple minimal dataclass for a fixed boundary equilibrium.\n    \"\"\"\n\n    # Solver information\n    mesh: dolfin.Mesh\n    psi: Callable[[float, float], float]\n\n    # Profile information\n    p_prime: np.ndarray\n    ff_prime: np.ndarray\n    R_0: float\n    B_0: float\n    I_p: float",
  "class FemGradShafranovFixedBoundary(FemMagnetostatic2d):\n    \"\"\"\n    A 2D fem Grad Shafranov solver. The solver is thought as support for the fem fixed\n    boundary module.\n\n    Parameters\n    ----------\n    p_prime:\n        p' flux function. If callable, then used directly (50 points saved in file).\n        If None, these must be specified later on, but before the solve.\n    ff_prime:\n        FF' flux function. If callable, then used directly (50 points saved in file).\n        If None, these must be specified later on, but before the solve.\n    mesh:\n        Mesh to use when solving the problem.\n        If None, must be specified later on, but before the solve.\n    I_p:\n        Plasma current [A]. If None, the plasma current is calculated, otherwise\n        the source term is scaled to match the plasma current.\n    B_0:\n        Toroidal field at R_0 [T]. Used when saving to file.\n    R_0:\n        Major radius [m]. Used when saving to file.\n    p_order:\n        Order of the approximating polynomial basis functions\n    max_iter:\n        Maximum number of iterations\n    iter_err_max:\n        Convergence criterion value\n    relaxation:\n        Relaxation factor for the Picard iteration procedure\n    \"\"\"\n\n    def __init__(\n        self,\n        p_prime: Optional[Callable[[float], float]] = None,\n        ff_prime: Optional[Callable[[float], float]] = None,\n        mesh: Optional[Union[dolfin.Mesh, str]] = None,\n        I_p: Optional[float] = None,\n        R_0: Optional[float] = None,\n        B_0: Optional[float] = None,\n        p_order: int = 2,\n        max_iter: int = 10,\n        iter_err_max: float = 1e-5,\n        relaxation: float = 0.0,\n    ):\n        super().__init__(p_order)\n        self._g_func = None\n        self._psi_ax = None\n        self._psi_b = None\n        self._grad_psi = None\n        self._pprime = None\n        self._ffprime = None\n\n        self._curr_target = I_p\n        self._R_0 = R_0\n        self._B_0 = B_0\n\n        if (p_prime is not None) and (ff_prime is not None):\n            self.set_profiles(p_prime, ff_prime)\n\n        if mesh is not None:\n            self.set_mesh(mesh)\n\n        self.iter_err_max = iter_err_max\n        self.max_iter = max_iter\n        self.relaxation = relaxation\n        self.k = 1\n\n    @property\n    def psi_ax(self) -> float:\n        \"\"\"Poloidal flux on the magnetic axis\"\"\"\n        if self._psi_ax is None:\n            self._psi_ax = self.psi(find_magnetic_axis(self.psi, self.mesh))\n        return self._psi_ax\n\n    @property\n    def psi_b(self) -> float:\n        \"\"\"Poloidal flux on the boundary\"\"\"\n        if self._psi_b is None:\n            self._psi_b = 0.0\n        return self._psi_b\n\n    def grad_psi(self, point: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Calculate the gradients of psi at a point\n        \"\"\"\n        if self._grad_psi is None:\n            w = dolfin.VectorFunctionSpace(self.mesh, \"CG\", 1)\n            dpsi_dx = self.psi.dx(0)\n            dpsi_dz = self.psi.dx(1)\n            self._grad_psi = dolfin.project(dolfin.as_vector((dpsi_dx, dpsi_dz)), w)\n            self._grad_psi.set_allow_extrapolation(True)\n        return self._grad_psi(point)\n\n    @property\n    def psi_norm_2d(self) -> Callable[[np.ndarray], np.ndarray]:\n        \"\"\"Normalized flux function in 2-D\"\"\"\n        return lambda x: np.sqrt(\n            np.abs((self.psi(x) - self.psi_ax) / (self.psi_b - self.psi_ax))\n        )\n\n    def set_mesh(self, mesh: Union[dolfin.Mesh, str]):\n        \"\"\"\n        Set the mesh for the solver\n\n        Parameters\n        ----------\n        mesh:\n            Filename of the xml file with the mesh definition or a dolfin mesh\n        \"\"\"\n        super().set_mesh(mesh=mesh)\n        self._reset_psi_cache()\n\n    def _create_g_func(\n        self,\n        pprime: Union[Callable[[np.ndarray], np.ndarray], float],\n        ffprime: Union[Callable[[np.ndarray], np.ndarray], float],\n        curr_target: Optional[float] = None,\n    ) -> Callable[[np.ndarray], float]:\n        \"\"\"\n        Return the density current function given pprime and ffprime.\n\n        Parameters\n        ----------\n        pprime:\n            pprime as function of psi_norm (1-D function)\n        ffprime:\n            ffprime as function of psi_norm (1-D function)\n        curr_target:\n            Target current (also used to initialize the solution in case self.psi is\n            still 0 and pprime and ffprime are, then, not defined) [A]\n\n        Returns\n        -------\n        Source current callable to solve the magnetostatic problem\n        \"\"\"\n        area = dolfin.assemble(\n            dolfin.Constant(1) * dolfin.Measure(\"dx\", domain=self.mesh)()\n        )\n\n        j_target = curr_target / area if curr_target else 1.0\n\n        def g(x):\n            if self.psi_ax == 0:\n                return j_target\n            else:\n                r = x[0]\n                x_psi = self.psi_norm_2d(x)\n\n                a = r * pprime(x_psi)\n                b = 1 / MU_0 / r * ffprime(x_psi)\n\n                return self.k * 2 * np.pi * (a + b)\n\n        return g\n\n    def define_g(self):\n        \"\"\"\n        Return the density current DOLFIN function given pprime and ffprime.\n        \"\"\"\n        self._g_func = self._create_g_func(\n            self._pprime, self._ffprime, self._curr_target\n        )\n\n        # # This instruction seems to slow the calculation\n        # super().define_g(ScalarSubFunc(self._g_func))\n\n        # it has been replaced by this code\n        dof_points = self.V.tabulate_dof_coordinates()\n        self.g.vector()[:] = np.array([self._g_func(p) for p in dof_points])\n\n    def set_profiles(\n        self,\n        p_prime: Callable[[float], float],\n        ff_prime: Callable[[float], float],\n        I_p: Optional[float] = None,\n        B_0: Optional[float] = None,\n        R_0: Optional[float] = None,\n    ):\n        \"\"\"\n        Set the profies for the FEM G-S solver.\n\n        Parameters\n        ----------\n        pprime:\n            pprime as function of psi_norm (1-D function)\n        ffprime:\n            ffprime as function of psi_norm (1-D function)\n        I_p:\n            Target current (also used to initialize the solution in case self.psi is\n            still 0 and pprime and ffprime are, then, not defined).\n            If None, plasma current is calculated and not constrained\n        B_0:\n            Toroidal field at R_0 [T]. Used when saving to file.\n        R_0:\n            Major radius [m]. Used when saving to file.\n        \"\"\"\n        # Note: pprime and ffprime have been limited to a Callable,\n        # because otherwise it is necessary to provide also psi_norm_1D\n        # to which they refer.\n        if callable(p_prime):\n            self._pprime = p_prime\n            self._pprime_data = p_prime(np.linspace(0, 1, 50))\n        else:\n            raise ValueError(\"p_prime must be a function\")\n        if callable(ff_prime):\n            self._ffprime = ff_prime\n            self._ffprime_data = ff_prime(np.linspace(0, 1, 50))\n        else:\n            raise ValueError(\"ff_prime must be a function\")\n        if I_p is not None:\n            self._curr_target = I_p\n        if B_0 is not None:\n            self._B_0 = B_0\n        if R_0 is not None:\n            self._R_0 = R_0\n\n    def _calculate_curr_tot(self) -> float:\n        \"\"\"Calculate the total current into the domain\"\"\"\n        return dolfin.assemble(self.g * dolfin.Measure(\"dx\", domain=self.mesh)())\n\n    def _update_curr(self):\n        self.k = 1\n\n        self.define_g()\n\n        if self._curr_target:\n            self.k = self._curr_target / self._calculate_curr_tot()\n\n    def _reset_psi_cache(self):\n        \"\"\"\n        Reset cached psi-axis and psi-boundary properties.\n        \"\"\"\n        self._psi_b = None\n        self._psi_ax = None\n        self._grad_psi = None\n\n    def _check_all_inputs_ready_error(self):\n        if self.mesh is None:\n            raise EquilibriaError(\n                \"You cannot solve this problem yet! Please set the mesh first, using set_mesh(mesh).\"\n            )\n        if self._pprime is None or self._ffprime is None:\n            raise EquilibriaError(\n                \"You cannot solve this problem yet! Please set the profile functions first, using set_profiles(p_prime, ff_prime).\"\n            )\n\n    def solve(\n        self,\n        plot: bool = False,\n        debug: bool = False,\n        gif: bool = False,\n        figname: Optional[str] = None,\n    ) -> FixedBoundaryEquilibrium:\n        \"\"\"\n        Solve the G-S problem.\n\n        Parameters\n        ----------\n        plot:\n            Whether or not to plot\n        debug:\n            Whether or not to display debug information\n        gif: bool\n            Whether or not to produce a GIF\n        figname:\n            The name of the figure. If None, a suitable default is used.\n\n        Returns\n        -------\n        FixedBoundaryEquilibrium object corresponding to the solve\n        \"\"\"\n        self._check_all_inputs_ready_error()\n        self.define_g()\n\n        points = self.mesh.coordinates()\n        plot = any((plot, debug, gif))\n        folder = try_get_bluemira_path(\n            \"\", subfolder=\"generated_data\", allow_missing=False\n        )\n        if figname is None:\n            figname = \"Fixed boundary equilibrium iteration \"\n\n        super().solve()\n        self._reset_psi_cache()\n        self._update_curr()\n\n        if plot:\n            plot_defaults()\n            f, ax, cax = self._setup_plot(debug)\n\n        diff = np.zeros(len(points))\n        for i in range(1, self.max_iter + 1):\n            prev_psi = self.psi.vector()[:]\n            prev = np.array([self.psi_norm_2d(p) for p in points])\n\n            if plot:\n                self._plot_current_iteration(f, ax, cax, i, points, prev, diff, debug)\n                if debug or gif:\n                    save_figure(\n                        f,\n                        figname + str(i),\n                        save=True,\n                        folder=folder,\n                        dpi=DPI_GIF,\n                    )\n\n            super().solve()\n            self._reset_psi_cache()\n\n            new = np.array([self.psi_norm_2d(p) for p in points])\n            diff = new - prev\n\n            eps = np.linalg.norm(diff, ord=2) / np.linalg.norm(new, ord=2)\n\n            bluemira_print_flush(\n                f\"iter = {i} eps = {eps:.3E} psi_ax : {self.psi_ax:.2f}\"\n            )\n\n            # Update psi in-place (Fenics handles this with the below syntax)\n            self.psi.vector()[:] = (1 - self.relaxation) * self.psi.vector()[\n                :\n            ] + self.relaxation * prev_psi\n\n            self._update_curr()\n\n            if eps < self.iter_err_max:\n                break\n\n        if plot:\n            plt.close(f)\n        if gif:\n            make_gif(folder, figname, clean=not debug)\n\n        return self._equilibrium()\n\n    def _equilibrium(self):\n        \"\"\"Equilibrium data object\"\"\"\n        return FixedBoundaryEquilibrium(\n            self.mesh,\n            self.psi,\n            self._pprime_data,\n            self._ffprime_data,\n            self._R_0,\n            self._B_0,\n            self._calculate_curr_tot(),\n        )\n\n    def _setup_plot(self, debug):\n        n_col = 3 if debug else 2\n        fig, ax = plt.subplots(1, n_col, figsize=(18, 10))\n        plt.subplots_adjust(wspace=0.5)\n\n        cax = []\n        for axis in ax:\n            divider = make_axes_locatable(axis)\n            cax.append(divider.append_axes(\"right\", size=\"10%\", pad=0.1))\n\n        return fig, ax, cax\n\n    def _plot_current_iteration(\n        self,\n        f,\n        ax,\n        cax,\n        i_iter: int,\n        points: Iterable,\n        prev: np.ndarray,\n        diff: np.ndarray,\n        debug: bool,\n    ):\n        for axis in ax:\n            axis.clear()\n            axis.set_xlabel(\"x\")\n            axis.set_ylabel(\"z\")\n            axis.set_aspect(\"equal\")\n\n        cm = self._plot_array(\n            ax[0],\n            points,\n            np.array([self._g_func(p) for p in points]),\n            f\"({i_iter}) \" + \"$J_{tor}$\",\n            PLOT_DEFAULTS[\"current\"][\"cmap\"],\n        )\n        self._add_colorbar(cm, cax[0], \"A/m$^{2}$\\n\")\n\n        levels = np.linspace(0, 1, 11)\n        cm = self._plot_array(\n            ax[1],\n            points,\n            prev,\n            f\"({i_iter}) \" + \"$\\\\Psi_{n}$\",\n            PLOT_DEFAULTS[\"psi\"][\"cmap\"],\n            levels,\n        )\n        self._add_colorbar(cm, cax[1], \"\")\n\n        if debug:\n            cm = self._plot_array(\n                ax[2],\n                points,\n                100 * diff,\n                f\"({i_iter}) \" + \"$\\\\Psi_{n}$ error\",\n                \"seismic\",\n            )\n            self._add_colorbar(cm, cax[2], \"%\")\n\n        plt.pause(PLT_PAUSE)\n\n    def _plot_array(\n        self,\n        ax,\n        points: np.ndarray,\n        array: np.ndarray,\n        title: str,\n        cmap: str,\n        levels: Optional[np.ndarray] = None,\n    ):\n        cm = ax.tricontourf(points[:, 0], points[:, 1], array, cmap=cmap, levels=levels)\n        ax.tricontour(\n            points[:, 0], points[:, 1], array, colors=\"k\", linewidths=0.5, levels=levels\n        )\n\n        ax.set_title(title)\n        return cm\n\n    @staticmethod\n    def _add_colorbar(cm, cax, title):\n        last_axes = plt.gca()\n        ax = cm.axes\n        fig = ax.figure\n        fig.colorbar(cm, cax=cax)\n        cax.set_title(title)\n        plt.sca(last_axes)",
  "def __init__(\n        self,\n        p_prime: Optional[Callable[[float], float]] = None,\n        ff_prime: Optional[Callable[[float], float]] = None,\n        mesh: Optional[Union[dolfin.Mesh, str]] = None,\n        I_p: Optional[float] = None,\n        R_0: Optional[float] = None,\n        B_0: Optional[float] = None,\n        p_order: int = 2,\n        max_iter: int = 10,\n        iter_err_max: float = 1e-5,\n        relaxation: float = 0.0,\n    ):\n        super().__init__(p_order)\n        self._g_func = None\n        self._psi_ax = None\n        self._psi_b = None\n        self._grad_psi = None\n        self._pprime = None\n        self._ffprime = None\n\n        self._curr_target = I_p\n        self._R_0 = R_0\n        self._B_0 = B_0\n\n        if (p_prime is not None) and (ff_prime is not None):\n            self.set_profiles(p_prime, ff_prime)\n\n        if mesh is not None:\n            self.set_mesh(mesh)\n\n        self.iter_err_max = iter_err_max\n        self.max_iter = max_iter\n        self.relaxation = relaxation\n        self.k = 1",
  "def psi_ax(self) -> float:\n        \"\"\"Poloidal flux on the magnetic axis\"\"\"\n        if self._psi_ax is None:\n            self._psi_ax = self.psi(find_magnetic_axis(self.psi, self.mesh))\n        return self._psi_ax",
  "def psi_b(self) -> float:\n        \"\"\"Poloidal flux on the boundary\"\"\"\n        if self._psi_b is None:\n            self._psi_b = 0.0\n        return self._psi_b",
  "def grad_psi(self, point: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Calculate the gradients of psi at a point\n        \"\"\"\n        if self._grad_psi is None:\n            w = dolfin.VectorFunctionSpace(self.mesh, \"CG\", 1)\n            dpsi_dx = self.psi.dx(0)\n            dpsi_dz = self.psi.dx(1)\n            self._grad_psi = dolfin.project(dolfin.as_vector((dpsi_dx, dpsi_dz)), w)\n            self._grad_psi.set_allow_extrapolation(True)\n        return self._grad_psi(point)",
  "def psi_norm_2d(self) -> Callable[[np.ndarray], np.ndarray]:\n        \"\"\"Normalized flux function in 2-D\"\"\"\n        return lambda x: np.sqrt(\n            np.abs((self.psi(x) - self.psi_ax) / (self.psi_b - self.psi_ax))\n        )",
  "def set_mesh(self, mesh: Union[dolfin.Mesh, str]):\n        \"\"\"\n        Set the mesh for the solver\n\n        Parameters\n        ----------\n        mesh:\n            Filename of the xml file with the mesh definition or a dolfin mesh\n        \"\"\"\n        super().set_mesh(mesh=mesh)\n        self._reset_psi_cache()",
  "def _create_g_func(\n        self,\n        pprime: Union[Callable[[np.ndarray], np.ndarray], float],\n        ffprime: Union[Callable[[np.ndarray], np.ndarray], float],\n        curr_target: Optional[float] = None,\n    ) -> Callable[[np.ndarray], float]:\n        \"\"\"\n        Return the density current function given pprime and ffprime.\n\n        Parameters\n        ----------\n        pprime:\n            pprime as function of psi_norm (1-D function)\n        ffprime:\n            ffprime as function of psi_norm (1-D function)\n        curr_target:\n            Target current (also used to initialize the solution in case self.psi is\n            still 0 and pprime and ffprime are, then, not defined) [A]\n\n        Returns\n        -------\n        Source current callable to solve the magnetostatic problem\n        \"\"\"\n        area = dolfin.assemble(\n            dolfin.Constant(1) * dolfin.Measure(\"dx\", domain=self.mesh)()\n        )\n\n        j_target = curr_target / area if curr_target else 1.0\n\n        def g(x):\n            if self.psi_ax == 0:\n                return j_target\n            else:\n                r = x[0]\n                x_psi = self.psi_norm_2d(x)\n\n                a = r * pprime(x_psi)\n                b = 1 / MU_0 / r * ffprime(x_psi)\n\n                return self.k * 2 * np.pi * (a + b)\n\n        return g",
  "def define_g(self):\n        \"\"\"\n        Return the density current DOLFIN function given pprime and ffprime.\n        \"\"\"\n        self._g_func = self._create_g_func(\n            self._pprime, self._ffprime, self._curr_target\n        )\n\n        # # This instruction seems to slow the calculation\n        # super().define_g(ScalarSubFunc(self._g_func))\n\n        # it has been replaced by this code\n        dof_points = self.V.tabulate_dof_coordinates()\n        self.g.vector()[:] = np.array([self._g_func(p) for p in dof_points])",
  "def set_profiles(\n        self,\n        p_prime: Callable[[float], float],\n        ff_prime: Callable[[float], float],\n        I_p: Optional[float] = None,\n        B_0: Optional[float] = None,\n        R_0: Optional[float] = None,\n    ):\n        \"\"\"\n        Set the profies for the FEM G-S solver.\n\n        Parameters\n        ----------\n        pprime:\n            pprime as function of psi_norm (1-D function)\n        ffprime:\n            ffprime as function of psi_norm (1-D function)\n        I_p:\n            Target current (also used to initialize the solution in case self.psi is\n            still 0 and pprime and ffprime are, then, not defined).\n            If None, plasma current is calculated and not constrained\n        B_0:\n            Toroidal field at R_0 [T]. Used when saving to file.\n        R_0:\n            Major radius [m]. Used when saving to file.\n        \"\"\"\n        # Note: pprime and ffprime have been limited to a Callable,\n        # because otherwise it is necessary to provide also psi_norm_1D\n        # to which they refer.\n        if callable(p_prime):\n            self._pprime = p_prime\n            self._pprime_data = p_prime(np.linspace(0, 1, 50))\n        else:\n            raise ValueError(\"p_prime must be a function\")\n        if callable(ff_prime):\n            self._ffprime = ff_prime\n            self._ffprime_data = ff_prime(np.linspace(0, 1, 50))\n        else:\n            raise ValueError(\"ff_prime must be a function\")\n        if I_p is not None:\n            self._curr_target = I_p\n        if B_0 is not None:\n            self._B_0 = B_0\n        if R_0 is not None:\n            self._R_0 = R_0",
  "def _calculate_curr_tot(self) -> float:\n        \"\"\"Calculate the total current into the domain\"\"\"\n        return dolfin.assemble(self.g * dolfin.Measure(\"dx\", domain=self.mesh)())",
  "def _update_curr(self):\n        self.k = 1\n\n        self.define_g()\n\n        if self._curr_target:\n            self.k = self._curr_target / self._calculate_curr_tot()",
  "def _reset_psi_cache(self):\n        \"\"\"\n        Reset cached psi-axis and psi-boundary properties.\n        \"\"\"\n        self._psi_b = None\n        self._psi_ax = None\n        self._grad_psi = None",
  "def _check_all_inputs_ready_error(self):\n        if self.mesh is None:\n            raise EquilibriaError(\n                \"You cannot solve this problem yet! Please set the mesh first, using set_mesh(mesh).\"\n            )\n        if self._pprime is None or self._ffprime is None:\n            raise EquilibriaError(\n                \"You cannot solve this problem yet! Please set the profile functions first, using set_profiles(p_prime, ff_prime).\"\n            )",
  "def solve(\n        self,\n        plot: bool = False,\n        debug: bool = False,\n        gif: bool = False,\n        figname: Optional[str] = None,\n    ) -> FixedBoundaryEquilibrium:\n        \"\"\"\n        Solve the G-S problem.\n\n        Parameters\n        ----------\n        plot:\n            Whether or not to plot\n        debug:\n            Whether or not to display debug information\n        gif: bool\n            Whether or not to produce a GIF\n        figname:\n            The name of the figure. If None, a suitable default is used.\n\n        Returns\n        -------\n        FixedBoundaryEquilibrium object corresponding to the solve\n        \"\"\"\n        self._check_all_inputs_ready_error()\n        self.define_g()\n\n        points = self.mesh.coordinates()\n        plot = any((plot, debug, gif))\n        folder = try_get_bluemira_path(\n            \"\", subfolder=\"generated_data\", allow_missing=False\n        )\n        if figname is None:\n            figname = \"Fixed boundary equilibrium iteration \"\n\n        super().solve()\n        self._reset_psi_cache()\n        self._update_curr()\n\n        if plot:\n            plot_defaults()\n            f, ax, cax = self._setup_plot(debug)\n\n        diff = np.zeros(len(points))\n        for i in range(1, self.max_iter + 1):\n            prev_psi = self.psi.vector()[:]\n            prev = np.array([self.psi_norm_2d(p) for p in points])\n\n            if plot:\n                self._plot_current_iteration(f, ax, cax, i, points, prev, diff, debug)\n                if debug or gif:\n                    save_figure(\n                        f,\n                        figname + str(i),\n                        save=True,\n                        folder=folder,\n                        dpi=DPI_GIF,\n                    )\n\n            super().solve()\n            self._reset_psi_cache()\n\n            new = np.array([self.psi_norm_2d(p) for p in points])\n            diff = new - prev\n\n            eps = np.linalg.norm(diff, ord=2) / np.linalg.norm(new, ord=2)\n\n            bluemira_print_flush(\n                f\"iter = {i} eps = {eps:.3E} psi_ax : {self.psi_ax:.2f}\"\n            )\n\n            # Update psi in-place (Fenics handles this with the below syntax)\n            self.psi.vector()[:] = (1 - self.relaxation) * self.psi.vector()[\n                :\n            ] + self.relaxation * prev_psi\n\n            self._update_curr()\n\n            if eps < self.iter_err_max:\n                break\n\n        if plot:\n            plt.close(f)\n        if gif:\n            make_gif(folder, figname, clean=not debug)\n\n        return self._equilibrium()",
  "def _equilibrium(self):\n        \"\"\"Equilibrium data object\"\"\"\n        return FixedBoundaryEquilibrium(\n            self.mesh,\n            self.psi,\n            self._pprime_data,\n            self._ffprime_data,\n            self._R_0,\n            self._B_0,\n            self._calculate_curr_tot(),\n        )",
  "def _setup_plot(self, debug):\n        n_col = 3 if debug else 2\n        fig, ax = plt.subplots(1, n_col, figsize=(18, 10))\n        plt.subplots_adjust(wspace=0.5)\n\n        cax = []\n        for axis in ax:\n            divider = make_axes_locatable(axis)\n            cax.append(divider.append_axes(\"right\", size=\"10%\", pad=0.1))\n\n        return fig, ax, cax",
  "def _plot_current_iteration(\n        self,\n        f,\n        ax,\n        cax,\n        i_iter: int,\n        points: Iterable,\n        prev: np.ndarray,\n        diff: np.ndarray,\n        debug: bool,\n    ):\n        for axis in ax:\n            axis.clear()\n            axis.set_xlabel(\"x\")\n            axis.set_ylabel(\"z\")\n            axis.set_aspect(\"equal\")\n\n        cm = self._plot_array(\n            ax[0],\n            points,\n            np.array([self._g_func(p) for p in points]),\n            f\"({i_iter}) \" + \"$J_{tor}$\",\n            PLOT_DEFAULTS[\"current\"][\"cmap\"],\n        )\n        self._add_colorbar(cm, cax[0], \"A/m$^{2}$\\n\")\n\n        levels = np.linspace(0, 1, 11)\n        cm = self._plot_array(\n            ax[1],\n            points,\n            prev,\n            f\"({i_iter}) \" + \"$\\\\Psi_{n}$\",\n            PLOT_DEFAULTS[\"psi\"][\"cmap\"],\n            levels,\n        )\n        self._add_colorbar(cm, cax[1], \"\")\n\n        if debug:\n            cm = self._plot_array(\n                ax[2],\n                points,\n                100 * diff,\n                f\"({i_iter}) \" + \"$\\\\Psi_{n}$ error\",\n                \"seismic\",\n            )\n            self._add_colorbar(cm, cax[2], \"%\")\n\n        plt.pause(PLT_PAUSE)",
  "def _plot_array(\n        self,\n        ax,\n        points: np.ndarray,\n        array: np.ndarray,\n        title: str,\n        cmap: str,\n        levels: Optional[np.ndarray] = None,\n    ):\n        cm = ax.tricontourf(points[:, 0], points[:, 1], array, cmap=cmap, levels=levels)\n        ax.tricontour(\n            points[:, 0], points[:, 1], array, colors=\"k\", linewidths=0.5, levels=levels\n        )\n\n        ax.set_title(title)\n        return cm",
  "def _add_colorbar(cm, cax, title):\n        last_axes = plt.gca()\n        ax = cm.axes\n        fig = ax.figure\n        fig.colorbar(cm, cax=cax)\n        cax.set_title(title)\n        plt.sca(last_axes)",
  "def g(x):\n            if self.psi_ax == 0:\n                return j_target\n            else:\n                r = x[0]\n                x_psi = self.psi_norm_2d(x)\n\n                a = r * pprime(x_psi)\n                b = 1 / MU_0 / r * ffprime(x_psi)\n\n                return self.k * 2 * np.pi * (a + b)",
  "def plot_scalar_field(\n    x: np.ndarray,\n    y: np.ndarray,\n    data: np.ndarray,\n    levels: int = 20,\n    ax: Optional[Axes] = None,\n    contour: bool = True,\n    tofill: bool = True,\n    **kwargs,\n) -> Tuple[Axes, Union[Axes, None], Union[Axes, None]]:\n    \"\"\"\n    Plot a scalar field\n\n    Parameters\n    ----------\n    x:\n        x coordinate array\n    z:\n        z coordinate array\n    data:\n        value array\n    levels:\n        Number of contour levels to plot\n    axis:\n        axis onto which to plot\n    contour:\n        Whether or not to plot contour lines\n    tofill:\n        Whether or not to plot filled contours\n\n    Returns\n    -------\n    Matplotlib axis on which the plot ocurred\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n    else:\n        fig = ax.get_figure()\n\n    defaults = {\"linewidths\": 2, \"colors\": \"k\"}\n    contour_kwargs = {**defaults, **kwargs}\n\n    cntr = None\n    cntrf = None\n\n    if contour:\n        cntr = ax.tricontour(x, y, data, levels=levels, **contour_kwargs)\n\n    if tofill:\n        cntrf = ax.tricontourf(x, y, data, levels=levels, cmap=\"RdBu_r\")\n        fig.colorbar(cntrf, ax=ax)\n\n    ax.set_xlabel(\"x [m]\")\n    ax.set_ylabel(\"z [m]\")\n    ax.set_aspect(\"equal\")\n\n    return ax, cntr, cntrf",
  "def plot_profile(\n    x: np.ndarray,\n    prof: np.ndarray,\n    var_name: str,\n    var_unit: str,\n    ax: Optional[Axes] = None,\n    show: bool = True,\n):\n    \"\"\"\n    Plot profile\n    \"\"\"\n    if ax is None:\n        _, ax = plt.subplots()\n\n    ax.plot(x, prof)\n    ax.set(xlabel=\"x (-)\", ylabel=f\"{var_name} ({var_unit})\")\n    ax.grid()\n    if show:\n        plt.show()",
  "def get_tricontours(\n    x: np.ndarray, z: np.ndarray, array: np.ndarray, value: Union[float, Iterable]\n) -> List[Union[np.ndarray, None]]:\n    \"\"\"\n    Get the contours of a value in a triangular set of points.\n\n    Parameters\n    ----------\n    x:\n        The x value array\n    z:\n        The z value array\n    array:\n        The value array\n    value:\n        The value of the desired contour in the array\n\n    Returns\n    -------\n    The points of the value contour in the array. If no contour is found\n    for a value, None is returned\n    \"\"\"\n    tri = Triangulation(x, z)\n    tcg = TriContourGenerator(tri.get_cpp_triangulation(), array)\n    if is_num(value):\n        value = [value]\n\n    results = []\n    for val in value:\n        contour = tcg.create_contour(val)[0]\n        if len(contour) > 0:\n            results.append(contour[0])\n        else:\n            bluemira_warn(f\"No tricontour found for {val=}\")\n            results.append(None)\n    return results",
  "def find_flux_surface(\n    psi_norm_func: Callable[[np.ndarray], float],\n    psi_norm: float,\n    mesh: Optional[dolfin.Mesh] = None,\n    n_points: int = 100,\n) -> np.ndarray:\n    \"\"\"\n    Find a flux surface in the psi_norm function precisely by normalised psi value.\n\n    Parameters\n    ----------\n    psi_norm_func:\n        Function to calculate normalised psi\n    psi_norm:\n        Normalised psi value for which to find the flux surface\n    mesh:\n        Mesh object to use to estimate the flux surface\n        If None, reasonable guesses are used.\n    n_points:\n        Number of points along the flux surface\n\n    Returns\n    -------\n    x, z coordinates of the flux surface\n    \"\"\"\n    x_axis, z_axis = find_magnetic_axis(lambda x: -psi_norm_func(x), mesh=mesh)\n\n    if mesh:\n        search_range = mesh.hmax()\n        mpoints = mesh.coordinates()\n        psi_norm_array = [psi_norm_func(x) for x in mpoints]\n        contour = get_tricontours(\n            mpoints[:, 0], mpoints[:, 1], psi_norm_array, psi_norm\n        )[0]\n        d_guess = np.array([abs(np.max(contour[0, :]) - x_axis) - search_range])\n\n        def lower_bound(x):\n            return max(0.1, x - search_range)\n\n        def upper_bound(x):\n            return x + search_range\n\n    else:\n        d_guess = np.array([0.5])\n\n        def lower_bound(x):\n            return 0.1\n\n        def upper_bound(x):\n            return np.inf\n\n    def psi_norm_match(x):\n        return abs(psi_norm_func(x) - psi_norm)\n\n    def theta_line(d, theta_i):\n        return float(x_axis + d * np.cos(theta_i)), float(z_axis + d * np.sin(theta_i))\n\n    def psi_line_match(d, theta):\n        return psi_norm_match(theta_line(d, theta))\n\n    theta = np.linspace(0, 2 * np.pi, n_points - 1, endpoint=False, dtype=float)\n    points = np.zeros((2, n_points), dtype=float)\n    distances = np.zeros(n_points)\n\n    for i in range(len(theta)):\n        result = optimise(\n            f_objective=lambda d: psi_line_match(d, theta[i]),\n            x0=d_guess,\n            dimensions=1,\n            algorithm=\"SLSQP\",\n            opt_conditions={\"ftol_abs\": 1e-14, \"max_eval\": 1000},\n            bounds=(lower_bound(d_guess), upper_bound(d_guess)),\n        )\n        points[:, i] = theta_line(result.x, theta[i])\n        distances[i] = result.x\n        d_guess = result.x\n\n    points[:, -1] = points[:, 0]\n\n    return points",
  "def get_mesh_boundary(mesh: dolfin.Mesh) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Retrieve the boundary of the mesh, as an ordered set of coordinates.\n\n    Parameters\n    ----------\n    mesh:\n        Mesh for which to retrieve the exterior boundary\n\n    Returns\n    -------\n    xbdry:\n        x coordinates of the boundary\n    zbdry:\n        z coordinates of the boundary\n    \"\"\"\n    boundary = BoundaryMesh(mesh, \"exterior\")\n    edges = boundary.cells()\n    check_edge = np.ones(boundary.num_edges())\n\n    index = 0\n    temp_edge = edges[index]\n    sorted_v = []\n    sorted_v.append(temp_edge[0])\n\n    for i in range(len(edges) - 1):\n        temp_v = [v for v in temp_edge if v not in sorted_v][0]\n        sorted_v.append(temp_v)\n        check_edge[index] = 0\n        connected = np.where(edges == temp_v)[0]\n        index = [e for e in connected if check_edge[e] == 1][0]\n        temp_edge = edges[index]\n\n    points_sorted = []\n    for v in sorted_v:\n        points_sorted.append(Vertex(boundary, v).point().array())\n    points_sorted = np.array(points_sorted)\n    return points_sorted[:, 0], points_sorted[:, 1]",
  "def get_flux_surfaces_from_mesh(\n    mesh: dolfin.Mesh,\n    psi_norm_func: Callable[[float, float], float],\n    x_1d: Optional[np.ndarray] = None,\n    nx: Optional[int] = None,\n) -> Tuple[np.ndarray, List[ClosedFluxSurface]]:\n    \"\"\"\n    Get a list of flux surfaces from a mesh and normalised psi callable.\n\n    Parameters\n    ----------\n    mesh:\n        Mesh for which to extract the flux surfaces\n    psi_norm_func:\n        Callable for psi_norm on the mesh\n    x_1d:\n        Array of 1-D normalised psi_values [0..1]. If None, nx will\n        define a linearly spaced vector.\n    nx:\n        Number of points to linearly space along [0..1]. If x_1d is\n        defined, not used.\n\n    Returns\n    -------\n    x_1d:\n        The 1-D normalised psi_values for which flux surfaces could be\n        retrieved.\n    flux_surfaces:\n        The list of closed flux surfaces\n\n    Notes\n    -----\n    x_1d is returned, as it is not always possible to return a flux surface for\n    small values of normalised psi.\n    \"\"\"\n    if x_1d is None:\n        if nx is None:\n            raise ValueError(\"Please input either x_1d: np.ndarray or nx: int.\")\n        else:\n            x_1d = np.linspace(0, 1, nx)\n    else:\n        if nx is not None:\n            bluemira_warn(\"x_1d and nx specified, discarding nx.\")\n\n    mesh_points = mesh.coordinates()\n    x = mesh_points[:, 0]\n    z = mesh_points[:, 1]\n    psi_norm_data = np.array([psi_norm_func(p) for p in mesh_points])\n\n    index = []\n    flux_surfaces = []\n    for i, xi in enumerate(x_1d):\n        if np.isclose(xi, 1.0, rtol=0, atol=EPS):\n            path = get_mesh_boundary(mesh)\n            fs = Coordinates({\"x\": path[0], \"z\": path[1]})\n            fs.close()\n            flux_surfaces.append(ClosedFluxSurface(fs))\n        else:\n            path = get_tricontours(x, z, psi_norm_data, xi)[0]\n            if path is not None:\n                fs = Coordinates({\"x\": path.T[0], \"z\": path.T[1]})\n                fs.close()\n                flux_surfaces.append(ClosedFluxSurface(fs))\n            else:\n                index.append(i)\n\n    mask = np.ones_like(x_1d, dtype=bool)\n    mask[index] = False\n    return x_1d[mask], flux_surfaces",
  "def calculate_plasma_shape_params(\n    psi_norm_func: Callable[[np.ndarray], np.ndarray],\n    mesh: dolfin.Mesh,\n    psi_norm: float,\n    plot: bool = False,\n) -> Tuple[float, float, float]:\n    \"\"\"\n    Calculate the plasma parameters (r_geo, kappa, delta) for a given magnetic\n    isoflux from the mesh.\n\n    Parameters\n    ----------\n    psi_norm_func:\n        Function to calculate normalised psi\n    mesh:\n        Mesh object to use to estimate extrema prior to optimisation\n    psi_norm:\n        Normalised psi value for which to calculate the shape parameters\n    plot:\n        Whether or not to plot\n\n    Returns\n    -------\n    r_geo:\n        Geometric major radius of the flux surface at psi_norm\n    kappa:\n        Elongation of the flux surface at psi_norm\n    delta:\n        Triangularity of the flux surface at psi_norm\n    \"\"\"\n    points = mesh.coordinates()\n    psi_norm_array = [psi_norm_func(x) for x in points]\n\n    contour = get_tricontours(points[:, 0], points[:, 1], psi_norm_array, psi_norm)[0]\n    x, z = contour.T\n\n    pu = contour[np.argmax(z)]\n    pl = contour[np.argmin(z)]\n    po = contour[np.argmax(x)]\n    pi = contour[np.argmin(x)]\n\n    if plot:\n        _, ax = plt.subplots()\n        dolfin.plot(mesh)\n        ax.tricontour(points[:, 0], points[:, 1], psi_norm_array)\n        ax.plot(x, z, color=\"r\")\n        ax.plot(*po, marker=\"o\", color=\"r\")\n        ax.plot(*pi, marker=\"o\", color=\"r\")\n        ax.plot(*pu, marker=\"o\", color=\"r\")\n        ax.plot(*pl, marker=\"o\", color=\"r\")\n\n        ax.set_aspect(\"equal\")\n        plt.show()\n\n    # geometric center of a magnetic flux surface\n    r_geo = 0.5 * (po[0] + pi[0])\n\n    # elongation\n    a = 0.5 * (po[0] - pi[0])\n    b = 0.5 * (pu[1] - pl[1])\n    kappa = 1 if a == 0 else b / a\n\n    # triangularity\n    c = r_geo - pl[0]\n    d = r_geo - pu[0]\n    delta = 0 if a == 0 else 0.5 * (c + d) / a\n\n    return r_geo, kappa, delta",
  "def find_magnetic_axis(\n    psi_func: Callable[[np.ndarray], float], mesh: Optional[dolfin.Mesh] = None\n) -> np.ndarray:\n    \"\"\"\n    Find the magnetic axis in the poloidal flux map.\n\n    Parameters\n    ----------\n    psi_func:\n        Function to return psi at a given point\n    mesh:\n        Mesh object to use to estimate magnetic axis prior to optimisation\n        If None, a reasonable guess is made.\n\n    Returns\n    -------\n    Position vector (2) of the magnetic axis [m]\n    \"\"\"\n    if mesh:\n        points = mesh.coordinates()\n        psi_array = [psi_func(x) for x in points]\n        psi_max_arg = np.argmax(psi_array)\n\n        x0 = points[psi_max_arg]\n        search_range = mesh.hmax()\n        lower_bounds = x0 - search_range\n        upper_bounds = x0 + search_range\n    else:\n        x0 = np.array([0.1, 0.0])\n        lower_bounds = np.array([0, -2.0])\n        upper_bounds = np.array([20.0, 2.0])\n\n    def maximise_psi(x: npt.NDArray) -> float:\n        return -psi_func(x)\n\n    x_star = optimise(\n        f_objective=maximise_psi,\n        x0=x0,\n        dimensions=2,\n        algorithm=\"SLSQP\",\n        opt_conditions={\"ftol_abs\": 1e-6, \"max_eval\": 1000},\n        bounds=(lower_bounds, upper_bounds),\n    )\n\n    return x_star.x",
  "def _interpolate_profile(\n    x: np.ndarray, profile_data: np.ndarray\n) -> Callable[[np.ndarray], np.ndarray]:\n    \"\"\"Interpolate profile data\"\"\"\n    return interp1d(x, profile_data, kind=\"linear\", fill_value=\"extrapolate\")",
  "def _cell_near_point(cell: dolfin.Cell, refine_point: Iterable, distance: float) -> bool:\n    \"\"\"\n    Determine whether or not a cell is in the vicinity of a point.\n\n    Parameters\n    ----------\n    cell:\n        Cell to check for vicintiy to a point\n    refine_point:\n        Point from which to determine vicinity to a cell\n    distance:\n        Distance away from the midpoint of the cell to determine vicinity\n    Returns\n    -------\n    Whether or not the cell is in the vicinity of a point\n    \"\"\"\n    # Get the center of the cell\n    # Calculate the distance between the cell center and the refinement point\n    # Refine the cell if it is close to the refinement point\n    return np.linalg.norm(cell.midpoint()[:] - np.array(refine_point)) < distance",
  "def refine_mesh(\n    mesh: dolfin.Mesh,\n    refine_point: Iterable[float],\n    distance: float,\n    num_levels: int = 1,\n) -> dolfin.Mesh:\n    \"\"\"\n    Refine the mesh around a reference point.\n\n    Parameters\n    ----------\n    mesh:\n        Mesh to refine\n    refine_point:\n        Point at which to refine the mesh\n    distance:\n        Refinement distance from the point\n    num_levels:\n        Number of refinement levels\n\n    Returns\n    -------\n    Refined mesh\n    \"\"\"\n    for _ in range(num_levels):\n        cell_markers = dolfin.MeshFunction(\"bool\", mesh, mesh.topology().dim())\n        cell_markers.set_all(False)\n        for cell in dolfin.cells(mesh):\n            if _cell_near_point(cell, refine_point, distance):\n                cell_markers[cell.index()] = True\n        mesh = dolfin.refine(mesh, cell_markers)\n\n    return mesh",
  "def create_mesh(\n    plasma: PhysicalComponent,\n    directory: str,\n    mesh_filename: str,\n    mesh_name_msh: str,\n) -> Mesh:\n    \"\"\"\n    Create mesh\n    \"\"\"\n    meshing.Mesh(meshfile=os.path.join(directory, mesh_name_msh))(plasma)\n    msh_to_xdmf(mesh_name_msh, dimensions=(0, 2), directory=directory)\n    return import_mesh(mesh_filename, directory=directory, subdomains=True)[0]",
  "def psi_norm_match(x):\n        return abs(psi_norm_func(x) - psi_norm)",
  "def theta_line(d, theta_i):\n        return float(x_axis + d * np.cos(theta_i)), float(z_axis + d * np.sin(theta_i))",
  "def psi_line_match(d, theta):\n        return psi_norm_match(theta_line(d, theta))",
  "def maximise_psi(x: npt.NDArray) -> float:\n        return -psi_func(x)",
  "def lower_bound(x):\n            return max(0.1, x - search_range)",
  "def upper_bound(x):\n            return x + search_range",
  "def lower_bound(x):\n            return 0.1",
  "def upper_bound(x):\n            return np.inf",
  "class CoilGroupFieldsMixin:\n    \"\"\"\n    CoilGroup magnetic fields mixin.\n\n    Add field calculation mechanics to coilgroups\n    \"\"\"\n\n    __slots__ = (\n        \"_quad_dx\",\n        \"_quad_dz\",\n        \"_quad_x\",\n        \"_quad_z\",\n        \"_quad_weighting\",\n        \"_einsum_str\",\n    )\n\n    def psi(self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]):\n        \"\"\"\n        Calculate poloidal flux at (x, z)\n        \"\"\"\n        return self.psi_response(x, z) * self.current\n\n    def _psi_greens(self, pgreen: Union[float, np.ndarray]):\n        \"\"\"\n        Calculate plasma psi from Greens functions and current\n        \"\"\"\n        return self.current * pgreen\n\n    def psi_response(self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]):\n        \"\"\"\n        Calculate poloidal flux at (x, z) due to a unit current\n        \"\"\"\n        x, z = np.ascontiguousarray(x), np.ascontiguousarray(z)\n\n        ind = np.where(self._quad_weighting != 0)\n        out = np.zeros((*x.shape, *self._quad_x.shape))\n\n        out[(*(slice(None) for _ in x.shape), *ind)] = greens_psi(\n            self._quad_x[ind][np.newaxis],\n            self._quad_z[ind][np.newaxis],\n            x[..., np.newaxis],\n            z[..., np.newaxis],\n            self._quad_dx[ind][np.newaxis],\n            self._quad_dz[ind][np.newaxis],\n        )\n\n        return np.squeeze(\n            np.einsum(\n                self._einsum_str,\n                out,\n                self._quad_weighting[np.newaxis],\n            )\n        )\n\n    def Bx(self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]):\n        \"\"\"\n        Calculate radial magnetic field Bx at (x, z)\n        \"\"\"\n        return self.Bx_response(x, z) * self.current\n\n    def _Bx_greens(self, bgreen: Union[float, np.ndarray]):\n        \"\"\"\n        Uses the Greens mapped dict to quickly compute the Bx\n        \"\"\"\n        return self.current * bgreen\n\n    def Bx_response(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate the radial magnetic field response at (x, z) due to a unit\n        current. Green's functions are used outside the coil, and a semianalytic\n        method is used for the field inside the coil.\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the Bx response\n        z:\n            The z values at which to calculate the Bx response\n\n        Returns\n        -------\n        The radial magnetic field response at the x, z coordinates.\n        \"\"\"\n        return self._mix_control_method(\n            x, z, self._Bx_response_greens, self._Bx_response_analytical\n        )\n\n    def Bz(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate vertical magnetic field Bz at (x, z)\n        \"\"\"\n        return self.Bz_response(x, z) * self.current\n\n    def _Bz_greens(self, bgreen: Union[float, np.ndarray]):\n        \"\"\"\n        Uses the Greens mapped dict to quickly compute the Bx\n        \"\"\"\n        return self.current * bgreen\n\n    def Bz_response(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate the vertical magnetic field response at (x, z) due to a unit\n        current. Green's functions are used outside the coil, and a semianalytic\n        method is used for the field inside the coil.\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the Bz response\n        z:\n            The z values at which to calculate the Bz response\n\n        Returns\n        -------\n        The vertical magnetic field response at the x, z coordinates.\n        \"\"\"\n        return self._mix_control_method(\n            x, z, self._Bz_response_greens, self._Bz_response_analytical\n        )\n\n    def Bp(self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]):\n        \"\"\"\n        Calculate poloidal magnetic field Bp at (x, z)\n        \"\"\"\n        return np.hypot(self.Bx(x, z), self.Bz(x, z))\n\n    def _mix_control_method(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        greens_func: Callable,\n        semianalytic_func: Callable,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Boiler-plate helper function to mixed the Green's function responses\n        with the semi-analytic function responses, as a function of position\n        outside/inside the coil boundary.\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        greens_func:\n            greens function\n        semianalytic_func:\n            semianalytic function\n\n        Returns\n        -------\n        Mixed control response\n        \"\"\"\n        x, z = np.ascontiguousarray(x), np.ascontiguousarray(z)\n\n        # if not wrapped in np.array the following if won't work for `Coil`\n        zero_coil_size = np.array(\n            np.logical_or(np.isclose(self.dx, 0), np.isclose(self.dz, 0))\n        )\n\n        if False in zero_coil_size:\n            # if dx or dz is not 0 and x,z inside coil\n            inside = np.logical_and(\n                self._points_inside_coil(x, z), ~zero_coil_size[np.newaxis]\n            )\n            if np.all(~inside):\n                return greens_func(x, z)\n            elif np.all(inside):\n                # Not called for circuits as they will always be a mixture\n                return semianalytic_func(x, z)\n            else:\n                return self._combined_control(\n                    inside, x, z, greens_func, semianalytic_func\n                )\n        else:\n            return greens_func(x, z)\n\n    def _combined_control(\n        self,\n        inside: np.ndarray,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        greens_func: Callable,\n        semianalytic_func: Callable,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Combine semianalytic and greens function calculation of magnetic field\n\n        Used for situation where there are calculation points both inside and\n        outside the coil boundaries.\n\n        Parameters\n        ----------\n        inside:\n            array of if the point is inside a coil\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        greens_func:\n            greens function\n        semianalytic_func:\n            semianalytic function\n\n        Returns\n        -------\n        Combined control response\n        \"\"\"\n        response = np.zeros_like(inside, dtype=float)\n        for coil, (points, qx, qz, qw, cx, cz, cdx, cdz) in enumerate(\n            zip(\n                np.moveaxis(inside, -1, 0),\n                self._quad_x,\n                self._quad_z,\n                self._quad_weighting,\n                self.x,\n                self.z,\n                self.dx,\n                self.dz,\n            )\n        ):\n            if np.any(~points):\n                response[~points, coil] = greens_func(\n                    x[~points], z[~points], True, qx, qz, qw\n                )\n\n            if np.any(points):\n                response[points, coil] = semianalytic_func(\n                    x[points], z[points], True, cx, cz, cdx, cdz\n                )\n\n        return np.squeeze(response)\n\n    def _points_inside_coil(\n        self,\n        x: Union[float, np.array],\n        z: Union[float, np.array],\n        *,\n        atol: float = X_TOLERANCE,\n    ) -> np.ndarray:\n        \"\"\"\n        Determine which points lie inside or on the coil boundary.\n\n        Parameters\n        ----------\n        x:\n            The x coordinates to check\n        z:\n            The z coordinates to check\n        atol:\n            Add an offset, to ensure points very near the edge are counted as\n            being on the edge of a coil\n\n        Returns\n        -------\n        The Boolean array of point indices inside/outside the coil boundary\n        \"\"\"\n        x, z = (\n            np.ascontiguousarray(x)[..., np.newaxis],\n            np.ascontiguousarray(z)[..., np.newaxis],\n        )\n\n        x_min, x_max = (\n            self.x - self.dx - atol,\n            self.x + self.dx + atol,\n        )\n        z_min, z_max = (\n            self.z - self.dz - atol,\n            self.z + self.dz + atol,\n        )\n        return (\n            (x >= x_min[np.newaxis])\n            & (x <= x_max[np.newaxis])\n            & (z >= z_min[np.newaxis])\n            & (z <= z_max[np.newaxis])\n        )\n\n    def _B_response_greens(\n        self,\n        greens: Callable,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        split: bool = False,\n        _quad_x: Optional[np.ndarray] = None,\n        _quad_z: Optional[np.ndarray] = None,\n        _quad_weight: Optional[np.ndarray] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate magnetic field B response at (x, z) due to a unit\n        current using Green's functions.\n\n        Parameters\n        ----------\n        greens:\n            greens function\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        split:\n            Flag for if :func:_combined_control is used\n        _quad_x:\n            :func:_combined_control x positions\n        _quad_z:\n            :func:_combined_control z positions\n        _quad_weight:\n            :func:_combined_control weighting\n\n        Returns\n        -------\n        Magnetic field response\n        \"\"\"\n        if not split:\n            _quad_x = self._quad_x\n            _quad_z = self._quad_z\n            _quad_weight = self._quad_weighting\n\n        ind = np.where(_quad_weight != 0)\n        out = np.zeros((*x.shape, *_quad_x.shape))\n\n        out[(*(slice(None) for _ in x.shape), *ind)] = greens(\n            _quad_x[ind][np.newaxis],\n            _quad_z[ind][np.newaxis],\n            x[..., np.newaxis],\n            z[..., np.newaxis],\n        )\n\n        return np.squeeze(\n            np.einsum(\n                self._einsum_str,\n                out,\n                _quad_weight,\n            )\n        )\n\n    def _Bx_response_greens(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        split: bool = False,\n        _quad_x: Optional[np.ndarray] = None,\n        _quad_z: Optional[np.ndarray] = None,\n        _quad_weight: Optional[np.ndarray] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate radial magnetic field Bx response at (x, z) due to a unit\n        current using Green's functions.\n\n        Parameters\n        ----------\n        greens:\n            greens function\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        split:\n            Flag for if :func:_combined_control is used\n        _quad_x:\n            :func:_combined_control x positions\n        _quad_z:\n            :func:_combined_control z positions\n        _quad_weight:\n            :func:_combined_control weighting\n\n        Returns\n        -------\n        Radial magnetic field response\n        \"\"\"\n        return self._B_response_greens(\n            greens_Bx, x, z, split, _quad_x, _quad_z, _quad_weight\n        )\n\n    def _Bz_response_greens(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        split: bool = False,\n        _quad_x: Optional[np.ndarray] = None,\n        _quad_z: Optional[np.ndarray] = None,\n        _quad_weight: Optional[np.ndarray] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate vertical magnetic field Bz at (x, z) due to a unit current\n\n        Parameters\n        ----------\n        greens:\n            greens function\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        split:\n            Flag for if :func:_combined_control is used\n        _quad_x:\n            :func:_combined_control x positions\n        _quad_z:\n            :func:_combined_control z positions\n        _quad_weight:\n            :func:_combined_control weighting\n\n        Returns\n        -------\n        Vertical magnetic field response\n        \"\"\"\n        return self._B_response_greens(\n            greens_Bz, x, z, split, _quad_x, _quad_z, _quad_weight\n        )\n\n    def _B_response_analytical(\n        self,\n        semianalytic: Callable,\n        x: np.ndarray,\n        z: np.ndarray,\n        split: bool = False,\n        coil_x: Optional[np.ndarray] = None,\n        coil_z: Optional[np.ndarray] = None,\n        coil_dx: Optional[np.ndarray] = None,\n        coil_dz: Optional[np.ndarray] = None,\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate magnetic field Bx response at (x, z) due to a unit\n        current using semi-analytic method.\n\n        Parameters\n        ----------\n        semianalytic:\n            semianalytic function\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        split:\n            Flag for if :func:_combined_control is used\n        coil_x:\n            :func:_combined_control x positions\n        coil_z:\n            :func:_combined_control z positions\n        coil_dx:\n            :func:_combined_control x positions\n        coil_dz:\n            :func:_combined_control z positions\n\n        Returns\n        -------\n        Magnetic field response\n        \"\"\"\n        if not split:\n            coil_x = self.x\n            coil_z = self.z\n            coil_dx = self.dx\n            coil_dz = self.dz\n\n        return np.squeeze(\n            semianalytic(\n                coil_x[np.newaxis],\n                coil_z[np.newaxis],\n                x[..., np.newaxis],\n                z[..., np.newaxis],\n                d_xc=coil_dx[np.newaxis],\n                d_zc=coil_dz[np.newaxis],\n            )\n        )\n\n    def _Bx_response_analytical(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        split: bool = False,\n        coil_x: Optional[np.ndarray] = None,\n        coil_z: Optional[np.ndarray] = None,\n        coil_dx: Optional[np.ndarray] = None,\n        coil_dz: Optional[np.ndarray] = None,\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate radial magnetic field Bx response at (x, z) due to a unit\n        current using semi-analytic method.\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        split:\n            Flag for if :func:_combined_control is used\n        coil_x:\n            :func:_combined_control x positions\n        coil_z:\n            :func:_combined_control z positions\n        coil_dx:\n            :func:_combined_control x positions\n        coil_dz:\n            :func:_combined_control z positions\n\n        Returns\n        -------\n        Radial magnetic field response\n        \"\"\"\n        return self._B_response_analytical(\n            semianalytic_Bx, x, z, split, coil_x, coil_z, coil_dx, coil_dz\n        )\n\n    def _Bz_response_analytical(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        split: bool = False,\n        coil_x: Optional[np.ndarray] = None,\n        coil_z: Optional[np.ndarray] = None,\n        coil_dx: Optional[np.ndarray] = None,\n        coil_dz: Optional[np.ndarray] = None,\n    ):\n        \"\"\"\n        Calculate vertical magnetic field Bz response at (x, z) due to a unit\n        current using semi-analytic method.\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        split:\n            Flag for if :func:_combined_control is used\n        coil_x:\n            :func:_combined_control x positions\n        coil_z:\n            :func:_combined_control z positions\n        coil_dx:\n            :func:_combined_control x positions\n        coil_dz:\n            :func:_combined_control z positions\n\n        Returns\n        -------\n        Vertical magnetic field response\n        \"\"\"\n        return self._B_response_analytical(\n            semianalytic_Bz, x, z, split, coil_x, coil_z, coil_dx, coil_dz\n        )\n\n    def F(self, eqcoil: CoilGroup) -> np.ndarray:  # noqa :N802\n        \"\"\"\n        Calculate the force response at the coil centre including the coil\n        self-force.\n\n        .... math::\n\n             \\\\mathbf{F} = \\\\mathbf{j}\\\\times \\\\mathbf{B}\n            F_x = IB_z+\\\\dfrac{\\\\mu_0I^2}{4\\\\pi X}\\\\textrm{ln}\\\\bigg(\\\\dfrac{8X}{r_c}-1+\\\\xi/2\\\\bigg)\n            F_z = -IBx\n        \"\"\"  # noqa :W505\n        multiplier = self.current * 2 * np.pi * self.x\n        cr = self._current_radius\n        if any(cr != 0):\n            # true divide errors for zero current coils\n            cr_ind = np.where(cr != 0)\n            fx = np.zeros_like(cr)\n            fx[cr_ind] = (\n                MU_0\n                * self.current[cr_ind] ** 2\n                / (4 * np.pi * self.x[cr_ind])\n                * (np.log(8 * self.x[cr_ind] / cr[cr_ind]) - 1 + 0.25)\n            )\n        else:\n            fx = 0\n\n        return np.array(\n            [\n                multiplier * (eqcoil.Bz(self.x, self.z) + fx),\n                -multiplier * eqcoil.Bx(self.x, self.z),\n            ]\n        ).T\n\n    def control_F(self, coil: CoilGroup) -> np.ndarray:  # noqa :N802\n        \"\"\"\n        Returns the Green's matrix element for the coil mutual force.\n\n        \\t:math:`Fz_{i,j}=-2\\\\pi X_i\\\\mathcal{G}(X_j,Z_j,X_i,Z_i)`\n        \"\"\"\n        # TODO Vectorise\n        x, z = np.atleast_1d(self.x), np.atleast_1d(self.z)  # single coil\n        pos = np.array([x, z])\n        response = np.zeros((x.size, coil.x.size, 2))\n        coils = coil._coils\n        for j, coil2 in enumerate(coils):\n            xw = np.where(x == coil2.x)[0]\n            zw = np.where(z == coil2.z)[0]\n            same_pos = np.where(xw == zw)[0]\n            if same_pos.size > 0:\n                # self inductance\n                xxw = xw[same_pos]\n                cr = self._current_radius[xxw]\n                Bz = np.zeros((x.size, 1))\n                Bx = Bz.copy()  # Should be 0 anyway\n                mask = np.zeros_like(Bz, dtype=bool)\n                mask[same_pos] = True\n                if any(cr != 0):\n                    cr_ind = np.where(cr != 0)\n                    Bz[mask][cr_ind] = (\n                        MU_0\n                        / (4 * np.pi * x[cr_ind])\n                        * (np.log(8 * x[cr_ind] / cr[cr_ind]) - 1 + 0.25)\n                    )\n                if False in mask:\n                    Bz[~mask] = coil2.Bz_response(*pos[:, ~mask[:, 0]])\n                    Bx[~mask] = coil2.Bx_response(*pos[:, ~mask[:, 0]])\n\n            else:\n                Bz = coil2.Bz_response(x, z)\n                Bx = coil2.Bx_response(x, z)\n            # 1 cross B\n            response[:, j, :] = (\n                2 * np.pi * x[:, np.newaxis] * np.squeeze(np.array([Bz, -Bx]).T)\n            )\n        return response",
  "class CoilSetFieldsMixin(CoilGroupFieldsMixin):\n    \"\"\"\n    CoilSet magnetic fields mixin.\n\n    Adjust output of coilgroup field calculations dealing with control coils\n    or summing over coils\n    \"\"\"\n\n    __slots__ = ()\n\n    def psi(\n        self, x: np.ndarray, z: np.ndarray, sum_coils: bool = True, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Psi of Coilset\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the psi response\n        z:\n            The z values at which to calculate the psi response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Poloidal magnetic flux density\n        \"\"\"\n        return self._sum(super().psi(x, z), sum_coils=sum_coils, control=control)\n\n    def Bx(\n        self, x: np.ndarray, z: np.ndarray, sum_coils: bool = True, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Bx of Coilset\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the Bx response\n        z:\n            The z values at which to calculate the Bx response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Radial magnetic field\n        \"\"\"\n        return self._sum(super().Bx(x, z), sum_coils=sum_coils, control=control)\n\n    def Bz(\n        self, x: np.ndarray, z: np.ndarray, sum_coils: bool = True, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Bz of Coilset\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the Bz response\n        z:\n            The z values at which to calculate the Bz response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Vertical magnetic field\n        \"\"\"\n        return self._sum(super().Bz(x, z), sum_coils=sum_coils, control=control)\n\n    def psi_response(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        sum_coils: bool = False,\n        control: bool = False,\n    ) -> np.ndarray:\n        \"\"\"\n        Unit psi of Coilset\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the psi response\n        z:\n            The z values at which to calculate the psi response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Psi response\n        \"\"\"\n        return self._sum(\n            super().psi_response(x, z), sum_coils=sum_coils, control=control\n        )\n\n    def Bx_response(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        sum_coils: bool = False,\n        control: bool = False,\n    ) -> np.ndarray:\n        \"\"\"\n        Unit Bx of Coilset\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the Bx response\n        z:\n            The z values at which to calculate the Bx response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Bx response\n        \"\"\"\n        return self._sum(super().Bx_response(x, z), sum_coils=sum_coils, control=control)\n\n    def Bz_response(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        sum_coils: bool = False,\n        control: bool = False,\n    ) -> np.ndarray:\n        \"\"\"\n        Bz of Coilset\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the Bz response\n        z:\n            The z values at which to calculate the Bz response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Bz response\n        \"\"\"\n        return self._sum(super().Bz_response(x, z), sum_coils=sum_coils, control=control)\n\n    def _psi_greens(\n        self, psigreens: np.ndarray, sum_coils: bool = True, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Uses the Greens mapped dict to quickly compute the psi\n\n        Parameters\n        ----------\n        psigreens:\n            The unit psi response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Cached Greens psi response\n        \"\"\"\n        return self._sum(\n            super()._psi_greens(psigreens), sum_coils=sum_coils, control=control\n        )\n\n    def _Bx_greens(\n        self, bgreen: np.ndarray, sum_coils: bool = True, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Uses the Greens mapped dict to quickly compute the Bx\n\n        Parameters\n        ----------\n        bgreen:\n            The unit Bx response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Cached Greens Bx response\n        \"\"\"\n        return self._sum(\n            super()._Bx_greens(bgreen), sum_coils=sum_coils, control=control\n        )\n\n    def _Bz_greens(\n        self, bgreen: np.ndarray, sum_coils: bool = True, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Uses the Greens mapped dict to quickly compute the Bz\n\n        Parameters\n        ----------\n        bgreen:\n            The unit Bz response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Cached Greens Bs response\n        \"\"\"\n        return self._sum(\n            super()._Bz_greens(bgreen), sum_coils=sum_coils, control=control\n        )",
  "class CoilFieldsMixin(CoilGroupFieldsMixin):\n    \"\"\"\n    Coil magnetic fields mixin.\n\n    Add field calculation mechanics to Coils\n    \"\"\"\n\n    __slots__ = ()\n\n    def _points_inside_coil(\n        self,\n        x: Union[float, np.array],\n        z: Union[float, np.array],\n        *,\n        atol: float = X_TOLERANCE,\n    ) -> np.ndarray:\n        \"\"\"\n        Determine which points lie inside or on the coil boundary.\n\n        Parameters\n        ----------\n        x:\n            The x values to check\n        z:\n            The z values to check\n        atol:\n            Add an offset, to ensure points very near the edge are counted as\n            being on the edge of a coil\n\n        Returns\n        -------\n        The Boolean array of point indices inside/outside the coil boundary\n        \"\"\"\n        x, z = (\n            np.ascontiguousarray(x)[..., np.newaxis],\n            np.ascontiguousarray(z)[..., np.newaxis],\n        )\n\n        x_min, x_max = (\n            self.x - self.dx - atol,\n            self.x + self.dx + atol,\n        )\n        z_min, z_max = (\n            self.z - self.dz - atol,\n            self.z + self.dz + atol,\n        )\n        return (x >= x_min) & (x <= x_max) & (z >= z_min) & (z <= z_max)\n\n    def _combined_control(\n        self,\n        inside: np.ndarray,\n        x: np.ndarray,\n        z: np.ndarray,\n        greens_func: Callable,\n        semianalytic_func: Callable,\n    ):\n        \"\"\"\n        Combine semianalytic and greens function calculation of magnetic field\n\n        Used for situation where there are calculation points both inside and\n        outside the coil boundaries.\n\n        Parameters\n        ----------\n        inside:\n            array of if the point is inside a coil\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        greens_func:\n            greens function\n        semianalytic_func:\n            semianalytic function\n\n        Returns\n        -------\n        Combined response\n        \"\"\"\n        response = np.zeros(inside.shape[:-1])\n        points = inside[..., 0]\n\n        if np.any(~points):\n            response[~points] = greens_func(x[~points], z[~points])\n\n        if np.any(points):\n            response[points] = semianalytic_func(x[points], z[points])\n\n        return response\n\n    def _B_response_analytical(\n        self,\n        semianalytic: Callable,\n        x: np.ndarray,\n        z: np.ndarray,\n        *args,\n        **kwargs,\n    ):\n        \"\"\"\n        Calculate [psi, Bx, Bz] response at (x, z) due to a unit\n        current using semi-analytic method.\n\n        Parameters\n        ----------\n        semianalytic:\n            semianalytic function\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n\n        Returns\n        -------\n        Analytical response\n        \"\"\"\n        return super()._B_response_analytical(\n            semianalytic,\n            x,\n            z,\n            split=True,\n            coil_x=np.array([self.x]),\n            coil_z=np.array([self.z]),\n            coil_dx=np.array([self.dx]),\n            coil_dz=np.array([self.dz]),\n        )",
  "def psi(self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]):\n        \"\"\"\n        Calculate poloidal flux at (x, z)\n        \"\"\"\n        return self.psi_response(x, z) * self.current",
  "def _psi_greens(self, pgreen: Union[float, np.ndarray]):\n        \"\"\"\n        Calculate plasma psi from Greens functions and current\n        \"\"\"\n        return self.current * pgreen",
  "def psi_response(self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]):\n        \"\"\"\n        Calculate poloidal flux at (x, z) due to a unit current\n        \"\"\"\n        x, z = np.ascontiguousarray(x), np.ascontiguousarray(z)\n\n        ind = np.where(self._quad_weighting != 0)\n        out = np.zeros((*x.shape, *self._quad_x.shape))\n\n        out[(*(slice(None) for _ in x.shape), *ind)] = greens_psi(\n            self._quad_x[ind][np.newaxis],\n            self._quad_z[ind][np.newaxis],\n            x[..., np.newaxis],\n            z[..., np.newaxis],\n            self._quad_dx[ind][np.newaxis],\n            self._quad_dz[ind][np.newaxis],\n        )\n\n        return np.squeeze(\n            np.einsum(\n                self._einsum_str,\n                out,\n                self._quad_weighting[np.newaxis],\n            )\n        )",
  "def Bx(self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]):\n        \"\"\"\n        Calculate radial magnetic field Bx at (x, z)\n        \"\"\"\n        return self.Bx_response(x, z) * self.current",
  "def _Bx_greens(self, bgreen: Union[float, np.ndarray]):\n        \"\"\"\n        Uses the Greens mapped dict to quickly compute the Bx\n        \"\"\"\n        return self.current * bgreen",
  "def Bx_response(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate the radial magnetic field response at (x, z) due to a unit\n        current. Green's functions are used outside the coil, and a semianalytic\n        method is used for the field inside the coil.\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the Bx response\n        z:\n            The z values at which to calculate the Bx response\n\n        Returns\n        -------\n        The radial magnetic field response at the x, z coordinates.\n        \"\"\"\n        return self._mix_control_method(\n            x, z, self._Bx_response_greens, self._Bx_response_analytical\n        )",
  "def Bz(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate vertical magnetic field Bz at (x, z)\n        \"\"\"\n        return self.Bz_response(x, z) * self.current",
  "def _Bz_greens(self, bgreen: Union[float, np.ndarray]):\n        \"\"\"\n        Uses the Greens mapped dict to quickly compute the Bx\n        \"\"\"\n        return self.current * bgreen",
  "def Bz_response(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate the vertical magnetic field response at (x, z) due to a unit\n        current. Green's functions are used outside the coil, and a semianalytic\n        method is used for the field inside the coil.\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the Bz response\n        z:\n            The z values at which to calculate the Bz response\n\n        Returns\n        -------\n        The vertical magnetic field response at the x, z coordinates.\n        \"\"\"\n        return self._mix_control_method(\n            x, z, self._Bz_response_greens, self._Bz_response_analytical\n        )",
  "def Bp(self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]):\n        \"\"\"\n        Calculate poloidal magnetic field Bp at (x, z)\n        \"\"\"\n        return np.hypot(self.Bx(x, z), self.Bz(x, z))",
  "def _mix_control_method(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        greens_func: Callable,\n        semianalytic_func: Callable,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Boiler-plate helper function to mixed the Green's function responses\n        with the semi-analytic function responses, as a function of position\n        outside/inside the coil boundary.\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        greens_func:\n            greens function\n        semianalytic_func:\n            semianalytic function\n\n        Returns\n        -------\n        Mixed control response\n        \"\"\"\n        x, z = np.ascontiguousarray(x), np.ascontiguousarray(z)\n\n        # if not wrapped in np.array the following if won't work for `Coil`\n        zero_coil_size = np.array(\n            np.logical_or(np.isclose(self.dx, 0), np.isclose(self.dz, 0))\n        )\n\n        if False in zero_coil_size:\n            # if dx or dz is not 0 and x,z inside coil\n            inside = np.logical_and(\n                self._points_inside_coil(x, z), ~zero_coil_size[np.newaxis]\n            )\n            if np.all(~inside):\n                return greens_func(x, z)\n            elif np.all(inside):\n                # Not called for circuits as they will always be a mixture\n                return semianalytic_func(x, z)\n            else:\n                return self._combined_control(\n                    inside, x, z, greens_func, semianalytic_func\n                )\n        else:\n            return greens_func(x, z)",
  "def _combined_control(\n        self,\n        inside: np.ndarray,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        greens_func: Callable,\n        semianalytic_func: Callable,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Combine semianalytic and greens function calculation of magnetic field\n\n        Used for situation where there are calculation points both inside and\n        outside the coil boundaries.\n\n        Parameters\n        ----------\n        inside:\n            array of if the point is inside a coil\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        greens_func:\n            greens function\n        semianalytic_func:\n            semianalytic function\n\n        Returns\n        -------\n        Combined control response\n        \"\"\"\n        response = np.zeros_like(inside, dtype=float)\n        for coil, (points, qx, qz, qw, cx, cz, cdx, cdz) in enumerate(\n            zip(\n                np.moveaxis(inside, -1, 0),\n                self._quad_x,\n                self._quad_z,\n                self._quad_weighting,\n                self.x,\n                self.z,\n                self.dx,\n                self.dz,\n            )\n        ):\n            if np.any(~points):\n                response[~points, coil] = greens_func(\n                    x[~points], z[~points], True, qx, qz, qw\n                )\n\n            if np.any(points):\n                response[points, coil] = semianalytic_func(\n                    x[points], z[points], True, cx, cz, cdx, cdz\n                )\n\n        return np.squeeze(response)",
  "def _points_inside_coil(\n        self,\n        x: Union[float, np.array],\n        z: Union[float, np.array],\n        *,\n        atol: float = X_TOLERANCE,\n    ) -> np.ndarray:\n        \"\"\"\n        Determine which points lie inside or on the coil boundary.\n\n        Parameters\n        ----------\n        x:\n            The x coordinates to check\n        z:\n            The z coordinates to check\n        atol:\n            Add an offset, to ensure points very near the edge are counted as\n            being on the edge of a coil\n\n        Returns\n        -------\n        The Boolean array of point indices inside/outside the coil boundary\n        \"\"\"\n        x, z = (\n            np.ascontiguousarray(x)[..., np.newaxis],\n            np.ascontiguousarray(z)[..., np.newaxis],\n        )\n\n        x_min, x_max = (\n            self.x - self.dx - atol,\n            self.x + self.dx + atol,\n        )\n        z_min, z_max = (\n            self.z - self.dz - atol,\n            self.z + self.dz + atol,\n        )\n        return (\n            (x >= x_min[np.newaxis])\n            & (x <= x_max[np.newaxis])\n            & (z >= z_min[np.newaxis])\n            & (z <= z_max[np.newaxis])\n        )",
  "def _B_response_greens(\n        self,\n        greens: Callable,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        split: bool = False,\n        _quad_x: Optional[np.ndarray] = None,\n        _quad_z: Optional[np.ndarray] = None,\n        _quad_weight: Optional[np.ndarray] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate magnetic field B response at (x, z) due to a unit\n        current using Green's functions.\n\n        Parameters\n        ----------\n        greens:\n            greens function\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        split:\n            Flag for if :func:_combined_control is used\n        _quad_x:\n            :func:_combined_control x positions\n        _quad_z:\n            :func:_combined_control z positions\n        _quad_weight:\n            :func:_combined_control weighting\n\n        Returns\n        -------\n        Magnetic field response\n        \"\"\"\n        if not split:\n            _quad_x = self._quad_x\n            _quad_z = self._quad_z\n            _quad_weight = self._quad_weighting\n\n        ind = np.where(_quad_weight != 0)\n        out = np.zeros((*x.shape, *_quad_x.shape))\n\n        out[(*(slice(None) for _ in x.shape), *ind)] = greens(\n            _quad_x[ind][np.newaxis],\n            _quad_z[ind][np.newaxis],\n            x[..., np.newaxis],\n            z[..., np.newaxis],\n        )\n\n        return np.squeeze(\n            np.einsum(\n                self._einsum_str,\n                out,\n                _quad_weight,\n            )\n        )",
  "def _Bx_response_greens(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        split: bool = False,\n        _quad_x: Optional[np.ndarray] = None,\n        _quad_z: Optional[np.ndarray] = None,\n        _quad_weight: Optional[np.ndarray] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate radial magnetic field Bx response at (x, z) due to a unit\n        current using Green's functions.\n\n        Parameters\n        ----------\n        greens:\n            greens function\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        split:\n            Flag for if :func:_combined_control is used\n        _quad_x:\n            :func:_combined_control x positions\n        _quad_z:\n            :func:_combined_control z positions\n        _quad_weight:\n            :func:_combined_control weighting\n\n        Returns\n        -------\n        Radial magnetic field response\n        \"\"\"\n        return self._B_response_greens(\n            greens_Bx, x, z, split, _quad_x, _quad_z, _quad_weight\n        )",
  "def _Bz_response_greens(\n        self,\n        x: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n        split: bool = False,\n        _quad_x: Optional[np.ndarray] = None,\n        _quad_z: Optional[np.ndarray] = None,\n        _quad_weight: Optional[np.ndarray] = None,\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate vertical magnetic field Bz at (x, z) due to a unit current\n\n        Parameters\n        ----------\n        greens:\n            greens function\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        split:\n            Flag for if :func:_combined_control is used\n        _quad_x:\n            :func:_combined_control x positions\n        _quad_z:\n            :func:_combined_control z positions\n        _quad_weight:\n            :func:_combined_control weighting\n\n        Returns\n        -------\n        Vertical magnetic field response\n        \"\"\"\n        return self._B_response_greens(\n            greens_Bz, x, z, split, _quad_x, _quad_z, _quad_weight\n        )",
  "def _B_response_analytical(\n        self,\n        semianalytic: Callable,\n        x: np.ndarray,\n        z: np.ndarray,\n        split: bool = False,\n        coil_x: Optional[np.ndarray] = None,\n        coil_z: Optional[np.ndarray] = None,\n        coil_dx: Optional[np.ndarray] = None,\n        coil_dz: Optional[np.ndarray] = None,\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate magnetic field Bx response at (x, z) due to a unit\n        current using semi-analytic method.\n\n        Parameters\n        ----------\n        semianalytic:\n            semianalytic function\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        split:\n            Flag for if :func:_combined_control is used\n        coil_x:\n            :func:_combined_control x positions\n        coil_z:\n            :func:_combined_control z positions\n        coil_dx:\n            :func:_combined_control x positions\n        coil_dz:\n            :func:_combined_control z positions\n\n        Returns\n        -------\n        Magnetic field response\n        \"\"\"\n        if not split:\n            coil_x = self.x\n            coil_z = self.z\n            coil_dx = self.dx\n            coil_dz = self.dz\n\n        return np.squeeze(\n            semianalytic(\n                coil_x[np.newaxis],\n                coil_z[np.newaxis],\n                x[..., np.newaxis],\n                z[..., np.newaxis],\n                d_xc=coil_dx[np.newaxis],\n                d_zc=coil_dz[np.newaxis],\n            )\n        )",
  "def _Bx_response_analytical(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        split: bool = False,\n        coil_x: Optional[np.ndarray] = None,\n        coil_z: Optional[np.ndarray] = None,\n        coil_dx: Optional[np.ndarray] = None,\n        coil_dz: Optional[np.ndarray] = None,\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate radial magnetic field Bx response at (x, z) due to a unit\n        current using semi-analytic method.\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        split:\n            Flag for if :func:_combined_control is used\n        coil_x:\n            :func:_combined_control x positions\n        coil_z:\n            :func:_combined_control z positions\n        coil_dx:\n            :func:_combined_control x positions\n        coil_dz:\n            :func:_combined_control z positions\n\n        Returns\n        -------\n        Radial magnetic field response\n        \"\"\"\n        return self._B_response_analytical(\n            semianalytic_Bx, x, z, split, coil_x, coil_z, coil_dx, coil_dz\n        )",
  "def _Bz_response_analytical(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        split: bool = False,\n        coil_x: Optional[np.ndarray] = None,\n        coil_z: Optional[np.ndarray] = None,\n        coil_dx: Optional[np.ndarray] = None,\n        coil_dz: Optional[np.ndarray] = None,\n    ):\n        \"\"\"\n        Calculate vertical magnetic field Bz response at (x, z) due to a unit\n        current using semi-analytic method.\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        split:\n            Flag for if :func:_combined_control is used\n        coil_x:\n            :func:_combined_control x positions\n        coil_z:\n            :func:_combined_control z positions\n        coil_dx:\n            :func:_combined_control x positions\n        coil_dz:\n            :func:_combined_control z positions\n\n        Returns\n        -------\n        Vertical magnetic field response\n        \"\"\"\n        return self._B_response_analytical(\n            semianalytic_Bz, x, z, split, coil_x, coil_z, coil_dx, coil_dz\n        )",
  "def F(self, eqcoil: CoilGroup) -> np.ndarray:  # noqa :N802\n        \"\"\"\n        Calculate the force response at the coil centre including the coil\n        self-force.\n\n        .... math::\n\n             \\\\mathbf{F} = \\\\mathbf{j}\\\\times \\\\mathbf{B}\n            F_x = IB_z+\\\\dfrac{\\\\mu_0I^2}{4\\\\pi X}\\\\textrm{ln}\\\\bigg(\\\\dfrac{8X}{r_c}-1+\\\\xi/2\\\\bigg)\n            F_z = -IBx\n        \"\"\"  # noqa :W505\n        multiplier = self.current * 2 * np.pi * self.x\n        cr = self._current_radius\n        if any(cr != 0):\n            # true divide errors for zero current coils\n            cr_ind = np.where(cr != 0)\n            fx = np.zeros_like(cr)\n            fx[cr_ind] = (\n                MU_0\n                * self.current[cr_ind] ** 2\n                / (4 * np.pi * self.x[cr_ind])\n                * (np.log(8 * self.x[cr_ind] / cr[cr_ind]) - 1 + 0.25)\n            )\n        else:\n            fx = 0\n\n        return np.array(\n            [\n                multiplier * (eqcoil.Bz(self.x, self.z) + fx),\n                -multiplier * eqcoil.Bx(self.x, self.z),\n            ]\n        ).T",
  "def control_F(self, coil: CoilGroup) -> np.ndarray:  # noqa :N802\n        \"\"\"\n        Returns the Green's matrix element for the coil mutual force.\n\n        \\t:math:`Fz_{i,j}=-2\\\\pi X_i\\\\mathcal{G}(X_j,Z_j,X_i,Z_i)`\n        \"\"\"\n        # TODO Vectorise\n        x, z = np.atleast_1d(self.x), np.atleast_1d(self.z)  # single coil\n        pos = np.array([x, z])\n        response = np.zeros((x.size, coil.x.size, 2))\n        coils = coil._coils\n        for j, coil2 in enumerate(coils):\n            xw = np.where(x == coil2.x)[0]\n            zw = np.where(z == coil2.z)[0]\n            same_pos = np.where(xw == zw)[0]\n            if same_pos.size > 0:\n                # self inductance\n                xxw = xw[same_pos]\n                cr = self._current_radius[xxw]\n                Bz = np.zeros((x.size, 1))\n                Bx = Bz.copy()  # Should be 0 anyway\n                mask = np.zeros_like(Bz, dtype=bool)\n                mask[same_pos] = True\n                if any(cr != 0):\n                    cr_ind = np.where(cr != 0)\n                    Bz[mask][cr_ind] = (\n                        MU_0\n                        / (4 * np.pi * x[cr_ind])\n                        * (np.log(8 * x[cr_ind] / cr[cr_ind]) - 1 + 0.25)\n                    )\n                if False in mask:\n                    Bz[~mask] = coil2.Bz_response(*pos[:, ~mask[:, 0]])\n                    Bx[~mask] = coil2.Bx_response(*pos[:, ~mask[:, 0]])\n\n            else:\n                Bz = coil2.Bz_response(x, z)\n                Bx = coil2.Bx_response(x, z)\n            # 1 cross B\n            response[:, j, :] = (\n                2 * np.pi * x[:, np.newaxis] * np.squeeze(np.array([Bz, -Bx]).T)\n            )\n        return response",
  "def psi(\n        self, x: np.ndarray, z: np.ndarray, sum_coils: bool = True, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Psi of Coilset\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the psi response\n        z:\n            The z values at which to calculate the psi response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Poloidal magnetic flux density\n        \"\"\"\n        return self._sum(super().psi(x, z), sum_coils=sum_coils, control=control)",
  "def Bx(\n        self, x: np.ndarray, z: np.ndarray, sum_coils: bool = True, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Bx of Coilset\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the Bx response\n        z:\n            The z values at which to calculate the Bx response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Radial magnetic field\n        \"\"\"\n        return self._sum(super().Bx(x, z), sum_coils=sum_coils, control=control)",
  "def Bz(\n        self, x: np.ndarray, z: np.ndarray, sum_coils: bool = True, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Bz of Coilset\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the Bz response\n        z:\n            The z values at which to calculate the Bz response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Vertical magnetic field\n        \"\"\"\n        return self._sum(super().Bz(x, z), sum_coils=sum_coils, control=control)",
  "def psi_response(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        sum_coils: bool = False,\n        control: bool = False,\n    ) -> np.ndarray:\n        \"\"\"\n        Unit psi of Coilset\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the psi response\n        z:\n            The z values at which to calculate the psi response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Psi response\n        \"\"\"\n        return self._sum(\n            super().psi_response(x, z), sum_coils=sum_coils, control=control\n        )",
  "def Bx_response(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        sum_coils: bool = False,\n        control: bool = False,\n    ) -> np.ndarray:\n        \"\"\"\n        Unit Bx of Coilset\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the Bx response\n        z:\n            The z values at which to calculate the Bx response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Bx response\n        \"\"\"\n        return self._sum(super().Bx_response(x, z), sum_coils=sum_coils, control=control)",
  "def Bz_response(\n        self,\n        x: np.ndarray,\n        z: np.ndarray,\n        sum_coils: bool = False,\n        control: bool = False,\n    ) -> np.ndarray:\n        \"\"\"\n        Bz of Coilset\n\n        Parameters\n        ----------\n        x:\n            The x values at which to calculate the Bz response\n        z:\n            The z values at which to calculate the Bz response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Bz response\n        \"\"\"\n        return self._sum(super().Bz_response(x, z), sum_coils=sum_coils, control=control)",
  "def _psi_greens(\n        self, psigreens: np.ndarray, sum_coils: bool = True, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Uses the Greens mapped dict to quickly compute the psi\n\n        Parameters\n        ----------\n        psigreens:\n            The unit psi response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Cached Greens psi response\n        \"\"\"\n        return self._sum(\n            super()._psi_greens(psigreens), sum_coils=sum_coils, control=control\n        )",
  "def _Bx_greens(\n        self, bgreen: np.ndarray, sum_coils: bool = True, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Uses the Greens mapped dict to quickly compute the Bx\n\n        Parameters\n        ----------\n        bgreen:\n            The unit Bx response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Cached Greens Bx response\n        \"\"\"\n        return self._sum(\n            super()._Bx_greens(bgreen), sum_coils=sum_coils, control=control\n        )",
  "def _Bz_greens(\n        self, bgreen: np.ndarray, sum_coils: bool = True, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Uses the Greens mapped dict to quickly compute the Bz\n\n        Parameters\n        ----------\n        bgreen:\n            The unit Bz response\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Cached Greens Bs response\n        \"\"\"\n        return self._sum(\n            super()._Bz_greens(bgreen), sum_coils=sum_coils, control=control\n        )",
  "def _points_inside_coil(\n        self,\n        x: Union[float, np.array],\n        z: Union[float, np.array],\n        *,\n        atol: float = X_TOLERANCE,\n    ) -> np.ndarray:\n        \"\"\"\n        Determine which points lie inside or on the coil boundary.\n\n        Parameters\n        ----------\n        x:\n            The x values to check\n        z:\n            The z values to check\n        atol:\n            Add an offset, to ensure points very near the edge are counted as\n            being on the edge of a coil\n\n        Returns\n        -------\n        The Boolean array of point indices inside/outside the coil boundary\n        \"\"\"\n        x, z = (\n            np.ascontiguousarray(x)[..., np.newaxis],\n            np.ascontiguousarray(z)[..., np.newaxis],\n        )\n\n        x_min, x_max = (\n            self.x - self.dx - atol,\n            self.x + self.dx + atol,\n        )\n        z_min, z_max = (\n            self.z - self.dz - atol,\n            self.z + self.dz + atol,\n        )\n        return (x >= x_min) & (x <= x_max) & (z >= z_min) & (z <= z_max)",
  "def _combined_control(\n        self,\n        inside: np.ndarray,\n        x: np.ndarray,\n        z: np.ndarray,\n        greens_func: Callable,\n        semianalytic_func: Callable,\n    ):\n        \"\"\"\n        Combine semianalytic and greens function calculation of magnetic field\n\n        Used for situation where there are calculation points both inside and\n        outside the coil boundaries.\n\n        Parameters\n        ----------\n        inside:\n            array of if the point is inside a coil\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n        greens_func:\n            greens function\n        semianalytic_func:\n            semianalytic function\n\n        Returns\n        -------\n        Combined response\n        \"\"\"\n        response = np.zeros(inside.shape[:-1])\n        points = inside[..., 0]\n\n        if np.any(~points):\n            response[~points] = greens_func(x[~points], z[~points])\n\n        if np.any(points):\n            response[points] = semianalytic_func(x[points], z[points])\n\n        return response",
  "def _B_response_analytical(\n        self,\n        semianalytic: Callable,\n        x: np.ndarray,\n        z: np.ndarray,\n        *args,\n        **kwargs,\n    ):\n        \"\"\"\n        Calculate [psi, Bx, Bz] response at (x, z) due to a unit\n        current using semi-analytic method.\n\n        Parameters\n        ----------\n        semianalytic:\n            semianalytic function\n        x:\n            The x values at which to calculate the response at\n        z:\n            The z values at which to calculate the response at\n\n        Returns\n        -------\n        Analytical response\n        \"\"\"\n        return super()._B_response_analytical(\n            semianalytic,\n            x,\n            z,\n            split=True,\n            coil_x=np.array([self.x]),\n            coil_z=np.array([self.z]),\n            coil_dx=np.array([self.dx]),\n            coil_dz=np.array([self.dz]),\n        )",
  "def symmetrise_coilset(coilset: CoilSet) -> CoilSet:\n    \"\"\"\n    Symmetrise a CoilSet by converting any coils that are up-down symmetric about\n    z=0 to SymmetricCircuits.\n\n    Parameters\n    ----------\n    coilset:\n        CoilSet to symmetrise\n\n    Returns\n    -------\n    New CoilSet with SymmetricCircuits where appropriate\n    \"\"\"\n    if not check_coilset_symmetric(coilset):\n        bluemira_warn(\n            \"Symmetrising a CoilSet which is not purely symmetric about z=0. This can result in undesirable behaviour.\"\n        )\n    coilset = deepcopy(coilset)\n\n    sym_stack = _get_symmetric_coils(coilset)\n    counts = np.array(sym_stack, dtype=object).T[1]\n\n    new_coils = []\n    for coil, count in zip(coilset._coils, counts):\n        if count == 1:\n            new_coils.append(coil)\n        elif count == 2:\n            if isinstance(coil, SymmetricCircuit):\n                new_coils.append(coil)\n            elif isinstance(coil, Coil):\n                new_coils.append(SymmetricCircuit(coil))\n            else:\n                raise EquilibriaError(f\"Unrecognised class {coil.__class__.__name__}\")\n        else:\n            raise EquilibriaError(\"There are super-posed Coils in this CoilSet.\")\n\n    return CoilSet(*new_coils)",
  "class CoilGroup(CoilGroupFieldsMixin):\n    \"\"\"\n    Coil Grouping object\n\n    Allow nested coils or groups of coils with access to the methods and properties\n    in the same way to a vanilla Coil\n\n    Parameters\n    ----------\n    coils:\n        Coils and groups of Coils to group\n    \"\"\"\n\n    __slots__ = (\"_coils\", \"_pad_size\")\n\n    def __init__(self, *coils: Union[Coil, CoilGroup[Coil]]):\n        if any(not isinstance(c, (Coil, CoilGroup)) for c in coils):\n            raise TypeError(\"Not all arguments are a Coil or CoilGroup.\")\n        self._coils = coils\n        self._pad_discretisation(self.__list_getter(\"_quad_x\"))\n\n    def __repr__(self):\n        \"\"\"\n        Pretty print\n        \"\"\"\n        coils_repr = \"\\n    \"\n        coils_repr += \"\".join(f\"{c.__repr__()}\\n    \" for c in self._coils)\n        coils_repr = coils_repr.replace(\"\\n\", \"\\n    \")\n        return f\"{type(self).__name__}({coils_repr[:-5]})\"\n\n    def n_coils(self, ctype: Optional[Union[str, CoilType]] = None) -> int:\n        \"\"\"\n        Get number of coils\n\n        Parameters\n        ----------\n        ctype:\n            get number of coils of a specific type\n\n        Returns\n        -------\n        Number of coils\n        \"\"\"\n        if ctype is None:\n            return len(self.x)\n\n        if not isinstance(ctype, CoilType):\n            ctype = CoilType[ctype]\n\n        return Counter(self.ctype)[ctype]\n\n    def plot(\n        self,\n        ax: Optional[Axes] = None,\n        subcoil: bool = True,\n        label: bool = False,\n        force: Optional[Iterable] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Plot a CoilGroup\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis object\n        subcoil:\n            plot coil discretisations\n        label:\n            show coil labels on plot\n        force:\n            force arrows iterable\n        kwargs:\n            passed to matplotlib's Axes.plot\n        \"\"\"\n        return CoilGroupPlotter(\n            self, ax=ax, subcoil=subcoil, label=label, force=force, **kwargs\n        )\n\n    def fix_sizes(self):\n        \"\"\"\n        Fix the sizes of coils in CoilGroup\n        \"\"\"\n        self.__run_func(\"fix_size\")\n\n    def resize(self, currents: Union[float, List, np.ndarray]):\n        \"\"\"\n        Resize coils based on their current if their size is not fixed\n        \"\"\"\n        self.__run_func(\"resize\", currents)\n\n    def _resize(self, currents: Union[float, List, np.ndarray]):\n        \"\"\"\n        Resize coils based on their current\n\n        Notes\n        -----\n        Ignores any protections on their size\n        \"\"\"\n        self.__run_func(\"_resize\", currents)\n\n    def __run_func(self, func: str, *args, **kwargs):\n        \"\"\"\n        Runs a function with no outputs that exists on a coil or coilgroup\n\n        This function aims to deal with the edge cases that are around nested coilgroups\n        If kwargs are passed they will be passed to all function calls as is.\n        If args are passed an attempt is made to push the right shaped argument to a\n        given function.\n        \"\"\"\n        if not args:\n            for ff in self.__list_getter(func):\n                ff(**kwargs)\n        else:\n            args = list(args)\n            funclist = self.__list_getter(func)\n            len_funclist = len(funclist)\n            for no, arg in enumerate(args):\n                if isinstance(arg, (float, int)):\n                    args[no] = np.full(len_funclist, arg)\n                elif len(arg) != len_funclist:\n                    raise ValueError(\n                        f\"length of {arg} != number of coilgroups ({len_funclist})\"\n                    )\n            for ff, *_args in zip(funclist, *args):\n                ff(*_args, **kwargs)\n\n    def add_coil(self, *coils: Union[Coil, CoilGroup[Coil]]):\n        \"\"\"Add coils to the coil group\"\"\"\n        self._coils = (*self._coils, *coils)\n\n    def remove_coil(self, *coil_name: str, _top_level: bool = True) -> Union[None, List]:\n        \"\"\"\n        Remove coil from CoilGroup\n\n        Parameters\n        ----------\n        coil_name:\n            coil(s) to remove\n        _top_level:\n            FOR INTERNAL USE, flags if at top level of nested coilgroup stack\n\n        Returns\n        -------\n        Removed names if not at top level of nested stack\n\n        Notes\n        -----\n        If a nested coilgroup is empty it is also removed from the parent coilgroup\n\n        \"\"\"\n        names = self.name\n\n        if _top_level and (remainder := set(coil_name) - set(names)):\n            raise EquilibriaError(f\"Unknown coils {remainder}\")\n\n        c_names = []\n        removed_names = []\n\n        for c in self._coils:\n            if isinstance(c, CoilGroup):\n                removed_names.extend(c.remove_coil(*coil_name, _top_level=False))\n            elif c.name in coil_name:\n                c_names.append(c.name)\n\n        to_remove = [names.index(c_n) for c_n in c_names]\n\n        coils = np.array(self._coils, dtype=object)\n        mask = np.full(coils.size, True, dtype=bool)\n        mask[to_remove] = False\n\n        for no, c in enumerate(self._coils):\n            if c.name == []:\n                # if a coil group is empty the name list will be empty\n                mask[no] = False\n\n        self._coils = tuple(coils[mask])\n\n        if not _top_level:\n            return removed_names + to_remove\n\n    @classmethod\n    def from_group_vecs(cls, eqdsk: EQDSKInterface):\n        \"\"\"\n        Initialises an instance of CoilSet from group vectors.\n\n        This has been implemented as a dict operation, because it will\n        occur for eqdsks only.\n        Future dict instantiation methods will likely differ, hence the\n        confusing name of this method.\n        \"\"\"\n        pfcoils = []\n        cscoils = []\n        passivecoils = []\n        for i in range(eqdsk.ncoil):\n            dx = eqdsk.dxc[i]\n            dz = eqdsk.dzc[i]\n            if abs(eqdsk.Ic[i]) < I_MIN:\n                # Some eqdsk formats (e.g., CREATE) contain 'quasi-coils'\n                # with currents very close to 0.\n                # Catch these cases and make sure current is set to zero.\n                passivecoils.append(\n                    Coil(\n                        eqdsk.xc[i],\n                        eqdsk.zc[i],\n                        current=0,\n                        dx=dx,\n                        dz=dz,\n                        ctype=\"NONE\",\n                        control=False,\n                    )\n                )\n            else:\n                if dx != dz:  # Rough and ready\n                    cscoils.append(\n                        Coil(\n                            eqdsk.xc[i],\n                            eqdsk.zc[i],\n                            current=eqdsk.Ic[i],\n                            dx=dx,\n                            dz=dz,\n                            ctype=\"CS\",\n                        )\n                    )\n                else:\n                    coil = Coil(\n                        eqdsk.xc[i],\n                        eqdsk.zc[i],\n                        current=eqdsk.Ic[i],\n                        dx=dx,\n                        dz=dz,\n                        ctype=\"PF\",\n                    )\n                    coil.fix_size()  # Oh ja\n                    pfcoils.append(coil)\n\n        coils = pfcoils\n        coils.extend(cscoils)\n        coils.extend(passivecoils)\n        return cls(*coils)\n\n    def to_group_vecs(\n        self,\n    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Output CoilGroup properties as numpy arrays\n\n        Returns\n        -------\n        x:\n            The x-positions of coils\n        z:\n            The z-positions of coils.\n        dx:\n            The coil size in the x-direction.\n        dz:\n            The coil size in the z-direction.\n        currents:\n            The coil currents.\n        \"\"\"\n        return self.x, self.z, self.dx, self.dz, self.current\n\n    def __list_getter(self, attr: str) -> List:\n        \"\"\"Get attributes from coils tuple\"\"\"\n        return np.frompyfunc(attrgetter(attr), 1, 1)(self._coils)\n\n    def __getter(self, attr: str) -> np.ndarray:\n        \"\"\"Get attribute from coils and convert to flattened numpy array\"\"\"\n        arr = np.array([*flatten_iterable(self.__list_getter(attr))])\n        arr.flags.writeable = False\n        return arr\n\n    def __quad_getter(self, attr: str) -> np.ndarray:\n        \"\"\"Get quadratures and autopad to create non ragged array\"\"\"\n        _quad_list = self.__list_getter(attr)\n        self._pad_discretisation(_quad_list)\n\n        for i, d in enumerate(self._pad_size):\n            if _quad_list[i].ndim > 1:\n                pad = tuple((0, 0) for _ in range(_quad_list[i].ndim - 1)) + ((0, d),)\n            else:\n                pad = (0, d)\n            _quad_list[i] = np.pad(_quad_list[i], pad)\n\n        return np.vstack(_quad_list)\n\n    def __setter(\n        self,\n        attr: str,\n        values: Union[CoilType, float, Iterable[Union[CoilType, float]]],\n        dtype: Union[Type, None] = None,\n    ):\n        \"\"\"Set attributes on coils\"\"\"\n        values = np.atleast_1d(values)\n        if dtype not in (None, object):\n            values.dtype = np.dtype(dtype)\n        no_val = values.size\n        no = 0\n        for coil in flatten_iterable(self._coils):\n            end_no = no + coil.n_coils()\n            if end_no > no_val:\n                if no_val == 1:\n                    setattr(coil, attr, np.repeat(values[0], end_no - no))\n                elif isinstance(coil, Circuit):\n                    setattr(coil, attr, np.repeat(values[-1], coil.n_coils()))\n                else:\n                    raise ValueError(\n                        \"The number of elements is less than the number of coils\"\n                    )\n            else:\n                setattr(coil, attr, values[no:end_no])\n                no = end_no\n\n    def __getitem__(self, item):\n        \"\"\"Get coils\"\"\"\n        return self._find_coil(item)\n\n    def __copy__(self):\n        \"\"\"Copy dunder method, needed because attribute setter fails for quadratures\"\"\"\n        cls = self.__class__\n        result = cls.__new__(cls)\n        for k in self.__slots__:\n            setattr(result, k, getattr(self, k))\n        return result\n\n    def __deepcopy__(self, memo):\n        \"\"\"\n        Deepcopy dunder method, needed because attribute setter fails for\n        quadratures\n        \"\"\"\n        cls = self.__class__\n        result = cls.__new__(cls)\n        memo[id(self)] = result\n        for k in self.__slots__:\n            setattr(result, k, deepcopy(getattr(self, k), memo))\n        result._einsum_str = self._einsum_str\n        return result\n\n    def _pad_discretisation(\n        self,\n        _to_pad: List[np.ndarray],\n    ):\n        \"\"\"\n        Convert quadrature list of array to rectangular arrays.\n        Padding quadrature arrays with zeros to allow array operations\n        on rectangular matricies.\n\n        Parameters\n        ----------\n        _to_pad:\n            x quadratures\n\n        Notes\n        -----\n        Padding exists for coils with different discretisations or sizes within a\n        coilgroup.\n        There are a few extra calculations of the greens functions where padding\n        exists in the :func:_combined_control method of CoilGroupFieldMixin.\n\n        \"\"\"\n        all_len = np.array([q.shape[-1] for q in _to_pad])\n        max_len = max(all_len)\n        self._pad_size = max_len - all_len\n\n        self._einsum_str = \"...j, ...j -> ...\"\n\n    def _find_coil(self, name):\n        \"\"\"Find coil by name\"\"\"\n        for c in self._coils:\n            if isinstance(c, CoilGroup):\n                try:\n                    return c._find_coil(name)\n                except KeyError:\n                    pass\n            elif c.name == name:\n                return c\n\n        raise KeyError(f\"Coil '{name}' not found in Group\")\n\n    def _get_coiltype(self, ctype):\n        \"\"\"Find coil by type\"\"\"\n        coils = []\n        if isinstance(ctype, str):\n            ctype = CoilType[ctype]\n        for c in self._coils:\n            if isinstance(c, CoilGroup):\n                coils.extend(c._get_coiltype(ctype))\n            elif c.ctype == ctype:\n                coils.append(c)\n        return coils\n\n    def get_coiltype(self, ctype: Union[str, CoilType]):\n        \"\"\"Get coil by coil type\"\"\"\n        return CoilGroup(*self._get_coiltype(ctype))\n\n    def assign_material(self, ctype, j_max, b_max):\n        \"\"\"Assign material J and B to Coilgroup\"\"\"\n        cg = self.get_coiltype(ctype)\n        cg.j_max = j_max\n        cg.b_max = b_max\n\n    def get_max_current(self, max_current: float = np.infty) -> np.ndarray:\n        \"\"\"\n        Get max currents\n\n        If a max current argument is provided and the max current isn't set, the value\n        will be as input.\n\n        Parameters\n        ----------\n        max_current:\n            max current value if j_max == nan\n\n        Returns\n        -------\n        Maximum currents\n        \"\"\"\n        return np.where(\n            np.isnan(self.j_max) | ~self._flag_sizefix,  # or not\n            max_current,\n            get_max_current(self.dx, self.dz, self.j_max),\n        )\n\n    @property\n    def name(self) -> List:\n        \"\"\"Get coil names\"\"\"\n        return self.__getter(\"name\").tolist()\n\n    @property\n    def x(self) -> np.ndarray:\n        \"\"\"Get coil x positions\"\"\"\n        return self.__getter(\"x\")\n\n    @property\n    def z(self) -> np.ndarray:\n        \"\"\"Get coil z positions\"\"\"\n        return self.__getter(\"z\")\n\n    @property\n    def position(self):\n        \"\"\"Get coil x, z positions\"\"\"\n        return np.array([self.x, self.z])\n\n    @property\n    def ctype(self) -> List:\n        \"\"\"Get coil types\"\"\"\n        return self.__getter(\"ctype\").tolist()\n\n    @property\n    def dx(self) -> np.ndarray:\n        \"\"\"Get coil widths (half)\"\"\"\n        return self.__getter(\"dx\")\n\n    @property\n    def dz(self) -> np.ndarray:\n        \"\"\"Get coil heights (half)\"\"\"\n        return self.__getter(\"dz\")\n\n    @property\n    def current(self) -> np.ndarray:\n        \"\"\"Get coil currents\"\"\"\n        return self.__getter(\"current\")\n\n    @property\n    def j_max(self) -> np.ndarray:\n        \"\"\"Get coil max current density\"\"\"\n        return self.__getter(\"j_max\")\n\n    @property\n    def b_max(self) -> np.ndarray:\n        \"\"\"Get coil max field\"\"\"\n        return self.__getter(\"b_max\")\n\n    @property\n    def discretisation(self) -> np.ndarray:\n        \"\"\"Get coil discretisations\"\"\"\n        return self.__getter(\"discretisation\")\n\n    @property\n    def n_turns(self) -> np.ndarray:\n        \"\"\"Get coil number of turns\"\"\"\n        return self.__getter(\"n_turns\")\n\n    @property\n    def area(self) -> np.ndarray:\n        \"\"\"Get coil areas\"\"\"\n        return self.__getter(\"area\")\n\n    @property\n    def volume(self) -> np.ndarray:\n        \"\"\"Get coil volumes\"\"\"\n        return self.__getter(\"volume\")\n\n    @property\n    def x_boundary(self) -> np.ndarray:\n        \"\"\"Get coil x coordinate boundary\"\"\"\n        xb = self.__getter(\"x_boundary\")\n        if self.n_coils() > 1:\n            return xb.reshape(-1, 4)\n        else:\n            return xb\n\n    @property\n    def z_boundary(self) -> np.ndarray:\n        \"\"\"Get coil z coordinate boundary\"\"\"\n        zb = self.__getter(\"z_boundary\")\n        if self.n_coils() > 1:\n            return zb.reshape(-1, 4)\n        else:\n            return zb\n\n    @property\n    def _flag_sizefix(self) -> np.ndarray:\n        \"\"\"Get coil current radius\"\"\"\n        return self.__getter(\"_flag_sizefix\")\n\n    @property\n    def _current_radius(self) -> np.ndarray:\n        \"\"\"Get coil current radius\"\"\"\n        return self.__getter(\"_current_radius\")\n\n    @property\n    def _quad_x(self):\n        \"\"\"Get coil x quadratures\"\"\"\n        return self.__quad_getter(\"_quad_x\")\n\n    @property\n    def _quad_z(self):\n        \"\"\"Get coil z quadratures\"\"\"\n        return self.__quad_getter(\"_quad_z\")\n\n    @property\n    def _quad_dx(self):\n        \"\"\"Get coil dx quadratures\"\"\"\n        return self.__quad_getter(\"_quad_dx\")\n\n    @property\n    def _quad_dz(self):\n        \"\"\"Get coil dz quadratures\"\"\"\n        return self.__quad_getter(\"_quad_dz\")\n\n    @property\n    def _quad_weighting(self):\n        \"\"\"Get coil quadrature weightings\"\"\"\n        return self.__quad_getter(\"_quad_weighting\")\n\n    @property\n    def _quad_boundary(self):\n        \"\"\"Get coil quadrature boundaries\"\"\"\n        return [*self.__list_getter(\"_quad_boundary\")]\n\n    @x.setter\n    def x(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil x positions\"\"\"\n        self.__setter(\"x\", values)\n\n    @z.setter\n    def z(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil z positions\"\"\"\n        self.__setter(\"z\", values)\n\n    @position.setter\n    def position(self, values: np.ndarray):\n        \"\"\"Set coil positions\"\"\"\n        self.__setter(\"x\", values[0])\n        self.__setter(\"z\", values[1])\n\n    @ctype.setter\n    def ctype(self, values: Union[CoilType, Iterable[CoilType]]):\n        \"\"\"Set coil types\"\"\"\n        self.__setter(\"ctype\", values, dtype=object)\n\n    @dx.setter\n    def dx(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil dx sizes\"\"\"\n        self.__setter(\"dx\", values)\n\n    @dz.setter\n    def dz(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil dz sizes\"\"\"\n        self.__setter(\"dz\", values)\n\n    @current.setter\n    def current(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil currents\"\"\"\n        self.__setter(\"current\", values)\n\n    @j_max.setter\n    def j_max(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil max current densities\"\"\"\n        self.__setter(\"j_max\", values)\n\n    @b_max.setter\n    def b_max(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil max fields\"\"\"\n        self.__setter(\"b_max\", values)\n\n    @discretisation.setter\n    def discretisation(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil discretisations\"\"\"\n        self.__setter(\"discretisation\", values)\n        self._pad_discretisation(self.__list_getter(\"_quad_x\"))\n\n    @n_turns.setter\n    def n_turns(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil number of turns\"\"\"\n        self.__setter(\"n_turns\", values)",
  "class Circuit(CoilGroup):\n    \"\"\"\n    A CoilGroup where all coils have the same current\n\n    Parameters\n    ----------\n    coils:\n        coils in circuit\n    current:\n        The current value, if not provided the first coil current is used\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(\n        self, *coils: Union[Coil, CoilGroup[Coil]], current: Optional[float] = None\n    ):\n        super().__init__(*coils)\n        self.current = self._get_current() if current is None else current\n\n    def _get_current(self):\n        current = self._coils[0].current\n        if isinstance(current, Iterable):\n            current = current[0]\n        return current\n\n    def add_coil(self, *coils: Union[Coil, CoilGroup[Coil]]):\n        \"\"\"\n        Add coil to circuit forcing the same current\n        \"\"\"\n        super().add_coil(coils)\n        self.current = self._get_current()\n\n    @CoilGroup.current.setter\n    def current(self, values: Union[float, Iterable[float]]):\n        \"\"\"\n        Set current for circuit\n        \"\"\"\n        if isinstance(values, Iterable):\n            # Force the same value of current for all coils\n            values = values[0]\n        self._CoilGroup__setter(\"current\", values)",
  "class SymmetricCircuit(Circuit):\n    \"\"\"\n    A Circuit with positional symmetry\n\n    Parameters\n    ----------\n    coils:\n        2 coil or coil group objects to symmetrise in a circuit\n\n\n    Notes\n    -----\n    Although two groups can be defined any movement of the coils is\n    achieved by offsets to the mean position of the coilgroups.\n\n    Currently only symmetric about z = 0 see gh issue #210\n    \"\"\"\n\n    __slots__ = (\"_symmetry_line\", \"_shift\", \"sym_mat\", *CoilGroup.__slots__)\n\n    def __init__(\n        self,\n        *coils: Union[Coil, CoilGroup[Coil]],\n    ):\n        symmetry_line: Union[Tuple, np.ndarray] = ((0, 0), (1, 0))\n\n        if len(coils) == 1:\n            coils = (coils[0], deepcopy(coils[0]))\n        if len(coils) != 2:\n            raise EquilibriaError(\n                f\"Wrong number of coils to create a {type(self).__name__}\"\n            )\n\n        super().__init__(*coils)\n\n        self.modify_symmetry(symmetry_line)\n        diff = self._symmetrise()\n        self._coils[1].x = self._coils[1].x - diff[0]\n        self._coils[1].z = self._coils[1].z - diff[1]\n\n    def modify_symmetry(self, symmetry_line: np.ndarray):\n        \"\"\"\n        Create a unit vector for the symmetry of the circuit\n\n        Parameters\n        ----------\n        symmetry_line:\n            two points making a symmetry line [[float, float], [float, float]]\n        \"\"\"\n        self._symmetry_line = (\n            np.array(symmetry_line)\n            if isinstance(symmetry_line, tuple)\n            else symmetry_line\n        )\n        self._symmetry_matrix()\n\n    def _symmetry_matrix(self):\n        \"\"\"\n        Symmetry matrix\n\n        .. math::\n\n            \\\\frac{1}{1 + m} \\\\left[ {\\\\begin{array}{cc}\n                                        1 - m^2 & 2m \\\\\\\\\n                                        2m & -(1 - m^2) \\\\\\\\\n                                      \\\\end{array} } \\\\right]\n        \"\"\"\n        self._shift, grad = yintercept(self._symmetry_line)\n        grad2 = grad**2\n        mgrad2 = 1 - grad2\n        gradsq = 2 * grad\n        self.sym_mat = 1 / (1 + grad2) * np.array([[mgrad2, gradsq], [gradsq, -mgrad2]])\n\n    def _symmetrise(self) -> np.ndarray:\n        \"\"\"\n        Calculate the change in position to the symmetric coil,\n        twice the distance to the line of symmetry.\n        \"\"\"\n        cp = self._get_group_centre()\n        cp[1] -= self._shift\n        mirror = np.dot(self.sym_mat, cp.T)\n        mirror[1] += self._shift\n        return np.array([np.mean(self._coils[1].x), np.mean(self._coils[1].z)]) - mirror\n\n    @Circuit.x.setter\n    def x(self, new_x: float):\n        \"\"\"\n        Set x coordinate of each coil\n        \"\"\"\n        if isinstance(new_x, np.ndarray):\n            new_x = np.mean(new_x[0])\n        self._coils[0].x = self._coils[0].x + new_x - self._get_group_x_centre()\n        self._coils[1].x = self._coils[1].x - self._symmetrise()[0]\n\n    @Circuit.z.setter\n    def z(self, new_z: float):\n        \"\"\"\n        Set z coordinate of each coil\n        \"\"\"\n        if isinstance(new_z, np.ndarray):\n            new_z = np.mean(new_z[0])\n        self._coils[0].z = self._coils[0].z + new_z - self._get_group_z_centre()\n        self._coils[1].z = self._coils[1].z + self._symmetrise()[1]\n\n    def _get_group_x_centre(self) -> np.ndarray:\n        \"\"\"Get the x centre of the first coil group\"\"\"\n        return np.mean(self._coils[0].x)\n\n    def _get_group_z_centre(self) -> np.ndarray:\n        \"\"\"Get the z centre of the first coil group\"\"\"\n        return np.mean(self._coils[0].z)\n\n    def _get_group_centre(self) -> np.ndarray:\n        \"\"\"Get the centre of the first coil group\"\"\"\n        return np.array([self._get_group_x_centre(), self._get_group_z_centre()])",
  "class CoilSet(CoilSetFieldsMixin, CoilGroup):\n    \"\"\"\n    CoilSet is a CoilGroup with the concept of control coils\n\n    A CoilSet will return the total volume and area of the coils\n    and the respective psi or field calculations can optionally sum over the coils\n    or only sum over the control coils.\n\n    By default all coils are controlled\n\n    Parameters\n    ----------\n    coils:\n        The coils to be added to the set\n    control_names:\n        List of coil names to be controlled\n\n    \"\"\"\n\n    __slots__ = (\"_control\", \"_control_ind\", *CoilGroup.__slots__)\n\n    def __init__(\n        self,\n        *coils: Union[Coil, CoilGroup[Coil]],\n        control_names: Optional[Union[List, bool]] = None,\n    ):\n        super().__init__(*coils)\n        self.control = control_names\n\n    def remove_coil(self, *coil_name: str, _top_level: bool = True) -> Union[None, List]:\n        \"\"\"\n        Remove coil from CoilSet\n        \"\"\"\n        super().remove_coil(*coil_name, _top_level=_top_level)\n        self.control = list(set(self.control) & set(self.name))\n\n    @property\n    def control(self) -> List:\n        \"\"\"Get control coil names\"\"\"\n        return self._control\n\n    @control.setter\n    def control(self, control_names: Optional[Union[List, bool]] = None):\n        \"\"\"Set control coils\"\"\"\n        names = self.name\n        if isinstance(control_names, List):\n            self._control_ind = [names.index(c) for c in control_names]\n        elif control_names or control_names is None:\n            self._control_ind = np.arange(len(names)).tolist()\n        else:\n            self._control_ind = []\n        self._control = [names[c] for c in self._control_ind]\n\n    def get_control_coils(self):\n        \"\"\"Get Control coils\"\"\"\n        coils = []\n        for c in self._coils:\n            names = c.name\n            if isinstance(names, List):\n                # is subset of list\n                if isinstance(c, Circuit) and any([n in self.control for n in names]):\n                    coils.append(c)\n                else:\n                    coils.extend(c.get_control_coils()._coils)\n            elif names in self.control:\n                coils.append(c)\n        return CoilSet(*coils)\n\n    def get_coiltype(self, ctype):\n        \"\"\"Get coils by coils type\"\"\"\n        return CoilSet(*super()._get_coiltype(ctype))\n\n    @property\n    def area(self) -> float:\n        \"\"\"\n        Cross sectional area of CoilSet\n        \"\"\"\n        return np.sum(super().area)\n\n    @property\n    def volume(self) -> float:\n        \"\"\"\n        Volume of Coilset\n        \"\"\"\n        return np.sum(super().volume)\n\n    def _sum(\n        self, output: np.ndarray, sum_coils: bool = False, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Get responses of coils optionally only control and/or sum over the responses\n\n        Parameters\n        ----------\n        output:\n            Output of calculation\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Summed response output\n        \"\"\"\n        ind = self._control_ind if control else slice(None)\n\n        return np.sum(output[..., ind], axis=-1) if sum_coils else output[..., ind]",
  "def __init__(self, *coils: Union[Coil, CoilGroup[Coil]]):\n        if any(not isinstance(c, (Coil, CoilGroup)) for c in coils):\n            raise TypeError(\"Not all arguments are a Coil or CoilGroup.\")\n        self._coils = coils\n        self._pad_discretisation(self.__list_getter(\"_quad_x\"))",
  "def __repr__(self):\n        \"\"\"\n        Pretty print\n        \"\"\"\n        coils_repr = \"\\n    \"\n        coils_repr += \"\".join(f\"{c.__repr__()}\\n    \" for c in self._coils)\n        coils_repr = coils_repr.replace(\"\\n\", \"\\n    \")\n        return f\"{type(self).__name__}({coils_repr[:-5]})\"",
  "def n_coils(self, ctype: Optional[Union[str, CoilType]] = None) -> int:\n        \"\"\"\n        Get number of coils\n\n        Parameters\n        ----------\n        ctype:\n            get number of coils of a specific type\n\n        Returns\n        -------\n        Number of coils\n        \"\"\"\n        if ctype is None:\n            return len(self.x)\n\n        if not isinstance(ctype, CoilType):\n            ctype = CoilType[ctype]\n\n        return Counter(self.ctype)[ctype]",
  "def plot(\n        self,\n        ax: Optional[Axes] = None,\n        subcoil: bool = True,\n        label: bool = False,\n        force: Optional[Iterable] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Plot a CoilGroup\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis object\n        subcoil:\n            plot coil discretisations\n        label:\n            show coil labels on plot\n        force:\n            force arrows iterable\n        kwargs:\n            passed to matplotlib's Axes.plot\n        \"\"\"\n        return CoilGroupPlotter(\n            self, ax=ax, subcoil=subcoil, label=label, force=force, **kwargs\n        )",
  "def fix_sizes(self):\n        \"\"\"\n        Fix the sizes of coils in CoilGroup\n        \"\"\"\n        self.__run_func(\"fix_size\")",
  "def resize(self, currents: Union[float, List, np.ndarray]):\n        \"\"\"\n        Resize coils based on their current if their size is not fixed\n        \"\"\"\n        self.__run_func(\"resize\", currents)",
  "def _resize(self, currents: Union[float, List, np.ndarray]):\n        \"\"\"\n        Resize coils based on their current\n\n        Notes\n        -----\n        Ignores any protections on their size\n        \"\"\"\n        self.__run_func(\"_resize\", currents)",
  "def __run_func(self, func: str, *args, **kwargs):\n        \"\"\"\n        Runs a function with no outputs that exists on a coil or coilgroup\n\n        This function aims to deal with the edge cases that are around nested coilgroups\n        If kwargs are passed they will be passed to all function calls as is.\n        If args are passed an attempt is made to push the right shaped argument to a\n        given function.\n        \"\"\"\n        if not args:\n            for ff in self.__list_getter(func):\n                ff(**kwargs)\n        else:\n            args = list(args)\n            funclist = self.__list_getter(func)\n            len_funclist = len(funclist)\n            for no, arg in enumerate(args):\n                if isinstance(arg, (float, int)):\n                    args[no] = np.full(len_funclist, arg)\n                elif len(arg) != len_funclist:\n                    raise ValueError(\n                        f\"length of {arg} != number of coilgroups ({len_funclist})\"\n                    )\n            for ff, *_args in zip(funclist, *args):\n                ff(*_args, **kwargs)",
  "def add_coil(self, *coils: Union[Coil, CoilGroup[Coil]]):\n        \"\"\"Add coils to the coil group\"\"\"\n        self._coils = (*self._coils, *coils)",
  "def remove_coil(self, *coil_name: str, _top_level: bool = True) -> Union[None, List]:\n        \"\"\"\n        Remove coil from CoilGroup\n\n        Parameters\n        ----------\n        coil_name:\n            coil(s) to remove\n        _top_level:\n            FOR INTERNAL USE, flags if at top level of nested coilgroup stack\n\n        Returns\n        -------\n        Removed names if not at top level of nested stack\n\n        Notes\n        -----\n        If a nested coilgroup is empty it is also removed from the parent coilgroup\n\n        \"\"\"\n        names = self.name\n\n        if _top_level and (remainder := set(coil_name) - set(names)):\n            raise EquilibriaError(f\"Unknown coils {remainder}\")\n\n        c_names = []\n        removed_names = []\n\n        for c in self._coils:\n            if isinstance(c, CoilGroup):\n                removed_names.extend(c.remove_coil(*coil_name, _top_level=False))\n            elif c.name in coil_name:\n                c_names.append(c.name)\n\n        to_remove = [names.index(c_n) for c_n in c_names]\n\n        coils = np.array(self._coils, dtype=object)\n        mask = np.full(coils.size, True, dtype=bool)\n        mask[to_remove] = False\n\n        for no, c in enumerate(self._coils):\n            if c.name == []:\n                # if a coil group is empty the name list will be empty\n                mask[no] = False\n\n        self._coils = tuple(coils[mask])\n\n        if not _top_level:\n            return removed_names + to_remove",
  "def from_group_vecs(cls, eqdsk: EQDSKInterface):\n        \"\"\"\n        Initialises an instance of CoilSet from group vectors.\n\n        This has been implemented as a dict operation, because it will\n        occur for eqdsks only.\n        Future dict instantiation methods will likely differ, hence the\n        confusing name of this method.\n        \"\"\"\n        pfcoils = []\n        cscoils = []\n        passivecoils = []\n        for i in range(eqdsk.ncoil):\n            dx = eqdsk.dxc[i]\n            dz = eqdsk.dzc[i]\n            if abs(eqdsk.Ic[i]) < I_MIN:\n                # Some eqdsk formats (e.g., CREATE) contain 'quasi-coils'\n                # with currents very close to 0.\n                # Catch these cases and make sure current is set to zero.\n                passivecoils.append(\n                    Coil(\n                        eqdsk.xc[i],\n                        eqdsk.zc[i],\n                        current=0,\n                        dx=dx,\n                        dz=dz,\n                        ctype=\"NONE\",\n                        control=False,\n                    )\n                )\n            else:\n                if dx != dz:  # Rough and ready\n                    cscoils.append(\n                        Coil(\n                            eqdsk.xc[i],\n                            eqdsk.zc[i],\n                            current=eqdsk.Ic[i],\n                            dx=dx,\n                            dz=dz,\n                            ctype=\"CS\",\n                        )\n                    )\n                else:\n                    coil = Coil(\n                        eqdsk.xc[i],\n                        eqdsk.zc[i],\n                        current=eqdsk.Ic[i],\n                        dx=dx,\n                        dz=dz,\n                        ctype=\"PF\",\n                    )\n                    coil.fix_size()  # Oh ja\n                    pfcoils.append(coil)\n\n        coils = pfcoils\n        coils.extend(cscoils)\n        coils.extend(passivecoils)\n        return cls(*coils)",
  "def to_group_vecs(\n        self,\n    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Output CoilGroup properties as numpy arrays\n\n        Returns\n        -------\n        x:\n            The x-positions of coils\n        z:\n            The z-positions of coils.\n        dx:\n            The coil size in the x-direction.\n        dz:\n            The coil size in the z-direction.\n        currents:\n            The coil currents.\n        \"\"\"\n        return self.x, self.z, self.dx, self.dz, self.current",
  "def __list_getter(self, attr: str) -> List:\n        \"\"\"Get attributes from coils tuple\"\"\"\n        return np.frompyfunc(attrgetter(attr), 1, 1)(self._coils)",
  "def __getter(self, attr: str) -> np.ndarray:\n        \"\"\"Get attribute from coils and convert to flattened numpy array\"\"\"\n        arr = np.array([*flatten_iterable(self.__list_getter(attr))])\n        arr.flags.writeable = False\n        return arr",
  "def __quad_getter(self, attr: str) -> np.ndarray:\n        \"\"\"Get quadratures and autopad to create non ragged array\"\"\"\n        _quad_list = self.__list_getter(attr)\n        self._pad_discretisation(_quad_list)\n\n        for i, d in enumerate(self._pad_size):\n            if _quad_list[i].ndim > 1:\n                pad = tuple((0, 0) for _ in range(_quad_list[i].ndim - 1)) + ((0, d),)\n            else:\n                pad = (0, d)\n            _quad_list[i] = np.pad(_quad_list[i], pad)\n\n        return np.vstack(_quad_list)",
  "def __setter(\n        self,\n        attr: str,\n        values: Union[CoilType, float, Iterable[Union[CoilType, float]]],\n        dtype: Union[Type, None] = None,\n    ):\n        \"\"\"Set attributes on coils\"\"\"\n        values = np.atleast_1d(values)\n        if dtype not in (None, object):\n            values.dtype = np.dtype(dtype)\n        no_val = values.size\n        no = 0\n        for coil in flatten_iterable(self._coils):\n            end_no = no + coil.n_coils()\n            if end_no > no_val:\n                if no_val == 1:\n                    setattr(coil, attr, np.repeat(values[0], end_no - no))\n                elif isinstance(coil, Circuit):\n                    setattr(coil, attr, np.repeat(values[-1], coil.n_coils()))\n                else:\n                    raise ValueError(\n                        \"The number of elements is less than the number of coils\"\n                    )\n            else:\n                setattr(coil, attr, values[no:end_no])\n                no = end_no",
  "def __getitem__(self, item):\n        \"\"\"Get coils\"\"\"\n        return self._find_coil(item)",
  "def __copy__(self):\n        \"\"\"Copy dunder method, needed because attribute setter fails for quadratures\"\"\"\n        cls = self.__class__\n        result = cls.__new__(cls)\n        for k in self.__slots__:\n            setattr(result, k, getattr(self, k))\n        return result",
  "def __deepcopy__(self, memo):\n        \"\"\"\n        Deepcopy dunder method, needed because attribute setter fails for\n        quadratures\n        \"\"\"\n        cls = self.__class__\n        result = cls.__new__(cls)\n        memo[id(self)] = result\n        for k in self.__slots__:\n            setattr(result, k, deepcopy(getattr(self, k), memo))\n        result._einsum_str = self._einsum_str\n        return result",
  "def _pad_discretisation(\n        self,\n        _to_pad: List[np.ndarray],\n    ):\n        \"\"\"\n        Convert quadrature list of array to rectangular arrays.\n        Padding quadrature arrays with zeros to allow array operations\n        on rectangular matricies.\n\n        Parameters\n        ----------\n        _to_pad:\n            x quadratures\n\n        Notes\n        -----\n        Padding exists for coils with different discretisations or sizes within a\n        coilgroup.\n        There are a few extra calculations of the greens functions where padding\n        exists in the :func:_combined_control method of CoilGroupFieldMixin.\n\n        \"\"\"\n        all_len = np.array([q.shape[-1] for q in _to_pad])\n        max_len = max(all_len)\n        self._pad_size = max_len - all_len\n\n        self._einsum_str = \"...j, ...j -> ...\"",
  "def _find_coil(self, name):\n        \"\"\"Find coil by name\"\"\"\n        for c in self._coils:\n            if isinstance(c, CoilGroup):\n                try:\n                    return c._find_coil(name)\n                except KeyError:\n                    pass\n            elif c.name == name:\n                return c\n\n        raise KeyError(f\"Coil '{name}' not found in Group\")",
  "def _get_coiltype(self, ctype):\n        \"\"\"Find coil by type\"\"\"\n        coils = []\n        if isinstance(ctype, str):\n            ctype = CoilType[ctype]\n        for c in self._coils:\n            if isinstance(c, CoilGroup):\n                coils.extend(c._get_coiltype(ctype))\n            elif c.ctype == ctype:\n                coils.append(c)\n        return coils",
  "def get_coiltype(self, ctype: Union[str, CoilType]):\n        \"\"\"Get coil by coil type\"\"\"\n        return CoilGroup(*self._get_coiltype(ctype))",
  "def assign_material(self, ctype, j_max, b_max):\n        \"\"\"Assign material J and B to Coilgroup\"\"\"\n        cg = self.get_coiltype(ctype)\n        cg.j_max = j_max\n        cg.b_max = b_max",
  "def get_max_current(self, max_current: float = np.infty) -> np.ndarray:\n        \"\"\"\n        Get max currents\n\n        If a max current argument is provided and the max current isn't set, the value\n        will be as input.\n\n        Parameters\n        ----------\n        max_current:\n            max current value if j_max == nan\n\n        Returns\n        -------\n        Maximum currents\n        \"\"\"\n        return np.where(\n            np.isnan(self.j_max) | ~self._flag_sizefix,  # or not\n            max_current,\n            get_max_current(self.dx, self.dz, self.j_max),\n        )",
  "def name(self) -> List:\n        \"\"\"Get coil names\"\"\"\n        return self.__getter(\"name\").tolist()",
  "def x(self) -> np.ndarray:\n        \"\"\"Get coil x positions\"\"\"\n        return self.__getter(\"x\")",
  "def z(self) -> np.ndarray:\n        \"\"\"Get coil z positions\"\"\"\n        return self.__getter(\"z\")",
  "def position(self):\n        \"\"\"Get coil x, z positions\"\"\"\n        return np.array([self.x, self.z])",
  "def ctype(self) -> List:\n        \"\"\"Get coil types\"\"\"\n        return self.__getter(\"ctype\").tolist()",
  "def dx(self) -> np.ndarray:\n        \"\"\"Get coil widths (half)\"\"\"\n        return self.__getter(\"dx\")",
  "def dz(self) -> np.ndarray:\n        \"\"\"Get coil heights (half)\"\"\"\n        return self.__getter(\"dz\")",
  "def current(self) -> np.ndarray:\n        \"\"\"Get coil currents\"\"\"\n        return self.__getter(\"current\")",
  "def j_max(self) -> np.ndarray:\n        \"\"\"Get coil max current density\"\"\"\n        return self.__getter(\"j_max\")",
  "def b_max(self) -> np.ndarray:\n        \"\"\"Get coil max field\"\"\"\n        return self.__getter(\"b_max\")",
  "def discretisation(self) -> np.ndarray:\n        \"\"\"Get coil discretisations\"\"\"\n        return self.__getter(\"discretisation\")",
  "def n_turns(self) -> np.ndarray:\n        \"\"\"Get coil number of turns\"\"\"\n        return self.__getter(\"n_turns\")",
  "def area(self) -> np.ndarray:\n        \"\"\"Get coil areas\"\"\"\n        return self.__getter(\"area\")",
  "def volume(self) -> np.ndarray:\n        \"\"\"Get coil volumes\"\"\"\n        return self.__getter(\"volume\")",
  "def x_boundary(self) -> np.ndarray:\n        \"\"\"Get coil x coordinate boundary\"\"\"\n        xb = self.__getter(\"x_boundary\")\n        if self.n_coils() > 1:\n            return xb.reshape(-1, 4)\n        else:\n            return xb",
  "def z_boundary(self) -> np.ndarray:\n        \"\"\"Get coil z coordinate boundary\"\"\"\n        zb = self.__getter(\"z_boundary\")\n        if self.n_coils() > 1:\n            return zb.reshape(-1, 4)\n        else:\n            return zb",
  "def _flag_sizefix(self) -> np.ndarray:\n        \"\"\"Get coil current radius\"\"\"\n        return self.__getter(\"_flag_sizefix\")",
  "def _current_radius(self) -> np.ndarray:\n        \"\"\"Get coil current radius\"\"\"\n        return self.__getter(\"_current_radius\")",
  "def _quad_x(self):\n        \"\"\"Get coil x quadratures\"\"\"\n        return self.__quad_getter(\"_quad_x\")",
  "def _quad_z(self):\n        \"\"\"Get coil z quadratures\"\"\"\n        return self.__quad_getter(\"_quad_z\")",
  "def _quad_dx(self):\n        \"\"\"Get coil dx quadratures\"\"\"\n        return self.__quad_getter(\"_quad_dx\")",
  "def _quad_dz(self):\n        \"\"\"Get coil dz quadratures\"\"\"\n        return self.__quad_getter(\"_quad_dz\")",
  "def _quad_weighting(self):\n        \"\"\"Get coil quadrature weightings\"\"\"\n        return self.__quad_getter(\"_quad_weighting\")",
  "def _quad_boundary(self):\n        \"\"\"Get coil quadrature boundaries\"\"\"\n        return [*self.__list_getter(\"_quad_boundary\")]",
  "def x(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil x positions\"\"\"\n        self.__setter(\"x\", values)",
  "def z(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil z positions\"\"\"\n        self.__setter(\"z\", values)",
  "def position(self, values: np.ndarray):\n        \"\"\"Set coil positions\"\"\"\n        self.__setter(\"x\", values[0])\n        self.__setter(\"z\", values[1])",
  "def ctype(self, values: Union[CoilType, Iterable[CoilType]]):\n        \"\"\"Set coil types\"\"\"\n        self.__setter(\"ctype\", values, dtype=object)",
  "def dx(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil dx sizes\"\"\"\n        self.__setter(\"dx\", values)",
  "def dz(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil dz sizes\"\"\"\n        self.__setter(\"dz\", values)",
  "def current(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil currents\"\"\"\n        self.__setter(\"current\", values)",
  "def j_max(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil max current densities\"\"\"\n        self.__setter(\"j_max\", values)",
  "def b_max(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil max fields\"\"\"\n        self.__setter(\"b_max\", values)",
  "def discretisation(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil discretisations\"\"\"\n        self.__setter(\"discretisation\", values)\n        self._pad_discretisation(self.__list_getter(\"_quad_x\"))",
  "def n_turns(self, values: Union[float, Iterable[float]]):\n        \"\"\"Set coil number of turns\"\"\"\n        self.__setter(\"n_turns\", values)",
  "def __init__(\n        self, *coils: Union[Coil, CoilGroup[Coil]], current: Optional[float] = None\n    ):\n        super().__init__(*coils)\n        self.current = self._get_current() if current is None else current",
  "def _get_current(self):\n        current = self._coils[0].current\n        if isinstance(current, Iterable):\n            current = current[0]\n        return current",
  "def add_coil(self, *coils: Union[Coil, CoilGroup[Coil]]):\n        \"\"\"\n        Add coil to circuit forcing the same current\n        \"\"\"\n        super().add_coil(coils)\n        self.current = self._get_current()",
  "def current(self, values: Union[float, Iterable[float]]):\n        \"\"\"\n        Set current for circuit\n        \"\"\"\n        if isinstance(values, Iterable):\n            # Force the same value of current for all coils\n            values = values[0]\n        self._CoilGroup__setter(\"current\", values)",
  "def __init__(\n        self,\n        *coils: Union[Coil, CoilGroup[Coil]],\n    ):\n        symmetry_line: Union[Tuple, np.ndarray] = ((0, 0), (1, 0))\n\n        if len(coils) == 1:\n            coils = (coils[0], deepcopy(coils[0]))\n        if len(coils) != 2:\n            raise EquilibriaError(\n                f\"Wrong number of coils to create a {type(self).__name__}\"\n            )\n\n        super().__init__(*coils)\n\n        self.modify_symmetry(symmetry_line)\n        diff = self._symmetrise()\n        self._coils[1].x = self._coils[1].x - diff[0]\n        self._coils[1].z = self._coils[1].z - diff[1]",
  "def modify_symmetry(self, symmetry_line: np.ndarray):\n        \"\"\"\n        Create a unit vector for the symmetry of the circuit\n\n        Parameters\n        ----------\n        symmetry_line:\n            two points making a symmetry line [[float, float], [float, float]]\n        \"\"\"\n        self._symmetry_line = (\n            np.array(symmetry_line)\n            if isinstance(symmetry_line, tuple)\n            else symmetry_line\n        )\n        self._symmetry_matrix()",
  "def _symmetry_matrix(self):\n        \"\"\"\n        Symmetry matrix\n\n        .. math::\n\n            \\\\frac{1}{1 + m} \\\\left[ {\\\\begin{array}{cc}\n                                        1 - m^2 & 2m \\\\\\\\\n                                        2m & -(1 - m^2) \\\\\\\\\n                                      \\\\end{array} } \\\\right]\n        \"\"\"\n        self._shift, grad = yintercept(self._symmetry_line)\n        grad2 = grad**2\n        mgrad2 = 1 - grad2\n        gradsq = 2 * grad\n        self.sym_mat = 1 / (1 + grad2) * np.array([[mgrad2, gradsq], [gradsq, -mgrad2]])",
  "def _symmetrise(self) -> np.ndarray:\n        \"\"\"\n        Calculate the change in position to the symmetric coil,\n        twice the distance to the line of symmetry.\n        \"\"\"\n        cp = self._get_group_centre()\n        cp[1] -= self._shift\n        mirror = np.dot(self.sym_mat, cp.T)\n        mirror[1] += self._shift\n        return np.array([np.mean(self._coils[1].x), np.mean(self._coils[1].z)]) - mirror",
  "def x(self, new_x: float):\n        \"\"\"\n        Set x coordinate of each coil\n        \"\"\"\n        if isinstance(new_x, np.ndarray):\n            new_x = np.mean(new_x[0])\n        self._coils[0].x = self._coils[0].x + new_x - self._get_group_x_centre()\n        self._coils[1].x = self._coils[1].x - self._symmetrise()[0]",
  "def z(self, new_z: float):\n        \"\"\"\n        Set z coordinate of each coil\n        \"\"\"\n        if isinstance(new_z, np.ndarray):\n            new_z = np.mean(new_z[0])\n        self._coils[0].z = self._coils[0].z + new_z - self._get_group_z_centre()\n        self._coils[1].z = self._coils[1].z + self._symmetrise()[1]",
  "def _get_group_x_centre(self) -> np.ndarray:\n        \"\"\"Get the x centre of the first coil group\"\"\"\n        return np.mean(self._coils[0].x)",
  "def _get_group_z_centre(self) -> np.ndarray:\n        \"\"\"Get the z centre of the first coil group\"\"\"\n        return np.mean(self._coils[0].z)",
  "def _get_group_centre(self) -> np.ndarray:\n        \"\"\"Get the centre of the first coil group\"\"\"\n        return np.array([self._get_group_x_centre(), self._get_group_z_centre()])",
  "def __init__(\n        self,\n        *coils: Union[Coil, CoilGroup[Coil]],\n        control_names: Optional[Union[List, bool]] = None,\n    ):\n        super().__init__(*coils)\n        self.control = control_names",
  "def remove_coil(self, *coil_name: str, _top_level: bool = True) -> Union[None, List]:\n        \"\"\"\n        Remove coil from CoilSet\n        \"\"\"\n        super().remove_coil(*coil_name, _top_level=_top_level)\n        self.control = list(set(self.control) & set(self.name))",
  "def control(self) -> List:\n        \"\"\"Get control coil names\"\"\"\n        return self._control",
  "def control(self, control_names: Optional[Union[List, bool]] = None):\n        \"\"\"Set control coils\"\"\"\n        names = self.name\n        if isinstance(control_names, List):\n            self._control_ind = [names.index(c) for c in control_names]\n        elif control_names or control_names is None:\n            self._control_ind = np.arange(len(names)).tolist()\n        else:\n            self._control_ind = []\n        self._control = [names[c] for c in self._control_ind]",
  "def get_control_coils(self):\n        \"\"\"Get Control coils\"\"\"\n        coils = []\n        for c in self._coils:\n            names = c.name\n            if isinstance(names, List):\n                # is subset of list\n                if isinstance(c, Circuit) and any([n in self.control for n in names]):\n                    coils.append(c)\n                else:\n                    coils.extend(c.get_control_coils()._coils)\n            elif names in self.control:\n                coils.append(c)\n        return CoilSet(*coils)",
  "def get_coiltype(self, ctype):\n        \"\"\"Get coils by coils type\"\"\"\n        return CoilSet(*super()._get_coiltype(ctype))",
  "def area(self) -> float:\n        \"\"\"\n        Cross sectional area of CoilSet\n        \"\"\"\n        return np.sum(super().area)",
  "def volume(self) -> float:\n        \"\"\"\n        Volume of Coilset\n        \"\"\"\n        return np.sum(super().volume)",
  "def _sum(\n        self, output: np.ndarray, sum_coils: bool = False, control: bool = False\n    ) -> np.ndarray:\n        \"\"\"\n        Get responses of coils optionally only control and/or sum over the responses\n\n        Parameters\n        ----------\n        output:\n            Output of calculation\n        sum_coils:\n            sum over coils\n        control:\n            operations on control coils only\n\n        Returns\n        -------\n        Summed response output\n        \"\"\"\n        ind = self._control_ind if control else slice(None)\n\n        return np.sum(output[..., ind], axis=-1) if sum_coils else output[..., ind]",
  "class CoilTypeEnumMeta(EnumMeta):\n    \"\"\"\n    Allow override of KeyError error string\n    \"\"\"\n\n    def __getitem__(self, name):\n        try:\n            return super().__getitem__(name)\n        except KeyError:\n            raise KeyError(f\"Unknown CoilType {name}\") from None",
  "class CoilType(Enum, metaclass=CoilTypeEnumMeta):\n    \"\"\"\n    CoilType Enum\n    \"\"\"\n\n    PF = auto()\n    CS = auto()\n    NONE = auto()",
  "class CoilNumber:\n    \"\"\"\n    Coil naming-numbering utility class. Coil naming convention is not enforced here.\n    \"\"\"\n\n    __PF_counter: int = 1\n    __CS_counter: int = 1\n    __no_counter: int = 1\n\n    @staticmethod\n    def generate(ctype: CoilType) -> int:\n        \"\"\"\n        Generate a coil number based on its type and indexing if specified.\n        An encapsulated global counter assigns an index.\n\n        Parameters\n        ----------\n        coil:\n            Object to number\n\n        Returns\n        -------\n        Coil number\n        \"\"\"\n        if ctype == CoilType.NONE:\n            idx = CoilNumber.__no_counter\n            CoilNumber.__no_counter += 1\n        elif ctype == CoilType.CS:\n            idx = CoilNumber.__CS_counter\n            CoilNumber.__CS_counter += 1\n        elif ctype == CoilType.PF:\n            idx = CoilNumber.__PF_counter\n            CoilNumber.__PF_counter += 1\n        else:\n            raise ValueError(f\"Unknown coil type {ctype}\")\n\n        return idx",
  "class Coil(CoilFieldsMixin):\n    \"\"\"\n    Coil Object\n\n    For use with PF/CS/passive coils. All coils have a rectangular cross section.\n\n    Parameters\n    ----------\n    x:\n        Coil geometric centre x coordinate [m]\n    z:\n        Coil geometric centre z coordinate [m]\n    dx:\n        Coil radial half-width [m] from coil centre to edge (either side)\n    dz:\n        Coil vertical half-width [m] from coil centre to edge (either side)\n    name:\n        The name of the coil\n    ctype:\n        Type of coil as defined in CoilType\n    current:\n        Coil current [A] (default = 0)\n    j_max:\n        Maximum current density in the coil [A/m^2]\n    b_max:\n        Maximum magnetic field at the coil [T]\n    discretisation:\n        discretise the coil, value in [m]. The minimum size is COIL_DISCR\n    n_turns:\n        Number of turns\n\n    Notes\n    -----\n    If dx and dz are specified the coil size is fixed when modifying j_max or current\n\n    \"\"\"\n\n    __slots__ = (\n        \"_x\",\n        \"_z\",\n        \"_dx\",\n        \"_dz\",\n        \"_discretisation\",\n        \"_current\",\n        \"_j_max\",\n        \"_b_max\",\n        \"_ctype\",\n        \"name\",\n        \"n_turns\",\n        \"_number\",\n        \"_flag_sizefix\",\n        \"_current_radius\",\n        \"_x_boundary\",\n        \"_z_boundary\",\n    )\n\n    def __init__(\n        self,\n        x: float,\n        z: float,\n        dx: float = None,\n        dz: float = None,\n        name: Optional[str] = None,\n        ctype: Union[str, CoilType] = CoilType.NONE,\n        current: float = 0,\n        j_max: float = np.nan,\n        b_max: float = np.nan,\n        discretisation: float = np.nan,\n        n_turns: int = 1,\n    ):\n        self._dx = None\n        self._dz = None\n        self._discretisation = np.nan\n        self._flag_sizefix = None not in (dx, dz)\n\n        if dx is not None and x - dx < 0:\n            raise ValueError(\"Coil extent crosses x=0\")\n\n        self.x = x\n        self.z = z\n        self.dx = dx\n        self.dz = dz\n        self.discretisation = discretisation\n        self.current = current\n        self.j_max = j_max\n        self.b_max = b_max\n        self.ctype = ctype\n        self.name = name\n        self.n_turns = n_turns\n\n        self._number = CoilNumber.generate(self.ctype)\n        if self.name is None:\n            self.name = f\"{self._ctype.name}_{self._number}\"\n\n        # check if dx and not dz set\n        # check of j max set\n        self._validate_size()\n        if not self._flag_sizefix and None in (self.dx, self.dz):\n            self._dx, self._dz = 0, 0\n            self._re_discretise()\n\n    def __repr__(self):\n        \"\"\"\n        Pretty printing\n        \"\"\"\n        return (\n            f\"{type(self).__name__}({self.name} ctype={self.ctype.name} x={self.x:.2g}\"\n            f\" z={self.z:.2g} dx={self.dx:.2g} dz={self.dz:.2g} current={self.current:.2g}\"\n            f\" j_max={self.j_max:.2g} b_max={self.b_max:.2g}\"\n            f\" discretisation={self.discretisation:.2g})\"\n        )\n\n    def plot(\n        self,\n        ax: Optional[Axes] = None,\n        subcoil: bool = True,\n        label: bool = False,\n        force: Optional[Iterable] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Plot a Coil\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis object\n        subcoil:\n            plot coil discretisations\n        label:\n            show coil labels on plot\n        force:\n            force arrows iterable\n        kwargs:\n            passed to matplotlib's Axes.plot\n        \"\"\"\n        return CoilGroupPlotter(\n            self, ax=ax, subcoil=subcoil, label=label, force=force, **kwargs\n        )\n\n    def n_coils(self) -> int:\n        \"\"\"\n        Number of coils in coil\n\n        Notes\n        -----\n        Allows n_coils to be accessed if an individual coil or a CoilGroup\n        \"\"\"\n        return 1\n\n    @property\n    def x(self) -> float:\n        \"\"\"Get coil x position\"\"\"\n        return self._x\n\n    @property\n    def z(self) -> float:\n        \"\"\"Get coil z position\"\"\"\n        return self._z\n\n    @property\n    def position(self) -> np.ndarray:\n        \"\"\"Get coil x, z position\"\"\"\n        return np.array([self.x, self.z])\n\n    @property\n    def ctype(self) -> CoilType:\n        \"\"\"Get coil type\"\"\"\n        return self._ctype\n\n    @property\n    def dx(self) -> float:\n        \"\"\"Get coil width (half)\"\"\"\n        return self._dx\n\n    @property\n    def dz(self) -> float:\n        \"\"\"Get coil height (half)\"\"\"\n        return self._dz\n\n    @property\n    def current(self) -> float:\n        \"\"\"Get coil current\"\"\"\n        return self._current\n\n    @property\n    def j_max(self) -> float:\n        \"\"\"Get coil max current density\"\"\"\n        return self._j_max\n\n    @property\n    def b_max(self) -> float:\n        \"\"\"Get coil max field\"\"\"\n        return self._b_max\n\n    @property\n    def discretisation(self) -> float:\n        \"\"\"Get coil discretisation\"\"\"\n        return self._discretisation\n\n    @property\n    def area(self) -> np.ndarray:\n        \"\"\"\n        The cross-sectional area of the coil\n\n        Returns\n        -------\n        The cross-sectional area of the coil [m^2]\n        \"\"\"\n        return 4 * self.dx * self.dz\n\n    @property\n    def volume(self) -> np.ndarray:\n        \"\"\"\n        The volume of the coil\n\n        Returns\n        -------\n        The volume of the coil [m^3]\n        \"\"\"\n        return self.area * 2 * np.pi * self.x\n\n    @property\n    def x_boundary(self):\n        \"\"\"Get coil x coordinate boundary\"\"\"\n        if getattr(self, \"_x_boundary\") is not None:\n            return self._x_boundary\n        return self._make_boundary(self.x, self.z, self.dx, self.dz)[0]\n\n    @property\n    def z_boundary(self):\n        \"\"\"Get coil z coordinate boundary\"\"\"\n        if getattr(self, \"_z_boundary\") is not None:\n            return self._z_boundary\n        return self._make_boundary(self.x, self.z, self.dx, self.dz)[1]\n\n    @property\n    def _quad_boundary(self):\n        \"\"\"Get coil quadrature x,z coordinate boundary\"\"\"\n        return self._make_boundary(\n            self._quad_x, self._quad_z, self._quad_dx, self._quad_dz\n        )\n\n    @x.setter\n    def x(self, value: float):\n        \"\"\"Set coil x position\"\"\"\n        self._x = np.maximum(float(value), 0)\n        self._re_discretise()\n\n    @z.setter\n    def z(self, value: float):\n        \"\"\"Set coil z position\"\"\"\n        self._z = float(value)\n        self._re_discretise()\n\n    @position.setter\n    def position(self, values: np.ndarray):\n        \"\"\"Set coil position\"\"\"\n        self.x = values[0]\n        self.z = values[1]\n\n    @ctype.setter\n    def ctype(self, value: Union[str, np.ndarray, CoilType]):\n        \"\"\"Set coil type\"\"\"\n        self._ctype = (\n            value\n            if isinstance(value, CoilType)\n            else CoilType[value[0] if isinstance(value, np.ndarray) else value]\n        )\n\n    @dx.setter\n    def dx(self, value: float):\n        \"\"\"Set coil dx size\"\"\"\n        self._dx = None if value is None else float(value)\n        if isinstance(self._dx, float) and self._x - self._dx < 0:\n            bluemira_debug(\n                \"Coil extent crossing x=0, \"\n                \"setting dx to its largest value \"\n                \"keeping the coil above x=0\"\n            )\n            self._dx = self._x\n\n        self._re_discretise()\n\n    @dz.setter\n    def dz(self, value: float):\n        \"\"\"Set coil dz size\"\"\"\n        self._dz = None if value is None else float(value)\n        self._re_discretise()\n\n    @current.setter\n    def current(self, value: float):\n        \"\"\"Set coil current\"\"\"\n        self._current = float(value)\n        if None not in (self.dx, self.dz):\n            self.resize()\n\n    @j_max.setter\n    def j_max(self, value: float):\n        \"\"\"Set coil max current density\"\"\"\n        self._j_max = float(value)\n        if None not in (self.dx, self.dz):\n            self.resize()\n\n    @b_max.setter\n    def b_max(self, value: float):\n        \"\"\"Set coil max field\"\"\"\n        self._b_max = float(value)\n\n    @discretisation.setter\n    def discretisation(self, value: float):\n        \"\"\"Set coil discretisation\"\"\"\n        self._discretisation = np.clip(float(value), COIL_DISCR, None)\n        self._discretise()\n\n    def assign_material(\n        self,\n        j_max: float = NBTI_J_MAX,\n        b_max: float = NBTI_B_MAX,\n    ) -> None:\n        \"\"\"\n        Assigns EM material properties to coil\n\n        Parameters\n        ----------\n        j_max:\n            Overwrite default constant material max current density [A/m^2]\n        b_max:\n            Overwrite default constant material max field [T]\n\n        Notes\n        -----\n        Will always modify both j_max and b_max of the coil with either the default\n        or specified values.\n        \"\"\"\n        self.j_max = j_max\n        self.b_max = b_max\n\n    def get_max_current(self):\n        \"\"\"Get max current\"\"\"\n        return (\n            np.infty\n            if np.isnan(self.j_max)\n            else get_max_current(self.dx, self.dz, self.j_max)\n        )\n\n    def _discretise(self):\n        \"\"\"\n        Discretise a coil for greens function magnetic field calculations\n\n        Notes\n        -----\n        Only discretisation method currently implemented is rectangular.\n\n        Possible improvement: multiple discretisations for different coils\n\n        \"\"\"\n        self._quad_x = np.array([self.x])\n        self._quad_z = np.array([self.z])\n        self._quad_dx = np.array([self.dx])\n        self._quad_dz = np.array([self.dz])\n        self._quad_weighting = np.ones_like(self._quad_x)\n        self._einsum_str = \"...j, ...j -> ...\"\n\n        if not np.isnan(self.discretisation):\n            # How fancy do we want the mesh or just smaller rectangles?\n            self._rectangular_discretisation()\n\n    def _validate_size(self):\n        dx_spec = is_num(self.dx)\n        dz_spec = is_num(self.dz)\n        dxdz_spec = dx_spec and dz_spec\n\n        if (dx_spec ^ dz_spec) and not dxdz_spec:\n            # Check that we don't have dx = None and dz = float or vice versa\n            raise EquilibriaError(\"Must specify either dx and dz or neither.\")\n        if dxdz_spec:\n            # If dx and dz are specified, we presume the coil size should\n            # remain fixed\n            self.fix_size()\n\n            self._set_coil_attributes()\n            self._discretise()\n        else:\n            if not is_num(self.j_max):\n                # Check there is a viable way to size the coil\n                raise EquilibriaError(\"Must specify either dx and dz or j_max.\")\n\n            self._flag_sizefix = False\n\n    def _set_coil_attributes(self):\n        self._current_radius = 0.5 * np.hypot(self.dx, self.dz)\n        self._x_boundary, self._z_boundary = self._make_boundary(\n            self.x, self.z, self.dx, self.dz\n        )\n\n    def _rectangular_discretisation(self):\n        \"\"\"\n        Discretise a coil into filaments based on the length in [m]\n        of the discretisation. Each filament will be plotted as a rectangle\n        with the filament at its centre.\n        \"\"\"\n        nx = np.maximum(1, np.ceil(self.dx * 2 / self.discretisation))\n        nz = np.maximum(1, np.ceil(self.dz * 2 / self.discretisation))\n\n        if nx * nz != 1:\n            sc_dx, sc_dz = self.dx / nx, self.dz / nz\n\n            # Calculate sub-coil centroids\n            x_sc = (self.x - self.dx) + sc_dx * np.arange(1, 2 * nx, 2)\n            z_sc = (self.z - self.dz) + sc_dz * np.arange(1, 2 * nz, 2)\n            x_sc, z_sc = np.meshgrid(x_sc, z_sc)\n\n            self._quad_x = x_sc.flatten()\n            self._quad_z = z_sc.flatten()\n            self._quad_dx = np.full(x_sc.size, sc_dx)\n            self._quad_dz = np.full(x_sc.size, sc_dz)\n\n            self._quad_weighting = np.ones(x_sc.size) / x_sc.size\n\n    def fix_size(self):\n        \"\"\"\n        Fixes the size of the coil\n        \"\"\"\n        self._flag_sizefix = True\n        bluemira_debug(\n            \"Coil size fixed\\n\"\n            \"Adjusting the current or max current density will no\"\n            \" longer change the coil size.\"\n        )\n\n    def resize(self, current: Optional[float] = None):\n        \"\"\"Resize coil given a current\"\"\"\n        if not self._flag_sizefix:\n            # Adjust the size of the coil\n            self._resize(current)\n\n    def _resize(self, current):\n        self.dx, self.dz = self._make_size(current)\n        self._set_coil_attributes()\n\n    def _re_discretise(self):\n        \"\"\"\n        Re discretise and re set attributes if sizing information changes.\n        \"\"\"\n        if None not in (self.dx, self.dz):\n            self._discretise()\n            self._set_coil_attributes()\n\n    def _make_size(self, current: Optional[float] = None):\n        \"\"\"\n        Size the coil based on a current and a current density.\n        \"\"\"\n        if current is None:\n            current = self.current\n        if not np.isnan(self.j_max):\n            half_width = 0.5 * np.sqrt(abs(current) / self.j_max)\n            return half_width, half_width\n        else:\n            return self.dx, self.dz\n\n    @staticmethod\n    def _make_boundary(\n        x_c: float, z_c: float, dx: float, dz: float\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Makes the coil boundary vectors\n\n        Parameters\n        ----------\n        x_c:\n            x coordinate of centre\n        z_c:\n            z coordinate of centre\n        dx:\n            dx of coil\n        dz:\n            dz of coil\n\n        Returns\n        -------\n        x_boundary:\n            Radial coordinates of the boundary\n        z_boundary:\n            Vertical coordinates of the boundary\n\n        Note\n        ----\n        Only rectangular coils\n\n        \"\"\"\n        xx, zz = (np.ones((4, 1)) * x_c).T, (np.ones((4, 1)) * z_c).T\n        x_boundary = xx + (dx * np.array([-1, 1, 1, -1])[:, None]).T\n        z_boundary = zz + (dz * np.array([-1, -1, 1, 1])[:, None]).T\n        return x_boundary, z_boundary",
  "def __getitem__(self, name):\n        try:\n            return super().__getitem__(name)\n        except KeyError:\n            raise KeyError(f\"Unknown CoilType {name}\") from None",
  "def generate(ctype: CoilType) -> int:\n        \"\"\"\n        Generate a coil number based on its type and indexing if specified.\n        An encapsulated global counter assigns an index.\n\n        Parameters\n        ----------\n        coil:\n            Object to number\n\n        Returns\n        -------\n        Coil number\n        \"\"\"\n        if ctype == CoilType.NONE:\n            idx = CoilNumber.__no_counter\n            CoilNumber.__no_counter += 1\n        elif ctype == CoilType.CS:\n            idx = CoilNumber.__CS_counter\n            CoilNumber.__CS_counter += 1\n        elif ctype == CoilType.PF:\n            idx = CoilNumber.__PF_counter\n            CoilNumber.__PF_counter += 1\n        else:\n            raise ValueError(f\"Unknown coil type {ctype}\")\n\n        return idx",
  "def __init__(\n        self,\n        x: float,\n        z: float,\n        dx: float = None,\n        dz: float = None,\n        name: Optional[str] = None,\n        ctype: Union[str, CoilType] = CoilType.NONE,\n        current: float = 0,\n        j_max: float = np.nan,\n        b_max: float = np.nan,\n        discretisation: float = np.nan,\n        n_turns: int = 1,\n    ):\n        self._dx = None\n        self._dz = None\n        self._discretisation = np.nan\n        self._flag_sizefix = None not in (dx, dz)\n\n        if dx is not None and x - dx < 0:\n            raise ValueError(\"Coil extent crosses x=0\")\n\n        self.x = x\n        self.z = z\n        self.dx = dx\n        self.dz = dz\n        self.discretisation = discretisation\n        self.current = current\n        self.j_max = j_max\n        self.b_max = b_max\n        self.ctype = ctype\n        self.name = name\n        self.n_turns = n_turns\n\n        self._number = CoilNumber.generate(self.ctype)\n        if self.name is None:\n            self.name = f\"{self._ctype.name}_{self._number}\"\n\n        # check if dx and not dz set\n        # check of j max set\n        self._validate_size()\n        if not self._flag_sizefix and None in (self.dx, self.dz):\n            self._dx, self._dz = 0, 0\n            self._re_discretise()",
  "def __repr__(self):\n        \"\"\"\n        Pretty printing\n        \"\"\"\n        return (\n            f\"{type(self).__name__}({self.name} ctype={self.ctype.name} x={self.x:.2g}\"\n            f\" z={self.z:.2g} dx={self.dx:.2g} dz={self.dz:.2g} current={self.current:.2g}\"\n            f\" j_max={self.j_max:.2g} b_max={self.b_max:.2g}\"\n            f\" discretisation={self.discretisation:.2g})\"\n        )",
  "def plot(\n        self,\n        ax: Optional[Axes] = None,\n        subcoil: bool = True,\n        label: bool = False,\n        force: Optional[Iterable] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Plot a Coil\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis object\n        subcoil:\n            plot coil discretisations\n        label:\n            show coil labels on plot\n        force:\n            force arrows iterable\n        kwargs:\n            passed to matplotlib's Axes.plot\n        \"\"\"\n        return CoilGroupPlotter(\n            self, ax=ax, subcoil=subcoil, label=label, force=force, **kwargs\n        )",
  "def n_coils(self) -> int:\n        \"\"\"\n        Number of coils in coil\n\n        Notes\n        -----\n        Allows n_coils to be accessed if an individual coil or a CoilGroup\n        \"\"\"\n        return 1",
  "def x(self) -> float:\n        \"\"\"Get coil x position\"\"\"\n        return self._x",
  "def z(self) -> float:\n        \"\"\"Get coil z position\"\"\"\n        return self._z",
  "def position(self) -> np.ndarray:\n        \"\"\"Get coil x, z position\"\"\"\n        return np.array([self.x, self.z])",
  "def ctype(self) -> CoilType:\n        \"\"\"Get coil type\"\"\"\n        return self._ctype",
  "def dx(self) -> float:\n        \"\"\"Get coil width (half)\"\"\"\n        return self._dx",
  "def dz(self) -> float:\n        \"\"\"Get coil height (half)\"\"\"\n        return self._dz",
  "def current(self) -> float:\n        \"\"\"Get coil current\"\"\"\n        return self._current",
  "def j_max(self) -> float:\n        \"\"\"Get coil max current density\"\"\"\n        return self._j_max",
  "def b_max(self) -> float:\n        \"\"\"Get coil max field\"\"\"\n        return self._b_max",
  "def discretisation(self) -> float:\n        \"\"\"Get coil discretisation\"\"\"\n        return self._discretisation",
  "def area(self) -> np.ndarray:\n        \"\"\"\n        The cross-sectional area of the coil\n\n        Returns\n        -------\n        The cross-sectional area of the coil [m^2]\n        \"\"\"\n        return 4 * self.dx * self.dz",
  "def volume(self) -> np.ndarray:\n        \"\"\"\n        The volume of the coil\n\n        Returns\n        -------\n        The volume of the coil [m^3]\n        \"\"\"\n        return self.area * 2 * np.pi * self.x",
  "def x_boundary(self):\n        \"\"\"Get coil x coordinate boundary\"\"\"\n        if getattr(self, \"_x_boundary\") is not None:\n            return self._x_boundary\n        return self._make_boundary(self.x, self.z, self.dx, self.dz)[0]",
  "def z_boundary(self):\n        \"\"\"Get coil z coordinate boundary\"\"\"\n        if getattr(self, \"_z_boundary\") is not None:\n            return self._z_boundary\n        return self._make_boundary(self.x, self.z, self.dx, self.dz)[1]",
  "def _quad_boundary(self):\n        \"\"\"Get coil quadrature x,z coordinate boundary\"\"\"\n        return self._make_boundary(\n            self._quad_x, self._quad_z, self._quad_dx, self._quad_dz\n        )",
  "def x(self, value: float):\n        \"\"\"Set coil x position\"\"\"\n        self._x = np.maximum(float(value), 0)\n        self._re_discretise()",
  "def z(self, value: float):\n        \"\"\"Set coil z position\"\"\"\n        self._z = float(value)\n        self._re_discretise()",
  "def position(self, values: np.ndarray):\n        \"\"\"Set coil position\"\"\"\n        self.x = values[0]\n        self.z = values[1]",
  "def ctype(self, value: Union[str, np.ndarray, CoilType]):\n        \"\"\"Set coil type\"\"\"\n        self._ctype = (\n            value\n            if isinstance(value, CoilType)\n            else CoilType[value[0] if isinstance(value, np.ndarray) else value]\n        )",
  "def dx(self, value: float):\n        \"\"\"Set coil dx size\"\"\"\n        self._dx = None if value is None else float(value)\n        if isinstance(self._dx, float) and self._x - self._dx < 0:\n            bluemira_debug(\n                \"Coil extent crossing x=0, \"\n                \"setting dx to its largest value \"\n                \"keeping the coil above x=0\"\n            )\n            self._dx = self._x\n\n        self._re_discretise()",
  "def dz(self, value: float):\n        \"\"\"Set coil dz size\"\"\"\n        self._dz = None if value is None else float(value)\n        self._re_discretise()",
  "def current(self, value: float):\n        \"\"\"Set coil current\"\"\"\n        self._current = float(value)\n        if None not in (self.dx, self.dz):\n            self.resize()",
  "def j_max(self, value: float):\n        \"\"\"Set coil max current density\"\"\"\n        self._j_max = float(value)\n        if None not in (self.dx, self.dz):\n            self.resize()",
  "def b_max(self, value: float):\n        \"\"\"Set coil max field\"\"\"\n        self._b_max = float(value)",
  "def discretisation(self, value: float):\n        \"\"\"Set coil discretisation\"\"\"\n        self._discretisation = np.clip(float(value), COIL_DISCR, None)\n        self._discretise()",
  "def assign_material(\n        self,\n        j_max: float = NBTI_J_MAX,\n        b_max: float = NBTI_B_MAX,\n    ) -> None:\n        \"\"\"\n        Assigns EM material properties to coil\n\n        Parameters\n        ----------\n        j_max:\n            Overwrite default constant material max current density [A/m^2]\n        b_max:\n            Overwrite default constant material max field [T]\n\n        Notes\n        -----\n        Will always modify both j_max and b_max of the coil with either the default\n        or specified values.\n        \"\"\"\n        self.j_max = j_max\n        self.b_max = b_max",
  "def get_max_current(self):\n        \"\"\"Get max current\"\"\"\n        return (\n            np.infty\n            if np.isnan(self.j_max)\n            else get_max_current(self.dx, self.dz, self.j_max)\n        )",
  "def _discretise(self):\n        \"\"\"\n        Discretise a coil for greens function magnetic field calculations\n\n        Notes\n        -----\n        Only discretisation method currently implemented is rectangular.\n\n        Possible improvement: multiple discretisations for different coils\n\n        \"\"\"\n        self._quad_x = np.array([self.x])\n        self._quad_z = np.array([self.z])\n        self._quad_dx = np.array([self.dx])\n        self._quad_dz = np.array([self.dz])\n        self._quad_weighting = np.ones_like(self._quad_x)\n        self._einsum_str = \"...j, ...j -> ...\"\n\n        if not np.isnan(self.discretisation):\n            # How fancy do we want the mesh or just smaller rectangles?\n            self._rectangular_discretisation()",
  "def _validate_size(self):\n        dx_spec = is_num(self.dx)\n        dz_spec = is_num(self.dz)\n        dxdz_spec = dx_spec and dz_spec\n\n        if (dx_spec ^ dz_spec) and not dxdz_spec:\n            # Check that we don't have dx = None and dz = float or vice versa\n            raise EquilibriaError(\"Must specify either dx and dz or neither.\")\n        if dxdz_spec:\n            # If dx and dz are specified, we presume the coil size should\n            # remain fixed\n            self.fix_size()\n\n            self._set_coil_attributes()\n            self._discretise()\n        else:\n            if not is_num(self.j_max):\n                # Check there is a viable way to size the coil\n                raise EquilibriaError(\"Must specify either dx and dz or j_max.\")\n\n            self._flag_sizefix = False",
  "def _set_coil_attributes(self):\n        self._current_radius = 0.5 * np.hypot(self.dx, self.dz)\n        self._x_boundary, self._z_boundary = self._make_boundary(\n            self.x, self.z, self.dx, self.dz\n        )",
  "def _rectangular_discretisation(self):\n        \"\"\"\n        Discretise a coil into filaments based on the length in [m]\n        of the discretisation. Each filament will be plotted as a rectangle\n        with the filament at its centre.\n        \"\"\"\n        nx = np.maximum(1, np.ceil(self.dx * 2 / self.discretisation))\n        nz = np.maximum(1, np.ceil(self.dz * 2 / self.discretisation))\n\n        if nx * nz != 1:\n            sc_dx, sc_dz = self.dx / nx, self.dz / nz\n\n            # Calculate sub-coil centroids\n            x_sc = (self.x - self.dx) + sc_dx * np.arange(1, 2 * nx, 2)\n            z_sc = (self.z - self.dz) + sc_dz * np.arange(1, 2 * nz, 2)\n            x_sc, z_sc = np.meshgrid(x_sc, z_sc)\n\n            self._quad_x = x_sc.flatten()\n            self._quad_z = z_sc.flatten()\n            self._quad_dx = np.full(x_sc.size, sc_dx)\n            self._quad_dz = np.full(x_sc.size, sc_dz)\n\n            self._quad_weighting = np.ones(x_sc.size) / x_sc.size",
  "def fix_size(self):\n        \"\"\"\n        Fixes the size of the coil\n        \"\"\"\n        self._flag_sizefix = True\n        bluemira_debug(\n            \"Coil size fixed\\n\"\n            \"Adjusting the current or max current density will no\"\n            \" longer change the coil size.\"\n        )",
  "def resize(self, current: Optional[float] = None):\n        \"\"\"Resize coil given a current\"\"\"\n        if not self._flag_sizefix:\n            # Adjust the size of the coil\n            self._resize(current)",
  "def _resize(self, current):\n        self.dx, self.dz = self._make_size(current)\n        self._set_coil_attributes()",
  "def _re_discretise(self):\n        \"\"\"\n        Re discretise and re set attributes if sizing information changes.\n        \"\"\"\n        if None not in (self.dx, self.dz):\n            self._discretise()\n            self._set_coil_attributes()",
  "def _make_size(self, current: Optional[float] = None):\n        \"\"\"\n        Size the coil based on a current and a current density.\n        \"\"\"\n        if current is None:\n            current = self.current\n        if not np.isnan(self.j_max):\n            half_width = 0.5 * np.sqrt(abs(current) / self.j_max)\n            return half_width, half_width\n        else:\n            return self.dx, self.dz",
  "def _make_boundary(\n        x_c: float, z_c: float, dx: float, dz: float\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Makes the coil boundary vectors\n\n        Parameters\n        ----------\n        x_c:\n            x coordinate of centre\n        z_c:\n            z coordinate of centre\n        dx:\n            dx of coil\n        dz:\n            dz of coil\n\n        Returns\n        -------\n        x_boundary:\n            Radial coordinates of the boundary\n        z_boundary:\n            Vertical coordinates of the boundary\n\n        Note\n        ----\n        Only rectangular coils\n\n        \"\"\"\n        xx, zz = (np.ones((4, 1)) * x_c).T, (np.ones((4, 1)) * z_c).T\n        x_boundary = xx + (dx * np.array([-1, 1, 1, -1])[:, None]).T\n        z_boundary = zz + (dz * np.array([-1, -1, 1, 1])[:, None]).T\n        return x_boundary, z_boundary",
  "def make_mutual_inductance_matrix(coilset: CoilSet) -> np.ndarray:\n    \"\"\"\n    Calculate the mutual inductance matrix of a coilset.\n\n    Parameters\n    ----------\n    coilset:\n        Coilset for which to calculate the mutual inductance matrix\n\n    Returns\n    -------\n    The symmetric mutual inductance matrix [H]\n\n    Notes\n    -----\n    Single-filament coil formulation; serves as a useful approximation.\n    \"\"\"\n    n_coils = coilset.n_coils()\n    M = np.zeros((n_coils, n_coils))  # noqa\n    xcoord = coilset.x\n    zcoord = coilset.z\n    dx = coilset.dx\n    dz = coilset.dz\n    n_turns = coilset.n_turns\n\n    itri, jtri = np.triu_indices(n_coils, k=1)\n\n    M[itri, jtri] = (\n        n_turns[itri]\n        * n_turns[jtri]\n        * greens_psi(xcoord[itri], zcoord[itri], xcoord[jtri], zcoord[jtri])\n    )\n    M[jtri, itri] = M[itri, jtri]\n\n    radius = np.hypot(dx, dz)\n    for i in range(n_coils):\n        M[i, i] = n_turns[i] ** 2 * circular_coil_inductance_elliptic(\n            xcoord[i], radius[i]\n        )\n\n    return M",
  "def _get_symmetric_coils(coilset: CoilSet):\n    \"\"\"\n    Coilset symmetry utility\n    \"\"\"\n    x, z, dx, dz, currents = coilset.to_group_vecs()\n    coil_matrix = np.array([x, np.abs(z), dx, dz, currents]).T\n\n    sym_stack = [[coil_matrix[0], 1]]\n    for i in range(1, len(x)):\n        coil = coil_matrix[i]\n\n        for j, sym_coil in enumerate(sym_stack):\n            if np.allclose(coil, sym_coil[0]):\n                sym_stack[j][1] += 1\n                break\n\n        else:\n            sym_stack.append([coil, 1])\n\n    return sym_stack",
  "def check_coilset_symmetric(coilset: CoilSet) -> bool:\n    \"\"\"\n    Check whether or not a CoilSet is purely symmetric about z=0.\n\n    Parameters\n    ----------\n    coilset:\n        CoilSet to check for symmetry\n\n    Returns\n    -------\n    Whether or not the CoilSet is symmetric about z=0\n    \"\"\"\n    sym_stack = _get_symmetric_coils(coilset)\n    for coil, count in sym_stack:\n        if count != 2 and not np.isclose(coil[1], 0.0):\n            # therefore z = 0\n            return False\n    return True",
  "def get_max_current(dx: float, dz: float, j_max: float) -> float:\n    \"\"\"\n    Get the maximum current in a rectangular coil cross-sectional area\n\n    Parameters\n    ----------\n    dx:\n        Coil half-width [m]\n    dz:\n        Coil half-height [m]\n    j_max:\n        Coil current density [A/m^2]\n\n    Returns\n    -------\n    Maximum current [A]\n    \"\"\"\n    return abs(j_max * (4 * dx * dz))",
  "class ViewDescriptor:\n    \"\"\"Descriptor for placements in dataclass\"\"\"\n\n    def __init__(self):\n        self._default = tuple(\n            getattr(_placement.XZY, attr) for attr in (\"base\", \"axis\", \"angle\", \"label\")\n        )\n\n    def __set_name__(self, _, name: str):\n        \"\"\"Set the attribute name from a dataclass\"\"\"\n        self._name = \"_\" + name\n\n    def __get__(self, obj: Any, _) -> Tuple[np.ndarray, np.ndarray, float, str]:\n        \"\"\"Get the view tuple\"\"\"\n        if obj is None:\n            return self._default\n\n        return getattr(obj, self._name, self._default)\n\n    def __set__(self, obj: Any, value: Union[str, tuple, _placement.BluemiraPlacement]):\n        \"\"\"Set the view\"\"\"\n        if isinstance(value, str):\n            if value.startswith(\"xy\"):\n                value = _placement.XYZ\n            elif value.startswith(\"xz\"):\n                value = _placement.XZY\n            elif value.startswith(\"yz\"):\n                value = _placement.YZX\n            else:\n                raise DisplayError(f\"{value} is not a valid view\")\n\n        if isinstance(value, tuple):\n            value = _placement.BluemiraPlacement(*value)\n\n        setattr(\n            obj,\n            self._name,\n            tuple(getattr(value, attr) for attr in (\"base\", \"axis\", \"angle\", \"label\")),\n        )",
  "class DictOptionsDescriptor:\n    \"\"\"Keep defaults for options unless explicitly overwritten\n\n    Notes\n    -----\n    The default will be reinforced if value set to new dictionary.\n    Otherwise as a dictionary is mutable will act in the normal way.\n\n    .. code-block:: python\n\n      po = PlotOptions()\n      po.wire_options[\"linewidth\"] = 0.1  # overrides default\n      po.wire_options[\"zorder\"] = 2  # adds new zorder option\n      # setting a new dictionary resets the defaults with zorder overridden\n      po.wire_options = {'zorder': 1}\n      del po.wire_options[\"linewidth\"]  # linewidth unset\n\n    No checks are done on the contents of the dictionary.\n\n    \"\"\"\n\n    def __init__(self, default_factory: Optional[Callable[[], Dict[str, Any]]] = None):\n        self.default = {} if default_factory is None else default_factory()\n\n    def __set_name__(self, _, name: str):\n        \"\"\"Set the attribute name from a dataclass\"\"\"\n        self._name = \"_\" + name\n\n    def __get__(\n        self, obj: Any, _\n    ) -> Union[Callable[[], Dict[str, Any]], Dict[str, Any]]:\n        \"\"\"Get the options dictionary\"\"\"\n        if obj is None:\n            return lambda: self.default\n\n        return getattr(obj, self._name, self.default)\n\n    def __set__(\n        self, obj: Any, value: Union[Callable[[], Dict[str, Any]], Dict[str, Any]]\n    ):\n        \"\"\"Set the options dictionary\"\"\"\n        if callable(value):\n            value = value()\n        default = getattr(obj, self._name, self.default)\n        setattr(obj, self._name, {**default, **value})",
  "class DefaultPlotOptions:\n    \"\"\"\n    The options that are available for plotting objects in 2D.\n\n    Parameters\n    ----------\n    show_points:\n        If True, points are plotted. By default False.\n    show_wires:\n        If True, wires are plotted. By default True.\n    show_faces:\n        If True, faces are plotted. By default True.\n    point_options:\n        Dictionary with matplotlib options for points. By default  {\"s\": 10,\n        \"facecolors\": \"blue\", \"edgecolors\": \"black\"}\n    wire_options:\n        Dictionary with matplotlib options for wires. By default {\"color\": \"black\",\n        \"linewidth\": \"0.5\"}\n    face_options:\n        Dictionary with matplotlib options for faces. By default {\"color\": \"red\"}\n    view:\n        The reference view for plotting. As string, possible\n        options are \"xy\", \"xz\", \"yz\". By default 'xz'.\n    ndiscr:\n        The number of points to use when discretising a wire or face.\n    byedges:\n        If True then wires or faces will be discretised respecting their edges.\n    \"\"\"\n\n    # flags to enable points, wires, and faces plot\n    show_points: bool = False\n    show_wires: bool = True\n    show_faces: bool = True\n    # matplotlib set of options to plot points, wires, and faces. If an empty dictionary\n    # is specified, the default color plot of matplotlib is used.\n    point_options: DictOptionsDescriptor = DictOptionsDescriptor(\n        lambda: {\n            \"s\": 10,\n            \"facecolors\": \"red\",\n            \"edgecolors\": \"black\",\n            \"zorder\": 30,\n        }\n    )\n    wire_options: DictOptionsDescriptor = DictOptionsDescriptor(\n        lambda: {\"color\": \"black\", \"linewidth\": 0.5, \"zorder\": 20}\n    )\n    face_options: DictOptionsDescriptor = DictOptionsDescriptor(\n        lambda: {\"color\": \"blue\", \"zorder\": 10}\n    )\n    # discretization properties for plotting wires (and faces)\n    ndiscr: int = 100\n    byedges: bool = True\n    # View of object\n    view: ViewDescriptor = ViewDescriptor()\n\n    @property\n    def view_placement(self) -> _placement.BluemiraPlacement:\n        \"\"\"Get view as BluemiraPlacement\"\"\"\n        return _placement.BluemiraPlacement(*self.view)",
  "class PlotOptions(Options):\n    \"\"\"\n    The options that are available for plotting objects\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, **kwargs):\n        self._options = DefaultPlotOptions()\n        super().__init__(**kwargs)",
  "def get_default_options() -> PlotOptions:\n    \"\"\"\n    Returns the default plot options.\n    \"\"\"\n    return PlotOptions()",
  "class BasePlotter(ABC):\n    \"\"\"\n    Base utility plotting class\n    \"\"\"\n\n    _CLASS_PLOT_OPTIONS = {}\n\n    def __init__(self, options: Optional[PlotOptions] = None, **kwargs):\n        # discretization points representing the shape in global coordinate system\n        self._data = []\n        # modified discretization points for plotting (e.g. after view transformation)\n        self._data_to_plot = []\n        self.ax = None\n        self.options = (\n            PlotOptions(**self._CLASS_PLOT_OPTIONS) if options is None else options\n        )\n        self.options.modify(**kwargs)\n        self.set_view(self.options._options.view)\n\n    def set_view(self, view):\n        \"\"\"Set the plotting view\"\"\"\n        if isinstance(view, (str, _placement.BluemiraPlacement)):\n            self.options._options.view = view\n        else:\n            DisplayError(f\"{view} is not a valid view\")\n\n    @abstractmethod\n    def _check_obj(self, obj):\n        \"\"\"Internal function that check if obj is an instance of the correct class\"\"\"\n        pass\n\n    @abstractmethod\n    def _check_options(self):\n        \"\"\"Internal function that check if it is needed to plot something\"\"\"\n        pass\n\n    def initialize_plot_2d(self, ax=None):\n        \"\"\"Initialize the plot environment\"\"\"\n        if ax is None:\n            fig = plt.figure()\n            self.ax = fig.add_subplot()\n        else:\n            self.ax = ax\n\n    def show(self):\n        \"\"\"Function to show a plot\"\"\"\n        plt.show(block=True)\n\n    @abstractmethod\n    def _populate_data(self, obj):\n        \"\"\"\n        Internal function that makes the plot. It fills self._data and\n        self._data_to_plot\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _make_plot_2d(self):\n        \"\"\"\n        Internal function that makes the plot. It should use self._data and\n        self._data_to_plot, so _populate_data should be called before.\n        \"\"\"\n        pass\n\n    def _set_aspect_2d(self):\n        self.ax.set_aspect(\"equal\")\n\n    def _set_label_2d(self):\n        axis = np.abs(self.options.view_placement.axis)\n        if np.allclose(axis, (1, 0, 0)):\n            self.ax.set_xlabel(X_LABEL)\n            self.ax.set_ylabel(Z_LABEL)\n        elif np.allclose(axis, (0, 0, 1)):\n            self.ax.set_xlabel(X_LABEL)\n            self.ax.set_ylabel(Y_LABEL)\n        elif np.allclose(axis, (0, 1, 0)):\n            self.ax.set_xlabel(Y_LABEL)\n            self.ax.set_ylabel(Z_LABEL)\n        else:\n            # Do not put x,y,z labels for views we do not recognise\n            self.ax.set_xlabel(UNIT_LABEL)\n            self.ax.set_ylabel(UNIT_LABEL)\n\n    def _set_aspect_3d(self):\n        # This was the only way I found to get 3-D plots to look right in matplotlib\n        x_bb, y_bb, z_bb = bound_box.BoundingBox.from_xyz(*self._data.T).get_box_arrays()\n        for x, y, z in zip(x_bb, y_bb, z_bb):\n            self.ax.plot([x], [y], [z], color=\"w\")\n\n    def _set_label_3d(self):\n        offset = \"\\n\\n\"  # To keep labels from interfering with the axes\n        self.ax.set_xlabel(offset + X_LABEL)\n        self.ax.set_ylabel(offset + Y_LABEL)\n        self.ax.set_zlabel(offset + Z_LABEL)\n\n    def plot_2d(self, obj, ax=None, show: bool = True):\n        \"\"\"2D plotting method\"\"\"\n        self._check_obj(obj)\n\n        if not self._check_options():\n            self.ax = ax\n        else:\n            self.initialize_plot_2d(ax)\n            self._populate_data(obj)\n            self._make_plot_2d()\n            self._set_aspect_2d()\n            self._set_label_2d()\n\n            if show:\n                self.show()\n        return self.ax\n\n    # # =================================================================================\n    # # 3-D functions\n    # # =================================================================================\n    def initialize_plot_3d(self, ax=None):\n        \"\"\"Initialize the plot environment\"\"\"\n        if ax is None:\n            fig = plt.figure()\n            self.ax = fig.add_subplot(projection=\"3d\")\n        else:\n            self.ax = ax\n\n    @abstractmethod\n    def _make_plot_3d(self):\n        \"\"\"Internal function that makes the plot. It should use self._data and\n        self._data_to_plot, so _populate_data should be called before.\n        \"\"\"\n        pass\n\n    def plot_3d(self, obj, ax=None, show: bool = True):\n        \"\"\"3D plotting method\"\"\"\n        self._check_obj(obj)\n\n        if not self._check_options():\n            self.ax = ax\n        else:\n            self.initialize_plot_3d(ax=ax)\n            # this function can be common to 2D and 3D plot\n            # self._data is used for 3D plot\n            # self._data_to_plot is used for 2D plot\n            # TODO: probably better to rename self._data_to_plot into\n            #  self._projected_data or self._data2d\n            self._populate_data(obj)\n            self._make_plot_3d()\n            self._set_aspect_3d()\n            self._set_label_3d()\n\n            if show:\n                self.show()\n\n        return self.ax",
  "class PointsPlotter(BasePlotter):\n    \"\"\"\n    Base utility plotting class for points\n    \"\"\"\n\n    _CLASS_PLOT_OPTIONS = {\"show_points\": True}\n\n    def _check_obj(self, obj):\n        # TODO: create a function that checks if the obj is a cloud of 3D or 2D points\n        return True\n\n    def _check_options(self):\n        # Check if nothing has to be plotted\n        if not self.options.show_points:\n            return False\n        return True\n\n    def _populate_data(self, points):\n        points = _parse_to_xyz_array(points).T\n        self._data = points\n        # apply rotation matrix given by options['view']\n        rot = self.options.view_placement.to_matrix().T\n        temp_data = np.c_[self._data, np.ones(len(self._data))]\n        self._data_to_plot = temp_data.dot(rot).T\n        self._data_to_plot = self._data_to_plot[0:2]\n\n    def _make_plot_2d(self):\n        if self.options.show_points:\n            self.ax.scatter(*self._data_to_plot, **self.options.point_options)\n        self._set_aspect_2d()\n\n    def _make_plot_3d(self, *args, **kwargs):\n        if self.options.show_points:\n            self.ax.scatter(*self._data.T, **self.options.point_options)\n        self._set_aspect_3d()",
  "class WirePlotter(BasePlotter):\n    \"\"\"\n    Base utility plotting class for bluemira wires\n    \"\"\"\n\n    _CLASS_PLOT_OPTIONS = {\"show_points\": False}\n\n    def _check_obj(self, obj):\n        if not isinstance(obj, wire.BluemiraWire):\n            raise ValueError(f\"{obj} must be a BluemiraWire\")\n        return True\n\n    def _check_options(self):\n        # Check if nothing has to be plotted\n        if not self.options.show_points and not self.options.show_wires:\n            return False\n\n        return True\n\n    def _populate_data(self, wire):\n        self._pplotter = PointsPlotter(self.options)\n        new_wire = wire.deepcopy()\n        # # change of view integrated in PointsPlotter2D. Not necessary here.\n        # new_wire.change_placement(self.options._options['view'])\n        pointsw = new_wire.discretize(\n            ndiscr=self.options._options.ndiscr,\n            byedges=self.options._options.byedges,\n        ).T\n        self._pplotter._populate_data(pointsw)\n        self._data = pointsw\n        self._data_to_plot = self._pplotter._data_to_plot\n\n    def _make_plot_2d(self):\n        if self.options.show_wires:\n            self.ax.plot(*self._data_to_plot, **self.options.wire_options)\n\n        if self.options.show_points:\n            self._pplotter.ax = self.ax\n            self._pplotter._make_plot_2d()\n        self._set_aspect_2d()\n\n    def _make_plot_3d(self):\n        if self.options.show_wires:\n            self.ax.plot(*self._data.T, **self.options.wire_options)\n\n        if self.options.show_points:\n            self._pplotter.ax = self.ax\n            self._pplotter._make_plot_3d()\n        self._set_aspect_3d()",
  "class FacePlotter(BasePlotter):\n    \"\"\"Base utility plotting class for bluemira faces\"\"\"\n\n    _CLASS_PLOT_OPTIONS = {\"show_points\": False, \"show_wires\": False}\n\n    def _check_obj(self, obj):\n        if not isinstance(obj, face.BluemiraFace):\n            raise ValueError(f\"{obj} must be a BluemiraFace\")\n        return True\n\n    def _check_options(self):\n        # Check if nothing has to be plotted\n        if (\n            not self.options.show_points\n            and not self.options.show_wires\n            and not self.options.show_faces\n        ):\n            return False\n\n        return True\n\n    def _populate_data(self, face):\n        self._data = []\n        self._wplotters = []\n        # TODO: the for must be done using face.shape.Wires because FreeCAD\n        #  re-orient the Wires in the correct way for display. Find another way to do\n        #  it (maybe adding this function to the freecadapi.\n        for w in face.shape.Wires:\n            boundary = wire.BluemiraWire(w)\n            wplotter = WirePlotter(self.options)\n            self._wplotters.append(wplotter)\n            wplotter._populate_data(boundary)\n            self._data.extend(wplotter._data.tolist())\n        self._data = np.array(self._data)\n\n        self._data_to_plot = [[], []]\n        for w in self._wplotters:\n            self._data_to_plot[0] += w._data_to_plot[0].tolist() + [None]\n            self._data_to_plot[1] += w._data_to_plot[1].tolist() + [None]\n\n    def _make_plot_2d(self):\n        if self.options.show_faces:\n            self.ax.fill(*self._data_to_plot, **self.options.face_options)\n\n        for w in self._wplotters:\n            w.ax = self.ax\n            w._make_plot_2d()\n        self._set_aspect_2d()\n\n    def _make_plot_3d(self):\n        if self.options.show_faces:\n            poly = a3.art3d.Poly3DCollection([self._data], **self.options.face_options)\n            self.ax.add_collection3d(poly)\n\n        for w in self._wplotters:\n            w.ax = self.ax\n            w._make_plot_3d()\n        self._set_aspect_3d()",
  "class ComponentPlotter(BasePlotter):\n    \"\"\"Base utility plotting class for bluemira faces\"\"\"\n\n    _CLASS_PLOT_OPTIONS = {\"show_points\": False, \"show_wires\": False}\n\n    def _check_obj(self, obj):\n        import bluemira.base.components\n\n        if not isinstance(obj, bluemira.base.components.Component):\n            raise ValueError(f\"{obj} must be a BluemiraComponent\")\n        return True\n\n    def _check_options(self):\n        # Check if nothing has to be plotted\n        if (\n            not self.options.show_points\n            and not self.options.show_wires\n            and not self.options.show_faces\n        ):\n            return False\n\n        return True\n\n    def _populate_data(self, comp):\n        self._cplotters = []\n\n        def _populate_plotters(comp):\n            if comp.is_leaf and getattr(comp, \"shape\", None) is not None:\n                options = (\n                    self.options if comp.plot_options is None else comp.plot_options\n                )\n                plotter = _get_plotter_class(comp.shape)(options)\n                plotter._populate_data(comp.shape)\n                self._cplotters.append(plotter)\n            else:\n                for child in comp.children:\n                    _populate_plotters(child)\n\n        _populate_plotters(comp)\n\n    def _make_plot_2d(self):\n        for plotter in self._cplotters:\n            plotter.ax = self.ax\n            plotter._make_plot_2d()\n        self._set_aspect_2d()\n\n    def _make_plot_3d(self):\n        \"\"\"\n        Internal function that makes the plot. It should use self._data and\n        self._data_to_plot, so _populate_data should be called before.\n        \"\"\"\n        for plotter in self._cplotters:\n            plotter.ax = self.ax\n            plotter._make_plot_3d()\n\n    def _set_aspect_3d(self):\n        pass",
  "def _validate_plot_inputs(parts, options):\n    \"\"\"\n    Validate the lists of parts and options, applying some default options.\n    \"\"\"\n    if not isinstance(parts, list):\n        parts = [parts]\n\n    if options is None:\n        options = [None] * len(parts)\n    elif not isinstance(options, list):\n        options = [options] * len(parts)\n\n    if len(options) != len(parts):\n        raise DisplayError(\n            \"If options for plot are provided then there must be as many options as \"\n            \"there are parts to plot.\"\n        )\n    return parts, options",
  "def _get_plotter_class(part):\n    \"\"\"\n    Get the plotting class for a BluemiraGeo object.\n    \"\"\"\n    import bluemira.base.components\n\n    if isinstance(part, (list, np.ndarray, Coordinates)):\n        plot_class = PointsPlotter\n    elif isinstance(part, wire.BluemiraWire):\n        plot_class = WirePlotter\n    elif isinstance(part, face.BluemiraFace):\n        plot_class = FacePlotter\n    elif isinstance(part, bluemira.base.components.Component):\n        plot_class = ComponentPlotter\n    else:\n        raise DisplayError(\n            f\"{part} object cannot be plotted. No Plotter available for {type(part)}\"\n        )\n    return plot_class",
  "def plot_2d(\n    parts: Union[BluemiraGeo, List[BluemiraGeo]],\n    options: Optional[Union[PlotOptions, List[PlotOptions]]] = None,\n    ax=None,\n    show: bool = True,\n    **kwargs,\n):\n    \"\"\"\n    The implementation of the display API for BluemiraGeo parts.\n\n    Parameters\n    ----------\n    parts: Union[Part.Shape, List[Part.Shape]]\n        The parts to display.\n    options: Optional[Union[PlotOptions, List[PlotOptions]]]\n        The options to use to display the parts.\n    ax: Optional[Axes]\n        The axes onto which to plot\n    show: bool\n        Whether or not to show the plot immediately (default=True). Note\n        that if using iPython or Jupyter, this has no effect; the plot is shown\n        automatically.\n    \"\"\"\n    parts, options = _validate_plot_inputs(parts, options)\n\n    for part, option in zip(parts, options):\n        plotter = _get_plotter_class(part)(option, **kwargs)\n        ax = plotter.plot_2d(part, ax, show=False)\n\n    if show:\n        plotter.show()\n\n    return ax",
  "def plot_3d(\n    parts: Union[BluemiraGeo, List[BluemiraGeo]],\n    options: Optional[Union[PlotOptions, List[PlotOptions]]] = None,\n    ax=None,\n    show: bool = True,\n    **kwargs,\n):\n    \"\"\"\n    The implementation of the display API for BluemiraGeo parts.\n\n    Parameters\n    ----------\n    parts: Union[Part.Shape, List[Part.Shape]]\n        The parts to display.\n    options: Optional[Union[Plot3DOptions, List[Plot3Options]]]\n        The options to use to display the parts.\n    ax: Optional[Axes]\n        The axes onto which to plot\n    show: bool\n        Whether or not to show the plot immediately in the console. (default=True). Note\n        that if using iPython or Jupyter, this has no effect; the plot is shown\n        automatically.\n    \"\"\"\n    parts, options = _validate_plot_inputs(parts, options)\n\n    for part, option in zip(parts, options):\n        plotter = _get_plotter_class(part)(option, **kwargs)\n        ax = plotter.plot_3d(part, ax, show=False)\n\n    if show:\n        plotter.show()\n\n    return ax",
  "class Plottable:\n    \"\"\"\n    Mixin class to make a class plottable in 2D by imparting a plot2d method and\n    options.\n\n    Notes\n    -----\n    The implementing class must set the _plotter2D attribute to an instance of the\n    appropriate Plotter2D class.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self._plot_options: PlotOptions = PlotOptions()\n        self._plot_options.face_options[\"color\"] = next(BLUE_PALETTE)\n\n    @property\n    def plot_options(self) -> PlotOptions:\n        \"\"\"\n        The options that will be used to display the object.\n        \"\"\"\n        return self._plot_options\n\n    @plot_options.setter\n    def plot_options(self, value: PlotOptions):\n        if not isinstance(value, PlotOptions):\n            raise DisplayError(\"Display options must be set to a PlotOptions instance.\")\n        self._plot_options = value\n\n    @property\n    def _plotter(self) -> BasePlotter:\n        \"\"\"\n        The options that will be used to display the object.\n        \"\"\"\n        return _get_plotter_class(self)(self._plot_options)\n\n    def plot_2d(self, ax=None, show: bool = True) -> None:\n        \"\"\"\n        Default method to call display the object by calling into the Displayer's display\n        method.\n\n        Returns\n        -------\n        axes\n            The axes that the plot has been displayed onto.\n        \"\"\"\n        return self._plotter.plot_2d(self, ax=ax, show=show)\n\n    def plot_3d(self, ax=None, show: bool = True) -> None:\n        \"\"\"\n        Function to 3D plot a component.\n\n        Returns\n        -------\n        axes\n            The axes that the plot has been displayed onto.\n        \"\"\"\n        return self._plotter.plot_3d(self, ax=ax, show=show)",
  "def _get_ndim(coords):\n    count = 0\n    length = coords.shape[1]\n    for c in coords.xyz:\n        if len(c) == length and not np.allclose(c, c[0] * np.ones(length)):\n            count += 1\n\n    return max(count, 2)",
  "def _get_plan_dims(array):\n    length = array.shape[1]\n    axes = [\"x\", \"y\", \"z\"]\n    dims = []\n    for i, k in enumerate(axes):\n        c = array[i]\n        if not np.allclose(c[0] * np.ones(length), c):\n            dims.append(k)\n\n    if len(dims) == 1:\n        # Stops error when flat lines are given (same coords in two axes)\n        axes.remove(dims[0])  # remove variable axis\n        temp = []\n        for i, k in enumerate(axes):  # both all equal to something\n            c = array[i]\n            if c[0] != 0.0:\n                temp.append(k)\n        if len(temp) == 1:\n            dims.append(temp[0])\n        else:\n            # This is likely due to a 3-5 long loop which is still straight\n            # need to choose between one of the two constant dimensions\n            # Just default to x - z, this is pretty rare..\n            # usually due to an offset x - z loop\n            dims = [\"x\", \"z\"]\n\n    return sorted(dims)",
  "def plot_coordinates(coords, ax=None, points=False, **kwargs):\n    \"\"\"\n    Plot Coordinates.\n\n    Parameters\n    ----------\n    coords: Coordinates\n        Coordinates to plot\n    ax: Axes\n        Matplotlib axis on which to plot\n\n    Other Parameters\n    ----------------\n    edgecolor: str\n        The edgecolor to plot the Coordinates with\n    facecolor: str\n        The facecolor to plot the Coordinates fill with\n    alpha: float\n        The transparency to plot the Coordinates fill with\n    \"\"\"\n    from bluemira.utilities.plot_tools import coordinates_to_path\n\n    ndim = _get_ndim(coords)\n\n    fc = kwargs.get(\"facecolor\", \"royalblue\")\n    lw = kwargs.get(\"linewidth\", 2)\n    ls = kwargs.get(\"linestyle\", \"-\")\n    alpha = kwargs.get(\"alpha\", 1)\n\n    if coords.closed:\n        fill = kwargs.get(\"fill\", True)\n        ec = kwargs.get(\"edgecolor\", \"k\")\n    else:\n        fill = kwargs.get(\"fill\", False)\n        ec = kwargs.get(\"edgecolor\", \"r\")\n\n    if ndim == 2 and ax is None:\n        ax = kwargs.get(\"ax\", plt.gca())\n\n    if ndim == 3 or (ndim == 2 and hasattr(ax, \"zaxis\")):\n        kwargs = {\n            \"edgecolor\": ec,\n            \"facecolor\": fc,\n            \"linewidth\": lw,\n            \"linestyle\": ls,\n            \"alpha\": alpha,\n            \"fill\": fill,\n        }\n        _plot_3d(coords, ax=ax, **kwargs)\n\n    a, b = _get_plan_dims(coords.xyz)\n    x, y = [getattr(coords, c) for c in [a, b]]\n    marker = \"o\" if points else None\n    ax.set_xlabel(a + \" [m]\")\n    ax.set_ylabel(b + \" [m]\")\n    if fill:\n        poly = coordinates_to_path(x, y)\n        p = PathPatch(poly, color=fc, alpha=alpha)\n        ax.add_patch(p)\n\n    ax.plot(x, y, color=ec, marker=marker, linewidth=lw, linestyle=ls)\n\n    if points:\n        for i, p in enumerate(zip(x, y)):\n            ax.annotate(i, xy=(p[0], p[1]))\n\n    ax.set_aspect(\"equal\")",
  "def _plot_3d(coords, ax=None, **kwargs):\n    from bluemira.utilities.plot_tools import (\n        BluemiraPathPatch3D,\n        Plot3D,\n        coordinates_to_path,\n    )\n\n    if ax is None:\n        ax = Plot3D()\n        # Now we re-arrange a little so that matplotlib can show us something a little\n        # more correct\n        x_bb, y_bb, z_bb = bound_box.BoundingBox.from_xyz(*coords.xyz).get_box_arrays()\n        for x, y, z in zip(x_bb, y_bb, z_bb):\n            ax.plot([x], [y], [z], color=\"w\")\n\n    ax.plot(*coords.xyz, color=kwargs[\"edgecolor\"], lw=kwargs[\"linewidth\"])\n    if kwargs[\"fill\"]:\n        if not coords.is_planar:\n            bluemira_warn(\"Cannot fill plot of non-planar Coordinates.\")\n            return\n        dcm = rotation_matrix_v1v2(-coords.normal_vector, np.array([0.0, 0.0, 1.0]))\n\n        xyz = dcm.T @ coords.xyz\n        center_of_mass = get_centroid_3d(*xyz)\n\n        xyz -= center_of_mass\n\n        dims = [\"x\", \"y\", \"z\"]\n        a, b = _get_plan_dims(xyz)\n        i = dims.index(a)\n        j = dims.index(b)\n        x, y = xyz[i], xyz[j]\n\n        # To make an object which matplotlib can understand\n        poly = coordinates_to_path(x, y)\n\n        # And now re-transform the matplotlib object to 3-D\n        p = BluemiraPathPatch3D(\n            poly,\n            -coords.normal_vector,\n            coords.center_of_mass,\n            color=kwargs[\"facecolor\"],\n            alpha=kwargs[\"alpha\"],\n        )\n        ax.add_patch(p)\n\n    if not hasattr(ax, \"zaxis\"):\n        ax.set_aspect(\"equal\")",
  "def __init__(self):\n        self._default = tuple(\n            getattr(_placement.XZY, attr) for attr in (\"base\", \"axis\", \"angle\", \"label\")\n        )",
  "def __set_name__(self, _, name: str):\n        \"\"\"Set the attribute name from a dataclass\"\"\"\n        self._name = \"_\" + name",
  "def __get__(self, obj: Any, _) -> Tuple[np.ndarray, np.ndarray, float, str]:\n        \"\"\"Get the view tuple\"\"\"\n        if obj is None:\n            return self._default\n\n        return getattr(obj, self._name, self._default)",
  "def __set__(self, obj: Any, value: Union[str, tuple, _placement.BluemiraPlacement]):\n        \"\"\"Set the view\"\"\"\n        if isinstance(value, str):\n            if value.startswith(\"xy\"):\n                value = _placement.XYZ\n            elif value.startswith(\"xz\"):\n                value = _placement.XZY\n            elif value.startswith(\"yz\"):\n                value = _placement.YZX\n            else:\n                raise DisplayError(f\"{value} is not a valid view\")\n\n        if isinstance(value, tuple):\n            value = _placement.BluemiraPlacement(*value)\n\n        setattr(\n            obj,\n            self._name,\n            tuple(getattr(value, attr) for attr in (\"base\", \"axis\", \"angle\", \"label\")),\n        )",
  "def __init__(self, default_factory: Optional[Callable[[], Dict[str, Any]]] = None):\n        self.default = {} if default_factory is None else default_factory()",
  "def __set_name__(self, _, name: str):\n        \"\"\"Set the attribute name from a dataclass\"\"\"\n        self._name = \"_\" + name",
  "def __get__(\n        self, obj: Any, _\n    ) -> Union[Callable[[], Dict[str, Any]], Dict[str, Any]]:\n        \"\"\"Get the options dictionary\"\"\"\n        if obj is None:\n            return lambda: self.default\n\n        return getattr(obj, self._name, self.default)",
  "def __set__(\n        self, obj: Any, value: Union[Callable[[], Dict[str, Any]], Dict[str, Any]]\n    ):\n        \"\"\"Set the options dictionary\"\"\"\n        if callable(value):\n            value = value()\n        default = getattr(obj, self._name, self.default)\n        setattr(obj, self._name, {**default, **value})",
  "def view_placement(self) -> _placement.BluemiraPlacement:\n        \"\"\"Get view as BluemiraPlacement\"\"\"\n        return _placement.BluemiraPlacement(*self.view)",
  "def __init__(self, **kwargs):\n        self._options = DefaultPlotOptions()\n        super().__init__(**kwargs)",
  "def __init__(self, options: Optional[PlotOptions] = None, **kwargs):\n        # discretization points representing the shape in global coordinate system\n        self._data = []\n        # modified discretization points for plotting (e.g. after view transformation)\n        self._data_to_plot = []\n        self.ax = None\n        self.options = (\n            PlotOptions(**self._CLASS_PLOT_OPTIONS) if options is None else options\n        )\n        self.options.modify(**kwargs)\n        self.set_view(self.options._options.view)",
  "def set_view(self, view):\n        \"\"\"Set the plotting view\"\"\"\n        if isinstance(view, (str, _placement.BluemiraPlacement)):\n            self.options._options.view = view\n        else:\n            DisplayError(f\"{view} is not a valid view\")",
  "def _check_obj(self, obj):\n        \"\"\"Internal function that check if obj is an instance of the correct class\"\"\"\n        pass",
  "def _check_options(self):\n        \"\"\"Internal function that check if it is needed to plot something\"\"\"\n        pass",
  "def initialize_plot_2d(self, ax=None):\n        \"\"\"Initialize the plot environment\"\"\"\n        if ax is None:\n            fig = plt.figure()\n            self.ax = fig.add_subplot()\n        else:\n            self.ax = ax",
  "def show(self):\n        \"\"\"Function to show a plot\"\"\"\n        plt.show(block=True)",
  "def _populate_data(self, obj):\n        \"\"\"\n        Internal function that makes the plot. It fills self._data and\n        self._data_to_plot\n        \"\"\"\n        pass",
  "def _make_plot_2d(self):\n        \"\"\"\n        Internal function that makes the plot. It should use self._data and\n        self._data_to_plot, so _populate_data should be called before.\n        \"\"\"\n        pass",
  "def _set_aspect_2d(self):\n        self.ax.set_aspect(\"equal\")",
  "def _set_label_2d(self):\n        axis = np.abs(self.options.view_placement.axis)\n        if np.allclose(axis, (1, 0, 0)):\n            self.ax.set_xlabel(X_LABEL)\n            self.ax.set_ylabel(Z_LABEL)\n        elif np.allclose(axis, (0, 0, 1)):\n            self.ax.set_xlabel(X_LABEL)\n            self.ax.set_ylabel(Y_LABEL)\n        elif np.allclose(axis, (0, 1, 0)):\n            self.ax.set_xlabel(Y_LABEL)\n            self.ax.set_ylabel(Z_LABEL)\n        else:\n            # Do not put x,y,z labels for views we do not recognise\n            self.ax.set_xlabel(UNIT_LABEL)\n            self.ax.set_ylabel(UNIT_LABEL)",
  "def _set_aspect_3d(self):\n        # This was the only way I found to get 3-D plots to look right in matplotlib\n        x_bb, y_bb, z_bb = bound_box.BoundingBox.from_xyz(*self._data.T).get_box_arrays()\n        for x, y, z in zip(x_bb, y_bb, z_bb):\n            self.ax.plot([x], [y], [z], color=\"w\")",
  "def _set_label_3d(self):\n        offset = \"\\n\\n\"  # To keep labels from interfering with the axes\n        self.ax.set_xlabel(offset + X_LABEL)\n        self.ax.set_ylabel(offset + Y_LABEL)\n        self.ax.set_zlabel(offset + Z_LABEL)",
  "def plot_2d(self, obj, ax=None, show: bool = True):\n        \"\"\"2D plotting method\"\"\"\n        self._check_obj(obj)\n\n        if not self._check_options():\n            self.ax = ax\n        else:\n            self.initialize_plot_2d(ax)\n            self._populate_data(obj)\n            self._make_plot_2d()\n            self._set_aspect_2d()\n            self._set_label_2d()\n\n            if show:\n                self.show()\n        return self.ax",
  "def initialize_plot_3d(self, ax=None):\n        \"\"\"Initialize the plot environment\"\"\"\n        if ax is None:\n            fig = plt.figure()\n            self.ax = fig.add_subplot(projection=\"3d\")\n        else:\n            self.ax = ax",
  "def _make_plot_3d(self):\n        \"\"\"Internal function that makes the plot. It should use self._data and\n        self._data_to_plot, so _populate_data should be called before.\n        \"\"\"\n        pass",
  "def plot_3d(self, obj, ax=None, show: bool = True):\n        \"\"\"3D plotting method\"\"\"\n        self._check_obj(obj)\n\n        if not self._check_options():\n            self.ax = ax\n        else:\n            self.initialize_plot_3d(ax=ax)\n            # this function can be common to 2D and 3D plot\n            # self._data is used for 3D plot\n            # self._data_to_plot is used for 2D plot\n            # TODO: probably better to rename self._data_to_plot into\n            #  self._projected_data or self._data2d\n            self._populate_data(obj)\n            self._make_plot_3d()\n            self._set_aspect_3d()\n            self._set_label_3d()\n\n            if show:\n                self.show()\n\n        return self.ax",
  "def _check_obj(self, obj):\n        # TODO: create a function that checks if the obj is a cloud of 3D or 2D points\n        return True",
  "def _check_options(self):\n        # Check if nothing has to be plotted\n        if not self.options.show_points:\n            return False\n        return True",
  "def _populate_data(self, points):\n        points = _parse_to_xyz_array(points).T\n        self._data = points\n        # apply rotation matrix given by options['view']\n        rot = self.options.view_placement.to_matrix().T\n        temp_data = np.c_[self._data, np.ones(len(self._data))]\n        self._data_to_plot = temp_data.dot(rot).T\n        self._data_to_plot = self._data_to_plot[0:2]",
  "def _make_plot_2d(self):\n        if self.options.show_points:\n            self.ax.scatter(*self._data_to_plot, **self.options.point_options)\n        self._set_aspect_2d()",
  "def _make_plot_3d(self, *args, **kwargs):\n        if self.options.show_points:\n            self.ax.scatter(*self._data.T, **self.options.point_options)\n        self._set_aspect_3d()",
  "def _check_obj(self, obj):\n        if not isinstance(obj, wire.BluemiraWire):\n            raise ValueError(f\"{obj} must be a BluemiraWire\")\n        return True",
  "def _check_options(self):\n        # Check if nothing has to be plotted\n        if not self.options.show_points and not self.options.show_wires:\n            return False\n\n        return True",
  "def _populate_data(self, wire):\n        self._pplotter = PointsPlotter(self.options)\n        new_wire = wire.deepcopy()\n        # # change of view integrated in PointsPlotter2D. Not necessary here.\n        # new_wire.change_placement(self.options._options['view'])\n        pointsw = new_wire.discretize(\n            ndiscr=self.options._options.ndiscr,\n            byedges=self.options._options.byedges,\n        ).T\n        self._pplotter._populate_data(pointsw)\n        self._data = pointsw\n        self._data_to_plot = self._pplotter._data_to_plot",
  "def _make_plot_2d(self):\n        if self.options.show_wires:\n            self.ax.plot(*self._data_to_plot, **self.options.wire_options)\n\n        if self.options.show_points:\n            self._pplotter.ax = self.ax\n            self._pplotter._make_plot_2d()\n        self._set_aspect_2d()",
  "def _make_plot_3d(self):\n        if self.options.show_wires:\n            self.ax.plot(*self._data.T, **self.options.wire_options)\n\n        if self.options.show_points:\n            self._pplotter.ax = self.ax\n            self._pplotter._make_plot_3d()\n        self._set_aspect_3d()",
  "def _check_obj(self, obj):\n        if not isinstance(obj, face.BluemiraFace):\n            raise ValueError(f\"{obj} must be a BluemiraFace\")\n        return True",
  "def _check_options(self):\n        # Check if nothing has to be plotted\n        if (\n            not self.options.show_points\n            and not self.options.show_wires\n            and not self.options.show_faces\n        ):\n            return False\n\n        return True",
  "def _populate_data(self, face):\n        self._data = []\n        self._wplotters = []\n        # TODO: the for must be done using face.shape.Wires because FreeCAD\n        #  re-orient the Wires in the correct way for display. Find another way to do\n        #  it (maybe adding this function to the freecadapi.\n        for w in face.shape.Wires:\n            boundary = wire.BluemiraWire(w)\n            wplotter = WirePlotter(self.options)\n            self._wplotters.append(wplotter)\n            wplotter._populate_data(boundary)\n            self._data.extend(wplotter._data.tolist())\n        self._data = np.array(self._data)\n\n        self._data_to_plot = [[], []]\n        for w in self._wplotters:\n            self._data_to_plot[0] += w._data_to_plot[0].tolist() + [None]\n            self._data_to_plot[1] += w._data_to_plot[1].tolist() + [None]",
  "def _make_plot_2d(self):\n        if self.options.show_faces:\n            self.ax.fill(*self._data_to_plot, **self.options.face_options)\n\n        for w in self._wplotters:\n            w.ax = self.ax\n            w._make_plot_2d()\n        self._set_aspect_2d()",
  "def _make_plot_3d(self):\n        if self.options.show_faces:\n            poly = a3.art3d.Poly3DCollection([self._data], **self.options.face_options)\n            self.ax.add_collection3d(poly)\n\n        for w in self._wplotters:\n            w.ax = self.ax\n            w._make_plot_3d()\n        self._set_aspect_3d()",
  "def _check_obj(self, obj):\n        import bluemira.base.components\n\n        if not isinstance(obj, bluemira.base.components.Component):\n            raise ValueError(f\"{obj} must be a BluemiraComponent\")\n        return True",
  "def _check_options(self):\n        # Check if nothing has to be plotted\n        if (\n            not self.options.show_points\n            and not self.options.show_wires\n            and not self.options.show_faces\n        ):\n            return False\n\n        return True",
  "def _populate_data(self, comp):\n        self._cplotters = []\n\n        def _populate_plotters(comp):\n            if comp.is_leaf and getattr(comp, \"shape\", None) is not None:\n                options = (\n                    self.options if comp.plot_options is None else comp.plot_options\n                )\n                plotter = _get_plotter_class(comp.shape)(options)\n                plotter._populate_data(comp.shape)\n                self._cplotters.append(plotter)\n            else:\n                for child in comp.children:\n                    _populate_plotters(child)\n\n        _populate_plotters(comp)",
  "def _make_plot_2d(self):\n        for plotter in self._cplotters:\n            plotter.ax = self.ax\n            plotter._make_plot_2d()\n        self._set_aspect_2d()",
  "def _make_plot_3d(self):\n        \"\"\"\n        Internal function that makes the plot. It should use self._data and\n        self._data_to_plot, so _populate_data should be called before.\n        \"\"\"\n        for plotter in self._cplotters:\n            plotter.ax = self.ax\n            plotter._make_plot_3d()",
  "def _set_aspect_3d(self):\n        pass",
  "def __init__(self):\n        super().__init__()\n        self._plot_options: PlotOptions = PlotOptions()\n        self._plot_options.face_options[\"color\"] = next(BLUE_PALETTE)",
  "def plot_options(self) -> PlotOptions:\n        \"\"\"\n        The options that will be used to display the object.\n        \"\"\"\n        return self._plot_options",
  "def plot_options(self, value: PlotOptions):\n        if not isinstance(value, PlotOptions):\n            raise DisplayError(\"Display options must be set to a PlotOptions instance.\")\n        self._plot_options = value",
  "def _plotter(self) -> BasePlotter:\n        \"\"\"\n        The options that will be used to display the object.\n        \"\"\"\n        return _get_plotter_class(self)(self._plot_options)",
  "def plot_2d(self, ax=None, show: bool = True) -> None:\n        \"\"\"\n        Default method to call display the object by calling into the Displayer's display\n        method.\n\n        Returns\n        -------\n        axes\n            The axes that the plot has been displayed onto.\n        \"\"\"\n        return self._plotter.plot_2d(self, ax=ax, show=show)",
  "def plot_3d(self, ax=None, show: bool = True) -> None:\n        \"\"\"\n        Function to 3D plot a component.\n\n        Returns\n        -------\n        axes\n            The axes that the plot has been displayed onto.\n        \"\"\"\n        return self._plotter.plot_3d(self, ax=ax, show=show)",
  "def _populate_plotters(comp):\n            if comp.is_leaf and getattr(comp, \"shape\", None) is not None:\n                options = (\n                    self.options if comp.plot_options is None else comp.plot_options\n                )\n                plotter = _get_plotter_class(comp.shape)(options)\n                plotter._populate_data(comp.shape)\n                self._cplotters.append(plotter)\n            else:\n                for child in comp.children:\n                    _populate_plotters(child)",
  "def get_primary_screen_size(timeout: float = 3):\n    \"\"\"\n    Get the size in pixels of the primary screen.\n\n    Used for sizing figures to the screen for small screens.\n\n    Parameters\n    ----------\n    timeout: float\n        timeout value in seconds\n\n    Returns\n    -------\n    width: Union[int, None]\n        width of the primary screen in pixels. If there is no screen returns None\n    height: Union[int, None]\n        height of the primary screen in pixels. If there is no screen returns None\n    \"\"\"\n    with Pool(processes=1) as pool:\n        result = pool.apply_async(_get_primary_screen_size)\n        try:\n            val = result.get(timeout=timeout)\n        except TimeoutError:\n            pool.terminate()\n            bluemira_warn(\n                \"Unable to get screensize, please check your X server.\"\n                \" You may not be able to view live figures in this mode.\"\n            )\n            return None, None\n        else:\n            return val",
  "def _get_primary_screen_size():\n    \"\"\"\n    Direct run of screen size check without subprocess\n    \"\"\"\n    if sys.platform.startswith(\"linux\") and os.getenv(\"DISPLAY\") is None:\n        bluemira_debug(\n            \"No DISPLAY variable found, set DISPLAY to have interactive figures.\"\n        )\n        return None, None\n\n    # IPython detection (of sorts)\n    app = QtWidgets.QApplication.instance()\n    if app is None:\n        # if IPython isn't open then a QApplication is created to get screen size\n        app = QtWidgets.QApplication([])\n        rect = app.primaryScreen().availableGeometry()\n    else:\n        rect = app.primaryScreen().availableGeometry()\n\n    return rect.width(), rect.height()",
  "def get_figure_scale_factor(figsize):\n    \"\"\"\n    Scale figure size to fit on small screens.\n\n    If the screen fits the figure the scale factor is 1.\n\n    Parameters\n    ----------\n    figsize: np.array(float, float)\n        matplotlib figsize width x height\n\n    Returns\n    -------\n    sf: float\n        scale factor to fit screen\n\n    \"\"\"\n    screen_size = get_primary_screen_size()\n\n    if None in screen_size:\n        return 1\n\n    dpi = sns.mpl.rcParams[\"figure.dpi\"]\n\n    dpi_size = figsize * dpi\n    dpi_size += 0.10 * dpi_size  # space for toolbar\n\n    sf = 1  # scale factor\n    for ds, ss in zip(dpi_size, screen_size):\n        if ds > ss:\n            scale_temp = ss / ds\n            if scale_temp < sf:\n                sf = scale_temp\n    return sf",
  "def plot_defaults(force=False):\n    \"\"\"\n    Set a series of plotting defaults based on machine and user.\n\n    If bluemira plots are not to your tastes, do not work with your OS, or\n    don't fit your screen, please create a user profile for yourself/machine\n    here and adjust settings as needed.\n\n    Parameters\n    ----------\n    force: bool\n        force default figsize irrespective of screen size\n    \"\"\"\n    figsize = np.array([18, 15])\n\n    sf = 1 if force else get_figure_scale_factor(figsize)\n\n    sns.set_theme(\n        context=\"paper\",\n        style=\"ticks\",\n        font=\"DejaVu Sans\",\n        font_scale=2.5 * sf,\n        color_codes=False,\n        rc={\n            \"axes.labelweight\": \"normal\",\n            \"axes.titlesize\": 20 * sf,\n            \"contour.negative_linestyle\": \"solid\",\n            \"figure.figsize\": list(figsize * sf),\n            \"lines.linewidth\": 4 * sf,\n            \"lines.markersize\": 13 * sf,\n            \"xtick.direction\": \"in\",\n            \"ytick.direction\": \"in\",\n            \"xtick.major.size\": 8 * sf,\n            \"ytick.major.size\": 8 * sf,\n            \"xtick.minor.size\": 4 * sf,\n            \"ytick.minor.size\": 4 * sf,\n            \"xtick.color\": \"k\",\n        },\n    )\n    sns.set_palette(BLUEMIRA_PALETTE)",
  "class ColorPalette:\n    \"\"\"\n    Color palette object, wrapping some seaborn functionality.\n\n    Parameters\n    ----------\n    palette_map: Dict[str: Any]\n        Dictionary of color names to any object matplotlib will recognise as a color\n    \"\"\"\n\n    def __init__(self, palette_map):\n        self._dict = palette_map\n        color_list = []\n        for v in palette_map.values():\n            if isinstance(v, (str, tuple)):\n                color_list.append(v)\n            else:\n                color_list.extend(v._palette)\n        self._palette = sns.color_palette(color_list)\n        self._cycle = cycle(color_list)\n\n    def keys(self):\n        \"\"\"Keys of ColorPalette\"\"\"\n        return self._dict.keys()\n\n    def __next__(self):\n        \"\"\"\n        Get the next color in the ColorPalette\n        \"\"\"\n        return next(self._cycle)\n\n    def __setitem__(self, idx_or_key: Union[int, str], value):\n        \"\"\"\n        Set an item in the ColorPalette by index or key\n\n        Parameters\n        ----------\n        idx_or_key: Union[int, str]\n            Index or key of the ColorPalette\n        value: Union[ColorType, ColorPalette]\n            The value to set. Note that this can be another ColorPalette\n        \"\"\"\n        if isinstance(idx_or_key, int):\n            self._palette[idx_or_key] = value\n            key = list(self._dict)[idx_or_key]\n            self._dict[key] = value\n\n        elif isinstance(idx_or_key, str):\n            self._dict[idx_or_key] = type(self)({idx_or_key: value})\n            idx = list(self._dict).index(idx_or_key)\n            self._palette[idx] = type(self)({idx_or_key: value})\n\n    def __getitem__(self, idx_or_key: Union[int, str]):\n        \"\"\"\n        Get an item in the ColorPalette by index or key\n\n        Parameters\n        ----------\n        idx_or_key: Union[int, str]\n            Index or key of the ColorPalette\n\n        Returns\n        -------\n        value: Union[ColorType, ColorPalette]\n            The value. Note that this can be another ColorPalette\n        \"\"\"\n        if isinstance(idx_or_key, int):\n            return self._palette[idx_or_key]\n        elif isinstance(idx_or_key, str):\n            item = self._dict[idx_or_key]\n            return (\n                item\n                if isinstance(item, type(self))\n                else type(self)({idx_or_key: self._dict[idx_or_key]})\n            )\n\n    def _hex_horizontal(self) -> Union[List[str], List[List[str]]]:\n        _hex = self.as_hex()\n        if isinstance(_hex, str):\n            _hex = [_hex]\n        elif any(isinstance(h, list) for h in _hex):\n            for i, h in enumerate(_hex):\n                if isinstance(h, str):\n                    _hex[i] = [h]\n            _hex = list(map(list, zip_longest(*_hex, fillvalue=\"  \")))\n        return _hex\n\n    def _repr_html(self) -> str:\n        def html_str(_hex: Union[List[str], List[List[str]]], y: int = 0) -> str:\n            string = \"\"\n            x = 0\n            for col in _hex:\n                if isinstance(col, list):\n                    string += html_str(_hex=col, y=y)\n                    y += 1\n                else:\n                    if col != \"  \":\n                        string += (\n                            f'<rect x=\"{x*s}\" y=\"{y*s}\"'\n                            f' width=\"{s}\" height=\"{s}\" style=\"fill:{col};'\n                            'stroke-width:2;stroke:rgb(255,255,255)\"/>'\n                        )\n                    x += 1\n\n            return string\n\n        s = 55\n        hex_str = self._hex_horizontal()\n        m = len(hex_str) if any(isinstance(h, list) for h in hex_str) else 1\n        colours = html_str(hex_str)\n        return f'<svg  width=\"{(len(self))* s}\" height=\"{m * s}\">{colours}</svg>'\n\n    def _repr_colour_str(self, _hex: Union[List[str], List[List[str]]]) -> str:\n        \"\"\"Create colourful representation in terminal\"\"\"\n        string = \"\"\n        for col in _hex:\n            if isinstance(col, list):\n                string += self._repr_colour_str(_hex=col)\n            elif col != \"  \":\n                string += background_colour_string(col, sqlen=2)\n            else:\n                string += col\n        return f\"{string}\\n\"\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Create a representation of the ColorPalette\n        \"\"\"\n        try:\n            g_ipy = get_ipython()\n            if \"terminal\" in str(type(g_ipy)) or g_ipy is None:\n                return self._repr_colour_str(self._hex_horizontal()).strip(\" \\n\")\n        except NameError:\n            return self._repr_colour_str(self._hex_horizontal()).strip(\" \\n\")\n\n        from IPython.core.display import HTML, display\n\n        display(HTML(self._repr_html()))\n        return \"\"\n\n    def __len__(self) -> int:\n        \"\"\"Get the length of the ColorPalette\"\"\"\n        return len(self._palette)\n\n    def as_hex(self) -> Union[List[str], List[List[str]], str]:\n        \"\"\"\n        Get the hex representation of the palette\n        \"\"\"\n        hex_list = []\n        if isinstance(self._palette, list):\n            for pp in self._palette:\n                if isinstance(pp, tuple):\n                    hex_list.append(colors.to_hex(pp))\n                elif isinstance(pp, type(self)):\n                    hex_list.append(pp.as_hex())\n        elif isinstance(self._palette, tuple):\n            hex_list.append(colors.to_hex(self._palette))\n        else:\n            hex_list.append(self._palette)\n        return hex_list[0] if len(hex_list) == 1 else hex_list",
  "def background_colour_string(hexstring: str, sqlen=2) -> str:\n    \"\"\"Create ANSI background colour string for hex colour\"\"\"\n    hexstring = hexstring.strip(\"#\")\n    a, b, c = (1, 2, 3) if len(hexstring) == 3 else (2, 4, 6)\n    return (\n        f\"\\033[48:2::{int(hexstring[:a], 16)}:\"\n        f\"{int(hexstring[a:b], 16)}:\"\n        f\"{int(hexstring[b:c], 16)}m{' '*sqlen}\\033[49m\"\n    )",
  "def make_rgb_alpha(\n    rgb: Tuple[float, ...],\n    alpha: float,\n    background_rgb: Tuple[float, ...] = (1.0, 1.0, 1.0),\n) -> Tuple[float, ...]:\n    \"\"\"\n    Adds a transparency to a RGB color tuple\n\n    Parameters\n    ----------\n    rgb:\n        Tuple of 3 RGB floats  (0<=float<=1)\n    alpha:\n        Transparency as a fraction  (0<=float<=1)\n    background_rgb:\n        3 RGB floats (0<=float<=1), background colour (default = white)\n\n    Returns\n    -------\n    The RGB tuple accounting for transparency\n    \"\"\"\n    return tuple(alpha * c1 + (1 - alpha) * c2 for (c1, c2) in zip(rgb, background_rgb))",
  "def make_alpha_palette(color, n_colors: int, background_rgb=\"white\") -> ColorPalette:\n    \"\"\"\n    Make a palette from a color by varying alpha.\n\n    Parameters\n    ----------\n    color: Any\n        Palette base color. Anything matplotlib will recognise as a color\n    n_colors:\n        Numer of colors to make in the palette\n    background_rgb: Any\n        Background color. Anything matplotlib will recognise as a color\n\n    Returns\n    -------\n    Colour palette from the base color. The first color is the base color\n    \"\"\"\n    if isinstance(color, ColorPalette):\n        color = color._palette[0]\n\n    color_name = colors.to_hex(color)\n    color_rgb = colors.to_rgb(color)\n    background_rgb = colors.to_rgb(background_rgb)\n\n    color_values = [color_rgb] + [\n        make_rgb_alpha(color_rgb, alpha, background_rgb)\n        for alpha in np.linspace(0, 1, n_colors + 1)[1:-1][::-1]\n    ]\n    return ColorPalette(\n        {f\"{color_name}_{i}\": col_val for i, col_val in enumerate(color_values)}\n    )",
  "def __init__(self, palette_map):\n        self._dict = palette_map\n        color_list = []\n        for v in palette_map.values():\n            if isinstance(v, (str, tuple)):\n                color_list.append(v)\n            else:\n                color_list.extend(v._palette)\n        self._palette = sns.color_palette(color_list)\n        self._cycle = cycle(color_list)",
  "def keys(self):\n        \"\"\"Keys of ColorPalette\"\"\"\n        return self._dict.keys()",
  "def __next__(self):\n        \"\"\"\n        Get the next color in the ColorPalette\n        \"\"\"\n        return next(self._cycle)",
  "def __setitem__(self, idx_or_key: Union[int, str], value):\n        \"\"\"\n        Set an item in the ColorPalette by index or key\n\n        Parameters\n        ----------\n        idx_or_key: Union[int, str]\n            Index or key of the ColorPalette\n        value: Union[ColorType, ColorPalette]\n            The value to set. Note that this can be another ColorPalette\n        \"\"\"\n        if isinstance(idx_or_key, int):\n            self._palette[idx_or_key] = value\n            key = list(self._dict)[idx_or_key]\n            self._dict[key] = value\n\n        elif isinstance(idx_or_key, str):\n            self._dict[idx_or_key] = type(self)({idx_or_key: value})\n            idx = list(self._dict).index(idx_or_key)\n            self._palette[idx] = type(self)({idx_or_key: value})",
  "def __getitem__(self, idx_or_key: Union[int, str]):\n        \"\"\"\n        Get an item in the ColorPalette by index or key\n\n        Parameters\n        ----------\n        idx_or_key: Union[int, str]\n            Index or key of the ColorPalette\n\n        Returns\n        -------\n        value: Union[ColorType, ColorPalette]\n            The value. Note that this can be another ColorPalette\n        \"\"\"\n        if isinstance(idx_or_key, int):\n            return self._palette[idx_or_key]\n        elif isinstance(idx_or_key, str):\n            item = self._dict[idx_or_key]\n            return (\n                item\n                if isinstance(item, type(self))\n                else type(self)({idx_or_key: self._dict[idx_or_key]})\n            )",
  "def _hex_horizontal(self) -> Union[List[str], List[List[str]]]:\n        _hex = self.as_hex()\n        if isinstance(_hex, str):\n            _hex = [_hex]\n        elif any(isinstance(h, list) for h in _hex):\n            for i, h in enumerate(_hex):\n                if isinstance(h, str):\n                    _hex[i] = [h]\n            _hex = list(map(list, zip_longest(*_hex, fillvalue=\"  \")))\n        return _hex",
  "def _repr_html(self) -> str:\n        def html_str(_hex: Union[List[str], List[List[str]]], y: int = 0) -> str:\n            string = \"\"\n            x = 0\n            for col in _hex:\n                if isinstance(col, list):\n                    string += html_str(_hex=col, y=y)\n                    y += 1\n                else:\n                    if col != \"  \":\n                        string += (\n                            f'<rect x=\"{x*s}\" y=\"{y*s}\"'\n                            f' width=\"{s}\" height=\"{s}\" style=\"fill:{col};'\n                            'stroke-width:2;stroke:rgb(255,255,255)\"/>'\n                        )\n                    x += 1\n\n            return string\n\n        s = 55\n        hex_str = self._hex_horizontal()\n        m = len(hex_str) if any(isinstance(h, list) for h in hex_str) else 1\n        colours = html_str(hex_str)\n        return f'<svg  width=\"{(len(self))* s}\" height=\"{m * s}\">{colours}</svg>'",
  "def _repr_colour_str(self, _hex: Union[List[str], List[List[str]]]) -> str:\n        \"\"\"Create colourful representation in terminal\"\"\"\n        string = \"\"\n        for col in _hex:\n            if isinstance(col, list):\n                string += self._repr_colour_str(_hex=col)\n            elif col != \"  \":\n                string += background_colour_string(col, sqlen=2)\n            else:\n                string += col\n        return f\"{string}\\n\"",
  "def __repr__(self) -> str:\n        \"\"\"\n        Create a representation of the ColorPalette\n        \"\"\"\n        try:\n            g_ipy = get_ipython()\n            if \"terminal\" in str(type(g_ipy)) or g_ipy is None:\n                return self._repr_colour_str(self._hex_horizontal()).strip(\" \\n\")\n        except NameError:\n            return self._repr_colour_str(self._hex_horizontal()).strip(\" \\n\")\n\n        from IPython.core.display import HTML, display\n\n        display(HTML(self._repr_html()))\n        return \"\"",
  "def __len__(self) -> int:\n        \"\"\"Get the length of the ColorPalette\"\"\"\n        return len(self._palette)",
  "def as_hex(self) -> Union[List[str], List[List[str]], str]:\n        \"\"\"\n        Get the hex representation of the palette\n        \"\"\"\n        hex_list = []\n        if isinstance(self._palette, list):\n            for pp in self._palette:\n                if isinstance(pp, tuple):\n                    hex_list.append(colors.to_hex(pp))\n                elif isinstance(pp, type(self)):\n                    hex_list.append(pp.as_hex())\n        elif isinstance(self._palette, tuple):\n            hex_list.append(colors.to_hex(self._palette))\n        else:\n            hex_list.append(self._palette)\n        return hex_list[0] if len(hex_list) == 1 else hex_list",
  "def html_str(_hex: Union[List[str], List[List[str]]], y: int = 0) -> str:\n            string = \"\"\n            x = 0\n            for col in _hex:\n                if isinstance(col, list):\n                    string += html_str(_hex=col, y=y)\n                    y += 1\n                else:\n                    if col != \"  \":\n                        string += (\n                            f'<rect x=\"{x*s}\" y=\"{y*s}\"'\n                            f' width=\"{s}\" height=\"{s}\" style=\"fill:{col};'\n                            'stroke-width:2;stroke:rgb(255,255,255)\"/>'\n                        )\n                    x += 1\n\n            return string",
  "class DisplayError(BluemiraError):\n    \"\"\"\n    Exception class for Displayers.\n    \"\"\"\n\n    pass",
  "class Options:\n    \"\"\"\n    The options that are available for displaying objects.\n    \"\"\"\n\n    __slots__ = (\"_options\",)\n\n    def __init__(self, **kwargs):\n        self.modify(**kwargs)\n\n    def __setattr__(self, attr, val):\n        \"\"\"\n        Set attributes in options dictionary\n        \"\"\"\n        if getattr(self, \"_options\", None) is not None and (\n            attr in self._options.__annotations__ or hasattr(self._options, attr)\n        ):\n            setattr(self._options, attr, val)\n        else:\n            super().__setattr__(attr, val)\n\n    def __getattribute__(self, attr):\n        \"\"\"\n        Get attributes or from \"_options\" dict\n        \"\"\"\n        try:\n            return super().__getattribute__(attr)\n        except AttributeError as ae:\n            if attr != \"_options\":\n                try:\n                    return getattr(self._options, attr)\n                except AttributeError:\n                    raise ae\n            else:\n                raise ae\n\n    def modify(self, **kwargs):\n        \"\"\"Modify options\"\"\"\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n\n    def as_dict(self):\n        \"\"\"\n        Returns the instance as a dictionary.\n        \"\"\"\n        return asdict(self._options)\n\n    def __repr__(self):\n        \"\"\"\n        Representation string of the DisplayOptions.\n        \"\"\"\n        return f\"{type(self).__name__}({pprint.pformat(self.as_dict())}\\n)\"",
  "def __init__(self, **kwargs):\n        self.modify(**kwargs)",
  "def __setattr__(self, attr, val):\n        \"\"\"\n        Set attributes in options dictionary\n        \"\"\"\n        if getattr(self, \"_options\", None) is not None and (\n            attr in self._options.__annotations__ or hasattr(self._options, attr)\n        ):\n            setattr(self._options, attr, val)\n        else:\n            super().__setattr__(attr, val)",
  "def __getattribute__(self, attr):\n        \"\"\"\n        Get attributes or from \"_options\" dict\n        \"\"\"\n        try:\n            return super().__getattribute__(attr)\n        except AttributeError as ae:\n            if attr != \"_options\":\n                try:\n                    return getattr(self._options, attr)\n                except AttributeError:\n                    raise ae\n            else:\n                raise ae",
  "def modify(self, **kwargs):\n        \"\"\"Modify options\"\"\"\n        for k, v in kwargs.items():\n            setattr(self, k, v)",
  "def as_dict(self):\n        \"\"\"\n        Returns the instance as a dictionary.\n        \"\"\"\n        return asdict(self._options)",
  "def __repr__(self):\n        \"\"\"\n        Representation string of the DisplayOptions.\n        \"\"\"\n        return f\"{type(self).__name__}({pprint.pformat(self.as_dict())}\\n)\"",
  "class ViewerBackend(Enum):\n    \"\"\"CAD viewer backends.\"\"\"\n\n    FREECAD = \"bluemira.codes._freecadapi\"\n    POLYSCOPE = \"bluemira.codes._polyscope\"\n\n    @lru_cache(2)\n    def get_module(self):\n        \"\"\"Load viewer module\"\"\"\n        try:\n            return get_module(self.value)\n        except (ModuleNotFoundError, FileNotFoundError):\n            if self.name != \"FREECAD\":\n                name = self.name.lower()\n                bluemira_warn(\n                    f\"Unable to import {name.capitalize()} viewer\\n\"\n                    f\"Please 'pip install {name}' to use, falling back to FreeCAD.\"\n                )\n                return get_module(type(self).FREECAD.value)\n            raise",
  "def get_default_options(backend=ViewerBackend.FREECAD):\n    \"\"\"\n    Returns the default display options.\n    \"\"\"\n    return backend.get_module().DefaultDisplayOptions()",
  "class DisplayCADOptions(Options):\n    \"\"\"\n    The options that are available for displaying objects in 3D\n\n    Parameters\n    ----------\n    backend\n        the backend viewer being used\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, backend=ViewerBackend.FREECAD, **kwargs):\n        self._options = get_default_options(backend)\n        super().__init__(**kwargs)",
  "def _validate_display_inputs(parts, options, labels):\n    \"\"\"\n    Validate the lists of parts and options, applying some default options.\n    \"\"\"\n    if parts is None:\n        bluemira_debug(\"No new parts to display\")\n        return [], [], []\n\n    if not isinstance(parts, list):\n        parts = [parts]\n\n    if not isinstance(options, list) or options is None:\n        options = [options] * len(parts)\n\n    if labels is None:\n        labels = \"\"\n\n    if isinstance(labels, str):\n        labels = [labels] * len(parts)\n\n    if len(options) != len(parts):\n        raise DisplayError(\n            \"If options for plot are provided then there must be as many options as \"\n            \"there are parts to plot.\"\n        )\n    return parts, options, labels",
  "def show_cad(\n    parts: Optional[\n        Union[BluemiraGeo, List[BluemiraGeo]]  # noqa: F821\n    ] = None,  # avoiding circular deps\n    options: Optional[Union[DisplayCADOptions, List[DisplayCADOptions]]] = None,\n    labels: Optional[Union[str, List[str]]] = None,\n    backend: Union[str, ViewerBackend] = ViewerBackend.FREECAD,\n    **kwargs,\n):\n    \"\"\"\n    The CAD display API.\n\n    Parameters\n    ----------\n    parts\n        The parts to display.\n    options\n        The options to use to display the parts.\n    labels\n        Labels to use for each part object\n    backend\n        Viewer backend\n    kwargs\n        Passed on to modifications to the plotting style options and backend\n    \"\"\"\n    if isinstance(backend, str):\n        try:\n            backend = ViewerBackend[backend.upper()]\n        except KeyError:\n            bluemira_warn(f\"Unknown viewer backend '{backend}' defaulting to FreeCAD\")\n            backend = ViewerBackend.FREECAD\n\n    parts, options, labels = _validate_display_inputs(parts, options, labels)\n\n    new_options = []\n    for o in options:\n        if isinstance(o, DisplayCADOptions):\n            temp = DisplayCADOptions(**o.as_dict(), backend=backend)\n            temp.modify(**kwargs)\n            new_options.append(temp)\n        else:\n            new_options.append(DisplayCADOptions(**kwargs, backend=backend))\n\n    backend.get_module().show_cad(\n        [part.shape for part in parts],\n        [o.as_dict() for o in new_options],\n        labels,\n        **kwargs,\n    )",
  "class BaseDisplayer(ABC):\n    \"\"\"\n    Displayer abstract class\n    \"\"\"\n\n    _CLASS_DISPLAY_OPTIONS = {}\n\n    def __init__(self, options: Optional[DisplayCADOptions] = None, **kwargs):\n        self.options = (\n            DisplayCADOptions(**self._CLASS_DISPLAY_OPTIONS)\n            if options is None\n            else options\n        )\n        self.options.modify(**kwargs)\n\n    @abstractmethod\n    def show_cad(self, objs, **kwargs):\n        \"\"\"\n        Display a CAD object\n        \"\"\"\n        pass",
  "def _get_displayer_class(part):\n    \"\"\"\n    Get the displayer class for an object.\n    \"\"\"\n    import bluemira.base.components\n\n    if isinstance(part, bluemira.base.components.Component):\n        plot_class = ComponentDisplayer\n    else:\n        raise DisplayError(\n            f\"{part} object cannot be displayed. No Displayer available for {type(part)}\"\n        )\n    return plot_class",
  "class DisplayableCAD:\n    \"\"\"\n    Mixin class to make a class displayable by imparting a show_cad method and options.\n    \"\"\"\n\n    def __init__(self):\n        self._display_cad_options: DisplayCADOptions = DisplayCADOptions()\n        self._display_cad_options.colour = next(BLUE_PALETTE)\n\n    @property\n    def display_cad_options(self) -> DisplayCADOptions:\n        \"\"\"\n        The options that will be used to display the object.\n        \"\"\"\n        return self._display_cad_options\n\n    @display_cad_options.setter\n    def display_cad_options(self, value: DisplayCADOptions):\n        if not isinstance(value, DisplayCADOptions):\n            raise DisplayError(\n                \"Display options must be set to a DisplayCADOptions instance.\"\n            )\n        self._display_cad_options = value\n\n    @property\n    def _displayer(self) -> BaseDisplayer:\n        \"\"\"\n        The options that will be used to display the object.\n        \"\"\"\n        return _get_displayer_class(self)(self.display_cad_options)\n\n    def show_cad(self, **kwargs) -> None:\n        \"\"\"\n        Default method to call display the object by calling into the Displayer's display\n        method.\n\n        Returns\n        -------\n        axes\n            The axes that the plot has been displayed onto.\n        \"\"\"\n        return self._displayer.show_cad(self, **kwargs)",
  "class ComponentDisplayer(BaseDisplayer):\n    \"\"\"\n    CAD displayer for Components\n    \"\"\"\n\n    def show_cad(\n        self,\n        comps,\n        **kwargs,\n    ):\n        \"\"\"\n        Display the CAD of a component or iterable of components\n\n        Parameters\n        ----------\n        comp: Union[Iterable[Component], Component]\n            Component, or iterable of Components, to be displayed\n        \"\"\"\n        import bluemira.base.components as bm_comp\n\n        show_cad(\n            *bm_comp.get_properties_from_components(\n                comps, (\"shape\", \"display_cad_options\", \"name\")\n            ),\n            **kwargs,\n        )",
  "def get_module(self):\n        \"\"\"Load viewer module\"\"\"\n        try:\n            return get_module(self.value)\n        except (ModuleNotFoundError, FileNotFoundError):\n            if self.name != \"FREECAD\":\n                name = self.name.lower()\n                bluemira_warn(\n                    f\"Unable to import {name.capitalize()} viewer\\n\"\n                    f\"Please 'pip install {name}' to use, falling back to FreeCAD.\"\n                )\n                return get_module(type(self).FREECAD.value)\n            raise",
  "def __init__(self, backend=ViewerBackend.FREECAD, **kwargs):\n        self._options = get_default_options(backend)\n        super().__init__(**kwargs)",
  "def __init__(self, options: Optional[DisplayCADOptions] = None, **kwargs):\n        self.options = (\n            DisplayCADOptions(**self._CLASS_DISPLAY_OPTIONS)\n            if options is None\n            else options\n        )\n        self.options.modify(**kwargs)",
  "def show_cad(self, objs, **kwargs):\n        \"\"\"\n        Display a CAD object\n        \"\"\"\n        pass",
  "def __init__(self):\n        self._display_cad_options: DisplayCADOptions = DisplayCADOptions()\n        self._display_cad_options.colour = next(BLUE_PALETTE)",
  "def display_cad_options(self) -> DisplayCADOptions:\n        \"\"\"\n        The options that will be used to display the object.\n        \"\"\"\n        return self._display_cad_options",
  "def display_cad_options(self, value: DisplayCADOptions):\n        if not isinstance(value, DisplayCADOptions):\n            raise DisplayError(\n                \"Display options must be set to a DisplayCADOptions instance.\"\n            )\n        self._display_cad_options = value",
  "def _displayer(self) -> BaseDisplayer:\n        \"\"\"\n        The options that will be used to display the object.\n        \"\"\"\n        return _get_displayer_class(self)(self.display_cad_options)",
  "def show_cad(self, **kwargs) -> None:\n        \"\"\"\n        Default method to call display the object by calling into the Displayer's display\n        method.\n\n        Returns\n        -------\n        axes\n            The axes that the plot has been displayed onto.\n        \"\"\"\n        return self._displayer.show_cad(self, **kwargs)",
  "def show_cad(\n        self,\n        comps,\n        **kwargs,\n    ):\n        \"\"\"\n        Display the CAD of a component or iterable of components\n\n        Parameters\n        ----------\n        comp: Union[Iterable[Component], Component]\n            Component, or iterable of Components, to be displayed\n        \"\"\"\n        import bluemira.base.components as bm_comp\n\n        show_cad(\n            *bm_comp.get_properties_from_components(\n                comps, (\"shape\", \"display_cad_options\", \"name\")\n            ),\n            **kwargs,\n        )",
  "class ITERGravitySupportBuilderParams(ParameterFrame):\n    \"\"\"\n    ITER-like gravity support parameters\n    \"\"\"\n\n    x_g_support: Parameter[float]\n    z_gs: Parameter[float]\n    tf_wp_width: Parameter[float]\n    tf_wp_depth: Parameter[float]\n    tk_tf_side: Parameter[float]\n    tf_gs_tk_plate: Parameter[float]\n    tf_gs_g_plate: Parameter[float]\n    tf_gs_base_depth: Parameter[float]",
  "class ITERGravitySupportBuilder(Builder):\n    \"\"\"\n    ITER-like gravity support builder\n\n    Parameters\n    ----------\n    params:\n        Parameters to use\n    build_config:\n        Build config to use\n    tf_kz_keep_out_zone:\n        TF coil wire keep-out-zone for the outer edge of the TF coil (including casing)\n        Note that this should be on the y=0 plane.\n    \"\"\"\n\n    param_cls: Type[ITERGravitySupportBuilderParams] = ITERGravitySupportBuilderParams\n\n    def __init__(\n        self,\n        params: Union[ITERGravitySupportBuilderParams, Dict],\n        build_config: Dict,\n        tf_xz_keep_out_zone: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.tf_xz_keep_out_zone = tf_xz_keep_out_zone\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the ITER-like gravity support component.\n        \"\"\"\n        xyz = self.build_xyz()\n        return self.component_tree([self.build_xz(xyz)], self.build_xy(), [xyz])\n\n    def build_xz(self, xyz_component):\n        \"\"\"\n        Build the x-z component of the ITER-like gravity support.\n        \"\"\"\n        xz_plane = BluemiraPlane((0, 0, 0), (0, 1, 0))\n        slice_result = slice_shape(xyz_component.shape, xz_plane)\n\n        # Process UGLY SLICE\n        wires = sorted(slice_result, key=lambda wire: wire.length)\n        wire_list = [wires.pop()]\n        wire_list.extend(wires)\n        shape = BluemiraFace(wire_list)\n\n        component = PhysicalComponent(\"ITER-like gravity support\", shape)\n        apply_component_display_options(component, color=BLUE_PALETTE[\"TF\"][2])\n        return component\n\n    def build_xy(self):\n        \"\"\"\n        Build the x-y component of the ITER-like gravity support.\n        \"\"\"\n        pass\n\n    def _get_intersection_wire(self, width):\n        x_g_support = self.params.x_g_support.value\n        x_inner_line = x_g_support - 0.5 * width\n        x_outer_line = x_g_support + 0.5 * width\n        z_min = self.tf_xz_keep_out_zone.bounding_box.z_min\n        z_max = z_min + 0.5 * (self.tf_xz_keep_out_zone.bounding_box.z_max - z_min)\n        x_min = self.tf_xz_keep_out_zone.bounding_box.x_min + 0.5 * width\n        x_max = self.tf_xz_keep_out_zone.bounding_box.x_max - 0.5 * width\n        if (x_g_support < x_min) | (x_g_support > x_max):\n            raise BuilderError(\n                \"The gravity support footprint is not contained within the provided TF coil geometry!\"\n            )\n\n        if (self.params.z_gs.value - 6 * self.params.tf_gs_tk_plate.value) > z_min:\n            raise BuilderError(\n                \"The gravity support floor is not lower than where the TF coil is!\"\n            )\n        z_min = self.params.z_gs.value - 6 * self.params.tf_gs_tk_plate.value\n\n        cut_box = make_polygon(\n            {\n                \"x\": [x_inner_line, x_inner_line, x_outer_line, x_outer_line],\n                \"y\": 0,\n                \"z\": [z_min, z_max, z_max, z_min],\n            },\n            closed=True,\n        )\n\n        cut_result = boolean_cut(self.tf_xz_keep_out_zone, cut_box)\n\n        if cut_result is None:\n            raise BuilderError(\n                \"Boolean cutting returned nothing... check your geometry please.\"\n            )\n\n        return sorted(cut_result, key=lambda wire: wire.length)[0]\n\n    def _make_connection_block(self, width, v1, v4, intersection_wire):\n        \"\"\"\n        Make the connection block of the gravity support with the TF coil\n        \"\"\"\n        z_block_lower = min(v1.z[0], v4.z[0]) - 5 * self.params.tf_gs_tk_plate.value\n        v2 = Coordinates(np.array([v1.x[0], 0, z_block_lower]))\n        v3 = Coordinates(np.array([v4.x[0], 0, z_block_lower]))\n\n        points = np.concatenate([v1.xyz, v2.xyz, v3.xyz, v4.xyz], axis=1)\n        closing_wire = make_polygon(points, closed=False)\n        face = BluemiraFace(BluemiraWire([intersection_wire, closing_wire]))\n\n        # Then extrude that face in both directions to get the connection block\n        face.translate(vector=(0, -0.5 * width, 0))\n        return extrude_shape(face, vec=(0, width, 0))\n\n    def _make_plates(self, width, v1x, v4x, z_block_lower):\n        \"\"\"\n        Make the gravity support vertical plates\n        \"\"\"\n        plate_list = []\n        yz_profile = Coordinates(\n            {\n                \"x\": 4 * [v1x],\n                \"y\": [\n                    -0.5 * width,\n                    0.5 * width,\n                    0.5 * self.params.tf_gs_base_depth.value,\n                    -0.5 * self.params.tf_gs_base_depth.value,\n                ],\n                \"z\": [\n                    z_block_lower,\n                    z_block_lower,\n                    self.params.z_gs.value,\n                    self.params.z_gs.value,\n                ],\n            },\n        )\n        yz_profile = make_polygon(yz_profile, closed=True)\n\n        plating_width = v4x - v1x\n        plate_and_gap = (\n            self.params.tf_gs_g_plate.value + self.params.tf_gs_tk_plate.value\n        )\n        n_plates = int((plating_width + self.params.tf_gs_g_plate.value) / plate_and_gap)\n        total_width = (\n            n_plates * self.params.tf_gs_tk_plate.value\n            + (n_plates - 1) * self.params.tf_gs_g_plate.value\n        )\n        delta_width = plating_width - total_width\n        yz_profile.translate(vector=(0.5 * delta_width, 0, 0))\n\n        plate = extrude_shape(\n            BluemiraFace(yz_profile), vec=(self.params.tf_gs_tk_plate.value, 0, 0)\n        )\n        plate_list.append(plate)\n        for _ in range(n_plates - 1):\n            plate = plate.deepcopy()\n            plate.translate(\n                vector=(\n                    plate_and_gap,\n                    0,\n                    0,\n                )\n            )\n            plate_list.append(plate)\n        return plate_list\n\n    def _make_floor_block(self, v1x, v4x):\n        xz_profile = Coordinates(\n            {\n                \"x\": [v1x, v1x, v4x, v4x],\n                \"y\": [\n                    -0.5 * self.params.tf_gs_base_depth.value,\n                    0.5 * self.params.tf_gs_base_depth.value,\n                    0.5 * self.params.tf_gs_base_depth.value,\n                    -0.5 * self.params.tf_gs_base_depth.value,\n                ],\n                \"z\": 4 * [self.params.z_gs.value],\n            },\n        )\n        xz_profile = BluemiraFace(make_polygon(xz_profile, closed=True))\n        return extrude_shape(\n            xz_profile, vec=(0, 0, -5 * self.params.tf_gs_tk_plate.value)\n        )\n\n    def build_xyz(\n        self,\n    ) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y-z component of the ITER-like gravity support.\n        \"\"\"\n        shape_list = []\n        # First, project upwards at the radius of the GS into the keep-out-zone\n        # and get a x-z face of the boolean difference.\n\n        # Get the square width\n        width = self.params.tf_wp_depth.value + 2 * self.params.tk_tf_side.value\n\n        intersection_wire = self._get_intersection_wire(width)\n        v1 = intersection_wire.start_point()\n        v4 = intersection_wire.end_point()\n        if v1.x > v4.x:\n            v1, v4 = v4, v1\n\n        connection_block = self._make_connection_block(width, v1, v4, intersection_wire)\n        shape_list.append(connection_block)\n\n        # Next, make the plates in a linear pattern, in y-z, along x\n        z_block_lower = connection_block.bounding_box.z_min\n        shape_list.extend(\n            self._make_plates(width, float(v1.x), float(v4.x), z_block_lower)\n        )\n\n        # Finally, make the floor block\n        shape_list.append(self._make_floor_block(float(v1.x), float(v4.x)))\n        shape = boolean_fuse(shape_list)\n        component = PhysicalComponent(\"ITER-like gravity support\", shape)\n        apply_component_display_options(component, color=BLUE_PALETTE[\"TF\"][2])\n        return component",
  "class PFCoilSupportBuilderParams(ParameterFrame):\n    \"\"\"\n    PF coil support parameters\n    \"\"\"\n\n    tf_wp_width: Parameter[float]\n    tf_wp_depth: Parameter[float]\n    tk_tf_side: Parameter[float]\n    pf_s_tk_plate: Parameter[float]\n    pf_s_n_plate: Parameter[int]\n    pf_s_g: Parameter[float]",
  "class PFCoilSupportBuilder(Builder):\n    \"\"\"\n    PF coil support builder\n    \"\"\"\n\n    param_cls: Type[PFCoilSupportBuilderParams] = PFCoilSupportBuilderParams\n\n    def __init__(\n        self,\n        params: Union[PFCoilSupportBuilderParams, Dict],\n        build_config: Dict,\n        tf_xz_keep_out_zone: BluemiraWire,\n        pf_coil_xz: BluemiraWire,\n    ):\n        super().__init__(params, build_config, verbose=False)\n        self.tf_xz_keep_out_zone = tf_xz_keep_out_zone\n        self.pf_coil_xz = pf_coil_xz\n        self.name = f\"{self.name} {self.build_config.get('support_number', 0)}\"\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the PF coil support component.\n        \"\"\"\n        xyz = self.build_xyz()\n        return self.component_tree([self.build_xz(xyz)], self.build_xy(), [xyz])\n\n    def build_xy(self):\n        \"\"\"\n        Build the x-y components of the PF coil support.\n        \"\"\"\n        pass\n\n    def build_xz(self, xyz):\n        \"\"\"\n        Build the x-z components of the PF coil support.\n        \"\"\"\n        result = slice_shape(xyz.shape, BluemiraPlane(axis=(0, 1, 0)))\n        result.sort(key=lambda wire: -wire.length)\n        face = BluemiraFace(result)\n        component = PhysicalComponent(self.name, face)\n        apply_component_display_options(component, color=BLUE_PALETTE[\"TF\"][2])\n        return component\n\n    def _build_support_xs(self):\n        bb = self.pf_coil_xz.bounding_box\n        width = self.params.tf_wp_depth.value + 2 * self.params.tk_tf_side.value\n        half_width = 0.5 * width\n\n        if bb.x_min < half_width:\n            raise BuilderError(\"PF coil has too small a minimum radius!\")\n\n        alpha = np.arcsin(half_width / bb.x_min)\n        inner_dr = half_width * np.tan(alpha)\n\n        beta = np.arcsin(half_width / bb.x_max)\n        outer_dr = half_width * np.tan(beta)\n\n        x_min = bb.x_min - self.params.pf_s_g.value - inner_dr\n        x_max = bb.x_max + self.params.pf_s_g.value + outer_dr\n        z_min = bb.z_min\n        z_max = bb.z_max\n        box_inner = make_polygon(\n            {\n                \"x\": [x_min, x_max, x_max, x_min],\n                \"y\": 0,\n                \"z\": [z_min, z_min, z_max, z_max],\n            },\n            closed=True,\n        )\n        box_outer = offset_wire(box_inner, self.params.pf_s_tk_plate.value)\n        face = BluemiraFace([box_outer, box_inner])\n        return face\n\n    @staticmethod\n    def _get_first_intersection(point, angle, wire):\n        \"\"\"\n        Get the first intersection from a point along an angle with a wire.\n        \"\"\"\n        point = np.array(point)\n        x_out = point[0] + np.cos(angle) * VERY_BIG\n        z_out = point[2] + np.sin(angle) * VERY_BIG\n        dir_point = np.array([x_out, 0, z_out])\n\n        correct_direction = dir_point - point\n        correct_direction /= np.linalg.norm(correct_direction)\n\n        plane = BluemiraPlane.from_3_points(point, dir_point, [x_out, 1, z_out])\n        intersections = slice_shape(wire, plane)\n        distances = []\n        if intersections is None:\n            return None\n\n        directed_intersections = []\n        for inter in intersections:\n            direction = inter - point\n            direction /= np.linalg.norm(direction)\n            if not np.dot(correct_direction, direction) < 0:\n                dx = inter[0] - point[0]\n                dz = inter[2] - point[2]\n\n                dist = np.hypot(dx, dz)\n                distances.append(dist)\n                directed_intersections.append(inter)\n\n        if len(directed_intersections) > 0:\n            i_min = np.argmin(distances)\n            p_inter = directed_intersections[i_min]\n            return p_inter\n\n    def _get_support_point_angle(self, support_face: BluemiraFace):\n        bb = support_face.boundary[0].bounding_box\n        z_down = bb.z_min\n        z_up = bb.z_max\n\n        distance = np.inf\n        best_angle = None\n        v1, v2, v3, v4 = None, None, None, None\n        for z, sign in zip([z_up, z_down], [1, -1]):\n            for angle in [0.5 * np.pi, 2 / 3 * np.pi, 1 / 3 * np.pi]:\n                p_inters = []\n                distances = []\n                for x in [bb.x_min, bb.x_max]:\n                    point = [x, 0, z]\n                    p_inter = self._get_first_intersection(\n                        point, sign * angle, self.tf_xz_keep_out_zone\n                    )\n\n                    if p_inter is not None:\n                        d = np.hypot(point[0] - p_inter[0], point[2] - p_inter[2])\n                        p_inters.append(p_inter)\n                        distances.append(d)\n\n                if len(p_inters) == 2:\n                    avg_distance = np.average(distances)\n                    if avg_distance <= distance:\n                        distance = avg_distance\n                        v1 = np.array([bb.x_min, 0, z])\n                        v2 = np.array([bb.x_max, 0, z])\n                        v3 = p_inters[1]\n                        v4 = p_inters[0]\n                        best_angle = sign * angle\n\n        if distance == np.inf:\n            raise BuilderError(\"No intersections found!\")\n\n        return v1, v2, v3, v4, best_angle\n\n    def _get_intersecting_wire(self, v1, v2, v3, v4, angle):\n        # Add some offset to get one small wire when cutting\n        v3 += 0.1 * np.array([np.cos(angle), 0, np.sin(angle)])\n        v4 += 0.1 * np.array([np.cos(angle), 0, np.sin(angle)])\n\n        cut_box = make_polygon([v1, v2, v3, v4], closed=True)\n\n        intersection_wire = sorted(\n            boolean_cut(self.tf_xz_keep_out_zone, cut_box), key=lambda wire: wire.length\n        )[0]\n        return intersection_wire\n\n    def _make_rib_profile(self, support_face):\n        # Then, project sideways to find the minimum distance from a support point\n        # to the TF coil\n        v1, v2, v3, v4, angle = self._get_support_point_angle(support_face)\n\n        # Get the intersection with the TF edge wire and use this for the rib profile\n        intersection_wire = self._get_intersecting_wire(v1, v2, v3, v4, angle)\n\n        # Make the closing wire, and make sure the polygon doesn't self-intersect\n        v3 = intersection_wire.start_point().xyz.T[0]\n        v4 = intersection_wire.end_point().xyz.T[0]\n\n        inter1 = get_intersect(\n            np.array([[v1[0], v3[0]], [v1[2], v3[2]]]),\n            np.array([[v2[0], v4[0]], [v2[2], v4[2]]]),\n        )\n        if len(inter1[0]) > 0:\n            v3, v4 = v4, v3\n\n        closing_wire = make_polygon(\n            {\n                \"x\": [v3[0], v1[0], v2[0], v4[0]],\n                \"y\": 0,\n                \"z\": [v3[2], v1[2], v2[2], v4[2]],\n            },\n            closed=False,\n        )\n        rib_face = BluemiraFace(BluemiraWire([intersection_wire, closing_wire]))\n\n        # Trim rib face if there is a collision\n        result = boolean_cut(rib_face, BluemiraFace(self.tf_xz_keep_out_zone))\n\n        if result:\n            result.sort(key=lambda face: -face.area)\n            rib_face = result[0]\n\n        return rib_face\n\n    def _make_ribs(self, width, support_face):\n        xz_profile = self._make_rib_profile(support_face)\n        # Calculate the rib gap width and make the ribs\n        rib_list = []\n        total_rib_tk = self.params.pf_s_n_plate.value * self.params.pf_s_tk_plate.value\n        if total_rib_tk >= width:\n            bluemira_warn(\n                \"PF coil support rib thickness and number exceed available thickness! You're getting a solid block instead\"\n            )\n            gap_size = 0\n            rib_block = extrude_shape(xz_profile, vec=(0, width, 0))\n            rib_list.append(rib_block)\n        else:\n            gap_size = (width - total_rib_tk) / (self.params.pf_s_n_plate.value - 1)\n            rib = extrude_shape(xz_profile, vec=(0, self.params.pf_s_tk_plate.value, 0))\n            rib_list.append(rib)\n            for _ in range(self.params.pf_s_n_plate.value - 1):\n                rib = rib.deepcopy()\n                rib.translate(vector=(0, self.params.pf_s_tk_plate.value + gap_size, 0))\n                rib_list.append(rib)\n        return rib_list\n\n    def build_xyz(\n        self,\n    ) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y-z components of the PF coil support.\n        \"\"\"\n        shape_list = []\n        # First build the support block around the PF coil\n        support_face = self._build_support_xs()\n        # Trim support face is there is a collision\n        support_face = boolean_cut(support_face, BluemiraFace(self.tf_xz_keep_out_zone))[\n            0\n        ]\n\n        width = self.params.tf_wp_depth.value + 2 * self.params.tk_tf_side.value\n        support_block = extrude_shape(support_face, vec=(0, width, 0))\n        shape_list.append(support_block)\n\n        # Make the rib x-z profile and ribs\n        shape_list.extend(self._make_ribs(width, support_face))\n\n        try:\n            shape = boolean_fuse(shape_list)\n        except GeometryError:\n            bluemira_warn(\n                \"PFCoilSupportBuilder boolean_fuse failed, getting a BluemiraCompound instead of a BluemiraSolid, please check!\"\n            )\n            shape = BluemiraCompound(shape_list)\n\n        shape.translate(vector=(0, -0.5 * width, 0))\n        component = PhysicalComponent(self.name, shape)\n        apply_component_display_options(component, color=BLUE_PALETTE[\"TF\"][2])\n        return component",
  "class StraightOISOptimisationProblem(OptimisationProblem):\n    \"\"\"\n    Optimisation problem for a straight outer inter-coil structure\n\n    Parameters\n    ----------\n    wire:\n        Sub wire along which to place the OIS\n    keep_out_zone:\n        Region in which the OIS cannot be\n    n_koz_discr:\n        Number of discretisation points to use when checking the keep-out zone constraint\n    \"\"\"\n\n    def __init__(\n        self,\n        wire: BluemiraWire,\n        keep_out_zone: BluemiraFace,\n        optimiser: Optional[_DeprecatedOptimiser] = None,\n        n_koz_discr: int = 100,\n    ):\n        self.wire = wire\n        self.n_koz_discr = n_koz_discr\n        self.koz_points = (\n            keep_out_zone.boundary[0].discretize(byedges=True, ndiscr=n_koz_discr).xz.T\n        )\n        if optimiser is not None:\n            warnings.warn(\n                \"Use of StraightOISOptimisationProblem's 'optimiser' argument is \"\n                \"deprecated and it will be removed in version 2.0.0.\\n\"\n                \"See \"\n                \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n                \"optimisation.html \"\n                \"for documentation of the new optimisation module.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n\n    def objective(self, x: np.ndarray) -> float:\n        \"\"\"Objective function to maximise length.\"\"\"\n        return self.negative_length(x)\n\n    def ineq_constraints(self) -> List[ConstraintT]:\n        \"\"\"The inequality constraints for the problem.\"\"\"\n        return [\n            {\n                \"f_constraint\": self.constrain_koz,\n                \"tolerance\": np.full(self.n_koz_discr, 1e-6),\n            },\n            {\n                \"f_constraint\": self.constrain_x,\n                \"df_constraint\": self.df_constrain_x,\n                \"tolerance\": np.array([1e-6]),\n            },\n        ]\n\n    def bounds(self) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"The optimisation parameter bounds.\"\"\"\n        return np.array([0, 0]), np.array([1, 1])\n\n    @staticmethod\n    def f_L_to_wire(wire: BluemiraWire, x_norm: List[float]):  # noqa: N802\n        \"\"\"\n        Convert a pair of normalised L values to a wire\n        \"\"\"\n        p1 = wire.value_at(x_norm[0])\n        p2 = wire.value_at(x_norm[1])\n        return make_polygon([p1, p2])\n\n    @staticmethod\n    def f_L_to_xz(wire: BluemiraWire, value: float) -> np.ndarray:  # noqa: N802\n        \"\"\"\n        Convert a normalised L value to an x, z pair.\n        \"\"\"\n        point = wire.value_at(value)\n        return np.array([point[0], point[2]])\n\n    def negative_length(self, x_norm: np.ndarray) -> float:\n        \"\"\"\n        Calculate the negative length of the straight OIS\n\n        Parameters\n        ----------\n        x_norm:\n            Normalised solution vector\n\n        Returns\n        -------\n        Negative length from the normalised solution vector\n        \"\"\"\n        p1 = self.f_L_to_xz(self.wire, x_norm[0])\n        p2 = self.f_L_to_xz(self.wire, x_norm[1])\n        return -np.hypot(*(p2 - p1))\n\n    def constrain_koz(self, x_norm: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Constrain the straight OIS to be outside a keep-out-zone\n\n        Parameters\n        ----------\n        x_norm:\n            Normalised solution vector\n\n        Returns\n        -------\n        KOZ constraint array\n        \"\"\"\n        straight_line = self.f_L_to_wire(self.wire, x_norm)\n        straight_points = straight_line.discretize(ndiscr=self.n_koz_discr).xz.T\n        return signed_distance_2D_polygon(straight_points, self.koz_points)\n\n    def constrain_x(self, x_norm: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Constrain the second normalised value to be always greater than the first.\n        \"\"\"\n        return x_norm[0] - x_norm[1]\n\n    def df_constrain_x(self, x_norm: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Gradient of the constraint on  the solution vector\n        \"\"\"\n        return np.array([1.0, -1.0])",
  "class StraightOISDesignerParams(ParameterFrame):\n    \"\"\"\n    Parameters for the StraightOISDesigner\n    \"\"\"\n\n    tk_ois: Parameter[float]\n    g_ois_tf_edge: Parameter[float]\n    min_OIS_length: Parameter[float]",
  "class StraightOISDesigner(Designer[List[BluemiraWire]]):\n    \"\"\"\n    Design a set of straight length outer inter-coil structures.\n\n    Parameters\n    ----------\n    params:\n        ParameterFrame for the StraightOISDesigner\n    build_config:\n        Build config dictionary for the StraightOISDesigner\n    tf_coil_xz_face:\n        x-z face of the TF coil on the y=0 plane\n    keep_out_zones:\n        List of x-z keep_out_zone faces on the y=0 plane\n    \"\"\"\n\n    param_cls = StraightOISDesignerParams\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Dict,\n        tf_coil_xz_face: BluemiraFace,\n        keep_out_zones: List[BluemiraFace],\n    ):\n        super().__init__(params, build_config)\n        self.tf_face = tf_coil_xz_face\n        self.keep_out_zones = keep_out_zones\n\n    def run(self) -> List[BluemiraWire]:\n        \"\"\"\n        Create and run the design optimisation problem.\n\n        Returns\n        -------\n        A list of outer inter-coil structure wires on the y=0 plane.\n        \"\"\"\n        inner_tf_wire = self.tf_face.boundary[1]\n        koz_centreline = offset_wire(\n            inner_tf_wire,\n            self.params.g_ois_tf_edge.value,\n            open_wire=False,\n            join=\"arc\",\n        )\n        ois_centreline = offset_wire(\n            inner_tf_wire,\n            2 * self.params.g_ois_tf_edge.value,\n            open_wire=False,\n            join=\"arc\",\n        )\n        ois_regions = self._make_ois_regions(ois_centreline, koz_centreline)\n        koz = self._make_ois_koz(koz_centreline)\n\n        ois_wires = []\n        for region in ois_regions:\n            opt_problem = StraightOISOptimisationProblem(region, koz)\n            result = opt_problem.optimise(\n                x0=np.array([0.0, 1.0]),\n                algorithm=\"COBYLA\",\n                opt_conditions={\"ftol_rel\": 1e-6, \"max_eval\": 1000},\n            ).x\n            p1 = region.value_at(result[0])\n            p2 = region.value_at(result[1])\n            wire = self._make_ois_wire(p1, p2)\n            ois_wires.append(wire)\n        return ois_wires\n\n    def _make_ois_wire(self, p1, p2):\n        \"\"\"\n        Make a rectangular wire from the two inner edge points\n        \"\"\"\n        dx = p2[0] - p1[0]\n        dz = p2[2] - p1[2]\n        normal = np.array([dz, 0, -dx])\n        normal /= np.linalg.norm(normal)\n        tk = self.params.tk_ois.value\n        p3 = p2 + tk * normal\n        p4 = p1 + tk * normal\n        return make_polygon([p1, p2, p3, p4], closed=True)\n\n    def _make_ois_koz(self, koz_centreline):\n        \"\"\"\n        Make the (fused) keep-out-zone for the outer inter-coil structures.\n        \"\"\"\n        # Note we use the same offset to the exclusion zones as for the OIS\n        # to the TF.\n        koz_wires = [\n            offset_wire(koz.boundary[0], self.params.g_ois_tf_edge.value)\n            for koz in self.keep_out_zones\n        ]\n        koz_faces = [BluemiraFace(koz) for koz in koz_wires]\n\n        return boolean_fuse([BluemiraFace(koz_centreline)] + koz_faces)\n\n    def _make_ois_regions(self, ois_centreline, koz_centreline):\n        \"\"\"\n        Select regions that are viable for outer inter-coil structures\n        \"\"\"\n        inner_wire = self.tf_face.boundary[1]\n        # Drop the inboard (already connected by the vault)\n        # Note we also drop the probable worst case of the edge corners of the OIS\n        # colliding when swept.\n        x_min = inner_wire.bounding_box.x_min + np.sqrt(2) * self.params.tk_ois.value\n        z_min = self.tf_face.bounding_box.z_min - 0.1\n        z_max = self.tf_face.bounding_box.z_max + 0.1\n        inboard_cutter = BluemiraFace(\n            make_polygon(\n                {\"x\": [0, x_min, x_min, 0], \"z\": [z_min, z_min, z_max, z_max]},\n                closed=True,\n            )\n        )\n        cutter = BluemiraFace(koz_centreline)\n        cutter = boolean_fuse([cutter, inboard_cutter] + self.keep_out_zones)\n\n        ois_regions = boolean_cut(ois_centreline, cutter)\n\n        # Drop regions that are too short for OIS\n        big_ois_regions = []\n        for region in ois_regions:\n            length = np.sqrt(\n                np.sum((region.start_point().xyz - region.end_point().xyz) ** 2)\n            )\n            if length > self.params.min_OIS_length.value:\n                big_ois_regions.append(region)\n        return big_ois_regions",
  "class OISBuilderParams(ParameterFrame):\n    \"\"\"\n    Outer intercoil structure parameters\n    \"\"\"\n\n    n_TF: Parameter[int]\n    tf_wp_depth: Parameter[float]\n    tk_tf_side: Parameter[float]",
  "class OISBuilder(Builder):\n    \"\"\"\n    Outer intercoil structure builder\n    \"\"\"\n\n    RIGHT_OIS = \"TF OIS right\"\n    LEFT_OIS = \"TF OIS left\"\n    OIS_XZ = \"TF OIS\"\n    param_cls: Type[OISBuilderParams] = OISBuilderParams\n\n    def __init__(\n        self,\n        params: Union[OISBuilderParams, Dict],\n        build_config: Dict,\n        ois_xz_profiles: Union[BluemiraWire, List[BluemiraWire]],\n    ):\n        super().__init__(params, build_config)\n        if not isinstance(ois_xz_profiles, List):\n            ois_xz_profiles = [ois_xz_profiles]\n        self.ois_xz_profiles = ois_xz_profiles\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the PF coil support component.\n        \"\"\"\n        return self.component_tree(self.build_xz(), self.build_xy(), self.build_xyz())\n\n    def build_xy(self):\n        \"\"\"\n        Build the x-y component of the OIS\n        \"\"\"\n        pass\n\n    def build_xz(self):\n        \"\"\"\n        Build the x-z component of the OIS\n        \"\"\"\n        components = []\n        for i, ois_profile in enumerate(self.ois_xz_profiles):\n            face = BluemiraFace(ois_profile)\n            component = PhysicalComponent(f\"{self.OIS_XZ} {i}\", face)\n            apply_component_display_options(component, color=BLUE_PALETTE[\"TF\"][2])\n            components.append(component)\n        return components\n\n    def build_xyz(self):\n        \"\"\"\n        Build the x-y-z component of the OIS\n        \"\"\"\n        width = self.params.tf_wp_depth.value + 2 * self.params.tk_tf_side.value\n        tf_angle = 2 * np.pi / self.params.n_TF.value\n        centre_radius = 0.5 * width / np.tan(0.5 * tf_angle)\n        direction = (-np.sin(0.5 * tf_angle), np.cos(0.5 * tf_angle), 0)\n        half_plane = BluemiraPlane(base=(0, 0, 0), axis=direction)\n\n        components = []\n        for i, ois_profile in enumerate(self.ois_xz_profiles):\n            ois_profile_1 = ois_profile.deepcopy()\n            ois_profile_1.translate(vector=(0, 0.5 * width, 0))\n\n            ois_profile_2 = ois_profile_1.deepcopy()\n            ois_profile_2.rotate(\n                base=(centre_radius, 0.5 * width, 0), degree=np.rad2deg(tf_angle)\n            )\n\n            # First we make the full OIS\n            path = make_polygon(\n                [ois_profile_1.center_of_mass, ois_profile_2.center_of_mass]\n            )\n            ois_right = sweep_shape([ois_profile_1, ois_profile_2], path)\n\n            # Then we \"chop\" it in half, but without the boolean_cut operation\n            # This is because I cba to write a project_shape function...\n            ois_profile_mid = slice_shape(ois_right, half_plane)[0]\n\n            path = make_polygon(\n                [ois_profile_1.center_of_mass, ois_profile_mid.center_of_mass]\n            )\n            ois_right = sweep_shape([ois_profile_1, ois_profile_mid], path)\n            ois_left = mirror_shape(ois_right, base=(0, 0, 0), direction=(0, 1, 0))\n\n            right_component = PhysicalComponent(f\"{self.RIGHT_OIS} {i+1}\", ois_right)\n            left_component = PhysicalComponent(f\"{self.LEFT_OIS} {i+1}\", ois_left)\n            components.extend([left_component, right_component])\n\n        for component in components:\n            apply_component_display_options(component, color=BLUE_PALETTE[\"TF\"][2])\n\n        return components",
  "def __init__(\n        self,\n        params: Union[ITERGravitySupportBuilderParams, Dict],\n        build_config: Dict,\n        tf_xz_keep_out_zone: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.tf_xz_keep_out_zone = tf_xz_keep_out_zone",
  "def build(self) -> Component:\n        \"\"\"\n        Build the ITER-like gravity support component.\n        \"\"\"\n        xyz = self.build_xyz()\n        return self.component_tree([self.build_xz(xyz)], self.build_xy(), [xyz])",
  "def build_xz(self, xyz_component):\n        \"\"\"\n        Build the x-z component of the ITER-like gravity support.\n        \"\"\"\n        xz_plane = BluemiraPlane((0, 0, 0), (0, 1, 0))\n        slice_result = slice_shape(xyz_component.shape, xz_plane)\n\n        # Process UGLY SLICE\n        wires = sorted(slice_result, key=lambda wire: wire.length)\n        wire_list = [wires.pop()]\n        wire_list.extend(wires)\n        shape = BluemiraFace(wire_list)\n\n        component = PhysicalComponent(\"ITER-like gravity support\", shape)\n        apply_component_display_options(component, color=BLUE_PALETTE[\"TF\"][2])\n        return component",
  "def build_xy(self):\n        \"\"\"\n        Build the x-y component of the ITER-like gravity support.\n        \"\"\"\n        pass",
  "def _get_intersection_wire(self, width):\n        x_g_support = self.params.x_g_support.value\n        x_inner_line = x_g_support - 0.5 * width\n        x_outer_line = x_g_support + 0.5 * width\n        z_min = self.tf_xz_keep_out_zone.bounding_box.z_min\n        z_max = z_min + 0.5 * (self.tf_xz_keep_out_zone.bounding_box.z_max - z_min)\n        x_min = self.tf_xz_keep_out_zone.bounding_box.x_min + 0.5 * width\n        x_max = self.tf_xz_keep_out_zone.bounding_box.x_max - 0.5 * width\n        if (x_g_support < x_min) | (x_g_support > x_max):\n            raise BuilderError(\n                \"The gravity support footprint is not contained within the provided TF coil geometry!\"\n            )\n\n        if (self.params.z_gs.value - 6 * self.params.tf_gs_tk_plate.value) > z_min:\n            raise BuilderError(\n                \"The gravity support floor is not lower than where the TF coil is!\"\n            )\n        z_min = self.params.z_gs.value - 6 * self.params.tf_gs_tk_plate.value\n\n        cut_box = make_polygon(\n            {\n                \"x\": [x_inner_line, x_inner_line, x_outer_line, x_outer_line],\n                \"y\": 0,\n                \"z\": [z_min, z_max, z_max, z_min],\n            },\n            closed=True,\n        )\n\n        cut_result = boolean_cut(self.tf_xz_keep_out_zone, cut_box)\n\n        if cut_result is None:\n            raise BuilderError(\n                \"Boolean cutting returned nothing... check your geometry please.\"\n            )\n\n        return sorted(cut_result, key=lambda wire: wire.length)[0]",
  "def _make_connection_block(self, width, v1, v4, intersection_wire):\n        \"\"\"\n        Make the connection block of the gravity support with the TF coil\n        \"\"\"\n        z_block_lower = min(v1.z[0], v4.z[0]) - 5 * self.params.tf_gs_tk_plate.value\n        v2 = Coordinates(np.array([v1.x[0], 0, z_block_lower]))\n        v3 = Coordinates(np.array([v4.x[0], 0, z_block_lower]))\n\n        points = np.concatenate([v1.xyz, v2.xyz, v3.xyz, v4.xyz], axis=1)\n        closing_wire = make_polygon(points, closed=False)\n        face = BluemiraFace(BluemiraWire([intersection_wire, closing_wire]))\n\n        # Then extrude that face in both directions to get the connection block\n        face.translate(vector=(0, -0.5 * width, 0))\n        return extrude_shape(face, vec=(0, width, 0))",
  "def _make_plates(self, width, v1x, v4x, z_block_lower):\n        \"\"\"\n        Make the gravity support vertical plates\n        \"\"\"\n        plate_list = []\n        yz_profile = Coordinates(\n            {\n                \"x\": 4 * [v1x],\n                \"y\": [\n                    -0.5 * width,\n                    0.5 * width,\n                    0.5 * self.params.tf_gs_base_depth.value,\n                    -0.5 * self.params.tf_gs_base_depth.value,\n                ],\n                \"z\": [\n                    z_block_lower,\n                    z_block_lower,\n                    self.params.z_gs.value,\n                    self.params.z_gs.value,\n                ],\n            },\n        )\n        yz_profile = make_polygon(yz_profile, closed=True)\n\n        plating_width = v4x - v1x\n        plate_and_gap = (\n            self.params.tf_gs_g_plate.value + self.params.tf_gs_tk_plate.value\n        )\n        n_plates = int((plating_width + self.params.tf_gs_g_plate.value) / plate_and_gap)\n        total_width = (\n            n_plates * self.params.tf_gs_tk_plate.value\n            + (n_plates - 1) * self.params.tf_gs_g_plate.value\n        )\n        delta_width = plating_width - total_width\n        yz_profile.translate(vector=(0.5 * delta_width, 0, 0))\n\n        plate = extrude_shape(\n            BluemiraFace(yz_profile), vec=(self.params.tf_gs_tk_plate.value, 0, 0)\n        )\n        plate_list.append(plate)\n        for _ in range(n_plates - 1):\n            plate = plate.deepcopy()\n            plate.translate(\n                vector=(\n                    plate_and_gap,\n                    0,\n                    0,\n                )\n            )\n            plate_list.append(plate)\n        return plate_list",
  "def _make_floor_block(self, v1x, v4x):\n        xz_profile = Coordinates(\n            {\n                \"x\": [v1x, v1x, v4x, v4x],\n                \"y\": [\n                    -0.5 * self.params.tf_gs_base_depth.value,\n                    0.5 * self.params.tf_gs_base_depth.value,\n                    0.5 * self.params.tf_gs_base_depth.value,\n                    -0.5 * self.params.tf_gs_base_depth.value,\n                ],\n                \"z\": 4 * [self.params.z_gs.value],\n            },\n        )\n        xz_profile = BluemiraFace(make_polygon(xz_profile, closed=True))\n        return extrude_shape(\n            xz_profile, vec=(0, 0, -5 * self.params.tf_gs_tk_plate.value)\n        )",
  "def build_xyz(\n        self,\n    ) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y-z component of the ITER-like gravity support.\n        \"\"\"\n        shape_list = []\n        # First, project upwards at the radius of the GS into the keep-out-zone\n        # and get a x-z face of the boolean difference.\n\n        # Get the square width\n        width = self.params.tf_wp_depth.value + 2 * self.params.tk_tf_side.value\n\n        intersection_wire = self._get_intersection_wire(width)\n        v1 = intersection_wire.start_point()\n        v4 = intersection_wire.end_point()\n        if v1.x > v4.x:\n            v1, v4 = v4, v1\n\n        connection_block = self._make_connection_block(width, v1, v4, intersection_wire)\n        shape_list.append(connection_block)\n\n        # Next, make the plates in a linear pattern, in y-z, along x\n        z_block_lower = connection_block.bounding_box.z_min\n        shape_list.extend(\n            self._make_plates(width, float(v1.x), float(v4.x), z_block_lower)\n        )\n\n        # Finally, make the floor block\n        shape_list.append(self._make_floor_block(float(v1.x), float(v4.x)))\n        shape = boolean_fuse(shape_list)\n        component = PhysicalComponent(\"ITER-like gravity support\", shape)\n        apply_component_display_options(component, color=BLUE_PALETTE[\"TF\"][2])\n        return component",
  "def __init__(\n        self,\n        params: Union[PFCoilSupportBuilderParams, Dict],\n        build_config: Dict,\n        tf_xz_keep_out_zone: BluemiraWire,\n        pf_coil_xz: BluemiraWire,\n    ):\n        super().__init__(params, build_config, verbose=False)\n        self.tf_xz_keep_out_zone = tf_xz_keep_out_zone\n        self.pf_coil_xz = pf_coil_xz\n        self.name = f\"{self.name} {self.build_config.get('support_number', 0)}\"",
  "def build(self) -> Component:\n        \"\"\"\n        Build the PF coil support component.\n        \"\"\"\n        xyz = self.build_xyz()\n        return self.component_tree([self.build_xz(xyz)], self.build_xy(), [xyz])",
  "def build_xy(self):\n        \"\"\"\n        Build the x-y components of the PF coil support.\n        \"\"\"\n        pass",
  "def build_xz(self, xyz):\n        \"\"\"\n        Build the x-z components of the PF coil support.\n        \"\"\"\n        result = slice_shape(xyz.shape, BluemiraPlane(axis=(0, 1, 0)))\n        result.sort(key=lambda wire: -wire.length)\n        face = BluemiraFace(result)\n        component = PhysicalComponent(self.name, face)\n        apply_component_display_options(component, color=BLUE_PALETTE[\"TF\"][2])\n        return component",
  "def _build_support_xs(self):\n        bb = self.pf_coil_xz.bounding_box\n        width = self.params.tf_wp_depth.value + 2 * self.params.tk_tf_side.value\n        half_width = 0.5 * width\n\n        if bb.x_min < half_width:\n            raise BuilderError(\"PF coil has too small a minimum radius!\")\n\n        alpha = np.arcsin(half_width / bb.x_min)\n        inner_dr = half_width * np.tan(alpha)\n\n        beta = np.arcsin(half_width / bb.x_max)\n        outer_dr = half_width * np.tan(beta)\n\n        x_min = bb.x_min - self.params.pf_s_g.value - inner_dr\n        x_max = bb.x_max + self.params.pf_s_g.value + outer_dr\n        z_min = bb.z_min\n        z_max = bb.z_max\n        box_inner = make_polygon(\n            {\n                \"x\": [x_min, x_max, x_max, x_min],\n                \"y\": 0,\n                \"z\": [z_min, z_min, z_max, z_max],\n            },\n            closed=True,\n        )\n        box_outer = offset_wire(box_inner, self.params.pf_s_tk_plate.value)\n        face = BluemiraFace([box_outer, box_inner])\n        return face",
  "def _get_first_intersection(point, angle, wire):\n        \"\"\"\n        Get the first intersection from a point along an angle with a wire.\n        \"\"\"\n        point = np.array(point)\n        x_out = point[0] + np.cos(angle) * VERY_BIG\n        z_out = point[2] + np.sin(angle) * VERY_BIG\n        dir_point = np.array([x_out, 0, z_out])\n\n        correct_direction = dir_point - point\n        correct_direction /= np.linalg.norm(correct_direction)\n\n        plane = BluemiraPlane.from_3_points(point, dir_point, [x_out, 1, z_out])\n        intersections = slice_shape(wire, plane)\n        distances = []\n        if intersections is None:\n            return None\n\n        directed_intersections = []\n        for inter in intersections:\n            direction = inter - point\n            direction /= np.linalg.norm(direction)\n            if not np.dot(correct_direction, direction) < 0:\n                dx = inter[0] - point[0]\n                dz = inter[2] - point[2]\n\n                dist = np.hypot(dx, dz)\n                distances.append(dist)\n                directed_intersections.append(inter)\n\n        if len(directed_intersections) > 0:\n            i_min = np.argmin(distances)\n            p_inter = directed_intersections[i_min]\n            return p_inter",
  "def _get_support_point_angle(self, support_face: BluemiraFace):\n        bb = support_face.boundary[0].bounding_box\n        z_down = bb.z_min\n        z_up = bb.z_max\n\n        distance = np.inf\n        best_angle = None\n        v1, v2, v3, v4 = None, None, None, None\n        for z, sign in zip([z_up, z_down], [1, -1]):\n            for angle in [0.5 * np.pi, 2 / 3 * np.pi, 1 / 3 * np.pi]:\n                p_inters = []\n                distances = []\n                for x in [bb.x_min, bb.x_max]:\n                    point = [x, 0, z]\n                    p_inter = self._get_first_intersection(\n                        point, sign * angle, self.tf_xz_keep_out_zone\n                    )\n\n                    if p_inter is not None:\n                        d = np.hypot(point[0] - p_inter[0], point[2] - p_inter[2])\n                        p_inters.append(p_inter)\n                        distances.append(d)\n\n                if len(p_inters) == 2:\n                    avg_distance = np.average(distances)\n                    if avg_distance <= distance:\n                        distance = avg_distance\n                        v1 = np.array([bb.x_min, 0, z])\n                        v2 = np.array([bb.x_max, 0, z])\n                        v3 = p_inters[1]\n                        v4 = p_inters[0]\n                        best_angle = sign * angle\n\n        if distance == np.inf:\n            raise BuilderError(\"No intersections found!\")\n\n        return v1, v2, v3, v4, best_angle",
  "def _get_intersecting_wire(self, v1, v2, v3, v4, angle):\n        # Add some offset to get one small wire when cutting\n        v3 += 0.1 * np.array([np.cos(angle), 0, np.sin(angle)])\n        v4 += 0.1 * np.array([np.cos(angle), 0, np.sin(angle)])\n\n        cut_box = make_polygon([v1, v2, v3, v4], closed=True)\n\n        intersection_wire = sorted(\n            boolean_cut(self.tf_xz_keep_out_zone, cut_box), key=lambda wire: wire.length\n        )[0]\n        return intersection_wire",
  "def _make_rib_profile(self, support_face):\n        # Then, project sideways to find the minimum distance from a support point\n        # to the TF coil\n        v1, v2, v3, v4, angle = self._get_support_point_angle(support_face)\n\n        # Get the intersection with the TF edge wire and use this for the rib profile\n        intersection_wire = self._get_intersecting_wire(v1, v2, v3, v4, angle)\n\n        # Make the closing wire, and make sure the polygon doesn't self-intersect\n        v3 = intersection_wire.start_point().xyz.T[0]\n        v4 = intersection_wire.end_point().xyz.T[0]\n\n        inter1 = get_intersect(\n            np.array([[v1[0], v3[0]], [v1[2], v3[2]]]),\n            np.array([[v2[0], v4[0]], [v2[2], v4[2]]]),\n        )\n        if len(inter1[0]) > 0:\n            v3, v4 = v4, v3\n\n        closing_wire = make_polygon(\n            {\n                \"x\": [v3[0], v1[0], v2[0], v4[0]],\n                \"y\": 0,\n                \"z\": [v3[2], v1[2], v2[2], v4[2]],\n            },\n            closed=False,\n        )\n        rib_face = BluemiraFace(BluemiraWire([intersection_wire, closing_wire]))\n\n        # Trim rib face if there is a collision\n        result = boolean_cut(rib_face, BluemiraFace(self.tf_xz_keep_out_zone))\n\n        if result:\n            result.sort(key=lambda face: -face.area)\n            rib_face = result[0]\n\n        return rib_face",
  "def _make_ribs(self, width, support_face):\n        xz_profile = self._make_rib_profile(support_face)\n        # Calculate the rib gap width and make the ribs\n        rib_list = []\n        total_rib_tk = self.params.pf_s_n_plate.value * self.params.pf_s_tk_plate.value\n        if total_rib_tk >= width:\n            bluemira_warn(\n                \"PF coil support rib thickness and number exceed available thickness! You're getting a solid block instead\"\n            )\n            gap_size = 0\n            rib_block = extrude_shape(xz_profile, vec=(0, width, 0))\n            rib_list.append(rib_block)\n        else:\n            gap_size = (width - total_rib_tk) / (self.params.pf_s_n_plate.value - 1)\n            rib = extrude_shape(xz_profile, vec=(0, self.params.pf_s_tk_plate.value, 0))\n            rib_list.append(rib)\n            for _ in range(self.params.pf_s_n_plate.value - 1):\n                rib = rib.deepcopy()\n                rib.translate(vector=(0, self.params.pf_s_tk_plate.value + gap_size, 0))\n                rib_list.append(rib)\n        return rib_list",
  "def build_xyz(\n        self,\n    ) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y-z components of the PF coil support.\n        \"\"\"\n        shape_list = []\n        # First build the support block around the PF coil\n        support_face = self._build_support_xs()\n        # Trim support face is there is a collision\n        support_face = boolean_cut(support_face, BluemiraFace(self.tf_xz_keep_out_zone))[\n            0\n        ]\n\n        width = self.params.tf_wp_depth.value + 2 * self.params.tk_tf_side.value\n        support_block = extrude_shape(support_face, vec=(0, width, 0))\n        shape_list.append(support_block)\n\n        # Make the rib x-z profile and ribs\n        shape_list.extend(self._make_ribs(width, support_face))\n\n        try:\n            shape = boolean_fuse(shape_list)\n        except GeometryError:\n            bluemira_warn(\n                \"PFCoilSupportBuilder boolean_fuse failed, getting a BluemiraCompound instead of a BluemiraSolid, please check!\"\n            )\n            shape = BluemiraCompound(shape_list)\n\n        shape.translate(vector=(0, -0.5 * width, 0))\n        component = PhysicalComponent(self.name, shape)\n        apply_component_display_options(component, color=BLUE_PALETTE[\"TF\"][2])\n        return component",
  "def __init__(\n        self,\n        wire: BluemiraWire,\n        keep_out_zone: BluemiraFace,\n        optimiser: Optional[_DeprecatedOptimiser] = None,\n        n_koz_discr: int = 100,\n    ):\n        self.wire = wire\n        self.n_koz_discr = n_koz_discr\n        self.koz_points = (\n            keep_out_zone.boundary[0].discretize(byedges=True, ndiscr=n_koz_discr).xz.T\n        )\n        if optimiser is not None:\n            warnings.warn(\n                \"Use of StraightOISOptimisationProblem's 'optimiser' argument is \"\n                \"deprecated and it will be removed in version 2.0.0.\\n\"\n                \"See \"\n                \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n                \"optimisation.html \"\n                \"for documentation of the new optimisation module.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )",
  "def objective(self, x: np.ndarray) -> float:\n        \"\"\"Objective function to maximise length.\"\"\"\n        return self.negative_length(x)",
  "def ineq_constraints(self) -> List[ConstraintT]:\n        \"\"\"The inequality constraints for the problem.\"\"\"\n        return [\n            {\n                \"f_constraint\": self.constrain_koz,\n                \"tolerance\": np.full(self.n_koz_discr, 1e-6),\n            },\n            {\n                \"f_constraint\": self.constrain_x,\n                \"df_constraint\": self.df_constrain_x,\n                \"tolerance\": np.array([1e-6]),\n            },\n        ]",
  "def bounds(self) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"The optimisation parameter bounds.\"\"\"\n        return np.array([0, 0]), np.array([1, 1])",
  "def f_L_to_wire(wire: BluemiraWire, x_norm: List[float]):  # noqa: N802\n        \"\"\"\n        Convert a pair of normalised L values to a wire\n        \"\"\"\n        p1 = wire.value_at(x_norm[0])\n        p2 = wire.value_at(x_norm[1])\n        return make_polygon([p1, p2])",
  "def f_L_to_xz(wire: BluemiraWire, value: float) -> np.ndarray:  # noqa: N802\n        \"\"\"\n        Convert a normalised L value to an x, z pair.\n        \"\"\"\n        point = wire.value_at(value)\n        return np.array([point[0], point[2]])",
  "def negative_length(self, x_norm: np.ndarray) -> float:\n        \"\"\"\n        Calculate the negative length of the straight OIS\n\n        Parameters\n        ----------\n        x_norm:\n            Normalised solution vector\n\n        Returns\n        -------\n        Negative length from the normalised solution vector\n        \"\"\"\n        p1 = self.f_L_to_xz(self.wire, x_norm[0])\n        p2 = self.f_L_to_xz(self.wire, x_norm[1])\n        return -np.hypot(*(p2 - p1))",
  "def constrain_koz(self, x_norm: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Constrain the straight OIS to be outside a keep-out-zone\n\n        Parameters\n        ----------\n        x_norm:\n            Normalised solution vector\n\n        Returns\n        -------\n        KOZ constraint array\n        \"\"\"\n        straight_line = self.f_L_to_wire(self.wire, x_norm)\n        straight_points = straight_line.discretize(ndiscr=self.n_koz_discr).xz.T\n        return signed_distance_2D_polygon(straight_points, self.koz_points)",
  "def constrain_x(self, x_norm: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Constrain the second normalised value to be always greater than the first.\n        \"\"\"\n        return x_norm[0] - x_norm[1]",
  "def df_constrain_x(self, x_norm: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Gradient of the constraint on  the solution vector\n        \"\"\"\n        return np.array([1.0, -1.0])",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Dict,\n        tf_coil_xz_face: BluemiraFace,\n        keep_out_zones: List[BluemiraFace],\n    ):\n        super().__init__(params, build_config)\n        self.tf_face = tf_coil_xz_face\n        self.keep_out_zones = keep_out_zones",
  "def run(self) -> List[BluemiraWire]:\n        \"\"\"\n        Create and run the design optimisation problem.\n\n        Returns\n        -------\n        A list of outer inter-coil structure wires on the y=0 plane.\n        \"\"\"\n        inner_tf_wire = self.tf_face.boundary[1]\n        koz_centreline = offset_wire(\n            inner_tf_wire,\n            self.params.g_ois_tf_edge.value,\n            open_wire=False,\n            join=\"arc\",\n        )\n        ois_centreline = offset_wire(\n            inner_tf_wire,\n            2 * self.params.g_ois_tf_edge.value,\n            open_wire=False,\n            join=\"arc\",\n        )\n        ois_regions = self._make_ois_regions(ois_centreline, koz_centreline)\n        koz = self._make_ois_koz(koz_centreline)\n\n        ois_wires = []\n        for region in ois_regions:\n            opt_problem = StraightOISOptimisationProblem(region, koz)\n            result = opt_problem.optimise(\n                x0=np.array([0.0, 1.0]),\n                algorithm=\"COBYLA\",\n                opt_conditions={\"ftol_rel\": 1e-6, \"max_eval\": 1000},\n            ).x\n            p1 = region.value_at(result[0])\n            p2 = region.value_at(result[1])\n            wire = self._make_ois_wire(p1, p2)\n            ois_wires.append(wire)\n        return ois_wires",
  "def _make_ois_wire(self, p1, p2):\n        \"\"\"\n        Make a rectangular wire from the two inner edge points\n        \"\"\"\n        dx = p2[0] - p1[0]\n        dz = p2[2] - p1[2]\n        normal = np.array([dz, 0, -dx])\n        normal /= np.linalg.norm(normal)\n        tk = self.params.tk_ois.value\n        p3 = p2 + tk * normal\n        p4 = p1 + tk * normal\n        return make_polygon([p1, p2, p3, p4], closed=True)",
  "def _make_ois_koz(self, koz_centreline):\n        \"\"\"\n        Make the (fused) keep-out-zone for the outer inter-coil structures.\n        \"\"\"\n        # Note we use the same offset to the exclusion zones as for the OIS\n        # to the TF.\n        koz_wires = [\n            offset_wire(koz.boundary[0], self.params.g_ois_tf_edge.value)\n            for koz in self.keep_out_zones\n        ]\n        koz_faces = [BluemiraFace(koz) for koz in koz_wires]\n\n        return boolean_fuse([BluemiraFace(koz_centreline)] + koz_faces)",
  "def _make_ois_regions(self, ois_centreline, koz_centreline):\n        \"\"\"\n        Select regions that are viable for outer inter-coil structures\n        \"\"\"\n        inner_wire = self.tf_face.boundary[1]\n        # Drop the inboard (already connected by the vault)\n        # Note we also drop the probable worst case of the edge corners of the OIS\n        # colliding when swept.\n        x_min = inner_wire.bounding_box.x_min + np.sqrt(2) * self.params.tk_ois.value\n        z_min = self.tf_face.bounding_box.z_min - 0.1\n        z_max = self.tf_face.bounding_box.z_max + 0.1\n        inboard_cutter = BluemiraFace(\n            make_polygon(\n                {\"x\": [0, x_min, x_min, 0], \"z\": [z_min, z_min, z_max, z_max]},\n                closed=True,\n            )\n        )\n        cutter = BluemiraFace(koz_centreline)\n        cutter = boolean_fuse([cutter, inboard_cutter] + self.keep_out_zones)\n\n        ois_regions = boolean_cut(ois_centreline, cutter)\n\n        # Drop regions that are too short for OIS\n        big_ois_regions = []\n        for region in ois_regions:\n            length = np.sqrt(\n                np.sum((region.start_point().xyz - region.end_point().xyz) ** 2)\n            )\n            if length > self.params.min_OIS_length.value:\n                big_ois_regions.append(region)\n        return big_ois_regions",
  "def __init__(\n        self,\n        params: Union[OISBuilderParams, Dict],\n        build_config: Dict,\n        ois_xz_profiles: Union[BluemiraWire, List[BluemiraWire]],\n    ):\n        super().__init__(params, build_config)\n        if not isinstance(ois_xz_profiles, List):\n            ois_xz_profiles = [ois_xz_profiles]\n        self.ois_xz_profiles = ois_xz_profiles",
  "def build(self) -> Component:\n        \"\"\"\n        Build the PF coil support component.\n        \"\"\"\n        return self.component_tree(self.build_xz(), self.build_xy(), self.build_xyz())",
  "def build_xy(self):\n        \"\"\"\n        Build the x-y component of the OIS\n        \"\"\"\n        pass",
  "def build_xz(self):\n        \"\"\"\n        Build the x-z component of the OIS\n        \"\"\"\n        components = []\n        for i, ois_profile in enumerate(self.ois_xz_profiles):\n            face = BluemiraFace(ois_profile)\n            component = PhysicalComponent(f\"{self.OIS_XZ} {i}\", face)\n            apply_component_display_options(component, color=BLUE_PALETTE[\"TF\"][2])\n            components.append(component)\n        return components",
  "def build_xyz(self):\n        \"\"\"\n        Build the x-y-z component of the OIS\n        \"\"\"\n        width = self.params.tf_wp_depth.value + 2 * self.params.tk_tf_side.value\n        tf_angle = 2 * np.pi / self.params.n_TF.value\n        centre_radius = 0.5 * width / np.tan(0.5 * tf_angle)\n        direction = (-np.sin(0.5 * tf_angle), np.cos(0.5 * tf_angle), 0)\n        half_plane = BluemiraPlane(base=(0, 0, 0), axis=direction)\n\n        components = []\n        for i, ois_profile in enumerate(self.ois_xz_profiles):\n            ois_profile_1 = ois_profile.deepcopy()\n            ois_profile_1.translate(vector=(0, 0.5 * width, 0))\n\n            ois_profile_2 = ois_profile_1.deepcopy()\n            ois_profile_2.rotate(\n                base=(centre_radius, 0.5 * width, 0), degree=np.rad2deg(tf_angle)\n            )\n\n            # First we make the full OIS\n            path = make_polygon(\n                [ois_profile_1.center_of_mass, ois_profile_2.center_of_mass]\n            )\n            ois_right = sweep_shape([ois_profile_1, ois_profile_2], path)\n\n            # Then we \"chop\" it in half, but without the boolean_cut operation\n            # This is because I cba to write a project_shape function...\n            ois_profile_mid = slice_shape(ois_right, half_plane)[0]\n\n            path = make_polygon(\n                [ois_profile_1.center_of_mass, ois_profile_mid.center_of_mass]\n            )\n            ois_right = sweep_shape([ois_profile_1, ois_profile_mid], path)\n            ois_left = mirror_shape(ois_right, base=(0, 0, 0), direction=(0, 1, 0))\n\n            right_component = PhysicalComponent(f\"{self.RIGHT_OIS} {i+1}\", ois_right)\n            left_component = PhysicalComponent(f\"{self.LEFT_OIS} {i+1}\", ois_left)\n            components.extend([left_component, right_component])\n\n        for component in components:\n            apply_component_display_options(component, color=BLUE_PALETTE[\"TF\"][2])\n\n        return components",
  "class CryostatDesignerParams(ParameterFrame):\n    \"\"\"\n    Cryostat designer parameters\n    \"\"\"\n\n    g_cr_ts: Parameter[float]",
  "class CryostatBuilderParams(ParameterFrame):\n    \"\"\"\n    Cryostat builder parameters\n    \"\"\"\n\n    g_cr_ts: Parameter[float]\n    n_TF: Parameter[int]\n    tk_cr_vv: Parameter[float]\n    # TODO add to Parameter default = 5 chickens\n    well_depth: Parameter[float]\n    x_g_support: Parameter[float]\n    # TODO add to Parameter default = 2\n    x_gs_kink_diff: Parameter[float]\n    # TODO add to Parameter default (z gravity support) = -15 chickens\n    z_gs: Parameter[float]",
  "class CryostatDesigner(Designer[Tuple[float, float]]):\n    \"\"\"\n    Designer for the cryostat\n    \"\"\"\n\n    param_cls: Type[CryostatDesignerParams] = CryostatDesignerParams\n\n    def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        cryo_ts_xz: BluemiraFace,\n    ):\n        super().__init__(params)\n        self.cryo_ts_xz = cryo_ts_xz\n\n    def run(self) -> Tuple[float, float]:\n        \"\"\"\n        Cryostat designer run method\n        \"\"\"\n        bound_box = self.cryo_ts_xz.bounding_box\n        z_max = bound_box.z_max\n        x_max = bound_box.x_max\n        x_out = x_max + self.params.g_cr_ts.value\n        z_top = z_max + self.params.g_cr_ts.value\n        return x_out, z_top",
  "class CryostatBuilder(Builder):\n    \"\"\"\n    Builder for the cryostat\n    \"\"\"\n\n    CRYO = \"Cryostat VV\"\n    param_cls: Type[CryostatBuilderParams] = CryostatBuilderParams\n\n    def __init__(\n        self,\n        params: Union[ParameterFrame, Dict, None],\n        build_config: Dict,\n        x_out: float,\n        z_top: float,\n    ):\n        super().__init__(params, build_config)\n        self.x_out = x_out\n        self.z_top = z_top\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the cryostat component.\n        \"\"\"\n        xz_cryostat = self.build_xz(self.x_out, self.z_top)\n        xz_cross_section: BluemiraFace = xz_cryostat.get_component_properties(\"shape\")\n        return self.component_tree(\n            xz=[xz_cryostat],\n            xy=[self.build_xy(self.x_out)],\n            xyz=self.build_xyz(xz_cross_section, degree=0),\n        )\n\n    def build_xz(self, x_out: float, z_top: float) -> PhysicalComponent:\n        \"\"\"\n        Build the x-z components of the cryostat.\n\n        Parameters\n        ----------\n        x_out:\n            x coordinate extremity\n        z_top:\n            z coordinate extremity\n\n        Notes\n        -----\n        Only designed for an inward kink, outward kinks will fail\n        \"\"\"\n        x_in = 0\n        x_gs_kink = self.params.x_g_support.value - self.params.x_gs_kink_diff.value\n        if x_gs_kink > x_out:\n            raise ValueError(\n                \"Outward kinks not supported x_g_support-x_gs_kink_diff > x_out\"\n            )\n        z_mid = self.params.z_gs.value - self.params.g_cr_ts.value\n        z_bot = z_mid - self.params.well_depth.value\n        tk = self.params.tk_cr_vv.value\n\n        x_inner = np.array([x_in, x_out, x_out, x_gs_kink, x_gs_kink, x_in])\n        z_inner = np.array([z_top, z_top, z_mid, z_mid, z_bot, z_bot])\n\n        x_outer = np.array([x_in, x_gs_kink, x_gs_kink, x_out, x_out, x_in])\n        x_outer[1:-1] += tk\n\n        z_outer = np.array([z_bot, z_bot, z_mid, z_mid, z_top, z_top])\n        z_outer[:4] -= tk\n        z_outer[4:] += tk\n\n        x = np.concatenate([x_inner, x_outer])\n        z = np.concatenate([z_inner, z_outer])\n\n        cryostat_vv = PhysicalComponent(\n            self.CRYO, BluemiraFace(make_polygon({\"x\": x, \"y\": 0, \"z\": z}, closed=True))\n        )\n        apply_component_display_options(cryostat_vv, color=BLUE_PALETTE[\"CR\"][0])\n        return cryostat_vv\n\n    def build_xy(self, x_out: float) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y components of the cryostat.\n\n        Parameters\n        ----------\n        x_out:\n            x coordinate extremity\n        \"\"\"\n        cryostat_vv = PhysicalComponent(\n            self.CRYO, make_circular_xy_ring(x_out, x_out + self.params.tk_cr_vv.value)\n        )\n        apply_component_display_options(cryostat_vv, color=BLUE_PALETTE[\"CR\"][0])\n        return cryostat_vv\n\n    def build_xyz(\n        self, xz_cross_section: BluemiraFace, degree=360\n    ) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y-z components of the cryostat.\n\n        Parameters\n        ----------\n        xz_cross_section:\n            xz cross section of cryostat\n        degree:\n            Revolution degree\n        \"\"\"\n        return build_sectioned_xyz(\n            xz_cross_section,\n            self.CRYO,\n            self.params.n_TF.value,\n            BLUE_PALETTE[\"CR\"][0],\n            degree,\n        )",
  "def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        cryo_ts_xz: BluemiraFace,\n    ):\n        super().__init__(params)\n        self.cryo_ts_xz = cryo_ts_xz",
  "def run(self) -> Tuple[float, float]:\n        \"\"\"\n        Cryostat designer run method\n        \"\"\"\n        bound_box = self.cryo_ts_xz.bounding_box\n        z_max = bound_box.z_max\n        x_max = bound_box.x_max\n        x_out = x_max + self.params.g_cr_ts.value\n        z_top = z_max + self.params.g_cr_ts.value\n        return x_out, z_top",
  "def __init__(\n        self,\n        params: Union[ParameterFrame, Dict, None],\n        build_config: Dict,\n        x_out: float,\n        z_top: float,\n    ):\n        super().__init__(params, build_config)\n        self.x_out = x_out\n        self.z_top = z_top",
  "def build(self) -> Component:\n        \"\"\"\n        Build the cryostat component.\n        \"\"\"\n        xz_cryostat = self.build_xz(self.x_out, self.z_top)\n        xz_cross_section: BluemiraFace = xz_cryostat.get_component_properties(\"shape\")\n        return self.component_tree(\n            xz=[xz_cryostat],\n            xy=[self.build_xy(self.x_out)],\n            xyz=self.build_xyz(xz_cross_section, degree=0),\n        )",
  "def build_xz(self, x_out: float, z_top: float) -> PhysicalComponent:\n        \"\"\"\n        Build the x-z components of the cryostat.\n\n        Parameters\n        ----------\n        x_out:\n            x coordinate extremity\n        z_top:\n            z coordinate extremity\n\n        Notes\n        -----\n        Only designed for an inward kink, outward kinks will fail\n        \"\"\"\n        x_in = 0\n        x_gs_kink = self.params.x_g_support.value - self.params.x_gs_kink_diff.value\n        if x_gs_kink > x_out:\n            raise ValueError(\n                \"Outward kinks not supported x_g_support-x_gs_kink_diff > x_out\"\n            )\n        z_mid = self.params.z_gs.value - self.params.g_cr_ts.value\n        z_bot = z_mid - self.params.well_depth.value\n        tk = self.params.tk_cr_vv.value\n\n        x_inner = np.array([x_in, x_out, x_out, x_gs_kink, x_gs_kink, x_in])\n        z_inner = np.array([z_top, z_top, z_mid, z_mid, z_bot, z_bot])\n\n        x_outer = np.array([x_in, x_gs_kink, x_gs_kink, x_out, x_out, x_in])\n        x_outer[1:-1] += tk\n\n        z_outer = np.array([z_bot, z_bot, z_mid, z_mid, z_top, z_top])\n        z_outer[:4] -= tk\n        z_outer[4:] += tk\n\n        x = np.concatenate([x_inner, x_outer])\n        z = np.concatenate([z_inner, z_outer])\n\n        cryostat_vv = PhysicalComponent(\n            self.CRYO, BluemiraFace(make_polygon({\"x\": x, \"y\": 0, \"z\": z}, closed=True))\n        )\n        apply_component_display_options(cryostat_vv, color=BLUE_PALETTE[\"CR\"][0])\n        return cryostat_vv",
  "def build_xy(self, x_out: float) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y components of the cryostat.\n\n        Parameters\n        ----------\n        x_out:\n            x coordinate extremity\n        \"\"\"\n        cryostat_vv = PhysicalComponent(\n            self.CRYO, make_circular_xy_ring(x_out, x_out + self.params.tk_cr_vv.value)\n        )\n        apply_component_display_options(cryostat_vv, color=BLUE_PALETTE[\"CR\"][0])\n        return cryostat_vv",
  "def build_xyz(\n        self, xz_cross_section: BluemiraFace, degree=360\n    ) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y-z components of the cryostat.\n\n        Parameters\n        ----------\n        xz_cross_section:\n            xz cross section of cryostat\n        degree:\n            Revolution degree\n        \"\"\"\n        return build_sectioned_xyz(\n            xz_cross_section,\n            self.CRYO,\n            self.params.n_TF.value,\n            BLUE_PALETTE[\"CR\"][0],\n            degree,\n        )",
  "class RadiationShieldBuilderParams(ParameterFrame):\n    \"\"\"\n    Radiation Shield builder parameters\n    \"\"\"\n\n    n_TF: Parameter[int]\n    tk_rs: Parameter[float]\n    g_cr_rs: Parameter[float]",
  "class RadiationShieldBuilder(Builder):\n    \"\"\"\n    Radiation Shield builder\n    \"\"\"\n\n    RS = \"RS\"\n    BODY = \"Body\"\n    param_cls: Type[RadiationShieldBuilderParams] = RadiationShieldBuilderParams\n\n    def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        cryo_vv: BluemiraFace,\n    ):\n        super().__init__(params, build_config)\n        self.cryo_vv = cryo_vv\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the radiation shield component.\n        \"\"\"\n        rs_xz = self.build_xz()\n        rs_face = rs_xz.get_component_properties(\"shape\")\n\n        return self.component_tree(\n            xz=[rs_xz],\n            xy=[self.build_xy()],\n            xyz=self.build_xyz(rs_face, degree=0),\n        )\n\n    def build_xz(self) -> PhysicalComponent:\n        \"\"\"\n        Build the x-z components of the radiation shield.\n        \"\"\"\n        cryo_vv_rot = self.cryo_vv.deepcopy()\n        cryo_vv_rot.rotate(base=(0, 0, 0), direction=(0, 0, 1), degree=180)\n\n        rs_inner = offset_wire(\n            boolean_fuse([self.cryo_vv, cryo_vv_rot]).boundary[0],\n            self.params.g_cr_rs.value,\n        )\n        rs_outer = offset_wire(rs_inner, self.params.tk_rs.value)\n\n        # Now we slice in half\n        bound_box = rs_outer.bounding_box\n\n        x = np.zeros(4)\n        x[2:] = bound_box.x_min - 1.0\n\n        z = np.zeros(4)\n        z[[0, -1]] = bound_box.z_min - 1.0\n        z[[1, 2]] = bound_box.z_max + 1.0\n\n        cutter = BluemiraFace(make_polygon({\"x\": x, \"y\": 0, \"z\": z}, closed=True))\n\n        shield_body = PhysicalComponent(\n            self.BODY, boolean_cut(BluemiraFace([rs_outer, rs_inner]), cutter)[0]\n        )\n        apply_component_display_options(shield_body, color=BLUE_PALETTE[self.RS][0])\n        return shield_body\n\n    def build_xy(self) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y components of the radiation shield.\n        \"\"\"\n        r_in = self.cryo_vv.bounding_box.x_max + self.params.g_cr_rs.value\n        r_out = r_in + self.params.tk_rs.value\n\n        shield_body = PhysicalComponent(self.BODY, make_circular_xy_ring(r_in, r_out))\n        apply_component_display_options(shield_body, color=BLUE_PALETTE[self.RS][0])\n\n        return shield_body\n\n    def build_xyz(\n        self, rs_face: BluemiraFace, degree: float = 360.0\n    ) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y-z components of the radiation shield.\n        \"\"\"\n        return build_sectioned_xyz(\n            rs_face,\n            self.BODY,\n            self.params.n_TF.value,\n            BLUE_PALETTE[self.RS][0],\n            degree,\n        )",
  "def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        cryo_vv: BluemiraFace,\n    ):\n        super().__init__(params, build_config)\n        self.cryo_vv = cryo_vv",
  "def build(self) -> Component:\n        \"\"\"\n        Build the radiation shield component.\n        \"\"\"\n        rs_xz = self.build_xz()\n        rs_face = rs_xz.get_component_properties(\"shape\")\n\n        return self.component_tree(\n            xz=[rs_xz],\n            xy=[self.build_xy()],\n            xyz=self.build_xyz(rs_face, degree=0),\n        )",
  "def build_xz(self) -> PhysicalComponent:\n        \"\"\"\n        Build the x-z components of the radiation shield.\n        \"\"\"\n        cryo_vv_rot = self.cryo_vv.deepcopy()\n        cryo_vv_rot.rotate(base=(0, 0, 0), direction=(0, 0, 1), degree=180)\n\n        rs_inner = offset_wire(\n            boolean_fuse([self.cryo_vv, cryo_vv_rot]).boundary[0],\n            self.params.g_cr_rs.value,\n        )\n        rs_outer = offset_wire(rs_inner, self.params.tk_rs.value)\n\n        # Now we slice in half\n        bound_box = rs_outer.bounding_box\n\n        x = np.zeros(4)\n        x[2:] = bound_box.x_min - 1.0\n\n        z = np.zeros(4)\n        z[[0, -1]] = bound_box.z_min - 1.0\n        z[[1, 2]] = bound_box.z_max + 1.0\n\n        cutter = BluemiraFace(make_polygon({\"x\": x, \"y\": 0, \"z\": z}, closed=True))\n\n        shield_body = PhysicalComponent(\n            self.BODY, boolean_cut(BluemiraFace([rs_outer, rs_inner]), cutter)[0]\n        )\n        apply_component_display_options(shield_body, color=BLUE_PALETTE[self.RS][0])\n        return shield_body",
  "def build_xy(self) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y components of the radiation shield.\n        \"\"\"\n        r_in = self.cryo_vv.bounding_box.x_max + self.params.g_cr_rs.value\n        r_out = r_in + self.params.tk_rs.value\n\n        shield_body = PhysicalComponent(self.BODY, make_circular_xy_ring(r_in, r_out))\n        apply_component_display_options(shield_body, color=BLUE_PALETTE[self.RS][0])\n\n        return shield_body",
  "def build_xyz(\n        self, rs_face: BluemiraFace, degree: float = 360.0\n    ) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y-z components of the radiation shield.\n        \"\"\"\n        return build_sectioned_xyz(\n            rs_face,\n            self.BODY,\n            self.params.n_TF.value,\n            BLUE_PALETTE[self.RS][0],\n            degree,\n        )",
  "class DivertorBuilderParams(ParameterFrame):\n    \"\"\"\n    Divertor builder parameters\n    \"\"\"\n\n    n_TF: Parameter[int]\n    n_div_cassettes: Parameter[int]\n    c_rm: Parameter[float]",
  "class DivertorBuilder(Builder):\n    \"\"\"\n    Divertor builder\n    \"\"\"\n\n    DIV = \"DIV\"\n    BODY = \"Body\"\n    CASETTES = \"cassettes\"\n    SEGMENT_PREFIX = \"segment\"\n    param_cls: Type[DivertorBuilderParams] = DivertorBuilderParams\n\n    def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        divertor_silhouette: BluemiraFace,\n    ):\n        super().__init__(params, build_config)\n        self.div_koz = divertor_silhouette\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the divertor component.\n        \"\"\"\n        return self.component_tree(\n            xz=[self.build_xz()],\n            xy=[],\n            xyz=self.build_xyz(degree=0),\n        )\n\n    def build_xz(self) -> PhysicalComponent:\n        \"\"\"\n        Build the x-z components of the divertor.\n        \"\"\"\n        body = PhysicalComponent(self.BODY, self.div_koz)\n        apply_component_display_options(body, color=BLUE_PALETTE[self.DIV][0])\n\n        return body\n\n    def build_xyz(self, degree: float = 360.0) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y-z components of the divertor.\n        \"\"\"\n        sector_degree, n_sectors = get_n_sectors(self.params.n_TF.value, degree)\n        shapes = pattern_revolved_silhouette(\n            self.div_koz,\n            self.params.n_div_cassettes.value,\n            self.params.n_TF.value,\n            self.params.c_rm.value,\n        )\n\n        segments = []\n        for no, shape in enumerate(shapes):\n            segment = PhysicalComponent(f\"{self.SEGMENT_PREFIX}_{no}\", shape)\n            apply_component_display_options(segment, BLUE_PALETTE[self.DIV][no])\n            segments.append(segment)\n\n        return circular_pattern_component(\n            Component(self.CASETTES, children=segments),\n            n_sectors,\n            degree=sector_degree * n_sectors,\n        )",
  "def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        divertor_silhouette: BluemiraFace,\n    ):\n        super().__init__(params, build_config)\n        self.div_koz = divertor_silhouette",
  "def build(self) -> Component:\n        \"\"\"\n        Build the divertor component.\n        \"\"\"\n        return self.component_tree(\n            xz=[self.build_xz()],\n            xy=[],\n            xyz=self.build_xyz(degree=0),\n        )",
  "def build_xz(self) -> PhysicalComponent:\n        \"\"\"\n        Build the x-z components of the divertor.\n        \"\"\"\n        body = PhysicalComponent(self.BODY, self.div_koz)\n        apply_component_display_options(body, color=BLUE_PALETTE[self.DIV][0])\n\n        return body",
  "def build_xyz(self, degree: float = 360.0) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y-z components of the divertor.\n        \"\"\"\n        sector_degree, n_sectors = get_n_sectors(self.params.n_TF.value, degree)\n        shapes = pattern_revolved_silhouette(\n            self.div_koz,\n            self.params.n_div_cassettes.value,\n            self.params.n_TF.value,\n            self.params.c_rm.value,\n        )\n\n        segments = []\n        for no, shape in enumerate(shapes):\n            segment = PhysicalComponent(f\"{self.SEGMENT_PREFIX}_{no}\", shape)\n            apply_component_display_options(segment, BLUE_PALETTE[self.DIV][no])\n            segments.append(segment)\n\n        return circular_pattern_component(\n            Component(self.CASETTES, children=segments),\n            n_sectors,\n            degree=sector_degree * n_sectors,\n        )",
  "class PFCoilBuilderParams(ParameterFrame):\n    \"\"\"\n    Parameters for the `PFCoilBuilder` class.\n    \"\"\"\n\n    n_TF: Parameter[int]\n\n    tk_insulation: Parameter[float]\n    tk_casing: Parameter[float]\n    ctype: Parameter[str]",
  "class PFCoilBuilder(Builder):\n    \"\"\"\n    Builder for a single PF coil.\n    \"\"\"\n\n    CASING = \"Casing\"\n    GROUND_INSULATION = \"Ground Insulation\"\n    INNER = \"Inner\"\n    OUTER_INS = \"Outer Ins\"\n    WINDING_PACK = \"Winding Pack\"\n\n    param_cls = PFCoilBuilderParams\n\n    def __init__(\n        self,\n        params: Union[PFCoilBuilderParams, Dict],\n        build_config: Dict,\n        xz_cross_section: BluemiraWire,\n    ):\n        super().__init__(params, build_config, verbose=False)\n        self.xz_cross_section = xz_cross_section\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the PFCoil component.\n        \"\"\"\n        return self.component_tree(\n            xz=self.build_xz(self.xz_cross_section),\n            xy=self.build_xy(self.xz_cross_section),\n            xyz=self.build_xyz(self.xz_cross_section, degree=0),\n        )\n\n    def build_xy(self, shape: BluemiraWire) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the xy cross-section of the PF coil.\n        \"\"\"\n        r_in = shape.bounding_box.x_min\n        r_out = shape.bounding_box.x_max\n        c1 = make_circle(r_out)\n        c2 = make_circle(r_in)\n\n        wp = PhysicalComponent(self.WINDING_PACK, BluemiraFace([c1, c2]))\n        idx = 0 if self.params.ctype.value == \"CS\" else 1\n        apply_component_display_options(wp, color=BLUE_PALETTE[\"PF\"][idx])\n\n        r_in -= self.params.tk_insulation.value\n        c3 = make_circle(r_in)\n        inner_ins = PhysicalComponent(self.INNER, BluemiraFace([c2, c3]))\n        apply_component_display_options(inner_ins, color=BLUE_PALETTE[\"PF\"][3])\n\n        r_out += self.params.tk_insulation.value\n        c4 = make_circle(r_out)\n        outer_ins = PhysicalComponent(self.OUTER_INS, BluemiraFace([c4, c1]))\n        apply_component_display_options(outer_ins, color=BLUE_PALETTE[\"PF\"][3])\n\n        ins = Component(name=self.GROUND_INSULATION, children=[inner_ins, outer_ins])\n\n        r_in -= self.params.tk_casing.value\n        c5 = make_circle(r_in)\n        inner_cas = PhysicalComponent(self.INNER, BluemiraFace([c3, c5]))\n        apply_component_display_options(inner_cas, color=BLUE_PALETTE[\"PF\"][2])\n\n        r_out += self.params.tk_casing.value\n        c6 = make_circle(r_out)\n        outer_cas = PhysicalComponent(self.OUTER_INS, BluemiraFace([c6, c4]))\n        apply_component_display_options(outer_cas, color=BLUE_PALETTE[\"PF\"][2])\n\n        casing = Component(self.CASING, children=[inner_cas, outer_cas])\n\n        return [wp, ins, casing]\n\n    def build_xz(self, shape: BluemiraWire) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the xz cross-section of the PF coil.\n        \"\"\"\n        wp = PhysicalComponent(self.WINDING_PACK, BluemiraFace(shape))\n        idx = 0 if self.params.ctype.value == \"CS\" else 1\n        apply_component_display_options(wp, color=BLUE_PALETTE[\"PF\"][idx])\n\n        ins_shape = offset_wire(shape, self.params.tk_insulation.value)\n        ins = PhysicalComponent(self.GROUND_INSULATION, BluemiraFace([ins_shape, shape]))\n        apply_component_display_options(ins, color=BLUE_PALETTE[\"PF\"][3])\n\n        cas_shape = offset_wire(ins_shape, self.params.tk_casing.value)\n        casing = PhysicalComponent(self.CASING, BluemiraFace([cas_shape, ins_shape]))\n        apply_component_display_options(casing, color=BLUE_PALETTE[\"PF\"][2])\n        return [wp, ins, casing]\n\n    def build_xyz(\n        self,\n        shape: BluemiraWire,\n        degree: float = 360.0,\n    ) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the xyz representation of the PF coil.\n\n        Parameters\n        ----------\n        shape:\n            The xz cross-section shape of the coil.\n        degree:\n            The angle [\u00b0] around which to build the components, by default 360.0.\n\n        Returns\n        -------\n        The component grouping the results in 3D (xyz).\n        \"\"\"\n        sector_degree, n_sectors = get_n_sectors(self.params.n_TF.value, degree)\n\n        # I doubt this is floating-point safe to collisions...\n        xz_components = self.build_xz(shape)\n        components = []\n        for c in xz_components:\n            shape = revolve_shape(c.shape, degree=sector_degree * n_sectors)\n            c_xyz = PhysicalComponent(c.name, shape)\n            apply_component_display_options(\n                c_xyz, color=c.plot_options.face_options[\"color\"]\n            )\n            components.append(c_xyz)\n\n        return components",
  "class PFCoilPictureFrameParams(ParameterFrame):\n    \"\"\"\n    Parameters for the `PFCoilPictureFrame` designer.\n    \"\"\"\n\n    r_corner: Parameter[float]",
  "class PFCoilPictureFrame(Designer):\n    \"\"\"\n    Designer for the shape of a PF coil in the xz plane using a\n    PictureFrame parameterisation.\n    \"\"\"\n\n    param_cls = PFCoilPictureFrameParams\n\n    def __init__(self, params: Union[PFCoilPictureFrameParams, Dict], coil: Coil):\n        super().__init__(params, verbose=False)\n        self.coil = coil\n\n    def run(self) -> BluemiraWire:\n        \"\"\"\n        Run the design step, outputting the PictureFrame shape as a wire.\n        \"\"\"\n        x_in = self.coil.x - self.coil.dx\n        x_out = self.coil.x + self.coil.dx\n        z_up = self.coil.z + self.coil.dz\n        z_down = self.coil.z - self.coil.dz\n        return PictureFrame(\n            {\n                \"x1\": {\"value\": x_in, \"fixed\": True},\n                \"x2\": {\"value\": x_out, \"fixed\": True},\n                \"z1\": {\"value\": z_up, \"fixed\": True},\n                \"z2\": {\"value\": z_down, \"fixed\": True},\n                \"ri\": {\"value\": self.params.r_corner.value, \"fixed\": True},\n                \"ro\": {\"value\": self.params.r_corner.value, \"fixed\": True},\n            }\n        ).create_shape()",
  "def __init__(\n        self,\n        params: Union[PFCoilBuilderParams, Dict],\n        build_config: Dict,\n        xz_cross_section: BluemiraWire,\n    ):\n        super().__init__(params, build_config, verbose=False)\n        self.xz_cross_section = xz_cross_section",
  "def build(self) -> Component:\n        \"\"\"\n        Build the PFCoil component.\n        \"\"\"\n        return self.component_tree(\n            xz=self.build_xz(self.xz_cross_section),\n            xy=self.build_xy(self.xz_cross_section),\n            xyz=self.build_xyz(self.xz_cross_section, degree=0),\n        )",
  "def build_xy(self, shape: BluemiraWire) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the xy cross-section of the PF coil.\n        \"\"\"\n        r_in = shape.bounding_box.x_min\n        r_out = shape.bounding_box.x_max\n        c1 = make_circle(r_out)\n        c2 = make_circle(r_in)\n\n        wp = PhysicalComponent(self.WINDING_PACK, BluemiraFace([c1, c2]))\n        idx = 0 if self.params.ctype.value == \"CS\" else 1\n        apply_component_display_options(wp, color=BLUE_PALETTE[\"PF\"][idx])\n\n        r_in -= self.params.tk_insulation.value\n        c3 = make_circle(r_in)\n        inner_ins = PhysicalComponent(self.INNER, BluemiraFace([c2, c3]))\n        apply_component_display_options(inner_ins, color=BLUE_PALETTE[\"PF\"][3])\n\n        r_out += self.params.tk_insulation.value\n        c4 = make_circle(r_out)\n        outer_ins = PhysicalComponent(self.OUTER_INS, BluemiraFace([c4, c1]))\n        apply_component_display_options(outer_ins, color=BLUE_PALETTE[\"PF\"][3])\n\n        ins = Component(name=self.GROUND_INSULATION, children=[inner_ins, outer_ins])\n\n        r_in -= self.params.tk_casing.value\n        c5 = make_circle(r_in)\n        inner_cas = PhysicalComponent(self.INNER, BluemiraFace([c3, c5]))\n        apply_component_display_options(inner_cas, color=BLUE_PALETTE[\"PF\"][2])\n\n        r_out += self.params.tk_casing.value\n        c6 = make_circle(r_out)\n        outer_cas = PhysicalComponent(self.OUTER_INS, BluemiraFace([c6, c4]))\n        apply_component_display_options(outer_cas, color=BLUE_PALETTE[\"PF\"][2])\n\n        casing = Component(self.CASING, children=[inner_cas, outer_cas])\n\n        return [wp, ins, casing]",
  "def build_xz(self, shape: BluemiraWire) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the xz cross-section of the PF coil.\n        \"\"\"\n        wp = PhysicalComponent(self.WINDING_PACK, BluemiraFace(shape))\n        idx = 0 if self.params.ctype.value == \"CS\" else 1\n        apply_component_display_options(wp, color=BLUE_PALETTE[\"PF\"][idx])\n\n        ins_shape = offset_wire(shape, self.params.tk_insulation.value)\n        ins = PhysicalComponent(self.GROUND_INSULATION, BluemiraFace([ins_shape, shape]))\n        apply_component_display_options(ins, color=BLUE_PALETTE[\"PF\"][3])\n\n        cas_shape = offset_wire(ins_shape, self.params.tk_casing.value)\n        casing = PhysicalComponent(self.CASING, BluemiraFace([cas_shape, ins_shape]))\n        apply_component_display_options(casing, color=BLUE_PALETTE[\"PF\"][2])\n        return [wp, ins, casing]",
  "def build_xyz(\n        self,\n        shape: BluemiraWire,\n        degree: float = 360.0,\n    ) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the xyz representation of the PF coil.\n\n        Parameters\n        ----------\n        shape:\n            The xz cross-section shape of the coil.\n        degree:\n            The angle [\u00b0] around which to build the components, by default 360.0.\n\n        Returns\n        -------\n        The component grouping the results in 3D (xyz).\n        \"\"\"\n        sector_degree, n_sectors = get_n_sectors(self.params.n_TF.value, degree)\n\n        # I doubt this is floating-point safe to collisions...\n        xz_components = self.build_xz(shape)\n        components = []\n        for c in xz_components:\n            shape = revolve_shape(c.shape, degree=sector_degree * n_sectors)\n            c_xyz = PhysicalComponent(c.name, shape)\n            apply_component_display_options(\n                c_xyz, color=c.plot_options.face_options[\"color\"]\n            )\n            components.append(c_xyz)\n\n        return components",
  "def __init__(self, params: Union[PFCoilPictureFrameParams, Dict], coil: Coil):\n        super().__init__(params, verbose=False)\n        self.coil = coil",
  "def run(self) -> BluemiraWire:\n        \"\"\"\n        Run the design step, outputting the PictureFrame shape as a wire.\n        \"\"\"\n        x_in = self.coil.x - self.coil.dx\n        x_out = self.coil.x + self.coil.dx\n        z_up = self.coil.z + self.coil.dz\n        z_down = self.coil.z - self.coil.dz\n        return PictureFrame(\n            {\n                \"x1\": {\"value\": x_in, \"fixed\": True},\n                \"x2\": {\"value\": x_out, \"fixed\": True},\n                \"z1\": {\"value\": z_up, \"fixed\": True},\n                \"z2\": {\"value\": z_down, \"fixed\": True},\n                \"ri\": {\"value\": self.params.r_corner.value, \"fixed\": True},\n                \"ro\": {\"value\": self.params.r_corner.value, \"fixed\": True},\n            }\n        ).create_shape()",
  "class Plasma(ComponentManager):\n    \"\"\"\n    Wrapper around a plasma component tree.\n    \"\"\"\n\n    def lcfs(self) -> BluemiraWire:\n        \"\"\"Return a wire representing the last-closed flux surface.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(PlasmaBuilder.LCFS)\n            .shape.boundary[0]\n        )",
  "class PlasmaBuilderParams(ParameterFrame):\n    \"\"\"\n    Plasma builder parameters\n    \"\"\"\n\n    n_TF: Parameter[int]",
  "class PlasmaBuilder(Builder):\n    \"\"\"\n    Builder for a poloidally symmetric plasma.\n    \"\"\"\n\n    LCFS = \"LCFS\"\n\n    param_cls: Type[PlasmaBuilderParams] = PlasmaBuilderParams\n\n    def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        xz_lcfs: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.xz_lcfs = xz_lcfs\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the plasma component.\n        \"\"\"\n        return self.component_tree(\n            xz=[self.build_xz(self.xz_lcfs)],\n            xy=[self.build_xy(self.xz_lcfs)],\n            xyz=[self.build_xyz(self.xz_lcfs, degree=0)],\n        )\n\n    def build_xz(self, lcfs: BluemiraWire) -> PhysicalComponent:\n        \"\"\"\n        Build the x-z components of the plasma.\n\n        Parameters\n        ----------\n        lcfs:\n            LCFS wire\n        \"\"\"\n        face = BluemiraFace(lcfs, self.name)\n        component = PhysicalComponent(self.LCFS, face)\n        apply_component_display_options(\n            component, color=BLUE_PALETTE[\"PL\"], transparency=0.3\n        )\n        return component\n\n    def build_xy(self, lcfs: BluemiraWire) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y components of the plasma.\n\n        Parameters\n        ----------\n        lcfs:\n            LCFS wire\n        \"\"\"\n        inner = make_circle(lcfs.bounding_box.x_min)\n        outer = make_circle(lcfs.bounding_box.x_max)\n        face = BluemiraFace([outer, inner], self.name)\n        component = PhysicalComponent(self.LCFS, face)\n        apply_component_display_options(\n            component, color=BLUE_PALETTE[\"PL\"], transparency=0.3\n        )\n        return component\n\n    def build_xyz(self, lcfs: BluemiraWire, degree: float = 360.0) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y-z components of the plasma.\n\n        Parameters\n        ----------\n        lcfs:\n            LCFS wire\n        degree:\n            degrees to sweep the shape\n        \"\"\"\n        sector_degree, n_sectors = get_n_sectors(self.params.n_TF.value, degree)\n\n        solid = revolve_shape(\n            BluemiraFace(lcfs),\n            direction=(0, 0, 1),\n            degree=sector_degree * n_sectors,\n            label=self.LCFS,\n        )\n        component = PhysicalComponent(self.LCFS, solid)\n        apply_component_display_options(\n            component, color=BLUE_PALETTE[\"PL\"], transparency=0.3\n        )\n        return component",
  "def lcfs(self) -> BluemiraWire:\n        \"\"\"Return a wire representing the last-closed flux surface.\"\"\"\n        return (\n            self.component()\n            .get_component(\"xz\")\n            .get_component(PlasmaBuilder.LCFS)\n            .shape.boundary[0]\n        )",
  "def __init__(\n        self,\n        params: Union[ParameterFrame, Dict],\n        build_config: Dict,\n        xz_lcfs: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.xz_lcfs = xz_lcfs",
  "def build(self) -> Component:\n        \"\"\"\n        Build the plasma component.\n        \"\"\"\n        return self.component_tree(\n            xz=[self.build_xz(self.xz_lcfs)],\n            xy=[self.build_xy(self.xz_lcfs)],\n            xyz=[self.build_xyz(self.xz_lcfs, degree=0)],\n        )",
  "def build_xz(self, lcfs: BluemiraWire) -> PhysicalComponent:\n        \"\"\"\n        Build the x-z components of the plasma.\n\n        Parameters\n        ----------\n        lcfs:\n            LCFS wire\n        \"\"\"\n        face = BluemiraFace(lcfs, self.name)\n        component = PhysicalComponent(self.LCFS, face)\n        apply_component_display_options(\n            component, color=BLUE_PALETTE[\"PL\"], transparency=0.3\n        )\n        return component",
  "def build_xy(self, lcfs: BluemiraWire) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y components of the plasma.\n\n        Parameters\n        ----------\n        lcfs:\n            LCFS wire\n        \"\"\"\n        inner = make_circle(lcfs.bounding_box.x_min)\n        outer = make_circle(lcfs.bounding_box.x_max)\n        face = BluemiraFace([outer, inner], self.name)\n        component = PhysicalComponent(self.LCFS, face)\n        apply_component_display_options(\n            component, color=BLUE_PALETTE[\"PL\"], transparency=0.3\n        )\n        return component",
  "def build_xyz(self, lcfs: BluemiraWire, degree: float = 360.0) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y-z components of the plasma.\n\n        Parameters\n        ----------\n        lcfs:\n            LCFS wire\n        degree:\n            degrees to sweep the shape\n        \"\"\"\n        sector_degree, n_sectors = get_n_sectors(self.params.n_TF.value, degree)\n\n        solid = revolve_shape(\n            BluemiraFace(lcfs),\n            direction=(0, 0, 1),\n            degree=sector_degree * n_sectors,\n            label=self.LCFS,\n        )\n        component = PhysicalComponent(self.LCFS, solid)\n        apply_component_display_options(\n            component, color=BLUE_PALETTE[\"PL\"], transparency=0.3\n        )\n        return component",
  "class ParameterisedRippleSolver:\n    \"\"\"\n    A parameterised Biot-Savart HelmholtzCage solver.\n\n    Parameters\n    ----------\n    wp_xs:\n        Geometry of the TF coil winding pack cross-section\n    nx:\n        Number of radial Biot-Savart filaments to use\n    ny:\n        Number of toroidal Biot-Savart filaments to use\n    n_TF:\n        Number of TF coils\n    R_0:\n        Major radius at which to calculate B_0\n    z_0:\n        Vertical coordinate at which to calculate B_0\n    B_0:\n        Toroidal field at (R_0, z_0)\n    \"\"\"\n\n    def __init__(\n        self,\n        wp_xs: BluemiraWire,\n        nx: int,\n        ny: int,\n        n_TF: int,\n        R_0: float,\n        z_0: float,\n        B_0: float,\n    ):\n        self.wp_xs = wp_xs\n        self.nx = nx\n        self.ny = ny\n        self.n_TF = n_TF\n        self.R_0 = R_0\n        self.z_0 = z_0\n        self.B_0 = B_0\n        self.cage = None\n\n    def update_cage(self, wire: BluemiraWire):\n        \"\"\"\n        Update the HelmHoltzCage, setting the current to produce a field of B_0 at\n        (R_0, z_0).\n\n        Parameters\n        ----------\n        wire:\n            TF coil winding pack current centreline\n        \"\"\"\n        circuit = self._make_single_circuit(wire)\n        self.cage = HelmholtzCage(circuit, self.n_TF)\n        field = self.cage.field(self.R_0, 0, self.z_0)\n        current = -self.B_0 / field[1]  # single coil amp-turns\n        current /= self.nx * self.ny  # single filament amp-turns\n        self.cage.set_current(current)\n\n    def _make_single_circuit(self, wire: BluemiraWire) -> BiotSavartFilament:\n        \"\"\"\n        Make a single BioSavart Filament for a single TF coil\n        \"\"\"\n        bb = self.wp_xs.bounding_box\n        dx_xs = 0.5 * (bb.x_max - bb.x_min)\n        dy_xs = 0.5 * (bb.y_max - bb.y_min)\n\n        dx_wp, dy_wp = [0], [0]  # default to coil centreline\n        if self.nx > 1:\n            dx_wp = np.linspace(\n                dx_xs * (1 / self.nx - 1), dx_xs * (1 - 1 / self.nx), self.nx\n            )\n\n        if self.ny > 1:\n            dy_wp = np.linspace(\n                dy_xs * (1 / self.ny - 1), dy_xs * (1 - 1 / self.ny), self.ny\n            )\n\n        current_wires = []\n        for dx in dx_wp:\n            c_wire = offset_wire(wire, dx)\n            for dy in dy_wp:\n                c_w = deepcopy(c_wire)\n                c_w.translate((0, dy, 0))\n                current_wires.append(c_w)\n\n        current_arrays = [\n            w.discretize(byedges=True, dl=wire.length / 200) for w in current_wires\n        ]\n\n        for c in current_arrays:\n            c.set_ccw((0, 1, 0))\n\n        radius = 0.5 * BluemiraFace(self.wp_xs).area / (self.nx * self.ny)\n        filament = BiotSavartFilament(\n            current_arrays, radius=radius, current=1 / (self.nx * self.ny)\n        )\n        return filament\n\n    def ripple(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Get the toroidal field ripple at points.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the ripple\n        y:\n            The y coordinate(s) of the points at which to calculate the ripple\n        z:\n            The z coordinate(s) of the points at which to calculate the ripple\n\n        Returns\n        -------\n        The value of the TF ripple at the point(s) [%]\n        \"\"\"\n        return self.cage.ripple(x, y, z)",
  "class RipplePointSelector(ABC):\n    \"\"\"\n    ABC for ripple point selection strategies.\n    \"\"\"\n\n    def __init__(self):\n        self._wire: BluemiraWire = None\n        self.points: Coordinates = None\n\n    def set_wire(self, wire: BluemiraWire):\n        \"\"\"\n        Set the wire along which the points will be selected\n\n        Parameters\n        ----------\n        wire:\n            Wire along which the points will be selected\n        \"\"\"\n        self._wire = wire\n\n    def make_ripple_constraint(\n        self, parameterisation, solver, TF_ripple_limit, rip_con_tol\n    ) -> GeomConstraintT:\n        \"\"\"\n        Make the ripple OptimisationConstraint\n        \"\"\"\n        self.parameterisation = parameterisation\n        self.solver = solver\n        self.TF_ripple_limit = TF_ripple_limit\n        return {\n            \"f_constraint\": self._constrain_ripple,\n            \"tolerance\": np.full(len(self.points), rip_con_tol),\n        }\n\n    def _constrain_ripple(\n        self, parameterisation: GeometryParameterisation\n    ) -> np.ndarray:\n        \"\"\"\n        Ripple constraint function\n\n        Parameters\n        ----------\n        parameterisation:\n            Geometry parameterisation\n        \"\"\"\n        wire = parameterisation.create_shape()\n        self.solver.update_cage(wire)\n        ripple = self.solver.ripple(*self.points)\n        # TODO: This print will call every time now, Might be a case of explicitly\n        # defining a df_constraint on this class, would be good for me to play with.\n        bluemira_debug_flush(f\"Max ripple: {max(ripple)}\")\n        return ripple - self.TF_ripple_limit",
  "class EquispacedSelector(RipplePointSelector):\n    \"\"\"\n    Equispaced ripple points along a wire for a given number of points.\n\n    Parameters\n    ----------\n    n_rip_points:\n        Number of points along the wire constrain the ripple\n    x_frac:\n        If specified, the fraction of radius above which the points will\n        be selected.\n        If unspecified, the points will be selected on the full wire\n    \"\"\"\n\n    def __init__(self, n_rip_points: int, x_frac: Optional[float] = None):\n        self.n_rip_points = n_rip_points\n        self.x_frac = x_frac\n\n    def set_wire(self, wire: BluemiraWire):\n        \"\"\"\n        Set the wire along which the points will be selected\n\n        Parameters\n        ----------\n        wire:\n            Wire along which the points will be selected\n        \"\"\"\n        super().set_wire(wire)\n        if self.x_frac is not None and not np.isclose(self.x_frac, 0.0):\n            self.x_frac = np.clip(self.x_frac, 0.005, 0.995)\n            bb = wire.bounding_box\n\n            x_min = bb.x_min + self.x_frac * (bb.x_max - bb.x_min)\n\n            z_min, z_max = bb.z_min - 10, bb.z_max + 10\n            cut_face = BluemiraFace(\n                make_polygon(\n                    {\n                        \"x\": [0, x_min, x_min, 0],\n                        \"y\": 0,\n                        \"z\": [z_min, z_min, z_max, z_max],\n                    },\n                    closed=True,\n                )\n            )\n            wire = boolean_cut(wire, cut_face)[0]\n        self.points = wire.discretize(byedges=True, ndiscr=self.n_rip_points)",
  "class ExtremaSelector(RipplePointSelector):\n    \"\"\"\n    Select the extrema of the wire and constrain ripple there.\n    \"\"\"\n\n    def set_wire(self, wire: BluemiraWire):\n        \"\"\"\n        Set the wire along which the points will be selected\n\n        Parameters\n        ----------\n        wire:\n            Wire along which the points will be selected\n        \"\"\"\n        super().set_wire(wire)\n        coords = wire.discretize(byedges=True, ndiscr=2000)\n        self.points = Coordinates(\n            [\n                coords.points[np.argmin(coords.x)],\n                coords.points[np.argmax(coords.x)],\n                coords.points[np.argmin(coords.z)],\n                coords.points[np.argmax(coords.z)],\n            ]\n        )",
  "class FixedSelector(RipplePointSelector):\n    \"\"\"\n    Specified points at which to constrain the ripple, overrides any information\n    relating directly to the separatrix.\n\n    Parameters\n    ----------\n    points:\n        Points at which the ripple should be constrained.\n    \"\"\"\n\n    def __init__(self, points: Coordinates):\n        self.points = points",
  "class MaximiseSelector(RipplePointSelector):\n    \"\"\"\n    Finds and constrains the maximum ripple along the specified wire during\n    each minimisation function call.\n    \"\"\"\n\n    def __init__(self):\n        self.points = None\n\n    def set_wire(self, wire: BluemiraWire):\n        \"\"\"\n        Set the wire along which the points will be selected\n\n        Parameters\n        ----------\n        wire:\n            Wire along which the points will be selected\n        \"\"\"\n        super().set_wire(wire)\n        points = wire.discretize(byedges=True, ndiscr=200)\n        arg_x_max = np.argmax(points.x)\n        x_max_point = points[:, arg_x_max]\n        self._alpha_0 = wire.parameter_at(x_max_point, tolerance=10 * EPS)\n\n    def make_ripple_constraint(\n        self, parameterisation, solver, TF_ripple_limit, rip_con_tol\n    ) -> GeomConstraintT:\n        \"\"\"\n        Make the ripple OptimisationConstraint\n        \"\"\"\n        self.parameterisation = parameterisation\n        self.solver = solver\n        self.TF_ripple_limit = TF_ripple_limit\n        return {\n            \"f_constraint\": self._constrain_max_ripple,\n            \"tolerance\": np.full(2, rip_con_tol),\n        }\n\n    def _constrain_max_ripple(self, parameterisation: GeometryParameterisation) -> float:\n        \"\"\"\n        Ripple constraint function\n\n        Parameters\n        ----------\n        parameterisation:\n            Geometry parameterisation\n        \"\"\"\n        tf_wire = parameterisation.create_shape()\n        self.solver.update_cage(tf_wire)\n\n        def f_max_ripple(alpha):\n            point = self._wire.value_at(alpha)\n            return -self.solver.ripple(*point)\n\n        result = optimise(\n            f_max_ripple,\n            x0=np.array([self._alpha_0]),\n            dimensions=1,\n            bounds=[(0), (1)],\n            algorithm=\"SLSQP\",\n            opt_conditions={\"ftol_rel\": 1e-6, \"max_eval\": 2000},\n        )\n\n        max_ripple_point = self._wire.value_at(result.x)\n\n        self.points = Coordinates(max_ripple_point.reshape(3, -1))\n        ripple = self.solver.ripple(*self.points)\n        # TODO: This print will call every time now, Might be a case of explicitly\n        # defining a df_constraint on this class, would be good for me to play with.\n        bluemira_debug_flush(f\"Max ripple: {ripple}\")\n        return ripple - self.TF_ripple_limit",
  "class RippleConstrainedLengthGOPParams(ParameterFrame):\n    \"\"\"\n    Parameters for the RippleConstrainedLengthGOP\n    \"\"\"\n\n    n_TF: Parameter[int]\n    R_0: Parameter[float]\n    z_0: Parameter[float]\n    B_0: Parameter[float]\n    TF_ripple_limit: Parameter[float]",
  "class RippleConstrainedLengthGOP(GeomOptimisationProblem):\n    \"\"\"\n    Toroidal field coil winding pack shape optimisation problem.\n\n    Parameters\n    ----------\n    parameterisation:\n        Geometry parameterisation for the winding pack current centreline\n    algorithm:\n        Optimisation algorithm to use\n    opt_conditions:\n        Optimisation termination conditions dictionary\n    opt_parameters:\n        Optimisation parameters dictionary\n    params:\n        Parameters required to solve the optimisation problem\n    wp_cross_section:\n        Geometry of the TF coil winding pack cross-section\n    separatrix:\n        Separatrix shape at which the TF ripple is to be constrained\n    keep_out_zone:\n        Zone boundary which the WP may not enter\n    rip_con_tol:\n        Tolerance with which to apply the ripple constraints\n    kox_con_tol:\n        Tolerance with which to apply the keep-out-zone constraints\n    nx:\n        Number of radial Biot-Savart filaments to use\n    ny:\n        Number of toroidal Biot-Savart filaments to use\n    n_koz_points:\n        Number of discretised points to use when enforcing the keep-out-zone constraint\n    ripple_selector:\n        Selection strategy for the points at which to calculate ripple. Defaults to\n        an equi-spaced set of points along the separatrix\n\n    Notes\n    -----\n    x^* = minimise: winding_pack_length\n          subject to:\n              ripple|separatrix \\\\preceq TF_ripple_limit\n              SDF(wp_shape, keep_out_zone) \\\\preceq 0\n\n    The geometry parameterisation is updated in place\n    \"\"\"\n\n    def __init__(\n        self,\n        parameterisation: GeometryParameterisation,\n        algorithm: str,\n        opt_conditions: Dict[str, float],\n        opt_parameters: Dict[str, float],\n        params: ParameterFrame,\n        wp_cross_section: BluemiraWire,\n        separatrix: BluemiraWire,\n        keep_out_zone: Optional[BluemiraWire] = None,\n        rip_con_tol: float = 1e-3,\n        koz_con_tol: float = 1e-3,\n        nx: int = 1,\n        ny: int = 1,\n        n_rip_points: int = 100,\n        n_koz_points: int = 100,\n        ripple_selector: Optional[RipplePointSelector] = None,\n    ):\n        self.parameterisation = parameterisation\n        self.params = make_parameter_frame(params, RippleConstrainedLengthGOPParams)\n        self.separatrix = separatrix\n        self.wp_cross_section = wp_cross_section\n        self.algorithm = algorithm\n        self.opt_parameters = opt_parameters\n        self.opt_conditions = opt_conditions\n\n        if keep_out_zone:\n            self._keep_out_zone = [\n                KeepOutZone(\n                    keep_out_zone,\n                    byedges=True,\n                    dl=keep_out_zone.length / 200,\n                    tol=koz_con_tol,\n                    shape_n_discr=n_koz_points,\n                )\n            ]\n        else:\n            self._keep_out_zone = []\n\n        if ripple_selector is None:\n            warnings.warn(\n                \"RippleConstrainedLengthGOP API has changed, please specify how you want \"\n                \"to constrain TF ripple by using one of the available RipplePointSelector \"\n                f\"classes. Defaulting to an EquispacedSelector with {n_rip_points=} for now.\",\n                category=DeprecationWarning,\n            )\n            ripple_selector = EquispacedSelector(n_rip_points)\n\n        ripple_selector.set_wire(self.separatrix)\n        self.ripple_values = None\n\n        self.solver = ParameterisedRippleSolver(\n            wp_cross_section,\n            nx,\n            ny,\n            params.n_TF.value,\n            params.R_0.value,\n            params.z_0.value,\n            params.B_0.value,\n        )\n        self._ripple_constraint = ripple_selector.make_ripple_constraint(\n            parameterisation, self.solver, params.TF_ripple_limit.value, rip_con_tol\n        )\n        self.ripple_selector = ripple_selector\n\n    def objective(self, parameterisation: GeometryParameterisation) -> float:\n        \"\"\"\n        Objective function (minimise length)\n        \"\"\"\n        return parameterisation.create_shape().length\n\n    def keep_out_zones(self):\n        \"\"\"\n        Keep out zone\n        \"\"\"\n        return self._keep_out_zone\n\n    def ineq_constraints(self):\n        \"\"\"\n        Inequality constraints\n        \"\"\"\n        return [self._ripple_constraint]\n\n    def optimise(self) -> GeometryParameterisation:\n        \"\"\"\n        Solve the GeometryOptimisationProblem.\n        \"\"\"\n        self.parameterisation = (\n            super()\n            .optimise(\n                self.parameterisation,\n                algorithm=self.algorithm,\n                opt_conditions=self.opt_conditions,\n                opt_parameters=self.opt_parameters,\n            )\n            .geom\n        )\n\n        self.solver.update_cage(self.parameterisation.create_shape())\n        self.ripple_values = self.solver.ripple(*self.ripple_selector.points)\n        if isinstance(self.ripple_values, float):\n            self.ripple_values = np.array([self.ripple_values])\n        return self.parameterisation\n\n    def plot(self, ax: Optional[plt.Axes] = None):\n        \"\"\"\n        Plot the optimisation problem.\n\n        Parameters\n        ----------\n        ax:\n            The optional Axes to plot onto, by default None.\n            If None then the current Axes will be used.\n        \"\"\"\n        if ax is None:\n            ax = plt.gca()\n\n        plot_2d(\n            self.separatrix,\n            ax=ax,\n            show=False,\n            wire_options={\"color\": \"red\", \"linewidth\": \"0.5\"},\n        )\n        plot_2d(\n            self.parameterisation.create_shape(),\n            ax=ax,\n            show=False,\n            wire_options={\"color\": \"blue\", \"linewidth\": 1.0},\n        )\n\n        for koz in self._keep_out_zone:\n            plot_2d(\n                koz.wire,\n                ax=ax,\n                show=False,\n                wire_options={\"color\": \"k\", \"linewidth\": 0.5},\n            )\n\n        rv = self.ripple_values\n        norm = matplotlib.colors.Normalize()\n        norm.autoscale(rv)\n        cm = matplotlib.cm.viridis\n        sm = matplotlib.cm.ScalarMappable(cmap=cm, norm=norm)\n        vmin, vmax = np.min(rv) - 1e-6, np.max(rv) + 1e-6\n        sm.set_clim(vmin, vmax)\n        ax.scatter(\n            self.ripple_selector.points.x,\n            self.ripple_selector.points.z,\n            color=cm(norm(rv)),\n        )\n        color_bar = plt.colorbar(sm, ax=ax)\n        color_bar.ax.set_ylabel(\"Toroidal field ripple [%]\")",
  "def __init__(\n        self,\n        wp_xs: BluemiraWire,\n        nx: int,\n        ny: int,\n        n_TF: int,\n        R_0: float,\n        z_0: float,\n        B_0: float,\n    ):\n        self.wp_xs = wp_xs\n        self.nx = nx\n        self.ny = ny\n        self.n_TF = n_TF\n        self.R_0 = R_0\n        self.z_0 = z_0\n        self.B_0 = B_0\n        self.cage = None",
  "def update_cage(self, wire: BluemiraWire):\n        \"\"\"\n        Update the HelmHoltzCage, setting the current to produce a field of B_0 at\n        (R_0, z_0).\n\n        Parameters\n        ----------\n        wire:\n            TF coil winding pack current centreline\n        \"\"\"\n        circuit = self._make_single_circuit(wire)\n        self.cage = HelmholtzCage(circuit, self.n_TF)\n        field = self.cage.field(self.R_0, 0, self.z_0)\n        current = -self.B_0 / field[1]  # single coil amp-turns\n        current /= self.nx * self.ny  # single filament amp-turns\n        self.cage.set_current(current)",
  "def _make_single_circuit(self, wire: BluemiraWire) -> BiotSavartFilament:\n        \"\"\"\n        Make a single BioSavart Filament for a single TF coil\n        \"\"\"\n        bb = self.wp_xs.bounding_box\n        dx_xs = 0.5 * (bb.x_max - bb.x_min)\n        dy_xs = 0.5 * (bb.y_max - bb.y_min)\n\n        dx_wp, dy_wp = [0], [0]  # default to coil centreline\n        if self.nx > 1:\n            dx_wp = np.linspace(\n                dx_xs * (1 / self.nx - 1), dx_xs * (1 - 1 / self.nx), self.nx\n            )\n\n        if self.ny > 1:\n            dy_wp = np.linspace(\n                dy_xs * (1 / self.ny - 1), dy_xs * (1 - 1 / self.ny), self.ny\n            )\n\n        current_wires = []\n        for dx in dx_wp:\n            c_wire = offset_wire(wire, dx)\n            for dy in dy_wp:\n                c_w = deepcopy(c_wire)\n                c_w.translate((0, dy, 0))\n                current_wires.append(c_w)\n\n        current_arrays = [\n            w.discretize(byedges=True, dl=wire.length / 200) for w in current_wires\n        ]\n\n        for c in current_arrays:\n            c.set_ccw((0, 1, 0))\n\n        radius = 0.5 * BluemiraFace(self.wp_xs).area / (self.nx * self.ny)\n        filament = BiotSavartFilament(\n            current_arrays, radius=radius, current=1 / (self.nx * self.ny)\n        )\n        return filament",
  "def ripple(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Get the toroidal field ripple at points.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the ripple\n        y:\n            The y coordinate(s) of the points at which to calculate the ripple\n        z:\n            The z coordinate(s) of the points at which to calculate the ripple\n\n        Returns\n        -------\n        The value of the TF ripple at the point(s) [%]\n        \"\"\"\n        return self.cage.ripple(x, y, z)",
  "def __init__(self):\n        self._wire: BluemiraWire = None\n        self.points: Coordinates = None",
  "def set_wire(self, wire: BluemiraWire):\n        \"\"\"\n        Set the wire along which the points will be selected\n\n        Parameters\n        ----------\n        wire:\n            Wire along which the points will be selected\n        \"\"\"\n        self._wire = wire",
  "def make_ripple_constraint(\n        self, parameterisation, solver, TF_ripple_limit, rip_con_tol\n    ) -> GeomConstraintT:\n        \"\"\"\n        Make the ripple OptimisationConstraint\n        \"\"\"\n        self.parameterisation = parameterisation\n        self.solver = solver\n        self.TF_ripple_limit = TF_ripple_limit\n        return {\n            \"f_constraint\": self._constrain_ripple,\n            \"tolerance\": np.full(len(self.points), rip_con_tol),\n        }",
  "def _constrain_ripple(\n        self, parameterisation: GeometryParameterisation\n    ) -> np.ndarray:\n        \"\"\"\n        Ripple constraint function\n\n        Parameters\n        ----------\n        parameterisation:\n            Geometry parameterisation\n        \"\"\"\n        wire = parameterisation.create_shape()\n        self.solver.update_cage(wire)\n        ripple = self.solver.ripple(*self.points)\n        # TODO: This print will call every time now, Might be a case of explicitly\n        # defining a df_constraint on this class, would be good for me to play with.\n        bluemira_debug_flush(f\"Max ripple: {max(ripple)}\")\n        return ripple - self.TF_ripple_limit",
  "def __init__(self, n_rip_points: int, x_frac: Optional[float] = None):\n        self.n_rip_points = n_rip_points\n        self.x_frac = x_frac",
  "def set_wire(self, wire: BluemiraWire):\n        \"\"\"\n        Set the wire along which the points will be selected\n\n        Parameters\n        ----------\n        wire:\n            Wire along which the points will be selected\n        \"\"\"\n        super().set_wire(wire)\n        if self.x_frac is not None and not np.isclose(self.x_frac, 0.0):\n            self.x_frac = np.clip(self.x_frac, 0.005, 0.995)\n            bb = wire.bounding_box\n\n            x_min = bb.x_min + self.x_frac * (bb.x_max - bb.x_min)\n\n            z_min, z_max = bb.z_min - 10, bb.z_max + 10\n            cut_face = BluemiraFace(\n                make_polygon(\n                    {\n                        \"x\": [0, x_min, x_min, 0],\n                        \"y\": 0,\n                        \"z\": [z_min, z_min, z_max, z_max],\n                    },\n                    closed=True,\n                )\n            )\n            wire = boolean_cut(wire, cut_face)[0]\n        self.points = wire.discretize(byedges=True, ndiscr=self.n_rip_points)",
  "def set_wire(self, wire: BluemiraWire):\n        \"\"\"\n        Set the wire along which the points will be selected\n\n        Parameters\n        ----------\n        wire:\n            Wire along which the points will be selected\n        \"\"\"\n        super().set_wire(wire)\n        coords = wire.discretize(byedges=True, ndiscr=2000)\n        self.points = Coordinates(\n            [\n                coords.points[np.argmin(coords.x)],\n                coords.points[np.argmax(coords.x)],\n                coords.points[np.argmin(coords.z)],\n                coords.points[np.argmax(coords.z)],\n            ]\n        )",
  "def __init__(self, points: Coordinates):\n        self.points = points",
  "def __init__(self):\n        self.points = None",
  "def set_wire(self, wire: BluemiraWire):\n        \"\"\"\n        Set the wire along which the points will be selected\n\n        Parameters\n        ----------\n        wire:\n            Wire along which the points will be selected\n        \"\"\"\n        super().set_wire(wire)\n        points = wire.discretize(byedges=True, ndiscr=200)\n        arg_x_max = np.argmax(points.x)\n        x_max_point = points[:, arg_x_max]\n        self._alpha_0 = wire.parameter_at(x_max_point, tolerance=10 * EPS)",
  "def make_ripple_constraint(\n        self, parameterisation, solver, TF_ripple_limit, rip_con_tol\n    ) -> GeomConstraintT:\n        \"\"\"\n        Make the ripple OptimisationConstraint\n        \"\"\"\n        self.parameterisation = parameterisation\n        self.solver = solver\n        self.TF_ripple_limit = TF_ripple_limit\n        return {\n            \"f_constraint\": self._constrain_max_ripple,\n            \"tolerance\": np.full(2, rip_con_tol),\n        }",
  "def _constrain_max_ripple(self, parameterisation: GeometryParameterisation) -> float:\n        \"\"\"\n        Ripple constraint function\n\n        Parameters\n        ----------\n        parameterisation:\n            Geometry parameterisation\n        \"\"\"\n        tf_wire = parameterisation.create_shape()\n        self.solver.update_cage(tf_wire)\n\n        def f_max_ripple(alpha):\n            point = self._wire.value_at(alpha)\n            return -self.solver.ripple(*point)\n\n        result = optimise(\n            f_max_ripple,\n            x0=np.array([self._alpha_0]),\n            dimensions=1,\n            bounds=[(0), (1)],\n            algorithm=\"SLSQP\",\n            opt_conditions={\"ftol_rel\": 1e-6, \"max_eval\": 2000},\n        )\n\n        max_ripple_point = self._wire.value_at(result.x)\n\n        self.points = Coordinates(max_ripple_point.reshape(3, -1))\n        ripple = self.solver.ripple(*self.points)\n        # TODO: This print will call every time now, Might be a case of explicitly\n        # defining a df_constraint on this class, would be good for me to play with.\n        bluemira_debug_flush(f\"Max ripple: {ripple}\")\n        return ripple - self.TF_ripple_limit",
  "def __init__(\n        self,\n        parameterisation: GeometryParameterisation,\n        algorithm: str,\n        opt_conditions: Dict[str, float],\n        opt_parameters: Dict[str, float],\n        params: ParameterFrame,\n        wp_cross_section: BluemiraWire,\n        separatrix: BluemiraWire,\n        keep_out_zone: Optional[BluemiraWire] = None,\n        rip_con_tol: float = 1e-3,\n        koz_con_tol: float = 1e-3,\n        nx: int = 1,\n        ny: int = 1,\n        n_rip_points: int = 100,\n        n_koz_points: int = 100,\n        ripple_selector: Optional[RipplePointSelector] = None,\n    ):\n        self.parameterisation = parameterisation\n        self.params = make_parameter_frame(params, RippleConstrainedLengthGOPParams)\n        self.separatrix = separatrix\n        self.wp_cross_section = wp_cross_section\n        self.algorithm = algorithm\n        self.opt_parameters = opt_parameters\n        self.opt_conditions = opt_conditions\n\n        if keep_out_zone:\n            self._keep_out_zone = [\n                KeepOutZone(\n                    keep_out_zone,\n                    byedges=True,\n                    dl=keep_out_zone.length / 200,\n                    tol=koz_con_tol,\n                    shape_n_discr=n_koz_points,\n                )\n            ]\n        else:\n            self._keep_out_zone = []\n\n        if ripple_selector is None:\n            warnings.warn(\n                \"RippleConstrainedLengthGOP API has changed, please specify how you want \"\n                \"to constrain TF ripple by using one of the available RipplePointSelector \"\n                f\"classes. Defaulting to an EquispacedSelector with {n_rip_points=} for now.\",\n                category=DeprecationWarning,\n            )\n            ripple_selector = EquispacedSelector(n_rip_points)\n\n        ripple_selector.set_wire(self.separatrix)\n        self.ripple_values = None\n\n        self.solver = ParameterisedRippleSolver(\n            wp_cross_section,\n            nx,\n            ny,\n            params.n_TF.value,\n            params.R_0.value,\n            params.z_0.value,\n            params.B_0.value,\n        )\n        self._ripple_constraint = ripple_selector.make_ripple_constraint(\n            parameterisation, self.solver, params.TF_ripple_limit.value, rip_con_tol\n        )\n        self.ripple_selector = ripple_selector",
  "def objective(self, parameterisation: GeometryParameterisation) -> float:\n        \"\"\"\n        Objective function (minimise length)\n        \"\"\"\n        return parameterisation.create_shape().length",
  "def keep_out_zones(self):\n        \"\"\"\n        Keep out zone\n        \"\"\"\n        return self._keep_out_zone",
  "def ineq_constraints(self):\n        \"\"\"\n        Inequality constraints\n        \"\"\"\n        return [self._ripple_constraint]",
  "def optimise(self) -> GeometryParameterisation:\n        \"\"\"\n        Solve the GeometryOptimisationProblem.\n        \"\"\"\n        self.parameterisation = (\n            super()\n            .optimise(\n                self.parameterisation,\n                algorithm=self.algorithm,\n                opt_conditions=self.opt_conditions,\n                opt_parameters=self.opt_parameters,\n            )\n            .geom\n        )\n\n        self.solver.update_cage(self.parameterisation.create_shape())\n        self.ripple_values = self.solver.ripple(*self.ripple_selector.points)\n        if isinstance(self.ripple_values, float):\n            self.ripple_values = np.array([self.ripple_values])\n        return self.parameterisation",
  "def plot(self, ax: Optional[plt.Axes] = None):\n        \"\"\"\n        Plot the optimisation problem.\n\n        Parameters\n        ----------\n        ax:\n            The optional Axes to plot onto, by default None.\n            If None then the current Axes will be used.\n        \"\"\"\n        if ax is None:\n            ax = plt.gca()\n\n        plot_2d(\n            self.separatrix,\n            ax=ax,\n            show=False,\n            wire_options={\"color\": \"red\", \"linewidth\": \"0.5\"},\n        )\n        plot_2d(\n            self.parameterisation.create_shape(),\n            ax=ax,\n            show=False,\n            wire_options={\"color\": \"blue\", \"linewidth\": 1.0},\n        )\n\n        for koz in self._keep_out_zone:\n            plot_2d(\n                koz.wire,\n                ax=ax,\n                show=False,\n                wire_options={\"color\": \"k\", \"linewidth\": 0.5},\n            )\n\n        rv = self.ripple_values\n        norm = matplotlib.colors.Normalize()\n        norm.autoscale(rv)\n        cm = matplotlib.cm.viridis\n        sm = matplotlib.cm.ScalarMappable(cmap=cm, norm=norm)\n        vmin, vmax = np.min(rv) - 1e-6, np.max(rv) + 1e-6\n        sm.set_clim(vmin, vmax)\n        ax.scatter(\n            self.ripple_selector.points.x,\n            self.ripple_selector.points.z,\n            color=cm(norm(rv)),\n        )\n        color_bar = plt.colorbar(sm, ax=ax)\n        color_bar.ax.set_ylabel(\"Toroidal field ripple [%]\")",
  "def f_max_ripple(alpha):\n            point = self._wire.value_at(alpha)\n            return -self.solver.ripple(*point)",
  "def varied_offset(\n    wire: BluemiraWire,\n    inboard_offset: float,\n    outboard_offset: float,\n    inboard_offset_degree: float,\n    outboard_offset_degree: float,\n    num_points: int = 200,\n) -> BluemiraWire:\n    \"\"\"\n    Create a new wire that offsets the given wire using a variable\n    offset in the xz plane.\n\n    All angles are measured from the negative x-direction (9 o'clock),\n    centred at the center of mass of the wire.\n    The offset will be 'inboard_offset' between the negative x-direction\n    and 'inboard_offset_degree'. Between 'outboard_offset_degree' and\n    the positive x-direction the offset will be 'outboard_offset'. Between\n    those angles, the offset will linearly transition between the min\n    and max.\n\n    Parameters\n    ----------\n    wire:\n        The wire to create the offset from. This should be convex in\n        order to get a sensible, non-intersecting, offset.\n    inboard_offset:\n        The size of the offset on the inboard side.\n    outboard_offset:\n        The size of the offset on the outboard side.\n    inboard_offset_degree:\n        The angle at which the variable offset should begin, in degrees.\n    outboard_offset_degree:\n        The angle at which the variable offset should end, in degrees.\n    num_points:\n        The number of points to use in the discretization of the input\n        wire.\n\n    Returns\n    -------\n    New wire at a variable offset to the input.\n    \"\"\"\n    _throw_if_inputs_invalid(wire, inboard_offset_degree, outboard_offset_degree)\n    coordinates = wire.discretize(num_points, byedges=True)\n    if not np.all(coordinates.normal_vector == [0, 1, 0]):\n        raise GeometryError(\n            \"Cannot create a variable offset from a wire that is not xz planar.\"\n        )\n    wire_coords = coordinates.xz\n    inboard_offset_degree = np.radians(inboard_offset_degree)\n    outboard_offset_degree = np.radians(outboard_offset_degree)\n    center_of_mass = wire.center_of_mass[[0, 2]].reshape((2, 1))\n\n    ib_axis = np.array([-1, 0])\n    angles = np.radians(find_clockwise_angle_2d(ib_axis, wire_coords - center_of_mass))\n    # Sort angles so coordinates are always clockwise and normals point outward\n    angles, wire_coords = _sort_coords_by_angle(angles, wire_coords)\n\n    offsets = _calculate_offset_magnitudes(\n        angles,\n        inboard_offset_degree,\n        outboard_offset_degree,\n        inboard_offset,\n        outboard_offset,\n    )\n    normals = _calculate_normals_2d(wire_coords)\n    new_shape_coords = wire_coords + normals * offsets\n    return _2d_coords_to_wire(new_shape_coords)",
  "def _throw_if_inputs_invalid(wire, inboard_offset_degree, outboard_offset_degree):\n    if not wire.is_closed():\n        raise GeometryError(\n            \"Cannot create a variable offset from a wire that is not closed.\"\n        )\n    if not 0 < inboard_offset_degree < 180:\n        raise ValueError(\"Inboard offset angle must be in the range [0, 180].\")\n    if not 0 < outboard_offset_degree < 180:\n        raise ValueError(\"Outboard offset angle must be in the range [0, 180].\")\n    if inboard_offset_degree > outboard_offset_degree:\n        raise ValueError(\n            f\"Inboard offset angle must be less than outboard angle. \"\n            f\"Found '{inboard_offset_degree}' and '{outboard_offset_degree}'.\"\n        )",
  "def _sort_coords_by_angle(angles: np.ndarray, coords: np.ndarray):\n    \"\"\"Sort the given angles and use that to re-order the coords.\"\"\"\n    angle_sort_idx = np.argsort(angles)\n    return angles[angle_sort_idx], coords[:, angle_sort_idx]",
  "def _calculate_offset_magnitudes(\n    angles,\n    inboard_offset_degree,\n    outboard_offset_degree,\n    inboard_offset,\n    outboard_offset,\n):\n    \"\"\"Calculate the magnitude of the offset at each angle.\"\"\"\n    offsets = np.empty_like(angles)\n    # All angles less than inboard_offset_degree set to min offset\n    constant_minor_offset_idxs = np.logical_or(\n        angles < inboard_offset_degree, angles > (2 * np.pi - inboard_offset_degree)\n    )\n    offsets[constant_minor_offset_idxs] = inboard_offset\n\n    # All angles greater than outboard_offset_degree set to max offset\n    constant_major_offset_idxs = np.logical_and(\n        angles > outboard_offset_degree, angles < 2 * np.pi - outboard_offset_degree\n    )\n    offsets[constant_major_offset_idxs] = outboard_offset\n\n    variable_offset_idxs = np.logical_not(\n        np.logical_or(constant_minor_offset_idxs, constant_major_offset_idxs)\n    )\n    offsets[variable_offset_idxs] = _calculate_variable_offset_magnitudes(\n        angles[variable_offset_idxs],\n        inboard_offset_degree,\n        outboard_offset_degree,\n        inboard_offset,\n        outboard_offset,\n    )\n    return offsets",
  "def _calculate_variable_offset_magnitudes(\n    angles, start_angle, end_angle, inboard_offset, outboard_offset\n):\n    \"\"\"\n    Calculate the variable offset magnitude for each of the given angles.\n\n    The offset increases linearly between start_angle and end_angle,\n    between inboard_offset and outboard_offset.\n    \"\"\"\n    angles[angles > np.pi] = 2 * np.pi - angles[angles > np.pi]\n    angle_fraction = (angles - start_angle) / (end_angle - start_angle)\n    return inboard_offset + angle_fraction * (outboard_offset - inboard_offset)",
  "def _calculate_normals_2d(wire_coords: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculate the unit normals to the tangents at each of the given\n    coordinates.\n\n    Note that this applies an anti-clockwise rotation to the tangents,\n    so to get an outward facing normal to a polygon, the coordinates\n    should be ordered in the clockwise direction.\n    \"\"\"\n    gradients = np.gradient(wire_coords, axis=1)\n    normals = np.array([-gradients[1], gradients[0]])\n    return normals / np.linalg.norm(normals, axis=0)",
  "def _2d_coords_to_wire(coords_2d):\n    \"\"\"\n    Build a wire from a 2D array of coordinates using a bspline.\n    \"\"\"\n    coords_3d = np.zeros((3, coords_2d.shape[1]))\n    coords_3d[(0, 2), :] = coords_2d\n    return interpolate_bspline(coords_3d, closed=True)",
  "class VVTSBuilderParams(ParameterFrame):\n    \"\"\"\n    VVTS builder parameters\n    \"\"\"\n\n    g_vv_ts: Parameter[float]\n    n_TF: Parameter[int]\n    tk_ts: Parameter[float]",
  "class VVTSBuilder(Builder):\n    \"\"\"\n    Vacuum vessel thermal shield builder\n    \"\"\"\n\n    VVTS = \"VVTS\"\n    VOID = \"VVTS voidspace\"\n    param_cls: Type[VVTSBuilderParams] = VVTSBuilderParams\n\n    def __init__(\n        self,\n        params: Union[VVTSBuilderParams, Dict],\n        build_config: Dict,\n        keep_out_zone: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.keep_out_zone = keep_out_zone\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the vacuum vessel thermal shield component.\n        \"\"\"\n        xz_vvts, xz_vvts_void = self.build_xz(self.keep_out_zone)\n        vvts_face: BluemiraFace = xz_vvts.get_component_properties(\"shape\")\n        vvts_void_face: BluemiraFace = xz_vvts_void.get_component_properties(\"shape\")\n\n        return self.component_tree(\n            xz=[xz_vvts, xz_vvts_void],\n            xy=self.build_xy(vvts_face),\n            xyz=self.build_xyz(vvts_face, vvts_void_face, degree=0),\n        )\n\n    def build_xz(self, koz: BluemiraWire) -> Tuple[PhysicalComponent, ...]:\n        \"\"\"\n        Build the x-z components of the vacuum vessel thermal shield.\n\n        Parameters\n        ----------\n        koz:\n            keep out zone for the thermal shield\n        \"\"\"\n        # This split hack works round #1319\n        # _offset_wire_discretised used because\n        # the cad offset regularly doesn't work properly here.\n        # due to topology but unknown why here particularly\n        ex_args = dict(\n            join=\"intersect\",\n            open_wire=False,\n            ndiscr=600,\n        )\n        vvts_inner_wire = _offset_wire_discretised(\n            koz, self.params.g_vv_ts.value, **ex_args\n        )\n        vvts_outer_wire = _offset_wire_discretised(\n            koz, self.params.tk_ts.value + self.params.g_vv_ts.value, **ex_args\n        )\n        vvts_inner_wire = force_wire_to_spline(vvts_inner_wire, n_edges_max=100)\n        vvts_outer_wire = force_wire_to_spline(vvts_outer_wire, n_edges_max=100)\n        vvts_face = BluemiraFace([vvts_outer_wire, vvts_inner_wire])\n        self.vvts_face = vvts_face\n\n        vvts = PhysicalComponent(self.VVTS, vvts_face)\n        vvts_void = PhysicalComponent(\n            self.VOID, BluemiraFace(vvts_face.boundary[1]), material=Void(\"vacuum\")\n        )\n\n        apply_component_display_options(vvts, color=BLUE_PALETTE[\"TS\"][0])\n        apply_component_display_options(vvts_void, color=(0, 0, 0))\n        return vvts, vvts_void\n\n    def build_xy(self, vvts_face: BluemiraFace) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y components of the vacuum vessel thermal shield.\n\n        Parameters\n        ----------\n        vvts_face:\n            xz face to build vvts\n        \"\"\"\n        return build_sectioned_xy(vvts_face, BLUE_PALETTE[\"TS\"][0])\n\n    def build_xyz(\n        self, vvts_face: BluemiraFace, vvts_void_face: BluemiraFace, degree: float = 360\n    ) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y-z components of the vacuum vessel thermal shield\n\n        Parameters\n        ----------\n        vvts_face:\n            xz face to build vvts\n        degree:\n            Revolution degrees\n        \"\"\"\n        return build_sectioned_xyz(\n            [vvts_face, vvts_void_face],\n            [self.VVTS, self.VOID],\n            self.params.n_TF.value,\n            [BLUE_PALETTE[\"TS\"][0], (0, 0, 0)],\n            degree,\n            material=[None, Void(\"vacuum\")],\n        )",
  "class CryostatTSBuilderParams(ParameterFrame):\n    \"\"\"\n    Cryostat thermal shield builder parameters\n    \"\"\"\n\n    g_ts_pf: Parameter[float]\n    g_ts_tf: Parameter[float]\n    n_TF: Parameter[int]\n    tk_ts: Parameter[float]",
  "class CryostatTSBuilder(Builder):\n    \"\"\"\n    Cryostat thermal shield builder\n    \"\"\"\n\n    CRYO_TS = \"Cryostat TS\"\n    VOID = \"Cryostat voidspace\"\n\n    param_cls: Type[CryostatTSBuilderParams] = CryostatTSBuilderParams\n\n    def __init__(\n        self,\n        params: Union[CryostatTSBuilderParams, Dict],\n        build_config: Dict,\n        pf_keep_out_zones: List[BluemiraWire],\n        tf_keep_out_zone: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.pf_keep_out_zones = pf_keep_out_zones\n        self.tf_keep_out_zone = tf_keep_out_zone\n\n    def build(self) -> Component:\n        \"\"\"\n        Build the cryostat thermal shield component.\n        \"\"\"\n        xz_cts, xz_cts_void = self.build_xz(\n            self.pf_keep_out_zones, self.tf_keep_out_zone\n        )\n        cts_face: BluemiraFace = xz_cts.get_component_properties(\"shape\")\n        cts_void_face: BluemiraFace = xz_cts_void.get_component_properties(\"shape\")\n\n        return self.component_tree(\n            xz=[xz_cts, xz_cts_void],\n            xy=[self.build_xy(cts_face)],\n            xyz=self.build_xyz(cts_face, cts_void_face, degree=0),\n        )\n\n    def build_xz(\n        self, pf_kozs: List[BluemiraWire], tf_koz: BluemiraWire\n    ) -> PhysicalComponent:\n        \"\"\"\n        Build the x-z components of the thermal shield.\n        \"\"\"\n        x, z = [], []\n        for coil in pf_kozs:\n            bb = coil.bounding_box\n            x.extend([bb.x_min, bb.x_max, bb.x_max, bb.x_min])\n            z.extend([bb.z_min, bb.z_min, bb.z_max, bb.z_max])\n\n        # Project extrema slightly beyond axis (might be bad for NT) - will get cut later\n        x.extend([-0.5, -0.5])  # [m]\n        z.extend([np.min(z), np.max(z)])\n        x, z = np.array(x), np.array(z)\n        hull_idx = ConvexHull(np.array([x, z]).T).vertices\n\n        pf_o_wire = offset_wire(\n            make_polygon({\"x\": x[hull_idx], \"y\": 0, \"z\": z[hull_idx]}, closed=True),\n            self.params.g_ts_pf.value + self.params.tk_ts.value,\n            open_wire=False,\n            ndiscr=600,\n        )\n\n        tf_o_wire = offset_wire(\n            tf_koz,\n            self.params.g_ts_tf.value,\n            join=\"arc\",\n            open_wire=False,\n            ndiscr=600,\n        )\n\n        try:\n            cts_inner = boolean_fuse(\n                [BluemiraFace(pf_o_wire), BluemiraFace(tf_o_wire)]\n            ).boundary[0]\n        except GeometryError:\n            # TODO: boolean_fuse probably shouldn't throw an error here...\n            # the TF offset face is probably enclosed by the PF offset face\n            cts_inner = pf_o_wire\n\n        cts_outer = offset_wire(cts_inner, self.params.tk_ts.value, ndiscr=600)\n        cts_face = BluemiraFace([cts_outer, cts_inner])\n        bb = cts_face.bounding_box\n        x_in, x_out = 0, -bb.x_max\n        cutter = BluemiraFace(\n            make_polygon(\n                {\n                    \"x\": [x_in, x_out, x_out, x_in],\n                    \"y\": 0,\n                    \"z\": [bb.z_min, bb.z_min, bb.z_max, bb.z_max],\n                },\n                closed=True,\n            )\n        )\n\n        cts = boolean_cut(cts_face, cutter)[0]\n        cts_void_wire = boolean_cut(cts_inner, cutter)[0]\n        cts_void_wire.close()\n        cts_void_face = BluemiraFace(cts_void_wire)\n\n        cryostat_ts = PhysicalComponent(self.CRYO_TS, cts)\n        cryostat_ts_void = PhysicalComponent(\n            self.VOID, cts_void_face, material=Void(\"vacuum\")\n        )\n\n        apply_component_display_options(cryostat_ts, color=BLUE_PALETTE[\"TS\"][0])\n        apply_component_display_options(cryostat_ts_void, color=(0, 0, 0))\n        return cryostat_ts, cryostat_ts_void\n\n    def build_xy(self, cts_face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y components of the thermal shield.\n        \"\"\"\n        mid_plane = BluemiraPlane.from_3_points([0, 0, 0], [1, 0, 0], [1, 1, 0])\n        r_in, r_out = find_xy_plane_radii(cts_face.boundary[0], mid_plane)\n\n        cryostat_ts = PhysicalComponent(self.CRYO_TS, make_circular_xy_ring(r_in, r_out))\n        apply_component_display_options(cryostat_ts, color=BLUE_PALETTE[\"TS\"][0])\n\n        return cryostat_ts\n\n    def build_xyz(\n        self, cts_face: BluemiraFace, cts_void_face: BluemiraFace, degree: float = 360\n    ) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y-z components of the thermal shield.\n        \"\"\"\n        return build_sectioned_xyz(\n            [cts_face, cts_void_face],\n            [self.CRYO_TS, self.VOID],\n            self.params.n_TF.value,\n            [BLUE_PALETTE[\"TS\"][0], (0, 0, 0)],\n            degree,\n            enable_sectioning=True,\n            material=[None, Void(\"vacuum\")],\n        )",
  "def __init__(\n        self,\n        params: Union[VVTSBuilderParams, Dict],\n        build_config: Dict,\n        keep_out_zone: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.keep_out_zone = keep_out_zone",
  "def build(self) -> Component:\n        \"\"\"\n        Build the vacuum vessel thermal shield component.\n        \"\"\"\n        xz_vvts, xz_vvts_void = self.build_xz(self.keep_out_zone)\n        vvts_face: BluemiraFace = xz_vvts.get_component_properties(\"shape\")\n        vvts_void_face: BluemiraFace = xz_vvts_void.get_component_properties(\"shape\")\n\n        return self.component_tree(\n            xz=[xz_vvts, xz_vvts_void],\n            xy=self.build_xy(vvts_face),\n            xyz=self.build_xyz(vvts_face, vvts_void_face, degree=0),\n        )",
  "def build_xz(self, koz: BluemiraWire) -> Tuple[PhysicalComponent, ...]:\n        \"\"\"\n        Build the x-z components of the vacuum vessel thermal shield.\n\n        Parameters\n        ----------\n        koz:\n            keep out zone for the thermal shield\n        \"\"\"\n        # This split hack works round #1319\n        # _offset_wire_discretised used because\n        # the cad offset regularly doesn't work properly here.\n        # due to topology but unknown why here particularly\n        ex_args = dict(\n            join=\"intersect\",\n            open_wire=False,\n            ndiscr=600,\n        )\n        vvts_inner_wire = _offset_wire_discretised(\n            koz, self.params.g_vv_ts.value, **ex_args\n        )\n        vvts_outer_wire = _offset_wire_discretised(\n            koz, self.params.tk_ts.value + self.params.g_vv_ts.value, **ex_args\n        )\n        vvts_inner_wire = force_wire_to_spline(vvts_inner_wire, n_edges_max=100)\n        vvts_outer_wire = force_wire_to_spline(vvts_outer_wire, n_edges_max=100)\n        vvts_face = BluemiraFace([vvts_outer_wire, vvts_inner_wire])\n        self.vvts_face = vvts_face\n\n        vvts = PhysicalComponent(self.VVTS, vvts_face)\n        vvts_void = PhysicalComponent(\n            self.VOID, BluemiraFace(vvts_face.boundary[1]), material=Void(\"vacuum\")\n        )\n\n        apply_component_display_options(vvts, color=BLUE_PALETTE[\"TS\"][0])\n        apply_component_display_options(vvts_void, color=(0, 0, 0))\n        return vvts, vvts_void",
  "def build_xy(self, vvts_face: BluemiraFace) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y components of the vacuum vessel thermal shield.\n\n        Parameters\n        ----------\n        vvts_face:\n            xz face to build vvts\n        \"\"\"\n        return build_sectioned_xy(vvts_face, BLUE_PALETTE[\"TS\"][0])",
  "def build_xyz(\n        self, vvts_face: BluemiraFace, vvts_void_face: BluemiraFace, degree: float = 360\n    ) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y-z components of the vacuum vessel thermal shield\n\n        Parameters\n        ----------\n        vvts_face:\n            xz face to build vvts\n        degree:\n            Revolution degrees\n        \"\"\"\n        return build_sectioned_xyz(\n            [vvts_face, vvts_void_face],\n            [self.VVTS, self.VOID],\n            self.params.n_TF.value,\n            [BLUE_PALETTE[\"TS\"][0], (0, 0, 0)],\n            degree,\n            material=[None, Void(\"vacuum\")],\n        )",
  "def __init__(\n        self,\n        params: Union[CryostatTSBuilderParams, Dict],\n        build_config: Dict,\n        pf_keep_out_zones: List[BluemiraWire],\n        tf_keep_out_zone: BluemiraWire,\n    ):\n        super().__init__(params, build_config)\n        self.pf_keep_out_zones = pf_keep_out_zones\n        self.tf_keep_out_zone = tf_keep_out_zone",
  "def build(self) -> Component:\n        \"\"\"\n        Build the cryostat thermal shield component.\n        \"\"\"\n        xz_cts, xz_cts_void = self.build_xz(\n            self.pf_keep_out_zones, self.tf_keep_out_zone\n        )\n        cts_face: BluemiraFace = xz_cts.get_component_properties(\"shape\")\n        cts_void_face: BluemiraFace = xz_cts_void.get_component_properties(\"shape\")\n\n        return self.component_tree(\n            xz=[xz_cts, xz_cts_void],\n            xy=[self.build_xy(cts_face)],\n            xyz=self.build_xyz(cts_face, cts_void_face, degree=0),\n        )",
  "def build_xz(\n        self, pf_kozs: List[BluemiraWire], tf_koz: BluemiraWire\n    ) -> PhysicalComponent:\n        \"\"\"\n        Build the x-z components of the thermal shield.\n        \"\"\"\n        x, z = [], []\n        for coil in pf_kozs:\n            bb = coil.bounding_box\n            x.extend([bb.x_min, bb.x_max, bb.x_max, bb.x_min])\n            z.extend([bb.z_min, bb.z_min, bb.z_max, bb.z_max])\n\n        # Project extrema slightly beyond axis (might be bad for NT) - will get cut later\n        x.extend([-0.5, -0.5])  # [m]\n        z.extend([np.min(z), np.max(z)])\n        x, z = np.array(x), np.array(z)\n        hull_idx = ConvexHull(np.array([x, z]).T).vertices\n\n        pf_o_wire = offset_wire(\n            make_polygon({\"x\": x[hull_idx], \"y\": 0, \"z\": z[hull_idx]}, closed=True),\n            self.params.g_ts_pf.value + self.params.tk_ts.value,\n            open_wire=False,\n            ndiscr=600,\n        )\n\n        tf_o_wire = offset_wire(\n            tf_koz,\n            self.params.g_ts_tf.value,\n            join=\"arc\",\n            open_wire=False,\n            ndiscr=600,\n        )\n\n        try:\n            cts_inner = boolean_fuse(\n                [BluemiraFace(pf_o_wire), BluemiraFace(tf_o_wire)]\n            ).boundary[0]\n        except GeometryError:\n            # TODO: boolean_fuse probably shouldn't throw an error here...\n            # the TF offset face is probably enclosed by the PF offset face\n            cts_inner = pf_o_wire\n\n        cts_outer = offset_wire(cts_inner, self.params.tk_ts.value, ndiscr=600)\n        cts_face = BluemiraFace([cts_outer, cts_inner])\n        bb = cts_face.bounding_box\n        x_in, x_out = 0, -bb.x_max\n        cutter = BluemiraFace(\n            make_polygon(\n                {\n                    \"x\": [x_in, x_out, x_out, x_in],\n                    \"y\": 0,\n                    \"z\": [bb.z_min, bb.z_min, bb.z_max, bb.z_max],\n                },\n                closed=True,\n            )\n        )\n\n        cts = boolean_cut(cts_face, cutter)[0]\n        cts_void_wire = boolean_cut(cts_inner, cutter)[0]\n        cts_void_wire.close()\n        cts_void_face = BluemiraFace(cts_void_wire)\n\n        cryostat_ts = PhysicalComponent(self.CRYO_TS, cts)\n        cryostat_ts_void = PhysicalComponent(\n            self.VOID, cts_void_face, material=Void(\"vacuum\")\n        )\n\n        apply_component_display_options(cryostat_ts, color=BLUE_PALETTE[\"TS\"][0])\n        apply_component_display_options(cryostat_ts_void, color=(0, 0, 0))\n        return cryostat_ts, cryostat_ts_void",
  "def build_xy(self, cts_face: BluemiraFace) -> PhysicalComponent:\n        \"\"\"\n        Build the x-y components of the thermal shield.\n        \"\"\"\n        mid_plane = BluemiraPlane.from_3_points([0, 0, 0], [1, 0, 0], [1, 1, 0])\n        r_in, r_out = find_xy_plane_radii(cts_face.boundary[0], mid_plane)\n\n        cryostat_ts = PhysicalComponent(self.CRYO_TS, make_circular_xy_ring(r_in, r_out))\n        apply_component_display_options(cryostat_ts, color=BLUE_PALETTE[\"TS\"][0])\n\n        return cryostat_ts",
  "def build_xyz(\n        self, cts_face: BluemiraFace, cts_void_face: BluemiraFace, degree: float = 360\n    ) -> List[PhysicalComponent]:\n        \"\"\"\n        Build the x-y-z components of the thermal shield.\n        \"\"\"\n        return build_sectioned_xyz(\n            [cts_face, cts_void_face],\n            [self.CRYO_TS, self.VOID],\n            self.params.n_TF.value,\n            [BLUE_PALETTE[\"TS\"][0], (0, 0, 0)],\n            degree,\n            enable_sectioning=True,\n            material=[None, Void(\"vacuum\")],\n        )",
  "def apply_component_display_options(\n    phys_component: PhysicalComponent,\n    color: Union[Iterable, ColorPalette],\n    transparency: Optional[float] = None,\n):\n    \"\"\"\n    Apply color and transparency to a PhysicalComponent for both plotting and CAD.\n    \"\"\"\n    if isinstance(color, ColorPalette):\n        color = color.as_hex()\n    phys_component.plot_options.face_options[\"color\"] = color\n    phys_component.display_cad_options.color = color\n    if transparency:\n        phys_component.plot_options.face_options[\"alpha\"] = transparency\n        phys_component.display_cad_options.transparency = transparency",
  "def get_n_sectors(no_obj: int, degree: float = 360) -> Tuple[float, int]:\n    \"\"\"\n    Get sector count and angle size for a given number of degrees of the reactor.\n\n    Parameters\n    ----------\n    no_obj:\n        total number of components (eg TF coils)\n    degree:\n        angle to view of reactor\n\n    Returns\n    -------\n    sector_degree:\n        number of degrees per sector\n    n_sectors:\n        number of sectors\n    \"\"\"\n    sector_degree = 360 / no_obj\n    n_sectors = max(1, int(degree // int(sector_degree)))\n    return sector_degree, n_sectors",
  "def circular_pattern_component(\n    component: Union[bm_comp.Component, List[bm_comp.Component]],\n    n_children: int,\n    parent_prefix: str = \"Sector\",\n    *,\n    origin: Tuple[float, float, float] = (0.0, 0.0, 0.0),\n    direction: Tuple[float, float, float] = (0.0, 0.0, 1.0),\n    degree: float = 360.0,\n):\n    \"\"\"\n    Pattern the provided Component equally spaced around a circle n_children times.\n\n    The resulting components are assigned to a set of common parent Components having\n    a name with the structure \"{parent_prefix} {idx}\", where idx runs from 1 to\n    n_children. The Components produced under each parent are named according to the\n    original Component with the corresponding idx value appended.\n\n    Parameters\n    ----------\n    component:\n        The original Component to use as the template for copying around the circle.\n    n_children:\n        The number of children to produce around the circle.\n    parent_prefix:\n        The prefix to provide to the new parent component, having a name of the form\n        \"{parent_prefix} {idx}\", by default \"Sector\".\n    origin:\n        The origin of the circle to pattern around, by default (0., 0., 0.).\n    direction:\n        The surface normal of the circle to pattern around, by default (0., 0., 1.) i.e.\n        the positive z axis, resulting in a counter clockwise circle in the x-y plane.\n    degree:\n        The angular extent of the patterning in degrees, by default 360.\n    \"\"\"\n    component = [component] if isinstance(component, bm_comp.Component) else component\n    sectors = [bm_comp.Component(f\"{parent_prefix}\") for _ in range(n_children)]\n    # build sector trees by assigning copies of each component to sec. parents\n    for c in component:\n        for parent_sc in sectors:\n            c.copy(parent_sc)\n\n    sector_tree_indexs = [list(PreOrderIter(sc)) for sc in sectors]\n\n    # to keep naming convention\n    for sec_i, sector_index in enumerate(sector_tree_indexs):\n        for comp in sector_index:\n            comp.name = f\"{comp.name} {sec_i + 1}\"\n\n    faux_sec_comp = bm_comp.Component(f\"{parent_prefix} X\")\n    faux_sec_comp.children = component\n\n    for search_index_i, comp in enumerate(PreOrderIter(faux_sec_comp)):\n        if isinstance(comp, bm_comp.PhysicalComponent):\n            shapes = bm_geo.tools.circular_pattern(\n                comp.shape,\n                n_shapes=n_children,\n                origin=origin,\n                direction=direction,\n                degree=degree,\n            )\n            # assign each shape to each sector at index search_index_i\n            # which should be the copy of the PhysicalComponent\n            for sector_index, shape in zip(sector_tree_indexs, shapes):\n                phy_comp = sector_index[search_index_i]\n                if not isinstance(phy_comp, bm_comp.PhysicalComponent):\n                    raise ComponentError(\n                        \"Could not find corresponding PhysicalComponent in \"\n                        f\"sector index: {sector_index}, \"\n                        f\"with search index: {search_index_i}\"\n                    )\n                phy_comp.shape = shape\n\n    return sectors",
  "def pattern_revolved_silhouette(\n    face: BluemiraFace, n_seg_p_sector: int, n_sectors: int, gap: float\n) -> List[BluemiraSolid]:\n    \"\"\"\n    Pattern a silhouette with revolutions about the z-axis, inter-spaced with parallel\n    gaps between solids.\n\n    Parameters\n    ----------\n    face:\n        x-z silhouette of the geometry to revolve and pattern\n    n_seg_p_sector:\n        Number of segments per sector\n    n_sectors:\n        Number of sectors\n    gap:\n        Absolute distance between segments (parallel)\n\n    Returns\n    -------\n    List of solids for each segment (ordered anti-clockwise)\n    \"\"\"\n    sector_degree = 360 / n_sectors\n\n    if gap <= 0.0:\n        # No gaps; just touching solids\n        segment_degree = sector_degree / n_seg_p_sector\n        shape = revolve_shape(\n            face, base=(0, 0, 0), direction=(0, 0, 1), degree=segment_degree\n        )\n        shapes = circular_pattern(\n            shape, origin=(0, 0, 0), degree=sector_degree, n_shapes=n_seg_p_sector\n        )\n    else:\n        volume = revolve_shape(\n            face, base=(0, 0, 0), direction=(0, 0, 1), degree=sector_degree\n        )\n        gaps = _generate_gap_volumes(face, n_seg_p_sector, n_sectors, gap)\n        shapes = boolean_cut(volume, gaps)\n    return _order_shapes_anticlockwise(shapes)",
  "def pattern_lofted_silhouette(\n    face: BluemiraFace, n_seg_p_sector: int, n_sectors: int, gap: float\n) -> List[BluemiraSolid]:\n    \"\"\"\n    Pattern a silhouette with lofts about the z-axis, inter-spaced with parallel\n    gaps between solids.\n\n    Parameters\n    ----------\n    face:\n        x-z silhouette of the geometry to loft and pattern\n    n_seg_p_sector:\n        Number of segments per sector\n    n_sectors:\n        Number of sectors\n    gap:\n        Absolute distance between segments (parallel)\n\n    Returns\n    -------\n    List of solids for each segment (ordered anti-clockwise)\n    \"\"\"\n    sector_degree = 360 / n_sectors\n\n    degree = sector_degree * (1 + 1 / n_seg_p_sector)\n    faces = circular_pattern(\n        face,\n        origin=(0, 0, 0),\n        direction=(0, 0, 1),\n        degree=degree,\n        n_shapes=n_seg_p_sector + 1,\n    )\n    shapes = []\n    for i, r_face in enumerate(faces[:-1]):\n        com_1 = r_face.center_of_mass\n        com_2 = faces[i + 1].center_of_mass\n\n        wire = make_polygon(\n            {\n                \"x\": [com_1[0], com_2[0]],\n                \"y\": [com_1[1], com_2[1]],\n                \"z\": [com_1[2], com_2[2]],\n            }\n        )\n        volume = sweep_shape([r_face.boundary[0], faces[i + 1].boundary[0]], wire)\n        shapes.append(volume)\n\n    if gap > 0.0:\n        if len(shapes) > 1:\n            full_volume = boolean_fuse(shapes)\n        else:\n            full_volume = shapes[0]\n\n        gaps = _generate_gap_volumes(face, n_seg_p_sector, n_sectors, gap)\n        shapes = boolean_cut(full_volume, gaps)\n\n    return _order_shapes_anticlockwise(shapes)",
  "def _generate_gap_volumes(face, n_seg_p_sector, n_sectors, gap):\n    \"\"\"\n    Generate the gap volumes\n    \"\"\"\n    bb = face.bounding_box\n    delta = 1.0\n    x = np.array(\n        [bb.x_min - delta, bb.x_max + delta, bb.x_max + delta, bb.x_min - delta]\n    )\n    z = np.array(\n        [bb.z_min - delta, bb.z_min - delta, bb.z_max + delta, bb.z_max + delta]\n    )\n    poly = make_polygon({\"x\": x, \"y\": 0, \"z\": z}, closed=True)\n    bb_face = BluemiraFace(poly)\n    bb_face.translate((0, -0.5 * gap, 0))\n    gap_volume = extrude_shape(bb_face, (0, gap, 0))\n    degree = 360 / n_sectors\n    degree += degree / n_seg_p_sector\n    gap_volumes = circular_pattern(\n        gap_volume, degree=degree, n_shapes=n_seg_p_sector + 1\n    )\n    return gap_volumes",
  "def _order_shapes_anticlockwise(shapes):\n    \"\"\"\n    Order shapes anti-clockwise about (0, 0, 1) by center of mass\n    \"\"\"\n    x, y = np.zeros(len(shapes)), np.zeros(len(shapes))\n\n    for i, shape in enumerate(shapes):\n        com = shape.center_of_mass\n        x[i] = com[0]\n        y[i] = com[1]\n\n    r = np.hypot(x, y)\n    angles = np.where(y > 0, np.arccos(x / r), 2 * np.pi - np.arccos(x / r))\n    indices = np.argsort(angles)\n    return list(np.array(shapes)[indices])",
  "def find_xy_plane_radii(wire: BluemiraWire, plane: BluemiraPlane) -> List[float]:\n    \"\"\"\n    Get the radial coordinates of a wire's intersection points with a plane.\n\n    Parameters\n    ----------\n    wire:\n        Wire to get the radii for in the plane\n    plane:\n        Plane to slice with\n\n    Returns\n    -------\n    The radii of intersections, sorted from smallest to largest\n    \"\"\"\n    intersections = slice_shape(wire, plane)\n    return sorted(intersections[:, 0])",
  "def make_circular_xy_ring(r_inner: float, r_outer: float) -> BluemiraFace:\n    \"\"\"\n    Make a circular annulus in the x-y plane (z=0)\n    \"\"\"\n    centre = (0, 0, 0)\n    axis = (0, 0, 1)\n    if np.isclose(r_inner, r_outer, rtol=0, atol=2 * EPS):\n        raise BuilderError(f\"Cannot make an annulus where r_inner = r_outer = {r_inner}\")\n\n    if r_inner > r_outer:\n        r_inner, r_outer = r_outer, r_inner\n\n    inner = make_circle(r_inner, center=centre, axis=axis)\n    outer = make_circle(r_outer, center=centre, axis=axis)\n    return BluemiraFace([outer, inner])",
  "def build_sectioned_xy(\n    face: BluemiraFace,\n    plot_colour: Tuple[float],\n    material: Optional[SerialisedMaterial] = None,\n) -> List[PhysicalComponent]:\n    \"\"\"\n    Build the x-y components of sectioned component\n\n    Parameters\n    ----------\n    face:\n        xz face to build xy component\n    plot_colour:\n        colour tuple for component\n    material:\n        Optional material to apply to physical component\n\n    Returns\n    -------\n    List of PhysicalComponents with colours applied\n    \"\"\"\n    xy_plane = BluemiraPlane.from_3_points([0, 0, 0], [1, 0, 0], [1, 1, 0])\n\n    r_ib_out, r_ob_out = find_xy_plane_radii(face.boundary[0], xy_plane)\n    r_ib_in, r_ob_in = find_xy_plane_radii(face.boundary[1], xy_plane)\n\n    sections = []\n    for name, r_in, r_out in [\n        [\"inboard\", r_ib_in, r_ib_out],\n        [\"outboard\", r_ob_in, r_ob_out],\n    ]:\n        board = make_circular_xy_ring(r_in, r_out)\n        section = PhysicalComponent(name, board, material=material)\n        apply_component_display_options(section, color=plot_colour)\n        sections.append(section)\n\n    return sections",
  "def build_sectioned_xyz(\n    face: BluemiraFace,\n    name: str,\n    n_TF: int,\n    plot_colour: Tuple[float],\n    degree: float = 360,\n    enable_sectioning: bool = True,\n    material: Optional[SerialisedMaterial] = None,\n) -> List[PhysicalComponent]:\n    \"\"\"\n    Build the x-y-z components of sectioned component\n\n    Parameters\n    ----------\n    face:\n        xz face to build xyz component\n    name:\n        PhysicalComponent name\n    n_TF:\n        number of TF coils\n    plot_colour:\n        colour tuple for component\n    degree:\n        angle to sweep through\n    enable_sectioning:\n        Switch on/off sectioning (#1319 Topology issue)\n    material:\n        Optional material to apply to physical component\n\n    Returns\n    -------\n    List of PhysicalComponents\n\n    Notes\n    -----\n    When `enable_sectioning=False` a list with a single component rotated a maximum\n    of 359 degrees will be returned. This is a workaround for two issues\n    from the topology naming issue #1319:\n\n        - Some objects fail to be rebuilt when rotated\n        - Some objects cant be rotated 360 degrees due to DisjointedFaceError\n\n    \"\"\"\n    sector_degree, n_sectors = get_n_sectors(n_TF, degree)\n\n    if isinstance(face, BluemiraFace):\n        face = [face]\n    if isinstance(name, str):\n        name = [name]\n    if isinstance(plot_colour, Tuple):\n        plot_colour = [plot_colour]\n    if not isinstance(material, list):\n        material = [material]\n\n    if not (len(face) == len(name) == len(plot_colour) == len(material)):\n        raise ValueError(\n            \"Lengths of the face, name, plot_colour, and material lists are not equal.\"\n        )\n\n    bodies = []\n    for fac, nam, color, mat in zip(face, name, plot_colour, material):\n        shape = revolve_shape(\n            fac,\n            base=(0, 0, 0),\n            direction=(0, 0, 1),\n            degree=sector_degree if enable_sectioning else min(359, degree),\n        )\n        body = PhysicalComponent(nam, shape, material=mat)\n        apply_component_display_options(body, color=color)\n        bodies.append(body)\n\n    # this is currently broken in some situations\n    # because of #1319 and related Topological naming issues\n    return (\n        circular_pattern_component(bodies, n_sectors, degree=sector_degree * n_sectors)\n        if enable_sectioning\n        else bodies\n    )",
  "def optimise(\n    f_objective: ObjectiveCallable,\n    df_objective: Optional[OptimiserCallable] = None,\n    *,\n    x0: Optional[np.ndarray] = None,\n    dimensions: Optional[int] = None,\n    algorithm: AlgorithmType = Algorithm.SLSQP,\n    opt_conditions: Optional[Mapping[str, Union[int, float]]] = None,\n    opt_parameters: Optional[Mapping[str, Any]] = None,\n    bounds: Optional[Tuple[npt.ArrayLike, npt.ArrayLike]] = None,\n    eq_constraints: Iterable[ConstraintT] = (),\n    ineq_constraints: Iterable[ConstraintT] = (),\n    keep_history: bool = False,\n    check_constraints: bool = True,\n    check_constraints_warn: bool = True,\n) -> OptimiserResult:\n    r\"\"\"\n    Find the parameters that minimise the given objective function.\n\n    Parameters\n    ----------\n    f_objective:\n        The objective function to minimise.\n    dimensions:\n        The dimensionality of the problem. This or ``x0`` must be given.\n    x0:\n        The initial guess for the optimisation parameters. This or\n        `dimensions` must be given, if both are given, ``x0.size`` must\n        be equal to ``dimensions``.\n    df_objective:\n        The derivative of the objective function.\n    algorithm:\n        The optimisation algorithm to use. See enum\n        :class:`.Algorithm` for supported algorithms.\n        (default: ``\"SLSQP\"``)\n    opt_conditions:\n        The stopping conditions for the optimiser. Supported conditions\n        are:\n\n            * ftol_abs: float\n            * ftol_rel: float\n            * xtol_abs: float\n            * xtol_rel: float\n            * max_eval: int\n            * max_time: float\n            * stop_val: float\n\n        for defaults see\n        :class:`~bluemira.optimisation._algorithm.AlgorithmDefaultConditions`.\n\n    opt_parameters:\n        The algorithm-specific optimisation parameters.\n    bounds:\n        The upper and lower bounds for the optimisation parameters.\n        The first array being the lower bounds, the second the upper.\n        This can also be ``None``, in which case the bounds are\n        ``(-inf, inf)`` for each optimisation parameter. You can also\n        specify scalars for either the upper or lower bounds or both,\n        and those bound will be applied to every optimisation parameter.\n    eq_constraints:\n        The equality constraints for the optimiser.\n        A dict with keys:\n\n            * f_constraint: the constraint function.\n            * tolerance: the tolerances in each constraint dimension.\n            * df_constraint (optional): the derivative of the constraint\n              function. If not given, a numerical approximation of the\n              gradient is made (if a gradient is required).\n\n        A constraint is a vector-valued, non-linear, equality\n        constraint of the form :math:`f_{c}(x) = 0`.\n\n        The constraint function should have the form\n        :math:`f(x) \\rightarrow y`, where:\n\n            * :math:`x` is a numpy array of the optimisation parameters.\n            * :math:`y` is a numpy array containing the values of the\n              constraint at :math:`x`, with size :math:`m`, where\n              :math:`m` is the dimensionality of the constraint.\n\n        The tolerance array must have the same dimensionality as the\n        constraint.\n\n        The gradient function should have the same form as the\n        constraint function, however its output should have size\n        :math:`n \\times m` where :math:`m` is the dimensionality of the\n        constraint and :math:`n` is the number of optimisation\n        parameters.\n\n        Equality constraints are only supported by algorithms:\n\n            * SLSQP\n            * COBYLA\n            * ISRES\n\n    ineq_constraints:\n        The inequality constraints for the optimiser.\n        This argument has the same form as the ``eq_constraint`` argument,\n        but each constraint is in the form :math:`f_{c}(x) \\le 0`.\n\n        Inequality constraints are only supported by algorithms:\n\n            * SLSQP\n            * COBYLA\n            * ISRES\n\n    keep_history:\n        Whether to record the history of each step of the optimisation.\n        (default: False)\n    check_constraints:\n        Whether to check all constraints have been satisfied at the end\n        of the optimisation, and warn if they have not. Note that, if\n        this is set to False, the result's ``constraints_satisfied``\n        attribute will be set to ``None``.\n    check_constraints_warn:\n        Whether to print a warning that constraints have not been\n        satisfied at the end of an optimisation. This argument has no\n        effect if ``check_constraints`` is ``False``.\n\n    Returns\n    -------\n    The result of the optimisation; including the optimised parameters\n    and the number of iterations.\n    \"\"\"\n    if dimensions is None:\n        if x0 is not None:\n            dimensions = x0.size\n        else:\n            raise ValueError(\"Must give argument 'dimension' or 'x0'.\")\n    else:\n        if x0 is not None and x0.size != dimensions:\n            raise ValueError(\"Size of 'x0' and 'dimensions' must agree.\")\n\n    opt_conditions = _set_default_termination_conditions(algorithm, opt_conditions)\n\n    bounds = _process_bounds(bounds, dimensions)\n    # Convert to lists, as these could be generators, and we may need to\n    # consume them more than once.\n    eq_constraints = list(eq_constraints)\n    ineq_constraints = list(ineq_constraints)\n\n    optimiser = _make_optimiser(\n        f_objective,\n        dimensions,\n        df_objective,\n        algorithm,\n        opt_conditions,\n        opt_parameters,\n        bounds,\n        eq_constraints,\n        ineq_constraints,\n        keep_history,\n    )\n    result = optimiser.optimise(x0)\n    if check_constraints:\n        result.constraints_satisfied = validate_constraints(\n            result.x, eq_constraints, ineq_constraints, warn=check_constraints_warn\n        )\n    return result",
  "def validate_constraints(\n    x_star: np.ndarray,\n    eq_constraints: List[ConstraintT],\n    ineq_constraints: List[ConstraintT],\n    warn: bool = True,\n) -> bool:\n    \"\"\"\n    Check the given parametrisation satisfies the given constraints.\n\n    Additionally, print warnings listing constraints that are not\n    satisfied.\n\n    Parameters\n    ----------\n    x_star:\n        The parameterisation to check the constraints against.\n    eq_constraints:\n        The list of equality constraints to check.\n    ineq_constraints:\n        The list of inequality constraints to check.\n    warn:\n        Whether to print warnings if constraints are violated.\n        Default is true.\n\n    Returns\n    -------\n    True if no constraints are violated by the parameterisation.\n    \"\"\"\n    eq_warnings = _check_constraints(x_star, eq_constraints, \"equality\")\n    ineq_warnings = _check_constraints(x_star, ineq_constraints, \"inequality\")\n    all_warnings = eq_warnings + ineq_warnings\n    if all_warnings:\n        if warn:\n            message = \"\\n\".join(all_warnings)\n            bluemira_warn(\n                f\"Some constraints have not been adequately satisfied.\\n{message}\"\n            )\n        return False\n    return True",
  "def _make_optimiser(\n    f_objective: ObjectiveCallable,\n    dimensions: int,\n    df_objective: Optional[OptimiserCallable] = None,\n    algorithm: AlgorithmType = Algorithm.SLSQP,\n    opt_conditions: Optional[Mapping[str, Union[int, float]]] = None,\n    opt_parameters: Optional[Mapping[str, Any]] = None,\n    bounds: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n    eq_constraints: Iterable[ConstraintT] = (),\n    ineq_constraints: Iterable[ConstraintT] = (),\n    keep_history: bool = False,\n) -> Optimiser:\n    \"\"\"Make a new optimiser object.\"\"\"\n    opt = NloptOptimiser(\n        algorithm,\n        dimensions,\n        f_objective=f_objective,\n        df_objective=df_objective,\n        opt_conditions=opt_conditions,\n        opt_parameters=opt_parameters,\n        keep_history=keep_history,\n    )\n    for constraint in eq_constraints:\n        opt.add_eq_constraint(**constraint)\n    for constraint in ineq_constraints:\n        opt.add_ineq_constraint(**constraint)\n    if bounds:\n        opt.set_lower_bounds(bounds[0])\n        opt.set_upper_bounds(bounds[1])\n    return opt",
  "def _process_bounds(\n    bounds: Union[Tuple[npt.ArrayLike, npt.ArrayLike], None], dims: int\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Handle bounds converting ``None`` to +/-inf and expanding scalar bounds.\"\"\"\n    if bounds is None:\n        return (np.full(dims, -np.inf), np.full(dims, np.inf))\n    bounds = tuple(bounds)\n    if len(bounds) != 2:\n        raise ValueError(f\"Bounds must have exactly 2 elements, found '{len(bounds)}'\")\n    new_bounds = [np.full(dims, b) if np.isscalar(b) else np.array(b) for b in bounds]\n    return new_bounds[0], new_bounds[1]",
  "def _check_constraints(\n    x_star: np.ndarray,\n    constraints: List[ConstraintT],\n    constraint_type: Literal[\"inequality\", \"equality\"],\n) -> List[str]:\n    \"\"\"\n    Check if any of the given constraints are violated by the parameterisation.\n\n    Returns a list of formatted warnings. If there are no warnings, there\n    are no violations.\n    \"\"\"\n\n    def _check_constraint(\n        x_star: np.ndarray,\n        constraint: ConstraintT,\n        condition: Callable[[np.ndarray, np.ndarray], np.ndarray],\n    ) -> Union[Tuple[np.ndarray, np.ndarray, np.ndarray], None]:\n        \"\"\"Return the items in the constraint vector that violate the condition.\"\"\"\n        c_value = constraint[\"f_constraint\"](x_star)\n        # Deal with scalar constraints\n        c_value = np.array([c_value]) if np.isscalar(c_value) else c_value\n        tols = np.array(constraint[\"tolerance\"])\n        indices = np.where(condition(c_value, tols))[0]\n        if indices.size > 0:\n            return (indices, c_value, tols)\n        return None\n\n    condition, comp_str = (\n        (_eq_constraint_condition, \"!=\")\n        if constraint_type == \"equality\"\n        else (_ineq_constraint_condition, \"!<\")\n    )\n\n    warnings = []\n    for i, constraint in enumerate(constraints):\n        if diff := _check_constraint(x_star, constraint, condition):\n            indices, c_value, tols = diff\n            warnings.append(\n                \"\\n\".join(\n                    [\n                        f\"{constraint_type} constraint {i} [{j}]: \"\n                        f\"{pformat(c_value[j])} {comp_str} {pformat(tols[j])}\"\n                        for j in indices\n                    ]\n                )\n            )\n    return warnings",
  "def _eq_constraint_condition(c_value: np.ndarray, tols: np.ndarray) -> np.ndarray:\n    \"\"\"Condition under which an equality constraint is violated.\"\"\"\n    return ~np.isclose(c_value, 0, atol=tols)",
  "def _ineq_constraint_condition(c_value: np.ndarray, tols: np.ndarray) -> np.ndarray:\n    \"\"\"Condition under which an inequality constraint is violated.\"\"\"\n    return c_value > tols",
  "def _set_default_termination_conditions(\n    algorithm: AlgorithmType,\n    opt_conditions: Optional[Mapping[str, Union[int, float]]] = None,\n) -> Optional[Mapping[str, Union[int, float]]]:\n    if opt_conditions is None:\n        if isinstance(algorithm, str):\n            algorithm = Algorithm[algorithm]\n\n        if not isinstance(algorithm, Algorithm):\n            return opt_conditions\n\n        return getattr(AlgorithmDefaultConditions(), algorithm.name).to_dict()\n    return opt_conditions",
  "def _check_constraint(\n        x_star: np.ndarray,\n        constraint: ConstraintT,\n        condition: Callable[[np.ndarray, np.ndarray], np.ndarray],\n    ) -> Union[Tuple[np.ndarray, np.ndarray, np.ndarray], None]:\n        \"\"\"Return the items in the constraint vector that violate the condition.\"\"\"\n        c_value = constraint[\"f_constraint\"](x_star)\n        # Deal with scalar constraints\n        c_value = np.array([c_value]) if np.isscalar(c_value) else c_value\n        tols = np.array(constraint[\"tolerance\"])\n        indices = np.where(condition(c_value, tols))[0]\n        if indices.size > 0:\n            return (indices, c_value, tols)\n        return None",
  "class OptimiserResult:\n    \"\"\"Container for optimiser results.\"\"\"\n\n    f_x: float\n    \"\"\"The evaluation of the optimised parameterisation.\"\"\"\n    x: np.ndarray\n    \"\"\"The optimised parameterisation.\"\"\"\n    n_evals: int\n    \"\"\"The number of evaluations of the objective function in the optimisation.\"\"\"\n    history: List[Tuple[np.ndarray, float]] = field(repr=False)\n    \"\"\"\n    The history of the parametrisation at each iteration.\n\n    The first element of each tuple is the parameterisation (x), the\n    second is the evaluation of the objective function at x (f(x)).\n    \"\"\"\n    constraints_satisfied: Union[bool, None] = None\n    \"\"\"\n    Whether all constraints have been satisfied to within the required tolerance.\n\n    Is ``None`` if constraints have not been checked.\n    \"\"\"",
  "class Optimiser(abc.ABC):\n    \"\"\"Interface for an optimiser supporting bounds and constraints.\"\"\"\n\n    @abc.abstractmethod\n    def add_eq_constraint(\n        self,\n        f_constraint: OptimiserCallable,\n        tolerance: np.ndarray,\n        df_constraint: Optional[OptimiserCallable] = None,\n    ) -> None:\n        r\"\"\"\n        Add an equality constraint to the optimiser.\n\n        The constraint is a vector-valued, non-linear, equality\n        constraint of the form :math:`f_{c}(x) = 0`.\n\n        The constraint function should have the form\n        :math:`f(x) \\rightarrow y`, where:\n\n            * :math:`x` is a numpy array of the optimisation parameters.\n            * :math:`y` is a numpy array containing the values of the\n              constraint at :math:`x`, with size :math:`m`, where\n              :math:`m` is the dimensionality of the constraint.\n\n        Parameters\n        ----------\n        f_constraint:\n            The constraint function, with form as described above.\n        tolerance:\n            The tolerances for each optimisation parameter.\n        df_constraint:\n            The gradient of the constraint function. This should have\n            the same form as the constraint function, however its output\n            array should have dimensions :math:`m \\times n` where\n            :math`m` is the dimensionality of the constraint, and\n            :math:`n` is the number of optimisation parameters.\n\n        Notes\n        -----\n        Inequality constraints are only supported by algorithms:\n\n            * SLSQP\n            * COBYLA\n            * ISRES\n\n        \"\"\"\n\n    @abc.abstractmethod\n    def add_ineq_constraint(\n        self,\n        f_constraint: OptimiserCallable,\n        tolerance: np.ndarray,\n        df_constraint: Optional[OptimiserCallable] = None,\n    ) -> None:\n        r\"\"\"\n        Add an inequality constrain to the optimiser.\n\n        The constraint is a vector-valued, non-linear, inequality\n        constraint of the form :math:`f_{c}(x) \\le 0`.\n\n        The constraint function should have the form\n        :math:`f(x) \\rightarrow y`, where:\n\n            * :math:`x` is a numpy array of the optimisation parameters.\n            * :math:`y` is a numpy array containing the values of the\n              constraint at :math:`x`, with size :math:`m`, where\n              :math:`m` is the dimensionality of the constraint.\n\n        Parameters\n        ----------\n        f_constraint:\n            The constraint function, with form as described above.\n        tolerance:\n            The tolerances for each optimisation parameter.\n        df_constraint:\n            The gradient of the constraint function. This should have\n            the same form as the constraint function, however its output\n            array should have dimensions :math:`m \\times n` where\n            :math`m` is the dimensionality of the constraint, and\n            :math:`n` is the number of optimisation parameters.\n\n        Notes\n        -----\n        Inequality constraints are only supported by algorithms:\n\n            * SLSQP\n            * COBYLA\n            * ISRES\n\n        \"\"\"\n\n    @abc.abstractmethod\n    def optimise(self, x0: Optional[np.ndarray] = None) -> OptimiserResult:\n        \"\"\"\n        Run the optimiser.\n\n        Parameters\n        ----------\n        x0:\n            The initial guess for each of the optimisation parameters.\n            If not given, each parameter is set to the average of its\n            lower and upper bound. If no bounds exist, the initial guess\n            will be all zeros.\n\n        Returns\n        -------\n        The result of the optimisation, containing the optimised\n        parameters ``x``, as well as other information about the\n        optimisation.\n        \"\"\"\n\n    @abc.abstractmethod\n    def set_lower_bounds(self, bounds: np.ndarray) -> None:\n        \"\"\"\n        Set the lower bound for each optimisation parameter.\n\n        Set to `-np.inf` to unbound the parameter's minimum.\n        \"\"\"\n\n    @abc.abstractmethod\n    def set_upper_bounds(self, bounds: np.ndarray) -> None:\n        \"\"\"\n        Set the upper bound for each optimisation parameter.\n\n        Set to `np.inf` to unbound the parameter's minimum.\n        \"\"\"",
  "def add_eq_constraint(\n        self,\n        f_constraint: OptimiserCallable,\n        tolerance: np.ndarray,\n        df_constraint: Optional[OptimiserCallable] = None,\n    ) -> None:\n        r\"\"\"\n        Add an equality constraint to the optimiser.\n\n        The constraint is a vector-valued, non-linear, equality\n        constraint of the form :math:`f_{c}(x) = 0`.\n\n        The constraint function should have the form\n        :math:`f(x) \\rightarrow y`, where:\n\n            * :math:`x` is a numpy array of the optimisation parameters.\n            * :math:`y` is a numpy array containing the values of the\n              constraint at :math:`x`, with size :math:`m`, where\n              :math:`m` is the dimensionality of the constraint.\n\n        Parameters\n        ----------\n        f_constraint:\n            The constraint function, with form as described above.\n        tolerance:\n            The tolerances for each optimisation parameter.\n        df_constraint:\n            The gradient of the constraint function. This should have\n            the same form as the constraint function, however its output\n            array should have dimensions :math:`m \\times n` where\n            :math`m` is the dimensionality of the constraint, and\n            :math:`n` is the number of optimisation parameters.\n\n        Notes\n        -----\n        Inequality constraints are only supported by algorithms:\n\n            * SLSQP\n            * COBYLA\n            * ISRES\n\n        \"\"\"",
  "def add_ineq_constraint(\n        self,\n        f_constraint: OptimiserCallable,\n        tolerance: np.ndarray,\n        df_constraint: Optional[OptimiserCallable] = None,\n    ) -> None:\n        r\"\"\"\n        Add an inequality constrain to the optimiser.\n\n        The constraint is a vector-valued, non-linear, inequality\n        constraint of the form :math:`f_{c}(x) \\le 0`.\n\n        The constraint function should have the form\n        :math:`f(x) \\rightarrow y`, where:\n\n            * :math:`x` is a numpy array of the optimisation parameters.\n            * :math:`y` is a numpy array containing the values of the\n              constraint at :math:`x`, with size :math:`m`, where\n              :math:`m` is the dimensionality of the constraint.\n\n        Parameters\n        ----------\n        f_constraint:\n            The constraint function, with form as described above.\n        tolerance:\n            The tolerances for each optimisation parameter.\n        df_constraint:\n            The gradient of the constraint function. This should have\n            the same form as the constraint function, however its output\n            array should have dimensions :math:`m \\times n` where\n            :math`m` is the dimensionality of the constraint, and\n            :math:`n` is the number of optimisation parameters.\n\n        Notes\n        -----\n        Inequality constraints are only supported by algorithms:\n\n            * SLSQP\n            * COBYLA\n            * ISRES\n\n        \"\"\"",
  "def optimise(self, x0: Optional[np.ndarray] = None) -> OptimiserResult:\n        \"\"\"\n        Run the optimiser.\n\n        Parameters\n        ----------\n        x0:\n            The initial guess for each of the optimisation parameters.\n            If not given, each parameter is set to the average of its\n            lower and upper bound. If no bounds exist, the initial guess\n            will be all zeros.\n\n        Returns\n        -------\n        The result of the optimisation, containing the optimised\n        parameters ``x``, as well as other information about the\n        optimisation.\n        \"\"\"",
  "def set_lower_bounds(self, bounds: np.ndarray) -> None:\n        \"\"\"\n        Set the lower bound for each optimisation parameter.\n\n        Set to `-np.inf` to unbound the parameter's minimum.\n        \"\"\"",
  "def set_upper_bounds(self, bounds: np.ndarray) -> None:\n        \"\"\"\n        Set the upper bound for each optimisation parameter.\n\n        Set to `np.inf` to unbound the parameter's minimum.\n        \"\"\"",
  "class OptimisationProblemBase:\n    \"\"\"Common base class for OptimisationProblem classes.\"\"\"\n\n    __MethodT = TypeVar(\"__MethodT\", bound=Callable[..., Any])\n    __AnyT = TypeVar(\"__AnyT\")\n\n    def _overridden_or_default(\n        self, f: __MethodT, cls: Type[Any], default: __AnyT\n    ) -> Union[__MethodT, __AnyT]:\n        \"\"\"\n        If the given object is not a member of this class return a default.\n\n        This can be used to decide whether a function has been overridden or not.\n        Which is useful in this class for the ``df_objective`` case, where overriding\n        the method is possible, but not necessary. We want it to appear in the class\n        interface, but we want to be able to tell if it's been overridden so we can\n        use an approximate gradient if it has not been.\n        \"\"\"\n        if self.__is_method(f, cls):\n            return f\n        return default\n\n    def __is_method(self, f: __MethodT, cls: Type[Any]) -> bool:\n        \"\"\"\n        Determine if the given method is a member of this base class or not.\n\n        Note that ``f`` must be a bound method, i.e., it needs the\n        ``__func__`` dunder method.\n        \"\"\"\n        try:\n            this_f = getattr(cls, f.__name__)\n        except AttributeError:\n            return False\n        return f.__func__ is not this_f",
  "class OptimisationProblem(abc.ABC, OptimisationProblemBase):\n    \"\"\"\n    Interface for an optimisation problem.\n\n    This is an alternative to running an optimisation using the\n    :func:`.optimise` function.\n\n    Using this interface to define an optimisation can provide a few\n    benefits, including:\n\n        * Shared state between optimisation functions and constraints.\n          This can enable things like shared parameters and dynamic\n          constraints.\n        * Switch out optimisation problems using Liskov Substitution.\n        * Logical grouping of related functions.\n    \"\"\"\n\n    @abc.abstractmethod\n    def objective(self, x: np.ndarray) -> float:\n        \"\"\"The objective function to minimise.\"\"\"\n\n    def df_objective(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"The gradient of the objective function at ``x``.\"\"\"\n\n    def eq_constraints(self) -> List[ConstraintT]:\n        \"\"\"The equality constraints on the optimisation.\"\"\"\n        return []\n\n    def ineq_constraints(self) -> List[ConstraintT]:\n        \"\"\"The inequality constraints on the optimisation.\"\"\"\n        return []\n\n    def bounds(self) -> Tuple[npt.ArrayLike, npt.ArrayLike]:\n        \"\"\"\n        The lower and upper bounds of the optimisation parameters.\n\n        Each set of bounds must be convertible to a numpy array of\n        floats. If the lower or upper bound is a scalar value, that\n        value is set as the bound for each of the optimisation\n        parameters.\n        \"\"\"\n        return -np.inf, np.inf\n\n    def optimise(\n        self,\n        x0: np.ndarray,\n        *,\n        algorithm: AlgorithmType = Algorithm.SLSQP,\n        opt_conditions: Optional[Mapping[str, Union[int, float]]] = None,\n        opt_parameters: Optional[Mapping[str, Any]] = None,\n        keep_history: bool = False,\n        check_constraints: bool = True,\n        check_constraints_warn: bool = True,\n    ) -> OptimiserResult:\n        \"\"\"\n        Perform the optimisation.\n\n        See :func:`.optimise` for more function parameter details.\n        \"\"\"\n        df_objective = self._overridden_or_default(\n            self.df_objective, OptimisationProblem, None\n        )\n        return optimise(\n            self.objective,\n            df_objective=df_objective,\n            x0=x0,\n            algorithm=algorithm,\n            opt_conditions=opt_conditions,\n            opt_parameters=opt_parameters,\n            bounds=self.bounds(),\n            eq_constraints=self.eq_constraints(),\n            ineq_constraints=self.ineq_constraints(),\n            keep_history=keep_history,\n            check_constraints=check_constraints,\n            check_constraints_warn=check_constraints_warn,\n        )\n\n    def check_constraints(self, x: np.ndarray, warn: bool = True) -> bool:\n        \"\"\"\n        Check if the given parameterisation violates this optimiser's constraints.\n\n        Parameters\n        ----------\n        x:\n            The parametrisation to check the constraints against.\n        warn:\n            If ``True`` print a warning that lists the violated\n            constraints.\n\n        Returns\n        -------\n        True if any constraints are violated by the parameterisation.\n        \"\"\"\n        return validate_constraints(\n            x, self.eq_constraints(), self.ineq_constraints(), warn=warn\n        )",
  "def _overridden_or_default(\n        self, f: __MethodT, cls: Type[Any], default: __AnyT\n    ) -> Union[__MethodT, __AnyT]:\n        \"\"\"\n        If the given object is not a member of this class return a default.\n\n        This can be used to decide whether a function has been overridden or not.\n        Which is useful in this class for the ``df_objective`` case, where overriding\n        the method is possible, but not necessary. We want it to appear in the class\n        interface, but we want to be able to tell if it's been overridden so we can\n        use an approximate gradient if it has not been.\n        \"\"\"\n        if self.__is_method(f, cls):\n            return f\n        return default",
  "def __is_method(self, f: __MethodT, cls: Type[Any]) -> bool:\n        \"\"\"\n        Determine if the given method is a member of this base class or not.\n\n        Note that ``f`` must be a bound method, i.e., it needs the\n        ``__func__`` dunder method.\n        \"\"\"\n        try:\n            this_f = getattr(cls, f.__name__)\n        except AttributeError:\n            return False\n        return f.__func__ is not this_f",
  "def objective(self, x: np.ndarray) -> float:\n        \"\"\"The objective function to minimise.\"\"\"",
  "def df_objective(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"The gradient of the objective function at ``x``.\"\"\"",
  "def eq_constraints(self) -> List[ConstraintT]:\n        \"\"\"The equality constraints on the optimisation.\"\"\"\n        return []",
  "def ineq_constraints(self) -> List[ConstraintT]:\n        \"\"\"The inequality constraints on the optimisation.\"\"\"\n        return []",
  "def bounds(self) -> Tuple[npt.ArrayLike, npt.ArrayLike]:\n        \"\"\"\n        The lower and upper bounds of the optimisation parameters.\n\n        Each set of bounds must be convertible to a numpy array of\n        floats. If the lower or upper bound is a scalar value, that\n        value is set as the bound for each of the optimisation\n        parameters.\n        \"\"\"\n        return -np.inf, np.inf",
  "def optimise(\n        self,\n        x0: np.ndarray,\n        *,\n        algorithm: AlgorithmType = Algorithm.SLSQP,\n        opt_conditions: Optional[Mapping[str, Union[int, float]]] = None,\n        opt_parameters: Optional[Mapping[str, Any]] = None,\n        keep_history: bool = False,\n        check_constraints: bool = True,\n        check_constraints_warn: bool = True,\n    ) -> OptimiserResult:\n        \"\"\"\n        Perform the optimisation.\n\n        See :func:`.optimise` for more function parameter details.\n        \"\"\"\n        df_objective = self._overridden_or_default(\n            self.df_objective, OptimisationProblem, None\n        )\n        return optimise(\n            self.objective,\n            df_objective=df_objective,\n            x0=x0,\n            algorithm=algorithm,\n            opt_conditions=opt_conditions,\n            opt_parameters=opt_parameters,\n            bounds=self.bounds(),\n            eq_constraints=self.eq_constraints(),\n            ineq_constraints=self.ineq_constraints(),\n            keep_history=keep_history,\n            check_constraints=check_constraints,\n            check_constraints_warn=check_constraints_warn,\n        )",
  "def check_constraints(self, x: np.ndarray, warn: bool = True) -> bool:\n        \"\"\"\n        Check if the given parameterisation violates this optimiser's constraints.\n\n        Parameters\n        ----------\n        x:\n            The parametrisation to check the constraints against.\n        warn:\n            If ``True`` print a warning that lists the violated\n            constraints.\n\n        Returns\n        -------\n        True if any constraints are violated by the parameterisation.\n        \"\"\"\n        return validate_constraints(\n            x, self.eq_constraints(), self.ineq_constraints(), warn=warn\n        )",
  "class ObjectiveCallable(Protocol):\n    \"\"\"Form for an optimiser objective function.\"\"\"\n\n    def __call__(self, x: np.ndarray) -> float:\n        \"\"\"\n        Call the objective function.\n\n        Parameters\n        ----------\n        x:\n            The optimisation parameters.\n        \"\"\"\n        ...",
  "class OptimiserCallable(Protocol):\n    \"\"\"\n    Form for an non-objective optimiser function.\n\n    This is the form for a gradient, constraint, or constraint gradient.\n    \"\"\"\n\n    def __call__(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Call the optimiser function.\n\n        Parameters\n        ----------\n        x:\n            The optimisation parameters.\n        \"\"\"\n        ...",
  "class ConstraintT(TypedDict):\n    \"\"\"Typing for definition of a constraint.\"\"\"\n\n    f_constraint: OptimiserCallable\n    tolerance: np.ndarray\n    df_constraint: NotRequired[Optional[OptimiserCallable]]",
  "def __call__(self, x: np.ndarray) -> float:\n        \"\"\"\n        Call the objective function.\n\n        Parameters\n        ----------\n        x:\n            The optimisation parameters.\n        \"\"\"\n        ...",
  "def __call__(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Call the optimiser function.\n\n        Parameters\n        ----------\n        x:\n            The optimisation parameters.\n        \"\"\"\n        ...",
  "class _AlgorithmMeta(enum.EnumMeta):\n    def __getitem__(self, s: str) -> Algorithm:\n        try:\n            return super().__getitem__(s)\n        except KeyError:\n            if s == \"DIRECT-L\":\n                # special case for backward compatibility\n                return super().__getitem__(\"DIRECT_L\")\n            raise ValueError(f\"No such Algorithm value '{s}'.\")",
  "class Algorithm(enum.Enum, metaclass=_AlgorithmMeta):\n    \"\"\"Enumeration of available optimisation algorithms.\"\"\"\n\n    SLSQP = enum.auto()\n    COBYLA = enum.auto()\n    SBPLX = enum.auto()\n    MMA = enum.auto()\n    BFGS = enum.auto()\n    DIRECT = enum.auto()\n    DIRECT_L = enum.auto()\n    CRS = enum.auto()\n    ISRES = enum.auto()",
  "class AlgorithmConditions:\n    \"\"\"Algorithm conditions container\"\"\"\n\n    ftol_abs: Optional[float] = None\n    ftol_rel: Optional[float] = None\n    xtol_abs: Optional[float] = None\n    xtol_rel: Optional[float] = None\n    max_eval: int = 2000\n    max_time: Optional[float] = None\n    stop_val: Optional[float] = None\n\n    def to_dict(self) -> Dict[str, float]:\n        \"\"\"Convert to dictionary without Nones\"\"\"\n        return {k: v for k, v in asdict(self).items() if v is not None}",
  "class AlgorithmDefaultConditions:\n    \"\"\"Default Algorithm conditions\"\"\"\n\n    SLSQP: AlgorithmConditions = field(\n        default_factory=lambda: AlgorithmConditions(\n            xtol_rel=1e-4, xtol_abs=1e-4, ftol_rel=1e-4, ftol_abs=1e-4\n        )\n    )\n    COBYLA: AlgorithmConditions = field(\n        default_factory=lambda: AlgorithmConditions(ftol_rel=1e-6)\n    )\n    SBPLX: AlgorithmConditions = field(\n        default_factory=lambda: AlgorithmConditions(stop_val=1)\n    )\n    MMA: AlgorithmConditions = field(default_factory=AlgorithmConditions)\n    BFGS: AlgorithmConditions = field(\n        default_factory=lambda: AlgorithmConditions(xtol_rel=0)\n    )\n    DIRECT: AlgorithmConditions = field(\n        default_factory=lambda: AlgorithmConditions(ftol_rel=1e-4)\n    )\n    DIRECT_L: AlgorithmConditions = field(default_factory=AlgorithmConditions)\n    CRS: AlgorithmConditions = field(default_factory=AlgorithmConditions)\n    ISRES: AlgorithmConditions = field(default_factory=AlgorithmConditions)",
  "def __getitem__(self, s: str) -> Algorithm:\n        try:\n            return super().__getitem__(s)\n        except KeyError:\n            if s == \"DIRECT-L\":\n                # special case for backward compatibility\n                return super().__getitem__(\"DIRECT_L\")\n            raise ValueError(f\"No such Algorithm value '{s}'.\")",
  "def to_dict(self) -> Dict[str, float]:\n        \"\"\"Convert to dictionary without Nones\"\"\"\n        return {k: v for k, v in asdict(self).items() if v is not None}",
  "class OptimisationError(BluemiraError):\n    \"\"\"Generic optimisation error.\"\"\"",
  "class GeometryOptimisationError(BluemiraError):\n    \"\"\"Generic geometry optimisation error.\"\"\"",
  "class OptimisationConditionsError(OptimisationError):\n    \"\"\"Error relating to optimiser conditions.\"\"\"",
  "class OptimisationParametersError(OptimisationError):\n    \"\"\"Error relating to optimiser parameters.\"\"\"",
  "def approx_derivative(\n    func: Callable[[np.ndarray], _FloatOrArray],\n    x0: np.ndarray,\n    method: str = \"3-point\",\n    rel_step: Optional[_FloatOrArray] = None,\n    f0: Optional[_FloatOrArray] = None,\n    bounds: Optional[Iterable[_FloatOrArray]] = (-np.inf, np.inf),\n    args: Optional[Tuple[Any, ...]] = (),\n) -> np.ndarray:\n    \"\"\"\n    Approximate the gradient of a function about a point.\n\n    Parameters\n    ----------\n    func:\n        Function for which to calculate the gradient.\n    x0:\n        Point about which to calculate the gradient.\n    method:\n        Finite difference method to use.\n    rel_step:\n        Relative step size to use.\n    f0:\n        Result of func(x0). If None, this is recomputed.\n    bounds:\n        Lower and upper bounds on individual variables.\n    args:\n        Additional positional arguments to ``func``.\n    \"\"\"\n    return _approx_derivative(\n        func, x0, method=method, rel_step=rel_step, f0=f0, bounds=bounds, args=args\n    )",
  "def process_scipy_result(res):\n    \"\"\"\n    Handle a scipy.minimize OptimizeResult object. Process error codes, if any.\n\n    Parameters\n    ----------\n    res:\n        Scipy optimise result\n\n    Returns\n    -------\n    x: np.array\n        The optimal set of parameters (result of the optimisation)\n\n    Raises\n    ------\n    InternalOptError if an error code returned without a usable result.\n    \"\"\"\n    if res.success:\n        return res.x\n\n    if not hasattr(res, \"status\"):\n        bluemira_warn(\"Scipy optimisation was not succesful. Failed without status.\")\n        raise OptimisationError(\"\\n\".join([res.message, res.__str__()]))\n\n    elif res.status == 8:\n        # This can happen when scipy is not convinced that it has found a minimum.\n        bluemira_warn(\n            \"\\nOptimiser (scipy) found a positive directional derivative,\\n\"\n            \"returning suboptimal result. \\n\"\n            \"\\n\".join([res.message, res.__str__()])\n        )\n        return res.x\n\n    elif res.status == 9:\n        bluemira_warn(\n            \"\\nOptimiser (scipy) exceeded number of iterations, returning \"\n            \"suboptimal result. \\n\"\n            \"\\n\".join([res.message, res.__str__()])\n        )\n        return res.x\n\n    else:\n        raise OptimisationError(\"\\n\".join([res.message, res.__str__()]))",
  "class NLOptConditions:\n    \"\"\"Hold and validate optimiser stopping conditions.\"\"\"\n\n    ftol_abs: Optional[float] = None\n    ftol_rel: Optional[float] = None\n    xtol_abs: Optional[float] = None\n    xtol_rel: Optional[float] = None\n    max_eval: Optional[int] = None\n    max_time: Optional[float] = None\n    stop_val: Optional[float] = None\n\n    def __post_init__(self):\n        \"\"\"Validate initialised values.\"\"\"\n        self._validate()\n\n    def to_dict(self) -> Dict[str, float]:\n        \"\"\"Return the data in dictionary form.\"\"\"\n        return asdict(self)\n\n    def _validate(self) -> None:\n        for condition in [\n            self.ftol_abs,\n            self.ftol_rel,\n            self.xtol_abs,\n            self.xtol_rel,\n        ]:\n            if condition and condition < EPS:\n                bluemira_warn(\n                    \"optimisation: Setting stopping condition to less than machine \"\n                    \"precision. This condition may never be met.\"\n                )\n        if self._no_stopping_condition_set():\n            raise OptimisationConditionsError(\n                \"Must specify at least one stopping condition for the optimiser.\"\n            )\n        if self.max_eval is not None and isinstance(self.max_eval, float):\n            bluemira_warn(\"optimisation: max_eval must be an integer, forcing type.\")\n            self.max_eval = int(self.max_eval)\n\n    def _no_stopping_condition_set(self) -> bool:\n        return all(\n            condition is None\n            for condition in [\n                self.ftol_abs,\n                self.ftol_rel,\n                self.xtol_abs,\n                self.xtol_rel,\n                self.max_eval,\n                self.max_time,\n                self.stop_val,\n            ]\n        )",
  "def __post_init__(self):\n        \"\"\"Validate initialised values.\"\"\"\n        self._validate()",
  "def to_dict(self) -> Dict[str, float]:\n        \"\"\"Return the data in dictionary form.\"\"\"\n        return asdict(self)",
  "def _validate(self) -> None:\n        for condition in [\n            self.ftol_abs,\n            self.ftol_rel,\n            self.xtol_abs,\n            self.xtol_rel,\n        ]:\n            if condition and condition < EPS:\n                bluemira_warn(\n                    \"optimisation: Setting stopping condition to less than machine \"\n                    \"precision. This condition may never be met.\"\n                )\n        if self._no_stopping_condition_set():\n            raise OptimisationConditionsError(\n                \"Must specify at least one stopping condition for the optimiser.\"\n            )\n        if self.max_eval is not None and isinstance(self.max_eval, float):\n            bluemira_warn(\"optimisation: max_eval must be an integer, forcing type.\")\n            self.max_eval = int(self.max_eval)",
  "def _no_stopping_condition_set(self) -> bool:\n        return all(\n            condition is None\n            for condition in [\n                self.ftol_abs,\n                self.ftol_rel,\n                self.xtol_abs,\n                self.xtol_rel,\n                self.max_eval,\n                self.max_time,\n                self.stop_val,\n            ]\n        )",
  "class NloptOptimiser(Optimiser):\n    r\"\"\"\n    Optimiser implementation using NLOpt as the backend.\n\n    Parameters\n    ----------\n    algorithm:\n        The optimisation algorithm to use. Available algorithms are:\n\n            * SLSQP\n            * COBYLA\n            * SBPLX\n            * MMA\n            * BFGS\n            * DIRECT\n            * DIRECT_L\n            * CRS\n            * ISRES\n\n    n_variables:\n        The number of optimisation parameters.\n    f_objective:\n        The objective function to minimise. This function must take one\n        argument (a numpy array), and return a numpy array or float.\n    df_objective:\n        The derivative of the objective function. This must take the\n        form: :math:`f(x) \\rightarrow y` where :math:`x` is a numpy\n        array containing the optimization parameters, and :math:`y` is a\n        numpy array where each element :math:`i` is the partial\n        derivative :math:`\\frac{\\partial f(x)}{\\partial x_{i}}`.\n        If not given, and a gradient based algorithm is used, a\n        numerical approximation of the gradient will be made.\n    opt_conditions:\n        The stopping conditions for the optimiser. At least one stopping\n        condition is required. Supported conditions are:\n\n            * ftol_abs: float\n            * ftol_rel: float\n            * xtol_abs: float\n            * xtol_rel: float\n            * max_eval: int\n            * max_time: float\n            * stop_val: float\n\n    opt_parameters:\n        Parameters specific to the algorithm being used. Consult the\n        NLopt documentation for these.\n    keep_history:\n        Whether to record the history of each step of the optimisation.\n        (default: ``False``)\n    \"\"\"\n\n    def __init__(\n        self,\n        algorithm: AlgorithmType,\n        n_variables: int,\n        f_objective: ObjectiveCallable,\n        df_objective: Optional[OptimiserCallable] = None,\n        opt_conditions: Optional[Mapping[str, Union[int, float]]] = None,\n        opt_parameters: Optional[Mapping[str, Any]] = None,\n        keep_history: bool = False,\n    ):\n        opt_conditions = {} if opt_conditions is None else opt_conditions\n        opt_parameters = {} if opt_parameters is None else opt_parameters\n        self._keep_history = keep_history\n\n        self._set_algorithm(algorithm)\n        self._opt = nlopt.opt(_NLOPT_ALG_MAPPING[self.algorithm], n_variables)\n        self._set_objective_function(f_objective, df_objective, n_variables)\n        self._set_termination_conditions(opt_conditions)\n        self._set_algorithm_parameters(opt_parameters)\n        self._eq_constraints: List[Constraint] = []\n        self._ineq_constraints: List[Constraint] = []\n\n    @property\n    def algorithm(self) -> Algorithm:\n        \"\"\"Return the optimiser's algorithm.\"\"\"\n        return self._algorithm\n\n    @property\n    def opt_conditions(self) -> Dict[str, float]:\n        \"\"\"Return the optimiser's stopping conditions.\"\"\"\n        return self._opt_conditions.to_dict()\n\n    @property\n    def opt_parameters(self) -> Mapping[str, Union[int, float]]:\n        \"\"\"Return the optimiser algorithms's parameters.\"\"\"\n        return self._opt_parameters\n\n    @property\n    def lower_bounds(self) -> np.ndarray:\n        \"\"\"Return the lower bounds for the optimisation parameters.\"\"\"\n        return self._opt.get_lower_bounds().copy()\n\n    @property\n    def upper_bounds(self) -> np.ndarray:\n        \"\"\"Return the upper bounds for the optimisation parameters.\"\"\"\n        return self._opt.get_upper_bounds().copy()\n\n    def add_eq_constraint(\n        self,\n        f_constraint: OptimiserCallable,\n        tolerance: np.ndarray,\n        df_constraint: Optional[OptimiserCallable] = None,\n    ) -> None:\n        \"\"\"\n        Add an equality constraint.\n\n        See :meth:`~bluemira.optimisation._optimiser.Optimiser.add_eq_constraint`.\n        \"\"\"\n        if self.algorithm not in [Algorithm.SLSQP, Algorithm.COBYLA, Algorithm.ISRES]:\n            raise OptimisationError(\n                f\"Algorithm '{self.algorithm.name}' does not support equality \"\n                f\"constraints.\"\n            )\n        constraint = Constraint(\n            ConstraintType.EQUALITY,\n            f_constraint,\n            tolerance,\n            df_constraint,\n            bounds=(self.lower_bounds, self.upper_bounds),\n        )\n        self._opt.add_equality_mconstraint(constraint.call, constraint.tolerance)\n        self._eq_constraints.append(constraint)\n\n    def add_ineq_constraint(\n        self,\n        f_constraint: OptimiserCallable,\n        tolerance: np.ndarray,\n        df_constraint: Optional[OptimiserCallable] = None,\n    ) -> None:\n        \"\"\"\n        Add an inequality constraint.\n\n        See :meth:`~bluemira.optimisation._optimiser.Optimiser.add_ineq_constraint`.\n        \"\"\"\n        if self.algorithm not in [Algorithm.SLSQP, Algorithm.COBYLA, Algorithm.ISRES]:\n            raise OptimisationError(\n                f\"Algorithm '{self.algorithm.name}' does not support inequality \"\n                f\"constraints.\"\n            )\n        constraint = Constraint(\n            ConstraintType.INEQUALITY,\n            f_constraint,\n            tolerance,\n            df_constraint,\n            bounds=(self.lower_bounds, self.upper_bounds),\n        )\n        self._opt.add_inequality_mconstraint(constraint.call, constraint.tolerance)\n        self._ineq_constraints.append(constraint)\n\n    def optimise(self, x0: Optional[np.ndarray] = None) -> OptimiserResult:\n        \"\"\"\n        Run the optimisation.\n\n        See :meth:`~bluemira.optimisation._optimiser.Optimiser.optimise`.\n        \"\"\"\n        if x0 is None:\n            x0 = _initial_guess_from_bounds(self.lower_bounds, self.upper_bounds)\n\n        try:\n            x_star = self._opt.optimize(x0)\n            f_x = self._objective.f(x_star)\n        except nlopt.RoundoffLimited:\n            # It's likely that the last call was still a reasonably good solution.\n            x_star, f_x = self._get_previous_iter_result()\n        except OptVariablesError:\n            # Probably still some rounding errors due to numerical gradients\n            # It's likely that the last call was still a reasonably good solution.\n            bluemira_warn(\"Badly behaved numerical gradients are causing trouble...\")\n            x_star, f_x = self._get_previous_iter_result()\n        except RuntimeError as error:\n            # Usually \"more than iter SQP iterations\"\n            _process_nlopt_result(self._opt, self.algorithm)\n            raise OptimisationError(str(error))\n        except KeyboardInterrupt:\n            _process_nlopt_result(self._opt, self.algorithm)\n            raise KeyboardInterrupt(\n                \"The optimisation was halted by the user. Please check \"\n                \"your optimisation problem and termination conditions.\"\n            )\n\n        _process_nlopt_result(self._opt, self.algorithm)\n        return OptimiserResult(\n            f_x=f_x,\n            x=x_star,\n            n_evals=self._opt.get_numevals(),\n            history=self._objective.history,\n        )\n\n    def set_lower_bounds(self, bounds: npt.ArrayLike) -> None:\n        \"\"\"\n        Set the lower bound for each optimisation parameter.\n\n        See :meth:`~bluemira.optimisation._optimiser.Optimiser.set_lower_bounds`.\n        \"\"\"\n        bounds = np.array(bounds)\n        _check_bounds(self._opt.get_dimension(), bounds)\n        self._opt.set_lower_bounds(bounds)\n        # As we use the optimisation variable bounds when calculating an\n        # approximate derivative, we must set the new bounds on the\n        # objective function and constraints.\n        self._objective.set_approx_derivative_lower_bound(bounds)\n        for constraint in self._eq_constraints + self._ineq_constraints:\n            constraint.set_approx_derivative_lower_bound(bounds)\n\n    def set_upper_bounds(self, bounds: npt.ArrayLike) -> None:\n        \"\"\"\n        Set the upper bound for each optimisation parameter.\n\n        See :meth:`~bluemira.optimisation._optimiser.Optimiser.set_upper_bounds`.\n        \"\"\"\n        bounds = np.array(bounds)\n        _check_bounds(self._opt.get_dimension(), bounds)\n        self._opt.set_upper_bounds(bounds)\n        # As we use the optimisation variable bounds when calculating an\n        # approximate derivative, we must set the new bounds on the\n        # objective function and constraints.\n        self._objective.set_approx_derivative_upper_bound(bounds)\n        for constraint in self._eq_constraints + self._ineq_constraints:\n            constraint.set_approx_derivative_upper_bound(bounds)\n\n    def _get_previous_iter_result(self) -> Tuple[np.ndarray, float]:\n        \"\"\"Get the parameterisation and result from the previous iteration.\"\"\"\n        x_star = self._objective.prev_iter\n        f_x = self._objective.f(x_star) if x_star.size else np.inf\n        return x_star, f_x\n\n    def _handle_round_off_error(self) -> Tuple[np.ndarray, float]:\n        \"\"\"\n        Handle a round-off error occurring in an optimisation.\n\n        It's likely the last call was a decent solution, so return that\n        (with a warning).\n        \"\"\"\n        bluemira_warn(\n            \"optimisation: round-off error occurred. \"\n            \"Returning last optimisation parameterisation.\"\n        )\n        x_star = self._objective.prev_iter\n        f_x = self._objective.f(x_star) if x_star.size else np.inf\n        return x_star, f_x\n\n    def _set_algorithm(self, alg: AlgorithmType) -> None:\n        \"\"\"Set the optimiser's algorithm.\"\"\"\n        self._algorithm = _check_algorithm(alg)\n\n    def _set_objective_function(\n        self,\n        func: ObjectiveCallable,\n        df: Union[None, OptimiserCallable],\n        n_variables: int,\n    ) -> None:\n        \"\"\"Wrap and set the objective function.\"\"\"\n        self._objective = ObjectiveFunction(\n            func, df, n_variables, bounds=(self.lower_bounds, self.upper_bounds)\n        )\n        if self._keep_history:\n            self._opt.set_min_objective(self._objective.call_with_history)\n        else:\n            self._opt.set_min_objective(self._objective.call)\n\n    def _set_termination_conditions(\n        self, opt_conditions: Mapping[str, Union[int, float]]\n    ) -> None:\n        \"\"\"Validate and set the termination conditions.\"\"\"\n        self._opt_conditions = NLOptConditions(**opt_conditions)\n        if self._opt_conditions.ftol_abs:\n            self._opt.set_ftol_abs(self._opt_conditions.ftol_abs)\n        if self._opt_conditions.ftol_rel:\n            self._opt.set_ftol_rel(self._opt_conditions.ftol_rel)\n        if self._opt_conditions.xtol_abs:\n            self._opt.set_xtol_abs(self._opt_conditions.xtol_abs)\n        if self._opt_conditions.xtol_rel:\n            self._opt.set_xtol_rel(self._opt_conditions.xtol_rel)\n        if self._opt_conditions.max_time:\n            self._opt.set_maxtime(self._opt_conditions.max_time)\n        if self._opt_conditions.max_eval:\n            self._opt.set_maxeval(self._opt_conditions.max_eval)\n        if self._opt_conditions.stop_val:\n            self._opt.set_stopval(self._opt_conditions.stop_val)\n\n    def _set_algorithm_parameters(self, opt_parameters: Mapping) -> None:\n        self._opt_parameters = opt_parameters\n        unrecognised = []\n        for k, v in self.opt_parameters.items():\n            if self._opt.has_param(k):\n                self._opt.set_param(k, v)\n            elif k == \"initial_step\":\n                self._opt.set_initial_step(v)\n            else:\n                unrecognised.append(k)\n\n        if unrecognised:\n            raise OptimisationParametersError(\n                f\"Unrecognised algorithm parameter(s): {str(unrecognised)[1:-1]}\"\n            )",
  "def _check_algorithm(algorithm: AlgorithmType) -> Algorithm:\n    \"\"\"Validate, and convert, the given algorithm.\"\"\"\n    if isinstance(algorithm, str):\n        return Algorithm[algorithm]\n    elif isinstance(algorithm, Algorithm):\n        return algorithm\n    raise TypeError(f\"Cannot set algorithm with object of type '{type(algorithm)}'.\")",
  "def _check_bounds(n_dims: int, new_bounds: np.ndarray) -> None:\n    \"\"\"Validate that the bounds have the correct dimensions.\"\"\"\n    if new_bounds.ndim != 1 or new_bounds.size != n_dims:\n        raise ValueError(\n            f\"Cannot set bounds with shape '{new_bounds.shape}', \"\n            f\"array must be one dimensional and have '{n_dims}' elements.\"\n        )",
  "def _initial_guess_from_bounds(lower: np.ndarray, upper: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Derive an initial guess for the optimiser.\n\n    Takes the center of the bounds for each parameter.\n    \"\"\"\n    bounds = np.array([lower, upper])\n    # bounds are +/- inf by default, change to real numbers so\n    # we can take an average\n    np.nan_to_num(\n        bounds,\n        posinf=np.finfo(np.float64).max,\n        neginf=np.finfo(np.float64).min,\n        copy=False,\n    )\n    return np.mean(bounds, axis=0)",
  "def _process_nlopt_result(opt: nlopt.opt, algorithm: Algorithm) -> None:\n    \"\"\"\n    Communicate to the user the NLopt optimisation result.\n\n    Usually this would be called when dealing with an error in an\n    optimisation loop.\n\n    Parameters\n    ----------\n    opt:\n        The optimiser to check\n    algorithm:\n        The optimisation algorithm\n    \"\"\"\n    result = opt.last_optimize_result()\n    message = None\n    log_func = bluemira_warn\n    if result == nlopt.MAXEVAL_REACHED:\n        message = \"optimiser succeeded but stopped at the maximum number of evaluations.\"\n        if algorithm is Algorithm.ISRES:\n            log_func = bluemira_debug\n            message += f\"\\nThis is expected for the {Algorithm.ISRES.name} algorithm.\"\n    elif result == nlopt.MAXTIME_REACHED:\n        message = \"optimiser succeeded but stopped at the maximum duration.\"\n    elif result == nlopt.ROUNDOFF_LIMITED:\n        message = (\n            \"optimiser was halted due to round-off errors.\\n\"\n            \"Returning last optimisation parameterisation.\"\n        )\n    elif result == nlopt.FAILURE:\n        message = \"optimiser failed real hard...\"\n    elif result == nlopt.INVALID_ARGS:\n        message = \"optimiser failed because of invalid arguments.\"\n    elif result == nlopt.OUT_OF_MEMORY:\n        message = \"optimiser failed because it ran out of memory.\"\n    elif result == nlopt.FORCED_STOP:\n        message = \"optimiser failed because of a forced stop.\"\n    if message:\n        log_func(f\"\\n{message}\\n\")",
  "def __init__(\n        self,\n        algorithm: AlgorithmType,\n        n_variables: int,\n        f_objective: ObjectiveCallable,\n        df_objective: Optional[OptimiserCallable] = None,\n        opt_conditions: Optional[Mapping[str, Union[int, float]]] = None,\n        opt_parameters: Optional[Mapping[str, Any]] = None,\n        keep_history: bool = False,\n    ):\n        opt_conditions = {} if opt_conditions is None else opt_conditions\n        opt_parameters = {} if opt_parameters is None else opt_parameters\n        self._keep_history = keep_history\n\n        self._set_algorithm(algorithm)\n        self._opt = nlopt.opt(_NLOPT_ALG_MAPPING[self.algorithm], n_variables)\n        self._set_objective_function(f_objective, df_objective, n_variables)\n        self._set_termination_conditions(opt_conditions)\n        self._set_algorithm_parameters(opt_parameters)\n        self._eq_constraints: List[Constraint] = []\n        self._ineq_constraints: List[Constraint] = []",
  "def algorithm(self) -> Algorithm:\n        \"\"\"Return the optimiser's algorithm.\"\"\"\n        return self._algorithm",
  "def opt_conditions(self) -> Dict[str, float]:\n        \"\"\"Return the optimiser's stopping conditions.\"\"\"\n        return self._opt_conditions.to_dict()",
  "def opt_parameters(self) -> Mapping[str, Union[int, float]]:\n        \"\"\"Return the optimiser algorithms's parameters.\"\"\"\n        return self._opt_parameters",
  "def lower_bounds(self) -> np.ndarray:\n        \"\"\"Return the lower bounds for the optimisation parameters.\"\"\"\n        return self._opt.get_lower_bounds().copy()",
  "def upper_bounds(self) -> np.ndarray:\n        \"\"\"Return the upper bounds for the optimisation parameters.\"\"\"\n        return self._opt.get_upper_bounds().copy()",
  "def add_eq_constraint(\n        self,\n        f_constraint: OptimiserCallable,\n        tolerance: np.ndarray,\n        df_constraint: Optional[OptimiserCallable] = None,\n    ) -> None:\n        \"\"\"\n        Add an equality constraint.\n\n        See :meth:`~bluemira.optimisation._optimiser.Optimiser.add_eq_constraint`.\n        \"\"\"\n        if self.algorithm not in [Algorithm.SLSQP, Algorithm.COBYLA, Algorithm.ISRES]:\n            raise OptimisationError(\n                f\"Algorithm '{self.algorithm.name}' does not support equality \"\n                f\"constraints.\"\n            )\n        constraint = Constraint(\n            ConstraintType.EQUALITY,\n            f_constraint,\n            tolerance,\n            df_constraint,\n            bounds=(self.lower_bounds, self.upper_bounds),\n        )\n        self._opt.add_equality_mconstraint(constraint.call, constraint.tolerance)\n        self._eq_constraints.append(constraint)",
  "def add_ineq_constraint(\n        self,\n        f_constraint: OptimiserCallable,\n        tolerance: np.ndarray,\n        df_constraint: Optional[OptimiserCallable] = None,\n    ) -> None:\n        \"\"\"\n        Add an inequality constraint.\n\n        See :meth:`~bluemira.optimisation._optimiser.Optimiser.add_ineq_constraint`.\n        \"\"\"\n        if self.algorithm not in [Algorithm.SLSQP, Algorithm.COBYLA, Algorithm.ISRES]:\n            raise OptimisationError(\n                f\"Algorithm '{self.algorithm.name}' does not support inequality \"\n                f\"constraints.\"\n            )\n        constraint = Constraint(\n            ConstraintType.INEQUALITY,\n            f_constraint,\n            tolerance,\n            df_constraint,\n            bounds=(self.lower_bounds, self.upper_bounds),\n        )\n        self._opt.add_inequality_mconstraint(constraint.call, constraint.tolerance)\n        self._ineq_constraints.append(constraint)",
  "def optimise(self, x0: Optional[np.ndarray] = None) -> OptimiserResult:\n        \"\"\"\n        Run the optimisation.\n\n        See :meth:`~bluemira.optimisation._optimiser.Optimiser.optimise`.\n        \"\"\"\n        if x0 is None:\n            x0 = _initial_guess_from_bounds(self.lower_bounds, self.upper_bounds)\n\n        try:\n            x_star = self._opt.optimize(x0)\n            f_x = self._objective.f(x_star)\n        except nlopt.RoundoffLimited:\n            # It's likely that the last call was still a reasonably good solution.\n            x_star, f_x = self._get_previous_iter_result()\n        except OptVariablesError:\n            # Probably still some rounding errors due to numerical gradients\n            # It's likely that the last call was still a reasonably good solution.\n            bluemira_warn(\"Badly behaved numerical gradients are causing trouble...\")\n            x_star, f_x = self._get_previous_iter_result()\n        except RuntimeError as error:\n            # Usually \"more than iter SQP iterations\"\n            _process_nlopt_result(self._opt, self.algorithm)\n            raise OptimisationError(str(error))\n        except KeyboardInterrupt:\n            _process_nlopt_result(self._opt, self.algorithm)\n            raise KeyboardInterrupt(\n                \"The optimisation was halted by the user. Please check \"\n                \"your optimisation problem and termination conditions.\"\n            )\n\n        _process_nlopt_result(self._opt, self.algorithm)\n        return OptimiserResult(\n            f_x=f_x,\n            x=x_star,\n            n_evals=self._opt.get_numevals(),\n            history=self._objective.history,\n        )",
  "def set_lower_bounds(self, bounds: npt.ArrayLike) -> None:\n        \"\"\"\n        Set the lower bound for each optimisation parameter.\n\n        See :meth:`~bluemira.optimisation._optimiser.Optimiser.set_lower_bounds`.\n        \"\"\"\n        bounds = np.array(bounds)\n        _check_bounds(self._opt.get_dimension(), bounds)\n        self._opt.set_lower_bounds(bounds)\n        # As we use the optimisation variable bounds when calculating an\n        # approximate derivative, we must set the new bounds on the\n        # objective function and constraints.\n        self._objective.set_approx_derivative_lower_bound(bounds)\n        for constraint in self._eq_constraints + self._ineq_constraints:\n            constraint.set_approx_derivative_lower_bound(bounds)",
  "def set_upper_bounds(self, bounds: npt.ArrayLike) -> None:\n        \"\"\"\n        Set the upper bound for each optimisation parameter.\n\n        See :meth:`~bluemira.optimisation._optimiser.Optimiser.set_upper_bounds`.\n        \"\"\"\n        bounds = np.array(bounds)\n        _check_bounds(self._opt.get_dimension(), bounds)\n        self._opt.set_upper_bounds(bounds)\n        # As we use the optimisation variable bounds when calculating an\n        # approximate derivative, we must set the new bounds on the\n        # objective function and constraints.\n        self._objective.set_approx_derivative_upper_bound(bounds)\n        for constraint in self._eq_constraints + self._ineq_constraints:\n            constraint.set_approx_derivative_upper_bound(bounds)",
  "def _get_previous_iter_result(self) -> Tuple[np.ndarray, float]:\n        \"\"\"Get the parameterisation and result from the previous iteration.\"\"\"\n        x_star = self._objective.prev_iter\n        f_x = self._objective.f(x_star) if x_star.size else np.inf\n        return x_star, f_x",
  "def _handle_round_off_error(self) -> Tuple[np.ndarray, float]:\n        \"\"\"\n        Handle a round-off error occurring in an optimisation.\n\n        It's likely the last call was a decent solution, so return that\n        (with a warning).\n        \"\"\"\n        bluemira_warn(\n            \"optimisation: round-off error occurred. \"\n            \"Returning last optimisation parameterisation.\"\n        )\n        x_star = self._objective.prev_iter\n        f_x = self._objective.f(x_star) if x_star.size else np.inf\n        return x_star, f_x",
  "def _set_algorithm(self, alg: AlgorithmType) -> None:\n        \"\"\"Set the optimiser's algorithm.\"\"\"\n        self._algorithm = _check_algorithm(alg)",
  "def _set_objective_function(\n        self,\n        func: ObjectiveCallable,\n        df: Union[None, OptimiserCallable],\n        n_variables: int,\n    ) -> None:\n        \"\"\"Wrap and set the objective function.\"\"\"\n        self._objective = ObjectiveFunction(\n            func, df, n_variables, bounds=(self.lower_bounds, self.upper_bounds)\n        )\n        if self._keep_history:\n            self._opt.set_min_objective(self._objective.call_with_history)\n        else:\n            self._opt.set_min_objective(self._objective.call)",
  "def _set_termination_conditions(\n        self, opt_conditions: Mapping[str, Union[int, float]]\n    ) -> None:\n        \"\"\"Validate and set the termination conditions.\"\"\"\n        self._opt_conditions = NLOptConditions(**opt_conditions)\n        if self._opt_conditions.ftol_abs:\n            self._opt.set_ftol_abs(self._opt_conditions.ftol_abs)\n        if self._opt_conditions.ftol_rel:\n            self._opt.set_ftol_rel(self._opt_conditions.ftol_rel)\n        if self._opt_conditions.xtol_abs:\n            self._opt.set_xtol_abs(self._opt_conditions.xtol_abs)\n        if self._opt_conditions.xtol_rel:\n            self._opt.set_xtol_rel(self._opt_conditions.xtol_rel)\n        if self._opt_conditions.max_time:\n            self._opt.set_maxtime(self._opt_conditions.max_time)\n        if self._opt_conditions.max_eval:\n            self._opt.set_maxeval(self._opt_conditions.max_eval)\n        if self._opt_conditions.stop_val:\n            self._opt.set_stopval(self._opt_conditions.stop_val)",
  "def _set_algorithm_parameters(self, opt_parameters: Mapping) -> None:\n        self._opt_parameters = opt_parameters\n        unrecognised = []\n        for k, v in self.opt_parameters.items():\n            if self._opt.has_param(k):\n                self._opt.set_param(k, v)\n            elif k == \"initial_step\":\n                self._opt.set_initial_step(v)\n            else:\n                unrecognised.append(k)\n\n        if unrecognised:\n            raise OptimisationParametersError(\n                f\"Unrecognised algorithm parameter(s): {str(unrecognised)[1:-1]}\"\n            )",
  "class ConstraintType(enum.Enum):\n    \"\"\"Enumeration of constraint types.\"\"\"\n\n    EQUALITY = enum.auto()\n    INEQUALITY = enum.auto()",
  "class _NloptFunction(abc.ABC):\n    \"\"\"\n    Base class for NLOpt objective/constraint functions.\n\n    Implements the ability to calculate a numerical gradient, if an\n    analytical one is not provided.\n    \"\"\"\n\n    def __init__(\n        self,\n        f: Callable[[np.ndarray], _FloatOrArrayT],\n        bounds: Tuple[_FloatOrArrayT, _FloatOrArrayT],\n    ):\n        self.f = f\n        self.f0: Union[float, np.ndarray] = 0\n        self.bounds = bounds\n\n    def _approx_derivative(self, x: np.ndarray) -> np.ndarray:\n        return approx_derivative(self.f, x, bounds=self.bounds, f0=self.f0)\n\n    def set_approx_derivative_lower_bound(self, lower_bound: np.ndarray) -> None:\n        \"\"\"Set the lower bounds for use in derivative approximation.\"\"\"\n        self.bounds = (lower_bound, self.bounds[1])\n\n    def set_approx_derivative_upper_bound(self, upper_bound: np.ndarray) -> None:\n        \"\"\"Set the upper bounds for use in derivative approximation.\"\"\"\n        self.bounds = (self.bounds[0], upper_bound)",
  "class ObjectiveFunction(_NloptFunction):\n    \"\"\"\n    Holds an objective function for an NLOpt optimiser.\n\n    Adapts the given objective function, and optional derivative, to a\n    form understood by NLOpt.\n\n    If no optimiser derivative is given, and the algorithm is gradient\n    based, a numerical approximation of the gradient is calculated.\n    \"\"\"\n\n    f: ObjectiveCallable\n    f0: float\n\n    def __init__(\n        self,\n        f: ObjectiveCallable,\n        df: Optional[OptimiserCallable],\n        n_variables: int,\n        bounds: Tuple[_FloatOrArrayT, _FloatOrArrayT] = (-np.inf, np.inf),\n    ):\n        super().__init__(f, bounds)\n        self.df = df if df is not None else self._approx_derivative\n        self.history: List[Tuple[np.ndarray, float]] = []\n        self.prev_iter = np.zeros(n_variables, dtype=float)\n\n    def call(self, x: np.ndarray, grad: np.ndarray) -> float:\n        \"\"\"Execute the NLOpt objective function.\"\"\"\n        if not np.any(np.isnan(x)):\n            self._store_x(x)\n        return self._call_inner(x, grad)\n\n    def call_with_history(self, x: np.ndarray, grad: np.ndarray) -> float:\n        \"\"\"Execute the NLOpt objective function, recording the iteration history.\"\"\"\n        f_x = self._call_inner(x, grad)\n        self.history.append((np.copy(x), f_x))\n        self.prev_iter = self.history[-1][0]\n        return f_x\n\n    def _call_inner(self, x: np.ndarray, grad: np.ndarray) -> float:\n        \"\"\"Execute the objective function in the form required by NLOpt.\"\"\"\n        # Cache f(x) so we do not need to recalculate it if we're using\n        # an approximate gradient\n        self.f0 = self.f(x)\n        if grad.size > 0:\n            grad[:] = self.df(x)\n        return self.f0\n\n    def _store_x(self, x: np.ndarray) -> None:\n        \"\"\"Store ``x`` in ``self.prev_iter``.\"\"\"\n        # Assign in place to avoid lots of allocations.\n        # Not benchmarked, but may be more efficient...\n        self.prev_iter[:] = x",
  "class Constraint(_NloptFunction):\n    \"\"\"Holder for NLOpt constraint functions.\"\"\"\n\n    f: OptimiserCallable\n    f0: np.ndarray\n\n    def __init__(\n        self,\n        constraint_type: ConstraintType,\n        f: OptimiserCallable,\n        tolerance: np.ndarray,\n        df: Optional[OptimiserCallable] = None,\n        bounds: Tuple[_FloatOrArrayT, _FloatOrArrayT] = (-np.inf, np.inf),\n    ):\n        super().__init__(f, bounds)\n        self.constraint_type = constraint_type\n        self.tolerance = tolerance\n        self.df = df if df is not None else self._approx_derivative\n\n    def call(self, result: np.ndarray, x: np.ndarray, grad: np.ndarray) -> None:\n        \"\"\"\n        Execute the constraint function in the form required by NLOpt.\n\n        https://nlopt.readthedocs.io/en/latest/NLopt_Python_Reference/#vector-valued-constraints\n        \"\"\"\n        # Cache f(x) so we do not need to recalculate it if we're using\n        # an approximate gradient\n        result[:] = self.f(x)\n        self.f0 = result\n        if grad.size > 0:\n            grad[:] = self.df(x)",
  "def __init__(\n        self,\n        f: Callable[[np.ndarray], _FloatOrArrayT],\n        bounds: Tuple[_FloatOrArrayT, _FloatOrArrayT],\n    ):\n        self.f = f\n        self.f0: Union[float, np.ndarray] = 0\n        self.bounds = bounds",
  "def _approx_derivative(self, x: np.ndarray) -> np.ndarray:\n        return approx_derivative(self.f, x, bounds=self.bounds, f0=self.f0)",
  "def set_approx_derivative_lower_bound(self, lower_bound: np.ndarray) -> None:\n        \"\"\"Set the lower bounds for use in derivative approximation.\"\"\"\n        self.bounds = (lower_bound, self.bounds[1])",
  "def set_approx_derivative_upper_bound(self, upper_bound: np.ndarray) -> None:\n        \"\"\"Set the upper bounds for use in derivative approximation.\"\"\"\n        self.bounds = (self.bounds[0], upper_bound)",
  "def __init__(\n        self,\n        f: ObjectiveCallable,\n        df: Optional[OptimiserCallable],\n        n_variables: int,\n        bounds: Tuple[_FloatOrArrayT, _FloatOrArrayT] = (-np.inf, np.inf),\n    ):\n        super().__init__(f, bounds)\n        self.df = df if df is not None else self._approx_derivative\n        self.history: List[Tuple[np.ndarray, float]] = []\n        self.prev_iter = np.zeros(n_variables, dtype=float)",
  "def call(self, x: np.ndarray, grad: np.ndarray) -> float:\n        \"\"\"Execute the NLOpt objective function.\"\"\"\n        if not np.any(np.isnan(x)):\n            self._store_x(x)\n        return self._call_inner(x, grad)",
  "def call_with_history(self, x: np.ndarray, grad: np.ndarray) -> float:\n        \"\"\"Execute the NLOpt objective function, recording the iteration history.\"\"\"\n        f_x = self._call_inner(x, grad)\n        self.history.append((np.copy(x), f_x))\n        self.prev_iter = self.history[-1][0]\n        return f_x",
  "def _call_inner(self, x: np.ndarray, grad: np.ndarray) -> float:\n        \"\"\"Execute the objective function in the form required by NLOpt.\"\"\"\n        # Cache f(x) so we do not need to recalculate it if we're using\n        # an approximate gradient\n        self.f0 = self.f(x)\n        if grad.size > 0:\n            grad[:] = self.df(x)\n        return self.f0",
  "def _store_x(self, x: np.ndarray) -> None:\n        \"\"\"Store ``x`` in ``self.prev_iter``.\"\"\"\n        # Assign in place to avoid lots of allocations.\n        # Not benchmarked, but may be more efficient...\n        self.prev_iter[:] = x",
  "def __init__(\n        self,\n        constraint_type: ConstraintType,\n        f: OptimiserCallable,\n        tolerance: np.ndarray,\n        df: Optional[OptimiserCallable] = None,\n        bounds: Tuple[_FloatOrArrayT, _FloatOrArrayT] = (-np.inf, np.inf),\n    ):\n        super().__init__(f, bounds)\n        self.constraint_type = constraint_type\n        self.tolerance = tolerance\n        self.df = df if df is not None else self._approx_derivative",
  "def call(self, result: np.ndarray, x: np.ndarray, grad: np.ndarray) -> None:\n        \"\"\"\n        Execute the constraint function in the form required by NLOpt.\n\n        https://nlopt.readthedocs.io/en/latest/NLopt_Python_Reference/#vector-valued-constraints\n        \"\"\"\n        # Cache f(x) so we do not need to recalculate it if we're using\n        # an approximate gradient\n        result[:] = self.f(x)\n        self.f0 = result\n        if grad.size > 0:\n            grad[:] = self.df(x)",
  "def cryo_power(\n    s_tf: float,\n    m_cold: float,\n    nucl_heating: float,\n    e_pf_max: float,\n    t_pulse: float,\n    tf_current: float,\n    n_TF: int,\n) -> float:\n    \"\"\"\n    Calculates cryogenic loads (taken from PROCESS)\n\n    Parameters\n    ----------\n    s_tf:\n        TF coil total surface area [m^2]\n    m_cold:\n        Total cold mass [kg]\n    nucl_heating:\n        Total coil nuclear heating [W]\n    e_pf_max:\n        Maximum stored energy in the PF coils [J]\n    t_pulse:\n        Pulse length [s]\n    tf_current:\n        TF coil current per turn [A]\n    n_TF:\n        Number of TF coils\n\n    Returns\n    -------\n    Total power required to cool cryogenic components\n\n    Note\n    ----\n    Author: P J Knight, CCFE, Culham Science Centre\n    D. Slack memo SCMDG 88-5-1-059, LLNL ITER-88-054, Aug. 1988\n    \"\"\"\n    # TODO: Temperature!\n    # Steady-state loads\n    qss = 4.3e-4 * m_cold + 2 * s_tf\n    # AC losses\n    qac = raw_uc(e_pf_max, \"J\", \"kJ\") / t_pulse\n    # Current leads\n    qcl = 13.6e-3 * n_TF * tf_current\n    # Misc. loads (piping and reserves)\n    fmisc = 0.45\n    return (1 + fmisc) * (nucl_heating + qcl + qac + qss)",
  "def He_pumping(  # noqa :N802\n    pressure_in: float,\n    pressure_out: float,\n    t_in: float,\n    t_out: float,\n    blanket_power: float,\n    eta_isen: float,\n    eta_el: float,\n) -> Tuple[float, float]:\n    \"\"\"\n    Calculate the pumping power for helium-cooled blankets.\n\n    Parameters\n    ----------\n    pressure_in:\n        Inlet pressure [Pa]\n    pressure_out:\n        Pressure drop [Pa]\n    t_in:\n        Inlet temperature [K]\n    t_out:\n        Outlet temperature [K]\n    blanket_power:\n        Total blanket power excluding pumping power [W]\n    eta_isen:\n        Isentropic efficiency of the He compressors\n    eta_el:\n        Electrical efficiency of the He compressors\n\n    Returns\n    -------\n    P_pump_is:\n        The isentropic pumping power (added to the working fluid) [W]\n    P_pump_el:\n        The electrical pumping power (parasitic load) [W]\n\n    \\t:math:`T_{in_{comp}} = \\\\dfrac{T_{in_{BB}}}{\\\\dfrac{P}{P-dP}^{\\\\dfrac{\\\\gamma-1}{\\\\gamma}}}`\\n\n    \\t:math:`f_{p} = \\\\dfrac{T_{in_{comp}}}{\\\\eta_{is}dT}\\\\Bigg(\\\\dfrac{P}{P-dP}^{\\\\dfrac{\\\\gamma-1}{\\\\gamma}}-1\\\\Bigg)`\n\n    Notes\n    -----\n    \\t:math:`f_{p} = \\\\dfrac{T_{in_{BB}}}{\\\\eta_{is}dT}\\\\Bigg(1-\\\\dfrac{P-dP}{P}^{\\\\dfrac{\\\\gamma-1}{\\\\gamma}}\\\\Bigg)`\n    **Outputs:**\\n\n    \\t:math:`P_{pump} = \\\\dfrac{f_{p}P_{plasma}}{1-f_p}` [W]\\n\n    \\t:math:`P_{pump,el} = \\\\dfrac{P_{pump}}{\\\\eta_{el}}` [W]\\n\n    **No longer in use:**\n    \\t:math:`f_{pump}=\\\\dfrac{dP}{dTc_P\\\\rho_{av}}`\n    \"\"\"  # noqa :W505\n    d_temp = t_out - t_in\n    t_bb_inlet = t_in\n    # Ideal monoatomic gas - small compression ratios\n    t_comp_inlet = t_bb_inlet / ((pressure_in / pressure_out) ** (2 / 5))\n    # Ivo not sure why can't refind it - probably right but very little\n    # difference ~ 1 K\n    # T_comp_inlet = eta_isen*T_bb_inlet/((P/(P-dP))**(6/15)+eta_isen-1)\n    f_pump = (t_comp_inlet / (eta_isen * d_temp)) * (\n        (pressure_in / pressure_out) ** (2 / 5) - 1\n    )  # kJ/kg\n    p_pump_is = f_pump * blanket_power / (1 - f_pump)\n    p_pump_el = p_pump_is / eta_el\n    return p_pump_is, p_pump_el",
  "def H2O_pumping(  # noqa :N802\n    p_blanket: float, f_pump: float, eta_isen: float, eta_el: float\n) -> Tuple[float, float]:\n    \"\"\"\n    H20-cooling pumping power calculation strategy\n\n    Parameters\n    ----------\n    f_pump:\n        Fraction of thermal power required to pump\n    eta_isen:\n        Isentropic efficiency of the water pumps\n    eta_el:t\n        Electrical efficiency of the water pumps\n\n    Returns\n    -------\n    P_pump_is:\n        The isentropic pumping power (added to the working fluid)\n    P_pump_el:\n        The eletrical pumping power (parasitic load)\n    \"\"\"\n    # TODO: Add proper pump model\n    f_pump /= eta_isen\n\n    p_pump_is = f_pump * p_blanket / (1 - f_pump)\n    p_pump_el = p_pump_is / eta_el\n    return p_pump_is, p_pump_el",
  "def superheated_rankine(\n    blanket_power: float, div_power: float, bb_outlet_temp: float, delta_t_turbine: float\n) -> float:\n    \"\"\"\n    PROCESS C. Harrington correlation. Accounts for low-grade heat penalty.\n    Used for He-cooled blankets. Not applicable to H2O temperatures.\n\n    Parameters\n    ----------\n    blanket_power:\n        Blanket thermal power [W]\n    div_power:\n        Divertor thermal power [W]\n    bb_outlet_temp:\n        Blanket outlet temperature [K]\n    delta_t_turbine:\n        Turbine inlet temperature drop [K]\n\n    Returns\n    -------\n    Efficiency of a superheated Rankine cycle\n    \"\"\"\n    t_turb = bb_outlet_temp - delta_t_turbine\n    if t_turb < 657 or t_turb > 915:\n        bluemira_warn(\"BoP turbine inlet temperature outside range of validity.\")\n    f_lgh = div_power / (blanket_power + div_power)\n    delta_eta = 0.339 * f_lgh\n    return 0.1802 * np.log(t_turb) - 0.7823 - delta_eta",
  "class SuperSankey(Sankey):\n    \"\"\"\n    A sub-class of the Sankey diagram class from matplotlib, which is capable\n    of connecting two blocks, instead of just one. This is done using a cute\n    sledgehammer approach, using optimisation. Basically, the Sankey object\n    is quite complex, and it makes it very hard to calculate the exact lengths\n    required to connect two sub-diagrams.\n    \"\"\"\n\n    def add(  # noqa :D102\n        self,\n        patchlabel=\"\",\n        flows=None,\n        orientations=None,\n        labels=\"\",\n        trunklength=1.0,\n        pathlengths=0.25,\n        prior=None,\n        future=None,\n        connect=(0, 0),\n        rotation=0,\n        **kwargs,\n    ):\n        __doc__ = super().__doc__  # noqa :F841\n        # Here we first check if the \"add\" method has received arguments that\n        # the Sankey class can't handle.\n        if future is None:\n            # There is only one connection, Sankey knows how to do this\n            super().add(\n                patchlabel,\n                flows,\n                orientations,\n                labels,\n                trunklength,\n                pathlengths,\n                prior,\n                connect,\n                rotation,\n                **kwargs,\n            )\n        else:\n            # There are two connections, use new method\n            self._double_connect(\n                patchlabel,\n                flows,\n                orientations,\n                labels,\n                trunklength,\n                pathlengths,\n                prior,\n                future,\n                connect,\n                rotation,\n                **kwargs,\n            )\n\n    def _double_connect(\n        self,\n        patchlabel,\n        flows,\n        orientations,\n        labels,\n        trunklength,\n        pathlengths,\n        prior,\n        future,\n        connect,\n        rotation,\n        **kwargs,\n    ):\n        \"\"\"\n        Handles two connections in a Sankey diagram.\n\n        Parameters\n        ----------\n        future: int\n            The index of the diagram to connect to\n        connect: List[Tuple]\n            The list of (int, int) connections.\n            - connect[0] is a (prior, this) tuple indexing the flow of the\n            prior diagram and the flow of this diagram to connect.\n            - connect[1] is a (future, this) tuple indexing of the flow of the\n            future diagram and the flow of this diagram to connect.\n\n        See Also\n        --------\n        Sankey.add for a full description of the various args and kwargs\n\n        \"\"\"\n        # Get the optimum deltas\n        dx, dy = self._opt_connect(\n            flows, orientations, prior, future, connect, trunklength=trunklength\n        )\n        # Replace\n        pathlengths[0] = dx\n        pathlengths[-1] = dy\n        self.add(\n            patchlabel=patchlabel,\n            labels=labels,\n            flows=flows,\n            orientations=orientations,\n            prior=prior,\n            connect=connect[0],\n            trunklength=trunklength,\n            pathlengths=pathlengths,\n            rotation=rotation,\n            facecolor=kwargs.get(\"facecolor\", None),\n        )\n\n    def _opt_connect(self, flows, orient, prior, future, connect, trunklength):\n        \"\"\"\n        Optimises the second connection between Sankey diagrams.\n\n        Returns\n        -------\n        dx: float\n            The x pathlength to use to match the tips\n        dy:float\n            The y pathlength to use to match the tips\n\n        Notes\n        -----\n        This is because Sankey is very complicated, and makes it hard to work\n        out the positions of things prior to adding them to the diagrams.\n        Because we are bizarrely using a plotting function as a minimisation\n        objective, we need to make sure we clean the plot on every call.\n        \"\"\"\n        future_index, this_f_index = connect[1]\n        labels = [None] * len(flows)\n        pathlengths = [0] * len(flows)\n\n        # Make a local copy of the Sankey.extent attribute to override any\n        # modifications during optimisation\n        extent = deepcopy(self.extent)\n\n        def minimise_dxdy(x_opt):\n            \"\"\"\n            Minimisation function for the spatial difference between the target\n            tip and the actual tip.\n\n            Parameters\n            ----------\n            x_opt: array_like\n                The vector of d_x, d_y delta-vectors to match tip positions\n\n            Returns\n            -------\n            delta: float\n                The sum of the absolute differences\n            \"\"\"\n            tip2 = self.diagrams[future].tips[future_index]\n            pathlengths[0] = x_opt[0]\n            pathlengths[-1] = x_opt[1]\n            self.add(\n                trunklength=trunklength,\n                pathlengths=pathlengths,\n                flows=flows,\n                prior=prior,\n                connect=connect[0],\n                orientations=orient,\n                labels=labels,\n                facecolor=\"#00000000\",\n            )\n            new_tip = self.diagrams[-1].tips[this_f_index].copy()\n            # Clean sankey plot\n            self.diagrams.pop()\n            self.ax.patches[-1].remove()\n            return np.sum(np.abs(tip2 - new_tip))\n\n        x0 = np.zeros(2)\n        result = minimize(minimise_dxdy, x0, method=\"SLSQP\")\n        self.extent = extent  # Finish clean-up\n        return result.x",
  "class BalanceOfPlantPlotter:\n    \"\"\"\n    The plotting object for the BalanceOfPlant system. Builds a relatively\n    complicated Sankey diagram, connecting the various flows of energy in the\n    reactor.\n    \"\"\"\n\n    plot_options = deepcopy(BALANCE_PLOT_DEFAULTS)\n\n    def __init__(self, **kwargs):\n        self.plot_options = {**self.plot_options, **kwargs}\n        self.fig = None\n        self.sankey = None\n\n    def _scale_flows(self, flow_dict):\n        plot_unit = self.plot_options.get(\"unit\", \"MW\")\n        flow_unit = \"W\"\n\n        for k, v in flow_dict.items():\n            flow_dict[k] = [raw_uc(vi, flow_unit, plot_unit) for vi in v]\n        return flow_dict\n\n    def plot(self, flow_dict, title=None):\n        \"\"\"\n        Plots the BalanceOfPlant system, based on the inputs and flows.\n\n        Parameters\n        ----------\n        inputs: dict\n            The inputs to BalanceOfPlant (used here to format the title)\n        op_mode: str\n            The operation mode of the reactor\n        flow_dict: dict\n            The dictionary of flows for each of the Sankey diagrams.\n        \"\"\"\n        flow_dict = self._scale_flows(flow_dict)\n        # Build the base figure object\n        self.fig = plt.figure(\n            figsize=self.plot_options[\"figsize\"],\n            facecolor=self.plot_options[\"facecolor\"],\n        )\n        ax = self.fig.add_subplot(1, 1, 1, xticks=[], yticks=[])\n        plt.axis(\"off\")\n\n        self.sankey = SuperSankey(\n            ax=ax,\n            scale=self.plot_options[\"scale\"],\n            format=self.plot_options[\"format\"],\n            unit=self.plot_options[\"unit\"],\n            gap=self.plot_options[\"gap\"],\n            radius=self.plot_options[\"radius\"],\n            shoulder=self.plot_options[\"shoulder\"],\n            head_angle=self.plot_options[\"head_angle\"],\n        )\n        self._build_diagram(flow_dict)\n        self._polish()\n        self.fig.suptitle(\n            title, color=self.plot_options[\"font_color\"], fontsize=24, weight=\"bold\"\n        )\n\n    def _build_diagram(self, flow_dict):\n        \"\"\"\n        Builds the Sankey diagram. This is much more verbose than looping over\n        some structs, but that's how it used to be and it was hard to modify.\n        This is easier to read and modify.\n        \"\"\"\n        trunk_length = self.plot_options[\"trunk_length\"]\n        l_s = self.plot_options[\"standard_length\"]\n        l_m = self.plot_options[\"medium_length\"]\n\n        # 0: Plasma\n        self.sankey.add(\n            patchlabel=\"Plasma\",\n            labels=[\"Fusion Power\", None, \"Neutrons\", \"Alphas + Aux\"],\n            flows=flow_dict[\"Plasma\"],\n            orientations=[0, -1, 0, -1],\n            prior=None,\n            connect=None,\n            trunklength=trunk_length,\n            pathlengths=[l_m, l_s / 1.5, l_s, l_s],\n            facecolor=BLUEMIRA_PALETTE[\"blue\"].as_hex(),\n        )\n        # 1: H&CD (first block)\n        self.sankey.add(\n            patchlabel=\"H&CD\",\n            labels=[\"\", \"H&CD power\", \"Losses\"],\n            flows=flow_dict[\"H&CD\"],\n            orientations=[-1, 1, -1],\n            prior=0,\n            connect=(1, 1),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_s / 1.5, l_s],\n            facecolor=BLUEMIRA_PALETTE[\"pink\"].as_hex(),\n        )\n        # 2: Neutrons\n        self.sankey.add(\n            patchlabel=\"Neutrons\",\n            labels=[None, \"Energy Multiplication\", \"Blanket n\", \"Divertor n\", \"Aux n\"],\n            flows=flow_dict[\"Neutrons\"],\n            orientations=[0, 1, 0, -1, -1],\n            prior=0,\n            connect=(2, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_s, l_s, 3 * l_m, l_m],\n            facecolor=BLUEMIRA_PALETTE[\"orange\"].as_hex(),\n        )\n        # 3: Radiation and separatrix\n        self.sankey.add(\n            patchlabel=\"Radiation and\\nseparatrix\",\n            labels=[None, \"\", \"Divertor rad and\\n charged p\"],\n            flows=flow_dict[\"Radiation and \\nseparatrix\"],\n            orientations=[1, 0, -1],\n            prior=0,\n            connect=(3, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_s, l_s],\n            facecolor=BLUEMIRA_PALETTE[\"red\"].as_hex(),\n        )\n        # 4: Blanket\n        self.sankey.add(\n            patchlabel=\"Blanket\",\n            labels=[None, \"\", \"\", \"Decay heat\", \"\"],\n            flows=flow_dict[\"Blanket\"],\n            orientations=[0, -1, -1, 1, 0],\n            prior=2,\n            connect=(2, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_s, l_s, l_s, l_s],\n            facecolor=BLUEMIRA_PALETTE[\"yellow\"].as_hex(),\n        )\n        # 5: Divertor\n        self.sankey.add(\n            patchlabel=\"Divertor\",\n            labels=[None, None, \"\"],\n            flows=flow_dict[\"Divertor\"],\n            orientations=[1, 0, 0],\n            prior=2,\n            connect=(3, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_m, l_s, l_s],\n            facecolor=BLUEMIRA_PALETTE[\"cyan\"].as_hex(),\n        )\n        # 6: First wall\n        self.sankey.add(\n            patchlabel=\"First wall\",\n            labels=[None, \"Auxiliary \\n FW\", None],\n            flows=flow_dict[\"First wall\"],\n            orientations=[0, -1, 1],\n            prior=3,\n            future=4,\n            connect=[(1, 0), (1, 2)],\n            trunklength=trunk_length,\n            pathlengths=[0, l_s, 0],\n            facecolor=BLUEMIRA_PALETTE[\"grey\"].as_hex(),\n        )\n        # 7: BoP\n        self.sankey.add(\n            patchlabel=\"BoP\",\n            labels=[None, None, \"Losses\", None],\n            flows=flow_dict[\"BoP\"],\n            orientations=[0, -1, -1, 0],\n            prior=4,\n            connect=(4, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_m, l_m, 0],\n            facecolor=BLUEMIRA_PALETTE[\"purple\"].as_hex(),\n        )\n        # 8: Electricity\n        # Check if we have net electric power\n        labels = [\n            \"$P_{el}$\",\n            \"T plant\",\n            \"P_oth...\",\n            \"Cryoplant\",\n            \"Magnets\",\n            None,\n            None,\n            \"BB Pumping \\n electrical \\n power\",\n            \"\",\n        ]\n        orientations = [0, -1, -1, -1, -1, -1, -1, -1, 0]\n\n        if flow_dict[\"Electricity\"][-1] > 0:\n            # Conversely, this means \"net electric loss\"\n            labels[-1] = \"Grid\"\n            orientations[-1] = 1\n\n        self.sankey.add(\n            patchlabel=\"Electricity\",\n            labels=labels,\n            flows=flow_dict[\"Electricity\"],\n            orientations=orientations,\n            prior=7,\n            connect=(3, 0),\n            trunklength=trunk_length,\n            pathlengths=[\n                l_m,\n                2 * l_m,\n                3 * l_m,\n                4 * l_m,\n                5 * l_m,\n                7 * l_m,\n                5 * l_m,\n                3 * l_m,\n                l_s,\n            ],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n        # 9: H&CD return leg\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, \"H&CD Power\"],\n            flows=flow_dict[\"_H&CD loop\"],\n            orientations=[-1, 0],\n            prior=8,\n            connect=(5, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s / 2, 7 * l_m],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n        # 10: Divertor (second block)\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, None],\n            flows=flow_dict[\"_Divertor 2\"],\n            orientations=[1, 0],\n            prior=3,\n            future=5,\n            connect=[(2, 0), (1, 1)],\n            trunklength=trunk_length,\n            pathlengths=[0, 0],\n            facecolor=BLUEMIRA_PALETTE[\"cyan\"].as_hex(),\n        )\n        # 11: H&CD return leg (second half)\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, None],\n            flows=flow_dict[\"_H&CD loop 2\"],\n            orientations=[-1, 0],\n            prior=9,\n            future=1,\n            connect=[(1, 0), (0, 1)],\n            trunklength=trunk_length,\n            pathlengths=[0, 0],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n        # 12: Divertor back into BoP\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, \"\", \"\"],\n            flows=flow_dict[\"_DIV to BOP\"],\n            orientations=[0, -1, 1],\n            prior=5,\n            future=7,\n            connect=[(2, 0), (1, 2)],\n            trunklength=trunk_length,\n            pathlengths=[0, l_s / 2, 0],\n            facecolor=BLUEMIRA_PALETTE[\"cyan\"].as_hex(),\n        )\n        # 13: BB electrical pumping loss turn leg\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, \"Losses\", \"BB coolant \\n pumping\"],\n            flows=flow_dict[\"_BB coolant loop turn\"],\n            orientations=[0, 0, -1],\n            prior=8,\n            connect=(7, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_s, l_m * 3],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n        # 14: BB electrical pumping return leg into blanket\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, None],\n            flows=flow_dict[\"_BB coolant loop blanket\"],\n            orientations=[0, -1],\n            prior=13,\n            future=4,\n            connect=[(2, 0), (2, 1)],\n            trunklength=trunk_length,\n            pathlengths=[0, 0],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n        # 15: Divertor electrical pumping loss turn leg\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, \"Losses\", \"Div coolant \\n pumping\"],\n            flows=flow_dict[\"_DIV coolant loop turn\"],\n            orientations=[0, 0, -1],\n            prior=8,\n            connect=(6, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_s / 2, l_m],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n        # 16: Divertor electrical pumping return into divertor\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, None],\n            flows=flow_dict[\"_DIV coolant loop divertor\"],\n            orientations=[0, -1],\n            prior=15,\n            future=12,\n            connect=[(2, 0), (1, 1)],\n            trunklength=trunk_length,\n            pathlengths=[0, 0],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n\n    def _polish(self):\n        \"\"\"\n        Finish up and polish figure, and format text\n        \"\"\"\n        diagrams = self.sankey.finish()\n        for diagram in diagrams:\n            diagram.text.set_fontweight(self.plot_options[\"font_weight\"])\n            diagram.text.set_fontsize(self.plot_options[\"font_size\"])\n            diagram.text.set_color(self.plot_options[\"font_color\"])\n            for text in diagram.texts:\n                text.set_fontsize(self.plot_options[\"flow_font_size\"])\n                text.set_color(self.plot_options[\"font_color\"])\n\n        self.fig.tight_layout()",
  "def add(  # noqa :D102\n        self,\n        patchlabel=\"\",\n        flows=None,\n        orientations=None,\n        labels=\"\",\n        trunklength=1.0,\n        pathlengths=0.25,\n        prior=None,\n        future=None,\n        connect=(0, 0),\n        rotation=0,\n        **kwargs,\n    ):\n        __doc__ = super().__doc__  # noqa :F841\n        # Here we first check if the \"add\" method has received arguments that\n        # the Sankey class can't handle.\n        if future is None:\n            # There is only one connection, Sankey knows how to do this\n            super().add(\n                patchlabel,\n                flows,\n                orientations,\n                labels,\n                trunklength,\n                pathlengths,\n                prior,\n                connect,\n                rotation,\n                **kwargs,\n            )\n        else:\n            # There are two connections, use new method\n            self._double_connect(\n                patchlabel,\n                flows,\n                orientations,\n                labels,\n                trunklength,\n                pathlengths,\n                prior,\n                future,\n                connect,\n                rotation,\n                **kwargs,\n            )",
  "def _double_connect(\n        self,\n        patchlabel,\n        flows,\n        orientations,\n        labels,\n        trunklength,\n        pathlengths,\n        prior,\n        future,\n        connect,\n        rotation,\n        **kwargs,\n    ):\n        \"\"\"\n        Handles two connections in a Sankey diagram.\n\n        Parameters\n        ----------\n        future: int\n            The index of the diagram to connect to\n        connect: List[Tuple]\n            The list of (int, int) connections.\n            - connect[0] is a (prior, this) tuple indexing the flow of the\n            prior diagram and the flow of this diagram to connect.\n            - connect[1] is a (future, this) tuple indexing of the flow of the\n            future diagram and the flow of this diagram to connect.\n\n        See Also\n        --------\n        Sankey.add for a full description of the various args and kwargs\n\n        \"\"\"\n        # Get the optimum deltas\n        dx, dy = self._opt_connect(\n            flows, orientations, prior, future, connect, trunklength=trunklength\n        )\n        # Replace\n        pathlengths[0] = dx\n        pathlengths[-1] = dy\n        self.add(\n            patchlabel=patchlabel,\n            labels=labels,\n            flows=flows,\n            orientations=orientations,\n            prior=prior,\n            connect=connect[0],\n            trunklength=trunklength,\n            pathlengths=pathlengths,\n            rotation=rotation,\n            facecolor=kwargs.get(\"facecolor\", None),\n        )",
  "def _opt_connect(self, flows, orient, prior, future, connect, trunklength):\n        \"\"\"\n        Optimises the second connection between Sankey diagrams.\n\n        Returns\n        -------\n        dx: float\n            The x pathlength to use to match the tips\n        dy:float\n            The y pathlength to use to match the tips\n\n        Notes\n        -----\n        This is because Sankey is very complicated, and makes it hard to work\n        out the positions of things prior to adding them to the diagrams.\n        Because we are bizarrely using a plotting function as a minimisation\n        objective, we need to make sure we clean the plot on every call.\n        \"\"\"\n        future_index, this_f_index = connect[1]\n        labels = [None] * len(flows)\n        pathlengths = [0] * len(flows)\n\n        # Make a local copy of the Sankey.extent attribute to override any\n        # modifications during optimisation\n        extent = deepcopy(self.extent)\n\n        def minimise_dxdy(x_opt):\n            \"\"\"\n            Minimisation function for the spatial difference between the target\n            tip and the actual tip.\n\n            Parameters\n            ----------\n            x_opt: array_like\n                The vector of d_x, d_y delta-vectors to match tip positions\n\n            Returns\n            -------\n            delta: float\n                The sum of the absolute differences\n            \"\"\"\n            tip2 = self.diagrams[future].tips[future_index]\n            pathlengths[0] = x_opt[0]\n            pathlengths[-1] = x_opt[1]\n            self.add(\n                trunklength=trunklength,\n                pathlengths=pathlengths,\n                flows=flows,\n                prior=prior,\n                connect=connect[0],\n                orientations=orient,\n                labels=labels,\n                facecolor=\"#00000000\",\n            )\n            new_tip = self.diagrams[-1].tips[this_f_index].copy()\n            # Clean sankey plot\n            self.diagrams.pop()\n            self.ax.patches[-1].remove()\n            return np.sum(np.abs(tip2 - new_tip))\n\n        x0 = np.zeros(2)\n        result = minimize(minimise_dxdy, x0, method=\"SLSQP\")\n        self.extent = extent  # Finish clean-up\n        return result.x",
  "def __init__(self, **kwargs):\n        self.plot_options = {**self.plot_options, **kwargs}\n        self.fig = None\n        self.sankey = None",
  "def _scale_flows(self, flow_dict):\n        plot_unit = self.plot_options.get(\"unit\", \"MW\")\n        flow_unit = \"W\"\n\n        for k, v in flow_dict.items():\n            flow_dict[k] = [raw_uc(vi, flow_unit, plot_unit) for vi in v]\n        return flow_dict",
  "def plot(self, flow_dict, title=None):\n        \"\"\"\n        Plots the BalanceOfPlant system, based on the inputs and flows.\n\n        Parameters\n        ----------\n        inputs: dict\n            The inputs to BalanceOfPlant (used here to format the title)\n        op_mode: str\n            The operation mode of the reactor\n        flow_dict: dict\n            The dictionary of flows for each of the Sankey diagrams.\n        \"\"\"\n        flow_dict = self._scale_flows(flow_dict)\n        # Build the base figure object\n        self.fig = plt.figure(\n            figsize=self.plot_options[\"figsize\"],\n            facecolor=self.plot_options[\"facecolor\"],\n        )\n        ax = self.fig.add_subplot(1, 1, 1, xticks=[], yticks=[])\n        plt.axis(\"off\")\n\n        self.sankey = SuperSankey(\n            ax=ax,\n            scale=self.plot_options[\"scale\"],\n            format=self.plot_options[\"format\"],\n            unit=self.plot_options[\"unit\"],\n            gap=self.plot_options[\"gap\"],\n            radius=self.plot_options[\"radius\"],\n            shoulder=self.plot_options[\"shoulder\"],\n            head_angle=self.plot_options[\"head_angle\"],\n        )\n        self._build_diagram(flow_dict)\n        self._polish()\n        self.fig.suptitle(\n            title, color=self.plot_options[\"font_color\"], fontsize=24, weight=\"bold\"\n        )",
  "def _build_diagram(self, flow_dict):\n        \"\"\"\n        Builds the Sankey diagram. This is much more verbose than looping over\n        some structs, but that's how it used to be and it was hard to modify.\n        This is easier to read and modify.\n        \"\"\"\n        trunk_length = self.plot_options[\"trunk_length\"]\n        l_s = self.plot_options[\"standard_length\"]\n        l_m = self.plot_options[\"medium_length\"]\n\n        # 0: Plasma\n        self.sankey.add(\n            patchlabel=\"Plasma\",\n            labels=[\"Fusion Power\", None, \"Neutrons\", \"Alphas + Aux\"],\n            flows=flow_dict[\"Plasma\"],\n            orientations=[0, -1, 0, -1],\n            prior=None,\n            connect=None,\n            trunklength=trunk_length,\n            pathlengths=[l_m, l_s / 1.5, l_s, l_s],\n            facecolor=BLUEMIRA_PALETTE[\"blue\"].as_hex(),\n        )\n        # 1: H&CD (first block)\n        self.sankey.add(\n            patchlabel=\"H&CD\",\n            labels=[\"\", \"H&CD power\", \"Losses\"],\n            flows=flow_dict[\"H&CD\"],\n            orientations=[-1, 1, -1],\n            prior=0,\n            connect=(1, 1),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_s / 1.5, l_s],\n            facecolor=BLUEMIRA_PALETTE[\"pink\"].as_hex(),\n        )\n        # 2: Neutrons\n        self.sankey.add(\n            patchlabel=\"Neutrons\",\n            labels=[None, \"Energy Multiplication\", \"Blanket n\", \"Divertor n\", \"Aux n\"],\n            flows=flow_dict[\"Neutrons\"],\n            orientations=[0, 1, 0, -1, -1],\n            prior=0,\n            connect=(2, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_s, l_s, 3 * l_m, l_m],\n            facecolor=BLUEMIRA_PALETTE[\"orange\"].as_hex(),\n        )\n        # 3: Radiation and separatrix\n        self.sankey.add(\n            patchlabel=\"Radiation and\\nseparatrix\",\n            labels=[None, \"\", \"Divertor rad and\\n charged p\"],\n            flows=flow_dict[\"Radiation and \\nseparatrix\"],\n            orientations=[1, 0, -1],\n            prior=0,\n            connect=(3, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_s, l_s],\n            facecolor=BLUEMIRA_PALETTE[\"red\"].as_hex(),\n        )\n        # 4: Blanket\n        self.sankey.add(\n            patchlabel=\"Blanket\",\n            labels=[None, \"\", \"\", \"Decay heat\", \"\"],\n            flows=flow_dict[\"Blanket\"],\n            orientations=[0, -1, -1, 1, 0],\n            prior=2,\n            connect=(2, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_s, l_s, l_s, l_s],\n            facecolor=BLUEMIRA_PALETTE[\"yellow\"].as_hex(),\n        )\n        # 5: Divertor\n        self.sankey.add(\n            patchlabel=\"Divertor\",\n            labels=[None, None, \"\"],\n            flows=flow_dict[\"Divertor\"],\n            orientations=[1, 0, 0],\n            prior=2,\n            connect=(3, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_m, l_s, l_s],\n            facecolor=BLUEMIRA_PALETTE[\"cyan\"].as_hex(),\n        )\n        # 6: First wall\n        self.sankey.add(\n            patchlabel=\"First wall\",\n            labels=[None, \"Auxiliary \\n FW\", None],\n            flows=flow_dict[\"First wall\"],\n            orientations=[0, -1, 1],\n            prior=3,\n            future=4,\n            connect=[(1, 0), (1, 2)],\n            trunklength=trunk_length,\n            pathlengths=[0, l_s, 0],\n            facecolor=BLUEMIRA_PALETTE[\"grey\"].as_hex(),\n        )\n        # 7: BoP\n        self.sankey.add(\n            patchlabel=\"BoP\",\n            labels=[None, None, \"Losses\", None],\n            flows=flow_dict[\"BoP\"],\n            orientations=[0, -1, -1, 0],\n            prior=4,\n            connect=(4, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_m, l_m, 0],\n            facecolor=BLUEMIRA_PALETTE[\"purple\"].as_hex(),\n        )\n        # 8: Electricity\n        # Check if we have net electric power\n        labels = [\n            \"$P_{el}$\",\n            \"T plant\",\n            \"P_oth...\",\n            \"Cryoplant\",\n            \"Magnets\",\n            None,\n            None,\n            \"BB Pumping \\n electrical \\n power\",\n            \"\",\n        ]\n        orientations = [0, -1, -1, -1, -1, -1, -1, -1, 0]\n\n        if flow_dict[\"Electricity\"][-1] > 0:\n            # Conversely, this means \"net electric loss\"\n            labels[-1] = \"Grid\"\n            orientations[-1] = 1\n\n        self.sankey.add(\n            patchlabel=\"Electricity\",\n            labels=labels,\n            flows=flow_dict[\"Electricity\"],\n            orientations=orientations,\n            prior=7,\n            connect=(3, 0),\n            trunklength=trunk_length,\n            pathlengths=[\n                l_m,\n                2 * l_m,\n                3 * l_m,\n                4 * l_m,\n                5 * l_m,\n                7 * l_m,\n                5 * l_m,\n                3 * l_m,\n                l_s,\n            ],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n        # 9: H&CD return leg\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, \"H&CD Power\"],\n            flows=flow_dict[\"_H&CD loop\"],\n            orientations=[-1, 0],\n            prior=8,\n            connect=(5, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s / 2, 7 * l_m],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n        # 10: Divertor (second block)\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, None],\n            flows=flow_dict[\"_Divertor 2\"],\n            orientations=[1, 0],\n            prior=3,\n            future=5,\n            connect=[(2, 0), (1, 1)],\n            trunklength=trunk_length,\n            pathlengths=[0, 0],\n            facecolor=BLUEMIRA_PALETTE[\"cyan\"].as_hex(),\n        )\n        # 11: H&CD return leg (second half)\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, None],\n            flows=flow_dict[\"_H&CD loop 2\"],\n            orientations=[-1, 0],\n            prior=9,\n            future=1,\n            connect=[(1, 0), (0, 1)],\n            trunklength=trunk_length,\n            pathlengths=[0, 0],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n        # 12: Divertor back into BoP\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, \"\", \"\"],\n            flows=flow_dict[\"_DIV to BOP\"],\n            orientations=[0, -1, 1],\n            prior=5,\n            future=7,\n            connect=[(2, 0), (1, 2)],\n            trunklength=trunk_length,\n            pathlengths=[0, l_s / 2, 0],\n            facecolor=BLUEMIRA_PALETTE[\"cyan\"].as_hex(),\n        )\n        # 13: BB electrical pumping loss turn leg\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, \"Losses\", \"BB coolant \\n pumping\"],\n            flows=flow_dict[\"_BB coolant loop turn\"],\n            orientations=[0, 0, -1],\n            prior=8,\n            connect=(7, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_s, l_m * 3],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n        # 14: BB electrical pumping return leg into blanket\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, None],\n            flows=flow_dict[\"_BB coolant loop blanket\"],\n            orientations=[0, -1],\n            prior=13,\n            future=4,\n            connect=[(2, 0), (2, 1)],\n            trunklength=trunk_length,\n            pathlengths=[0, 0],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n        # 15: Divertor electrical pumping loss turn leg\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, \"Losses\", \"Div coolant \\n pumping\"],\n            flows=flow_dict[\"_DIV coolant loop turn\"],\n            orientations=[0, 0, -1],\n            prior=8,\n            connect=(6, 0),\n            trunklength=trunk_length,\n            pathlengths=[l_s, l_s / 2, l_m],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )\n        # 16: Divertor electrical pumping return into divertor\n        self.sankey.add(\n            patchlabel=\"\",\n            labels=[None, None],\n            flows=flow_dict[\"_DIV coolant loop divertor\"],\n            orientations=[0, -1],\n            prior=15,\n            future=12,\n            connect=[(2, 0), (1, 1)],\n            trunklength=trunk_length,\n            pathlengths=[0, 0],\n            facecolor=BLUEMIRA_PALETTE[\"green\"].as_hex(),\n        )",
  "def _polish(self):\n        \"\"\"\n        Finish up and polish figure, and format text\n        \"\"\"\n        diagrams = self.sankey.finish()\n        for diagram in diagrams:\n            diagram.text.set_fontweight(self.plot_options[\"font_weight\"])\n            diagram.text.set_fontsize(self.plot_options[\"font_size\"])\n            diagram.text.set_color(self.plot_options[\"font_color\"])\n            for text in diagram.texts:\n                text.set_fontsize(self.plot_options[\"flow_font_size\"])\n                text.set_color(self.plot_options[\"font_color\"])\n\n        self.fig.tight_layout()",
  "def minimise_dxdy(x_opt):\n            \"\"\"\n            Minimisation function for the spatial difference between the target\n            tip and the actual tip.\n\n            Parameters\n            ----------\n            x_opt: array_like\n                The vector of d_x, d_y delta-vectors to match tip positions\n\n            Returns\n            -------\n            delta: float\n                The sum of the absolute differences\n            \"\"\"\n            tip2 = self.diagrams[future].tips[future_index]\n            pathlengths[0] = x_opt[0]\n            pathlengths[-1] = x_opt[1]\n            self.add(\n                trunklength=trunklength,\n                pathlengths=pathlengths,\n                flows=flows,\n                prior=prior,\n                connect=connect[0],\n                orientations=orient,\n                labels=labels,\n                facecolor=\"#00000000\",\n            )\n            new_tip = self.diagrams[-1].tips[this_f_index].copy()\n            # Clean sankey plot\n            self.diagrams.pop()\n            self.ax.patches[-1].remove()\n            return np.sum(np.abs(tip2 - new_tip))",
  "class CoolantPumping(abc.ABC):\n    \"\"\"\n    Pumping power strategy abstract base class\n    \"\"\"\n\n    @abc.abstractmethod\n    def pump(self, power: float) -> Tuple[float, float]:\n        \"\"\"\n        Calculate the pump work and electrical pumping power required for a given power.\n        \"\"\"\n        pass",
  "class HePumping(CoolantPumping):\n    \"\"\"\n    He-cooling pumping power calculation strategy\n\n    Parameters\n    ----------\n    pressure_in:\n        Inlet pressure [Pa]\n    pressure_out:\n        Pressure drop [Pa]\n    temp_in:\n        Inlet temperature [K]\n    temp_out:\n        Outlet temperature [K]\n    eta_isen:\n        Isentropic efficiency of the He compressors\n    eta_el:\n        Electrical efficiency of the He compressors\n    \"\"\"\n\n    def __init__(\n        self,\n        pressure_in: float,\n        pressure_out: float,\n        temp_in: float,\n        temp_out: float,\n        eta_isentropic: float,\n        eta_electric: float,\n    ):\n        self.p_in = pressure_in\n        self.p_out = pressure_out\n        self.t_in = temp_in\n        self.t_out = temp_out\n        self.eta_isen = eta_isentropic\n        self.eta_el = eta_electric\n\n    def pump(self, power: float) -> Tuple[float, float]:\n        \"\"\"\n        Calculate the pump work and electrical pumping power required for a given power.\n\n        Parameters\n        ----------\n        power:\n            Total blanket power excluding pumping power [W]\n\n        Returns\n        -------\n        P_pump_is:\n            The isentropic pumping power (added to the working fluid)\n        P_pump_el:\n            The electrical pumping power (parasitic load)\n        \"\"\"\n        p_pump, p_electric = He_pumping(\n            self.p_in,\n            self.p_out,\n            self.t_in,\n            self.t_out,\n            power,\n            self.eta_isen,\n            self.eta_el,\n        )\n        return p_pump, p_electric",
  "class H2OPumping(CoolantPumping):\n    \"\"\"\n    H20-cooling pumping power calculation strategy\n\n    Parameters\n    ----------\n    f_pump:\n        Fraction of thermal power required to pump\n    eta_isen:\n        Isentropic efficiency of the water pumps\n    eta_el:\n        Electrical efficiency of the water pumps\n    \"\"\"\n\n    def __init__(self, f_pump: float, eta_isentropic: float, eta_electric: float):\n        self.f_pump = f_pump\n        self.eta_isen = eta_isentropic\n        self.eta_el = eta_electric\n\n    def pump(self, power: float) -> Tuple[float, float]:\n        \"\"\"\n        Calculate the pump work and electrical pumping power required for a given power.\n\n        Parameters\n        ----------\n        power:\n            Total blanket power excluding pumping power [W]\n\n        Returns\n        -------\n        P_pump_is:\n            The isentropic pumping power (added to the working fluid)\n        P_pump_el:\n            The eletrical pumping power (parasitic load)\n        \"\"\"\n        p_pump, p_electric = H2O_pumping(power, self.f_pump, self.eta_isen, self.eta_el)\n        return p_pump, p_electric",
  "class PowerCycleEfficiencyCalc(abc.ABC):\n    \"\"\"\n    Power cycle efficiency calculation abstract base class\n    \"\"\"\n\n    @abc.abstractmethod\n    def calculate(self, *args) -> float:\n        \"\"\"\n        Calculate the efficiency of the power cycle\n        \"\"\"\n        pass",
  "class PredeterminedEfficiency(PowerCycleEfficiencyCalc):\n    \"\"\"\n    Predetermined efficiency 'calculation'\n\n    Parameters\n    ----------\n    efficiency:\n        The efficiency to 'calculate'\n    \"\"\"\n\n    def __init__(self, efficiency: float):\n        self.efficiency = efficiency\n\n    def calculate(self, p_blanket: float, p_divertor: float) -> float:\n        \"\"\"\n        Calculate the efficiency of the power cycle\n\n        Parameters\n        ----------\n        p_blanket:\n            Blanket thermal power [MW]\n        p_divertor:\n            Divertor thermal power [MW]\n\n        Returns\n        -------\n        The efficiency\n        \"\"\"\n        return self.efficiency",
  "class SuperheatedRankine(PowerCycleEfficiencyCalc):\n    \"\"\"\n    Superheated Rankine power cycle for use with gas coolants\n\n    Parameters\n    ----------\n    bb_t_out:\n        Breeding blanket outlet temperature [K]\n    delta_t_turbine:\n        Turbine inlet delta T [K]\n    \"\"\"\n\n    def __init__(self, bb_t_out: float, delta_t_turbine: float):\n        self.bb_t_out = bb_t_out\n        self.delta_t_turbine = delta_t_turbine\n\n    def calculate(self, p_blanket: float, p_divertor: float) -> float:\n        \"\"\"\n        Calculate the efficiency of the power cycle\n\n        Parameters\n        ----------\n        p_blanket:\n            Blanket thermal power [MW]\n        p_divertor:\n            Divertor thermal power [MW]\n\n        Returns\n        -------\n        The efficiency\n        \"\"\"\n        return superheated_rankine(\n            p_blanket, p_divertor, self.bb_t_out, self.delta_t_turbine\n        )",
  "class FractionSplitStrategy(abc.ABC):\n    \"\"\"\n    Strategy ABC for splitting flows according to fractions.\n    \"\"\"\n\n    @abc.abstractmethod\n    def split(self, *args):\n        \"\"\"\n        Split flows somehow.\n        \"\"\"\n        pass\n\n    def check_fractions(self, fractions: List[float]) -> bool:\n        \"\"\"\n        Check that fractions sum to 1.0\n\n        Raises\n        ------\n        BalanceOfPlantError\n            If they do not\n        \"\"\"\n        frac_sum = sum(fractions)\n        if not np.isclose(frac_sum, 1.0, atol=1e-6, rtol=0):\n            raise BalanceOfPlantError(\n                f\"{self.__class__.__name__} fractions sum to {frac_sum:.7f}\"\n            )",
  "class NeutronPowerStrategy(FractionSplitStrategy):\n    \"\"\"\n    Strategy for distributing neutron power among components\n\n    Parameters\n    ----------\n    f_blanket:\n        Fraction of neutron power going to the blankets\n    f_divertor:\n        Fraction of neutron power going to the divertors\n    f_vessel:\n        Fraction of neutron power going to the vacuum vessel\n    f_other:\n        Fraction of neutron power going to other systems\n    energy_multiplication:\n        Energy multiplication factor applied to blanket neutron power\n    decay_multiplication:\n        Decay energy multiplication applied to the blanket neutron power\n    \"\"\"\n\n    def __init__(\n        self,\n        f_blanket: float,\n        f_divertor: float,\n        f_vessel: float,\n        f_other: float,\n        energy_multiplication: float,\n        decay_multiplication: float,\n    ):\n        self.check_fractions([f_blanket, f_divertor, f_vessel, f_other])\n        self.f_blanket = f_blanket\n        self.f_divertor = f_divertor\n        self.f_vessel = f_vessel\n        self.f_other = f_other\n        if energy_multiplication < 1.0:\n            raise BalanceOfPlantError(\n                \"Energy multiplication factor cannot be less than 1.0\"\n            )\n        if decay_multiplication < 1.0:\n            raise BalanceOfPlantError(\n                \"Decay multiplication factor cannot be less than 1.0\"\n            )\n        self.nrg_mult = energy_multiplication\n        self.dec_mult = decay_multiplication\n\n    def split(\n        self, neutron_power: float\n    ) -> Tuple[float, float, float, float, float, float]:\n        \"\"\"\n        Split neutron power into several flows\n\n        Parameters\n        ----------\n        neutron_power:\n            Total neutron power\n\n        Returns\n        -------\n        blk_power:\n            Neutron power to blankets\n        div_power:\n            Neutron power to divertors\n        vv_power:\n            Neutron power to vessel\n        aux_power:\n            Neutron power to auxiliary systems\n        mult_power:\n            Energy multiplication power which is assumed to come solely from the blanket\n        decay_power:\n            Decay power which is assumed to come solely from the blanket\n        \"\"\"\n        blk_power = self.f_blanket * self.nrg_mult * neutron_power\n        div_power = self.f_divertor * neutron_power\n        vv_power = self.f_vessel * neutron_power\n        aux_power = self.f_other * neutron_power\n        mult_power = blk_power - self.f_blanket * neutron_power\n        decay_power = (self.dec_mult - 1.0) * neutron_power\n        return blk_power, div_power, vv_power, aux_power, mult_power, decay_power",
  "class RadChargedPowerStrategy(FractionSplitStrategy):\n    \"\"\"\n    Strategy for distributing radiation and charged particle power from the plasma\n    core and scrape-off layer\n\n    Parameters\n    ----------\n    f_core_rad_fw:\n        Fraction of core radiation power distributed to the first wall\n    f_sol_rad:\n        Fraction of SOL power that is radiated\n    f_sol_rad_fw:\n        Fraction of radiated SOL power that is distributed to the first wall\n    f_sol_ch_fw:\n        Fraction of SOL charged particle power that is distributed to the first wall\n    f_fw_aux:\n        Fraction of first power that actually goes into auxiliary systems\n    \"\"\"\n\n    def __init__(\n        self,\n        f_core_rad_fw: float,\n        f_sol_rad: float,\n        f_sol_rad_fw: float,\n        f_sol_ch_fw: float,\n        f_fw_aux: float,\n    ):\n        self.f_core_rad_fw = f_core_rad_fw\n        self.f_sol_rad = f_sol_rad\n        self.f_sol_rad_fw = f_sol_rad_fw\n        self.f_sol_ch_fw = f_sol_ch_fw\n        self.f_fw_aux = f_fw_aux\n\n    def split(\n        self, p_radiation: float, p_separatrix: float\n    ) -> Tuple[float, float, float]:\n        \"\"\"\n        Split the radiation and charged particle power\n\n        Parameters\n        ----------\n        p_radiation:\n            Plasma core radiation power\n        p_separatrix:\n            Charged particle power crossing the separatrix\n\n        Returns\n        -------\n        p_rad_sep_blk:\n            Radiation power from separatrix to blanket\n        p_rad_sep_div:\n            Radiation power from separatrix to divertor\n        p_rad_sep_aux:\n            Radiation power from separatrix to auxiliaries\n        \"\"\"\n        # Core radiation\n        p_core_rad_fw = p_radiation * self.f_core_rad_fw\n        p_core_rad_div = p_radiation - p_core_rad_fw\n\n        # Scrape-off layer radiation\n        p_sol_rad = p_separatrix * self.f_sol_rad\n        p_sol_rad_fw = p_sol_rad * self.f_sol_rad_fw\n        p_sol_rad_div = p_sol_rad - p_sol_rad_fw\n\n        # Scrape-off layer charged particles\n        p_sol_charged = p_separatrix - p_sol_rad\n        p_sol_charged_fw = p_sol_charged * self.f_sol_ch_fw\n        p_sol_charged_div = p_sol_charged - p_sol_charged_fw\n\n        # Split first wall into blanket and auxiliary\n        p_rad_sep_fw = p_core_rad_fw + p_sol_rad_fw + p_sol_charged_fw\n        p_rad_sep_blk = p_rad_sep_fw * (1 - self.f_fw_aux)\n        p_rad_sep_aux = p_rad_sep_fw - p_rad_sep_blk\n        p_rad_sep_div = p_core_rad_div + p_sol_rad_div + p_sol_charged_div\n        return p_rad_sep_blk, p_rad_sep_div, p_rad_sep_aux",
  "class ParasiticLoadStrategy(abc.ABC):\n    \"\"\"\n    Strategy for calculating the parasitic loads\n    \"\"\"\n\n    @abc.abstractmethod\n    def calculate(*args, **kwargs) -> Tuple[float, float, float, float]:\n        \"\"\"\n        Calculate the parasitic loads somehow\n\n        Returns\n        -------\n        p_mag:\n            Parasitic loads to power the magnets\n        p_cryo:\n            Parasitic loads to power the cryoplant\n        p_t_plant:\n            Parasitic loads to power the tritium plant\n        p_other:\n            Parasitic loads to power other miscellaneous things\n        \"\"\"\n        pass",
  "class BoPModelParams(ParameterFrame):\n    \"\"\"Parameters required to run :class:`BalanceOfPlantModel`.\"\"\"\n\n    P_fus_DT: Parameter[float]\n    P_fus_DD: Parameter[float]\n    P_rad: Parameter[float]\n    P_hcd_ss: Parameter[float]\n    P_hcd_ss_el: Parameter[float]",
  "class BalanceOfPlantModel:\n    \"\"\"\n    Balance of plant calculator for a fusion power reactor.\n\n    Parameters\n    ----------\n    params:\n        Structure containing input parameters.\n        If this is a dictionary, required keys are:\n\n            * P_fus_DT: float\n            * P_fus_DD: float\n            * P_rad: float\n            * P_hcd_ss: float\n            * P_hcd_ss_el: float\n\n        See :class:`BoPModelParams` for parameter details.\n    rad_sep_strat:\n        Strategy to calculate the where the radiation and charged particle power\n        in the scrape-off-layer is carried to\n    neutron_strat:\n        Strategy to calculate where the neutron power is carried to\n    blanket_pump_strat:\n        Strategy to calculate the coolant pumping power for the blanket\n    divertor_pump_strat:\n        Strategy to calculate the coolant pumping power for the divertor\n    bop_cycle_strat:\n        Strategy to calculate the balance of plant thermal efficiency\n    parasitic_load_strat:\n        Strategy to calculate the parasitic loads\n\n    Notes\n    -----\n\n    .. math::\n        P_{el}={\\\\eta}_{BOP}\\\\Bigg[\\\\Bigg(\\\\frac{4}{5}P_{fus}f_{nrgm}-\\\\\n        P_{n_{aux}}-P_{n_{DIV}}+f_{SOL_{rad}}f_{SOL_{ch}}\\\\Big(\\\\frac{P_{fus}}{5}+P_{HCD}\\\\Big)\\\\Bigg)\\\\\n        \\\\Big(1+\\\\frac{f_{p_{BB}}}{1-f_{p_{BB}}}\\\\Big)\n        +\\\\Bigg(P_{n_{DIV}}+f_{SOL_{rad}}f_{SOL_{ch}}f_{fw}\\\\Big(\\\\frac{P_{fus}}{5}+P_{HCD}\\\\Big)\\\\Bigg)\\\\\n        \\\\Big(1+\\\\frac{f_{p_{DIV}}}{1-f_{p_{DIV}}}\\\\Big)\\\\Bigg]\n\n    \"\"\"  # noqa :W505\n\n    _plotter = BalanceOfPlantPlotter\n\n    def __init__(\n        self,\n        params: Union[Dict[str, float], BoPModelParams],\n        rad_sep_strat: FractionSplitStrategy,\n        neutron_strat: FractionSplitStrategy,\n        blanket_pump_strat: CoolantPumping,\n        divertor_pump_strat: CoolantPumping,\n        bop_cycle_strat: PowerCycleEfficiencyCalc,\n        parasitic_load_strat: ParasiticLoadStrategy,\n    ):\n        self.params = make_parameter_frame(params, BoPModelParams)\n        self.rad_sep_strat = rad_sep_strat\n        self.neutron_strat = neutron_strat\n        self.blanket_pump_strat = blanket_pump_strat\n        self.divertor_pump_strat = divertor_pump_strat\n        self.bop_strat = bop_cycle_strat\n        self.parasitic_strat = parasitic_load_strat\n        self.flow_dict = None\n\n    def build(self):\n        \"\"\"\n        Carry out the balance of plant calculation\n        \"\"\"\n        p_fusion = self.params.P_fus_DT.value + self.params.P_fus_DD.value\n        f_neutron_DT = HE_MOLAR_MASS / (HE_MOLAR_MASS + NEUTRON_MOLAR_MASS)\n        f_neutron_DD = 0.5 * HE3_MOLAR_MASS / (NEUTRON_MOLAR_MASS + HE3_MOLAR_MASS)\n        p_neutron = (\n            f_neutron_DT * self.params.P_fus_DT.value\n            + f_neutron_DD * self.params.P_fus_DD.value\n        )\n        p_charged = self.params.P_fus_DT.value + self.params.P_fus_DD.value - p_neutron\n\n        p_radiation = self.params.P_rad.value\n        p_hcd = self.params.P_hcd_ss.value\n        p_hcd_el = self.params.P_hcd_ss_el.value\n        p_separatrix = p_charged - p_radiation + p_hcd\n        (\n            p_n_blk,\n            p_n_div,\n            p_n_vv,\n            p_n_aux,\n            p_nrgm,\n            p_blk_decay,\n        ) = self.neutron_strat.split(p_neutron)\n        p_rad_sep_blk, p_rad_sep_div, p_rad_sep_aux = self.rad_sep_strat.split(\n            p_radiation, p_separatrix\n        )\n        p_rad_sep_fw = p_rad_sep_blk + p_rad_sep_aux\n\n        p_blanket = p_n_blk + p_blk_decay + p_rad_sep_blk\n        p_blk_pump, p_blk_pump_el = self.blanket_pump_strat.pump(p_blanket)\n        p_blanket += p_blk_pump\n\n        p_div = p_n_div + p_rad_sep_div\n        p_div_pump, p_div_pump_el = self.divertor_pump_strat.pump(p_div)\n        p_div += p_div_pump\n\n        eta_bop = self.bop_strat.calculate(p_blanket, p_div)\n        total_bop_power = p_blanket + p_div\n        p_bop = eta_bop * total_bop_power\n        p_bop_loss = total_bop_power - p_bop\n\n        p_mag, p_cryo, p_t_plant, p_other = self.parasitic_strat.calculate(p_fusion)\n\n        p_el_net = (\n            p_bop\n            - p_hcd_el\n            - p_blk_pump_el\n            - p_cryo\n            - p_mag\n            - p_other\n            - p_t_plant\n            - p_div_pump_el\n        )\n\n        self.flow_dict = {\n            \"Plasma\": [p_fusion, p_hcd, -p_neutron, -p_separatrix - p_radiation],\n            \"H&CD\": [p_hcd_el, -p_hcd, -(p_hcd_el - p_hcd)],\n            \"Neutrons\": [p_neutron, p_nrgm, -p_n_blk, -p_n_div, -p_n_vv - p_n_aux],\n            \"Radiation and \\nseparatrix\": [\n                p_radiation + p_separatrix,\n                -p_rad_sep_fw,\n                -p_rad_sep_div,\n            ],\n            \"Blanket\": [p_n_blk, p_rad_sep_blk, p_blk_pump, p_blk_decay, -p_blanket],\n            \"Divertor\": [p_n_div, p_rad_sep_div, -p_n_div - p_rad_sep_div],\n            \"First wall\": [p_rad_sep_fw, -p_rad_sep_aux, -p_rad_sep_blk],\n            \"BoP\": [p_blanket, p_div, -p_bop_loss, -p_bop],\n            \"Electricity\": [\n                p_bop,\n                -p_t_plant,\n                -p_other,\n                -p_cryo,\n                -p_mag,\n                -p_hcd_el,\n                -p_div_pump_el,\n                -p_blk_pump_el,\n                -p_el_net,\n            ],\n            \"_H&CD loop\": [p_hcd_el, -p_hcd_el],\n            \"_Divertor 2\": [p_rad_sep_div, -p_rad_sep_div],\n            \"_H&CD loop 2\": [p_hcd_el, -p_hcd_el],\n            \"_DIV to BOP\": [p_div - p_div_pump, p_div_pump, -p_div],\n            \"_BB coolant loop turn\": [\n                p_blk_pump_el,\n                -p_blk_pump_el + p_blk_pump,\n                -p_blk_pump,\n            ],\n            \"_BB coolant loop blanket\": [p_blk_pump, -p_blk_pump],\n            \"_DIV coolant loop turn\": [\n                p_div_pump_el,\n                -p_div_pump_el + p_div_pump,\n                -p_div_pump,\n            ],\n            \"_DIV coolant loop divertor\": [p_div_pump, -p_div_pump],\n        }\n        self.sanity()\n\n    def sanity(self):\n        \"\"\"\n        Perform a series of sanity checks.\n        \"\"\"\n        delta_truth = 0\n        # Per block check\n        for label, flow in self.flow_dict.items():\n            delta = sum(flow)\n            if round(delta) != 0:\n                bluemira_warn(\n                    f\"Power block {label} is not self-consistent.. {delta:.2f} MW are missing\"\n                )\n            delta_truth += delta\n\n        # Global check\n        if round(delta_truth) != 0:\n            bluemira_warn(\n                f\"The balance of plant model is inconsistent: {delta_truth:.2f} MW are lost somewhere.\"\n            )\n\n    def plot(self, title: Optional[str] = None, **kwargs):\n        \"\"\"\n        Plot the BalanceOfPlant object.\n\n        Parameters\n        ----------\n        title:\n            Title to print on the plot\n\n        Other Parameters\n        ----------------\n        see BALANCE_PLOT_DEFAULTS for details\n        \"\"\"\n        plotter = self._plotter(**kwargs)\n        return plotter.plot(self.flow_dict, title=title)",
  "def pump(self, power: float) -> Tuple[float, float]:\n        \"\"\"\n        Calculate the pump work and electrical pumping power required for a given power.\n        \"\"\"\n        pass",
  "def __init__(\n        self,\n        pressure_in: float,\n        pressure_out: float,\n        temp_in: float,\n        temp_out: float,\n        eta_isentropic: float,\n        eta_electric: float,\n    ):\n        self.p_in = pressure_in\n        self.p_out = pressure_out\n        self.t_in = temp_in\n        self.t_out = temp_out\n        self.eta_isen = eta_isentropic\n        self.eta_el = eta_electric",
  "def pump(self, power: float) -> Tuple[float, float]:\n        \"\"\"\n        Calculate the pump work and electrical pumping power required for a given power.\n\n        Parameters\n        ----------\n        power:\n            Total blanket power excluding pumping power [W]\n\n        Returns\n        -------\n        P_pump_is:\n            The isentropic pumping power (added to the working fluid)\n        P_pump_el:\n            The electrical pumping power (parasitic load)\n        \"\"\"\n        p_pump, p_electric = He_pumping(\n            self.p_in,\n            self.p_out,\n            self.t_in,\n            self.t_out,\n            power,\n            self.eta_isen,\n            self.eta_el,\n        )\n        return p_pump, p_electric",
  "def __init__(self, f_pump: float, eta_isentropic: float, eta_electric: float):\n        self.f_pump = f_pump\n        self.eta_isen = eta_isentropic\n        self.eta_el = eta_electric",
  "def pump(self, power: float) -> Tuple[float, float]:\n        \"\"\"\n        Calculate the pump work and electrical pumping power required for a given power.\n\n        Parameters\n        ----------\n        power:\n            Total blanket power excluding pumping power [W]\n\n        Returns\n        -------\n        P_pump_is:\n            The isentropic pumping power (added to the working fluid)\n        P_pump_el:\n            The eletrical pumping power (parasitic load)\n        \"\"\"\n        p_pump, p_electric = H2O_pumping(power, self.f_pump, self.eta_isen, self.eta_el)\n        return p_pump, p_electric",
  "def calculate(self, *args) -> float:\n        \"\"\"\n        Calculate the efficiency of the power cycle\n        \"\"\"\n        pass",
  "def __init__(self, efficiency: float):\n        self.efficiency = efficiency",
  "def calculate(self, p_blanket: float, p_divertor: float) -> float:\n        \"\"\"\n        Calculate the efficiency of the power cycle\n\n        Parameters\n        ----------\n        p_blanket:\n            Blanket thermal power [MW]\n        p_divertor:\n            Divertor thermal power [MW]\n\n        Returns\n        -------\n        The efficiency\n        \"\"\"\n        return self.efficiency",
  "def __init__(self, bb_t_out: float, delta_t_turbine: float):\n        self.bb_t_out = bb_t_out\n        self.delta_t_turbine = delta_t_turbine",
  "def calculate(self, p_blanket: float, p_divertor: float) -> float:\n        \"\"\"\n        Calculate the efficiency of the power cycle\n\n        Parameters\n        ----------\n        p_blanket:\n            Blanket thermal power [MW]\n        p_divertor:\n            Divertor thermal power [MW]\n\n        Returns\n        -------\n        The efficiency\n        \"\"\"\n        return superheated_rankine(\n            p_blanket, p_divertor, self.bb_t_out, self.delta_t_turbine\n        )",
  "def split(self, *args):\n        \"\"\"\n        Split flows somehow.\n        \"\"\"\n        pass",
  "def check_fractions(self, fractions: List[float]) -> bool:\n        \"\"\"\n        Check that fractions sum to 1.0\n\n        Raises\n        ------\n        BalanceOfPlantError\n            If they do not\n        \"\"\"\n        frac_sum = sum(fractions)\n        if not np.isclose(frac_sum, 1.0, atol=1e-6, rtol=0):\n            raise BalanceOfPlantError(\n                f\"{self.__class__.__name__} fractions sum to {frac_sum:.7f}\"\n            )",
  "def __init__(\n        self,\n        f_blanket: float,\n        f_divertor: float,\n        f_vessel: float,\n        f_other: float,\n        energy_multiplication: float,\n        decay_multiplication: float,\n    ):\n        self.check_fractions([f_blanket, f_divertor, f_vessel, f_other])\n        self.f_blanket = f_blanket\n        self.f_divertor = f_divertor\n        self.f_vessel = f_vessel\n        self.f_other = f_other\n        if energy_multiplication < 1.0:\n            raise BalanceOfPlantError(\n                \"Energy multiplication factor cannot be less than 1.0\"\n            )\n        if decay_multiplication < 1.0:\n            raise BalanceOfPlantError(\n                \"Decay multiplication factor cannot be less than 1.0\"\n            )\n        self.nrg_mult = energy_multiplication\n        self.dec_mult = decay_multiplication",
  "def split(\n        self, neutron_power: float\n    ) -> Tuple[float, float, float, float, float, float]:\n        \"\"\"\n        Split neutron power into several flows\n\n        Parameters\n        ----------\n        neutron_power:\n            Total neutron power\n\n        Returns\n        -------\n        blk_power:\n            Neutron power to blankets\n        div_power:\n            Neutron power to divertors\n        vv_power:\n            Neutron power to vessel\n        aux_power:\n            Neutron power to auxiliary systems\n        mult_power:\n            Energy multiplication power which is assumed to come solely from the blanket\n        decay_power:\n            Decay power which is assumed to come solely from the blanket\n        \"\"\"\n        blk_power = self.f_blanket * self.nrg_mult * neutron_power\n        div_power = self.f_divertor * neutron_power\n        vv_power = self.f_vessel * neutron_power\n        aux_power = self.f_other * neutron_power\n        mult_power = blk_power - self.f_blanket * neutron_power\n        decay_power = (self.dec_mult - 1.0) * neutron_power\n        return blk_power, div_power, vv_power, aux_power, mult_power, decay_power",
  "def __init__(\n        self,\n        f_core_rad_fw: float,\n        f_sol_rad: float,\n        f_sol_rad_fw: float,\n        f_sol_ch_fw: float,\n        f_fw_aux: float,\n    ):\n        self.f_core_rad_fw = f_core_rad_fw\n        self.f_sol_rad = f_sol_rad\n        self.f_sol_rad_fw = f_sol_rad_fw\n        self.f_sol_ch_fw = f_sol_ch_fw\n        self.f_fw_aux = f_fw_aux",
  "def split(\n        self, p_radiation: float, p_separatrix: float\n    ) -> Tuple[float, float, float]:\n        \"\"\"\n        Split the radiation and charged particle power\n\n        Parameters\n        ----------\n        p_radiation:\n            Plasma core radiation power\n        p_separatrix:\n            Charged particle power crossing the separatrix\n\n        Returns\n        -------\n        p_rad_sep_blk:\n            Radiation power from separatrix to blanket\n        p_rad_sep_div:\n            Radiation power from separatrix to divertor\n        p_rad_sep_aux:\n            Radiation power from separatrix to auxiliaries\n        \"\"\"\n        # Core radiation\n        p_core_rad_fw = p_radiation * self.f_core_rad_fw\n        p_core_rad_div = p_radiation - p_core_rad_fw\n\n        # Scrape-off layer radiation\n        p_sol_rad = p_separatrix * self.f_sol_rad\n        p_sol_rad_fw = p_sol_rad * self.f_sol_rad_fw\n        p_sol_rad_div = p_sol_rad - p_sol_rad_fw\n\n        # Scrape-off layer charged particles\n        p_sol_charged = p_separatrix - p_sol_rad\n        p_sol_charged_fw = p_sol_charged * self.f_sol_ch_fw\n        p_sol_charged_div = p_sol_charged - p_sol_charged_fw\n\n        # Split first wall into blanket and auxiliary\n        p_rad_sep_fw = p_core_rad_fw + p_sol_rad_fw + p_sol_charged_fw\n        p_rad_sep_blk = p_rad_sep_fw * (1 - self.f_fw_aux)\n        p_rad_sep_aux = p_rad_sep_fw - p_rad_sep_blk\n        p_rad_sep_div = p_core_rad_div + p_sol_rad_div + p_sol_charged_div\n        return p_rad_sep_blk, p_rad_sep_div, p_rad_sep_aux",
  "def calculate(*args, **kwargs) -> Tuple[float, float, float, float]:\n        \"\"\"\n        Calculate the parasitic loads somehow\n\n        Returns\n        -------\n        p_mag:\n            Parasitic loads to power the magnets\n        p_cryo:\n            Parasitic loads to power the cryoplant\n        p_t_plant:\n            Parasitic loads to power the tritium plant\n        p_other:\n            Parasitic loads to power other miscellaneous things\n        \"\"\"\n        pass",
  "def __init__(\n        self,\n        params: Union[Dict[str, float], BoPModelParams],\n        rad_sep_strat: FractionSplitStrategy,\n        neutron_strat: FractionSplitStrategy,\n        blanket_pump_strat: CoolantPumping,\n        divertor_pump_strat: CoolantPumping,\n        bop_cycle_strat: PowerCycleEfficiencyCalc,\n        parasitic_load_strat: ParasiticLoadStrategy,\n    ):\n        self.params = make_parameter_frame(params, BoPModelParams)\n        self.rad_sep_strat = rad_sep_strat\n        self.neutron_strat = neutron_strat\n        self.blanket_pump_strat = blanket_pump_strat\n        self.divertor_pump_strat = divertor_pump_strat\n        self.bop_strat = bop_cycle_strat\n        self.parasitic_strat = parasitic_load_strat\n        self.flow_dict = None",
  "def build(self):\n        \"\"\"\n        Carry out the balance of plant calculation\n        \"\"\"\n        p_fusion = self.params.P_fus_DT.value + self.params.P_fus_DD.value\n        f_neutron_DT = HE_MOLAR_MASS / (HE_MOLAR_MASS + NEUTRON_MOLAR_MASS)\n        f_neutron_DD = 0.5 * HE3_MOLAR_MASS / (NEUTRON_MOLAR_MASS + HE3_MOLAR_MASS)\n        p_neutron = (\n            f_neutron_DT * self.params.P_fus_DT.value\n            + f_neutron_DD * self.params.P_fus_DD.value\n        )\n        p_charged = self.params.P_fus_DT.value + self.params.P_fus_DD.value - p_neutron\n\n        p_radiation = self.params.P_rad.value\n        p_hcd = self.params.P_hcd_ss.value\n        p_hcd_el = self.params.P_hcd_ss_el.value\n        p_separatrix = p_charged - p_radiation + p_hcd\n        (\n            p_n_blk,\n            p_n_div,\n            p_n_vv,\n            p_n_aux,\n            p_nrgm,\n            p_blk_decay,\n        ) = self.neutron_strat.split(p_neutron)\n        p_rad_sep_blk, p_rad_sep_div, p_rad_sep_aux = self.rad_sep_strat.split(\n            p_radiation, p_separatrix\n        )\n        p_rad_sep_fw = p_rad_sep_blk + p_rad_sep_aux\n\n        p_blanket = p_n_blk + p_blk_decay + p_rad_sep_blk\n        p_blk_pump, p_blk_pump_el = self.blanket_pump_strat.pump(p_blanket)\n        p_blanket += p_blk_pump\n\n        p_div = p_n_div + p_rad_sep_div\n        p_div_pump, p_div_pump_el = self.divertor_pump_strat.pump(p_div)\n        p_div += p_div_pump\n\n        eta_bop = self.bop_strat.calculate(p_blanket, p_div)\n        total_bop_power = p_blanket + p_div\n        p_bop = eta_bop * total_bop_power\n        p_bop_loss = total_bop_power - p_bop\n\n        p_mag, p_cryo, p_t_plant, p_other = self.parasitic_strat.calculate(p_fusion)\n\n        p_el_net = (\n            p_bop\n            - p_hcd_el\n            - p_blk_pump_el\n            - p_cryo\n            - p_mag\n            - p_other\n            - p_t_plant\n            - p_div_pump_el\n        )\n\n        self.flow_dict = {\n            \"Plasma\": [p_fusion, p_hcd, -p_neutron, -p_separatrix - p_radiation],\n            \"H&CD\": [p_hcd_el, -p_hcd, -(p_hcd_el - p_hcd)],\n            \"Neutrons\": [p_neutron, p_nrgm, -p_n_blk, -p_n_div, -p_n_vv - p_n_aux],\n            \"Radiation and \\nseparatrix\": [\n                p_radiation + p_separatrix,\n                -p_rad_sep_fw,\n                -p_rad_sep_div,\n            ],\n            \"Blanket\": [p_n_blk, p_rad_sep_blk, p_blk_pump, p_blk_decay, -p_blanket],\n            \"Divertor\": [p_n_div, p_rad_sep_div, -p_n_div - p_rad_sep_div],\n            \"First wall\": [p_rad_sep_fw, -p_rad_sep_aux, -p_rad_sep_blk],\n            \"BoP\": [p_blanket, p_div, -p_bop_loss, -p_bop],\n            \"Electricity\": [\n                p_bop,\n                -p_t_plant,\n                -p_other,\n                -p_cryo,\n                -p_mag,\n                -p_hcd_el,\n                -p_div_pump_el,\n                -p_blk_pump_el,\n                -p_el_net,\n            ],\n            \"_H&CD loop\": [p_hcd_el, -p_hcd_el],\n            \"_Divertor 2\": [p_rad_sep_div, -p_rad_sep_div],\n            \"_H&CD loop 2\": [p_hcd_el, -p_hcd_el],\n            \"_DIV to BOP\": [p_div - p_div_pump, p_div_pump, -p_div],\n            \"_BB coolant loop turn\": [\n                p_blk_pump_el,\n                -p_blk_pump_el + p_blk_pump,\n                -p_blk_pump,\n            ],\n            \"_BB coolant loop blanket\": [p_blk_pump, -p_blk_pump],\n            \"_DIV coolant loop turn\": [\n                p_div_pump_el,\n                -p_div_pump_el + p_div_pump,\n                -p_div_pump,\n            ],\n            \"_DIV coolant loop divertor\": [p_div_pump, -p_div_pump],\n        }\n        self.sanity()",
  "def sanity(self):\n        \"\"\"\n        Perform a series of sanity checks.\n        \"\"\"\n        delta_truth = 0\n        # Per block check\n        for label, flow in self.flow_dict.items():\n            delta = sum(flow)\n            if round(delta) != 0:\n                bluemira_warn(\n                    f\"Power block {label} is not self-consistent.. {delta:.2f} MW are missing\"\n                )\n            delta_truth += delta\n\n        # Global check\n        if round(delta_truth) != 0:\n            bluemira_warn(\n                f\"The balance of plant model is inconsistent: {delta_truth:.2f} MW are lost somewhere.\"\n            )",
  "def plot(self, title: Optional[str] = None, **kwargs):\n        \"\"\"\n        Plot the BalanceOfPlant object.\n\n        Parameters\n        ----------\n        title:\n            Title to print on the plot\n\n        Other Parameters\n        ----------------\n        see BALANCE_PLOT_DEFAULTS for details\n        \"\"\"\n        plotter = self._plotter(**kwargs)\n        return plotter.plot(self.flow_dict, title=title)",
  "class BalanceOfPlantError(BluemiraError):\n    \"\"\"\n    Base error for the balance_of_plant module.\n    \"\"\"\n\n    pass",
  "class FuelCycleAnalysis:\n    \"\"\"\n    Analysis class for compiling and analysing fuel cycle statistics.\n\n    Parameters\n    ----------\n    fuel_cycle_model:\n        The model for the fuel cycle on a single timeline\n    \"\"\"\n\n    build_tweaks = {\n        \"timestep\": 1200,\n        \"n\": None,\n        \"conv_thresh\": 0.0002,\n        \"verbose\": False,\n    }\n\n    def __init__(self, fuel_cycle_model: EUDEMOFuelCycleModel, **kwargs):\n        self.model = fuel_cycle_model\n\n        for key, value in kwargs.items():\n            if kwargs in self.build_tweaks:\n                self.build_tweaks[key] = value\n            else:\n                bluemira_warn(f\"Unknown kwarg: {key} = {value}\")\n\n        self.m_T_req = []\n        self.t_d = []\n        self.m_dot_release = []\n\n    def run_model(self, timelines: Iterable[Dict[str, Union[np.ndarray, int]]]):\n        \"\"\"\n        Run the tritium fuel cycle model for each timeline.\n\n        Parameters\n        ----------\n        timelines:\n            Timeline dict from LifeCycle object:\n                DEMO_t : np.array\n                    Real time signal in seconds\n                DEMO_rt : np.array\n                    Fusion time signal in years\n                DEMO_DT_rate : np.array\n                    D-T fusion reaction rate signal (NOTE: P_fus is wrapped in\n                    here, along with maintenance outages, etc.)\n                DEMO_DD_rate : np.array\n                    D-D fusion reaction rate signal (NOTE: P_fus is wrapped in\n                    here, along with maintenance outages, etc.)\n                bci : int\n                    Blanket change index\n        \"\"\"\n        if not isinstance(timelines, Iterable):  # Single timeline\n            timelines = [timelines]\n\n        for timeline in track(timelines):\n            self.model.run(timeline)\n            self.m_T_req.append(self.model.m_T_req)\n            self.t_d.append(self.model.t_d)\n            self.m_dot_release.append(self.model.m_dot_release)\n\n    def get_startup_inventory(self, query: str = \"max\") -> float:\n        \"\"\"\n        Get the tritium start-up inventory.\n\n        Parameters\n        ----------\n        query:\n            The type of statistical value to return\n            - [min, max, mean, median, 95th]\n\n        Returns\n        -------\n        The tritium start-up inventory [kg]\n        \"\"\"\n        return self._query(\"m_T_req\", query)\n\n    def get_doubling_time(self, query: str = \"max\") -> float:\n        \"\"\"\n        Get the reactor doubling time.\n\n        Parameters\n        ----------\n        query:\n            The type of statistical value to return\n            - [min, max, mean, median, 95th]\n\n        Returns\n        -------\n        The reactor doubling time [years]\n        \"\"\"\n        return self._query(\"t_d\", s=query)\n\n    def _query(self, p: str, s: str) -> float:\n        if s == \"min\":\n            return min(self.__dict__[p])\n        if s == \"max\":\n            return max(self.__dict__[p])\n        elif s == \"mean\":\n            return np.mean(self.__dict__[p])\n        elif s == \"median\":\n            return np.median(self.__dict__[p])\n        elif s == \"95th\":\n            return np.percentile(self.__dict__[p], 95)\n        else:\n            raise ValueError(f\"Unknown query: '{s}'\")\n\n    def plot(self, figsize=[12, 6], bins=20, **kwargs):\n        \"\"\"\n        Plot the distributions of m_T_start and t_d.\n        \"\"\"\n        f, ax = plt.subplots(1, 2, sharey=True, figsize=figsize)\n        ax[0].hist(self.m_T_req, bins=bins, **kwargs)\n        ax[0].set_xlabel(\"$m_{T_{start}}$ [kg]\")\n        ax[0].set_ylabel(\"$n$\")\n\n        if np.all(self.t_d == np.inf):\n            # If all the doubling times are infinite, make a special hist plot\n            t_d = 100 * np.ones(len(self.t_d))\n            ax[1].hist(\n                t_d,\n                bins=bins,\n                color=next(ax[0]._get_lines.prop_cycler)[\"color\"],\n                **kwargs,\n            )\n            ax[1].set_xticks([100 + 0.5 / bins])\n            ax[1].set_xticklabels([r\"$\\infty$\"])\n        else:\n            ax[1].hist(\n                self.t_d,\n                bins=bins,\n                color=next(ax[0]._get_lines.prop_cycler)[\"color\"],\n                **kwargs,\n            )\n        ax[1].set_xlabel(\"$t_{d}$ [yr]\")\n        f.tight_layout()",
  "def __init__(self, fuel_cycle_model: EUDEMOFuelCycleModel, **kwargs):\n        self.model = fuel_cycle_model\n\n        for key, value in kwargs.items():\n            if kwargs in self.build_tweaks:\n                self.build_tweaks[key] = value\n            else:\n                bluemira_warn(f\"Unknown kwarg: {key} = {value}\")\n\n        self.m_T_req = []\n        self.t_d = []\n        self.m_dot_release = []",
  "def run_model(self, timelines: Iterable[Dict[str, Union[np.ndarray, int]]]):\n        \"\"\"\n        Run the tritium fuel cycle model for each timeline.\n\n        Parameters\n        ----------\n        timelines:\n            Timeline dict from LifeCycle object:\n                DEMO_t : np.array\n                    Real time signal in seconds\n                DEMO_rt : np.array\n                    Fusion time signal in years\n                DEMO_DT_rate : np.array\n                    D-T fusion reaction rate signal (NOTE: P_fus is wrapped in\n                    here, along with maintenance outages, etc.)\n                DEMO_DD_rate : np.array\n                    D-D fusion reaction rate signal (NOTE: P_fus is wrapped in\n                    here, along with maintenance outages, etc.)\n                bci : int\n                    Blanket change index\n        \"\"\"\n        if not isinstance(timelines, Iterable):  # Single timeline\n            timelines = [timelines]\n\n        for timeline in track(timelines):\n            self.model.run(timeline)\n            self.m_T_req.append(self.model.m_T_req)\n            self.t_d.append(self.model.t_d)\n            self.m_dot_release.append(self.model.m_dot_release)",
  "def get_startup_inventory(self, query: str = \"max\") -> float:\n        \"\"\"\n        Get the tritium start-up inventory.\n\n        Parameters\n        ----------\n        query:\n            The type of statistical value to return\n            - [min, max, mean, median, 95th]\n\n        Returns\n        -------\n        The tritium start-up inventory [kg]\n        \"\"\"\n        return self._query(\"m_T_req\", query)",
  "def get_doubling_time(self, query: str = \"max\") -> float:\n        \"\"\"\n        Get the reactor doubling time.\n\n        Parameters\n        ----------\n        query:\n            The type of statistical value to return\n            - [min, max, mean, median, 95th]\n\n        Returns\n        -------\n        The reactor doubling time [years]\n        \"\"\"\n        return self._query(\"t_d\", s=query)",
  "def _query(self, p: str, s: str) -> float:\n        if s == \"min\":\n            return min(self.__dict__[p])\n        if s == \"max\":\n            return max(self.__dict__[p])\n        elif s == \"mean\":\n            return np.mean(self.__dict__[p])\n        elif s == \"median\":\n            return np.median(self.__dict__[p])\n        elif s == \"95th\":\n            return np.percentile(self.__dict__[p], 95)\n        else:\n            raise ValueError(f\"Unknown query: '{s}'\")",
  "def plot(self, figsize=[12, 6], bins=20, **kwargs):\n        \"\"\"\n        Plot the distributions of m_T_start and t_d.\n        \"\"\"\n        f, ax = plt.subplots(1, 2, sharey=True, figsize=figsize)\n        ax[0].hist(self.m_T_req, bins=bins, **kwargs)\n        ax[0].set_xlabel(\"$m_{T_{start}}$ [kg]\")\n        ax[0].set_ylabel(\"$n$\")\n\n        if np.all(self.t_d == np.inf):\n            # If all the doubling times are infinite, make a special hist plot\n            t_d = 100 * np.ones(len(self.t_d))\n            ax[1].hist(\n                t_d,\n                bins=bins,\n                color=next(ax[0]._get_lines.prop_cycler)[\"color\"],\n                **kwargs,\n            )\n            ax[1].set_xticks([100 + 0.5 / bins])\n            ax[1].set_xticklabels([r\"$\\infty$\"])\n        else:\n            ax[1].hist(\n                self.t_d,\n                bins=bins,\n                color=next(ax[0]._get_lines.prop_cycler)[\"color\"],\n                **kwargs,\n            )\n        ax[1].set_xlabel(\"$t_{d}$ [yr]\")\n        f.tight_layout()",
  "class Phase:\n    \"\"\"\n    Abstract object parent mixin class for Phases\n\n    Attributes\n    ----------\n    t: calendar time [years]\n    ft: fusion time [years]\n    inventory: plasma current [A]\n    DD_rate: D-D fusion rate [1/s]\n    DT_rate: D-T fusion rate [1/s]\n    \"\"\"\n\n    def __init__(self):\n        self.t = None\n        self.ft = None\n        self.inventory = None\n        self.DD_rate = None\n        self.DT_rate = None\n\n    def plot(self):\n        \"\"\"\n        Plot the Phase.\n        \"\"\"\n        _, ax = plt.subplots()\n        ax.plot(self.t, self.inventory)\n        ax2 = ax.twinx()\n        ax2.plot(self.t, self.DT_rate, label=\"D-T\")\n        ax2.plot(self.t, self.DD_rate, label=\"D-D\")\n        ax2.set_xlabel(\"$t$ [s]\")\n        ax2.legend()",
  "class OperationPhase(Phase):\n    \"\"\"\n    Object describing an operational phase in a reactor LifeCycle\n\n    Parameters\n    ----------\n    name:\n        Name of the operational phase\n    n_pulse:\n        Number of pulses in the phase\n    load_factor:\n        Load factor of the phase  0 < float < 1\n    t_rampup:\n        Ramp-up duration of each pulse during the phase [s]\n    t_flattop:\n        Phase flat-top duration of each pulse [s]\n    t_rampdown:\n        Ramp-down duration of each pulse during the phase [s]\n    t_min_down:\n        Minimum downtime between pulses [s]\n    n_DT_reactions:\n        D-T reaction rate at full power [1/s]\n    n_DD_reactions:\n        D-D reaction rate at full power [1/s]\n    plasma_current:\n        Plasma current [A]\n    t_start:\n        Time at which the phase starts [s] (default = 0)\n    sigma:\n        Standard deviation of the underlying normal distribution of the outages\n\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        n_pulse: int,\n        load_factor: float,\n        t_rampup: float,\n        t_flattop: float,\n        t_rampdown: float,\n        t_min_down: float,\n        n_DT_reactions: float,\n        n_DD_reactions: float,\n        plasma_current: float,\n        t_start: float = 0.0,\n        availability_strategy: OperationalAvailabilityStrategy = LogNormalAvailabilityStrategy(\n            sigma=2.0\n        ),\n    ):\n        super().__init__()\n        self.name = name\n        self.n_pulse = n_pulse\n        self.load_factor = load_factor\n        self.t_rampup = t_rampup\n        self.t_flattop = t_flattop\n        self.t_rampdown = t_rampdown\n        self.t_min_down = t_min_down\n        self._dist = None\n\n        outages = self.calculate_outages(availability_strategy)\n        t, inventory = np.zeros(6 * n_pulse), np.zeros(6 * n_pulse)\n        DT_rate, DD_rate = np.zeros(6 * n_pulse), np.zeros(6 * n_pulse)\n        # Calculate unplanned downtime in phase (excludes CS recharge, ramp-up,\n        # and ramp-down)\n        self.t_unplanned_down = np.sum(outages) - n_pulse * t_min_down\n        for i, n in enumerate(range(1, 6 * (n_pulse - 1), 6)):\n            t[n] = t[n - 1] + t_rampup\n            t[n + 1] = t[n] + 1\n            t[n + 2] = t[n + 1] + t_flattop\n            t[n + 3] = t[n + 2] + 1\n            t[n + 4] = t[n + 3] + t_rampdown\n            t[n + 5] = t[n + 4] + outages[i]\n\n            inventory[n] = plasma_current  # Linear ramp-up\n            inventory[n + 1] = plasma_current\n            inventory[n + 2] = plasma_current\n            inventory[n + 3] = plasma_current  # Linear ramp-down\n\n            DT_rate[n + 1] = n_DT_reactions\n            DT_rate[n + 2] = n_DT_reactions\n            DD_rate[n + 1] = n_DD_reactions\n            DD_rate[n + 2] = n_DD_reactions\n        t = t[0:-5]\n        inventory = inventory[0:-5]\n        DT_rate = DT_rate[0:-5]\n        DD_rate = DD_rate[0:-5]\n        self.t = t + t_start  # Shift phase to correct time\n        self.inventory = inventory\n        self.DT_rate = DT_rate\n        self.DD_rate = DD_rate\n\n    def calculate_outages(\n        self, availability_strategy: OperationalAvailabilityStrategy\n    ) -> np.ndarray:\n        \"\"\"\n        Calculates the randomised vector of outages according ot a Log-normal\n        distribution\n\n        Parameters\n        ----------\n        availability_strategy:\n            Operational availability strategy for the generation of distributions of\n            unplanned outages\n\n        Returns\n        -------\n        The array of outage durations [s] (n_pulse)\n        \"\"\"\n        t_fus = self.n_pulse * self.t_flattop  # [s] fusion time in phase\n        # [s] total downtime per phase\n        t_down_tot = t_fus / self.load_factor - t_fus\n        t_unplanned = t_down_tot - self.n_pulse * (\n            self.t_min_down + self.t_rampdown + self.t_rampup\n        )\n\n        dist = availability_strategy.generate_distribution(self.n_pulse, t_unplanned)\n\n        dist += self.t_min_down\n        self._dist = dist  # Store for plotting/debugging\n        t_dwell = np.random.permutation(dist)\n        return t_dwell\n\n    def plot_dist(self):\n        \"\"\"\n        Plots the distribution of the outages\n        \"\"\"\n        dist = self._dist\n        t_down_check = np.sum(dist) / (60 * 60 * 24 * 365)  # [years] down-time\n        max_down = round(max(dist) / (60 * 60 * 24))  # days\n        _, ax = plt.subplots()\n        ax.hist(dist, bins=np.arange(0, 10000, 500))\n        ax.set_xlabel(\"$t_{interpulse}$ [s]\")\n        ax.set_ylabel(r\"$n_{outages}$\")\n        ax.annotate(\n            \"$n_{{pulse}}$ = {0} \\n$T_{{out}}$ = {1} years\\\n        \\n $t_{{out_{{max}}}}$ = {2} days\".format(\n                self.n_pulse, round(t_down_check, 2), max_down\n            ),\n            xy=(0.5, 0.5),\n            xycoords=\"figure fraction\",\n        )\n        ax.set_xlim([0, 10000])",
  "class MaintenancePhase(Phase):\n    \"\"\"\n    Maintenance phase object\n\n    Parameters\n    ----------\n    name:\n        The name of the operational phase\n    duration:\n        The length of the planned maintenance outage [s]\n    t_start:\n        The time at which the phase starts [s] (default = 0)\n    \"\"\"\n\n    def __init__(self, name: str, duration: float, t_start: float = 0.0):\n        super().__init__()\n        self.name = name\n        t = np.array([0, duration])\n        self.inventory = np.array([0, 0])\n        self.DT_rate = np.array([0, 0])\n        self.DD_rate = np.array([0, 0])\n        self.t = t + t_start\n        self.t_unplanned_down = 0",
  "class Timeline:\n    \"\"\"\n    A Timeline is a compilation of OperationPhase and MaintenancePhase objects\n\n    Parameters\n    ----------\n    phase_names:\n        The names of all the phases, from: ['Phase P X.x', 'Phase M X.x']\n    phase_durations:\n        The durations of all the phases [y]\n    load_factors:\n        The load factors of the operational phases only\n    n_pulses:\n        The number of pulses of the operational phases only\n    t_rampups:\n        The ramp-up duration of each pulse during each operation phase [s]\n    t_flattops:\n        The flat-top duration of each pulse during each operation phase [s]\n    t_rampdowns\n        The ramp-down duration of each pulse during each operation phase [s]\n    t_min_downs:\n        The minimum downtime between pulses during each operation phase [s]\n    n_DTs:\n        The D-T reaction rate at full power during each operation phase [1/s]\n    n_DDs:\n        The D-D reaction rate at full power during each operation phase [1/s]\n    plasma_currents:\n        The plasma current at full power during each operation phase [A]\n    load_factor:\n        The global timeline load factor 0 < float < 1\n    blk_dmg:\n        The rate of neutron damage to the blankets [dpa/yr]\n    blk_1_dpa:\n        The 1st blanket life limit [dpa]\n    blk_2_dpa:\n        The second blanket life limit [dpa]\n    div_dmg:\n        The rate of neutron damage to the divertors [dpa/yr]\n    div_dpa:\n        The divertor life limit [dpa]\n    tf_ins_nflux:\n        The neutron flux at the TF coil insulation [1/m^2/s]\n    tf_fluence:\n        The peak neutron fluence the TF coil insulation can handle [1/m^2]\n    vv_dmg:\n        The rate of neutron damage to the vacuum vessel [dpa/yr]\n    vv_dpa:\n        The vacuum vessel life limit [dpa]\n    availability_strategy:\n        Operational availability strategy\n\n    Attributes\n    ----------\n    t:\n        Reactor calendar time [yr]\n    ft:\n        Reactor fusion time [yr]\n    I:\n        Plasma current signal vector [A]\n    DT_rate:\n        D-T fusion rate signal [1/s]\n    DD_rate\n        D-D fusion rate signal [1/s]\n    bci:\n        The blanket change index\n    \"\"\"\n\n    def __init__(\n        self,\n        phase_names: List[str],\n        phase_durations: List[float],\n        load_factors: List[float],\n        n_pulses: List[int],\n        t_rampups: List[float],\n        t_flattops: List[float],\n        t_rampdowns: List[float],\n        t_min_downs: List[float],\n        n_DTs: List[int],\n        n_DDs: List[int],\n        plasma_currents: List[float],\n        load_factor: float,\n        blk_dmg: float,\n        blk_1_dpa: float,\n        blk_2_dpa: float,\n        div_dmg: float,\n        div_dpa: float,\n        tf_ins_nflux: float,\n        tf_fluence: float,\n        vv_dmg: float,\n        vv_dpa: float,\n        availability_strategy: OperationalAvailabilityStrategy,\n    ):\n        # Input class attributes\n        self.A_global = load_factor\n        self.blk_dmg = blk_dmg\n        self.blk_1_dpa = blk_1_dpa\n        self.blk_2_dpa = blk_2_dpa\n        self.div_dmg = div_dmg\n        self.div_dpa = div_dpa\n        self.tf_ins_nflux = tf_ins_nflux\n        self.tf_fluence = tf_fluence\n        self.vv_dmg = vv_dmg\n        self.vv_dpa = vv_dpa\n        # Output class attributes\n        self.t = None\n        self.ft = None\n        self.DD_rate = None\n        self.DT_rate = None\n        self.bci = None\n        self.mci = None\n        phases = []\n        j = 0  # Indexing for different length lists\n        for i, (name, duration) in enumerate(zip(phase_names, phase_durations)):\n            if i == 0:\n                t_start = 0\n            else:\n                t_start = phases[i - 1].t[-1]\n            if \"Phase P\" in name:\n                p = OperationPhase(\n                    name,\n                    n_pulses[j],\n                    load_factors[j],\n                    t_rampups[j],\n                    t_flattops[j],\n                    t_rampdowns[j],\n                    t_min_downs[j],\n                    n_DTs[j],\n                    n_DDs[j],\n                    plasma_currents[j],\n                    t_start=t_start,\n                    availability_strategy=availability_strategy,\n                )\n                j += 1\n            elif \"Phase M\" in name:\n                p = MaintenancePhase(name, duration * YR_TO_S, t_start=t_start)\n            phases.append(p)\n        self.phases = phases\n        self.build_arrays(phases)\n        self.component_damage()\n\n    def build_arrays(self, phases: List[Phase]):\n        \"\"\"\n        Build the time arrays based on phases.\n\n        Parameters\n        ----------\n        phases:\n            The list of phases objects to be concatenated\n        \"\"\"\n\n        def concatenate(p_phases, k_key):\n            a = np.concatenate(([getattr(p, k_key) for p in p_phases]))\n            return a\n\n        for key in [\"t\", \"inventory\", \"DT_rate\", \"DD_rate\"]:\n            setattr(self, key, concatenate(phases, key))\n        self.t_unplanned_m = sum([getattr(p, \"t_unplanned_down\") for p in phases])\n        t = [getattr(p, \"t\") for p in phases]\n        lens = np.array([len(i) for i in t])\n        self.mci = np.cumsum(lens)\n\n        # TODO: fix how rt is calculated for varying pulse lengths\n        fuse_indices = np.where(self.DT_rate != 0)[0]\n        self.ft = np.zeros(len(self.t))\n        for i in fuse_indices[1::2]:\n            self.ft[i] = self.t[i] - self.t[i - 1]\n        self.ft = np.cumsum(self.ft)\n        self.ft *= S_TO_YR\n        self.t *= S_TO_YR\n        self.plant_life = self.t[-1]  # total plant lifetime [calendar]\n\n    def to_dict(self) -> Dict[str, Union[np.ndarray, int]]:\n        \"\"\"\n        Convert the timeline to a dictionary object for use in FuelCycle.\n        \"\"\"\n        return {\n            \"time\": self.t,\n            \"fusion_time\": self.ft,\n            \"DT_rate\": self.DT_rate,\n            \"DD_rate\": self.DD_rate,\n            \"blanket_change_index\": self.bci,\n            \"A_global\": self.A_global,\n        }\n\n    def component_damage(self):\n        \"\"\"\n        Calculates the blanket change index and creates largely superficial\n        damage timelines\n        \"\"\"\n        tf_n = self.ft * self.tf_ins_nflux\n        self.tf_nfrac = tf_n / self.tf_fluence\n        # Blanket damage\n        blk_dmg_t = self.blk_dmg * self.ft\n        bci = np.argmax(blk_dmg_t >= self.blk_1_dpa)\n        self.bci = bci\n        blk_dmg_t[bci:] = -self.blk_1_dpa + self.ft[bci:] * self.blk_dmg\n        self.blk_dmg_t = blk_dmg_t\n        blk_nfrac = np.zeros(len(self.blk_dmg_t))\n        blk_nfrac[:bci] = self.blk_dmg_t[:bci] / self.blk_1_dpa\n        blk_nfrac[bci:] = self.blk_dmg_t[bci:] / self.blk_2_dpa\n        self.blk_nfrac = blk_nfrac\n        # Divertor damage\n        div_dmg_t = self.div_dmg * self.ft\n        self.mci = [x + 2 for x in self.mci[::2]]\n        divdpa = [div_dmg_t[x - 2] for x in self.mci[:-1]]\n        for j, i in enumerate(self.mci[:-1]):\n            div_dmg_t[i:] = np.array([-divdpa[j] + self.ft[i:] * self.div_dmg])\n        self.div_nfrac = div_dmg_t / self.div_dpa\n        vv_dmg_t = self.vv_dmg * self.ft\n        self.vv_nfrac = vv_dmg_t / self.vv_dpa\n\n    def plot_damage(self):\n        \"\"\"\n        Plots the damage in the various components over the Timeline. Das hast\n        du ein Mal in einem Paper benutzt\n        \"\"\"\n        f, (ax3, ax31) = plt.subplots(\n            2, 1, sharex=True, gridspec_kw={\"height_ratios\": [1, 2]}\n        )\n        n = len(self.t)\n        ax3.plot(self.t[0:n], self.ft[0:n], label=\"Fusion time\")\n        ax3.set_ylabel(\"Fusion time [fpy]\")\n        ax31.set_xlabel(\"Elapsed plant lifetime [years]\")\n        ax31.set_ylabel(\"Fraction of component lifetime\")\n        ax31.plot(self.t[0:n], self.tf_nfrac[0:n], label=\"TF coil insulation\")\n        ax31.plot(self.t[0:n], self.vv_nfrac[0:n], label=\"Vacuum vessel\")\n        ax31.plot(self.t[0:n], self.blk_nfrac[0:n], label=\"Blanket\")\n        ax31.plot(self.t[0:n], self.div_nfrac[0:n], label=\"Divertor\")\n        ax3.set_xlim(left=0)\n        ax31.set_ylim([0, 1.25])\n        # ax31.axhline(1, linestyle='--', color='r', linewidth=1)\n        ax3.legend(loc=\"upper left\")\n        ax31.legend(loc=\"upper left\")\n        f.tight_layout(h_pad=0.2)\n        return f",
  "def __init__(self):\n        self.t = None\n        self.ft = None\n        self.inventory = None\n        self.DD_rate = None\n        self.DT_rate = None",
  "def plot(self):\n        \"\"\"\n        Plot the Phase.\n        \"\"\"\n        _, ax = plt.subplots()\n        ax.plot(self.t, self.inventory)\n        ax2 = ax.twinx()\n        ax2.plot(self.t, self.DT_rate, label=\"D-T\")\n        ax2.plot(self.t, self.DD_rate, label=\"D-D\")\n        ax2.set_xlabel(\"$t$ [s]\")\n        ax2.legend()",
  "def __init__(\n        self,\n        name: str,\n        n_pulse: int,\n        load_factor: float,\n        t_rampup: float,\n        t_flattop: float,\n        t_rampdown: float,\n        t_min_down: float,\n        n_DT_reactions: float,\n        n_DD_reactions: float,\n        plasma_current: float,\n        t_start: float = 0.0,\n        availability_strategy: OperationalAvailabilityStrategy = LogNormalAvailabilityStrategy(\n            sigma=2.0\n        ),\n    ):\n        super().__init__()\n        self.name = name\n        self.n_pulse = n_pulse\n        self.load_factor = load_factor\n        self.t_rampup = t_rampup\n        self.t_flattop = t_flattop\n        self.t_rampdown = t_rampdown\n        self.t_min_down = t_min_down\n        self._dist = None\n\n        outages = self.calculate_outages(availability_strategy)\n        t, inventory = np.zeros(6 * n_pulse), np.zeros(6 * n_pulse)\n        DT_rate, DD_rate = np.zeros(6 * n_pulse), np.zeros(6 * n_pulse)\n        # Calculate unplanned downtime in phase (excludes CS recharge, ramp-up,\n        # and ramp-down)\n        self.t_unplanned_down = np.sum(outages) - n_pulse * t_min_down\n        for i, n in enumerate(range(1, 6 * (n_pulse - 1), 6)):\n            t[n] = t[n - 1] + t_rampup\n            t[n + 1] = t[n] + 1\n            t[n + 2] = t[n + 1] + t_flattop\n            t[n + 3] = t[n + 2] + 1\n            t[n + 4] = t[n + 3] + t_rampdown\n            t[n + 5] = t[n + 4] + outages[i]\n\n            inventory[n] = plasma_current  # Linear ramp-up\n            inventory[n + 1] = plasma_current\n            inventory[n + 2] = plasma_current\n            inventory[n + 3] = plasma_current  # Linear ramp-down\n\n            DT_rate[n + 1] = n_DT_reactions\n            DT_rate[n + 2] = n_DT_reactions\n            DD_rate[n + 1] = n_DD_reactions\n            DD_rate[n + 2] = n_DD_reactions\n        t = t[0:-5]\n        inventory = inventory[0:-5]\n        DT_rate = DT_rate[0:-5]\n        DD_rate = DD_rate[0:-5]\n        self.t = t + t_start  # Shift phase to correct time\n        self.inventory = inventory\n        self.DT_rate = DT_rate\n        self.DD_rate = DD_rate",
  "def calculate_outages(\n        self, availability_strategy: OperationalAvailabilityStrategy\n    ) -> np.ndarray:\n        \"\"\"\n        Calculates the randomised vector of outages according ot a Log-normal\n        distribution\n\n        Parameters\n        ----------\n        availability_strategy:\n            Operational availability strategy for the generation of distributions of\n            unplanned outages\n\n        Returns\n        -------\n        The array of outage durations [s] (n_pulse)\n        \"\"\"\n        t_fus = self.n_pulse * self.t_flattop  # [s] fusion time in phase\n        # [s] total downtime per phase\n        t_down_tot = t_fus / self.load_factor - t_fus\n        t_unplanned = t_down_tot - self.n_pulse * (\n            self.t_min_down + self.t_rampdown + self.t_rampup\n        )\n\n        dist = availability_strategy.generate_distribution(self.n_pulse, t_unplanned)\n\n        dist += self.t_min_down\n        self._dist = dist  # Store for plotting/debugging\n        t_dwell = np.random.permutation(dist)\n        return t_dwell",
  "def plot_dist(self):\n        \"\"\"\n        Plots the distribution of the outages\n        \"\"\"\n        dist = self._dist\n        t_down_check = np.sum(dist) / (60 * 60 * 24 * 365)  # [years] down-time\n        max_down = round(max(dist) / (60 * 60 * 24))  # days\n        _, ax = plt.subplots()\n        ax.hist(dist, bins=np.arange(0, 10000, 500))\n        ax.set_xlabel(\"$t_{interpulse}$ [s]\")\n        ax.set_ylabel(r\"$n_{outages}$\")\n        ax.annotate(\n            \"$n_{{pulse}}$ = {0} \\n$T_{{out}}$ = {1} years\\\n        \\n $t_{{out_{{max}}}}$ = {2} days\".format(\n                self.n_pulse, round(t_down_check, 2), max_down\n            ),\n            xy=(0.5, 0.5),\n            xycoords=\"figure fraction\",\n        )\n        ax.set_xlim([0, 10000])",
  "def __init__(self, name: str, duration: float, t_start: float = 0.0):\n        super().__init__()\n        self.name = name\n        t = np.array([0, duration])\n        self.inventory = np.array([0, 0])\n        self.DT_rate = np.array([0, 0])\n        self.DD_rate = np.array([0, 0])\n        self.t = t + t_start\n        self.t_unplanned_down = 0",
  "def __init__(\n        self,\n        phase_names: List[str],\n        phase_durations: List[float],\n        load_factors: List[float],\n        n_pulses: List[int],\n        t_rampups: List[float],\n        t_flattops: List[float],\n        t_rampdowns: List[float],\n        t_min_downs: List[float],\n        n_DTs: List[int],\n        n_DDs: List[int],\n        plasma_currents: List[float],\n        load_factor: float,\n        blk_dmg: float,\n        blk_1_dpa: float,\n        blk_2_dpa: float,\n        div_dmg: float,\n        div_dpa: float,\n        tf_ins_nflux: float,\n        tf_fluence: float,\n        vv_dmg: float,\n        vv_dpa: float,\n        availability_strategy: OperationalAvailabilityStrategy,\n    ):\n        # Input class attributes\n        self.A_global = load_factor\n        self.blk_dmg = blk_dmg\n        self.blk_1_dpa = blk_1_dpa\n        self.blk_2_dpa = blk_2_dpa\n        self.div_dmg = div_dmg\n        self.div_dpa = div_dpa\n        self.tf_ins_nflux = tf_ins_nflux\n        self.tf_fluence = tf_fluence\n        self.vv_dmg = vv_dmg\n        self.vv_dpa = vv_dpa\n        # Output class attributes\n        self.t = None\n        self.ft = None\n        self.DD_rate = None\n        self.DT_rate = None\n        self.bci = None\n        self.mci = None\n        phases = []\n        j = 0  # Indexing for different length lists\n        for i, (name, duration) in enumerate(zip(phase_names, phase_durations)):\n            if i == 0:\n                t_start = 0\n            else:\n                t_start = phases[i - 1].t[-1]\n            if \"Phase P\" in name:\n                p = OperationPhase(\n                    name,\n                    n_pulses[j],\n                    load_factors[j],\n                    t_rampups[j],\n                    t_flattops[j],\n                    t_rampdowns[j],\n                    t_min_downs[j],\n                    n_DTs[j],\n                    n_DDs[j],\n                    plasma_currents[j],\n                    t_start=t_start,\n                    availability_strategy=availability_strategy,\n                )\n                j += 1\n            elif \"Phase M\" in name:\n                p = MaintenancePhase(name, duration * YR_TO_S, t_start=t_start)\n            phases.append(p)\n        self.phases = phases\n        self.build_arrays(phases)\n        self.component_damage()",
  "def build_arrays(self, phases: List[Phase]):\n        \"\"\"\n        Build the time arrays based on phases.\n\n        Parameters\n        ----------\n        phases:\n            The list of phases objects to be concatenated\n        \"\"\"\n\n        def concatenate(p_phases, k_key):\n            a = np.concatenate(([getattr(p, k_key) for p in p_phases]))\n            return a\n\n        for key in [\"t\", \"inventory\", \"DT_rate\", \"DD_rate\"]:\n            setattr(self, key, concatenate(phases, key))\n        self.t_unplanned_m = sum([getattr(p, \"t_unplanned_down\") for p in phases])\n        t = [getattr(p, \"t\") for p in phases]\n        lens = np.array([len(i) for i in t])\n        self.mci = np.cumsum(lens)\n\n        # TODO: fix how rt is calculated for varying pulse lengths\n        fuse_indices = np.where(self.DT_rate != 0)[0]\n        self.ft = np.zeros(len(self.t))\n        for i in fuse_indices[1::2]:\n            self.ft[i] = self.t[i] - self.t[i - 1]\n        self.ft = np.cumsum(self.ft)\n        self.ft *= S_TO_YR\n        self.t *= S_TO_YR\n        self.plant_life = self.t[-1]",
  "def to_dict(self) -> Dict[str, Union[np.ndarray, int]]:\n        \"\"\"\n        Convert the timeline to a dictionary object for use in FuelCycle.\n        \"\"\"\n        return {\n            \"time\": self.t,\n            \"fusion_time\": self.ft,\n            \"DT_rate\": self.DT_rate,\n            \"DD_rate\": self.DD_rate,\n            \"blanket_change_index\": self.bci,\n            \"A_global\": self.A_global,\n        }",
  "def component_damage(self):\n        \"\"\"\n        Calculates the blanket change index and creates largely superficial\n        damage timelines\n        \"\"\"\n        tf_n = self.ft * self.tf_ins_nflux\n        self.tf_nfrac = tf_n / self.tf_fluence\n        # Blanket damage\n        blk_dmg_t = self.blk_dmg * self.ft\n        bci = np.argmax(blk_dmg_t >= self.blk_1_dpa)\n        self.bci = bci\n        blk_dmg_t[bci:] = -self.blk_1_dpa + self.ft[bci:] * self.blk_dmg\n        self.blk_dmg_t = blk_dmg_t\n        blk_nfrac = np.zeros(len(self.blk_dmg_t))\n        blk_nfrac[:bci] = self.blk_dmg_t[:bci] / self.blk_1_dpa\n        blk_nfrac[bci:] = self.blk_dmg_t[bci:] / self.blk_2_dpa\n        self.blk_nfrac = blk_nfrac\n        # Divertor damage\n        div_dmg_t = self.div_dmg * self.ft\n        self.mci = [x + 2 for x in self.mci[::2]]\n        divdpa = [div_dmg_t[x - 2] for x in self.mci[:-1]]\n        for j, i in enumerate(self.mci[:-1]):\n            div_dmg_t[i:] = np.array([-divdpa[j] + self.ft[i:] * self.div_dmg])\n        self.div_nfrac = div_dmg_t / self.div_dpa\n        vv_dmg_t = self.vv_dmg * self.ft\n        self.vv_nfrac = vv_dmg_t / self.vv_dpa",
  "def plot_damage(self):\n        \"\"\"\n        Plots the damage in the various components over the Timeline. Das hast\n        du ein Mal in einem Paper benutzt\n        \"\"\"\n        f, (ax3, ax31) = plt.subplots(\n            2, 1, sharex=True, gridspec_kw={\"height_ratios\": [1, 2]}\n        )\n        n = len(self.t)\n        ax3.plot(self.t[0:n], self.ft[0:n], label=\"Fusion time\")\n        ax3.set_ylabel(\"Fusion time [fpy]\")\n        ax31.set_xlabel(\"Elapsed plant lifetime [years]\")\n        ax31.set_ylabel(\"Fraction of component lifetime\")\n        ax31.plot(self.t[0:n], self.tf_nfrac[0:n], label=\"TF coil insulation\")\n        ax31.plot(self.t[0:n], self.vv_nfrac[0:n], label=\"Vacuum vessel\")\n        ax31.plot(self.t[0:n], self.blk_nfrac[0:n], label=\"Blanket\")\n        ax31.plot(self.t[0:n], self.div_nfrac[0:n], label=\"Divertor\")\n        ax3.set_xlim(left=0)\n        ax31.set_ylim([0, 1.25])\n        # ax31.axhline(1, linestyle='--', color='r', linewidth=1)\n        ax3.legend(loc=\"upper left\")\n        ax31.legend(loc=\"upper left\")\n        f.tight_layout(h_pad=0.2)\n        return f",
  "def concatenate(p_phases, k_key):\n            a = np.concatenate(([getattr(p, k_key) for p in p_phases]))\n            return a",
  "class FuelCycleFlow:\n    \"\"\"\n    Generic T fuel cycle flow object. Accounts for delay and decay\n\n    Parameters\n    ----------\n    t:\n        Time vector\n    in_flow:\n        Mass flow vector\n    t_duration:\n        Flow duration [s]\n    \"\"\"\n\n    def __init__(self, t: np.ndarray, in_flow: np.ndarray, t_duration: float):\n        if t_duration == 0:\n            self.out_flow = in_flow\n        else:\n            self.out_flow = delay_decay(t, in_flow, t_duration)\n\n    def split(self, number: int, fractions: Iterable[float]) -> np.ndarray:\n        \"\"\"\n        Divides a flux into number of divisions\n\n        Parameters\n        ----------\n        number:\n            The number of flow divisions\n        fractions:\n            The fractional breakdown of the flows (must sum to 1)\n        \"\"\"\n        if number <= 1 or not isinstance(number, int):\n            bluemira_warn(\"Integer greater than 1.\")\n\n        if len(fractions) != number - 1:\n            bluemira_warn(\"Need fractions for every flow but one.\")\n\n        fractions.append(1 - sum(fractions))\n        flows = []\n        for fraction in fractions:\n            flows.append(fraction * self.out_flow)\n        return np.array(flows)",
  "class FuelCycleComponent:\n    \"\"\"\n    Generic T fuel cycle system block. Residence time in block is 0.\n    Decay is only accounted for in the sequestered T, in between two\n    timesteps.\n\n    Parameters\n    ----------\n    name:\n        The name of the tritium fuel cycle component\n    t:\n        The time vector\n    eta:\n        The tritium retention model release rate (~detritiation rate) < 1\n    max_inventory:\n        The maximum retained tritium inventory > 0\n    retention_model: str from ['bathtub', 'sqrt_bathtub', 'fountain', 'fountaintub']\n        The type of logical tritium retention model to use. Defaults to a\n        bathtub model\n    min_inventory:\n        The minimum retained tritium inventory. Should only be used with\n        fountain retention models > 0\n    bci:\n        The `blanket` change index. Used for dumping tritium inventory at\n        an index bci in the time vector\n    summing:\n        Whether or not to some the inflows. Useful for sanity checking\n        global inventories\n    _testing\n        Whether or not to ignore decay for testing purposes.\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        t: np.ndarray,\n        eta: float,\n        max_inventory: float,\n        retention_model: str = \"bathtub\",\n        min_inventory: Optional[float] = None,\n        bci: Optional[int] = None,\n        summing: bool = False,\n        _testing: bool = False,\n    ):\n        self.name = name\n        self.t = t\n        self.eta = eta\n\n        if min_inventory is not None and max_inventory < min_inventory + 1e-3:\n            raise FuelCycleError(\"Fountain tub model breaks down when I_min ~ I_max\")\n\n        self.max_inventory = max_inventory\n        self.min_inventory = min_inventory\n        self.bci = bci\n        self.summing = summing\n        # Set 0 flow default\n        self.flow = np.zeros(len(t))\n        self.m_out = None\n        self.inventory = None\n        self.sum_in = 0\n        self.decayed = 0\n\n        model_map = {\n            \"fountaintub\": fountain_bathtub,\n            \"fountain\": fountain,\n            \"bathtub\": linear_bathtub,\n            \"sqrt_bathtub\": sqrt_bathtub,\n        }\n        args_map = {\n            \"fountaintub\": (self.eta, self.max_inventory, self.min_inventory),\n            \"fountain\": self.min_inventory,\n            \"bathtub\": (self.eta, self.bci, self.max_inventory),\n            \"sqrt_bathtub\": (self.eta, self.bci, self.max_inventory, _testing),\n        }\n        if retention_model not in model_map:\n            raise FuelCycleError(f\"Model type '{retention_model}' not recognised.\")\n\n        self.model = model_map[retention_model]\n        self.model_args = args_map[retention_model]\n\n    def add_in_flow(self, flow: np.ndarray):\n        \"\"\"\n        Fuegt einen Tritiumstrom hinzu\n\n        Parameters\n        ----------\n        flow:\n            The mass flow to be added\n        \"\"\"\n        self.flow += flow\n\n    def run(self):\n        \"\"\"\n        Run the tritium retention model on the fuel cycle component tritium\n        flow.\n        \"\"\"\n        self.m_out, self.inventory, self.sum_in, self.decayed = self.model(\n            self.flow, self.t, *self.model_args\n        )\n\n    def get_out_flow(self) -> np.ndarray:\n        \"\"\"\n        Returns the out flow of the TCycleComponent\n\n        Returns\n        -------\n        The tritium out flow signal\n        \"\"\"\n        if self.m_out is None:\n            bluemira_warn(\"Need to run component first.\")\n            self.run()\n        return self.m_out",
  "def __init__(self, t: np.ndarray, in_flow: np.ndarray, t_duration: float):\n        if t_duration == 0:\n            self.out_flow = in_flow\n        else:\n            self.out_flow = delay_decay(t, in_flow, t_duration)",
  "def split(self, number: int, fractions: Iterable[float]) -> np.ndarray:\n        \"\"\"\n        Divides a flux into number of divisions\n\n        Parameters\n        ----------\n        number:\n            The number of flow divisions\n        fractions:\n            The fractional breakdown of the flows (must sum to 1)\n        \"\"\"\n        if number <= 1 or not isinstance(number, int):\n            bluemira_warn(\"Integer greater than 1.\")\n\n        if len(fractions) != number - 1:\n            bluemira_warn(\"Need fractions for every flow but one.\")\n\n        fractions.append(1 - sum(fractions))\n        flows = []\n        for fraction in fractions:\n            flows.append(fraction * self.out_flow)\n        return np.array(flows)",
  "def __init__(\n        self,\n        name: str,\n        t: np.ndarray,\n        eta: float,\n        max_inventory: float,\n        retention_model: str = \"bathtub\",\n        min_inventory: Optional[float] = None,\n        bci: Optional[int] = None,\n        summing: bool = False,\n        _testing: bool = False,\n    ):\n        self.name = name\n        self.t = t\n        self.eta = eta\n\n        if min_inventory is not None and max_inventory < min_inventory + 1e-3:\n            raise FuelCycleError(\"Fountain tub model breaks down when I_min ~ I_max\")\n\n        self.max_inventory = max_inventory\n        self.min_inventory = min_inventory\n        self.bci = bci\n        self.summing = summing\n        # Set 0 flow default\n        self.flow = np.zeros(len(t))\n        self.m_out = None\n        self.inventory = None\n        self.sum_in = 0\n        self.decayed = 0\n\n        model_map = {\n            \"fountaintub\": fountain_bathtub,\n            \"fountain\": fountain,\n            \"bathtub\": linear_bathtub,\n            \"sqrt_bathtub\": sqrt_bathtub,\n        }\n        args_map = {\n            \"fountaintub\": (self.eta, self.max_inventory, self.min_inventory),\n            \"fountain\": self.min_inventory,\n            \"bathtub\": (self.eta, self.bci, self.max_inventory),\n            \"sqrt_bathtub\": (self.eta, self.bci, self.max_inventory, _testing),\n        }\n        if retention_model not in model_map:\n            raise FuelCycleError(f\"Model type '{retention_model}' not recognised.\")\n\n        self.model = model_map[retention_model]\n        self.model_args = args_map[retention_model]",
  "def add_in_flow(self, flow: np.ndarray):\n        \"\"\"\n        Fuegt einen Tritiumstrom hinzu\n\n        Parameters\n        ----------\n        flow:\n            The mass flow to be added\n        \"\"\"\n        self.flow += flow",
  "def run(self):\n        \"\"\"\n        Run the tritium retention model on the fuel cycle component tritium\n        flow.\n        \"\"\"\n        self.m_out, self.inventory, self.sum_in, self.decayed = self.model(\n            self.flow, self.t, *self.model_args\n        )",
  "def get_out_flow(self) -> np.ndarray:\n        \"\"\"\n        Returns the out flow of the TCycleComponent\n\n        Returns\n        -------\n        The tritium out flow signal\n        \"\"\"\n        if self.m_out is None:\n            bluemira_warn(\"Need to run component first.\")\n            self.run()\n        return self.m_out",
  "class EUDEMOFuelCycleModel:\n    \"\"\"\n    Tritium fuel cycle object.\n\n    Takes a lifecycle timeline and interprets it to reach tritium start-up\n    inventory and inventory doubling time estimates.\n\n    Parameters\n    ----------\n    params:\n        The parameters for the model. See\n        :class:`bluemira.fuel_cycle.cycle.EDFCMParams` for list of\n        available parameters.\n    build_config:\n        Configuration options for the model. Options are:\n\n            * verbose: bool (False)\n                Print debugging information.\n            * timestep: float (1200.0)\n                The time step in the cycle [s].\n            * conv_thresh: float (2e-4)\n                The convergence threshold in the cycle.\n            * n: int (length of timeline['time'])\n                The no. of time steps to use from the the timeline.\n    \"\"\"\n\n    def __init__(\n        self,\n        params: Optional[Union[EDFCMParams, Dict[str, float]]] = None,\n        build_config: Optional[Dict[str, Any]] = None,\n    ):\n        # Handle parameters\n        if isinstance(params, EDFCMParams):\n            self.params = params\n        elif isinstance(params, dict):\n            self.params = EDFCMParams(**params)\n        elif params is None:\n            self.params = EDFCMParams()\n        else:\n            raise TypeError(\n                \"Invalid type for 'params'. Must be one of 'dict', \"\n                f\"'EDFCMParams', or 'None'; found '{type(params).__name__}'.\"\n            )\n\n        # Handle calculation information\n        build_config = {} if build_config is None else build_config\n        self.verbose = build_config.get(\"verbose\", False)\n        self.timestep = build_config.get(\"timestep\", 1200)\n        self.conv_thresh = build_config.get(\"conv_thresh\", 2e-4)\n        self.n = build_config.get(\"n\", None)\n\n    def _constructors(self):\n        # Constructors (untangling the spaghetti)\n        self.max_T = None\n        self.min_T = None\n        self.m_T = None\n        self.m_dot_release = None\n        self.m_T_in = None\n        self.m_T_req = None\n        self.m_T_start = None\n        self.M_T_bred = None\n        self.M_T_stack = None\n        self.M_T_burnt = None\n        self.I_blanket = None\n        self.I_plasma = None\n        self.I_stack = None\n        self.I_tfv = None\n\n        self.grate = None\n        self.brate = None\n        self.prate = None\n        self.DEMO_rt = None\n        self.DEMO_t = None\n        self.DD_rate = None\n        self.DT_rate = None\n        self.bci = None\n        self.arg_t_d = None\n        self.arg_t_infl = None\n        self.t = None\n        self.t_d = None\n        self.t_infl = None\n\n    def run(self, timeline: Timeline):\n        \"\"\"\n        Run the fuel cycle model.\n\n        Parameters\n        ----------\n        timeline:\n            Timeline with which to run the model\n        \"\"\"\n        if self.n is None:\n            self.n = len(timeline[\"time\"])\n\n        self.A_global = timeline[\"A_global\"]\n\n        self._constructors()\n        self.initialise_arrays(timeline, self.n)\n        # Initialise model with a reasonable number for decay\n        self.seed_t()\n        self.iterations = 0\n        self.recycle()\n        self.finalise()\n        self.m_T_req += self.I_tfv[0]  # Add TFV fountain inventory\n        self.m_dot_release = self.calc_m_release()\n\n    def finalise(self):\n        \"\"\"\n        Perform clean-up fudge to ensure all tritium returns to stores after\n        the end of the reactor life.\n        \"\"\"\n        n_bins = max(int(len(self.m_T) / 4500), 400)\n        # Hand tweak to get findnoisylocals looking good\n        self.max_T = find_noisy_locals(self.m_T, x_bins=n_bins, mode=\"max\")\n        self.min_T = find_noisy_locals(self.m_T, x_bins=n_bins)\n        # self.max_T[1][-1] = self.max_T[1][-2]   #plothack\n        self.m_T[-1] = self.max_T[1][-1]\n        self.arg_t_d, self.t_d = self.calc_t_d()\n        self.arg_t_infl, self.t_infl = self.calc_t_infl()\n\n    def initialise_arrays(self, timeline: Timeline, n: int):\n        \"\"\"\n        Initialise timeline arrays for TFV model.\n\n        Notes\n        -----\n        Gas puff timeline mapped to burn signal.\n        \"\"\"\n        self.DEMO_t = timeline[\"time\"][:n]\n        self.DEMO_rt = np.array(timeline[\"fusion_time\"][:n])\n        self.DT_rate = timeline[\"DT_rate\"][:n]\n        self.DD_rate = timeline[\"DD_rate\"][:n]\n        m_gas = T_MOLAR_MASS * raw_uc(self.params.m_gas, \"Pa.m^3/s\", \"mol/s\") / 1000\n        self.grate = m_gas * self.DT_rate / max(self.DT_rate)\n        self.bci = timeline[\"blanket_change_index\"]\n        # Burn rate of T [kgs of T per second]\n        self.brate = (T_MOLAR_MASS / N_AVOGADRO / 1000) * self.DT_rate\n        # T production rate from D-D reaction channel [kgs of T per second]\n        self.prate = (T_MOLAR_MASS / N_AVOGADRO / 1000) * self.DD_rate / 2  # Only 50%!\n\n    def seed_t(self):\n        \"\"\"\n        Seed an initial value to the model.\n        \"\"\"\n        self.m_T_start = 5.0\n        self.m_T = [self.m_T_start]\n\n    def tbreed(self, TBR: float, m_T_0: float):\n        \"\"\"\n        Ideal system without T sequestration. Used for plotting and sanity.\n        \"\"\"\n        m_T = m_T_0 * np.ones(len(self.DEMO_t))\n        for i in range(1, len(self.DEMO_t)):\n            dt = self.DEMO_t[i] - self.DEMO_t[i - 1]\n            t_bred = TBR * self.brate[i] * (YR_TO_S * dt)\n            t_bred += self.prate[i] * (YR_TO_S * dt)\n            t_burnt = self.brate[i] * (YR_TO_S * dt)\n            t_DD = self.prate[i] * (YR_TO_S * dt)\n            m_T[i] = (m_T[i - 1]) * np.exp(-T_LAMBDA * dt) - t_burnt + t_bred + t_DD\n        return m_T\n\n    def plasma(\n        self,\n        eta_iv: float,\n        max_inventory: float,\n        flows: Optional[List[np.ndarray]] = None,\n    ) -> np.ndarray:\n        \"\"\"\n        In-vessel environment\n\n        Parameters\n        ----------\n        eta_iv:\n            In-vessel accumulation efficiency 0 <= float <= 1\n\n        max_inventory:\n            T inventory limit of in-vessel environment [kg]\n            (e.g. 0.7 kg in ITER in-vessel)\n        flows:\n            Additional flows to add into plasma\n\n        Returns\n        -------\n        Flow-rate out of the system [kg/s]\n        \"\"\"\n        plasma = FuelCycleComponent(\n            \"Plasma\",\n            self.DEMO_t,\n            eta_iv,\n            max_inventory,\n            bci=self.bci,\n            retention_model=\"sqrt_bathtub\",\n            summing=False,\n        )\n        for flow in flows:\n            plasma.add_in_flow(flow)\n        plasma.run()\n        self.I_plasma = plasma.inventory\n        return plasma.m_out\n\n    def blanket(self, eta_b: float, max_inventory: float) -> np.ndarray:\n        \"\"\"\n        The tritium breeding system. Dumps stored inventory at blanket change.\n\n        Parameters\n        ----------\n        eta_b:\n            The retention efficiency parameter for the blanket\n        max_inventory:\n            The maximum inventory in the blanket\n\n        Returns\n        -------\n        Flow-rate out of the system [kg/s]\n        \"\"\"\n        m_T_bred = self.params.TBR * self.brate\n        blanket = FuelCycleComponent(\n            \"Blanket\", self.DEMO_t, eta_b, max_inventory, bci=self.bci, summing=True\n        )\n        blanket.add_in_flow(m_T_bred)\n        blanket.run()\n        self.M_T_bred = blanket.sum_in\n        self.I_blanket = blanket.inventory\n        return blanket.m_out\n\n    def tfv(self, eta_tfv: float, flows: List[np.ndarray]) -> np.ndarray:\n        \"\"\"\n        The TFV system where the tritium flows from the BB and plasma are combined.\n\n        Parameters\n        ----------\n        eta_tfv:\n            Detritiation factor of the system\n        flows:\n            The flows to be added to the TFV block\n\n        Returns\n        -------\n        Flow-rate out of the system [kg/s]\n        \"\"\"\n        # Runs in compressed time\n        tfv = FuelCycleComponent(\n            \"TFV systems\",\n            self.t,\n            eta_tfv,\n            self.params.I_tfv_max,\n            min_inventory=self.params.I_tfv_min,\n            retention_model=\"fountaintub\",\n        )\n        for flow in flows:\n            tfv.add_in_flow(flow)\n        tfv.run()\n        m_tfv_out = FuelCycleFlow(self.t, tfv.m_out, 0)\n        self.I_tfv = tfv.inventory\n        # Exhaust processing\n        m_in_isotope_re, m_in_exhaust_det = m_tfv_out.split(2, [self.params.f_exh_split])\n        # Isotope rebalancing\n        # Storage and Gas Distribution and Control are the same for me\n        # Flie\u00dft direkt zum Injektor\n        # Exhaust detritiation\n        # Combines Water Detritiation and Isotope Separation\n        m_in_exhaust_det = FuelCycleFlow(self.t, m_in_exhaust_det, self.params.t_detrit)\n        m_exh_stor, m_ex_stack = m_in_exhaust_det.split(2, [self.params.f_detrit_split])\n        return m_in_isotope_re + m_exh_stor, m_ex_stack\n\n    def stack(self, flows: List[np.ndarray]):\n        \"\"\"\n        Exhaust to environment\n        \"\"\"\n        stack = FuelCycleComponent(\n            \"Stack\", self.t, 0, float(\"inf\"), retention_model=\"bathtub\", summing=True\n        )\n        for flow in flows:\n            stack.add_in_flow(flow)\n        stack.run()\n        self.I_stack = stack.inventory\n        # Total release to the environment\n        self.M_T_stack = stack.sum_in\n\n    def injector(self, flows: List[np.ndarray]) -> np.ndarray:\n        \"\"\"\n        Pellet injection system assumed\n        \"\"\"\n        injector = FuelCycleComponent(\"Injector\", self.t, 1, 0)\n        for flow in flows:\n            if flow is not None:\n                injector.add_in_flow(flow)\n        injector.run()\n        return injector.m_out\n\n    def recycle(self):\n        \"\"\"\n        The main loop of the fuel cycle, which is called recursively until the\n        convergence criterion is met.\n        \"\"\"\n        # Fuelling (fuel in)\n        # Fuel pump built in (ghosted component)\n        self.m_T_in = self.brate / (self.params.f_b * self.params.eta_f)\n        # m_T_out = (1/self.f_b-1)*self.brate\n        # In-vessel flow lost from fuelling lines as gas (does not enter core)\n        iv_loss_flow = (\n            (1 - self.params.eta_fuel_pump) * (1 - self.params.eta_f) * self.m_T_in\n        )\n        # Gas puff flow\n        gpuff = self.grate\n\n        # Plasma/in-vessel block\n\n        flows = [\n            self.brate / self.params.f_b,\n            iv_loss_flow,\n            gpuff,\n            self.prate,  # D-D T production from plasma\n            -self.brate,\n        ]\n\n        m_T_out = self.plasma(self.params.eta_iv, self.params.I_miv, flows=flows)\n        # Resolution - Not used everywhere for speed\n        n_ts = int(round((YR_TO_S * self.DEMO_t[-1]) / self.timestep))\n        self.t, m_pellet_in = discretise_1d(self.DEMO_t, self.m_T_in, n_ts)\n\n        # Flow out of the vacuum vessel\n        t, m_T_out = discretise_1d(self.DEMO_t, m_T_out, n_ts)\n        # Direct Internal Recycling\n        m_plasma_out = FuelCycleFlow(t, m_T_out, 0)  # Initialise flow 0 t\n\n        m_direct, m_indirect = m_plasma_out.split(2, [self.params.f_dir])\n        # DIR separation\n        # Flow 9\n        direct = FuelCycleFlow(t, m_direct, self.params.t_pump)\n        # Flow 10 with (time delay t_10+t_11/12)\n        indirect = FuelCycleFlow(t, m_indirect, self.params.t_pump + self.params.t_exh)\n        # Blanket\n        m_T_bred = self.blanket(self.params.eta_bb, self.params.I_mbb)\n        t, m_bred = discretise_1d(self.DEMO_t, m_T_bred, n_ts)\n        m_T_bred = FuelCycleFlow(t, m_bred, self.params.t_ters)\n        # Tritium extraction and recovery system + coolant water purification\n        m_T_bred_totfv, m_T_bred_tostack = m_T_bred.split(2, [self.params.f_terscwps])\n        # TFV systems - runs in t\n        m_tfv_out, m_tfv_stack = self.tfv(self.params.eta_tfv, flows=[indirect.out_flow])\n        # Release to environment\n        self.stack([m_T_bred_tostack, m_tfv_stack])\n        m_tfv_out = FuelCycleFlow(t, m_tfv_out, 0)\n        # Store\n        store = FuelCycleComponent(\"Store\", t, 1, np.inf)\n        # Flow 11+13\n        store.add_in_flow(m_tfv_out.out_flow)\n        # Flow 16\n        store.add_in_flow(m_T_bred_totfv)\n        # Pump which compensates fuelling efficiency loss in pellet\n        # injection flight tubes (Flow 3)\n        store.add_in_flow(\n            m_pellet_in * (1 - self.params.eta_f) * self.params.eta_fuel_pump\n        )\n        # Flow 9\n        store.add_in_flow(direct.out_flow)\n        store.run()\n        # This is conservative... need to find a way to make gas available\n        # instantaneously. At present this means gas puffs get \"frozen\" first\n        m_store = FuelCycleFlow(t, store.m_out, self.params.t_freeze).out_flow\n        # Add a correction flow for instantaneous gas puffing\n\n        # m_store += gpuff_corr\n        # Fuelling requirements\n        # Adds gas flow now (not accounted for in ghosted fuel\n        # line pumps)\n        _, m_in = discretise_1d(self.DEMO_t, self.m_T_in + gpuff, n_ts)\n        # Completes the loop in numba\n        m_T = _speed_recycle(self.m_T_start, t, m_in, m_store)\n        self.m_T = m_T + self.params.I_tfv_min  # !!!!\n\n        min_tritium = np.min(m_T)\n        self.m_T_req = self.m_T_start - min_tritium\n\n        while abs(self.m_T_req - self.m_T_start) / self.m_T_req > self.conv_thresh:\n            # Recursively called until start-up inventory is roughly equal to\n            # the initial seeded (and re-calculated) value. This is important\n            # to accurately calculate decay losses (which are a function of\n            # mass)\n\n            self.iterations += 1\n            if self.verbose:\n                old_m_start = self.m_T_start + self.params.I_tfv_min\n                new_m_start = self.m_T_start - min_tritium + self.params.I_tfv_min\n                bluemira_print(\n                    f\"m_T_start old: {old_m_start:.2f} kg \\n\"\n                    f\"m_T_start new: {new_m_start:.2f}\"\n                    f\" kg\\niterations: {self.iterations}\"\n                )\n            self.m_T_start -= min_tritium\n            self.recycle()\n\n    def plot(self):\n        \"\"\"\n        Plot the results of the fuel cycle model.\n        \"\"\"\n        _, ax = plt.subplots(2, 1)\n        self.plot_m_T(ax=ax[0])\n        self.plot_inventory(ax=ax[1])\n\n    def plot_m_T(self, **kwargs):\n        \"\"\"\n        Plot the evolution of the tritium masses over time.\n        \"\"\"\n        ax = kwargs.get(\"ax\", plt.gca())\n        ax.plot(\n            self.DEMO_t,\n            self.tbreed(self.params.TBR, self.m_T_req),\n            label=\"Total T inventory\",\n        )\n\n        (c,) = ax.plot(\n            self.t[self.max_T[0]],\n            self.max_T[1],\n            label=\"Total unsequestered T inventory\",\n        )\n        ax.plot(\n            self.t,\n            self.m_T,\n            color=\"gray\",\n            alpha=0.8,\n            linewidth=0.1,\n            label=\"Unsequestered T inventory in stores\",\n        )\n        ax.plot(self.t[self.max_T[0]], self.max_T[1], color=c.get_color())\n        leg = ax.legend()\n        for line in leg.get_lines():\n            line.set_linewidth(3)\n            line.set_alpha(1)\n        ax.set_ylabel(\"$m_{{T}}$ [kg]\")\n        if \"ax\" not in kwargs:\n            ax.set_xlabel(\"Elapsed plant lifetime [years]\")\n        ax.annotate(\n            \"$m_{T_{start}}$\",\n            xy=[0, self.m_T_req],\n            xytext=[1, self.m_T_req + 4],\n            arrowprops=dict(headwidth=0.5, width=0.5, facecolor=\"k\", shrink=0.1),\n        )\n\n        if np.isfinite(self.t_d):\n            if self.t_d < 0.8 * self.DEMO_t[-1]:\n                s = 1\n            else:\n                s = -1.5\n            ax.annotate(\n                \"$t_{d}$\",\n                xy=[self.t_d, 0],\n                xytext=[self.t_d + s, 4],\n                arrowprops=dict(headwidth=0.5, width=0.5, facecolor=\"k\", shrink=0.1),\n            )\n            if self.arg_t_d is not None:\n                self._plot_t_d(ax=ax)\n        else:\n            ax.annotate(\"$t_{d}=\\\\infty$\", xy=[self.t[-1] - 3, 2])\n\n        if np.isfinite(self.t_infl):\n            if self.t_d < 0.8 * self.DEMO_t[-1]:\n                s = 1\n            else:\n                s = 1.5\n            ax.annotate(\n                \"$t_{infl}$\",\n                xy=[self.t_infl, 0],\n                xytext=[self.t_infl + s, 2],\n                arrowprops=dict(headwidth=0.5, width=0.5, facecolor=\"k\", shrink=0.1),\n            )\n            if self.arg_t_infl is not None:\n                self._plot_t_infl(self.arg_t_infl, ax=ax)\n\n        ax.set_xlim([0, self.t[-1]])\n        ax.set_ylim(bottom=0)\n\n        return ax\n\n    def plot_inventory(self, **kwargs):\n        \"\"\"\n        Plot the evolution of the tritium inventories (including sequestered)\n        over time.\n        \"\"\"\n        ax = kwargs.get(\"ax\", plt.gca())\n        chop = -2\n\n        inventory = self._adjust_inv_plot(self.DEMO_t[:chop], self.I_plasma[:chop])\n        ax.plot(self.DEMO_t[:chop], inventory, label=\"In-vessel\")\n        inventory = self._adjust_inv_plot(self.DEMO_t[:chop], self.I_blanket[:chop])\n\n        ax.plot(self.DEMO_t[:chop], inventory, label=\"Blanket\")\n        ax.plot(self.t[:chop], self.I_tfv[:chop], label=\"TFV systems\")\n        # ax.plot(self.t[:chop], self.I_stack[:chop],\n        #        label='Environment')\n        ax.legend(bbox_to_anchor=[0.99, 0.89])\n        if \"ax\" not in kwargs:\n            ax.set_title(\"Trapped T [kg]\")\n        ax.set_ylabel(\"$m_{{T}}$ [kg]\")\n        ax.set_xlabel(\"Elapsed plant lifetime [years]\")\n        ax.set_xlim(left=0)\n\n    @staticmethod\n    def _adjust_inv_plot(t, inventory, thresh=0.2):\n        \"\"\"\n        Plot correction for compressed time inventories\n        \"\"\"\n        idx = np.where(t - np.roll(t, 1) > thresh)[0] - 2\n        inventory = inventory.copy()\n        for i in idx:\n            inventory[i + 1] = inventory[i]\n        return inventory\n\n    def calc_t_d(self) -> float:\n        \"\"\"\n        Calculate the doubling time of a fuel cycle timeline, assuming that a future\n        tokamak requires the same start-up inventory as the present one.\n\n        Returns\n        -------\n        Doubling time of the tritium fuel cycle [y]\n\n        \\t:math:`t_{d} = t[\\\\text{max}(\\\\text{argmin}\\\\lvert m_{T_{store}}-I_{TFV_{min}}-m_{T_{start}}\\\\rvert))]`\n        \"\"\"  # noqa :W505\n        t_req = self.m_T[0] + self.params.I_tfv_min\n        m_temp = self.m_T[::-1]\n        try:\n            arg_t_d_temp = next(i for i, v in enumerate(m_temp) if v < t_req)\n        except StopIteration:\n            # Technically, an infinte doubling time is correct here, however it\n            # does make the database rather annoying to build reduced laws from\n            # TODO: Consider another way...\n            return None, float(\"Inf\")\n        else:\n            arg_t_d = len(self.t) - arg_t_d_temp\n            # Check a little around\n            # TODO: This single line of code is now the worst offender (0.066s)\n            if True not in [x > t_req for x in self.m_T[arg_t_d - 10 : arg_t_d + 10]]:\n                return None, float(\"Inf\")\n        try:\n            return arg_t_d, self.t[arg_t_d]\n        except IndexError:\n            return arg_t_d - 1, self.t[-1]\n\n    def calc_t_infl(self) -> Tuple[int, float]:\n        \"\"\"\n        Calculate the inflection time of the reactor tritium inventory\n        \"\"\"\n        arg_t_infl = np.argmin(self.m_T)\n        return arg_t_infl, self.t[arg_t_infl]\n\n    def _plot_t_d(self, **kwargs):\n        ax = kwargs.get(\"ax\", plt.gca())\n        next(ax._get_lines.prop_cycler)\n        vlinex = [self.t_d, self.t_d]\n        vliney = [0, self.m_T[0] + self.params.I_tfv_min]\n        (c,) = ax.plot(\n            self.t_d, self.m_T[0] + self.params.I_tfv_min, marker=\"o\", markersize=10\n        )\n        ax.plot(vlinex, vliney, color=c.get_color(), linestyle=\"--\")\n\n    def _plot_t_infl(self, arg, **kwargs):\n        ax = kwargs.get(\"ax\", plt.gca())\n        next(ax._get_lines.prop_cycler)\n        vlinex = [self.t[arg], self.t[arg]]\n        vliney = [0, self.m_T[arg]]\n        (c,) = ax.plot(self.t[arg], self.m_T[arg], marker=\"o\", markersize=10)\n        ax.plot(vlinex, vliney, color=c.get_color(), linestyle=\"--\")\n\n    def calc_m_release(self) -> float:\n        \"\"\"\n        Calculate the tritium release rate from the entire system to the environment.\n\n        Returns\n        -------\n        Tritium release rate [g/yr]\n        \"\"\"\n        max_load_factor = find_max_load_factor(self.DEMO_t, self.DEMO_rt)\n        mb = 1000 * max(self.brate)\n        m_gas = 1000 * max(self.grate)\n        return legal_limit(\n            max_load_factor,\n            self.params.f_b,\n            m_gas,\n            self.params.eta_f,\n            self.params.eta_fuel_pump,\n            self.params.f_dir,\n            self.params.f_exh_split,\n            self.params.f_detrit_split,\n            self.params.f_terscwps,\n            self.params.TBR,\n            mb=mb,\n        )\n\n    def sanity(self):\n        \"\"\"\n        Check that no tritium is lost (graphically).\n        \"\"\"\n        f, ax = plt.subplots()\n        m_ideal = self.tbreed(self.params.TBR, self.m_T_req)\n        inter = interp1d(self.DEMO_t, self.I_blanket)\n        bb_inventory = inter(self.t)\n        inter = interp1d(self.DEMO_t, self.I_plasma)\n        pl_inventory = inter(self.t)\n        m_tritium = (\n            self.m_T\n            + bb_inventory\n            + pl_inventory\n            + self.I_tfv\n            - self.params.I_tfv_min\n            + self.I_stack\n        )\n        ax.plot(self.t, m_tritium, label=\"max with sequestered\")\n        ax.plot(self.DEMO_t, m_ideal, label=\"ideal\")\n        ax.plot(self.t[self.max_T[0]], self.max_T[1], label=\"max yellow\")\n        ax.legend()",
  "class EDFCMParams:\n    \"\"\"\n    Parameters required to run :class:`bluemira.fuel_cycle.cycle.EUDEMOFuelCycleModel`.\n    \"\"\"\n\n    TBR: float = 1.05\n    \"\"\"Tritium breeding ratio [dimensionless].\"\"\"\n    f_b: float = 0.015\n    \"\"\"Burn-up fraction [dimensionless].\"\"\"\n    m_gas: float = 50\n    \"\"\"\n    Gas puff flow rate [Pa m^3/s]. To maintain detachment - no chance of\n    fusion from gas injection.\n    \"\"\"\n    A_global: float = 0.3\n    \"\"\"Load factor [dimensionless].\"\"\"\n    r_learn: float = 1\n    \"\"\"Learning rate [dimensionless].\"\"\"\n    t_pump: float = 100\n    \"\"\"\n    Time in DIR loop [s]. Time between exit from plasma and entry into\n    plasma through DIR loop.\n    \"\"\"\n    t_exh: float = 3600\n    \"\"\"\n    Time in INDIR loop [s]. Time between exit from plasma and entry into\n    TFV systems INDIR.\n    \"\"\"\n    t_ters: float = 18000\n    \"\"\"Time from BB exit to TFV system [s].\"\"\"\n    t_freeze: float = 1800\n    \"\"\"Time taken to freeze pellets [s].\"\"\"\n    f_dir: float = 0.9\n    \"\"\"Fraction of flow through DIR loop [dimensionless].\"\"\"\n    t_detrit: float = 36000\n    \"\"\"Time in detritiation system [s].\"\"\"\n    f_detrit_split: float = 0.9999\n    \"\"\"Fraction of detritiation line tritium extracted [dimensionless].\"\"\"\n    f_exh_split: float = 0.99\n    \"\"\"Fraction of exhaust tritium extracted [dimensionless].\"\"\"\n    eta_fuel_pump: float = 0.9\n    \"\"\"\n    Efficiency of fuel line pump [dimensionless]. Pump which pumps down\n    the fuelling lines.\n    \"\"\"\n    eta_f: float = 0.5\n    \"\"\"\n    Fuelling efficiency [dimensionless]. Efficiency of the fuelling\n    lines prior to entry into the VV chamber.\n    \"\"\"\n    I_miv: float = 0.3\n    \"\"\"Maximum in-vessel T inventory [kg].\"\"\"\n    I_tfv_min: float = 2\n    \"\"\"\n    Minimum TFV inventory [kg]. Without which e.g. cryodistillation\n    columns are not effective.\n    \"\"\"\n    I_tfv_max: float = 2.2\n    \"\"\"\n    Maximum TFV inventory [kg]. Account for T sequestration inside the T\n    plant.\n    \"\"\"\n    I_mbb: float = 0.055\n    \"\"\"Maximum BB T inventory [kg].\"\"\"\n    eta_iv: float = 0.9995\n    \"\"\"In-vessel bathtub parameter [dimensionless].\"\"\"\n    eta_bb: float = 0.995\n    \"\"\"BB bathtub parameter [dimensionless].\"\"\"\n    eta_tfv: float = 0.998\n    \"\"\"TFV bathtub parameter [dimensionless].\"\"\"\n    f_terscwps: float = 0.9999\n    \"\"\"TERS and CWPS cumulated factor [dimensionless].\"\"\"",
  "def __init__(\n        self,\n        params: Optional[Union[EDFCMParams, Dict[str, float]]] = None,\n        build_config: Optional[Dict[str, Any]] = None,\n    ):\n        # Handle parameters\n        if isinstance(params, EDFCMParams):\n            self.params = params\n        elif isinstance(params, dict):\n            self.params = EDFCMParams(**params)\n        elif params is None:\n            self.params = EDFCMParams()\n        else:\n            raise TypeError(\n                \"Invalid type for 'params'. Must be one of 'dict', \"\n                f\"'EDFCMParams', or 'None'; found '{type(params).__name__}'.\"\n            )\n\n        # Handle calculation information\n        build_config = {} if build_config is None else build_config\n        self.verbose = build_config.get(\"verbose\", False)\n        self.timestep = build_config.get(\"timestep\", 1200)\n        self.conv_thresh = build_config.get(\"conv_thresh\", 2e-4)\n        self.n = build_config.get(\"n\", None)",
  "def _constructors(self):\n        # Constructors (untangling the spaghetti)\n        self.max_T = None\n        self.min_T = None\n        self.m_T = None\n        self.m_dot_release = None\n        self.m_T_in = None\n        self.m_T_req = None\n        self.m_T_start = None\n        self.M_T_bred = None\n        self.M_T_stack = None\n        self.M_T_burnt = None\n        self.I_blanket = None\n        self.I_plasma = None\n        self.I_stack = None\n        self.I_tfv = None\n\n        self.grate = None\n        self.brate = None\n        self.prate = None\n        self.DEMO_rt = None\n        self.DEMO_t = None\n        self.DD_rate = None\n        self.DT_rate = None\n        self.bci = None\n        self.arg_t_d = None\n        self.arg_t_infl = None\n        self.t = None\n        self.t_d = None\n        self.t_infl = None",
  "def run(self, timeline: Timeline):\n        \"\"\"\n        Run the fuel cycle model.\n\n        Parameters\n        ----------\n        timeline:\n            Timeline with which to run the model\n        \"\"\"\n        if self.n is None:\n            self.n = len(timeline[\"time\"])\n\n        self.A_global = timeline[\"A_global\"]\n\n        self._constructors()\n        self.initialise_arrays(timeline, self.n)\n        # Initialise model with a reasonable number for decay\n        self.seed_t()\n        self.iterations = 0\n        self.recycle()\n        self.finalise()\n        self.m_T_req += self.I_tfv[0]  # Add TFV fountain inventory\n        self.m_dot_release = self.calc_m_release()",
  "def finalise(self):\n        \"\"\"\n        Perform clean-up fudge to ensure all tritium returns to stores after\n        the end of the reactor life.\n        \"\"\"\n        n_bins = max(int(len(self.m_T) / 4500), 400)\n        # Hand tweak to get findnoisylocals looking good\n        self.max_T = find_noisy_locals(self.m_T, x_bins=n_bins, mode=\"max\")\n        self.min_T = find_noisy_locals(self.m_T, x_bins=n_bins)\n        # self.max_T[1][-1] = self.max_T[1][-2]   #plothack\n        self.m_T[-1] = self.max_T[1][-1]\n        self.arg_t_d, self.t_d = self.calc_t_d()\n        self.arg_t_infl, self.t_infl = self.calc_t_infl()",
  "def initialise_arrays(self, timeline: Timeline, n: int):\n        \"\"\"\n        Initialise timeline arrays for TFV model.\n\n        Notes\n        -----\n        Gas puff timeline mapped to burn signal.\n        \"\"\"\n        self.DEMO_t = timeline[\"time\"][:n]\n        self.DEMO_rt = np.array(timeline[\"fusion_time\"][:n])\n        self.DT_rate = timeline[\"DT_rate\"][:n]\n        self.DD_rate = timeline[\"DD_rate\"][:n]\n        m_gas = T_MOLAR_MASS * raw_uc(self.params.m_gas, \"Pa.m^3/s\", \"mol/s\") / 1000\n        self.grate = m_gas * self.DT_rate / max(self.DT_rate)\n        self.bci = timeline[\"blanket_change_index\"]\n        # Burn rate of T [kgs of T per second]\n        self.brate = (T_MOLAR_MASS / N_AVOGADRO / 1000) * self.DT_rate\n        # T production rate from D-D reaction channel [kgs of T per second]\n        self.prate = (T_MOLAR_MASS / N_AVOGADRO / 1000) * self.DD_rate / 2",
  "def seed_t(self):\n        \"\"\"\n        Seed an initial value to the model.\n        \"\"\"\n        self.m_T_start = 5.0\n        self.m_T = [self.m_T_start]",
  "def tbreed(self, TBR: float, m_T_0: float):\n        \"\"\"\n        Ideal system without T sequestration. Used for plotting and sanity.\n        \"\"\"\n        m_T = m_T_0 * np.ones(len(self.DEMO_t))\n        for i in range(1, len(self.DEMO_t)):\n            dt = self.DEMO_t[i] - self.DEMO_t[i - 1]\n            t_bred = TBR * self.brate[i] * (YR_TO_S * dt)\n            t_bred += self.prate[i] * (YR_TO_S * dt)\n            t_burnt = self.brate[i] * (YR_TO_S * dt)\n            t_DD = self.prate[i] * (YR_TO_S * dt)\n            m_T[i] = (m_T[i - 1]) * np.exp(-T_LAMBDA * dt) - t_burnt + t_bred + t_DD\n        return m_T",
  "def plasma(\n        self,\n        eta_iv: float,\n        max_inventory: float,\n        flows: Optional[List[np.ndarray]] = None,\n    ) -> np.ndarray:\n        \"\"\"\n        In-vessel environment\n\n        Parameters\n        ----------\n        eta_iv:\n            In-vessel accumulation efficiency 0 <= float <= 1\n\n        max_inventory:\n            T inventory limit of in-vessel environment [kg]\n            (e.g. 0.7 kg in ITER in-vessel)\n        flows:\n            Additional flows to add into plasma\n\n        Returns\n        -------\n        Flow-rate out of the system [kg/s]\n        \"\"\"\n        plasma = FuelCycleComponent(\n            \"Plasma\",\n            self.DEMO_t,\n            eta_iv,\n            max_inventory,\n            bci=self.bci,\n            retention_model=\"sqrt_bathtub\",\n            summing=False,\n        )\n        for flow in flows:\n            plasma.add_in_flow(flow)\n        plasma.run()\n        self.I_plasma = plasma.inventory\n        return plasma.m_out",
  "def blanket(self, eta_b: float, max_inventory: float) -> np.ndarray:\n        \"\"\"\n        The tritium breeding system. Dumps stored inventory at blanket change.\n\n        Parameters\n        ----------\n        eta_b:\n            The retention efficiency parameter for the blanket\n        max_inventory:\n            The maximum inventory in the blanket\n\n        Returns\n        -------\n        Flow-rate out of the system [kg/s]\n        \"\"\"\n        m_T_bred = self.params.TBR * self.brate\n        blanket = FuelCycleComponent(\n            \"Blanket\", self.DEMO_t, eta_b, max_inventory, bci=self.bci, summing=True\n        )\n        blanket.add_in_flow(m_T_bred)\n        blanket.run()\n        self.M_T_bred = blanket.sum_in\n        self.I_blanket = blanket.inventory\n        return blanket.m_out",
  "def tfv(self, eta_tfv: float, flows: List[np.ndarray]) -> np.ndarray:\n        \"\"\"\n        The TFV system where the tritium flows from the BB and plasma are combined.\n\n        Parameters\n        ----------\n        eta_tfv:\n            Detritiation factor of the system\n        flows:\n            The flows to be added to the TFV block\n\n        Returns\n        -------\n        Flow-rate out of the system [kg/s]\n        \"\"\"\n        # Runs in compressed time\n        tfv = FuelCycleComponent(\n            \"TFV systems\",\n            self.t,\n            eta_tfv,\n            self.params.I_tfv_max,\n            min_inventory=self.params.I_tfv_min,\n            retention_model=\"fountaintub\",\n        )\n        for flow in flows:\n            tfv.add_in_flow(flow)\n        tfv.run()\n        m_tfv_out = FuelCycleFlow(self.t, tfv.m_out, 0)\n        self.I_tfv = tfv.inventory\n        # Exhaust processing\n        m_in_isotope_re, m_in_exhaust_det = m_tfv_out.split(2, [self.params.f_exh_split])\n        # Isotope rebalancing\n        # Storage and Gas Distribution and Control are the same for me\n        # Flie\u00dft direkt zum Injektor\n        # Exhaust detritiation\n        # Combines Water Detritiation and Isotope Separation\n        m_in_exhaust_det = FuelCycleFlow(self.t, m_in_exhaust_det, self.params.t_detrit)\n        m_exh_stor, m_ex_stack = m_in_exhaust_det.split(2, [self.params.f_detrit_split])\n        return m_in_isotope_re + m_exh_stor, m_ex_stack",
  "def stack(self, flows: List[np.ndarray]):\n        \"\"\"\n        Exhaust to environment\n        \"\"\"\n        stack = FuelCycleComponent(\n            \"Stack\", self.t, 0, float(\"inf\"), retention_model=\"bathtub\", summing=True\n        )\n        for flow in flows:\n            stack.add_in_flow(flow)\n        stack.run()\n        self.I_stack = stack.inventory\n        # Total release to the environment\n        self.M_T_stack = stack.sum_in",
  "def injector(self, flows: List[np.ndarray]) -> np.ndarray:\n        \"\"\"\n        Pellet injection system assumed\n        \"\"\"\n        injector = FuelCycleComponent(\"Injector\", self.t, 1, 0)\n        for flow in flows:\n            if flow is not None:\n                injector.add_in_flow(flow)\n        injector.run()\n        return injector.m_out",
  "def recycle(self):\n        \"\"\"\n        The main loop of the fuel cycle, which is called recursively until the\n        convergence criterion is met.\n        \"\"\"\n        # Fuelling (fuel in)\n        # Fuel pump built in (ghosted component)\n        self.m_T_in = self.brate / (self.params.f_b * self.params.eta_f)\n        # m_T_out = (1/self.f_b-1)*self.brate\n        # In-vessel flow lost from fuelling lines as gas (does not enter core)\n        iv_loss_flow = (\n            (1 - self.params.eta_fuel_pump) * (1 - self.params.eta_f) * self.m_T_in\n        )\n        # Gas puff flow\n        gpuff = self.grate\n\n        # Plasma/in-vessel block\n\n        flows = [\n            self.brate / self.params.f_b,\n            iv_loss_flow,\n            gpuff,\n            self.prate,  # D-D T production from plasma\n            -self.brate,\n        ]\n\n        m_T_out = self.plasma(self.params.eta_iv, self.params.I_miv, flows=flows)\n        # Resolution - Not used everywhere for speed\n        n_ts = int(round((YR_TO_S * self.DEMO_t[-1]) / self.timestep))\n        self.t, m_pellet_in = discretise_1d(self.DEMO_t, self.m_T_in, n_ts)\n\n        # Flow out of the vacuum vessel\n        t, m_T_out = discretise_1d(self.DEMO_t, m_T_out, n_ts)\n        # Direct Internal Recycling\n        m_plasma_out = FuelCycleFlow(t, m_T_out, 0)  # Initialise flow 0 t\n\n        m_direct, m_indirect = m_plasma_out.split(2, [self.params.f_dir])\n        # DIR separation\n        # Flow 9\n        direct = FuelCycleFlow(t, m_direct, self.params.t_pump)\n        # Flow 10 with (time delay t_10+t_11/12)\n        indirect = FuelCycleFlow(t, m_indirect, self.params.t_pump + self.params.t_exh)\n        # Blanket\n        m_T_bred = self.blanket(self.params.eta_bb, self.params.I_mbb)\n        t, m_bred = discretise_1d(self.DEMO_t, m_T_bred, n_ts)\n        m_T_bred = FuelCycleFlow(t, m_bred, self.params.t_ters)\n        # Tritium extraction and recovery system + coolant water purification\n        m_T_bred_totfv, m_T_bred_tostack = m_T_bred.split(2, [self.params.f_terscwps])\n        # TFV systems - runs in t\n        m_tfv_out, m_tfv_stack = self.tfv(self.params.eta_tfv, flows=[indirect.out_flow])\n        # Release to environment\n        self.stack([m_T_bred_tostack, m_tfv_stack])\n        m_tfv_out = FuelCycleFlow(t, m_tfv_out, 0)\n        # Store\n        store = FuelCycleComponent(\"Store\", t, 1, np.inf)\n        # Flow 11+13\n        store.add_in_flow(m_tfv_out.out_flow)\n        # Flow 16\n        store.add_in_flow(m_T_bred_totfv)\n        # Pump which compensates fuelling efficiency loss in pellet\n        # injection flight tubes (Flow 3)\n        store.add_in_flow(\n            m_pellet_in * (1 - self.params.eta_f) * self.params.eta_fuel_pump\n        )\n        # Flow 9\n        store.add_in_flow(direct.out_flow)\n        store.run()\n        # This is conservative... need to find a way to make gas available\n        # instantaneously. At present this means gas puffs get \"frozen\" first\n        m_store = FuelCycleFlow(t, store.m_out, self.params.t_freeze).out_flow\n        # Add a correction flow for instantaneous gas puffing\n\n        # m_store += gpuff_corr\n        # Fuelling requirements\n        # Adds gas flow now (not accounted for in ghosted fuel\n        # line pumps)\n        _, m_in = discretise_1d(self.DEMO_t, self.m_T_in + gpuff, n_ts)\n        # Completes the loop in numba\n        m_T = _speed_recycle(self.m_T_start, t, m_in, m_store)\n        self.m_T = m_T + self.params.I_tfv_min  # !!!!\n\n        min_tritium = np.min(m_T)\n        self.m_T_req = self.m_T_start - min_tritium\n\n        while abs(self.m_T_req - self.m_T_start) / self.m_T_req > self.conv_thresh:\n            # Recursively called until start-up inventory is roughly equal to\n            # the initial seeded (and re-calculated) value. This is important\n            # to accurately calculate decay losses (which are a function of\n            # mass)\n\n            self.iterations += 1\n            if self.verbose:\n                old_m_start = self.m_T_start + self.params.I_tfv_min\n                new_m_start = self.m_T_start - min_tritium + self.params.I_tfv_min\n                bluemira_print(\n                    f\"m_T_start old: {old_m_start:.2f} kg \\n\"\n                    f\"m_T_start new: {new_m_start:.2f}\"\n                    f\" kg\\niterations: {self.iterations}\"\n                )\n            self.m_T_start -= min_tritium\n            self.recycle()",
  "def plot(self):\n        \"\"\"\n        Plot the results of the fuel cycle model.\n        \"\"\"\n        _, ax = plt.subplots(2, 1)\n        self.plot_m_T(ax=ax[0])\n        self.plot_inventory(ax=ax[1])",
  "def plot_m_T(self, **kwargs):\n        \"\"\"\n        Plot the evolution of the tritium masses over time.\n        \"\"\"\n        ax = kwargs.get(\"ax\", plt.gca())\n        ax.plot(\n            self.DEMO_t,\n            self.tbreed(self.params.TBR, self.m_T_req),\n            label=\"Total T inventory\",\n        )\n\n        (c,) = ax.plot(\n            self.t[self.max_T[0]],\n            self.max_T[1],\n            label=\"Total unsequestered T inventory\",\n        )\n        ax.plot(\n            self.t,\n            self.m_T,\n            color=\"gray\",\n            alpha=0.8,\n            linewidth=0.1,\n            label=\"Unsequestered T inventory in stores\",\n        )\n        ax.plot(self.t[self.max_T[0]], self.max_T[1], color=c.get_color())\n        leg = ax.legend()\n        for line in leg.get_lines():\n            line.set_linewidth(3)\n            line.set_alpha(1)\n        ax.set_ylabel(\"$m_{{T}}$ [kg]\")\n        if \"ax\" not in kwargs:\n            ax.set_xlabel(\"Elapsed plant lifetime [years]\")\n        ax.annotate(\n            \"$m_{T_{start}}$\",\n            xy=[0, self.m_T_req],\n            xytext=[1, self.m_T_req + 4],\n            arrowprops=dict(headwidth=0.5, width=0.5, facecolor=\"k\", shrink=0.1),\n        )\n\n        if np.isfinite(self.t_d):\n            if self.t_d < 0.8 * self.DEMO_t[-1]:\n                s = 1\n            else:\n                s = -1.5\n            ax.annotate(\n                \"$t_{d}$\",\n                xy=[self.t_d, 0],\n                xytext=[self.t_d + s, 4],\n                arrowprops=dict(headwidth=0.5, width=0.5, facecolor=\"k\", shrink=0.1),\n            )\n            if self.arg_t_d is not None:\n                self._plot_t_d(ax=ax)\n        else:\n            ax.annotate(\"$t_{d}=\\\\infty$\", xy=[self.t[-1] - 3, 2])\n\n        if np.isfinite(self.t_infl):\n            if self.t_d < 0.8 * self.DEMO_t[-1]:\n                s = 1\n            else:\n                s = 1.5\n            ax.annotate(\n                \"$t_{infl}$\",\n                xy=[self.t_infl, 0],\n                xytext=[self.t_infl + s, 2],\n                arrowprops=dict(headwidth=0.5, width=0.5, facecolor=\"k\", shrink=0.1),\n            )\n            if self.arg_t_infl is not None:\n                self._plot_t_infl(self.arg_t_infl, ax=ax)\n\n        ax.set_xlim([0, self.t[-1]])\n        ax.set_ylim(bottom=0)\n\n        return ax",
  "def plot_inventory(self, **kwargs):\n        \"\"\"\n        Plot the evolution of the tritium inventories (including sequestered)\n        over time.\n        \"\"\"\n        ax = kwargs.get(\"ax\", plt.gca())\n        chop = -2\n\n        inventory = self._adjust_inv_plot(self.DEMO_t[:chop], self.I_plasma[:chop])\n        ax.plot(self.DEMO_t[:chop], inventory, label=\"In-vessel\")\n        inventory = self._adjust_inv_plot(self.DEMO_t[:chop], self.I_blanket[:chop])\n\n        ax.plot(self.DEMO_t[:chop], inventory, label=\"Blanket\")\n        ax.plot(self.t[:chop], self.I_tfv[:chop], label=\"TFV systems\")\n        # ax.plot(self.t[:chop], self.I_stack[:chop],\n        #        label='Environment')\n        ax.legend(bbox_to_anchor=[0.99, 0.89])\n        if \"ax\" not in kwargs:\n            ax.set_title(\"Trapped T [kg]\")\n        ax.set_ylabel(\"$m_{{T}}$ [kg]\")\n        ax.set_xlabel(\"Elapsed plant lifetime [years]\")\n        ax.set_xlim(left=0)",
  "def _adjust_inv_plot(t, inventory, thresh=0.2):\n        \"\"\"\n        Plot correction for compressed time inventories\n        \"\"\"\n        idx = np.where(t - np.roll(t, 1) > thresh)[0] - 2\n        inventory = inventory.copy()\n        for i in idx:\n            inventory[i + 1] = inventory[i]\n        return inventory",
  "def calc_t_d(self) -> float:\n        \"\"\"\n        Calculate the doubling time of a fuel cycle timeline, assuming that a future\n        tokamak requires the same start-up inventory as the present one.\n\n        Returns\n        -------\n        Doubling time of the tritium fuel cycle [y]\n\n        \\t:math:`t_{d} = t[\\\\text{max}(\\\\text{argmin}\\\\lvert m_{T_{store}}-I_{TFV_{min}}-m_{T_{start}}\\\\rvert))]`\n        \"\"\"  # noqa :W505\n        t_req = self.m_T[0] + self.params.I_tfv_min\n        m_temp = self.m_T[::-1]\n        try:\n            arg_t_d_temp = next(i for i, v in enumerate(m_temp) if v < t_req)\n        except StopIteration:\n            # Technically, an infinte doubling time is correct here, however it\n            # does make the database rather annoying to build reduced laws from\n            # TODO: Consider another way...\n            return None, float(\"Inf\")\n        else:\n            arg_t_d = len(self.t) - arg_t_d_temp\n            # Check a little around\n            # TODO: This single line of code is now the worst offender (0.066s)\n            if True not in [x > t_req for x in self.m_T[arg_t_d - 10 : arg_t_d + 10]]:\n                return None, float(\"Inf\")\n        try:\n            return arg_t_d, self.t[arg_t_d]\n        except IndexError:\n            return arg_t_d - 1, self.t[-1]",
  "def calc_t_infl(self) -> Tuple[int, float]:\n        \"\"\"\n        Calculate the inflection time of the reactor tritium inventory\n        \"\"\"\n        arg_t_infl = np.argmin(self.m_T)\n        return arg_t_infl, self.t[arg_t_infl]",
  "def _plot_t_d(self, **kwargs):\n        ax = kwargs.get(\"ax\", plt.gca())\n        next(ax._get_lines.prop_cycler)\n        vlinex = [self.t_d, self.t_d]\n        vliney = [0, self.m_T[0] + self.params.I_tfv_min]\n        (c,) = ax.plot(\n            self.t_d, self.m_T[0] + self.params.I_tfv_min, marker=\"o\", markersize=10\n        )\n        ax.plot(vlinex, vliney, color=c.get_color(), linestyle=\"--\")",
  "def _plot_t_infl(self, arg, **kwargs):\n        ax = kwargs.get(\"ax\", plt.gca())\n        next(ax._get_lines.prop_cycler)\n        vlinex = [self.t[arg], self.t[arg]]\n        vliney = [0, self.m_T[arg]]\n        (c,) = ax.plot(self.t[arg], self.m_T[arg], marker=\"o\", markersize=10)\n        ax.plot(vlinex, vliney, color=c.get_color(), linestyle=\"--\")",
  "def calc_m_release(self) -> float:\n        \"\"\"\n        Calculate the tritium release rate from the entire system to the environment.\n\n        Returns\n        -------\n        Tritium release rate [g/yr]\n        \"\"\"\n        max_load_factor = find_max_load_factor(self.DEMO_t, self.DEMO_rt)\n        mb = 1000 * max(self.brate)\n        m_gas = 1000 * max(self.grate)\n        return legal_limit(\n            max_load_factor,\n            self.params.f_b,\n            m_gas,\n            self.params.eta_f,\n            self.params.eta_fuel_pump,\n            self.params.f_dir,\n            self.params.f_exh_split,\n            self.params.f_detrit_split,\n            self.params.f_terscwps,\n            self.params.TBR,\n            mb=mb,\n        )",
  "def sanity(self):\n        \"\"\"\n        Check that no tritium is lost (graphically).\n        \"\"\"\n        f, ax = plt.subplots()\n        m_ideal = self.tbreed(self.params.TBR, self.m_T_req)\n        inter = interp1d(self.DEMO_t, self.I_blanket)\n        bb_inventory = inter(self.t)\n        inter = interp1d(self.DEMO_t, self.I_plasma)\n        pl_inventory = inter(self.t)\n        m_tritium = (\n            self.m_T\n            + bb_inventory\n            + pl_inventory\n            + self.I_tfv\n            - self.params.I_tfv_min\n            + self.I_stack\n        )\n        ax.plot(self.t, m_tritium, label=\"max with sequestered\")\n        ax.plot(self.DEMO_t, m_ideal, label=\"ideal\")\n        ax.plot(self.t[self.max_T[0]], self.max_T[1], label=\"max yellow\")\n        ax.legend()",
  "def f_gompertz(t: float, a: float, b: float, c: float) -> float:\n    \"\"\"\n    Gompertz sigmoid function parameterisation.\n\n    \\t:math:`a\\\\text{exp}(-b\\\\text{exp}(-ct))`\n    \"\"\"\n    return a * np.exp(-b * np.exp(-c * t))",
  "def f_logistic(t: float, value: float, k: float, x_0: float) -> float:\n    \"\"\"\n    Logistic function parameterisation.\n    \"\"\"\n    return value / (1 + np.exp(-k * (t - x_0)))",
  "def histify(x: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Transform values into arrays usable to make histograms.\n    \"\"\"\n    x, y = np.array(x), np.array(y)\n    return x.repeat(2)[1:-1], y.repeat(2)",
  "def generate_lognorm_distribution(n: int, integral: float, sigma: float) -> np.ndarray:\n    \"\"\"\n    Generate a log-norm distribution for a given standard deviation of the\n    underlying normal distribution. The mean value of the normal distribution\n    is optimised approximately.\n\n    Parameters\n    ----------\n    n:\n        The size of the distribution\n    integral:\n        The integral value of the distribution\n    sigma:\n        The standard deviation of the underlying normal distribution\n\n    Returns\n    -------\n    The distribution of size n and of the correct integral value\n    \"\"\"\n\n    def f_integral(x):\n        return np.sum(np.random.lognormal(x, sigma, n)) - integral\n\n    mu = brentq(f_integral, -1e3, 1e3, maxiter=200)\n    distribution = np.random.lognormal(mu, sigma, n)\n    # Correct distribution integral\n    error = np.sum(distribution) - integral\n    distribution -= error / n\n    return distribution",
  "def generate_truncnorm_distribution(n: int, integral: float, sigma: float) -> np.ndarray:\n    \"\"\"\n    Generate a truncated normal distribution for a given standard deviation.\n\n    Parameters\n    ----------\n    n:\n        The size of the distribution\n    integral:\n        The integral value of the distribution\n    sigma:\n        The standard deviation of the underlying normal distribution\n\n    Returns\n    -------\n    The distribution of size n and of the correct integral value\n    \"\"\"\n    distribution = np.random.normal(0, sigma, n)\n    # Truncate distribution by 0-folding\n    distribution = np.abs(distribution)\n    # Correct distribution integral\n    distribution /= np.sum(distribution)\n    distribution *= integral\n    return distribution",
  "def generate_exponential_distribution(\n    n: int, integral: float, lambdda: float\n) -> np.ndarray:\n    \"\"\"\n    Generate an exponential distribution for a given rate parameter.\n\n    Parameters\n    ----------\n    n:\n        The size of the distribution\n    integral:\n        The integral value of the distribution\n    lambdda:\n        The rate parameter of the distribution\n\n    Returns\n    -------\n    The distribution of size n and of the correct integral value\n    \"\"\"\n    distribution = np.random.exponential(lambdda, n)\n    # Correct distribution integral\n    distribution /= np.sum(distribution)\n    distribution *= integral\n    return distribution",
  "class LearningStrategy(abc.ABC):\n    \"\"\"\n    Abstract base class for learning strategies distributing the total operational\n    availability over different operational phases.\n    \"\"\"\n\n    @abc.abstractmethod\n    def generate_phase_availabilities(\n        self, lifetime_op_availability: float, op_durations: Iterable[float]\n    ) -> Iterable[float]:\n        \"\"\"\n        Generate operational availabilities for the specified phase durations.\n\n        Parameters\n        ----------\n        lifetime_op_availability:\n            Operational availability averaged over the lifetime\n        op_durations:\n            Durations of the operational phases [fpy]\n\n        Returns\n        -------\n        Operational availabilities at each operational phase\n        \"\"\"\n        pass",
  "class UniformLearningStrategy(LearningStrategy):\n    \"\"\"\n    Uniform learning strategy\n    \"\"\"\n\n    def generate_phase_availabilities(\n        self, lifetime_op_availability: float, op_durations: Iterable[float]\n    ) -> Iterable[float]:\n        \"\"\"\n        Generate operational availabilities for the specified phase durations.\n\n        Parameters\n        ----------\n        lifetime_op_availability:\n            Operational availability averaged over the lifetime\n        op_durations:\n            Durations of the operational phases [fpy]\n\n        Returns\n        -------\n        Operational availabilities at each operational phase\n        \"\"\"\n        return lifetime_op_availability * np.ones(len(op_durations))",
  "class UserSpecifiedLearningStrategy(LearningStrategy):\n    \"\"\"\n    User-specified learning strategy to hard-code the operational availabilities at\n    each operational phase.\n    \"\"\"\n\n    def __init__(self, operational_availabilities: Iterable[float]):\n        \"\"\"\n        Parameters\n        ----------\n        operational_availabilities:\n            Operational availabilities to prescribe\n        \"\"\"\n        self.operational_availabilities = operational_availabilities\n\n    def generate_phase_availabilities(\n        self, lifetime_op_availability: float, op_durations: Iterable[float]\n    ) -> Iterable[float]:\n        \"\"\"\n        Generate operational availabilities for the specified phase durations.\n\n        Parameters\n        ----------\n        lifetime_op_availability:\n            Lifetime operational availability\n        op_durations:\n            Durations of the operational phases [fpy]\n\n        Returns\n        -------\n        Operational availabilities at each operational phase\n        \"\"\"\n        if len(op_durations) != len(self.operational_availabilities):\n            raise FuelCycleError(\n                \"The number of phases is not equal to the number of user-specified operational availabilities.\"\n            )\n\n        total_fpy = np.sum(op_durations)\n        fraction = (total_fpy / lifetime_op_availability) / (\n            op_durations / self.operational_availabilities\n        )\n        if fraction != 1.0:\n            bluemira_warn(\n                f\"User-specified operational availabilities do not match the specified lifetime operational : {fraction:.2f} != 1.0. Normalising to adjust to meet the specified lifetime operational availability.\"\n            )\n\n        return fraction * self.operational_availabilities",
  "class GompertzLearningStrategy(LearningStrategy):\n    \"\"\"\n    Gompertz learning strategy.\n    \"\"\"\n\n    def __init__(\n        self, learn_rate: float, min_op_availability: float, max_op_availability: float\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        learn_rate:\n            Gompertz distribution learning rate\n        min_op_availability:\n            Minimum operational availability within any given operational phase\n        max_op_availability:\n            Maximum operational availability within any given operational phase\n        \"\"\"\n        self.learn_rate = learn_rate\n        self.min_op_a = min_op_availability\n        self.max_op_a = max_op_availability\n        super().__init__()\n\n    def _f_op_availabilities(self, t, x, arg_dates):\n        a_ops = self.min_op_a + f_gompertz(\n            t, self.max_op_a - self.min_op_a, x, self.learn_rate\n        )\n\n        return np.array(\n            [np.mean(a_ops[arg_dates[i] : d]) for i, d in enumerate(arg_dates[1:])]\n        )\n\n    def generate_phase_availabilities(\n        self, lifetime_op_availability: float, op_durations: Iterable[float]\n    ) -> Iterable[float]:\n        \"\"\"\n        Generate operational availabilities for the specified phase durations.\n\n        Parameters\n        ----------\n        lifetime_op_availability:\n            Operational availability averaged over the lifetime\n        op_durations:\n            Durations of the operational phases [fpy]\n\n        Returns\n        -------\n        Operational availabilities at each operational phase\n        \"\"\"\n        if not self.min_op_a < lifetime_op_availability < self.max_op_a:\n            raise FuelCycleError(\n                \"Input lifetime operational availability must be within the specified bounds on the phase operational availability.\"\n            )\n\n        op_durations = np.append(0, op_durations)\n        total_fpy = np.sum(op_durations)\n        cum_fpy = np.cumsum(op_durations)\n\n        t = np.linspace(0, total_fpy, 100)\n        arg_dates = np.array([np.argmin(abs(t - i)) for i in cum_fpy])\n\n        def f_opt(x):\n            \"\"\"\n            Optimisation objective for chunky fit to Gompertz\n\n            \\t:math:`a_{min}+(a_{max}-a_{min})e^{\\\\dfrac{-\\\\text{ln}(2)}{e^{-ct_{infl}}}}`\n            \"\"\"\n            a_ops_i = self._f_op_availabilities(t, x, arg_dates)\n            # NOTE: Fancy analytical integral objective of Gompertz function\n            # was a resounding failure. Do not touch this again.\n            # The brute force is strong in this one.\n            return total_fpy / lifetime_op_availability - sum(op_durations[1:] / a_ops_i)\n\n        x_opt = brentq(f_opt, 0, 10e10)\n        return self._f_op_availabilities(t, x_opt, arg_dates)",
  "class OperationalAvailabilityStrategy(abc.ABC):\n    \"\"\"\n    Abstract base class for operational availability strategies to generate\n    distributions of unplanned outages.\n    \"\"\"\n\n    @abc.abstractmethod\n    def generate_distribution(self, n: int, integral: float) -> np.ndarray:\n        \"\"\"\n        Generate a distribution with a specified number of entries and integral.\n\n        Parameters\n        ----------\n        n:\n            Number of entries in the distribution\n        integral:\n            Integral of the distribution\n\n        Returns\n        -------\n        The distribution of size n and of the correct integral value\n        \"\"\"\n        pass",
  "class LogNormalAvailabilityStrategy(OperationalAvailabilityStrategy):\n    \"\"\"\n    Log-normal distribution strategy\n    \"\"\"\n\n    def __init__(self, sigma: float):\n        \"\"\"\n        Parameters\n        ----------\n        sigma:\n            Standard deviation of the underlying normal distribution\n        \"\"\"\n        self.sigma = sigma\n        super().__init__()\n\n    def generate_distribution(self, n: int, integral: float) -> np.ndarray:\n        \"\"\"\n        Generate a log-normal distribution with a specified number of entries and\n        integral.\n\n        Parameters\n        ----------\n        n:\n            Number of entries in the distribution\n        integral:\n            Integral of the distribution\n\n        Returns\n        -------\n        The distribution of size n and of the correct integral value\n        \"\"\"\n        return generate_lognorm_distribution(n, integral, self.sigma)",
  "class TruncNormAvailabilityStrategy(OperationalAvailabilityStrategy):\n    \"\"\"\n    Truncated normal distribution strategy\n    \"\"\"\n\n    def __init__(self, sigma: float):\n        \"\"\"\n        Parameters\n        ----------\n        sigma:\n            Standard deviation of the underlying normal distribution\n        \"\"\"\n        self.sigma = sigma\n        super().__init__()\n\n    def generate_distribution(self, n: int, integral: float) -> np.ndarray:\n        \"\"\"\n        Generate a truncated normal distribution with a specified number of entries and\n        integral.\n\n        Parameters\n        ----------\n        n:\n            Number of entries in the distribution\n        integral:\n            Integral of the distribution\n\n        Returns\n        -------\n        The distribution of size n and of the correct integral value\n        \"\"\"\n        return generate_truncnorm_distribution(n, integral, self.sigma)",
  "class ExponentialAvailabilityStrategy(OperationalAvailabilityStrategy):\n    \"\"\"\n    Exponential distribution strategy\n    \"\"\"\n\n    def __init__(self, lambdda: float):\n        \"\"\"\n        Parameters\n        ----------\n        lambdda:\n            Rate of the distribution\n        \"\"\"\n        self.lambdda = lambdda\n        super().__init__()\n\n    def generate_distribution(self, n: int, integral: float) -> np.ndarray:\n        \"\"\"\n        Generate an exponential distribution with a specified number of entries and\n        integral.\n\n        Parameters\n        ----------\n        n\n            Number of entries in the distribution\n        integral:\n            Integral of the distribution\n\n        Returns\n        -------\n        The distribution of size n and of the correct integral value\n        \"\"\"\n        return generate_exponential_distribution(n, integral, self.lambdda)",
  "def f_integral(x):\n        return np.sum(np.random.lognormal(x, sigma, n)) - integral",
  "def generate_phase_availabilities(\n        self, lifetime_op_availability: float, op_durations: Iterable[float]\n    ) -> Iterable[float]:\n        \"\"\"\n        Generate operational availabilities for the specified phase durations.\n\n        Parameters\n        ----------\n        lifetime_op_availability:\n            Operational availability averaged over the lifetime\n        op_durations:\n            Durations of the operational phases [fpy]\n\n        Returns\n        -------\n        Operational availabilities at each operational phase\n        \"\"\"\n        pass",
  "def generate_phase_availabilities(\n        self, lifetime_op_availability: float, op_durations: Iterable[float]\n    ) -> Iterable[float]:\n        \"\"\"\n        Generate operational availabilities for the specified phase durations.\n\n        Parameters\n        ----------\n        lifetime_op_availability:\n            Operational availability averaged over the lifetime\n        op_durations:\n            Durations of the operational phases [fpy]\n\n        Returns\n        -------\n        Operational availabilities at each operational phase\n        \"\"\"\n        return lifetime_op_availability * np.ones(len(op_durations))",
  "def __init__(self, operational_availabilities: Iterable[float]):\n        \"\"\"\n        Parameters\n        ----------\n        operational_availabilities:\n            Operational availabilities to prescribe\n        \"\"\"\n        self.operational_availabilities = operational_availabilities",
  "def generate_phase_availabilities(\n        self, lifetime_op_availability: float, op_durations: Iterable[float]\n    ) -> Iterable[float]:\n        \"\"\"\n        Generate operational availabilities for the specified phase durations.\n\n        Parameters\n        ----------\n        lifetime_op_availability:\n            Lifetime operational availability\n        op_durations:\n            Durations of the operational phases [fpy]\n\n        Returns\n        -------\n        Operational availabilities at each operational phase\n        \"\"\"\n        if len(op_durations) != len(self.operational_availabilities):\n            raise FuelCycleError(\n                \"The number of phases is not equal to the number of user-specified operational availabilities.\"\n            )\n\n        total_fpy = np.sum(op_durations)\n        fraction = (total_fpy / lifetime_op_availability) / (\n            op_durations / self.operational_availabilities\n        )\n        if fraction != 1.0:\n            bluemira_warn(\n                f\"User-specified operational availabilities do not match the specified lifetime operational : {fraction:.2f} != 1.0. Normalising to adjust to meet the specified lifetime operational availability.\"\n            )\n\n        return fraction * self.operational_availabilities",
  "def __init__(\n        self, learn_rate: float, min_op_availability: float, max_op_availability: float\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        learn_rate:\n            Gompertz distribution learning rate\n        min_op_availability:\n            Minimum operational availability within any given operational phase\n        max_op_availability:\n            Maximum operational availability within any given operational phase\n        \"\"\"\n        self.learn_rate = learn_rate\n        self.min_op_a = min_op_availability\n        self.max_op_a = max_op_availability\n        super().__init__()",
  "def _f_op_availabilities(self, t, x, arg_dates):\n        a_ops = self.min_op_a + f_gompertz(\n            t, self.max_op_a - self.min_op_a, x, self.learn_rate\n        )\n\n        return np.array(\n            [np.mean(a_ops[arg_dates[i] : d]) for i, d in enumerate(arg_dates[1:])]\n        )",
  "def generate_phase_availabilities(\n        self, lifetime_op_availability: float, op_durations: Iterable[float]\n    ) -> Iterable[float]:\n        \"\"\"\n        Generate operational availabilities for the specified phase durations.\n\n        Parameters\n        ----------\n        lifetime_op_availability:\n            Operational availability averaged over the lifetime\n        op_durations:\n            Durations of the operational phases [fpy]\n\n        Returns\n        -------\n        Operational availabilities at each operational phase\n        \"\"\"\n        if not self.min_op_a < lifetime_op_availability < self.max_op_a:\n            raise FuelCycleError(\n                \"Input lifetime operational availability must be within the specified bounds on the phase operational availability.\"\n            )\n\n        op_durations = np.append(0, op_durations)\n        total_fpy = np.sum(op_durations)\n        cum_fpy = np.cumsum(op_durations)\n\n        t = np.linspace(0, total_fpy, 100)\n        arg_dates = np.array([np.argmin(abs(t - i)) for i in cum_fpy])\n\n        def f_opt(x):\n            \"\"\"\n            Optimisation objective for chunky fit to Gompertz\n\n            \\t:math:`a_{min}+(a_{max}-a_{min})e^{\\\\dfrac{-\\\\text{ln}(2)}{e^{-ct_{infl}}}}`\n            \"\"\"\n            a_ops_i = self._f_op_availabilities(t, x, arg_dates)\n            # NOTE: Fancy analytical integral objective of Gompertz function\n            # was a resounding failure. Do not touch this again.\n            # The brute force is strong in this one.\n            return total_fpy / lifetime_op_availability - sum(op_durations[1:] / a_ops_i)\n\n        x_opt = brentq(f_opt, 0, 10e10)\n        return self._f_op_availabilities(t, x_opt, arg_dates)",
  "def generate_distribution(self, n: int, integral: float) -> np.ndarray:\n        \"\"\"\n        Generate a distribution with a specified number of entries and integral.\n\n        Parameters\n        ----------\n        n:\n            Number of entries in the distribution\n        integral:\n            Integral of the distribution\n\n        Returns\n        -------\n        The distribution of size n and of the correct integral value\n        \"\"\"\n        pass",
  "def __init__(self, sigma: float):\n        \"\"\"\n        Parameters\n        ----------\n        sigma:\n            Standard deviation of the underlying normal distribution\n        \"\"\"\n        self.sigma = sigma\n        super().__init__()",
  "def generate_distribution(self, n: int, integral: float) -> np.ndarray:\n        \"\"\"\n        Generate a log-normal distribution with a specified number of entries and\n        integral.\n\n        Parameters\n        ----------\n        n:\n            Number of entries in the distribution\n        integral:\n            Integral of the distribution\n\n        Returns\n        -------\n        The distribution of size n and of the correct integral value\n        \"\"\"\n        return generate_lognorm_distribution(n, integral, self.sigma)",
  "def __init__(self, sigma: float):\n        \"\"\"\n        Parameters\n        ----------\n        sigma:\n            Standard deviation of the underlying normal distribution\n        \"\"\"\n        self.sigma = sigma\n        super().__init__()",
  "def generate_distribution(self, n: int, integral: float) -> np.ndarray:\n        \"\"\"\n        Generate a truncated normal distribution with a specified number of entries and\n        integral.\n\n        Parameters\n        ----------\n        n:\n            Number of entries in the distribution\n        integral:\n            Integral of the distribution\n\n        Returns\n        -------\n        The distribution of size n and of the correct integral value\n        \"\"\"\n        return generate_truncnorm_distribution(n, integral, self.sigma)",
  "def __init__(self, lambdda: float):\n        \"\"\"\n        Parameters\n        ----------\n        lambdda:\n            Rate of the distribution\n        \"\"\"\n        self.lambdda = lambdda\n        super().__init__()",
  "def generate_distribution(self, n: int, integral: float) -> np.ndarray:\n        \"\"\"\n        Generate an exponential distribution with a specified number of entries and\n        integral.\n\n        Parameters\n        ----------\n        n\n            Number of entries in the distribution\n        integral:\n            Integral of the distribution\n\n        Returns\n        -------\n        The distribution of size n and of the correct integral value\n        \"\"\"\n        return generate_exponential_distribution(n, integral, self.lambdda)",
  "def f_opt(x):\n            \"\"\"\n            Optimisation objective for chunky fit to Gompertz\n\n            \\t:math:`a_{min}+(a_{max}-a_{min})e^{\\\\dfrac{-\\\\text{ln}(2)}{e^{-ct_{infl}}}}`\n            \"\"\"\n            a_ops_i = self._f_op_availabilities(t, x, arg_dates)\n            # NOTE: Fancy analytical integral objective of Gompertz function\n            # was a resounding failure. Do not touch this again.\n            # The brute force is strong in this one.\n            return total_fpy / lifetime_op_availability - sum(op_durations[1:] / a_ops_i)",
  "class LifeCycle:\n    \"\"\"\n    A life cycle object for a fusion reactor.\n\n    Parameters\n    ----------\n    config:\n        Parameters for the reactor life cycle. See\n        :class:`bluemira.fuel_cycle.lifecycle.LifeCycleParams` for\n        parameters details.\n        Set to an empty ``dict`` to use default values.\n    learning_strategy:\n        A concrete instance of a ``LearningStrategy`` for distributing\n        the total operational availability over different operational\n        phases.\n    availability_strategy:\n        Concrete instance of an OperationalAvailabilityStrategy\n        implementing a strategy to generate distributions of unplanned\n        outages.\n    inputs:\n        Currently unused.\n    \"\"\"\n\n    def __init__(\n        self,\n        config: Union[LifeCycleParams, Dict[str, float]],\n        learning_strategy: LearningStrategy,\n        availability_strategy: OperationalAvailabilityStrategy,\n        inputs: dict,\n    ):\n        self.learning_strategy = learning_strategy\n        self.availability_strategy = availability_strategy\n        self.inputs = inputs\n\n        if isinstance(config, LifeCycleParams):\n            self.params = config\n        elif isinstance(config, dict):\n            self.params = LifeCycleParams(**config)\n        else:\n            raise TypeError(\n                \"Invalid type for 'params'. Must be one of 'dict', or \"\n                f\"'LifeCycleParams'; found '{type(config).__name__}'.\"\n            )\n\n        # Constructors\n        self.total_planned_maintenance = None\n        self.total_ramptime = None\n        self.t_unplanned_m = None\n        self.t_on_total = None\n        self.t_interdown = None\n        self.cs_down = None\n        self.unplanned = None\n        self.min_downtime = None\n        self.T = None\n        self.a_ops = None\n        self.phase_names = None\n        self.phase_durations = None\n        self.n_blk_replace = None\n        self.n_div_replace = None\n        self.fpy = None\n        self.tf_lifeend = None\n        self.vv_lifeend = None\n        self.A_global = None\n        self.n_cycles = None  # Total number of D-T pulses\n\n        # Derive/convert inputs\n        self.maintenance_l = self.params.bmd  # [s]\n        self.maintenance_s = self.params.dmd  # [s]\n        self.t_rampup = self.params.I_p / self.params.s_ramp_up  # [s]\n        self.t_rampdown = self.params.I_p / self.params.s_ramp_down  # [s]\n        self.t_flattop = self.params.t_pulse - self.t_rampup - self.t_rampdown  # [s]\n        self.t_min_down = max(self.params.t_cs_recharge, self.params.t_pumpdown)\n\n        # Build timeline\n        self.life_neutronics()\n        self.set_availabilities(self.params.A_global)\n\n    def life_neutronics(self):\n        \"\"\"\n        Calculate the lifetime of various components based on their damage limits\n        and fluences.\n        \"\"\"\n        tf_ins_nflux = self.params.tf_ins_nflux\n        divl = self.params.div_dpa / self.params.div_dmg  # [fpy] Divertor life\n        blk1l = self.params.blk_1_dpa / self.params.blk_dmg  # [fpy] 1st Blanket life\n        blk2l = self.params.blk_2_dpa / self.params.blk_dmg  # [fpy] 2nd Blanket life\n\n        # Number of divertor changes in 1st blanket life\n        ndivch_in1blk = int(blk1l / divl)\n        # Number of divertor changes in 2nd blanket life (1 for div reset)\n        ndivch_in2blk = int(blk2l / divl)\n\n        self.n_blk_replace = 1  # HLR\n        self.n_div_replace = ndivch_in1blk + ndivch_in2blk\n        m_short = self.maintenance_s * S_TO_YR\n        m_long = self.maintenance_l * S_TO_YR\n        phases = []\n        for i in range(ndivch_in1blk):\n            p_str = \"Phase P1.\" + str(i + 1)\n            m_str = \"Phase M1.\" + str(i + 1)\n            phases.append([divl, p_str])\n            phases.append([m_short, m_str])\n            count = i\n        if ndivch_in1blk == 0:\n            count = 0\n        phases.append([blk1l % divl, \"Phase P1.\" + str(count + 2)])\n        phases.append([m_long, \"Phase M1.\" + str(count + 2)])\n        for i in range(ndivch_in2blk):\n            p_str = \"Phase P2.\" + str(i + 1)\n            m_str = \"Phase M2.\" + str(i + 1)\n            phases.append([divl, p_str])\n            phases.append([m_short, m_str])\n            count2 = i\n        phases.append([blk2l % divl, \"Phase P2.\" + str(count2 + 1)])\n        self.phase_durations = [p[0] for p in phases]\n        self.phase_names = [p[1] for p in phases]\n        self.calc_n_pulses(phases)\n        fpy = 0\n        for i in range(len(phases)):\n            if phases[i][1].startswith(\"Phase P\"):\n                fpy += phases[i][0]\n        self.fpy = fpy\n        # Irreplaceable components life checks\n        self.t_on_total = self.fpy * YR_TO_S  # [s] total fusion time\n        tf_ins_life_dose = tf_ins_nflux * self.t_on_total / self.params.tf_fluence\n        if tf_ins_life_dose > 1:\n            self.tf_lifeend = round(self.params.tf_fluence / tf_ins_nflux / YR_TO_S, 2)\n            tflifeperc = round(100 * self.tf_lifeend / self.fpy, 1)\n            bluemira_warn(\n                f\"TF coil insulation fried after {self.tf_lifeend:.2f} full-power years\"\n                f\", or {tflifeperc:.2f} % of neutron budget.\"\n            )\n        vv_life_dmg = self.params.vv_dmg * self.fpy / self.params.vv_dpa\n        if vv_life_dmg > 1:\n            self.vv_lifeend = round(self.params.vv_dpa / self.params.vv_dmg, 2)\n            vvlifeperc = round(100 * self.vv_lifeend / self.fpy, 1)\n            bluemira_warn(\n                f\"VV fried after {self.vv_lifeend:.2f} full-power\"\n                f\" years, or {vvlifeperc:.2f} % of neutron budget.\"\n            )\n            # TODO: treat output parameter\n        self.n_cycles = self.fpy * YR_TO_S / self.t_flattop\n\n    def set_availabilities(self, load_factor: float):\n        \"\"\"\n        Sets availability and distributes it between the two phases of planned operation.\n        The planned maintenance windows are subtracted from the availability which\n        needs to be achieved during the phase of operation. The target overall plant\n        lifetime availability as specified in input parameter A remains the same.\n\n        Notes\n        -----\n        \\t:math:`A_{overall}=\\\\dfrac{t_{on}}{t_{on}+t_{off}}`\n        \\t:math:`A_{operations}=\\\\dfrac{t_{on}}{t_{on}+t_{ramp}+t_{CS_{recharge}}+t_{m_{unplanned}}}`\n        \"\"\"\n        self.total_planned_maintenance = self.maintenance_l * self.n_blk_replace + (\n            self.maintenance_s * self.n_div_replace\n        )\n        self.t_interdown = sum(self.n_pulse_p) * self.t_min_down\n        self.total_ramptime = sum(self.n_pulse_p) * (self.t_rampup + self.t_rampdown)\n        self.min_downtime = (\n            self.total_planned_maintenance + self.t_interdown + self.total_ramptime\n        )\n        self.unplanned = self.t_on_total / load_factor - (\n            self.total_planned_maintenance\n            + self.t_interdown\n            + self.total_ramptime\n            + self.t_on_total\n        )\n\n        # TODO: Treat global load factor vs lifetime operational availability properly..!\n        op_durations = self.get_op_phases()\n        self.a_ops = self.learning_strategy.generate_phase_availabilities(\n            self.params.A_global, op_durations\n        )\n\n    def calc_n_pulses(self, phases: List[List[float]]):\n        \"\"\"\n        Calculate the number of pulses per phase.\n        \"\"\"\n        n_pulse_p = []\n        for i in range(len(phases)):\n            if phases[i][1].startswith(\"Phase P\"):\n                # TODO: Change to //\n                n_pulse_p.append(int(round(YR_TO_S * phases[i][0] / self.t_flattop, 0)))\n        self.n_pulse_p = n_pulse_p\n\n    def get_op_phases(self) -> List[float]:\n        \"\"\"\n        Get the operational phases for the LifeCycle.\n        \"\"\"\n        return [\n            d for n, d in zip(self.phase_names, self.phase_durations) if \"Phase P\" in n\n        ]\n\n    def make_timeline(self) -> Timeline:\n        \"\"\"\n        Builds a Timeline instance\n        \"\"\"\n        n = len(self.n_pulse_p)\n\n        for k in [\"t_rampup\", \"t_flattop\", \"t_rampdown\", \"t_min_down\"]:\n            v = getattr(self, k)\n            if is_num(v):\n                setattr(self, k, v * np.ones(n))\n\n        n_DT_reactions = self.params.n_DT_reactions * np.ones(n)\n        n_DD_reactions = self.params.n_DD_reactions * np.ones(n)\n        Ip = self.params.I_p * np.ones(n)\n\n        timeline = Timeline(\n            self.phase_names,\n            self.phase_durations,\n            self.a_ops,\n            self.n_pulse_p,\n            self.t_rampup,\n            self.t_flattop,\n            self.t_rampdown,\n            self.t_min_down,\n            n_DT_reactions,\n            n_DD_reactions,\n            Ip,\n            self.params.A_global,\n            self.params.blk_dmg,\n            self.params.blk_1_dpa,\n            self.params.blk_2_dpa,\n            self.params.div_dmg,\n            self.params.div_dpa,\n            self.params.tf_ins_nflux,\n            self.params.tf_fluence,\n            self.params.vv_dmg,\n            self.params.vv_dpa,\n            self.availability_strategy,\n        )\n        self.T = timeline\n        self.t_unplanned_m = self.T.t_unplanned_m\n        return self.T\n\n    def sanity(self):\n        \"\"\"\n        Perform a sanity check. Will raise warnings if the LifeCycle generates\n        results that violate the tolerances.\n        \"\"\"\n        life = self.fpy / self.params.A_global\n        actual_life = S_TO_YR * (\n            self.t_on_total\n            + self.total_ramptime\n            + self.t_interdown\n            + self.total_planned_maintenance\n            + self.t_unplanned_m\n        )\n        actual_lf = self.fpy / actual_life\n        delt = abs_rel_difference(actual_life, life)\n        delta2 = abs_rel_difference(actual_lf, self.params.A_global)\n        if delt > 0.015:\n            bluemira_warn(\n                \"FuelCycle::Lifecyle: discrepancy between actual and planned\\n\"\n                \"reactor lifetime\\n\"\n                f\"Actual: {actual_life:.2f}\\n\"\n                f\"Planned: {life:.2f}\\n\"\n                f\"% diff: {100*delt:.4f}\\n\"\n                \"the problem is probably related to unplanned maintenance.\"\n            )\n            self.__init__(\n                self.params,\n                self.learning_strategy,\n                self.availability_strategy,\n                self.inputs,\n            )  # Phoenix\n\n        if delta2 > 0.015:\n            bluemira_warn(\n                \"FuelCycle::Lifecyle: availability discrepancy greater than\\n\"\n                \"specified tolerance\\n\"\n                f\"Actual: {actual_lf:.4f}\\n\"\n                f\"Planned: {self.params.A_global:.4f}\\n\"\n                f\"% diff: {100*delta2:.4f}\\n\"\n                \"the problem is probably related to unplanned maintenance.\"\n            )\n            self.__init__(\n                self.params,\n                self.learning_strategy,\n                self.availability_strategy,\n                self.inputs,\n            )  # Phoenix\n\n        if self.params.A_global > self.fpy / (self.fpy + S_TO_YR * self.min_downtime):\n            bluemira_warn(\"FuelCycle::Lifecyle: Input availability is unachievable.\")\n        # Re-assign A\n        self.params.A_global = actual_lf\n\n    def summary(self):\n        \"\"\"\n        Plot the load factor breakdown and learning curve\n        \"\"\"\n        f, ax = plt.subplots(1, 2)\n        self.plot_learning(ax=ax[0])\n        self.plot_load_factor(ax=ax[1])\n\n    def plot_life(self):\n        \"\"\"\n        Plot the different maintenance events in the Lifecycle, and the slope\n        of each operational phase\n        \"\"\"\n        f, ax = plt.subplots(1, 1)\n        # Plotting crutches\n        fs, s, h = 0, 0, 0.95 * self.fpy\n        ft, rt = [0], [0]\n        j = 0\n        for p_n, p_d in zip(self.phase_names, self.phase_durations):\n            if p_n.startswith(\"Phase P\"):\n                c = \"b\"\n                ft.append(fs + p_d)\n                fs += p_d\n                length = p_d / self.a_ops[j]\n                rt.append(s + length)\n                j += 1\n            elif p_n.startswith(\"Phase M\"):\n                ft.append(ft[-1])\n                c = \"r\"\n                length = p_d\n                rt.append(rt[-1] + p_d)\n                if p_n.startswith(\"Phase M1.2\"):\n                    m = \"s\"\n                else:\n                    m = \"o\"\n                ax.plot(rt[-1] - p_d / 2, 0.3, marker=m, color=\"r\", ms=25)\n                ax.axvspan(s, s + length, color=c, alpha=0.2)\n            h -= 0.08 * self.fpy\n            s += length\n\n        legend = [\n            Line2D(\n                [0],\n                [0],\n                marker=\"o\",\n                color=\"w\",\n                label=\"Divertor replacement\",\n                markerfacecolor=\"r\",\n                markersize=25,\n            ),\n            Line2D(\n                [0],\n                [0],\n                marker=\"s\",\n                color=\"w\",\n                label=\"Blanket and divertor \\nreplacement\",\n                markerfacecolor=\"r\",\n                markersize=25,\n            ),\n        ]\n        ax.legend(handles=legend)\n        ax.plot(rt, ft, color=\"#0072bd\")\n        ax.set_xlabel(\"Elapsed plant lifetime [years]\")\n        ax.set_ylabel(\"Full power years [fpy]\")\n        ax.set_xlim([0, self.fpy / self.params.A_global])\n        ax.set_ylim(bottom=0)\n\n    def plot_load_factor(self, typ: str = \"pie\", ax: Optional[plt.Axes] = None):\n        \"\"\"\n        Plots a pie or bar chart of the breakdown of the reactor lifetime\n\n        Parameters\n        ----------\n        typ:\n            Whether to plot a pie or bar chart ['pie', 'bar']\n        \"\"\"\n        if ax is None:\n            ax = plt.gca()\n        c = [\"#0072bd\", \"#d95319\", \"#edb120\", \"#7e2f8e\", \"#77ac30\"]\n        labels = [\n            \"Fusion time\",\n            \"Ramp-up and\\nramp-down\",\n            \"CS recharge\",\n            \"Planned\\nmaintenance\",\n            \"Unallocated\\ndowntime\",\n        ]\n        sizes = [\n            self.t_on_total,\n            self.total_ramptime,\n            self.t_interdown,\n            self.total_planned_maintenance,\n            self.t_unplanned_m,\n        ]\n        if typ == \"pie\":\n            plt.pie(\n                sizes,\n                labels=labels,\n                colors=c,\n                startangle=90,\n                autopct=\"%.2f\",\n                counterclock=False,\n            )\n            plt.axis(\"equal\")\n        elif typ == \"bar\":\n            bottom = 0\n            for i, s in enumerate(sizes):\n                ax.bar(1, s / sum(sizes) * 100, bottom=bottom, label=labels[i])\n                bottom += s / sum(sizes) * 100\n            ax.set_xticklabels([\"\"])\n            ax.set_xlim([0, 6])\n            ax.legend()\n        plt.title(\n            \"Breakdown of DEMO reactor lifetime\\n A = {0:.2f},\"\n            \"{1:.2f} fpy, {2:.2f} years\".format(\n                self.params.A_global, self.fpy, self.T.plant_life\n            )\n        )\n\n    def write(self, filename: str, **kwargs):\n        \"\"\"\n        Save a Timeline to a JSON file.\n        \"\"\"\n        bluemira_print(f\"Writing {filename}\")\n        data = self.T.to_dict()\n        return json_writer(data, filename, **kwargs)\n\n    def read(self, filename: str):\n        \"\"\"\n        Load a Timeline from a JSON file.\n        \"\"\"\n        bluemira_print(f\"Reading {filename}\")\n        with open(filename) as f_h:\n            data = json.load(f_h)\n        return data",
  "class LifeCycleParams:\n    \"\"\"Parameters for running :class:`bluemira.fuel_cycle.lifecycle.LifeCycle`\"\"\"\n\n    A_global: float = 0.3\n    \"\"\"Global load factor [dimensionless]. Not always used.\"\"\"\n\n    I_p: float = 19e6\n    \"\"\"Plasma current [A]. None.\"\"\"\n\n    bmd: float = raw_uc(150, \"days\", \"s\")\n    \"\"\"Blanket maintenance duration [days]. Full replacement intervention duration.\"\"\"\n\n    dmd: float = raw_uc(90, \"days\", \"s\")\n    \"\"\"Divertor maintenance duration [s]. Full replacement intervention duration.\"\"\"\n\n    t_pulse: float = 7200\n    \"\"\"Pulse length [s]. Includes ramp-up and ramp-down time.\"\"\"\n\n    t_cs_recharge: float = 600\n    \"\"\"CS recharge time [s]. Presently assumed to dictate minimum dwell period.\"\"\"\n\n    t_pumpdown: float = 599\n    \"\"\"\n    Pump down duration of the vessel in between pulses [s]. Presently assumed to\n    take less time than the CS recharge.\n    \"\"\"\n\n    s_ramp_up: float = 1e5\n    \"\"\"Plasma current ramp-up rate [A/s]. None.\"\"\"\n\n    s_ramp_down: float = 1e5\n    \"\"\"Plasma current ramp-down rate [A/s]. None.\"\"\"\n\n    n_DT_reactions: float = 7.078779946428698e20\n    \"\"\"D-T fusion reaction rate [1/s]. At full power.\"\"\"\n\n    n_DD_reactions: float = 8.548069652616976e18\n    \"\"\"D-D fusion reaction rate [1/s]. At full power.\"\"\"\n\n    blk_1_dpa: float = 20\n    \"\"\"\n    Starter blanket life limit (EUROfer) [dpa].\n    https://iopscience.iop.org/article/10.1088/1741-4326/57/9/092002/pdf.\n    \"\"\"\n\n    blk_2_dpa: float = 50\n    \"\"\"\n    Second blanket life limit (EUROfer) [dpa].\n    https://iopscience.iop.org/article/10.1088/1741-4326/57/9/092002/pdf.\n    \"\"\"\n\n    div_dpa: float = 5\n    \"\"\"\n    Divertor life limit (CuCrZr) [dpa].\n    https://iopscience.iop.org/article/10.1088/1741-4326/57/9/092002/pdf.\n    \"\"\"\n\n    vv_dpa: float = 3.25\n    \"\"\"Vacuum vessel life limit (SS316-LN-IG) [dpa]. RCC-Mx or whatever it is called.\"\"\"\n\n    tf_fluence: float = 3.2e21\n    \"\"\"\n    Insulation fluence limit for ITER equivalent to 10 MGy [1/m^2].\n    https://ieeexplore.ieee.org/document/6374236/.\n    \"\"\"\n\n    tf_ins_nflux: float = 1.4e13\n    \"\"\"\n    TF insulation peak neutron flux [1/m^2/s]. Pavel Pereslavtsev sent me an email\n    20/02/2017.\n    \"\"\"\n\n    blk_dmg: float = 10.2\n    \"\"\"Blanket neutron damage rate [dpa/fpy]. Pavel Pereslavtsev 2M7HN3 fig. 20.\"\"\"\n\n    div_dmg: float = 3\n    \"\"\"\n    Divertor neutron damage rate [dpa/fpy].\n    https://iopscience.iop.org/article/10.1088/1741-4326/57/9/092002/pdf.\n    \"\"\"\n\n    vv_dmg: float = 0.3\n    \"\"\"Vacuum vessel neutron damage rate [dpa/fpy]. Pavel Pereslavtsev 2M7HN3 fig. 18.\"\"\"",
  "def __init__(\n        self,\n        config: Union[LifeCycleParams, Dict[str, float]],\n        learning_strategy: LearningStrategy,\n        availability_strategy: OperationalAvailabilityStrategy,\n        inputs: dict,\n    ):\n        self.learning_strategy = learning_strategy\n        self.availability_strategy = availability_strategy\n        self.inputs = inputs\n\n        if isinstance(config, LifeCycleParams):\n            self.params = config\n        elif isinstance(config, dict):\n            self.params = LifeCycleParams(**config)\n        else:\n            raise TypeError(\n                \"Invalid type for 'params'. Must be one of 'dict', or \"\n                f\"'LifeCycleParams'; found '{type(config).__name__}'.\"\n            )\n\n        # Constructors\n        self.total_planned_maintenance = None\n        self.total_ramptime = None\n        self.t_unplanned_m = None\n        self.t_on_total = None\n        self.t_interdown = None\n        self.cs_down = None\n        self.unplanned = None\n        self.min_downtime = None\n        self.T = None\n        self.a_ops = None\n        self.phase_names = None\n        self.phase_durations = None\n        self.n_blk_replace = None\n        self.n_div_replace = None\n        self.fpy = None\n        self.tf_lifeend = None\n        self.vv_lifeend = None\n        self.A_global = None\n        self.n_cycles = None  # Total number of D-T pulses\n\n        # Derive/convert inputs\n        self.maintenance_l = self.params.bmd  # [s]\n        self.maintenance_s = self.params.dmd  # [s]\n        self.t_rampup = self.params.I_p / self.params.s_ramp_up  # [s]\n        self.t_rampdown = self.params.I_p / self.params.s_ramp_down  # [s]\n        self.t_flattop = self.params.t_pulse - self.t_rampup - self.t_rampdown  # [s]\n        self.t_min_down = max(self.params.t_cs_recharge, self.params.t_pumpdown)\n\n        # Build timeline\n        self.life_neutronics()\n        self.set_availabilities(self.params.A_global)",
  "def life_neutronics(self):\n        \"\"\"\n        Calculate the lifetime of various components based on their damage limits\n        and fluences.\n        \"\"\"\n        tf_ins_nflux = self.params.tf_ins_nflux\n        divl = self.params.div_dpa / self.params.div_dmg  # [fpy] Divertor life\n        blk1l = self.params.blk_1_dpa / self.params.blk_dmg  # [fpy] 1st Blanket life\n        blk2l = self.params.blk_2_dpa / self.params.blk_dmg  # [fpy] 2nd Blanket life\n\n        # Number of divertor changes in 1st blanket life\n        ndivch_in1blk = int(blk1l / divl)\n        # Number of divertor changes in 2nd blanket life (1 for div reset)\n        ndivch_in2blk = int(blk2l / divl)\n\n        self.n_blk_replace = 1  # HLR\n        self.n_div_replace = ndivch_in1blk + ndivch_in2blk\n        m_short = self.maintenance_s * S_TO_YR\n        m_long = self.maintenance_l * S_TO_YR\n        phases = []\n        for i in range(ndivch_in1blk):\n            p_str = \"Phase P1.\" + str(i + 1)\n            m_str = \"Phase M1.\" + str(i + 1)\n            phases.append([divl, p_str])\n            phases.append([m_short, m_str])\n            count = i\n        if ndivch_in1blk == 0:\n            count = 0\n        phases.append([blk1l % divl, \"Phase P1.\" + str(count + 2)])\n        phases.append([m_long, \"Phase M1.\" + str(count + 2)])\n        for i in range(ndivch_in2blk):\n            p_str = \"Phase P2.\" + str(i + 1)\n            m_str = \"Phase M2.\" + str(i + 1)\n            phases.append([divl, p_str])\n            phases.append([m_short, m_str])\n            count2 = i\n        phases.append([blk2l % divl, \"Phase P2.\" + str(count2 + 1)])\n        self.phase_durations = [p[0] for p in phases]\n        self.phase_names = [p[1] for p in phases]\n        self.calc_n_pulses(phases)\n        fpy = 0\n        for i in range(len(phases)):\n            if phases[i][1].startswith(\"Phase P\"):\n                fpy += phases[i][0]\n        self.fpy = fpy\n        # Irreplaceable components life checks\n        self.t_on_total = self.fpy * YR_TO_S  # [s] total fusion time\n        tf_ins_life_dose = tf_ins_nflux * self.t_on_total / self.params.tf_fluence\n        if tf_ins_life_dose > 1:\n            self.tf_lifeend = round(self.params.tf_fluence / tf_ins_nflux / YR_TO_S, 2)\n            tflifeperc = round(100 * self.tf_lifeend / self.fpy, 1)\n            bluemira_warn(\n                f\"TF coil insulation fried after {self.tf_lifeend:.2f} full-power years\"\n                f\", or {tflifeperc:.2f} % of neutron budget.\"\n            )\n        vv_life_dmg = self.params.vv_dmg * self.fpy / self.params.vv_dpa\n        if vv_life_dmg > 1:\n            self.vv_lifeend = round(self.params.vv_dpa / self.params.vv_dmg, 2)\n            vvlifeperc = round(100 * self.vv_lifeend / self.fpy, 1)\n            bluemira_warn(\n                f\"VV fried after {self.vv_lifeend:.2f} full-power\"\n                f\" years, or {vvlifeperc:.2f} % of neutron budget.\"\n            )\n            # TODO: treat output parameter\n        self.n_cycles = self.fpy * YR_TO_S / self.t_flattop",
  "def set_availabilities(self, load_factor: float):\n        \"\"\"\n        Sets availability and distributes it between the two phases of planned operation.\n        The planned maintenance windows are subtracted from the availability which\n        needs to be achieved during the phase of operation. The target overall plant\n        lifetime availability as specified in input parameter A remains the same.\n\n        Notes\n        -----\n        \\t:math:`A_{overall}=\\\\dfrac{t_{on}}{t_{on}+t_{off}}`\n        \\t:math:`A_{operations}=\\\\dfrac{t_{on}}{t_{on}+t_{ramp}+t_{CS_{recharge}}+t_{m_{unplanned}}}`\n        \"\"\"\n        self.total_planned_maintenance = self.maintenance_l * self.n_blk_replace + (\n            self.maintenance_s * self.n_div_replace\n        )\n        self.t_interdown = sum(self.n_pulse_p) * self.t_min_down\n        self.total_ramptime = sum(self.n_pulse_p) * (self.t_rampup + self.t_rampdown)\n        self.min_downtime = (\n            self.total_planned_maintenance + self.t_interdown + self.total_ramptime\n        )\n        self.unplanned = self.t_on_total / load_factor - (\n            self.total_planned_maintenance\n            + self.t_interdown\n            + self.total_ramptime\n            + self.t_on_total\n        )\n\n        # TODO: Treat global load factor vs lifetime operational availability properly..!\n        op_durations = self.get_op_phases()\n        self.a_ops = self.learning_strategy.generate_phase_availabilities(\n            self.params.A_global, op_durations\n        )",
  "def calc_n_pulses(self, phases: List[List[float]]):\n        \"\"\"\n        Calculate the number of pulses per phase.\n        \"\"\"\n        n_pulse_p = []\n        for i in range(len(phases)):\n            if phases[i][1].startswith(\"Phase P\"):\n                # TODO: Change to //\n                n_pulse_p.append(int(round(YR_TO_S * phases[i][0] / self.t_flattop, 0)))\n        self.n_pulse_p = n_pulse_p",
  "def get_op_phases(self) -> List[float]:\n        \"\"\"\n        Get the operational phases for the LifeCycle.\n        \"\"\"\n        return [\n            d for n, d in zip(self.phase_names, self.phase_durations) if \"Phase P\" in n\n        ]",
  "def make_timeline(self) -> Timeline:\n        \"\"\"\n        Builds a Timeline instance\n        \"\"\"\n        n = len(self.n_pulse_p)\n\n        for k in [\"t_rampup\", \"t_flattop\", \"t_rampdown\", \"t_min_down\"]:\n            v = getattr(self, k)\n            if is_num(v):\n                setattr(self, k, v * np.ones(n))\n\n        n_DT_reactions = self.params.n_DT_reactions * np.ones(n)\n        n_DD_reactions = self.params.n_DD_reactions * np.ones(n)\n        Ip = self.params.I_p * np.ones(n)\n\n        timeline = Timeline(\n            self.phase_names,\n            self.phase_durations,\n            self.a_ops,\n            self.n_pulse_p,\n            self.t_rampup,\n            self.t_flattop,\n            self.t_rampdown,\n            self.t_min_down,\n            n_DT_reactions,\n            n_DD_reactions,\n            Ip,\n            self.params.A_global,\n            self.params.blk_dmg,\n            self.params.blk_1_dpa,\n            self.params.blk_2_dpa,\n            self.params.div_dmg,\n            self.params.div_dpa,\n            self.params.tf_ins_nflux,\n            self.params.tf_fluence,\n            self.params.vv_dmg,\n            self.params.vv_dpa,\n            self.availability_strategy,\n        )\n        self.T = timeline\n        self.t_unplanned_m = self.T.t_unplanned_m\n        return self.T",
  "def sanity(self):\n        \"\"\"\n        Perform a sanity check. Will raise warnings if the LifeCycle generates\n        results that violate the tolerances.\n        \"\"\"\n        life = self.fpy / self.params.A_global\n        actual_life = S_TO_YR * (\n            self.t_on_total\n            + self.total_ramptime\n            + self.t_interdown\n            + self.total_planned_maintenance\n            + self.t_unplanned_m\n        )\n        actual_lf = self.fpy / actual_life\n        delt = abs_rel_difference(actual_life, life)\n        delta2 = abs_rel_difference(actual_lf, self.params.A_global)\n        if delt > 0.015:\n            bluemira_warn(\n                \"FuelCycle::Lifecyle: discrepancy between actual and planned\\n\"\n                \"reactor lifetime\\n\"\n                f\"Actual: {actual_life:.2f}\\n\"\n                f\"Planned: {life:.2f}\\n\"\n                f\"% diff: {100*delt:.4f}\\n\"\n                \"the problem is probably related to unplanned maintenance.\"\n            )\n            self.__init__(\n                self.params,\n                self.learning_strategy,\n                self.availability_strategy,\n                self.inputs,\n            )  # Phoenix\n\n        if delta2 > 0.015:\n            bluemira_warn(\n                \"FuelCycle::Lifecyle: availability discrepancy greater than\\n\"\n                \"specified tolerance\\n\"\n                f\"Actual: {actual_lf:.4f}\\n\"\n                f\"Planned: {self.params.A_global:.4f}\\n\"\n                f\"% diff: {100*delta2:.4f}\\n\"\n                \"the problem is probably related to unplanned maintenance.\"\n            )\n            self.__init__(\n                self.params,\n                self.learning_strategy,\n                self.availability_strategy,\n                self.inputs,\n            )  # Phoenix\n\n        if self.params.A_global > self.fpy / (self.fpy + S_TO_YR * self.min_downtime):\n            bluemira_warn(\"FuelCycle::Lifecyle: Input availability is unachievable.\")\n        # Re-assign A\n        self.params.A_global = actual_lf",
  "def summary(self):\n        \"\"\"\n        Plot the load factor breakdown and learning curve\n        \"\"\"\n        f, ax = plt.subplots(1, 2)\n        self.plot_learning(ax=ax[0])\n        self.plot_load_factor(ax=ax[1])",
  "def plot_life(self):\n        \"\"\"\n        Plot the different maintenance events in the Lifecycle, and the slope\n        of each operational phase\n        \"\"\"\n        f, ax = plt.subplots(1, 1)\n        # Plotting crutches\n        fs, s, h = 0, 0, 0.95 * self.fpy\n        ft, rt = [0], [0]\n        j = 0\n        for p_n, p_d in zip(self.phase_names, self.phase_durations):\n            if p_n.startswith(\"Phase P\"):\n                c = \"b\"\n                ft.append(fs + p_d)\n                fs += p_d\n                length = p_d / self.a_ops[j]\n                rt.append(s + length)\n                j += 1\n            elif p_n.startswith(\"Phase M\"):\n                ft.append(ft[-1])\n                c = \"r\"\n                length = p_d\n                rt.append(rt[-1] + p_d)\n                if p_n.startswith(\"Phase M1.2\"):\n                    m = \"s\"\n                else:\n                    m = \"o\"\n                ax.plot(rt[-1] - p_d / 2, 0.3, marker=m, color=\"r\", ms=25)\n                ax.axvspan(s, s + length, color=c, alpha=0.2)\n            h -= 0.08 * self.fpy\n            s += length\n\n        legend = [\n            Line2D(\n                [0],\n                [0],\n                marker=\"o\",\n                color=\"w\",\n                label=\"Divertor replacement\",\n                markerfacecolor=\"r\",\n                markersize=25,\n            ),\n            Line2D(\n                [0],\n                [0],\n                marker=\"s\",\n                color=\"w\",\n                label=\"Blanket and divertor \\nreplacement\",\n                markerfacecolor=\"r\",\n                markersize=25,\n            ),\n        ]\n        ax.legend(handles=legend)\n        ax.plot(rt, ft, color=\"#0072bd\")\n        ax.set_xlabel(\"Elapsed plant lifetime [years]\")\n        ax.set_ylabel(\"Full power years [fpy]\")\n        ax.set_xlim([0, self.fpy / self.params.A_global])\n        ax.set_ylim(bottom=0)",
  "def plot_load_factor(self, typ: str = \"pie\", ax: Optional[plt.Axes] = None):\n        \"\"\"\n        Plots a pie or bar chart of the breakdown of the reactor lifetime\n\n        Parameters\n        ----------\n        typ:\n            Whether to plot a pie or bar chart ['pie', 'bar']\n        \"\"\"\n        if ax is None:\n            ax = plt.gca()\n        c = [\"#0072bd\", \"#d95319\", \"#edb120\", \"#7e2f8e\", \"#77ac30\"]\n        labels = [\n            \"Fusion time\",\n            \"Ramp-up and\\nramp-down\",\n            \"CS recharge\",\n            \"Planned\\nmaintenance\",\n            \"Unallocated\\ndowntime\",\n        ]\n        sizes = [\n            self.t_on_total,\n            self.total_ramptime,\n            self.t_interdown,\n            self.total_planned_maintenance,\n            self.t_unplanned_m,\n        ]\n        if typ == \"pie\":\n            plt.pie(\n                sizes,\n                labels=labels,\n                colors=c,\n                startangle=90,\n                autopct=\"%.2f\",\n                counterclock=False,\n            )\n            plt.axis(\"equal\")\n        elif typ == \"bar\":\n            bottom = 0\n            for i, s in enumerate(sizes):\n                ax.bar(1, s / sum(sizes) * 100, bottom=bottom, label=labels[i])\n                bottom += s / sum(sizes) * 100\n            ax.set_xticklabels([\"\"])\n            ax.set_xlim([0, 6])\n            ax.legend()\n        plt.title(\n            \"Breakdown of DEMO reactor lifetime\\n A = {0:.2f},\"\n            \"{1:.2f} fpy, {2:.2f} years\".format(\n                self.params.A_global, self.fpy, self.T.plant_life\n            )\n        )",
  "def write(self, filename: str, **kwargs):\n        \"\"\"\n        Save a Timeline to a JSON file.\n        \"\"\"\n        bluemira_print(f\"Writing {filename}\")\n        data = self.T.to_dict()\n        return json_writer(data, filename, **kwargs)",
  "def read(self, filename: str):\n        \"\"\"\n        Load a Timeline from a JSON file.\n        \"\"\"\n        bluemira_print(f\"Reading {filename}\")\n        with open(filename) as f_h:\n            data = json.load(f_h)\n        return data",
  "class FuelCycleError(BluemiraError):\n    \"\"\"\n    The base fuel_cycle error class.\n    \"\"\"\n\n    pass",
  "def find_noisy_locals(\n    x: np.ndarray, x_bins: int = 50, mode: str = \"min\"\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Find local minima or maxima in a noisy signal.\n\n    Parameters\n    ----------\n    x:\n        The noise data to search\n    x_bins:\n        The number of bins to search with\n    mode:\n        The search mode ['min', 'max']\n\n    Returns\n    -------\n    local_mid_x:\n        The arguments of the local minima or maxima\n    local_m:\n        The local minima or maxima\n    \"\"\"\n    if mode == \"max\":\n        peak = np.max\n        arg_peak = np.argmax\n    elif mode == \"min\":\n        peak = np.min\n        arg_peak = np.argmin\n    else:\n        raise FuelCycleError(f\"Unrecognised mode: {mode}.\")\n\n    n = len(x)\n    bin_size = round(n / x_bins)\n    y_bins = [x[i : i + bin_size] for i in range(0, n, bin_size)]\n\n    local_m = np.zeros(len(y_bins))\n    local_mid_x = np.zeros(len(y_bins), dtype=int)\n    for i, y_bin in enumerate(y_bins):\n        local_m[i] = peak(y_bin)\n        local_mid_x[i] = arg_peak(y_bin) + i * bin_size\n    return local_mid_x, local_m",
  "def discretise_1d(\n    x: np.ndarray, y: np.ndarray, n: int, method: str = \"linear\"\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Discretise x and y for a given number of points.\n\n    Parameters\n    ----------\n    x:\n        The x data\n    y:\n        The y data\n    n:\n        The number of discretisation points\n    method:\n        The interpolation method\n\n    Returns\n    -------\n    x_1d:\n        The discretised x data\n    y_1d:\n        The discretised y data\n    \"\"\"\n    x = np.array(x)\n    y = np.array(y)\n    x_1d = np.linspace(x[0], x[-1], n)\n    y_1d = griddata(x, y, xi=x_1d, method=method)\n    return [x_1d, y_1d]",
  "def convert_flux_to_flow(flux: float, area: float) -> float:\n    \"\"\"\n    Convert an atomic flux to a flow-rate.\n\n    Parameters\n    ----------\n    flux:\n        The atomic flux [T/m^2/s]\n    area:\n        The surface area of the flux [m^2]\n\n    Returns\n    -------\n    The flow-rate [kg/s]\n    \"\"\"\n    return flux * area * T_MOLAR_MASS / N_AVOGADRO / 1000",
  "def piecewise_linear_threshold(\n    x: np.ndarray, x0: float, y0: float, m1: float, m2: float\n) -> np.ndarray:\n    \"\"\"\n    Piecewise linear model with initial linear slope, followed by threshold.\n\n    Parameters\n    ----------\n    x:\n        The vector of x values to calculate the function for\n    x0:\n        The x coordinate of the kink point\n    y0:\n        The y coordinate of the kink point\n    m1:\n        The slope of the first curve\n    m2:\n        The threshold value of the function\n\n    Returns\n    -------\n    The vector of fitted values\n    \"\"\"\n    return np.piecewise(x, [x < x0], [lambda fx: m1 * fx + y0 - m1 * x0, lambda fx: m2])",
  "def piecewise_sqrt_threshold(\n    x: np.ndarray, factor: float, kink: float, threshold: float\n) -> np.ndarray:\n    \"\"\"\n    Piecewise square-root model, followed by threshold.\n\n    Parameters\n    ----------\n    x:\n        The vector of x values to calculate the function for\n    factor:\n        The multiplication factor for the sqrt function\n    kink:\n        The x value where the behaviour changes from sqrt to constant\n    threshold:\n        The threshold value of the model\n\n    Returns\n    -------\n    The vector of fitted values\n    \"\"\"\n    return np.piecewise(\n        x, [x < kink], [lambda fx: factor * np.sqrt(fx), lambda fx: threshold]\n    )",
  "def fit_sink_data(\n    x: np.ndarray, y: np.ndarray, method: str = \"sqrt\", plot: bool = True\n) -> Tuple[float, float]:\n    \"\"\"\n    Function used to determine simplified tritium sink model parameters, from\n    data values.\n\n    Parameters\n    ----------\n    x:\n        The vector of x values\n    y:\n        The vector of y values\n    method:\n        The type of fit to use ['linear', 'sqrt']\n    plot:\n        Whether or not to plot the fitting result\n\n    Returns\n    -------\n    slope:\n        The slope of the fitted piecewise linear threshold function\n    threshold:\n        The threshold of the fitted piecewise linear threshold function\n    \"\"\"\n    x, y = np.array(x), np.array(y)\n    arg = np.where(y > 0.98 * max(y))[0][0]\n    kink_point = x[arg]\n\n    if method == \"linear\":\n        fit_func = piecewise_linear_threshold\n        bounds = []\n\n    elif method == \"sqrt\":\n        fit_func = piecewise_sqrt_threshold\n\n        bounds = [[-np.inf, kink_point - 1, -np.inf], [np.inf, kink_point + 1, np.inf]]\n\n    else:\n        raise FuelCycleError(f\"Fitting method '{method}' not recgonised.\")\n\n    p_opt = curve_fit(fit_func, x, y, bounds=bounds)\n\n    slope = p_opt[0][0]\n    threshold = p_opt[0][-1]\n\n    if plot:\n        y_fit = fit_func(x, *p_opt[0])\n\n        true_integral = np.trapz(y)\n        fit_integral = np.trapz(y_fit)\n\n        f, ax = plt.subplots()\n        ax.set_xlabel(\"Time [years]\")\n        ax.set_ylabel(\"Sequestered tritium [kg]\")\n        ax.set_title(f\"Slope: {slope:.2f}, threshold: {threshold:.2f}\")\n\n        ax.plot(x, y, lw=3, color=\"k\", label=\"Data: $\\\\int$\" + f\"{true_integral:.2f}\")\n        ax.plot(x, y_fit, lw=3, color=\"r\", label=\"Fit: $\\\\int$\" + f\"{fit_integral:.2f}\")\n        ax.legend()\n\n    return p_opt[0]",
  "def delay_decay(t: np.ndarray, m_t_flow: np.ndarray, tt_delay: float) -> np.ndarray:\n    \"\"\"\n    Time-shift a tritium flow with a delay and account for radioactive decay.\n\n    Parameters\n    ----------\n    t:\n        The time vector\n    m_t_flow:\n        The mass flow vector\n    t_delay:\n        The delay duration [s]\n\n    Returns\n    -------\n    The delayed flow vector\n    \"\"\"\n    t_delay = tt_delay * S_TO_YR\n    shift = np.argmin(np.abs(t - t_delay))\n    flow = np.zeros(shift)\n    deldec = np.exp(-T_LAMBDA * t_delay)\n    flow = np.append(flow, deldec * m_t_flow)\n    # TODO: Slight \"loss\" of tritium because of this?\n    flow = flow[: len(t)]  # TODO: figure why you had to do this\n    return flow",
  "def fountain(flow: np.ndarray, t: np.ndarray, min_inventory: float) -> np.ndarray:\n    \"\"\"\n    Fountain tritium block. Needs a minimum T inventory to operate.\n    This is a binary description. In reality, the TFV systems modelled here\n    (such as the cryogenic distillation column) can and do operate below I_min.\n\n    **Inputs:** \\\\n\n      :math:`m_{T_{flow}}` [kg/s]: tritium flow through system [vector] \\\\n\n      :math:`t` [years]: time [vector] \\\\n\n      :math:`I_{min}` [kg]: minimum T inventory for system to operate \\\\n\n    **Outputs:** \\\\n\n      :math:`I` [kg]: built-up T inventory in system [vector]\\\\n\n      :math:`m_{T_{flowout}}` [kg/s]: mass flow out [vector] \\\\n\n    **Calculations** \\\\n\n      :math:`dt = t[i]-t[i-1]` \\\\n\n      :math:`I[i] = I[i-1]e^{-ln(2)dt/t_{1/2}}+m_{T_{flow}}dt` \\\\n\n\n      if :math:`I > I_{min}`:\n        :math:`I[i] = I_{min}` [kg]\\\\n\n        :math:`m_{T_{flowout}} = \\\\frac{I_{min}-I[i]}{dt}` [kg/s] \\\\n\n\n      if :math:`I < I_{min}`:\n        :math:`I[i] = I[i-1]+m_{T_{flow}}dt` [kg] \\\\n\n        :math:`m_{T_{flowout}} = 0` [kg/s]\n    \"\"\"\n    m_out, inventory = np.zeros(len(flow)), np.zeros(len(flow))\n    inventory[0] = min_inventory\n\n    for i, ti in zip(range(1, len(flow)), flow[1:]):\n        dt = t[i] - t[i - 1]\n        dts = dt * YR_TO_S\n        m_in = flow[i] * dts\n        inventory[i] = inventory[i - 1] * np.exp(-T_LAMBDA * dt)\n        overflow = inventory[i] + m_in\n\n        if overflow > min_inventory:\n            m_out[i] = (overflow - min_inventory) / dts\n            inventory[i] = min_inventory\n\n        else:\n            m_out[i] = 0\n            inventory[i] += m_in\n    return m_out, inventory",
  "def _speed_recycle(\n    m_start_up: float, t: np.ndarray, m_in: np.ndarray, m_fuel_injector: np.ndarray\n) -> np.ndarray:\n    \"\"\"\n    The main recycling loop, JIT compiled.\n\n    Parameters\n    ----------\n    m_start_up:\n        An initial guess for the start-up inventory [kg]\n    t:\n        The time vector [years]\n    m_in:\n        The array of tritium flow-rates required for fusion [kg/s]\n    m_fuel_injector:\n        The array of tritium flow-rates fuelling the plasma [kg/s]\n\n    Returns\n    -------\n    The tritium in the stores\n    \"\"\"\n    m_tritium = np.zeros(len(t))\n    m_tritium[0] = m_start_up\n    ts = t * YR_TO_S\n    for i in range(1, len(t)):\n        dt = t[i] - t[i - 1]\n        dts = ts[i] - ts[i - 1]\n        m_tritium[i] = (\n            m_tritium[i - 1] * np.exp(-T_LAMBDA * dt)\n            - (m_in[i] - m_fuel_injector[i]) * dts\n        )\n    return m_tritium",
  "def find_max_load_factor(time_years: np.ndarray, time_fpy: np.ndarray) -> float:\n    \"\"\"\n    Finds peak slope in fpy as a function of calendar years\n    Divides implicitly by slightly less than a year\n\n    Parameters\n    ----------\n    time_years:\n        The time signal [calendar years]\n    time_fpy:\n        The time signal [fpy]\n\n    Returns\n    -------\n    The maximum load factor in the time signal (over a one year period)\n    \"\"\"\n    t, rt = discretise_1d(time_years, time_fpy, int(np.ceil(time_years[-1])))\n    try:\n        a = max([x - x1 for x1, x in zip(rt[:-1], rt[1:])])\n    except ValueError:\n        # Shortened time overflow error (only happens when debugging)\n        a = 1\n    if a > 1 or a < 0:\n        bluemira_warn(f\"Maximum load factor result is non-sensical: {a}.\")\n    else:\n        return a",
  "def legal_limit(\n    max_load_factor: float,\n    fb: float,\n    m_gas: float,\n    eta_f: float,\n    eta_fuel_pump: float,\n    f_dir: float,\n    f_exh_split: float,\n    f_detrit_split: float,\n    f_terscwps: float,\n    TBR: float,\n    mb: Optional[float] = None,\n    p_fus: Optional[float] = None,\n):\n    \"\"\"\n    Calculates the release rate of T from the model TFV cycle in g/yr.\n\n    :math:`A_{max}\\\\Bigg[\\\\Big[\\\\dot{m_{b}}\\\\Big((\\\\frac{1}{f_{b}}-1)+\\\n    (1-{\\\\eta}_{f_{pump}})(1-{\\\\eta}_{f})\\\\frac{1}{f_{b}{\\\\eta}_{f}}\\\\Big)+\\\n        \\\\dot{m_{gas}}\\\\Big](1-f_{DIR})(1-f_{tfv})(1-f_{detrit})+\\\\dot{m_{b}}\\\n        \\\\Lambda f_{TERSCWPS}\\\\Bigg]\\\\times365\\\\times24\\\\times3600`\\n \\n\n    Where:\\n\n    :math:`\\\\dot{m_{b}} = \\\\frac{P_{fus}[MW]M_{T}[g/mol]}\n    {17.58 [MeV]eV[J]N_{A}[1/mol]} [g/s]`\n    \"\"\"\n    if p_fus is None and mb is None:\n        raise FuelCycleError(\"You must specify either fusion power or burn rate.\")\n\n    if p_fus is not None and mb is not None:\n        bluemira_warn(\n            \"Fusion power and burn rate specified... sticking with fusion power.\"\n        )\n        mb = None\n\n    if mb is None:\n        mb = r_T_burn(p_fus)\n\n    m_plasma = (\n        (mb * ((1 / fb - 1) + (1 - eta_fuel_pump) * (1 - eta_f) / (eta_f * fb)) + m_gas)\n        * (1 - f_dir)\n        * (1 - f_exh_split)\n        * (1 - f_detrit_split)\n    )\n    m_bb = mb * TBR * (1 - f_terscwps)\n    ll = max_load_factor * (m_plasma + m_bb)\n    return ll * 365 * 24 * 3600",
  "def _dec_I_mdot(  # noqa :N802\n    inventory: float, eta: float, m_dot: float, t_in: float, t_out: float\n) -> float:\n    \"\"\"\n    Analytical value of series expansion for an inventory I with a incoming\n    flux of tritium (kg/yr).\n\n    \\t:math:`I_{end} = Ie^{-{\\\\lambda}{\\\\Delta}t}+{\\\\eta}\\\\dot{m}\\\\sum_{t=0}^{{\\\\Delta}t}e^{-\\\\lambda(T-t)}`\n\n    \\t:math:`I_{end} = Ie^{-{\\\\lambda}{\\\\Delta}t}+{\\\\eta}\\\\dot{m}\\\\dfrac{e^{-{\\\\lambda}T}\\\\big(e^{{\\\\lambda}({\\\\Delta}t+1/2)}-1\\\\big)}{e^{\\\\lambda}-1}`\n    \"\"\"  # noqa :W505\n    # intuitive hack for 1/2... maths says it should be 1\n    dt = t_out - t_in\n\n    out_inventory = inventory * np.exp(-T_LAMBDA * dt) + eta * m_dot * (\n        np.exp(-T_LAMBDA * dt) * (np.exp(T_LAMBDA * (dt + 0)) - 1)\n    ) / (np.exp(T_LAMBDA) - 1)\n    if out_inventory < 0:\n        raise ValueError(\"The out inventory should not be below 0...\")\n    return out_inventory",
  "def _timestep_decay(flux: float, dt: float) -> float:\n    \"\"\"\n    Analytical value of series expansion for an in-flux of tritium over a time-\n    step. Accounts for decay during the timestep only.\n\n    \\t:math:`I_{end} = I\\\\dfrac{e^{-{\\\\lambda}T}\\\\big(e^{{\\\\lambda}({\\\\Delta}t+1)}-1\\\\big)}{e^{\\\\lambda}-1}`\n\n    Parameters\n    ----------\n    flux:\n        The total inventory flowing through on a given time-step [kg]\n    dt:\n        The time-step [years]\n\n    Returns\n    -------\n    The value of the total inventory which decayed over the time-step.\n    \"\"\"  # noqa :W505\n    return flux * (\n        1\n        - (np.exp(-T_LAMBDA * dt) * (np.exp(T_LAMBDA * (dt + 0)) - 1))\n        / (np.exp(T_LAMBDA) - 1)\n    )",
  "def _find_t15(\n    inventory: float,\n    eta: float,\n    m_flow: float,\n    t_in: float,\n    t_out: float,\n    inventory_limit: float,\n) -> float:\n    \"\"\"\n    Inter-timestep method solving for dt in the below equality:\n\n    :math:`Ie^{\\\\lambda{\\\\Delta}t}+{\\\\eta}\\\\dot{m}\\\\dfrac{e^{-{\\\\lambda}{\\\\Delta}t}\n    \\\\big(e^{{\\\\lambda}({\\\\Delta}t+1/2)}-1\\\\big)}{e^{\\\\lambda}-1}=I_{lim}`\\n\n    :math:`{\\\\Delta}t=\\\\dfrac{ln\\\\bigg(\\\\dfrac{Ie^{\\\\lambda}-I-{\\\\eta}\\\\dot{m}}\n    {I_{lim}e^{{\\\\lambda}}-I_{lim}-{\\\\eta}\\\\dot{m}e^{\\\\lambda/2}}\\\\bigg)}{\\\\lambda}`\n    \\n\n    returns dt relative to t_in of crossing point\n    \"\"\"\n    t = (\n        np.log(\n            (inventory * np.exp(T_LAMBDA) - inventory - eta * m_flow)\n            / (\n                inventory_limit * np.exp(T_LAMBDA)\n                - inventory_limit\n                - eta * m_flow * np.exp(T_LAMBDA / 2)\n            )\n        )\n        / T_LAMBDA\n    )\n    if t > 0.0:  # don't use max for numbagoodness\n        dt = t_out - t_in\n        if t < dt:\n            return t\n        else:\n            t = dt\n            return t\n    else:\n        return 0.0",
  "def _fountain_linear_sink(\n    m_flow: float,\n    t_in: float,\n    t_out: float,\n    inventory: float,\n    fs: float,\n    max_inventory: float,\n    min_inventory: float,\n    sum_in: float,\n    decayed: float,\n) -> Tuple[float, float, float, float]:\n    \"\"\"\n    A simple linear fountain tritium retention sink model between a minimum\n    and a maximum. Used over a time-step.\n\n    Parameters\n    ----------\n    m_flow:\n        The in-flow of tritium [kg/s]\n    t_in:\n        The first point in the time-step [years]\n    t_out:\n        The second point in the time-step [years]\n    inventory:\n        The inventory of tritium already in the sink [kg]\n    fs:\n        The tritium release rate of the sink (1-absorbtion rate)\n    max_inventory:\n        The threshold inventory of the sink at which point it saturates\n    min_inventory:\n        The minimum inventory required for the system to release tritium\n    sum_in:\n        Accountancy parameter to calculate the total value lost to a sink\n    decayed:\n        Accountancy parameter to calculate the total value of decayed T in a sink\n\n    Returns\n    -------\n    m_out:\n        The out-flow of tritium [kg/s]\n    inventory:\n        The amount of tritium in the sink [kg]\n    sum_in:\n        Accountancy parameter to calculate the total value lost to a sink\n    decayed:\n        Accountancy parameter to calculate the total value of decayed T in a sink\n    \"\"\"\n    dt = t_out - t_in\n    if dt == 0:\n        return m_flow, inventory, sum_in, decayed\n\n    m_in = m_flow * YR_TO_S  # kg/yr\n    dts = dt * YR_TO_S\n    mass_in = m_flow * dts\n    sum_in += mass_in\n\n    j_inv0 = inventory\n\n    if inventory <= min_inventory:\n        # Case where fountain is not full\n        i_mdot = _dec_I_mdot(inventory, 1, m_in, t_in, t_out)\n        if i_mdot < min_inventory:\n            # Case where M_in still doesn't fill up\n            m_out = 0.0\n            inventory = i_mdot\n\n        elif i_mdot >= min_inventory:\n            # Case where M_in crosses up into to uncanny valley\n            # (below which eta=1)\n\n            t15 = _find_t15(inventory, 1, m_in, t_in, t_out, min_inventory)\n            i_mdot2 = _dec_I_mdot(min_inventory, 1 - fs, m_in, t_in + t15, t_out)\n            if i_mdot2 <= min_inventory:\n                # Case where infinite unstable oscillations occur in model\n                # Treat reasonably here (you got unlucky) ==> stall\n\n                inventory = min_inventory\n                topup = min_inventory * (1 - np.exp(-T_LAMBDA * (t_out - t_in - t15)))\n                m_out_temp = mass_in - m_in * t15 - topup\n                m_out_temp = max(m_out_temp, 0)\n                m_out = m_out_temp / dts  # spread evenly over timestep\n            elif i_mdot2 >= max_inventory:\n                # Case (unlikely) where massive overshoot occurs\n                # TODO: Handle properly\n                inventory = max_inventory\n                t175 = _find_t15(\n                    min_inventory, 1 - fs, m_in, t_in + t15, t_out, max_inventory\n                )\n                topup = max_inventory * (\n                    1 - np.exp(-T_LAMBDA * (t_out - t_in - t175 - t15))\n                )\n                m_out_temp = mass_in - topup - m_in * t15 - (1 - fs) * m_in * t175\n                m_out_temp = max(m_out_temp, 0)\n                m_out = m_out_temp / dts\n            else:\n                # Case where successfully crosses up\n                dt2 = t_out - t_in - t15\n                inventory = i_mdot2\n                m_out = (mass_in - m_in * t15 - (1 - fs) * m_in * dt2) / dts\n\n    elif inventory <= max_inventory:\n        # Uncanny valley, no man's land\n        i_mdot = _dec_I_mdot(inventory, 1 - fs, m_in, t_in, t_out)\n        if i_mdot < min_inventory:\n            # Case where it crosses from uncanny valley downwards\n            t15 = _find_t15(inventory, 1 - fs, m_in, t_in, t_out, min_inventory)\n            i_mdot2 = _dec_I_mdot(min_inventory, 1, m_in, t_in + t15, t_out)\n            if i_mdot2 < min_inventory:\n                # Case where successfully crosses down\n                dt2 = t_out - t_in - t15\n                inventory = i_mdot2\n\n                m_out = (mass_in - (1 - fs) * m_in * t15 - m_in * dt2) / dts\n            elif i_mdot2 >= min_inventory:\n                # Case where infinite unstable oscillations occur in model\n                # Treat reasonably here (you got unlucky) ==> stall\n\n                inventory = min_inventory\n                topup = min_inventory * (1 - np.exp(-T_LAMBDA * (t_out - t_in - t15)))\n                m_out_temp = mass_in - m_in * t15 - topup\n                if m_out_temp < 0:\n                    m_out_temp = 0\n                m_out = m_out_temp / dts  # spread evenly over timestep\n\n        elif i_mdot >= max_inventory:\n            t15 = _find_t15(inventory, 1 - fs, m_in, t_in, t_out, max_inventory)\n\n            dt2 = t_out - t_in - t15\n            # Case where fountain and bathub are overflowing\n            topup = max_inventory * (1 - np.exp(-T_LAMBDA * dt2))\n            if topup <= mass_in:\n                # Case where I stays constant because of sufficient refill\n\n                m_out = (mass_in - topup) / dts\n                inventory = max_inventory\n            else:\n                # Case where refill insufficient and I depletes\n                i_mdot = _dec_I_mdot(inventory, 1 - fs, m_in, t_in, t_out)\n                m_out = (mass_in - (1 - fs) * m_in * dt2) / dts\n\n                inventory = i_mdot\n        else:\n            # Case where we stay in uncanny valley\n            inventory = i_mdot\n            m_out = (mass_in - (1 - fs) * m_in * dt) / dts\n    else:\n        # inventory > max_inventory\n        raise ValueError(\"Undefined behaviour for inventory > max_inventory.\")\n\n    decayed += j_inv0 - inventory\n\n    if m_out > m_flow:\n        print(m_flow, m_out)\n        raise ValueError(\n            \"Out flow greater than in flow. Check that your timesteps are small enough.\"\n        )\n    if m_out < 0:\n        raise ValueError(\"Negative out flow in fountain_linear_sink.\")\n    if inventory < 0:\n        raise ValueError(\"Negative inventory in fountain_linear_sink.\")\n    return m_out, inventory, sum_in, decayed",
  "def _linear_thresh_sink(\n    m_flow: float,\n    t_in: float,\n    t_out: float,\n    inventory: float,\n    fs: float,\n    max_inventory: float,\n    sum_in: float,\n    decayed: float,\n) -> Tuple[float, float, float, float]:\n    \"\"\"\n    A simple linear tritium retention sink model. Used over a time-step.\n\n    Parameters\n    ----------\n    m_flow:\n        The in-flow of tritium [kg/s]\n    t_in:\n        The first point in the time-step [years]\n    t_out:\n        The second point in the time-step [years]\n    inventory:\n        The inventory of tritium already in the sink [kg]\n    fs:\n        The tritium release rate of the sink (1-absorbtion rate)\n    max_inventory:\n        The threshold inventory of the sink at which point it saturates\n    sum_in:\n        Accountancy parameter to calculate the total value lost to a sink\n    decayed:\n        Accountancy parameter to calculate the total value of decayed T in a sink\n\n    Returns\n    -------\n    m_out:\n        The out-flow of tritium [kg/s]\n    inventory:\n        The amount of tritium in the sink [kg]\n    sum_in:\n        Accountancy parameter to calculate the total value lost to a sink\n    decayed:\n        Accountancy parameter to calculate the total value of decayed T in a sink\n    \"\"\"\n    years = 365 * 24 * 3600\n    dt = t_out - t_in\n    if dt == 0:\n        return m_flow, inventory, sum_in, decayed\n\n    m_in = m_flow * years  # kg/yr\n    dts = dt * years\n    mass_in = m_flow * dts\n    sum_in += mass_in\n    j_inv0 = inventory\n\n    i_mdot = _dec_I_mdot(inventory, 1 - fs, m_in, t_in, t_out)\n    if i_mdot >= max_inventory:\n        t15 = _find_t15(inventory, 1 - fs, m_in, t_in, t_out, max_inventory)\n        dt2 = t_out - t_in - t15\n        # Case where fountain and bathub are overflowing\n        topup = max_inventory * (1 - np.exp(-T_LAMBDA * dt2))\n        if topup <= mass_in:\n            # Case where I stays constant because of sufficient refill\n            m_out = (mass_in - topup) / dts\n\n            inventory = max_inventory\n        else:\n            # Case where refill insufficient and I depletes\n            i_mdot = _dec_I_mdot(inventory, 1 - fs, m_in, t_in, t_out)\n            m_out = (mass_in - (1 - fs) * m_in * dt2) / dts\n            inventory = i_mdot\n    else:\n        inventory = i_mdot\n        m_out = fs * m_flow\n\n    decayed += j_inv0 - inventory\n    return m_out, inventory, sum_in, decayed",
  "def _sqrt_thresh_sink(\n    m_flow: float,\n    t_in: float,\n    t_out: float,\n    inventory: float,\n    factor: float,\n    max_inventory: float,\n    sum_in: float,\n    decayed: float,\n    _testing: bool,\n) -> Tuple[float, float, float, float]:\n    \"\"\"\n    A simple sqrt tritium retention sink model. Used over a time-step.\n\n    Parameters\n    ----------\n    m_flow:\n        The in-flow of tritium [kg/s]\n    t_in:\n        The first point in the time-step [years]\n    t_out:\n        The second point in the time-step [years]\n    inventory:\n        The inventory of tritium already in the sink [kg]\n    factor:\n        The multiplication factor of the sqrt function\n    max_inventory:\n        The threshold inventory of the sink at which point it saturates\n    sum_in:\n        Accountancy parameter to calculate the total value lost to a sink\n    decayed:\n        Accountancy parameter to calculate the total value of decayed T in a sink\n\n    Returns\n    -------\n    m_out:\n        The out-flow of tritium [kg/s]\n    inventory:\n        The amount of tritium in the sink [kg]\n    sum_in:\n        Accountancy parameter to calculate the total value lost to a sink\n    decayed:\n        Accountancy parameter to calculate the total value of decayed T in a sink\n\n    Notes\n    -----\n    \\t:math:`I_{sequestered} = factor \\\\times \\\\sqrt{ t_{fpy}}`\n\n    The time in the equation is sub-planted for the inventory, to make the\n    retention model independent of time.\n\n    The values for the threshold and factor must be obtained from detailed T\n    retention modelling.\n\n    Here, we're tacking the growth of the inventory to a function, but decay is\n    not accounted for in this function. We have to add decay in the sink and\n    ensure this is handled when calculation the absorbtion and out-flow.\n    \"\"\"\n    years = 365 * 24 * 3600\n    dt = t_out - t_in\n    if dt == 0:\n        # Nothing can happen if time is zero\n        return m_flow, inventory, sum_in, decayed\n\n    dts = dt * years\n    mass_in = m_flow * dts\n    sum_in += mass_in\n\n    decay = inventory * (1 - np.exp(-T_LAMBDA * dt))\n\n    if mass_in == 0:\n        # Inventory decays, nothing else happens\n        new_inventory = inventory - decay\n        # If the in mass is 0, so must be the out-flow\n        return 0.0, new_inventory, sum_in, decayed\n\n    if inventory >= max_inventory:\n        # Sqrt bathtub is over-flowing\n        inventory -= decay\n        # Determine the equivalent time for a given inventory level\n        x = (inventory / factor) ** 2\n        new_inventory = factor * np.sqrt(x + dt)\n        absorbed = new_inventory - inventory\n        absorbed_decay = _timestep_decay(absorbed, dt)\n        absorbed += absorbed_decay\n        if absorbed > decay:\n            # Case where the absorbtion is greater than the decay loss\n            new_inventory = max_inventory\n\n            # Only absorb the decayed amount and top-up the sink to its limit\n            fraction = decay / mass_in\n            m_out = (1 - fraction) * m_flow\n        else:\n            # Case where there is decay which is not compensated by absorbtion\n            new_inventory += absorbed\n            new_inventory -= decay\n            fraction = absorbed / mass_in\n            m_out = (1 - fraction) * m_flow\n\n    else:\n        # Sqrt bathtub is not yet full..\n        # Determine the equivalent time for a given inventory level\n        x = (inventory / factor) ** 2\n\n        # This is equivalent to determining the gradient, but stabler\n        new_inventory = factor * np.sqrt(x + dt)\n        absorbed = new_inventory - inventory\n\n        absorbed_decay = _timestep_decay(absorbed, dt)\n\n        # Sum all the absolute loss terms and modify the out-flow\n        delta_inv = absorbed + absorbed_decay\n        fraction = delta_inv / mass_in\n        m_out = (1 - fraction) * m_flow\n        if not _testing:\n            new_inventory -= decay\n\n    return m_out, new_inventory, sum_in, decayed",
  "def linear_bathtub(\n    flow: np.ndarray, t: np.ndarray, eta: float, bci: int, max_inventory: float\n) -> Tuple[np.ndarray, np.ndarray, float, float]:\n    \"\"\"\n    Bathtub sink model.\n\n    Parameters\n    ----------\n    flow:\n        The vector of flow-rates [kg/s]\n    t:\n        The time vector [years]\n    eta:\n        The bathtub tritium release fraction\n    bci:\n        The blanket change index. Used if a component is replaced to reset the\n        inventory to 0.\n    max_inventory:\n        The threshold inventory for the bathtub.\n\n    Returns\n    -------\n    m_out:\n        The out-flow of tritium [kg/s]\n    inventory:\n        The amount of tritium in the sink [kg]\n    sum_in:\n        Accountancy parameter to calculate the total value lost to a sink\n    decayed:\n        Accountancy parameter to calculate the total value of decayed T in a sink\n    \"\"\"\n    decayed, sum_in = 0, 0\n    if bci is None:\n        bci = -1  # Numba typing fix\n    m_out, inventory = np.zeros(len(flow)), np.zeros(len(flow))\n    for i, mflow in enumerate(flow[:-1]):\n        m_out[i], inventory[i], sum_in, decayed = _linear_thresh_sink(\n            mflow, t[i], t[i + 1], inventory[i - 1], eta, max_inventory, sum_in, decayed\n        )\n        if i == bci or i < 1:\n            # Dump stored inventory on component change.\n            inventory[i] = 0\n    return m_out, inventory, sum_in, decayed",
  "def sqrt_bathtub(\n    flow: np.ndarray,\n    t: np.ndarray,\n    factor: float,\n    bci: int,\n    max_inventory: float,\n    _testing: bool = False,\n) -> Tuple[np.ndarray, np.ndarray, float, float]:\n    \"\"\"\n    Bathtub sink model with a sqrt inventory retention law.\n\n    Parameters\n    ----------\n    flow:\n        The vector of flow-rates [kg/s]\n    bci:\n        The blanket change index. Used if a component is replaced to reset the\n        inventory to 0.\n    t:\n        The time vector [years]\n    factor:\n        The sqrt model multiplication factor\n    max_inventory:\n        The threshold inventory for the bathtub.\n    _testing:\n        Used for testing purposes only (switches off decay).\n\n    Returns\n    -------\n    m_out:\n        The out-flow of tritium [kg/s]\n    inventory:\n        The amount of tritium in the sink [kg]\n    sum_in:\n        Accountancy parameter to calculate the total value lost to a sink\n    decayed:\n        Accountancy parameter to calculate the total value of decayed T in a sink\n    \"\"\"\n    decayed, sum_in = 0, 0\n    if bci is None:\n        bci = -1  # Numba typing fix\n    m_out, inventory = np.zeros(len(flow)), np.zeros(len(flow))\n\n    for i, mflow in enumerate(flow[:-1]):\n        m_out[i], inventory[i], sum_in, decayed = _sqrt_thresh_sink(\n            mflow,\n            t[i],\n            t[i + 1],\n            inventory[i - 1],\n            factor,\n            max_inventory,\n            sum_in,\n            decayed,\n            _testing,\n        )\n        if i == bci or i < 1:\n            # Dump stored inventory on component change.\n            inventory[i] = 0\n    return m_out, inventory, sum_in, decayed",
  "def fountain_bathtub(\n    flow: np.ndarray,\n    t: np.ndarray,\n    fs: float,\n    max_inventory: float,\n    min_inventory: float,\n) -> Tuple[np.ndarray, np.ndarray, float, float]:\n    \"\"\"\n    A fountain and bathtub sink simultaneously.\n\n    Parameters\n    ----------\n    flow:\n        Tritium flow through system [kg/s]\n    t:\n        Time [years]\n    fs:\n        efficiency of bathtub\n    min_inventory:\n        Minimum T inventory for system to operate [kg]\n    max_inventory:\n        Maximum T inventory for system to operate [kg]\n\n    Returns\n    -------\n    m_out:\n        The out-flow of tritium [kg/s]\n    inventory:\n        The amount of tritium in the sink [kg]\n    sum_in:\n        Accountancy parameter to calculate the total value lost to a sink\n    decayed:\n        Accountancy parameter to calculate the total value of decayed T in a sink\n\n    \\t:math:`dt = t[i]-t[i-1]` \\n\n    \\t:math:`I[i] = I[i-1]e^{-ln(2)dt/t_{1/2}}` \\n\n    \\tif :math:`I < I_{min}`:\n    \\t\\t:math:`I[i] += m_{T_{flow}}dt`\\n\n    \\t\\t:math:`m_{T_{flowout}} = 0` \\n\n    \\tif :math:`I >= I_{max}`:\n    \\t\\t:math:`I[i] = I_{max}` \\n\n    \\t\\t:math:`m_{T_{flowout}} = m_{T_{flow}}` \\n\n    \\tif :math:`I < I_{max}`:\n    \\t\\t:math:`m_{T_{flowout}} = {\\\\eta}m_{T_{flow}}`\\n\n    \\t\\t:math:`I += (1-{\\\\eta})m_{T_{flow}}dt`\n    \"\"\"\n    decayed, sum_in = 0, 0\n    m_out, inventory = np.zeros(len(flow)), np.zeros(len(flow))\n    for i, mflow in enumerate(flow[:-1]):\n        m_out[i], inventory[i], sum_in, decayed = _fountain_linear_sink(\n            mflow,\n            t[i],\n            t[i + 1],\n            inventory[i - 1],\n            fs,\n            max_inventory,\n            min_inventory,\n            sum_in,\n            decayed,\n        )\n        if i < 1:\n            inventory[i], m_out[i] = min_inventory, 0\n\n    return m_out, inventory, sum_in, decayed",
  "class ChargedParticleSolver:\n    \"\"\"\n    A simplified charged particle transport model along open field lines.\n\n    Parameters\n    ----------\n    config: Dict[str, float]\n        The parameters for running the transport model. See\n        :class:`ChargedParticleSolverParams` for available parameters\n        and their defaults.\n    equilibrium: Equilibrium\n        The equilibrium defining flux surfaces.\n    dx_mp: float (optional)\n        The midplane spatial resolution between flux surfaces [m]\n        (default: 0.001).\n    \"\"\"\n\n    def __init__(self, config: Dict[str, float], equilibrium, dx_mp: float = 0.001):\n        self.eq = equilibrium\n        self.params = self._make_params(config)\n        self._check_params()\n        self.dx_mp = dx_mp\n\n        # Constructors\n        self.first_wall = None\n        self.flux_surfaces_ob_lfs = None\n        self.flux_surfaces_ob_hfs = None\n        self.flux_surfaces_ib_lfs = None\n        self.flux_surfaces_ib_hfs = None\n        self.x_sep_omp = None\n        self.x_sep_imp = None\n        self.result = None\n\n        # Pre-processing\n        o_points, _ = self.eq.get_OX_points()\n        self._o_point = o_points[0]\n        z = self._o_point.z\n        self._yz_plane = BluemiraPlane.from_3_points([0, 0, z], [1, 0, z], [1, 1, z])\n\n    @property\n    def flux_surfaces(self):\n        \"\"\"\n        All flux surfaces in the ChargedParticleSolver.\n\n        Returns\n        -------\n        flux_surfaces: List[PartialOpenFluxSurface]\n        \"\"\"\n        flux_surfaces = []\n        for group in [\n            self.flux_surfaces_ob_lfs,\n            self.flux_surfaces_ob_hfs,\n            self.flux_surfaces_ib_lfs,\n            self.flux_surfaces_ib_hfs,\n        ]:\n            if group:\n                flux_surfaces.extend(group)\n        return flux_surfaces\n\n    def _check_params(self):\n        \"\"\"\n        Check input fractions for validity.\n        \"\"\"\n        # Check lower power fractions\n        lower_power = self.params.f_lfs_lower_target + self.params.f_hfs_lower_target\n        upper_power = self.params.f_lfs_upper_target + self.params.f_hfs_upper_target\n        power_sum = lower_power + upper_power\n\n        if not np.isclose(power_sum, 1.0, rtol=EPS, atol=1e-9):\n            raise AdvectionTransportError(\n                f\"Total power fractions should sum to 1, not : {power_sum}\"\n            )\n\n        zero_in_one_direction = np.any(\n            np.isclose([lower_power, upper_power], 0, rtol=EPS, atol=1e-9)\n        )\n        if self.eq.is_double_null and zero_in_one_direction:\n            bluemira_warn(\n                \"A DN equilibrium was detected but your power distribution\"\n                \" is 0 in either the lower or upper directions.\"\n            )\n        elif not self.eq.is_double_null and not zero_in_one_direction:\n            bluemira_warn(\n                \"A SN equilibrium was detected but you power distribution is not 0\"\n                \" in either the lower or upper directions.\"\n            )\n\n    @staticmethod\n    def _process_first_wall(first_wall):\n        \"\"\"\n        Force working first wall geometry to be closed and counter-clockwise.\n        \"\"\"\n        first_wall = deepcopy(first_wall)\n\n        if not first_wall.check_ccw(axis=[0, 1, 0]):\n            bluemira_warn(\n                \"First wall should be oriented counter-clockwise. Reversing it.\"\n            )\n            first_wall.reverse()\n\n        if not first_wall.closed:\n            bluemira_warn(\"First wall should be a closed geometry. Closing it.\")\n            first_wall.close()\n        return first_wall\n\n    @staticmethod\n    def _get_arrays(flux_surfaces):\n        \"\"\"\n        Get arrays of flux surface values.\n        \"\"\"\n        x_mp = np.array([fs.x_start for fs in flux_surfaces])\n        z_mp = np.array([fs.z_start for fs in flux_surfaces])\n        x_fw = np.array([fs.x_end for fs in flux_surfaces])\n        z_fw = np.array([fs.z_end for fs in flux_surfaces])\n        alpha = np.array([fs.alpha for fs in flux_surfaces])\n        return x_mp, z_mp, x_fw, z_fw, alpha\n\n    def _get_sep_out_intersection(self, outboard=True):\n        \"\"\"\n        Find the middle and maximum outboard mid-plane psi norm values\n        \"\"\"\n        yz_plane = self._yz_plane\n        o_point = self._o_point\n        separatrix = self.eq.get_separatrix()\n\n        if not isinstance(separatrix, Coordinates):\n            sep1_intersections = coords_plane_intersect(separatrix[0], yz_plane)\n            sep2_intersections = coords_plane_intersect(separatrix[1], yz_plane)\n            sep1_arg = np.argmin(np.abs(sep1_intersections.T[0] - o_point.x))\n            sep2_arg = np.argmin(np.abs(sep2_intersections.T[0] - o_point.x))\n            x_sep1_mp = sep1_intersections.T[0][sep1_arg]\n            x_sep2_mp = sep2_intersections.T[0][sep2_arg]\n            if outboard:\n                x_sep_mp = x_sep1_mp if x_sep1_mp > x_sep2_mp else x_sep2_mp\n            else:\n                x_sep_mp = x_sep1_mp if x_sep1_mp < x_sep2_mp else x_sep2_mp\n        else:\n            sep_intersections = coords_plane_intersect(separatrix, yz_plane)\n            sep_arg = np.argmin(np.abs(sep_intersections.T[0] - o_point.x))\n            x_sep_mp = sep_intersections.T[0][sep_arg]\n\n        out_intersections = coords_plane_intersect(self.first_wall, yz_plane)\n        if outboard:\n            x_out_mp = np.max(out_intersections.T[0])\n        else:\n            x_out_mp = np.min(out_intersections.T[0])\n\n        return x_sep_mp, x_out_mp\n\n    def _make_flux_surfaces(self, x, z):\n        \"\"\"\n        Make individual PartialOpenFluxSurfaces through a point.\n        \"\"\"\n        coords = find_flux_surface_through_point(\n            self.eq.x, self.eq.z, self.eq.psi(), x, z, self.eq.psi(x, z)\n        )\n        coords = Coordinates({\"x\": coords[0], \"z\": coords[1]})\n        f_s = OpenFluxSurface(coords)\n        lfs, hfs = f_s.split(self._o_point, plane=self._yz_plane)\n        return lfs, hfs\n\n    def _make_flux_surfaces_ob(self):\n        \"\"\"\n        Make the flux surfaces on the outboard.\n        \"\"\"\n        self.x_sep_omp, x_out_omp = self._get_sep_out_intersection(outboard=True)\n\n        self.flux_surfaces_ob_lfs = []\n        self.flux_surfaces_ob_hfs = []\n\n        x = self.x_sep_omp + self.dx_mp\n        while x < x_out_omp - EPS:\n            lfs, hfs = self._make_flux_surfaces(x, self._o_point.z)\n            self.flux_surfaces_ob_lfs.append(lfs)\n            self.flux_surfaces_ob_hfs.append(hfs)\n            x += self.dx_mp\n\n    def _make_flux_surfaces_ib(self):\n        \"\"\"\n        Make the flux surfaces on the inboard.\n        \"\"\"\n        self.x_sep_imp, x_out_imp = self._get_sep_out_intersection(outboard=False)\n\n        self.flux_surfaces_ib_lfs = []\n        self.flux_surfaces_ib_hfs = []\n        x = self.x_sep_imp - self.dx_mp\n        while x > x_out_imp + EPS:\n            lfs, hfs = self._make_flux_surfaces(x, self._o_point.z)\n            self.flux_surfaces_ib_lfs.append(lfs)\n            self.flux_surfaces_ib_hfs.append(hfs)\n            x -= self.dx_mp\n\n    def _clip_flux_surfaces(self, first_wall):\n        \"\"\"\n        Clip the flux surfaces to a first wall. Catch the cases where no intersections\n        are found.\n        \"\"\"\n        for group in [\n            self.flux_surfaces_ob_lfs,\n            self.flux_surfaces_ob_hfs,\n            self.flux_surfaces_ib_lfs,\n            self.flux_surfaces_ib_hfs,\n        ]:\n            if group:\n                for i, flux_surface in enumerate(group):\n                    flux_surface.clip(first_wall)\n                    if flux_surface.alpha is None:\n                        # No intersection detected between flux surface and first wall\n                        # Drop the flux surface from the group\n                        group.pop(i)\n\n    def analyse(self, first_wall):\n        \"\"\"\n        Perform the calculation to obtain charged particle heat fluxes on the\n        the specified first_wall\n\n        Parameters\n        ----------\n        first_wall: Coordinates\n            The closed first wall geometry on which to calculate the heat flux\n\n        Returns\n        -------\n        x: np.array\n            The x coordinates of the flux surface intersections\n        z: np.array\n            The z coordinates of the flux surface intersections\n        heat_flux: np.array\n            The perpendicular heat fluxes at the intersection points [MW/m^2]\n        \"\"\"\n        self.first_wall = self._process_first_wall(first_wall)\n\n        if self.eq.is_double_null:\n            x, z, hf = self._analyse_DN(first_wall)\n        else:\n            x, z, hf = self._analyse_SN(first_wall)\n\n        self.result = x, z, hf\n        return x, z, hf\n\n    def _analyse_SN(self, first_wall):\n        \"\"\"\n        Calculation for the case of single nulls.\n        \"\"\"\n        self._make_flux_surfaces_ob()\n\n        # Find the intersections of the flux surfaces with the first wall\n        self._clip_flux_surfaces(first_wall)\n\n        x_omp, z_omp, x_lfs_inter, z_lfs_inter, alpha_lfs = self._get_arrays(\n            self.flux_surfaces_ob_lfs\n        )\n        _, _, x_hfs_inter, z_hfs_inter, alpha_hfs = self._get_arrays(\n            self.flux_surfaces_ob_hfs\n        )\n\n        # Calculate values at OMP\n        dx_omp = x_omp - self.x_sep_omp\n        Bp_omp = self.eq.Bp(x_omp, z_omp)\n        Bt_omp = self.eq.Bt(x_omp)\n        B_omp = np.hypot(Bp_omp, Bt_omp)\n\n        # Parallel power at the outboard midplane\n        q_par_omp = self._q_par(x_omp, dx_omp, B_omp, Bp_omp)\n\n        # Calculate values at intersections\n        Bp_lfs = self.eq.Bp(x_lfs_inter, z_lfs_inter)\n        Bp_hfs = self.eq.Bp(x_hfs_inter, z_hfs_inter)\n\n        # Calculate parallel power at the intersections\n        # Note that flux expansion terms cancel down to this\n        q_par_lfs = q_par_omp * Bp_lfs / B_omp\n        q_par_hfs = q_par_omp * Bp_hfs / B_omp\n\n        # Calculate perpendicular heat fluxes\n        heat_flux_lfs = self.params.f_lfs_lower_target * q_par_lfs * np.sin(alpha_lfs)\n        heat_flux_hfs = self.params.f_hfs_lower_target * q_par_hfs * np.sin(alpha_hfs)\n\n        # Correct power (energy conservation)\n        q_omp_int = 2 * np.pi * np.sum(q_par_omp / (B_omp / Bp_omp) * self.dx_mp * x_omp)\n        f_correct_power = self.params.P_sep_particle / q_omp_int\n        return (\n            np.append(x_lfs_inter, x_hfs_inter),\n            np.append(z_lfs_inter, z_hfs_inter),\n            f_correct_power * np.append(heat_flux_lfs, heat_flux_hfs),\n        )\n\n    def _analyse_DN(self, first_wall):\n        \"\"\"\n        Calculation for the case of double nulls.\n        \"\"\"\n        self._make_flux_surfaces_ob()\n        self._make_flux_surfaces_ib()\n\n        # Find the intersections of the flux surfaces with the first wall\n        self._clip_flux_surfaces(first_wall)\n\n        (\n            x_omp,\n            z_omp,\n            x_lfs_down_inter,\n            z_lfs_down_inter,\n            alpha_lfs_down,\n        ) = self._get_arrays(self.flux_surfaces_ob_lfs)\n        _, _, x_lfs_up_inter, z_lfs_up_inter, alpha_lfs_up = self._get_arrays(\n            self.flux_surfaces_ob_hfs\n        )\n        (\n            x_imp,\n            z_imp,\n            x_hfs_down_inter,\n            z_hfs_down_inter,\n            alpha_hfs_down,\n        ) = self._get_arrays(self.flux_surfaces_ib_lfs)\n        _, _, x_hfs_up_inter, z_hfs_up_inter, alpha_hfs_up = self._get_arrays(\n            self.flux_surfaces_ib_hfs\n        )\n\n        # Calculate values at OMP\n        dx_omp = x_omp - self.x_sep_omp\n        Bp_omp = self.eq.Bp(x_omp, z_omp)\n        Bt_omp = self.eq.Bt(x_omp)\n        B_omp = np.hypot(Bp_omp, Bt_omp)\n\n        # Calculate values at IMP\n        dx_imp = abs(x_imp - self.x_sep_imp)\n        Bp_imp = self.eq.Bp(x_imp, z_imp)\n        Bt_imp = self.eq.Bt(x_imp)\n        B_imp = np.hypot(Bp_imp, Bt_imp)\n\n        # Parallel power at the outboard and inboard midplane\n        q_par_omp = self._q_par(x_omp, dx_omp, B_omp, Bp_omp)\n        q_par_imp = self._q_par(x_imp, dx_imp, B_imp, Bp_imp, outboard=False)\n\n        # Calculate poloidal field at intersections\n        Bp_lfs_down = self.eq.Bp(x_lfs_down_inter, z_lfs_down_inter)\n        Bp_lfs_up = self.eq.Bp(x_lfs_up_inter, z_lfs_up_inter)\n        Bp_hfs_down = self.eq.Bp(x_hfs_down_inter, z_hfs_down_inter)\n        Bp_hfs_up = self.eq.Bp(x_hfs_up_inter, z_hfs_up_inter)\n\n        # Calculate parallel power at the intersections\n        # Note that flux expansion terms cancel down to this\n        q_par_lfs_down = q_par_omp * Bp_lfs_down / B_omp\n        q_par_lfs_up = q_par_omp * Bp_lfs_up / B_omp\n        q_par_hfs_down = q_par_imp * Bp_hfs_down / B_imp\n        q_par_hfs_up = q_par_imp * Bp_hfs_up / B_imp\n\n        # Calculate perpendicular heat fluxes\n        heat_flux_lfs_down = (\n            self.params.f_lfs_lower_target * q_par_lfs_down * np.sin(alpha_lfs_down)\n        )\n        heat_flux_lfs_up = (\n            self.params.f_lfs_upper_target * q_par_lfs_up * np.sin(alpha_lfs_up)\n        )\n        heat_flux_hfs_down = (\n            self.params.f_hfs_lower_target * q_par_hfs_down * np.sin(alpha_hfs_down)\n        )\n        heat_flux_hfs_up = (\n            self.params.f_hfs_upper_target * q_par_hfs_up * np.sin(alpha_hfs_up)\n        )\n\n        # Correct power (energy conservation)\n        q_omp_int = 2 * np.pi * np.sum(q_par_omp * Bp_omp / B_omp * self.dx_mp * x_omp)\n        q_imp_int = 2 * np.pi * np.sum(q_par_imp * Bp_imp / B_imp * self.dx_mp * x_imp)\n\n        total_power = self.params.P_sep_particle\n        f_outboard = self.params.f_lfs_lower_target + self.params.f_lfs_upper_target\n        f_inboard = self.params.f_hfs_lower_target + self.params.f_hfs_upper_target\n        f_correct_lfs_down = (\n            total_power * self.params.f_lfs_lower_target / f_outboard\n        ) / q_omp_int\n        f_correct_lfs_up = (\n            total_power * self.params.f_lfs_upper_target / f_outboard\n        ) / q_omp_int\n        f_correct_hfs_down = (\n            total_power * self.params.f_hfs_lower_target / f_inboard\n        ) / q_imp_int\n        f_correct_hfs_up = (\n            total_power * self.params.f_hfs_upper_target / f_inboard\n        ) / q_imp_int\n\n        return (\n            np.concatenate(\n                [x_lfs_down_inter, x_lfs_up_inter, x_hfs_down_inter, x_hfs_up_inter]\n            ),\n            np.concatenate(\n                [z_lfs_down_inter, z_lfs_up_inter, z_hfs_down_inter, z_hfs_up_inter]\n            ),\n            np.concatenate(\n                [\n                    f_correct_lfs_down * heat_flux_lfs_down,\n                    f_correct_lfs_up * heat_flux_lfs_up,\n                    f_correct_hfs_down * heat_flux_hfs_down,\n                    f_correct_hfs_up * heat_flux_hfs_up,\n                ]\n            ),\n        )\n\n    def _q_par(self, x, dx, B, Bp, outboard=True):\n        \"\"\"\n        Calculate the parallel power at the midplane.\n        \"\"\"\n        p_sol_near = self.params.P_sep_particle * self.params.f_p_sol_near\n        p_sol_far = self.params.P_sep_particle * (1 - self.params.f_p_sol_near)\n        if outboard:\n            lq_near = self.params.fw_lambda_q_near_omp\n            lq_far = self.params.fw_lambda_q_far_omp\n        else:\n            lq_near = self.params.fw_lambda_q_near_imp\n            lq_far = self.params.fw_lambda_q_far_imp\n        return (\n            (\n                p_sol_near * np.exp(-dx / lq_near) / lq_near\n                + p_sol_far * np.exp(-dx / lq_far) / lq_far\n            )\n            * B\n            / (Bp * 2 * np.pi * x)\n        )\n\n    def plot(self, ax: Axes = None, show=False):\n        \"\"\"\n        Plot the ChargedParticleSolver results.\n        \"\"\"\n        if ax is None:\n            _, ax = plt.subplots()\n\n        plot_coordinates(self.first_wall, ax=ax, linewidth=0.5, fill=False)\n        separatrix = self.eq.get_separatrix()\n\n        if isinstance(separatrix, Coordinates):\n            separatrix = [separatrix]\n\n        for sep in separatrix:\n            plot_coordinates(sep, ax=ax, linewidth=0.2)\n\n        for f_s in self.flux_surfaces:\n            plot_coordinates(f_s.coords, ax=ax, linewidth=0.01)\n\n        cm = ax.scatter(\n            self.result[0],\n            self.result[1],\n            c=self.result[2],\n            s=10,\n            zorder=40,\n            cmap=\"plasma\",\n        )\n        f = ax.figure\n        f.colorbar(cm, label=\"MW/m\u00b2\")\n        if show:\n            plt.show()\n        return ax\n\n    def _make_params(self, config):\n        \"\"\"Convert the given params to ``ChargedParticleSolverParams``\"\"\"\n        if isinstance(config, dict):\n            try:\n                return ChargedParticleSolverParams(**config)\n            except TypeError:\n                unknown = [\n                    k for k in config if k not in fields(ChargedParticleSolverParams)\n                ]\n                raise TypeError(f\"Unknown config parameter(s) {str(unknown)[1:-1]}\")\n        elif isinstance(config, ChargedParticleSolverParams):\n            return config\n        else:\n            raise TypeError(\n                \"Unsupported type: 'config' must be a 'dict', or \"\n                \"'ChargedParticleSolverParams' instance; found \"\n                f\"'{type(config).__name__}'.\"\n            )",
  "class ChargedParticleSolverParams:\n    P_sep_particle: float = 150\n    \"\"\"Separatrix power [MW].\"\"\"\n\n    f_p_sol_near: float = 0.5\n    \"\"\"Near scrape-off layer power rate [dimensionless].\"\"\"\n\n    fw_lambda_q_near_omp: float = 0.003\n    \"\"\"Lambda q near SOL at the outboard [m].\"\"\"\n\n    fw_lambda_q_far_omp: float = 0.05\n    \"\"\"Lambda q far SOL at the outboard [m].\"\"\"\n\n    fw_lambda_q_near_imp: float = 0.003\n    \"\"\"Lambda q near SOL at the inboard [m].\"\"\"\n\n    fw_lambda_q_far_imp: float = 0.05\n    \"\"\"Lambda q far SOL at the inboard [m].\"\"\"\n\n    f_lfs_lower_target: float = 0.9\n    \"\"\"Fraction of SOL power deposited on the LFS lower target [dimensionless].\"\"\"\n\n    f_hfs_lower_target: float = 0.1\n    \"\"\"Fraction of SOL power deposited on the HFS lower target [dimensionless].\"\"\"\n\n    f_lfs_upper_target: float = 0\n    \"\"\"\n    Fraction of SOL power deposited on the LFS upper target (DN only)\n    [dimensionless].\n    \"\"\"\n\n    f_hfs_upper_target: float = 0\n    \"\"\"\n    Fraction of SOL power deposited on the HFS upper target (DN only)\n    [dimensionless].\n    \"\"\"",
  "def __init__(self, config: Dict[str, float], equilibrium, dx_mp: float = 0.001):\n        self.eq = equilibrium\n        self.params = self._make_params(config)\n        self._check_params()\n        self.dx_mp = dx_mp\n\n        # Constructors\n        self.first_wall = None\n        self.flux_surfaces_ob_lfs = None\n        self.flux_surfaces_ob_hfs = None\n        self.flux_surfaces_ib_lfs = None\n        self.flux_surfaces_ib_hfs = None\n        self.x_sep_omp = None\n        self.x_sep_imp = None\n        self.result = None\n\n        # Pre-processing\n        o_points, _ = self.eq.get_OX_points()\n        self._o_point = o_points[0]\n        z = self._o_point.z\n        self._yz_plane = BluemiraPlane.from_3_points([0, 0, z], [1, 0, z], [1, 1, z])",
  "def flux_surfaces(self):\n        \"\"\"\n        All flux surfaces in the ChargedParticleSolver.\n\n        Returns\n        -------\n        flux_surfaces: List[PartialOpenFluxSurface]\n        \"\"\"\n        flux_surfaces = []\n        for group in [\n            self.flux_surfaces_ob_lfs,\n            self.flux_surfaces_ob_hfs,\n            self.flux_surfaces_ib_lfs,\n            self.flux_surfaces_ib_hfs,\n        ]:\n            if group:\n                flux_surfaces.extend(group)\n        return flux_surfaces",
  "def _check_params(self):\n        \"\"\"\n        Check input fractions for validity.\n        \"\"\"\n        # Check lower power fractions\n        lower_power = self.params.f_lfs_lower_target + self.params.f_hfs_lower_target\n        upper_power = self.params.f_lfs_upper_target + self.params.f_hfs_upper_target\n        power_sum = lower_power + upper_power\n\n        if not np.isclose(power_sum, 1.0, rtol=EPS, atol=1e-9):\n            raise AdvectionTransportError(\n                f\"Total power fractions should sum to 1, not : {power_sum}\"\n            )\n\n        zero_in_one_direction = np.any(\n            np.isclose([lower_power, upper_power], 0, rtol=EPS, atol=1e-9)\n        )\n        if self.eq.is_double_null and zero_in_one_direction:\n            bluemira_warn(\n                \"A DN equilibrium was detected but your power distribution\"\n                \" is 0 in either the lower or upper directions.\"\n            )\n        elif not self.eq.is_double_null and not zero_in_one_direction:\n            bluemira_warn(\n                \"A SN equilibrium was detected but you power distribution is not 0\"\n                \" in either the lower or upper directions.\"\n            )",
  "def _process_first_wall(first_wall):\n        \"\"\"\n        Force working first wall geometry to be closed and counter-clockwise.\n        \"\"\"\n        first_wall = deepcopy(first_wall)\n\n        if not first_wall.check_ccw(axis=[0, 1, 0]):\n            bluemira_warn(\n                \"First wall should be oriented counter-clockwise. Reversing it.\"\n            )\n            first_wall.reverse()\n\n        if not first_wall.closed:\n            bluemira_warn(\"First wall should be a closed geometry. Closing it.\")\n            first_wall.close()\n        return first_wall",
  "def _get_arrays(flux_surfaces):\n        \"\"\"\n        Get arrays of flux surface values.\n        \"\"\"\n        x_mp = np.array([fs.x_start for fs in flux_surfaces])\n        z_mp = np.array([fs.z_start for fs in flux_surfaces])\n        x_fw = np.array([fs.x_end for fs in flux_surfaces])\n        z_fw = np.array([fs.z_end for fs in flux_surfaces])\n        alpha = np.array([fs.alpha for fs in flux_surfaces])\n        return x_mp, z_mp, x_fw, z_fw, alpha",
  "def _get_sep_out_intersection(self, outboard=True):\n        \"\"\"\n        Find the middle and maximum outboard mid-plane psi norm values\n        \"\"\"\n        yz_plane = self._yz_plane\n        o_point = self._o_point\n        separatrix = self.eq.get_separatrix()\n\n        if not isinstance(separatrix, Coordinates):\n            sep1_intersections = coords_plane_intersect(separatrix[0], yz_plane)\n            sep2_intersections = coords_plane_intersect(separatrix[1], yz_plane)\n            sep1_arg = np.argmin(np.abs(sep1_intersections.T[0] - o_point.x))\n            sep2_arg = np.argmin(np.abs(sep2_intersections.T[0] - o_point.x))\n            x_sep1_mp = sep1_intersections.T[0][sep1_arg]\n            x_sep2_mp = sep2_intersections.T[0][sep2_arg]\n            if outboard:\n                x_sep_mp = x_sep1_mp if x_sep1_mp > x_sep2_mp else x_sep2_mp\n            else:\n                x_sep_mp = x_sep1_mp if x_sep1_mp < x_sep2_mp else x_sep2_mp\n        else:\n            sep_intersections = coords_plane_intersect(separatrix, yz_plane)\n            sep_arg = np.argmin(np.abs(sep_intersections.T[0] - o_point.x))\n            x_sep_mp = sep_intersections.T[0][sep_arg]\n\n        out_intersections = coords_plane_intersect(self.first_wall, yz_plane)\n        if outboard:\n            x_out_mp = np.max(out_intersections.T[0])\n        else:\n            x_out_mp = np.min(out_intersections.T[0])\n\n        return x_sep_mp, x_out_mp",
  "def _make_flux_surfaces(self, x, z):\n        \"\"\"\n        Make individual PartialOpenFluxSurfaces through a point.\n        \"\"\"\n        coords = find_flux_surface_through_point(\n            self.eq.x, self.eq.z, self.eq.psi(), x, z, self.eq.psi(x, z)\n        )\n        coords = Coordinates({\"x\": coords[0], \"z\": coords[1]})\n        f_s = OpenFluxSurface(coords)\n        lfs, hfs = f_s.split(self._o_point, plane=self._yz_plane)\n        return lfs, hfs",
  "def _make_flux_surfaces_ob(self):\n        \"\"\"\n        Make the flux surfaces on the outboard.\n        \"\"\"\n        self.x_sep_omp, x_out_omp = self._get_sep_out_intersection(outboard=True)\n\n        self.flux_surfaces_ob_lfs = []\n        self.flux_surfaces_ob_hfs = []\n\n        x = self.x_sep_omp + self.dx_mp\n        while x < x_out_omp - EPS:\n            lfs, hfs = self._make_flux_surfaces(x, self._o_point.z)\n            self.flux_surfaces_ob_lfs.append(lfs)\n            self.flux_surfaces_ob_hfs.append(hfs)\n            x += self.dx_mp",
  "def _make_flux_surfaces_ib(self):\n        \"\"\"\n        Make the flux surfaces on the inboard.\n        \"\"\"\n        self.x_sep_imp, x_out_imp = self._get_sep_out_intersection(outboard=False)\n\n        self.flux_surfaces_ib_lfs = []\n        self.flux_surfaces_ib_hfs = []\n        x = self.x_sep_imp - self.dx_mp\n        while x > x_out_imp + EPS:\n            lfs, hfs = self._make_flux_surfaces(x, self._o_point.z)\n            self.flux_surfaces_ib_lfs.append(lfs)\n            self.flux_surfaces_ib_hfs.append(hfs)\n            x -= self.dx_mp",
  "def _clip_flux_surfaces(self, first_wall):\n        \"\"\"\n        Clip the flux surfaces to a first wall. Catch the cases where no intersections\n        are found.\n        \"\"\"\n        for group in [\n            self.flux_surfaces_ob_lfs,\n            self.flux_surfaces_ob_hfs,\n            self.flux_surfaces_ib_lfs,\n            self.flux_surfaces_ib_hfs,\n        ]:\n            if group:\n                for i, flux_surface in enumerate(group):\n                    flux_surface.clip(first_wall)\n                    if flux_surface.alpha is None:\n                        # No intersection detected between flux surface and first wall\n                        # Drop the flux surface from the group\n                        group.pop(i)",
  "def analyse(self, first_wall):\n        \"\"\"\n        Perform the calculation to obtain charged particle heat fluxes on the\n        the specified first_wall\n\n        Parameters\n        ----------\n        first_wall: Coordinates\n            The closed first wall geometry on which to calculate the heat flux\n\n        Returns\n        -------\n        x: np.array\n            The x coordinates of the flux surface intersections\n        z: np.array\n            The z coordinates of the flux surface intersections\n        heat_flux: np.array\n            The perpendicular heat fluxes at the intersection points [MW/m^2]\n        \"\"\"\n        self.first_wall = self._process_first_wall(first_wall)\n\n        if self.eq.is_double_null:\n            x, z, hf = self._analyse_DN(first_wall)\n        else:\n            x, z, hf = self._analyse_SN(first_wall)\n\n        self.result = x, z, hf\n        return x, z, hf",
  "def _analyse_SN(self, first_wall):\n        \"\"\"\n        Calculation for the case of single nulls.\n        \"\"\"\n        self._make_flux_surfaces_ob()\n\n        # Find the intersections of the flux surfaces with the first wall\n        self._clip_flux_surfaces(first_wall)\n\n        x_omp, z_omp, x_lfs_inter, z_lfs_inter, alpha_lfs = self._get_arrays(\n            self.flux_surfaces_ob_lfs\n        )\n        _, _, x_hfs_inter, z_hfs_inter, alpha_hfs = self._get_arrays(\n            self.flux_surfaces_ob_hfs\n        )\n\n        # Calculate values at OMP\n        dx_omp = x_omp - self.x_sep_omp\n        Bp_omp = self.eq.Bp(x_omp, z_omp)\n        Bt_omp = self.eq.Bt(x_omp)\n        B_omp = np.hypot(Bp_omp, Bt_omp)\n\n        # Parallel power at the outboard midplane\n        q_par_omp = self._q_par(x_omp, dx_omp, B_omp, Bp_omp)\n\n        # Calculate values at intersections\n        Bp_lfs = self.eq.Bp(x_lfs_inter, z_lfs_inter)\n        Bp_hfs = self.eq.Bp(x_hfs_inter, z_hfs_inter)\n\n        # Calculate parallel power at the intersections\n        # Note that flux expansion terms cancel down to this\n        q_par_lfs = q_par_omp * Bp_lfs / B_omp\n        q_par_hfs = q_par_omp * Bp_hfs / B_omp\n\n        # Calculate perpendicular heat fluxes\n        heat_flux_lfs = self.params.f_lfs_lower_target * q_par_lfs * np.sin(alpha_lfs)\n        heat_flux_hfs = self.params.f_hfs_lower_target * q_par_hfs * np.sin(alpha_hfs)\n\n        # Correct power (energy conservation)\n        q_omp_int = 2 * np.pi * np.sum(q_par_omp / (B_omp / Bp_omp) * self.dx_mp * x_omp)\n        f_correct_power = self.params.P_sep_particle / q_omp_int\n        return (\n            np.append(x_lfs_inter, x_hfs_inter),\n            np.append(z_lfs_inter, z_hfs_inter),\n            f_correct_power * np.append(heat_flux_lfs, heat_flux_hfs),\n        )",
  "def _analyse_DN(self, first_wall):\n        \"\"\"\n        Calculation for the case of double nulls.\n        \"\"\"\n        self._make_flux_surfaces_ob()\n        self._make_flux_surfaces_ib()\n\n        # Find the intersections of the flux surfaces with the first wall\n        self._clip_flux_surfaces(first_wall)\n\n        (\n            x_omp,\n            z_omp,\n            x_lfs_down_inter,\n            z_lfs_down_inter,\n            alpha_lfs_down,\n        ) = self._get_arrays(self.flux_surfaces_ob_lfs)\n        _, _, x_lfs_up_inter, z_lfs_up_inter, alpha_lfs_up = self._get_arrays(\n            self.flux_surfaces_ob_hfs\n        )\n        (\n            x_imp,\n            z_imp,\n            x_hfs_down_inter,\n            z_hfs_down_inter,\n            alpha_hfs_down,\n        ) = self._get_arrays(self.flux_surfaces_ib_lfs)\n        _, _, x_hfs_up_inter, z_hfs_up_inter, alpha_hfs_up = self._get_arrays(\n            self.flux_surfaces_ib_hfs\n        )\n\n        # Calculate values at OMP\n        dx_omp = x_omp - self.x_sep_omp\n        Bp_omp = self.eq.Bp(x_omp, z_omp)\n        Bt_omp = self.eq.Bt(x_omp)\n        B_omp = np.hypot(Bp_omp, Bt_omp)\n\n        # Calculate values at IMP\n        dx_imp = abs(x_imp - self.x_sep_imp)\n        Bp_imp = self.eq.Bp(x_imp, z_imp)\n        Bt_imp = self.eq.Bt(x_imp)\n        B_imp = np.hypot(Bp_imp, Bt_imp)\n\n        # Parallel power at the outboard and inboard midplane\n        q_par_omp = self._q_par(x_omp, dx_omp, B_omp, Bp_omp)\n        q_par_imp = self._q_par(x_imp, dx_imp, B_imp, Bp_imp, outboard=False)\n\n        # Calculate poloidal field at intersections\n        Bp_lfs_down = self.eq.Bp(x_lfs_down_inter, z_lfs_down_inter)\n        Bp_lfs_up = self.eq.Bp(x_lfs_up_inter, z_lfs_up_inter)\n        Bp_hfs_down = self.eq.Bp(x_hfs_down_inter, z_hfs_down_inter)\n        Bp_hfs_up = self.eq.Bp(x_hfs_up_inter, z_hfs_up_inter)\n\n        # Calculate parallel power at the intersections\n        # Note that flux expansion terms cancel down to this\n        q_par_lfs_down = q_par_omp * Bp_lfs_down / B_omp\n        q_par_lfs_up = q_par_omp * Bp_lfs_up / B_omp\n        q_par_hfs_down = q_par_imp * Bp_hfs_down / B_imp\n        q_par_hfs_up = q_par_imp * Bp_hfs_up / B_imp\n\n        # Calculate perpendicular heat fluxes\n        heat_flux_lfs_down = (\n            self.params.f_lfs_lower_target * q_par_lfs_down * np.sin(alpha_lfs_down)\n        )\n        heat_flux_lfs_up = (\n            self.params.f_lfs_upper_target * q_par_lfs_up * np.sin(alpha_lfs_up)\n        )\n        heat_flux_hfs_down = (\n            self.params.f_hfs_lower_target * q_par_hfs_down * np.sin(alpha_hfs_down)\n        )\n        heat_flux_hfs_up = (\n            self.params.f_hfs_upper_target * q_par_hfs_up * np.sin(alpha_hfs_up)\n        )\n\n        # Correct power (energy conservation)\n        q_omp_int = 2 * np.pi * np.sum(q_par_omp * Bp_omp / B_omp * self.dx_mp * x_omp)\n        q_imp_int = 2 * np.pi * np.sum(q_par_imp * Bp_imp / B_imp * self.dx_mp * x_imp)\n\n        total_power = self.params.P_sep_particle\n        f_outboard = self.params.f_lfs_lower_target + self.params.f_lfs_upper_target\n        f_inboard = self.params.f_hfs_lower_target + self.params.f_hfs_upper_target\n        f_correct_lfs_down = (\n            total_power * self.params.f_lfs_lower_target / f_outboard\n        ) / q_omp_int\n        f_correct_lfs_up = (\n            total_power * self.params.f_lfs_upper_target / f_outboard\n        ) / q_omp_int\n        f_correct_hfs_down = (\n            total_power * self.params.f_hfs_lower_target / f_inboard\n        ) / q_imp_int\n        f_correct_hfs_up = (\n            total_power * self.params.f_hfs_upper_target / f_inboard\n        ) / q_imp_int\n\n        return (\n            np.concatenate(\n                [x_lfs_down_inter, x_lfs_up_inter, x_hfs_down_inter, x_hfs_up_inter]\n            ),\n            np.concatenate(\n                [z_lfs_down_inter, z_lfs_up_inter, z_hfs_down_inter, z_hfs_up_inter]\n            ),\n            np.concatenate(\n                [\n                    f_correct_lfs_down * heat_flux_lfs_down,\n                    f_correct_lfs_up * heat_flux_lfs_up,\n                    f_correct_hfs_down * heat_flux_hfs_down,\n                    f_correct_hfs_up * heat_flux_hfs_up,\n                ]\n            ),\n        )",
  "def _q_par(self, x, dx, B, Bp, outboard=True):\n        \"\"\"\n        Calculate the parallel power at the midplane.\n        \"\"\"\n        p_sol_near = self.params.P_sep_particle * self.params.f_p_sol_near\n        p_sol_far = self.params.P_sep_particle * (1 - self.params.f_p_sol_near)\n        if outboard:\n            lq_near = self.params.fw_lambda_q_near_omp\n            lq_far = self.params.fw_lambda_q_far_omp\n        else:\n            lq_near = self.params.fw_lambda_q_near_imp\n            lq_far = self.params.fw_lambda_q_far_imp\n        return (\n            (\n                p_sol_near * np.exp(-dx / lq_near) / lq_near\n                + p_sol_far * np.exp(-dx / lq_far) / lq_far\n            )\n            * B\n            / (Bp * 2 * np.pi * x)\n        )",
  "def plot(self, ax: Axes = None, show=False):\n        \"\"\"\n        Plot the ChargedParticleSolver results.\n        \"\"\"\n        if ax is None:\n            _, ax = plt.subplots()\n\n        plot_coordinates(self.first_wall, ax=ax, linewidth=0.5, fill=False)\n        separatrix = self.eq.get_separatrix()\n\n        if isinstance(separatrix, Coordinates):\n            separatrix = [separatrix]\n\n        for sep in separatrix:\n            plot_coordinates(sep, ax=ax, linewidth=0.2)\n\n        for f_s in self.flux_surfaces:\n            plot_coordinates(f_s.coords, ax=ax, linewidth=0.01)\n\n        cm = ax.scatter(\n            self.result[0],\n            self.result[1],\n            c=self.result[2],\n            s=10,\n            zorder=40,\n            cmap=\"plasma\",\n        )\n        f = ax.figure\n        f.colorbar(cm, label=\"MW/m\u00b2\")\n        if show:\n            plt.show()\n        return ax",
  "def _make_params(self, config):\n        \"\"\"Convert the given params to ``ChargedParticleSolverParams``\"\"\"\n        if isinstance(config, dict):\n            try:\n                return ChargedParticleSolverParams(**config)\n            except TypeError:\n                unknown = [\n                    k for k in config if k not in fields(ChargedParticleSolverParams)\n                ]\n                raise TypeError(f\"Unknown config parameter(s) {str(unknown)[1:-1]}\")\n        elif isinstance(config, ChargedParticleSolverParams):\n            return config\n        else:\n            raise TypeError(\n                \"Unsupported type: 'config' must be a 'dict', or \"\n                \"'ChargedParticleSolverParams' instance; found \"\n                f\"'{type(config).__name__}'.\"\n            )",
  "class RadiationTransportError(BluemiraError):\n    \"\"\"\n    Base error for the radiation_transport module.\n    \"\"\"\n\n    pass",
  "class AdvectionTransportError(RadiationTransportError):\n    \"\"\"\n    Error class for advective transport solver.\n    \"\"\"\n\n    pass",
  "def systems_code_solver(\n    params: ParameterFrame,\n    build_config: BuildConfig,\n    module: str = \"PROCESS\",\n) -> CodesSolver:\n    \"\"\"\n    Runs, reads or mocks systems code according to the build configuration dictionary.\n\n    Parameters\n    ----------\n    params:\n        ParameterFrame for code\n    build_config:\n        build configuration dictionary\n    module:\n        Module to use\n\n    Returns\n    -------\n    The solver that has been run.\n\n    Raises\n    ------\n    CodesError\n        If the system code is not being mocked and is not installed, or\n        there is a problem running the system code.\n    \"\"\"\n    syscode = get_code_interface(module)\n    return syscode.Solver(params, build_config)",
  "def plot_radial_build(\n    filename: str, width: float = 1.0, show: bool = True, module: str = \"PROCESS\"\n):\n    \"\"\"\n    Systems code radial build\n\n    Parameters\n    ----------\n    filename:\n        The directory containing the system code run results.\n    width:\n        The relative width of the plot.\n    show:\n        If True then immediately display the plot, else delay displaying the plot until\n        the user shows it, by default True.\n    module:\n        Module to use\n    \"\"\"\n    syscode = get_code_interface(module)\n\n    return syscode.plot_radial_build(filename, width, show)",
  "def transport_code_solver(\n    params: ParameterFrame,\n    build_config: BuildConfig,\n    module: str = \"PLASMOD\",\n) -> CodesSolver:\n    \"\"\"\n    Transport solver\n\n    Parameters\n    ----------\n    params:\n        ParameterFrame for plasmod\n    build_config:\n        build configuration dictionary\n    module:\n        Module to use\n\n    Returns\n    -------\n    The solver object to be run\n    \"\"\"\n    transp = get_code_interface(module)\n    return transp.Solver(params, build_config)",
  "class DefaultDisplayOptions:\n    \"\"\"Polyscope default display options\"\"\"\n\n    colour: ColourDescriptor = ColourDescriptor()\n    transparency: float = 0.0\n    material: str = \"wax\"\n    tesselation: float = 0.05\n    wires_on: bool = False\n    wire_radius: float = 0.001\n    smooth: bool = True\n\n    @property\n    def color(self) -> str:\n        \"\"\"See colour\"\"\"\n        return self.colour\n\n    @color.setter\n    def color(self, value: Union[str, Tuple[float, float, float], ColorPalette]):\n        \"\"\"See colour\"\"\"\n        self.colour = value",
  "def show_cad(\n    parts: Union[cadapi.apiShape, List[cadapi.apiShape]],\n    part_options: List[Dict],\n    labels: List[str],\n    **kwargs,\n):\n    \"\"\"\n    The implementation of the display API for FreeCAD parts.\n\n    Parameters\n    ----------\n    parts:\n        The parts to display.\n    part_options:\n        The options to use to display the parts.\n    labels:\n        Labels to use for each part object\n    **kwargs:\n        options passed to polyscope\n    \"\"\"\n    if part_options is None:\n        part_options = [None]\n\n    if None in part_options:\n        part_options = [\n            DefaultDisplayOptions() if o is None else o for o in part_options\n        ]\n\n    transparency = \"none\"\n    for opt in part_options:\n        if not np.isclose(opt[\"transparency\"], 0):\n            transparency = \"pretty\"\n            break\n\n    polyscope_setup(\n        up_direction=kwargs.get(\"up_direction\", \"z_up\"),\n        fps=kwargs.get(\"fps\", 60),\n        aa=kwargs.get(\"aa\", 1),\n        transparency=transparency,\n        render_passes=kwargs.get(\"render_passes\", 3),\n        gplane=kwargs.get(\"gplane\", \"none\"),\n    )\n\n    add_features(labels, parts, part_options)\n\n    ps.show()",
  "def polyscope_setup(\n    up_direction: str = \"z_up\",\n    fps: int = 60,\n    aa: int = 1,\n    transparency: str = \"pretty\",\n    render_passes: int = 2,\n    gplane: str = \"none\",\n):\n    \"\"\"\n    Setup Polyscope default scene\n\n    Parameters\n    ----------\n    up_direction:\n        'x_up' The positive X-axis is up.\n        'neg_x_up' The negative X-axis is up.\n        'y_up' The positive Y-axis is up.\n        'neg_y_up' The negative Y-axis is up.\n        'z_up' The positive Z-axis is up.\n        'neg_z_up' The negative Z-axis is up.\n    fps:\n        maximum frames per second of viewer (-1 == infinite)\n    aa:\n        anti aliasing amount, 1 is off, 2 is usually enough\n    transparency:\n        the transparency mode (none, simple, pretty)\n    render_passes:\n        for transparent shapes how many render passes to undertake\n    gplane:\n        the ground plane mode (none, tile, tile_reflection, shadon_only)\n    \"\"\"\n    _init_polyscope()\n\n    ps.set_max_fps(fps)\n    ps.set_SSAA_factor(aa)\n    ps.set_transparency_mode(transparency)\n    if transparency != \"none\":\n        ps.set_transparency_render_passes(render_passes)\n    ps.set_ground_plane_mode(gplane)\n    ps.set_up_dir(up_direction)\n\n    ps.remove_all_structures()",
  "def _init_polyscope():\n    \"\"\"\n    Initialise polyscope (just once)\n    \"\"\"\n    bluemira_warn(\n        \"Polyscope is not a NURBS based viewer.\"\n        \" Some features may appear subtly different to their CAD representation\"\n    )\n    ps.set_program_name(\"Bluemira Display\")\n    ps.init()",
  "def add_features(\n    labels: List[str],\n    parts: Union[cadapi.apiShape, List[cadapi.apiShape]],\n    options: Union[Dict, List[Dict]],\n) -> Tuple[List[ps.SurfaceMesh], List[ps.CurveNetwork]]:\n    \"\"\"\n    Grab meshes of all parts to be displayed by Polyscope\n\n    Parameters\n    ----------\n    parts:\n        parts to be displayed\n    options:\n        display options\n\n    Returns\n    -------\n    Registered Polyspline surface meshes\n\n    \"\"\"\n    meshes = []\n    curves = []\n\n    # loop over every face adding their meshes to polyscope\n    for shape_i, (label, part, option) in enumerate(\n        zip(labels, parts, options),\n    ):\n        verts, faces = cadapi.collect_verts_faces(part, option[\"tesselation\"])\n\n        if not (verts is None or faces is None):\n            m = ps.register_surface_mesh(\n                clean_name(label, str(shape_i)),\n                verts,\n                faces,\n                smooth_shade=option[\"smooth\"],\n                color=colors.to_rgb(option[\"colour\"]),\n                transparency=1 - option[\"transparency\"],\n                material=option[\"material\"],\n            )\n            meshes.append(m)\n\n        if option[\"wires_on\"] or (verts is None or faces is None):\n            verts, edges = cadapi.collect_wires(part, Deflection=0.01)\n            c = ps.register_curve_network(\n                clean_name(label, f\"{shape_i}_wire\"),\n                verts,\n                edges,\n                radius=option[\"wire_radius\"],\n                color=colors.to_rgb(option[\"colour\"]),\n                transparency=1 - option[\"transparency\"],\n                material=option[\"material\"],\n            )\n            curves.append(c)\n\n    return meshes, curves",
  "def clean_name(label: str, index_label: str) -> str:\n    \"\"\"\n    Cleans or creates name.\n    Polyscope doesn't like hashes in names,\n    repeat names overwrite existing component.\n\n    Parameters\n    ----------\n    label:\n        name to be cleaned\n    index_label:\n        if name is empty -> {index_label}: NO LABEL\n\n    Returns\n    -------\n    name\n    \"\"\"\n    label = label.replace(\"#\", \"_\")\n    index_label = index_label.replace(\"#\", \"_\")\n    if len(label) == 0 or label == \"_\":\n        return f\"{index_label}: NO LABEL\"\n    else:\n        return f\"{index_label}: {label}\"",
  "def color(self) -> str:\n        \"\"\"See colour\"\"\"\n        return self.colour",
  "def color(self, value: Union[str, Tuple[float, float, float], ColorPalette]):\n        \"\"\"See colour\"\"\"\n        self.colour = value",
  "class _Unit(enum.IntEnum):\n    \"\"\"Available units in FreeCAD\"\"\"\n\n    MM = 0  # mmKS\n    SI = 1  # MKS\n    US = 2  # in/lb\n    IMP_DEC = 3  # imperial_decimal\n    BUILD_EURO = 4  # cm/m2/m3\n    BUILD_US = 5  # ft-in/sqft/cft\n    CNC = 6  # mm, mm/min\n    IMP_CIV = 7  # ft, ft/sec\n    FEM = 8",
  "class _StpFileScheme(enum.Enum):\n    \"\"\"Available STEP file schemes in FreeCAD\"\"\"\n\n    AP203 = enum.auto()\n    AP214CD = enum.auto()\n    AP214DIS = enum.auto()\n    AP214IS = enum.auto()\n    AP242DIS = enum.auto()",
  "def _freecad_save_config(\n    unit: str = \"SI\",\n    no_dp: int = 5,\n    author: str = \"Bluemira\",\n    stp_file_scheme: str = \"AP242DIS\",\n):\n    \"\"\"\n    Attempts to configure FreeCAD with units file schemes and attributions\n\n    This must be run before Part is imported for legacy exporters\n    \"\"\"\n    unit_prefs = FreeCAD.ParamGet(\"User parameter:BaseApp/Preferences/Units\")\n    # Seems to have little effect on anything but its an option to set\n    # does effect the GUI be apparently not the base unit of the built part...\n    unit_prefs.SetInt(\"UserSchema\", _Unit[unit].value)\n    unit_prefs.SetInt(\"Decimals\", no_dp)  # 100th mm\n\n    part_step_prefs = FreeCAD.ParamGet(\n        \"User parameter:BaseApp/Preferences/Mod/Part/STEP\"\n    )\n    part_step_prefs.SetString(\"Scheme\", _StpFileScheme[stp_file_scheme].name)\n    part_step_prefs.SetString(\"Author\", author)\n    part_step_prefs.SetString(\"Company\", \"Bluemira\")\n    # Seems to have little effect on anything but its an option to set\n    part_step_prefs.SetInt(\"Unit\", _Unit[unit].value)\n\n    part_gen_prefs = FreeCAD.ParamGet(\n        \"User parameter:BaseApp/Preferences/Mod/Part/General\"\n    )\n    part_gen_prefs.SetInt(\"WriteSurfaceCurveMode\", 1)\n\n    import_prefs = FreeCAD.ParamGet(\"User parameter:BaseApp/Preferences/Mod/Import\")\n    import_prefs.SetInt(\"ImportMode\", 0)\n    import_prefs.SetBool(\"ExportLegacy\", False)",
  "def process_NLOPT_conditions(  # noqa :N802\n    opt_conditions: Dict[str, float]\n) -> Dict[str, float]:\n    \"\"\"\n    Process NLopt termination conditions. Checks for negative or 0 values on some\n    conditions (which mean they are inactive), and warns if you are doing weird stuff.\n\n    Parameters\n    ----------\n    opt_conditions:\n        Dictionary of termination condition keys and values\n\n    Returns\n    -------\n    Dictionary of processed termination condition keys and values\n\n    Raises\n    ------\n    OptUtilitiesError\n        If no valid termination conditions are specified\n    \"\"\"\n    conditions = {}\n    for k, v in opt_conditions.items():\n        if k not in TERMINATION_KEYS:\n            bluemira_warn(f\"Unrecognised termination condition: {k}\")\n\n        # Negative or 0 conditions result in inactive NLopt termination conditions, for\n        # the most part.\n        if k == \"stop_val\":\n            conditions[k] = v\n\n        elif v > 0:\n            if k in [\"ftol_abs\", \"ftol_res\", \"xtol_abs\", \"xtol_res\"] and v < EPS:\n                bluemira_warn(\n                    \"You are setting an optimisation termination condition to below machine precision. Don't..\"\n                )\n\n            conditions[k] = v\n\n    if not conditions:\n        raise OptUtilitiesError(\n            \"You must specify at least one termination criterion for the optimisation algorithm.\"\n        )\n    return conditions",
  "def process_NLOPT_result(opt: nlopt.opt):  # noqa :N802\n    \"\"\"\n    Handle a NLopt optimiser and check results.\n\n    Parameters\n    ----------\n    opt:\n        The optimiser to check\n    \"\"\"\n    result = opt.last_optimize_result()\n\n    if result == nlopt.MAXEVAL_REACHED:\n        bluemira_warn(\n            \"\\nNLopt Optimiser succeeded but stopped at the maximum number of evaulations.\\n\"\n        )\n    elif result == nlopt.MAXTIME_REACHED:\n        bluemira_warn(\n            \"\\nNLopt Optimiser succeeded but stopped at the maximum duration.\\n\"\n        )\n    elif result == nlopt.ROUNDOFF_LIMITED:\n        bluemira_warn(\n            \"\\nNLopt Optimiser was halted due to round-off errors. A useful result was probably found...\\n\"\n        )\n    elif result == nlopt.FAILURE:\n        bluemira_warn(\"\\nNLopt Optimiser failed real hard...\\n\")\n    elif result == nlopt.INVALID_ARGS:\n        bluemira_warn(\"\\nNLopt Optimiser failed because of invalid arguments.\\n\")\n    elif result == nlopt.OUT_OF_MEMORY:\n        bluemira_warn(\"\\nNLopt Optimiser failed because it ran out of memory.\\n\")\n    elif result == nlopt.FORCED_STOP:\n        bluemira_warn(\"\\nNLopt Optimiser failed because of a forced stop.\\n\")",
  "class _NLOPTObjectiveFunction:\n    \"\"\"\n    Wrapper to store x-vector in case of RoundOffLimited errors.\n    \"\"\"\n\n    def __init__(self, func: Callable[[Any], float]):\n        self.func = func\n        self.last_x = None\n\n    def __call__(self, x, grad, *args):\n        self.store_x(x)\n        return self.func(x, grad, *args)\n\n    def store_x(self, x):\n        if not np.isnan(np.sum(x)):\n            self.last_x = x",
  "class NLOPTOptimiser:\n    \"\"\"\n    NLOpt optimiser API class.\n\n    Parameters\n    ----------\n    algorithm_name:\n        Optimisation algorithm to use\n    n_variables:\n        Size of the variable vector\n    opt_conditions:\n        Dictionary of algorithm termination criteria\n    opt_parameters:\n        Dictionary of algorithm parameters\n    \"\"\"\n\n    def __init__(\n        self,\n        algorithm_name: str,\n        n_variables: Optional[int] = None,\n        opt_conditions: Optional[Dict[str, float]] = None,\n        opt_parameters: Optional[Dict[str, float]] = None,\n    ):\n        self.opt_conditions = opt_conditions\n        self.opt_parameters = opt_parameters\n        self.algorithm_name = algorithm_name\n        self._flag_built = False\n        self.build_optimiser(n_variables)\n\n    def _opt_inputs_ready(func):\n        @functools.wraps(func)\n        def wrapper(self, *args, **kwargs):\n            if not self._flag_built:\n                raise OptUtilitiesError(\n                    f\"You must specify the dimensionality of the optimisation problem before using {func.__name__}.\"\n                )\n            func(self, *args, **kwargs)\n\n        return wrapper\n\n    def _setup_teardown(self):\n        \"\"\"\n        Setup / teardown the wrapper (phoenix design pattern).\n        \"\"\"\n        self.n_evals = 0\n        self.optimum_value = None\n        self._f_objective = None\n        self.lower_bounds = None\n        self.upper_bounds = None\n        self.constraints = []\n        self.constraint_tols = []\n\n    @property\n    def algorithm_name(self) -> str:\n        \"\"\"\n        Name of the optimisation algorithm.\n        \"\"\"\n        return self._algorithm_name\n\n    @algorithm_name.setter\n    def algorithm_name(self, name: str):\n        \"\"\"\n        Setter for the name of the optimisation algorithm.\n\n        Parameters\n        ----------\n        name:\n            Name of the optimisation algorithm\n\n        Raises\n        ------\n        OptUtilitiesError:\n            If the algorithm is not recognised\n        \"\"\"\n        if name not in NLOPT_ALG_MAPPING:\n            raise OptUtilitiesError(f\"Unknown or unmapped algorithm: {name}\")\n        self._algorithm_name = name\n\n    def build_optimiser(self, n_variables: Optional[int]):\n        \"\"\"\n        Build the underlying optimisation algorithm.\n\n        Parameters\n        ----------\n        n_variables:\n            Dimension of the optimisation problem. If None, the algorithm is not built.\n        \"\"\"\n        self.n_variables = n_variables\n        if n_variables is None:\n            return\n\n        self._set_algorithm(n_variables)\n        self._flag_built = True\n        self.set_termination_conditions(self.opt_conditions)\n        self.set_algorithm_parameters(self.opt_parameters)\n        self._setup_teardown()\n\n    def _append_constraint_tols(self, constraint, tolerance):\n        \"\"\"\n        Append constraint function and tolerances.\n        \"\"\"\n        self.constraints.append(constraint)\n        self.constraint_tols.append(tolerance)\n\n    def _set_algorithm(self, n_variables):\n        \"\"\"\n        Initialise the underlying NLOPT algorithm.\n        \"\"\"\n        algorithm = NLOPT_ALG_MAPPING[self.algorithm_name]\n        self._opt = nlopt.opt(algorithm, n_variables)\n\n    @_opt_inputs_ready\n    def set_algorithm_parameters(self, opt_parameters: Dict[str, float]):\n        \"\"\"\n        Set the optimisation algorithm parameters to use.\n\n        Parameters\n        ----------\n        opt_parameters:\n            Optimisation algorithm parameters to use\n        \"\"\"\n        if opt_parameters is None:\n            return\n\n        for k, v in opt_parameters.items():\n            if self._opt.has_param(k):\n                self._opt.set_param(k, v)\n            elif k == \"initial_step\":\n                self._opt.set_initial_step(v)\n            else:\n                bluemira_warn(f\"Unrecognised algorithm parameter: {k}\")\n\n    @_opt_inputs_ready\n    def set_termination_conditions(self, opt_conditions: Dict[str, float]):\n        \"\"\"\n        Set the optimisation algorithm termination condition(s) to use.\n\n        Parameters\n        ----------\n        opt_conditions:\n            Termination conditions for the optimisation algorithm\n        \"\"\"\n        if opt_conditions is None:\n            return\n\n        conditions = process_NLOPT_conditions(opt_conditions)\n\n        if \"ftol_abs\" in conditions:\n            self._opt.set_ftol_abs(conditions[\"ftol_abs\"])\n        if \"ftol_rel\" in opt_conditions:\n            self._opt.set_ftol_rel(conditions[\"ftol_rel\"])\n        if \"xtol_abs\" in opt_conditions:\n            self._opt.set_xtol_abs(conditions[\"xtol_abs\"])\n        if \"xtol_rel\" in opt_conditions:\n            self._opt.set_xtol_rel(conditions[\"xtol_rel\"])\n        if \"max_time\" in opt_conditions:\n            self._opt.set_maxtime(conditions[\"max_time\"])\n        if \"max_eval\" in opt_conditions:\n            self._opt.set_maxeval(conditions[\"max_eval\"])\n        if \"stop_val\" in opt_conditions:\n            self._opt.set_stopval(conditions[\"stop_val\"])\n\n    @_opt_inputs_ready\n    def set_objective_function(self, f_objective: Callable[[Any], float]):\n        \"\"\"\n        Set the objective function (minimisation).\n\n        Parameters\n        ----------\n        f_objective:\n            Objective function to minimise\n        \"\"\"\n        f_objective = _NLOPTObjectiveFunction(f_objective)\n        self._f_objective = f_objective\n        self._opt.set_min_objective(f_objective)\n\n    @_opt_inputs_ready\n    def set_lower_bounds(self, lower_bounds: np.ndarray):\n        \"\"\"\n        Set the lower bounds.\n\n        Parameters\n        ----------\n        lower_bounds:\n            Lower bound vector\n        \"\"\"\n        self.lower_bounds = lower_bounds\n        self._opt.set_lower_bounds(lower_bounds)\n\n    @_opt_inputs_ready\n    def set_upper_bounds(self, upper_bounds: np.ndarray):\n        \"\"\"\n        Set the upper bounds.\n\n        Parameters\n        ----------\n        upper_bounds:\n            Upper bound vector\n        \"\"\"\n        self.upper_bounds = upper_bounds\n        self._opt.set_upper_bounds(upper_bounds)\n\n    @_opt_inputs_ready\n    def add_eq_constraints(\n        self, f_constraint: Callable[[Any], np.ndarray], tolerance: float\n    ):\n        \"\"\"\n        Add a vector-valued equality constraint.\n\n        Parameters\n        ----------\n        f_constraint:\n            Constraint function\n        tolerance:\n            Tolerance with which to enforce the constraint\n        \"\"\"\n        if self.algorithm_name not in EQ_CON_ALGS:\n            raise OptUtilitiesError(\n                f\"{self.algorithm_name} does not support equality constraints.\"\n            )\n\n        self._opt.add_equality_mconstraint(f_constraint, tolerance)\n        self._append_constraint_tols(f_constraint, tolerance)\n\n    @_opt_inputs_ready\n    def add_ineq_constraints(\n        self, f_constraint: Callable[[Any], np.ndarray], tolerance: float\n    ):\n        \"\"\"\n        Add a vector-valued inequality constraint.\n\n        Parameters\n        ----------\n        f_constraint:\n            Constraint function\n        tolerance:\n            Tolerance array with which to enforce the constraint\n        \"\"\"\n        if self.algorithm_name not in INEQ_CON_ALGS:\n            raise OptUtilitiesError(\n                f\"{self.algorithm_name} does not support inequality constraints.\"\n            )\n\n        self._opt.add_inequality_mconstraint(f_constraint, tolerance)\n        self._append_constraint_tols(f_constraint, tolerance)\n\n    def optimise(self, x0: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Run the optimiser.\n\n        Parameters\n        ----------\n        x0:\n            Starting solution vector\n\n        Returns\n        -------\n        Optimal solution vector\n        \"\"\"\n        if self._f_objective is None:\n            raise OptUtilitiesError(\n                \"You must first specify an objective function before performing the optimisation.\"\n            )\n\n        if x0 is None:\n            x0 = np.zeros(self.n_variables)\n\n        try:\n            x_star = self._opt.optimize(x0)\n\n        except nlopt.RoundoffLimited:\n            # It's likely that the last call was still a reasonably good solution.\n            self.optimum_value = self._opt.last_optimum_value()\n            x_star = self._f_objective.last_x\n\n        except OptVariablesError:\n            # Probably still some rounding errors due to numerical gradients\n            # It's likely that the last call was still a reasonably good solution.\n            bluemira_warn(\"Badly behaved numerical gradients are causing trouble...\")\n            self.optimum_value = self._opt.last_optimum_value()\n            x_star = np.round(self._f_objective.last_x, 6)\n\n        except RuntimeError as error:\n            # Usually \"more than iter SQP iterations\"\n            self.optimum_value = self._opt.last_optimum_value()\n            self.n_evals = self._opt.get_numevals()\n            process_NLOPT_result(self._opt)\n            raise ExternalOptError(str(error))\n\n        except KeyboardInterrupt:\n            self.optimum_value = self._opt.last_optimum_value()\n            self.n_evals = self._opt.get_numevals()\n            process_NLOPT_result(self._opt)\n            raise KeyboardInterrupt(\n                \"The optimisation was halted by the user. Please check \"\n                \"your optimisation problem and termination conditions.\"\n            )\n\n        self.optimum_value = self._opt.last_optimum_value()\n        self.n_evals = self._opt.get_numevals()\n        process_NLOPT_result(self._opt)\n        return x_star\n\n    _opt_inputs_ready = staticmethod(_opt_inputs_ready)",
  "def __init__(self, func: Callable[[Any], float]):\n        self.func = func\n        self.last_x = None",
  "def __call__(self, x, grad, *args):\n        self.store_x(x)\n        return self.func(x, grad, *args)",
  "def store_x(self, x):\n        if not np.isnan(np.sum(x)):\n            self.last_x = x",
  "def __init__(\n        self,\n        algorithm_name: str,\n        n_variables: Optional[int] = None,\n        opt_conditions: Optional[Dict[str, float]] = None,\n        opt_parameters: Optional[Dict[str, float]] = None,\n    ):\n        self.opt_conditions = opt_conditions\n        self.opt_parameters = opt_parameters\n        self.algorithm_name = algorithm_name\n        self._flag_built = False\n        self.build_optimiser(n_variables)",
  "def _opt_inputs_ready(func):\n        @functools.wraps(func)\n        def wrapper(self, *args, **kwargs):\n            if not self._flag_built:\n                raise OptUtilitiesError(\n                    f\"You must specify the dimensionality of the optimisation problem before using {func.__name__}.\"\n                )\n            func(self, *args, **kwargs)\n\n        return wrapper",
  "def _setup_teardown(self):\n        \"\"\"\n        Setup / teardown the wrapper (phoenix design pattern).\n        \"\"\"\n        self.n_evals = 0\n        self.optimum_value = None\n        self._f_objective = None\n        self.lower_bounds = None\n        self.upper_bounds = None\n        self.constraints = []\n        self.constraint_tols = []",
  "def algorithm_name(self) -> str:\n        \"\"\"\n        Name of the optimisation algorithm.\n        \"\"\"\n        return self._algorithm_name",
  "def algorithm_name(self, name: str):\n        \"\"\"\n        Setter for the name of the optimisation algorithm.\n\n        Parameters\n        ----------\n        name:\n            Name of the optimisation algorithm\n\n        Raises\n        ------\n        OptUtilitiesError:\n            If the algorithm is not recognised\n        \"\"\"\n        if name not in NLOPT_ALG_MAPPING:\n            raise OptUtilitiesError(f\"Unknown or unmapped algorithm: {name}\")\n        self._algorithm_name = name",
  "def build_optimiser(self, n_variables: Optional[int]):\n        \"\"\"\n        Build the underlying optimisation algorithm.\n\n        Parameters\n        ----------\n        n_variables:\n            Dimension of the optimisation problem. If None, the algorithm is not built.\n        \"\"\"\n        self.n_variables = n_variables\n        if n_variables is None:\n            return\n\n        self._set_algorithm(n_variables)\n        self._flag_built = True\n        self.set_termination_conditions(self.opt_conditions)\n        self.set_algorithm_parameters(self.opt_parameters)\n        self._setup_teardown()",
  "def _append_constraint_tols(self, constraint, tolerance):\n        \"\"\"\n        Append constraint function and tolerances.\n        \"\"\"\n        self.constraints.append(constraint)\n        self.constraint_tols.append(tolerance)",
  "def _set_algorithm(self, n_variables):\n        \"\"\"\n        Initialise the underlying NLOPT algorithm.\n        \"\"\"\n        algorithm = NLOPT_ALG_MAPPING[self.algorithm_name]\n        self._opt = nlopt.opt(algorithm, n_variables)",
  "def set_algorithm_parameters(self, opt_parameters: Dict[str, float]):\n        \"\"\"\n        Set the optimisation algorithm parameters to use.\n\n        Parameters\n        ----------\n        opt_parameters:\n            Optimisation algorithm parameters to use\n        \"\"\"\n        if opt_parameters is None:\n            return\n\n        for k, v in opt_parameters.items():\n            if self._opt.has_param(k):\n                self._opt.set_param(k, v)\n            elif k == \"initial_step\":\n                self._opt.set_initial_step(v)\n            else:\n                bluemira_warn(f\"Unrecognised algorithm parameter: {k}\")",
  "def set_termination_conditions(self, opt_conditions: Dict[str, float]):\n        \"\"\"\n        Set the optimisation algorithm termination condition(s) to use.\n\n        Parameters\n        ----------\n        opt_conditions:\n            Termination conditions for the optimisation algorithm\n        \"\"\"\n        if opt_conditions is None:\n            return\n\n        conditions = process_NLOPT_conditions(opt_conditions)\n\n        if \"ftol_abs\" in conditions:\n            self._opt.set_ftol_abs(conditions[\"ftol_abs\"])\n        if \"ftol_rel\" in opt_conditions:\n            self._opt.set_ftol_rel(conditions[\"ftol_rel\"])\n        if \"xtol_abs\" in opt_conditions:\n            self._opt.set_xtol_abs(conditions[\"xtol_abs\"])\n        if \"xtol_rel\" in opt_conditions:\n            self._opt.set_xtol_rel(conditions[\"xtol_rel\"])\n        if \"max_time\" in opt_conditions:\n            self._opt.set_maxtime(conditions[\"max_time\"])\n        if \"max_eval\" in opt_conditions:\n            self._opt.set_maxeval(conditions[\"max_eval\"])\n        if \"stop_val\" in opt_conditions:\n            self._opt.set_stopval(conditions[\"stop_val\"])",
  "def set_objective_function(self, f_objective: Callable[[Any], float]):\n        \"\"\"\n        Set the objective function (minimisation).\n\n        Parameters\n        ----------\n        f_objective:\n            Objective function to minimise\n        \"\"\"\n        f_objective = _NLOPTObjectiveFunction(f_objective)\n        self._f_objective = f_objective\n        self._opt.set_min_objective(f_objective)",
  "def set_lower_bounds(self, lower_bounds: np.ndarray):\n        \"\"\"\n        Set the lower bounds.\n\n        Parameters\n        ----------\n        lower_bounds:\n            Lower bound vector\n        \"\"\"\n        self.lower_bounds = lower_bounds\n        self._opt.set_lower_bounds(lower_bounds)",
  "def set_upper_bounds(self, upper_bounds: np.ndarray):\n        \"\"\"\n        Set the upper bounds.\n\n        Parameters\n        ----------\n        upper_bounds:\n            Upper bound vector\n        \"\"\"\n        self.upper_bounds = upper_bounds\n        self._opt.set_upper_bounds(upper_bounds)",
  "def add_eq_constraints(\n        self, f_constraint: Callable[[Any], np.ndarray], tolerance: float\n    ):\n        \"\"\"\n        Add a vector-valued equality constraint.\n\n        Parameters\n        ----------\n        f_constraint:\n            Constraint function\n        tolerance:\n            Tolerance with which to enforce the constraint\n        \"\"\"\n        if self.algorithm_name not in EQ_CON_ALGS:\n            raise OptUtilitiesError(\n                f\"{self.algorithm_name} does not support equality constraints.\"\n            )\n\n        self._opt.add_equality_mconstraint(f_constraint, tolerance)\n        self._append_constraint_tols(f_constraint, tolerance)",
  "def add_ineq_constraints(\n        self, f_constraint: Callable[[Any], np.ndarray], tolerance: float\n    ):\n        \"\"\"\n        Add a vector-valued inequality constraint.\n\n        Parameters\n        ----------\n        f_constraint:\n            Constraint function\n        tolerance:\n            Tolerance array with which to enforce the constraint\n        \"\"\"\n        if self.algorithm_name not in INEQ_CON_ALGS:\n            raise OptUtilitiesError(\n                f\"{self.algorithm_name} does not support inequality constraints.\"\n            )\n\n        self._opt.add_inequality_mconstraint(f_constraint, tolerance)\n        self._append_constraint_tols(f_constraint, tolerance)",
  "def optimise(self, x0: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Run the optimiser.\n\n        Parameters\n        ----------\n        x0:\n            Starting solution vector\n\n        Returns\n        -------\n        Optimal solution vector\n        \"\"\"\n        if self._f_objective is None:\n            raise OptUtilitiesError(\n                \"You must first specify an objective function before performing the optimisation.\"\n            )\n\n        if x0 is None:\n            x0 = np.zeros(self.n_variables)\n\n        try:\n            x_star = self._opt.optimize(x0)\n\n        except nlopt.RoundoffLimited:\n            # It's likely that the last call was still a reasonably good solution.\n            self.optimum_value = self._opt.last_optimum_value()\n            x_star = self._f_objective.last_x\n\n        except OptVariablesError:\n            # Probably still some rounding errors due to numerical gradients\n            # It's likely that the last call was still a reasonably good solution.\n            bluemira_warn(\"Badly behaved numerical gradients are causing trouble...\")\n            self.optimum_value = self._opt.last_optimum_value()\n            x_star = np.round(self._f_objective.last_x, 6)\n\n        except RuntimeError as error:\n            # Usually \"more than iter SQP iterations\"\n            self.optimum_value = self._opt.last_optimum_value()\n            self.n_evals = self._opt.get_numevals()\n            process_NLOPT_result(self._opt)\n            raise ExternalOptError(str(error))\n\n        except KeyboardInterrupt:\n            self.optimum_value = self._opt.last_optimum_value()\n            self.n_evals = self._opt.get_numevals()\n            process_NLOPT_result(self._opt)\n            raise KeyboardInterrupt(\n                \"The optimisation was halted by the user. Please check \"\n                \"your optimisation problem and termination conditions.\"\n            )\n\n        self.optimum_value = self._opt.last_optimum_value()\n        self.n_evals = self._opt.get_numevals()\n        process_NLOPT_result(self._opt)\n        return x_star",
  "def wrapper(self, *args, **kwargs):\n            if not self._flag_built:\n                raise OptUtilitiesError(\n                    f\"You must specify the dimensionality of the optimisation problem before using {func.__name__}.\"\n                )\n            func(self, *args, **kwargs)",
  "def catch_caderr(new_error_type):\n    \"\"\"\n    Catch CAD errors with given error\n    \"\"\"\n\n    def argswrap(func):\n        def wrapper(*args, **kwargs):\n            try:\n                return func(*args, **kwargs)\n            except FreeCADError as fe:\n                raise new_error_type(fe.args[0]) from fe\n\n        return wrapper\n\n    return argswrap",
  "def arrange_edges(old_wire: apiWire, new_wire: apiWire) -> apiWire:\n    \"\"\"\n    A helper to try and fix some topological naming issues.\n    Tries to arrange edges as they were in the old wire\n\n    Parameters\n    ----------\n    old_wire:\n        old wire to emulate edges from\n    new_wire:\n        new wire to change edge arrangement\n\n    Returns\n    -------\n    Wire with arranged edges\n    \"\"\"\n    old_edges = Part.sortEdges(old_wire.Edges)[0]\n    new_edges = Part.sortEdges(new_wire.Edges)[0]\n    for old_edge in old_edges:\n        for new_edge in new_edges:\n            if old_edge.Orientation != new_edge.Orientation:\n                apiEdge.reverse(new_edge)\n    return apiWire(new_edges)",
  "def check_data_type(data_type):\n    \"\"\"\n    Decorator to check the data type of the first parameter input (args[0]) of a\n    function.\n\n    Raises\n    ------\n    TypeError: If args[0] objects are not instances of data_type\n    \"\"\"\n\n    def _apply_to_list(func):\n        def wrapper(*args, **kwargs):\n            output = []\n            objs = args[0]\n            is_list = isinstance(objs, list)\n            if not is_list:\n                objs = [objs]\n                if len(args) > 1:\n                    args = [objs, args[1:]]\n                else:\n                    args = [objs]\n            if all(isinstance(o, data_type) for o in objs):\n                output = func(*args, **kwargs)\n                if not is_list:\n                    output = output[0]\n            else:\n                raise TypeError(\n                    f\"Only {data_type} instances can be converted to {type(output)}\"\n                )\n            return output\n\n        return wrapper\n\n    return _apply_to_list",
  "def vector_to_list(vectors: List[apiVector]) -> List[List[float]]:\n    \"\"\"Converts a FreeCAD Base.Vector or list(Base.Vector) into a list\"\"\"\n    return [list(v) for v in vectors]",
  "def point_to_list(points: List[Part.Point]) -> List[List[float]]:\n    \"\"\"Converts a FreeCAD Part.Point or list(Part.Point) into a list\"\"\"\n    return [[p.X, p.Y, p.Z] for p in points]",
  "def vertex_to_list(vertexes: List[apiVertex]) -> List[List[float]]:\n    \"\"\"Converts a FreeCAD Part.Vertex or list(Part.Vertex) into a list\"\"\"\n    return [[v.X, v.Y, v.Z] for v in vertexes]",
  "def vector_to_numpy(vectors: List[apiVector]) -> np.ndarray:\n    \"\"\"Converts a FreeCAD Base.Vector or list(Base.Vector) into a numpy array\"\"\"\n    return np.array([np.array(v) for v in vectors])",
  "def point_to_numpy(points: List[Part.Point]) -> np.ndarray:\n    \"\"\"Converts a FreeCAD Part.Point or list(Part.Point) into a numpy array\"\"\"\n    return np.array([np.array([p.X, p.Y, p.Z]) for p in points])",
  "def vertex_to_numpy(vertexes: List[apiVertex]) -> np.ndarray:\n    \"\"\"Converts a FreeCAD Part.Vertex or list(Part.Vertex) into a numpy array\"\"\"\n    return np.array([np.array([v.X, v.Y, v.Z]) for v in vertexes])",
  "def make_solid(shell: apiShell) -> apiSolid:\n    \"\"\"Make a solid from a shell.\"\"\"\n    return Part.makeSolid(shell)",
  "def make_shell(faces: List[apiFace]) -> apiShell:\n    \"\"\"Make a shell from faces.\"\"\"\n    return Part.makeShell(faces)",
  "def make_compound(shapes: List[apiShape]) -> apiCompound:\n    \"\"\"\n    Make an FreeCAD compound object out of many shapes\n\n    Parameters\n    ----------\n    shapes:\n        A set of objects to be compounded\n\n    Returns\n    -------\n    A compounded set of shapes\n    \"\"\"\n    return Part.makeCompound(shapes)",
  "def make_polygon(points: Union[list, np.ndarray]) -> apiWire:\n    \"\"\"\n    Make a polygon from a set of points.\n\n    Parameters\n    ----------\n    points:\n        list of points. It can be given as a list of 3D tuples, a 3D numpy array,\n        or similar.\n\n    Returns\n    -------\n    A FreeCAD wire that contains the polygon\n    \"\"\"\n    # Points must be converted into FreeCAD Vectors\n    pntslist = [Base.Vector(x) for x in points]\n    wire = Part.makePolygon(pntslist)\n    return wire",
  "def make_bezier(points: Union[list, np.ndarray]) -> apiWire:\n    \"\"\"\n    Make a bezier curve from a set of points.\n\n    Parameters\n    ----------\n    points:\n        list of points. It can be given as a list of 3D tuples, a 3D numpy array,\n        or similar.\n\n    Returns\n    -------\n    A FreeCAD wire that contains the bezier curve\n    \"\"\"\n    # Points must be converted into FreeCAD Vectors\n    pntslist = [Base.Vector(x) for x in points]\n    bc = Part.BezierCurve()\n    bc.setPoles(pntslist)\n    wire = Part.Wire(bc.toShape())\n    return wire",
  "def make_bspline(\n    poles: np.ndarray,\n    mults: np.ndarray,\n    knots: np.ndarray,\n    periodic: bool,\n    degree: int,\n    weights: np.ndarray,\n    check_rational: bool,\n) -> apiWire:\n    \"\"\"\n    Builds a B-Spline by a lists of Poles, Mults, Knots\n\n    Parameters\n    ----------\n    poles:\n        list of poles.\n    mults:\n        list of integers for the multiplicity\n    knots:\n        list of knots\n    periodic:\n        Whether or not the spline is periodic (same curvature at start and end points)\n    degree: int\n        bspline degree\n    weights:\n        sequence of float\n    check_rational:\n        Whether or not to check if the BSpline is rational (not sure)\n\n    Returns\n    -------\n    A FreeCAD wire that contains the bspline curve\n\n    Notes\n    -----\n    This function wraps the FreeCAD function of bsplines buildFromPolesMultsKnots\n    \"\"\"\n    poles = [Base.Vector(p) for p in poles]\n    bspline = Part.BSplineCurve()\n    bspline.buildFromPolesMultsKnots(\n        poles, mults, knots, periodic, degree, weights, check_rational\n    )\n    wire = apiWire(bspline.toShape())\n    return wire",
  "def interpolate_bspline(\n    points: Union[list, np.ndarray],\n    closed: bool = False,\n    start_tangent: Optional[Iterable] = None,\n    end_tangent: Optional[Iterable] = None,\n) -> apiWire:\n    \"\"\"\n    Make a B-Spline curve by interpolating a set of points.\n\n    Parameters\n    ----------\n    points:\n        list of points. It can be given as a list of 3D tuples, a 3D numpy array,\n        or similar.\n    closed:\n        if True, the first and last points will be connected in order to form a\n        closed shape.\n    start_tangent:\n        Tangency of the BSpline at the first pole. Must be specified with end_tangent\n    end_tangent:\n        Tangency of the BSpline at the last pole. Must be specified with start_tangent\n\n    Returns\n    -------\n    A FreeCAD wire that contains the bspline curve\n    \"\"\"\n    # In this case, it is not really necessary to convert points in FreeCAD vector. Just\n    # left for consistency with other methods.\n    pntslist = [Base.Vector(x) for x in points]\n\n    # Recreate checks that are made in freecad/src/MOD/Draft/draftmake/make_bspline.py\n    # function make_bspline, line 75\n\n    if len(pntslist) < 2:\n        _err = \"interpolate_bspline: not enough points\"\n        raise InvalidCADInputsError(_err + \"\\n\")\n    if np.allclose(pntslist[0], pntslist[-1], rtol=0, atol=EPS):\n        if len(pntslist) > 2:\n            if not closed:\n                bluemira_warn(\"interpolate_bspline: equal endpoints forced Closed\")\n            closed = True\n            pntslist.pop()\n        else:\n            # len == 2 and first == last\n            _err = \"interpolate_bspline: Invalid pointslist (len == 2 and first == last)\"\n            raise InvalidCADInputsError(_err)\n\n    kwargs = {}\n    if start_tangent and end_tangent:\n        kwargs[\"InitialTangent\"] = Base.Vector(start_tangent)\n        kwargs[\"FinalTangent\"] = Base.Vector(end_tangent)\n\n    if start_tangent and not end_tangent or end_tangent and not start_tangent:\n        bluemira_warn(\n            \"You must set both start and end tangencies or neither when creating a \"\n            \"bspline. Start and end tangencies ignored.\"\n        )\n\n    try:\n        bsc = Part.BSplineCurve()\n        bsc.interpolate(pntslist, PeriodicFlag=closed, **kwargs)\n        wire = apiWire(bsc.toShape())\n    except Part.OCCError as error:\n        msg = \"\\n\".join(\n            [\n                \"FreeCAD was unable to make a spline:\",\n                f\"{error.args[0]}\",\n            ]\n        )\n        raise FreeCADError(msg) from error\n    return wire",
  "def make_circle(\n    radius: float = 1.0,\n    center: Iterable[float] = [0.0, 0.0, 0.0],\n    start_angle: float = 0.0,\n    end_angle: float = 360.0,\n    axis: Iterable[float] = [0.0, 0.0, 1.0],\n) -> apiWire:\n    \"\"\"\n    Create a circle or arc of circle object with given parameters.\n\n    Parameters\n    ----------\n    radius:\n        Radius of the circle\n    center:\n        Center of the circle\n    start_angle:\n        Start angle of the arc [degrees]\n    end_angle:\n        End angle of the arc [degrees]. If start_angle == end_angle, a circle is created,\n        otherwise a circle arc is created\n    axis:\n        Normal vector to the circle plane. It defines the clockwise/anticlockwise\n        circle orientation according to the right hand rule. Default [0., 0., 1.].\n\n    Returns\n    -------\n    FreeCAD wire that contains the arc or circle\n    \"\"\"\n    # TODO: check the creation of the arc when start_angle < end_angle\n    output = Part.Circle()\n    output.Radius = radius\n    output.Center = Base.Vector(center)\n    output.Axis = Base.Vector(axis)\n    if start_angle != end_angle:\n        output = Part.ArcOfCircle(\n            output, math.radians(start_angle), math.radians(end_angle)\n        )\n    return Part.Wire(Part.Edge(output))",
  "def make_circle_arc_3P(  # noqa: N802\n    p1: Iterable[float], p2: Iterable[float], p3: Iterable[float]\n) -> apiWire:\n    \"\"\"\n    Create an arc of circle object given three points.\n\n    Parameters\n    ----------\n    p1:\n        Starting point of the circle arc\n    p2:\n        Middle point of the circle arc\n    p3:\n        End point of the circle arc\n\n    Returns\n    -------\n    FreeCAD wire that contains the arc of circle\n    \"\"\"\n    # TODO: check what happens when the 3 points are in a line\n    arc = Part.ArcOfCircle(Base.Vector(p1), Base.Vector(p2), Base.Vector(p3))\n\n    # next steps are made to create an arc of circle that is consistent with that\n    # created by 'make_circle'\n    output = Part.Circle()\n    output.Radius = arc.Radius\n    output.Center = arc.Center\n    output.Axis = arc.Axis\n    arc = Part.ArcOfCircle(\n        output, output.parameter(arc.StartPoint), output.parameter(arc.EndPoint)\n    )\n\n    return Part.Wire(Part.Edge(arc))",
  "def make_ellipse(\n    center: Iterable[float] = [0.0, 0.0, 0.0],\n    major_radius: float = 2.0,\n    minor_radius: float = 1.0,\n    major_axis: Iterable[float] = [1, 0, 0],\n    minor_axis: Iterable[float] = [0, 1, 0],\n    start_angle: float = 0.0,\n    end_angle: float = 360.0,\n) -> apiWire:\n    \"\"\"\n    Creates an ellipse or arc of ellipse object with given parameters.\n\n    Parameters\n    ----------\n    center:\n        Center of the ellipse\n    major_radius:\n        the major radius of the ellipse\n    minor_radius:\n        the minor radius of the ellipse\n    major_axis:\n        major axis direction\n    minor_axis:\n        minor axis direction\n    start_angle:\n        Start angle of the arc [degrees]\n    end_angle:\n        End angle of the arc [degrees]. If start_angle == end_angle, an ellipse is\n        created, otherwise an arc of ellipse is created\n\n    Returns\n    -------\n    FreeCAD wire that contains the ellipse or arc of ellipse\n    \"\"\"\n    # TODO: check the creation of the arc when start_angle < end_angle\n    s1 = Base.Vector(major_axis).normalize().multiply(major_radius) + Base.Vector(center)\n    s2 = Base.Vector(minor_axis).normalize().multiply(minor_radius) + Base.Vector(center)\n    center = Base.Vector(center)\n    output = Part.Ellipse(s1, s2, center)\n\n    start_angle = start_angle % 360.0\n    end_angle = end_angle % 360.0\n\n    if start_angle != end_angle:\n        output = Part.ArcOfEllipse(\n            output, math.radians(start_angle), math.radians(end_angle)\n        )\n\n    return Part.Wire(Part.Edge(output))",
  "class JoinType(enum.IntEnum):\n    \"\"\"See Part/PartEnums.py, its not importable\"\"\"\n\n    Arc = 0\n    Tangent = 1\n    Intersect = 2",
  "def offset_wire(\n    wire: apiWire, thickness: float, join: str = \"intersect\", open_wire: bool = True\n) -> apiWire:\n    \"\"\"\n    Make an offset from a wire.\n\n    Parameters\n    ----------\n    wire:\n        Wire to offset from\n    thickness:\n        Offset distance. Positive values outwards, negative values inwards\n    join:\n        Offset method. \"arc\" gives rounded corners, and \"intersect\" gives sharp corners\n    open_wire:\n        For open wires (counter-clockwise default) whether or not to make an open offset\n        wire, or a closed offset wire that encompasses the original wire. This is\n        disabled for closed wires.\n\n    Returns\n    -------\n    Offset wire\n    \"\"\"\n    if thickness == 0.0:\n        return deepcopy(wire)\n\n    if _wire_is_straight(wire):\n        raise InvalidCADInputsError(\"Cannot offset a straight line.\")\n\n    if not _wire_is_planar(wire):\n        raise InvalidCADInputsError(\"Cannot offset a non-planar wire.\")\n\n    f_join = JoinType[join.lower().capitalize()]\n    if f_join is JoinType.Tangent:\n        # NOTE: The \"tangent\": 1 option misbehaves in FreeCAD\n        bluemira_warn(\n            f\"Join type: {join} is unstable.\"\n            \" Please consider using from ['arc', 'intersect'].\"\n        )\n\n    if wire.isClosed() and open_wire:\n        open_wire = False\n\n    shape = apiShape(wire)\n    try:\n        wire = arrange_edges(\n            wire, shape.makeOffset2D(thickness, f_join.value, False, open_wire)\n        )\n    except Base.FreeCADError as error:\n        msg = \"\\n\".join(\n            [\n                \"FreeCAD was unable to make an offset of wire:\",\n                f\"{error.args[0]['sErrMsg']}\",\n            ]\n        )\n        raise FreeCADError(msg)\n\n    fix_wire(wire)\n    return wire",
  "def make_face(wire: apiWire) -> apiFace:\n    \"\"\"\n    Make a face given a wire boundary.\n\n    Parameters\n    ----------\n    wire:\n        Wire boundary from which to make a face\n\n    Returns\n    -------\n    Face created from the wire boundary\n\n    Raises\n    ------\n    FreeCADError\n        If the created face is invalid\n    \"\"\"\n    face = apiFace(wire)\n    if face.isValid():\n        return face\n    else:\n        face.fix(WORKING_PRECISION, MIN_PRECISION, MAX_PRECISION)\n        if face.isValid():\n            return face\n        else:\n            raise FreeCADError(\"An invalid face has been generated\")",
  "def _get_api_attr(obj: apiShape, prop: str):\n    try:\n        return getattr(obj, prop)\n    except AttributeError:\n        raise FreeCADError(f\"FreeCAD object {obj} does not have an attribute: {prop}\")",
  "def length(obj: apiShape) -> float:\n    \"\"\"Object's length\"\"\"\n    return _get_api_attr(obj, \"Length\")",
  "def area(obj: apiShape) -> float:\n    \"\"\"Object's Area\"\"\"\n    return _get_api_attr(obj, \"Area\")",
  "def volume(obj: apiShape) -> float:\n    \"\"\"Object's volume\"\"\"\n    return _get_api_attr(obj, \"Volume\")",
  "def center_of_mass(obj: apiShape) -> np.ndarray:\n    \"\"\"Object's center of mass\"\"\"\n    return vector_to_numpy(_get_api_attr(obj, \"CenterOfMass\"))",
  "def is_null(obj: apiShape) -> bool:\n    \"\"\"True if obj is null\"\"\"\n    return _get_api_attr(obj, \"isNull\")()",
  "def is_closed(obj: apiShape) -> bool:\n    \"\"\"True if obj is closed\"\"\"\n    return _get_api_attr(obj, \"isClosed\")()",
  "def is_valid(obj) -> bool:\n    \"\"\"True if obj is valid\"\"\"\n    return _get_api_attr(obj, \"isValid\")()",
  "def is_same(obj1: apiShape, obj2: apiShape) -> bool:\n    \"\"\"True if obj1 and obj2 have the same shape.\"\"\"\n    return obj1.isSame(obj2)",
  "def bounding_box(obj: apiShape) -> Tuple[float, float, float, float, float, float]:\n    \"\"\"Object's bounding box\"\"\"\n    box = _get_api_attr(obj, \"BoundBox\")\n    return box.XMin, box.YMin, box.ZMin, box.XMax, box.YMax, box.ZMax",
  "def tessellate(obj: apiShape, tolerance: float) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Tessellate a geometry object.\n\n    Parameters\n    ----------\n    obj:\n        Shape to tessellate\n    tolerance:\n        Tolerance with which to perform the operation\n\n    Raises\n    ------\n    ValueError:\n        If the tolerance is <= 0.0\n\n    Returns\n    -------\n    vertices:\n        Array of the vertices (N, 3, dtype=float) from the tesselation operation\n    indices:\n        Array of the indices (M, 3, dtype=int) from the tesselation operation\n\n    Notes\n    -----\n    Once tesselated an object's properties may change. Tesselation cannot be reverted\n    to a previous lower value, but can be increased (irreversibly).\n    \"\"\"\n    if tolerance <= 0.0:\n        raise ValueError(\"Cannot have a tolerance that is less than or equal to 0.0\")\n\n    vectors, indices = obj.tessellate(tolerance)\n    return vector_to_numpy(vectors), np.array(indices)",
  "def start_point(obj: apiShape) -> np.ndarray:\n    \"\"\"The start point of the object\"\"\"\n    point = obj.Edges[0].firstVertex().Point\n    return vector_to_numpy(point)",
  "def end_point(obj: apiShape) -> np.ndarray:\n    \"\"\"The end point of the object\"\"\"\n    point = obj.Edges[-1].lastVertex().Point\n    return vector_to_numpy(point)",
  "def ordered_vertexes(obj: apiShape) -> np.ndarray:\n    \"\"\"Ordered vertexes of the object\"\"\"\n    vertexes = _get_api_attr(obj, \"OrderedVertexes\")\n    return vertex_to_numpy(vertexes)",
  "def vertexes(obj: apiShape) -> np.ndarray:\n    \"\"\"Wires of the object\"\"\"\n    vertexes = _get_api_attr(obj, \"Vertexes\")\n    return vertex_to_numpy(vertexes)",
  "def orientation(obj: apiShape) -> bool:\n    \"\"\"True if obj is valid\"\"\"\n    return _get_api_attr(obj, \"Orientation\")",
  "def edges(obj: apiShape) -> list[apiWire]:\n    \"\"\"Edges of the object\"\"\"\n    return _get_api_attr(obj, \"Edges\")",
  "def ordered_edges(obj: apiShape) -> np.ndarray:\n    \"\"\"Ordered edges of the object\"\"\"\n    return _get_api_attr(obj, \"OrderedEdges\")",
  "def wires(obj: apiShape) -> list[apiWire]:\n    \"\"\"Wires of the object\"\"\"\n    return _get_api_attr(obj, \"Wires\")",
  "def faces(obj: apiShape) -> list[apiFace]:\n    \"\"\"Faces of the object\"\"\"\n    return _get_api_attr(obj, \"Faces\")",
  "def shells(obj: apiShape) -> list[apiShell]:\n    \"\"\"Shells of the object\"\"\"\n    return _get_api_attr(obj, \"Shells\")",
  "def solids(obj: apiShape) -> list[apiSolid]:\n    \"\"\"Solids of the object\"\"\"\n    return _get_api_attr(obj, \"Solids\")",
  "def normal_at(face: apiFace, alpha_1: float = 0.0, alpha_2: float = 0.0) -> np.ndarray:\n    \"\"\"\n    Get the normal vector of the face at a parameterised point in space. For\n    planar faces, the normal is the same everywhere.\n    \"\"\"\n    return np.array(face.normalAt(alpha_1, alpha_2))",
  "def wire_closure(wire: apiWire) -> apiWire:\n    \"\"\"Create a line segment wire that closes an open wire\"\"\"\n    closure = None\n    if not wire.isClosed():\n        vertexes = wire.OrderedVertexes\n        points = [v.Point for v in vertexes]\n        closure = make_polygon([points[-1], points[0]])\n    return closure",
  "def close_wire(wire: apiWire) -> apiWire:\n    \"\"\"\n    Closes a wire with a line segment, if not already closed.\n    A new wire is returned.\n    \"\"\"\n    if not wire.isClosed():\n        vertexes = wire.OrderedVertexes\n        points = [v.Point for v in vertexes]\n        wline = make_polygon([points[-1], points[0]])\n        wire = Part.Wire([wire, wline])\n    return wire",
  "def discretize(w: apiWire, ndiscr: int = 10, dl: Optional[float] = None) -> np.ndarray:\n    \"\"\"\n    Discretize a wire.\n\n    Parameters\n    ----------\n    w:\n        wire to be discretized.\n    ndiscr:\n        number of points for the whole wire discretization.\n    dl:\n        target discretization length (default None). If dl is defined,\n        ndiscr is not considered.\n\n    Returns\n    -------\n    Array of points\n\n    Raises\n    ------\n    ValueError:\n        If ndiscr < 2\n        If dl <= 0.0\n    \"\"\"\n    if dl is None:\n        if ndiscr < 2:\n            raise ValueError(\"ndiscr must be greater than 2.\")\n    elif dl <= 0.0:\n        raise ValueError(\"dl must be > 0.\")\n    else:\n        # a dl is calculated for the discretisation of the different edges\n        # NOTE: must discretise to at least two points.\n        ndiscr = max(math.ceil(w.Length / dl + 1), 2)\n\n    # discretization points array\n    output = w.discretize(ndiscr)\n    output = vector_to_numpy(output)\n\n    if w.isClosed():\n        output[-1] = output[0]\n    return output",
  "def discretize_by_edges(\n    w: apiWire, ndiscr: int = 10, dl: Optional[float] = None\n) -> np.ndarray:\n    \"\"\"\n    Discretize a wire taking into account the edges of which it consists of.\n\n    Parameters\n    ----------\n    w:\n        Wire to be discretized.\n    ndiscr:\n        Number of points for the whole wire discretization.\n    dl:\n        Target discretization length (default None). If dl is defined,\n        ndiscr is not considered.\n\n    Returns\n    -------\n    Array of points\n\n    Notes\n    -----\n    Final number of points can be slightly different due to edge discretization\n    routine.\n    \"\"\"\n    # discretization points array\n    output = []\n\n    if dl is None:\n        # dl is calculated for the discretisation of the different edges\n        dl = w.Length / float(ndiscr)\n    elif dl <= 0.0:\n        raise ValueError(\"dl must be > 0.\")\n\n    # edges are discretised taking into account their orientation\n    # Note: OrderedEdges already return a list of edges that considers the edge in the\n    # correct sequence and orientation. No need for tricks after the discretization.\n    for e in w.OrderedEdges:\n        pointse = list(discretize(apiWire(e), dl=dl))\n        output += pointse[:-1]\n\n    if w.isClosed():\n        output += [output[0]]\n    else:\n        output += [pointse[-1]]\n\n    output = np.array(output)\n    return output",
  "def dist_to_shape(\n    shape1: apiShape, shape2: apiShape\n) -> Tuple[float, List[Tuple[np.ndarray, np.ndarray]]]:\n    \"\"\"\n    Find the minimum distance between two shapes\n\n    Parameters\n    ----------\n    shape1:\n        reference shape.\n    shape2:\n        target shape.\n\n    Returns\n    -------\n    dist:\n        Minimum distance\n    vectors:\n        List of tuples corresponding to the nearest points (numpy.ndarray)\n        between shape1 and shape2. The distance between those points is the minimum\n        distance given by dist.\n    \"\"\"\n    dist, solution, info = shape1.distToShape(shape2)\n    vectors = []\n    for v1, v2 in solution:\n        vectors.append((vector_to_numpy(v1), vector_to_numpy(v2)))\n    return dist, vectors",
  "def wire_value_at(wire: apiWire, distance: float) -> np.ndarray:\n    \"\"\"\n    Get a point a given distance along a wire.\n\n    Parameters\n    ----------\n    wire:\n        Wire along which to get a point\n    distance:\n        Distance\n\n    Returns\n    -------\n    Wire point value at distance\n    \"\"\"\n    if distance == 0.0:\n        return start_point(wire)\n    elif distance == wire.Length:\n        return end_point(wire)\n    elif distance < 0.0:\n        bluemira_warn(\"Distance must be greater than 0; returning start point.\")\n        return start_point(wire)\n    elif distance > wire.Length:\n        bluemira_warn(\"Distance greater than the length of wire; returning end point.\")\n        return end_point(wire)\n\n    length = 0\n    for edge in wire.OrderedEdges:\n        edge_length = edge.Length\n        new_length = length + edge_length\n        if new_length < distance:\n            length = new_length\n        elif new_length == distance:\n            point = edge.valueAt(edge.LastParameter)\n            break\n        else:\n            new_distance = distance - length\n            parameter = edge.getParameterByLength(new_distance)\n            point = edge.valueAt(parameter)\n            break\n\n    return np.array(point)",
  "def wire_parameter_at(\n    wire: apiWire, vertex: Iterable[float], tolerance: float = EPS * 10\n) -> float:\n    \"\"\"\n    Get the parameter value at a vertex along a wire.\n\n    Parameters\n    ----------\n    wire:\n        Wire along which to get the parameter\n    vertex:\n        Vertex for which to get the parameter\n    tolerance:\n        Tolerance within which to get the parameter\n\n    Returns\n    -------\n    Parameter value along the wire at the vertex\n\n    Raises\n    ------\n    FreeCADError:\n        If the vertex is further away to the wire than the specified tolerance\n    \"\"\"\n    split_wire_1, _ = split_wire(wire, vertex, tolerance)\n    if split_wire_1:\n        return split_wire_1.Length / wire.Length\n    else:\n        return 0.0",
  "def split_wire(\n    wire: apiWire, vertex: Iterable[float], tolerance: float\n) -> Tuple[Union[None, apiWire], Union[None, apiWire]]:\n    \"\"\"\n    Split a wire at a given vertex.\n\n    Parameters\n    ----------\n    wire:\n        Wire to be split\n    vertex:\n        Vertex at which to split the wire\n    tolerance:\n        Tolerance within which to find the closest vertex on the wire\n\n    Returns\n    -------\n    wire_1:\n        First half of the wire. Will be None if the vertex is the start point of the wire\n    wire_2:\n        Last half of the wire. Will be None if the vertex is the start point of the wire\n\n    Raises\n    ------\n    FreeCADError:\n        If the vertex is further away to the wire than the specified tolerance\n    \"\"\"\n\n    def warning_msg():\n        bluemira_warn(\n            \"Wire split operation only returning one wire; you are splitting at an end.\"\n        )\n\n    vertex = apiVertex(*vertex)\n    distance, points, _ = wire.distToShape(vertex)\n    if distance > tolerance:\n        raise FreeCADError(\n            f\"Vertex is not close enough to the wire, with a distance: {distance} > {tolerance}\"\n        )\n\n    edges = wire.OrderedEdges\n    idx = _get_closest_edge_idx(wire, vertex)\n\n    edges_1, edges_2 = [], []\n    for i, edge in enumerate(edges):\n        if i < idx:\n            edges_1.append(edge)\n        elif i == idx:\n            parameter = edge.Curve.parameter(points[0][0])\n            half_edge_1, half_edge_2 = _split_edge(edge, parameter)\n            if half_edge_1:\n                edges_1.append(half_edge_1)\n            if half_edge_2:\n                edges_2.append(half_edge_2)\n        else:\n            edges_2.append(edge)\n\n    if edges_1:\n        wire_1 = apiWire(edges_1)\n    else:\n        wire_1 = None\n        warning_msg()\n\n    if edges_2:\n        wire_2 = apiWire(edges_2)\n    else:\n        wire_2 = None\n        warning_msg()\n\n    return wire_1, wire_2",
  "def _split_edge(edge, parameter):\n    p0, p1 = edge.ParameterRange[0], edge.ParameterRange[1]\n    if parameter == p0:\n        return None, edge\n    if parameter == p1:\n        return edge, None\n\n    return edge.Curve.toShape(p0, parameter), edge.Curve.toShape(parameter, p1)",
  "def _get_closest_edge_idx(wire, vertex):\n    _, points, _ = wire.distToShape(vertex)\n    closest_vector = points[0][0]\n    closest_vertex = apiVertex(closest_vector)\n    distances = [edge.distToShape(closest_vertex)[0] for edge in wire.OrderedEdges]\n    idx = np.argmin(distances)\n    return idx",
  "def slice_shape(\n    shape: apiShape, plane_origin: Iterable[float], plane_axis: Iterable[float]\n):\n    \"\"\"\n    Slice a shape along a given plane\n\n    TODO improve face-solid-shell interface\n\n    Parameters\n    ----------\n    shape:\n        shape to slice\n    plane_origin:\n        plane origin\n    plane_axis:\n        normal plane axis\n\n    Notes\n    -----\n    Degenerate cases such as tangents to solid or faces do not return intersections\n    if the shape and plane are acting at the Plane base.\n    Further investigation needed.\n\n    \"\"\"\n    if isinstance(shape, apiWire):\n        return _slice_wire(shape, plane_axis, plane_origin)\n    else:\n        if not isinstance(shape, (apiFace, apiSolid)):\n            bluemira_warn(\"The output structure of this function may not be as expected\")\n        shift = np.dot(np.array(plane_origin), np.array(plane_axis))\n        return _slice_solid(shape, plane_axis, shift)",
  "def _slice_wire(wire, normal_plane, shift, *, BIG_NUMBER=1e5):\n    \"\"\"\n    Get the plane intersection points of any wire (possibly anything, needs testing)\n    \"\"\"\n    circ = Part.Circle(\n        Base.Vector(*shift), Base.Vector(*normal_plane), BIG_NUMBER\n    ).toShape()\n    plane = apiFace(apiWire(circ))\n    intersect_obj = wire.section(plane)\n    return np.array([[v.X, v.Y, v.Z] for v in intersect_obj.Vertexes])",
  "def _slice_solid(obj, normal_plane, shift):\n    \"\"\"\n    Get the plane intersection wires of a face or solid\n    \"\"\"\n    return obj.slice(Base.Vector(*normal_plane), shift)",
  "def _setup_document(\n    parts: Iterable[apiShape], labels: Optional[Iterable[str]] = None\n) -> Iterable[Part.Feature]:\n    \"\"\"\n    Setup FreeCAD document.\n\n    Converts shapes to FreeCAD Part.Features to enable saving and viewing\n    \"\"\"\n    if not hasattr(FreeCADGui, \"subgraphFromObject\"):\n        FreeCADGui.setupWithoutGUI()\n\n    doc = FreeCAD.newDocument()\n\n    if labels is None:\n        # Empty string is the default argument for addObject\n        labels = [\"\"] * len(parts)\n\n    elif len(labels) != len(parts):\n        raise ValueError(\n            f\"Number of labels ({len(labels)}) != number of objects ({len(parts)})\"\n        )\n\n    for part, label in zip(parts, labels):\n        new_part = part.copy()\n        new_part.rotate((0.0, 0.0, 0.0), (1.0, 0.0, 0.0), -90.0)\n        obj = doc.addObject(\"Part::FeaturePython\", label)\n        obj.Shape = new_part\n        doc.recompute()\n        yield obj",
  "class CADFileType(enum.Enum):\n    \"\"\"\n    FreeCAD standard export filetypes\n\n    Notes\n    -----\n    Some filetypes my require additional dependencies see:\n    https://wiki.freecad.org/Import_Export\n    \"\"\"\n\n    # Commented out currently don't function\n    ASCII_STEREO_MESH = (\"ast\", \"Mesh\")\n    ADDITIVE_MANUFACTURING = (\"amf\", \"Mesh\")\n    ASC = (\"asc\", \"Points\")\n    AUTOCAD = (\"dwg\", \"importDWG\")\n    AUTOCAD_DXF = (\"dxf\", \"importDXF\")\n    # BDF = (\"bdf\", \"feminout.exportNastranMesh\")\n    BINMESH = (\"bms\", \"Mesh\")\n    BREP = (\"brep\", \"Part\")\n    BREP_2 = (\"brp\", \"Part\")\n    CSG = (\"csg\", \"exportCSG\")\n    DAE = (\"dae\", \"importDAE\")\n    # DAT = (\"dat\", \"Fem\")\n    FREECAD = (\"FCStd\", None)\n    # FENICS_FEM = (\"xdmf\", \"feminout.importFenicsMesh\")\n    # FENICS_FEM_XML = (\"xml\", \"feminout.importFenicsMesh\")\n    GLTRANSMISSION = (\"gltf\", \"ImportGui\")\n    GLTRANSMISSION_2 = (\"glb\", \"ImportGui\")\n    IFC_BIM = (\"ifc\", \"exportIFC\")\n    IFC_BIM_JSON = (\"ifcJSON\", \"exportIFC\")\n    IGES = (\"iges\", \"ImportGui\")\n    IGES_2 = (\"igs\", \"ImportGui\")\n    # INP = (\"inp\", \"Fem\")\n    INVENTOR_V2_1 = (\"iv\", \"Mesh\")\n    JSON = (\"json\", \"importJSON\")\n    # JSON_MESH = (\"$json\", \"feminout.importYamlJsonMesh\")\n    # MED = (\"med\", \"Fem\")\n    # MESHJSON = (\"meshjson\", \"feminout.importYamlJsonMesh\")\n    # MESHPY = (\"meshpy\", \"feminout.importPyMesh\")\n    # MESHYAML = (\"meshyaml\", \"feminout.importYamlJsonMesh\")\n    OBJ = (\"obj\", \"Mesh\")\n    OBJ_WAVE = (\"$obj\", \"importOBJ\")\n    OFF = (\"off\", \"Mesh\")\n    OPENSCAD = (\"scad\", \"exportCSG\")\n    # PCD = (\"pcd\", \"Points\")\n    # PDF = (\"pdf\", \"FreeCADGui\")\n    # PLY = (\"ply\", \"Points\")\n    PLY_STANFORD = (\"ply\", \"Mesh\")\n    SIMPLE_MODEL = (\"smf\", \"Mesh\")\n    STEP = (\"stp\", \"ImportGui\")\n    STEP_2 = (\"step\", \"ImportGui\")\n    STEP_ZIP = (\"stpZ\", \"stepZ\")\n    STL = (\"stl\", \"Mesh\")\n    # SVG = (\"svg\", \"DrawingGui\")\n    # SVG_FLAT = (\"$svg\", \"importSVG\")\n    # TETGEN_FEM = (\"poly\", \"feminout.convert2TetGen\")\n    THREED_MANUFACTURING = (\"3mf\", \"Mesh\")\n    # UNV = (\"unv\", \"Fem\")\n    # VRML = (\"vrml\", \"FreeCADGui\")\n    # VRML_2 = (\"wrl\", \"FreeCADGui\")\n    # VRML_ZIP = (\"wrl.gz\", \"FreeCADGui\")\n    # VRML_ZIP_2 = (\"wrz\", \"FreeCADGui\")\n    # VTK = (\"vtk\", \"Fem\")\n    # VTU = (\"vtu\", \"Fem\")\n    # WEBGL = (\"html\", \"importWebGL\")\n    # WEBGL_X3D = (\"xhtml\", \"FreeCADGui\")\n    # X3D = (\"x3d\", \"FreeCADGui\")\n    # X3DZ = (\"x3dz\", \"FreeCADGui\")\n    # YAML = (\"yaml\", \"feminout.importYamlJsonMesh\")\n    # Z88_FEM_MESH = (\"z88\", \"Fem\")\n    # Z88_FEM_MESH_2 = (\"i1.txt\", \"feminout.importZ88Mesh\")\n\n    def __new__(cls, *args, **kwds):\n        \"\"\"Create Enum from first half of tuple\"\"\"\n        obj = object.__new__(cls)\n        obj._value_ = args[0]\n        return obj\n\n    def __init__(self, _, module: str = \"\"):\n        self.module = module\n\n    @classmethod\n    def unitless_formats(cls) -> Tuple[CADFileType, ...]:\n        \"\"\"CAD formats that don't need to be converted because they are unitless\"\"\"\n        return (cls.OBJ_WAVE, *[form for form in cls if form.module == \"Mesh\"])\n\n    @classmethod\n    def manual_mesh_formats(cls) -> Tuple[CADFileType, ...]:\n        \"\"\"CAD formats that need to have meshed objects.\"\"\"\n        return (\n            cls.GLTRANSMISSION,\n            cls.GLTRANSMISSION_2,\n            cls.PLY_STANFORD,\n            cls.SIMPLE_MODEL,\n        )\n\n    @DynamicClassAttribute\n    def exporter(self) -> ExporterProtocol:\n        \"\"\"Get exporter module for each filetype\"\"\"\n        try:\n            export_func = __import__(self.module).export\n            if self in self.manual_mesh_formats():\n                return meshed_exporter(self, export_func)\n            return export_func\n        except AttributeError:\n            modlist = self.module.split(\".\")\n            if len(modlist) > 1:\n                return getattr(__import__(modlist[0]), modlist[1]).export\n            else:\n                raise FreeCADError(\n                    f\"Unable to save to {self.value} please try through the main FreeCAD GUI\"\n                )\n        except TypeError:\n            # Assume CADFileType.FREECAD\n            def FreeCADwriter(objs, filename, **kwargs):\n                doc = objs[0].Document\n                doc.saveAs(filename)\n\n            return FreeCADwriter",
  "class ExporterProtocol(Protocol):\n    \"\"\"Typing for CAD exporter\"\"\"\n\n    def __call__(self, objs: List[Part.Feature], filename: str, **kwargs):\n        \"\"\"Export CAD protocol\"\"\"",
  "def meshed_exporter(\n    cad_format: CADFileType, export_func: Callable[[Part.Feature, str], None]\n) -> ExporterProtocol:\n    \"\"\"Meshing and then exporting CAD in certain formats.\"\"\"\n\n    @wraps(export_func)\n    def wrapper(objs: Part.Feature, filename: str, *, tessellate: float = 0.5, **kwargs):\n        \"\"\"\n        Tessellation should happen on a copied object\n        \"\"\"\n        if cad_format in CADFileType.unitless_formats():\n            for no, obj in enumerate(objs):\n                objs[no].Shape = obj.Shape.copy()\n        for ob in objs:\n            ob.Shape.tessellate(tessellate)\n\n        export_func(objs, filename, **kwargs)\n\n    return wrapper",
  "def save_as_STP(\n    shapes: List[apiShape], filename: str = \"test\", unit_scale: str = \"metre\", **kwargs\n):\n    \"\"\"\n    Saves a series of Shape objects as a STEP assembly\n\n    Parameters\n    ----------\n    shapes:\n        Iterable of shape objects to be saved\n    filename:\n        Full path filename of the STP assembly\n    unit_scale:\n        The scale in which to save the Shape objects\n\n    Notes\n    -----\n    This uses the legacy method to save to STP files.\n    It doesnt require freecad documents but also doesnt allow much customisation.\n    Part builds in millimetres therefore we need to scale to metres to be\n    consistent with our units.\n\n    \"\"\"\n    filename = force_file_extension(filename, [\".stp\", \".step\"])\n\n    if not isinstance(shapes, list):\n        shapes = [shapes]\n\n    if not all(not shape.isNull() for shape in shapes):\n        raise FreeCADError(\"Shape is null.\")\n\n    compound = make_compound(shapes)\n\n    if \"scale\" in kwargs:\n        scale = kwargs[\"scale\"]\n        warn(\n            \"Using kwarg 'scale' is no longer supported. Please use 'unit_scale'\",\n            category=DeprecationWarning,\n        )\n    else:\n        scale = raw_uc(1, unit_scale, \"mm\")\n\n    if scale != 1:\n        # scale the compound. Since the scale function modifies directly the shape,\n        # a copy of the compound is made to avoid modification of the original shapes.\n        compound = scale_shape(compound.copy(), scale)\n\n    compound.exportStep(filename)",
  "def _scale_obj(objs, scale: float = 1000):\n    \"\"\"\n    Scale objects\n\n    Notes\n    -----\n    Since the scale function modifies directly the shape,\n    a copy of the shape is made to avoid modification of the original shapes.\n    The scale of Part is in mm by default therefore we scale by 1000 to convert\n    to metres.\n    \"\"\"\n    if scale != 1:\n        for no, obj in enumerate(objs):\n            objs[no].Shape = scale_shape(obj.Shape.copy(), scale)",
  "def save_cad(\n    shapes: Iterable[apiShape],\n    filename: str,\n    cad_format: Union[str, CADFileType] = \"stp\",\n    labels: Optional[Iterable[str]] = None,\n    unit_scale: str = \"metre\",\n    **kwargs,\n):\n    \"\"\"\n    Save CAD in a given file format\n\n    Parameters\n    ----------\n    shapes:\n        CAD shape objects to save\n    filename:\n        filename (file extension will be forced base on `cad_format`)\n    cad_format:\n        file cad_format\n    labels:\n        shape labels\n    unit_scale:\n        unit to save the objects as.\n    kwargs:\n        passed to freecad preferences configuration\n\n    Notes\n    -----\n    Part builds in millimetres therefore we need to scale to metres to be\n    consistent with our units\n    \"\"\"\n    if kw_formatt := kwargs.pop(\"formatt\", None):\n        warn(\n            \"Using kwarg 'formatt' is no longer supported. Use cad_format instead.\",\n            category=DeprecationWarning,\n        )\n        cad_format = kw_formatt\n\n    try:\n        cad_format = CADFileType(cad_format)\n    except ValueError as ve:\n        try:\n            cad_format = CADFileType[cad_format.upper()]\n        except (KeyError, AttributeError):\n            raise ve\n\n    filename = force_file_extension(filename, f\".{cad_format.value.strip('$')}\")\n\n    _freecad_save_config(\n        **{\n            k: kwargs.pop(k)\n            for k in kwargs.keys() & {\"unit\", \"no_dp\", \"author\", \"stp_file_scheme\"}\n        }\n    )\n\n    objs = list(_setup_document(shapes, labels))\n\n    # Part is always built in mm but some formats are unitless\n    if cad_format not in CADFileType.unitless_formats():\n        _scale_obj(objs, scale=raw_uc(1, unit_scale, \"mm\"))\n\n    # Some exporters need FreeCADGui to be setup before their import,\n    # this is achieved in _setup_document\n    try:\n        cad_format.exporter(objs, filename, **kwargs)\n    except ImportError as imp_err:\n        raise FreeCADError(\n            f\"Unable to save to {cad_format.value} please try through the main FreeCAD GUI\"\n        ) from imp_err\n\n    if not os.path.exists(filename):\n        mesg = f\"{filename} not created, filetype not written by FreeCAD.\"\n        if cad_format is CADFileType.IFC_BIM:\n            mesg += \" FreeCAD requires `ifcopenshell` to save in this format.\"\n        elif cad_format is CADFileType.DAE:\n            mesg += \" FreeCAD requires `pycollada` to save in this format.\"\n        elif cad_format is CADFileType.IFC_BIM_JSON:\n            mesg += (\n                \" FreeCAD requires `ifcopenshell` and\"\n                \" IFCJSON module to save in this format.\"\n            )\n        elif cad_format is CADFileType.AUTOCAD:\n            mesg += \" FreeCAD requires `LibreDWG` to save in this format.\"\n\n        raise FreeCADError(\n            f\"{mesg} Not able to save object with format: '{cad_format.value.strip('$')}'\"\n        )",
  "def scale_shape(shape: apiShape, factor: float) -> apiShape:\n    \"\"\"\n    Apply scaling with factor to the shape\n\n    Parameters\n    ----------\n    shape:\n        The shape to be scaled\n    factor:\n        The scaling factor\n\n    Returns\n    -------\n    The scaled shape\n    \"\"\"\n    return shape.scale(factor)",
  "def translate_shape(shape: apiShape, vector: Tuple[float, float, float]) -> apiShape:\n    \"\"\"\n    Apply scaling with factor to the shape\n\n    Parameters\n    ----------\n    shape:\n        The shape to be scaled\n    vector:\n        The translation vector\n\n    Returns\n    -------\n    The translated shape\n    \"\"\"\n    return shape.translate(Base.Vector(vector))",
  "def rotate_shape(\n    shape: apiShape,\n    base: Tuple[float, float, float] = (0.0, 0.0, 0.0),\n    direction: Tuple[float, float, float] = (0.0, 0.0, 1.0),\n    degree: float = 180,\n) -> apiShape:\n    \"\"\"\n    Apply the rotation (base, dir, degree) to this shape\n\n    Parameters\n    ----------\n    shape:\n        The shape to be rotated\n    base:\n        Origin location of the rotation\n    direction:\n        The direction vector\n    degree:\n        rotation angle\n\n    Returns\n    -------\n    The rotated shape\n    \"\"\"\n    return shape.rotate(base, direction, degree)",
  "def mirror_shape(\n    shape: apiShape,\n    base: Tuple[float, float, float],\n    direction: Tuple[float, float, float],\n) -> apiShape:\n    \"\"\"\n    Mirror a shape about a plane.\n\n    Parameters\n    ----------\n    shape:\n        Shape to mirror\n    base:\n        Mirror plane base point\n    direction:\n        Mirror plane direction\n\n    Returns\n    -------\n    The mirrored shape\n    \"\"\"\n    base = Base.Vector(base)\n    direction = Base.Vector(direction)\n    mirrored_shape = shape.mirror(base, direction)\n    if isinstance(shape, apiSolid):\n        return mirrored_shape.Solids[0]\n    elif isinstance(shape, apiCompound):\n        return mirrored_shape.Compounds[0]\n    elif isinstance(shape, apiFace):\n        return mirrored_shape.Faces[0]\n    elif isinstance(shape, apiWire):\n        return mirrored_shape.Wires[0]\n    elif isinstance(shape, apiShell):\n        return mirrored_shape.Shells[0]",
  "def revolve_shape(\n    shape: apiShape,\n    base: Tuple[float, float, float] = (0.0, 0.0, 0.0),\n    direction: Tuple[float, float, float] = (0.0, 0.0, 1.0),\n    degree: float = 180.0,\n) -> apiShape:\n    \"\"\"\n    Apply the revolve (base, dir, degree) to this shape\n\n    Parameters\n    ----------\n    shape:\n        The shape to be revolved\n    base:\n        Origin location of the revolution\n    direction:\n        The direction vector\n    degree:\n        revolution angle\n\n    Returns\n    -------\n    The revolved shape.\n    \"\"\"\n    base = Base.Vector(base)\n    direction = Base.Vector(direction)\n    return shape.revolve(base, direction, degree)",
  "def extrude_shape(shape: apiShape, vec: Tuple[float, float, float]) -> apiShape:\n    \"\"\"\n    Apply the extrusion along vec to this shape\n\n    Parameters\n    ----------\n    shape:\n        The shape to be extruded\n    vec:\n        The vector along which to extrude\n\n    Returns\n    -------\n    The extruded shape.\n    \"\"\"\n    vec = Base.Vector(vec)\n    return shape.extrude(vec)",
  "def _split_wire(wire):\n    \"\"\"\n    Split a wire into two parts.\n    \"\"\"\n    edges = wire.OrderedEdges\n    if len(edges) == 1:\n        # Only one edge in the wire, which we need to split\n        edge = edges[0]\n        p_start, p_end = edge.ParameterRange\n        p_mid = 0.5 * (p_end - p_start)\n        edges_1 = edge.Curve.toShape(p_start, p_mid)\n        edges_2 = edge.Curve.toShape(p_mid, p_end)\n\n    else:\n        # We can just sub-divide the wire by its edges\n        n_split = int(len(edges) / 2)\n        edges_1, edges_2 = edges[:n_split], edges[n_split:]\n\n    return apiWire(edges_1), apiWire(edges_2)",
  "def sweep_shape(\n    profiles: Iterable[apiWire], path: apiWire, solid: bool = True, frenet: bool = True\n) -> Union[apiShell, apiSolid]:\n    \"\"\"\n    Sweep a a set of profiles along a path.\n\n    Parameters\n    ----------\n    profiles:\n        Set of profiles to sweep\n    path:\n        Path along which to sweep the profiles\n    solid:\n        Whether or not to create a Solid\n    frenet:\n        If true, the orientation of the profile(s) is calculated based on local curvature\n        and tangency. For planar paths, should not make a difference.\n\n    Returns\n    -------\n    Swept geometry object\n    \"\"\"\n    if not isinstance(profiles, Iterable):\n        profiles = [profiles]\n\n    closures = [p.isClosed() for p in profiles]\n    all_closed = sum(closures) == len(closures)\n    none_closed = sum(closures) == 0\n\n    if not all_closed and not none_closed:\n        raise FreeCADError(\"You cannot mix open and closed profiles when sweeping.\")\n\n    if none_closed and solid:\n        bluemira_warn(\n            \"You cannot sweep open profiles and expect a Solid result. Disabling this.\"\n        )\n        solid = False\n\n    if not _wire_edges_tangent(path):\n        raise FreeCADError(\n            \"Sweep path contains edges that are not consecutively tangent. This will produce unexpected results.\"\n        )\n\n    result = path.makePipeShell(profiles, True, frenet)\n\n    solid_result = apiSolid(result)\n    if solid:\n        return solid_result\n    else:\n        return solid_result.Shells[0]",
  "def fillet_wire_2D(wire: apiWire, radius: float, chamfer: bool = False) -> apiWire:\n    \"\"\"\n    Fillet or chamfer a two-dimensional wire, returning a new wire\n\n    Parameters\n    ----------\n    wire:\n        Wire to be filleted or chamfered\n    radius:\n        Radius of the fillet or chamfer operation\n    chamfer: bool (default=False)\n        Whether to chamfer or not\n\n    Returns\n    -------\n    Resulting filleted or chamfered wire\n    \"\"\"\n    # Temporarily suppress pesky print statement:\n    # DraftGeomUtils.fillet: Warning: edges have same direction. Did nothing\n    old_stdout = sys.stdout\n    try:\n        sys.stdout = open(os.devnull, \"w\")\n        result = DraftGeomUtils.filletWire(wire, radius, chamfer=chamfer)\n    finally:\n        sys.stdout = old_stdout\n\n    return result",
  "def boolean_fuse(shapes: Iterable[apiShape], remove_splitter: bool = True) -> apiShape:\n    \"\"\"\n    Fuse two or more shapes together. Internal splitter are removed.\n\n    Parameters\n    ----------\n    shapes:\n        List of FreeCAD shape objects to be fused together. All the objects in the\n        list must be of the same type.\n    remove_splitter:\n        if True, shape is refined removing extra edges.\n        See(https://wiki.freecadweb.org/Part_RefineShape)\n\n\n    Returns\n    -------\n    Result of the boolean operation.\n\n    Raises\n    ------\n    error: GeometryError\n        In case the boolean operation fails.\n    \"\"\"\n    if not isinstance(shapes, list):\n        raise ValueError(f\"{shapes} is not a list.\")\n\n    if len(shapes) < 2:\n        raise ValueError(\"At least 2 shapes must be given\")\n\n    _type = type(shapes[0])\n    _check_shapes_same_type(shapes)\n\n    if _is_wire_or_face(_type):\n        _check_shapes_coplanar(shapes)\n        if not _shapes_are_coaxis(shapes):\n            bluemira_warn(\n                \"Boolean fuse on shapes that do not have the same planar axis. Reversing.\"\n            )\n            _make_shapes_coaxis(shapes)\n\n    try:\n        if _type == apiWire:\n            merged_shape = BOPTools.SplitAPI.booleanFragments(shapes, \"Split\")\n            if len(merged_shape.Wires) > len(shapes):\n                raise FreeCADError(\n                    f\"Fuse wire creation failed. Possible \"\n                    f\"overlap or internal intersection of \"\n                    f\"input shapes {shapes}.\"\n                )\n            else:\n                merged_shape = merged_shape.fuse(merged_shape.Wires)\n                merged_shape = Part.Wire(merged_shape.Wires)\n                return merged_shape\n\n        elif _type == apiFace:\n            merged_shape = shapes[0].fuse(shapes[1:])\n            if remove_splitter:\n                merged_shape = merged_shape.removeSplitter()\n            if len(merged_shape.Faces) > 1:\n                raise FreeCADError(\n                    f\"Boolean fuse operation on {shapes} gives more than one face.\"\n                )\n            return merged_shape.Faces[0]\n\n        elif _type == apiSolid:\n            merged_shape = shapes[0].fuse(shapes[1:])\n            if remove_splitter:\n                merged_shape = merged_shape.removeSplitter()\n            if len(merged_shape.Solids) > 1:\n                raise FreeCADError(\n                    f\"Boolean fuse operation on {shapes} gives more than one solid.\"\n                )\n            return merged_shape.Solids[0]\n\n        else:\n            raise ValueError(\n                f\"Fuse function still not implemented for {_type} instances.\"\n            )\n    except Exception as e:\n        raise FreeCADError(str(e))",
  "def boolean_cut(\n    shape: apiShape, tools: List[apiShape], split: bool = True\n) -> List[apiShape]:\n    \"\"\"\n    Difference of shape and a given (list of) topo shape cut(tools)\n\n    Parameters\n    ----------\n    shape:\n        the reference object\n    tools:\n        List of FreeCAD shape objects to be used as tools.\n    split:\n        If True, shape is split into pieces based on intersections with tools.\n\n    Returns\n    -------\n    Result of the boolean operation.\n\n    Raises\n    ------\n    error: GeometryError\n        In case the boolean operation fails.\n    \"\"\"\n    _type = type(shape)\n\n    if not isinstance(tools, list):\n        tools = [tools]\n\n    if _is_wire_or_face(_type):\n        _check_shapes_coplanar([shape] + tools)\n\n    cut_shape = shape.cut(tools)\n    if split:\n        cut_shape = BOPTools.SplitAPI.slice(cut_shape, tools, mode=\"Split\")\n\n    if _type == apiWire:\n        output = cut_shape.Wires\n    elif _type == apiFace:\n        output = cut_shape.Faces\n    elif _type == apiShell:\n        output = cut_shape.Shells\n    elif _type == apiSolid:\n        output = cut_shape.Solids\n    else:\n        raise ValueError(f\"Cut function not implemented for {_type} objects.\")\n    return output",
  "def boolean_fragments(\n    shapes: List[apiSolid], tolerance: float = 0.0\n) -> Tuple[apiCompound, List[apiSolid]]:\n    \"\"\"\n    Split a list of shapes into their Boolean fragments.\n\n    Parameters\n    ----------\n    shapes:\n        List of BluemiraSolids to be split into Boolean fragments\n    tolerance:\n        Tolerance with which to perform the operation\n\n    Returns\n    -------\n    compound:\n        A compound of the unique fragments\n    fragment_map:\n        An ordered list of groups of solid Boolean fragments (ordered in terms of\n        input ordering)\n    \"\"\"\n    try:\n        compound, fragment_map = shapes[0].generalFuse(shapes[1:], tolerance)\n    except Exception as e:\n        raise FreeCADError(f\"Boolean fragments operation failed: {str(e)}\")\n    return compound, fragment_map",
  "def point_inside_shape(point: Iterable[float], shape: apiShape) -> bool:\n    \"\"\"\n    Whether or not a point is inside a shape.\n\n    Parameters\n    ----------\n    point:\n        Coordinates of the point\n    shape:\n        Geometry to check with\n\n    Returns\n    -------\n    Whether or not the point is inside the shape\n    \"\"\"\n    vector = apiVector(*point)\n    return shape.isInside(vector, EPS, True)",
  "def _edges_tangent(edge_1, edge_2):\n    \"\"\"\n    Check if two adjacent edges are tangent to one another.\n    \"\"\"\n    angle = edge_1.tangentAt(edge_1.LastParameter).getAngle(\n        edge_2.tangentAt(edge_2.FirstParameter)\n    )\n    return np.isclose(\n        angle,\n        0.0,\n        rtol=1e-4,\n        atol=1e-4,\n    )",
  "def _wire_edges_tangent(wire):\n    \"\"\"\n    Check that all consecutive edges in a wire are tangent\n    \"\"\"\n    if len(wire.Edges) <= 1:\n        return True\n\n    else:\n        edges_tangent = []\n        for i in range(len(wire.OrderedEdges) - 1):\n            edge_1 = wire.OrderedEdges[i]\n            edge_2 = wire.OrderedEdges[i + 1]\n            edges_tangent.append(_edges_tangent(edge_1, edge_2))\n\n    if wire.isClosed():\n        # Check last and first edge tangency\n        edges_tangent.append(_edges_tangent(wire.OrderedEdges[-1], wire.OrderedEdges[0]))\n\n    return all(edges_tangent)",
  "def _wire_is_planar(wire):\n    \"\"\"\n    Check if a wire is planar.\n    \"\"\"\n    try:\n        face = Part.Face(wire)\n    except Part.OCCError:\n        return False\n    return isinstance(face.Surface, Part.Plane)",
  "def _wire_is_straight(wire):\n    \"\"\"\n    Check if a wire is a straight line.\n    \"\"\"\n    if len(wire.Edges) == 1:\n        edge = wire.Edges[0]\n        if len(edge.Vertexes) == 2:\n            straight = dist_to_shape(edge.Vertexes[0], edge.Vertexes[1])[0]\n            if np.isclose(straight, wire.Length, rtol=EPS, atol=1e-8):\n                return True\n    return False",
  "def _is_wire_or_face(shape_type):\n    return shape_type == apiWire or shape_type == apiFace",
  "def _check_shapes_same_type(shapes):\n    \"\"\"\n    Check that all the shapes are of the same type.\n    \"\"\"\n    _type = type(shapes[0])\n    if not all(isinstance(s, _type) for s in shapes):\n        raise ValueError(f\"All instances in {shapes} must be of the same type.\")",
  "def _check_shapes_coplanar(shapes):\n    if not _shapes_are_coplanar(shapes):\n        raise ValueError(\n            \"Shapes are not co-planar; this operation does not support non-co-planar wires or faces.\"\n        )",
  "def _shapes_are_coplanar(shapes):\n    \"\"\"\n    Check if a list of shapes are all coplanar. First shape is taken as the reference.\n    \"\"\"\n    coplanar = []\n    for other in shapes[1:]:\n        coplanar.append(shapes[0].isCoplanar(other))\n    return all(coplanar)",
  "def _shapes_are_coaxis(shapes):\n    \"\"\"\n    Check if a list of shapes are all co-axis. First shape is taken as the reference.\n    \"\"\"\n    axis = shapes[0].findPlane().Axis\n    for shape in shapes[1:]:\n        other_axis = shape.findPlane().Axis\n        if axis != other_axis:\n            return False\n    return True",
  "def _make_shapes_coaxis(shapes):\n    \"\"\"\n    Make a list of shapes co-axis by reversing. First shape is taken as the reference.\n    \"\"\"\n    axis = shapes[0].findPlane().Axis\n    for shape in shapes[1:]:\n        other_axis = shape.findPlane().Axis\n        if axis != other_axis:\n            shape.reverse()",
  "def fix_wire(wire: apiWire, precision: float = EPS, min_length: float = MINIMUM_LENGTH):\n    \"\"\"\n    Fix a wire by removing any small edges and joining the remaining edges.\n\n    Parameters\n    ----------\n    wire:\n        Wire to fix\n    precision:\n        General precision with which to work\n    min_length:\n        Minimum edge length\n    \"\"\"\n    wire.fix(precision, min_length, min_length)",
  "def make_placement(\n    base: Iterable[float], axis: Iterable[float], angle: float\n) -> apiPlacement:\n    \"\"\"\n    Make a FreeCAD Placement\n\n    Parameters\n    ----------\n    base: Iterable\n        a vector representing the Placement local origin\n    axis: Iterable\n        axis of rotation\n    angle:\n        rotation angle in degree\n    \"\"\"\n    base = Base.Vector(base)\n    axis = Base.Vector(axis)\n\n    return Base.Placement(base, axis, angle)",
  "def make_placement_from_matrix(matrix: np.ndarray) -> apiPlacement:\n    \"\"\"\n    Make a FreeCAD Placement from a 4 x 4 matrix.\n\n    Parameters\n    ----------\n    matrix:\n        4 x 4 matrix from which to make the placement\n\n    Notes\n    -----\n    Matrix should be of the form:\n        [cos_11, cos_12, cos_13, dx]\n        [cos_21, cos_22, cos_23, dy]\n        [cos_31, cos_32, cos_33, dz]\n        [     0,      0,      0,  1]\n    \"\"\"\n    if matrix.shape != (4, 4):\n        raise FreeCADError(f\"Matrix must be of shape (4, 4), not: {matrix.shape}\")\n\n    for i in range(3):\n        row = matrix[i, :3]\n        matrix[i, :3] = row / np.linalg.norm(row)\n    matrix[-1, :] = [0, 0, 0, 1]\n\n    matrix = Base.Matrix(*matrix.flat)\n    return Base.Placement(matrix)",
  "def move_placement(placement: apiPlacement, vector: Iterable[float]):\n    \"\"\"\n    Moves the FreeCAD Placement along the given vector\n\n    Parameters\n    ----------\n    placement:\n        the FreeCAD placement to be modified\n    vector:\n        direction along which the placement is moved\n    \"\"\"\n    placement.move(Base.Vector(vector))",
  "def make_placement_from_vectors(\n    base: Iterable[float] = [0, 0, 0],\n    vx: Iterable[float] = [1, 0, 0],\n    vy: Iterable[float] = [0, 1, 0],\n    vz: Iterable[float] = [0, 0, 1],\n    order: str = \"ZXY\",\n) -> apiPlacement:\n    \"\"\"Create a placement from three directional vectors\"\"\"\n    rotation = Base.Rotation(vx, vy, vz, order)\n    placement = Base.Placement(base, rotation)\n    return placement",
  "def change_placement(geo: apiShape, placement: apiPlacement):\n    \"\"\"\n    Change the placement of a FreeCAD object\n\n    Parameters\n    ----------\n    geo:\n        the object to be modified\n    placement:\n        the FreeCAD placement to be modified\n    \"\"\"\n    new_placement = geo.Placement.multiply(placement)\n    new_base = placement.multVec(geo.Placement.Base)\n    new_placement.Base = new_base\n    geo.Placement = new_placement",
  "def make_plane(\n    base: Tuple[float, float, float] = (0.0, 0.0, 0.0),\n    axis: Tuple[float, float, float] = (0.0, 0.0, 1.0),\n) -> apiPlane:\n    \"\"\"\n    Creates a FreeCAD plane with a given location and normal\n\n    Parameters\n    ----------\n    base:\n        a reference point in the plane\n    axis:\n        normal vector to the plane\n\n    Returns\n    -------\n    Plane from base and axis\n    \"\"\"\n    base = Base.Vector(base)\n    axis = Base.Vector(axis)\n\n    return Part.Plane(base, axis)",
  "def make_plane_from_3_points(\n    point1: Tuple[float, float, float] = (0.0, 0.0, 0.0),\n    point2: Tuple[float, float, float] = (1.0, 0.0, 0.0),\n    point3: Tuple[float, float, float] = (0.0, 1.0, 0.0),\n) -> apiPlane:\n    \"\"\"\n    Creates a FreeCAD plane defined by three non-linear points\n\n    Parameters\n    ----------\n    point1:\n        a reference point in the plane\n    point2:\n        a reference point in the plane\n    point3:\n        a reference point in the plane\n\n    Returns\n    -------\n    Plane from three points\n    \"\"\"\n    point1 = Base.Vector(point1)\n    point2 = Base.Vector(point2)\n    point3 = Base.Vector(point3)\n\n    return Part.Plane(point1, point2, point3)",
  "def face_from_plane(plane: apiPlane, width: float, height: float) -> apiFace:\n    \"\"\"\n    Creates a FreeCAD face from a Plane with specified height and width.\n\n    Note\n    ----\n    Face is centered on the Plane Position. With respect to the global coordinate\n    system, the face placement is given by a simple rotation of the z axis.\n\n    Parameters\n    ----------\n    plane:\n        the reference plane\n    width:\n        output face width\n    height:\n        output face height\n\n    Returns\n    -------\n    Face from plane\n    \"\"\"\n    # as suggested in https://forum.freecadweb.org/viewtopic.php?t=46418\n    corners = [\n        Base.Vector(-width / 2, -height / 2, 0),\n        Base.Vector(width / 2, -height / 2, 0),\n        Base.Vector(width / 2, height / 2, 0),\n        Base.Vector(-width / 2, height / 2, 0),\n    ]\n    # create the closed border\n    border = Part.makePolygon(corners + [corners[0]])\n    wall = Part.Face(border)\n\n    wall.Placement = placement_from_plane(plane)\n\n    return wall",
  "def plane_from_shape(shape: apiShape) -> apiPlane:\n    \"\"\"Return a plane if the shape is planar\"\"\"\n    plane = shape.findPlane()\n    return plane",
  "def placement_from_plane(plane: apiPlane) -> apiPlacement:\n    \"\"\"\n    Return a placement from a plane with the origin on the plane base and the z-axis\n    directed as the plane normal.\n    \"\"\"\n    axis = plane.Axis\n    pos = plane.Position\n\n    vx = plane.value(1, 0) - pos\n    vy = plane.value(0, 1) - pos\n\n    return make_placement_from_vectors(pos, vx, vy, axis, \"ZXY\")",
  "def _colourise(node: coin.SoNode, options: Dict):\n    if isinstance(node, coin.SoMaterial):\n        rgb = colors.to_rgb(options[\"colour\"])\n        transparency = options[\"transparency\"]\n        node.ambientColor.setValue(coin.SbColor(*rgb))\n        node.diffuseColor.setValue(coin.SbColor(*rgb))\n        node.transparency.setValue(transparency)\n    for child in node.getChildren() or []:\n        _colourise(child, options)",
  "def collect_verts_faces(\n    solid: apiShape, tesselation: float = 0.1\n) -> Tuple[Optional[np.ndarray], ...]:\n    \"\"\"\n    Collects verticies and faces of parts and tessellates them\n    for the CAD viewer\n\n    Parameters\n    ----------\n    solid:\n        FreeCAD Part\n    tesselation:\n        amount of tesselation for the mesh\n\n    Returns\n    -------\n    vertices:\n        Vertices\n    faces:\n        Faces\n    \"\"\"\n    verts = []\n    faces = []\n    voffset = 0\n\n    # collect\n    for face in solid.Faces:\n        # tesselation is likely to be the most expensive part of this\n        v, f = face.tessellate(tesselation)\n\n        if v != []:\n            verts.append(np.array(v))\n            if f != []:\n                faces.append(np.array(f) + voffset)\n            voffset += len(v)\n\n    if len(solid.Faces) > 0:\n        return np.vstack(verts), np.vstack(faces)\n    else:\n        return None, None",
  "def collect_wires(solid: apiShape, **kwds) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Collects verticies and edges of parts and discretizes them\n    for the CAD viewer\n\n    Parameters\n    ----------\n    solid:\n        FreeCAD Part\n\n    Returns\n    -------\n    vertices:\n        Vertices\n    edges:\n        Edges\n    \"\"\"\n    verts = []\n    edges = []\n    voffset = 0\n    for wire in solid.Wires:\n        v = wire.discretize(**kwds)\n        verts.append(np.array(v))\n        edges.append(np.arange(voffset, voffset + len(v) - 1))\n        voffset += len(v)\n    edges = np.concatenate(edges)[:, None]\n    return np.vstack(verts), np.hstack([edges, edges + 1])",
  "class DefaultDisplayOptions:\n    \"\"\"Freecad default display options\"\"\"\n\n    colour: ColourDescriptor = ColourDescriptor()\n    transparency: float = 0.0\n\n    @property\n    def color(self) -> str:\n        \"\"\"See colour\"\"\"\n        return self.colour\n\n    @color.setter\n    def color(self, value: Union[str, Tuple[float, float, float], ColorPalette]):\n        \"\"\"See colour\"\"\"\n        self.colour = value",
  "def show_cad(\n    parts: Union[apiShape, List[apiShape]],\n    options: Union[Dict, List[Optional[Dict]]],\n    labels: List[str],\n    **kwargs,\n):\n    \"\"\"\n    The implementation of the display API for FreeCAD parts.\n\n    Parameters\n    ----------\n    parts:\n        The parts to display.\n    options:\n        The options to use to display the parts.\n    labels:\n        labels to use for each part object\n    \"\"\"\n    if options is None:\n        options = [None]\n\n    if None in options:\n        options = [DefaultDisplayOptions() if o is None else o for o in options]\n\n    if len(options) != len(parts):\n        raise FreeCADError(\n            \"If options for display are provided then there must be as many options as \"\n            \"there are parts to display.\"\n        )\n\n    app = QApplication.instance()\n    if app is None:\n        app = QApplication([])\n\n    root = coin.SoSeparator()\n\n    for obj, option in zip(_setup_document(parts, labels), options):\n        subgraph = FreeCADGui.subgraphFromObject(obj)\n        _colourise(subgraph, option)\n        root.addChild(subgraph)\n\n    viewer = quarter.QuarterWidget()\n    viewer.setBackgroundColor(coin.SbColor(1, 1, 1))\n    viewer.setTransparencyType(coin.SoGLRenderAction.SCREEN_DOOR)\n    viewer.setSceneGraph(root)\n\n    viewer.setWindowTitle(\"Bluemira Display\")\n    viewer.show()\n    app.exec_()",
  "def extract_attribute(func):\n    \"\"\"\n    Decorator for serialize_shape. Convert the function output attributes string\n    list to the corresponding object attributes.\n    The first argument of func is the reference object.\n    If an output is callable, the output result is returned.\n    \"\"\"\n\n    def wrapper(*args, **kwargs):\n        type_, attrs = func(*args, **kwargs)\n        output = {}\n        for k, v in attrs.items():\n            if k == \"type\":\n                output[k] = type(args[0])\n            else:\n                output[v] = getattr(args[0], k)\n                if callable(output[v]):\n                    output[v] = output[v]()\n        return {type_: output}\n\n    return wrapper",
  "def serialize_shape(shape):\n    \"\"\"\n    Serialize a FreeCAD topological data object.\n    \"\"\"\n    type_ = type(shape)\n\n    if type_ == Part.Wire:\n        output = []\n        edges = shape.OrderedEdges\n        for edge in edges:\n            output.append(serialize_shape(edge))\n        return {\"Wire\": output}\n\n    if type_ == Part.Edge:\n        output = serialize_shape(_convert_edge_to_curve(shape))\n        return output\n\n    if type_ in [Part.LineSegment, Part.Line]:\n        output = {\n            \"LineSegment\": {\n                \"StartPoint\": list(shape.StartPoint),\n                \"EndPoint\": list(shape.EndPoint),\n            },\n        }\n        return output\n\n    if type_ == Part.BezierCurve:\n        output = {\n            \"BezierCurve\": {\n                \"Poles\": vector_to_list(shape.getPoles()),\n                \"FirstParameter\": shape.FirstParameter,\n                \"LastParameter\": shape.LastParameter,\n            }\n        }\n        return output\n\n    if type_ == Part.BSplineCurve:\n        output = {\n            \"BSplineCurve\": {\n                \"Poles\": vector_to_list(shape.getPoles()),\n                \"Mults\": shape.getMultiplicities(),\n                \"Knots\": shape.getKnots(),\n                \"isPeriodic\": shape.isPeriodic(),\n                \"Degree\": shape.Degree,\n                \"Weights\": shape.getWeights(),\n                \"checkRational\": shape.isRational(),\n                \"FirstParameter\": shape.FirstParameter,\n                \"LastParameter\": shape.LastParameter,\n            }\n        }\n        return output\n\n    if type_ == Part.ArcOfCircle:\n        output = {\n            \"ArcOfCircle\": {\n                \"Radius\": shape.Radius,\n                \"Center\": list(shape.Center),\n                \"Axis\": list(shape.Axis),\n                \"StartAngle\": math.degrees(shape.FirstParameter),\n                \"EndAngle\": math.degrees(shape.LastParameter),\n                \"StartPoint\": list(shape.StartPoint),\n                \"EndPoint\": list(shape.EndPoint),\n            }\n        }\n        return output\n\n    if type_ == Part.ArcOfEllipse:\n        output = {\n            \"ArcOfEllipse\": {\n                \"Center\": list(shape.Center),\n                \"MajorRadius\": shape.MajorRadius,\n                \"MinorRadius\": shape.MinorRadius,\n                \"MajorAxis\": list(shape.XAxis),\n                \"MinorAxis\": list(shape.YAxis),\n                \"StartAngle\": math.degrees(shape.FirstParameter),\n                \"EndAngle\": math.degrees(shape.LastParameter),\n                \"Focus1\": list(shape.Ellipse.Focus1),\n                \"StartPoint\": list(shape.StartPoint),\n                \"EndPoint\": list(shape.EndPoint),\n            }\n        }\n        return output\n\n    raise NotImplementedError(f\"Serialization non implemented for {type_}\")",
  "def deserialize_shape(buffer):\n    \"\"\"\n    Deserialize a FreeCAD topological data object obtained from serialize_shape.\n\n    Parameters\n    ----------\n    buffer:\n        Object serialization as stored by serialize_shape\n\n    Returns\n    -------\n        The deserialized FreeCAD object\n    \"\"\"\n    for type_, v in buffer.items():\n        if type_ == \"Wire\":\n            temp_list = []\n            for edge in v:\n                temp_list.append(deserialize_shape(edge))\n\n            return Part.Wire(temp_list)\n        if type_ == \"LineSegment\":\n            return make_polygon([v[\"StartPoint\"], v[\"EndPoint\"]])\n        elif type_ == \"BezierCurve\":\n            return make_bezier(v[\"Poles\"])\n        elif type_ == \"BSplineCurve\":\n            return make_bspline(\n                v[\"Poles\"],\n                v[\"Mults\"],\n                v[\"Knots\"],\n                v[\"isPeriodic\"],\n                v[\"Degree\"],\n                v[\"Weights\"],\n                v[\"checkRational\"],\n            )\n        elif type_ == \"ArcOfCircle\":\n            return make_circle(\n                v[\"Radius\"], v[\"Center\"], v[\"StartAngle\"], v[\"EndAngle\"], v[\"Axis\"]\n            )\n        elif type_ == \"ArcOfEllipse\":\n            return make_ellipse(\n                v[\"Center\"],\n                v[\"MajorRadius\"],\n                v[\"MinorRadius\"],\n                v[\"MajorAxis\"],\n                v[\"MinorAxis\"],\n                v[\"StartAngle\"],\n                v[\"EndAngle\"],\n            )\n        else:\n            raise NotImplementedError(f\"Deserialization non implemented for {type_}\")",
  "def _convert_edge_to_curve(edge: apiEdge) -> Part.Curve:\n    \"\"\"\n    Convert a Freecad Edge to the respective curve.\n\n    Parameters\n    ----------\n    edge:\n        FreeCAD Edge\n\n    Returns\n    -------\n    FreeCAD Part curve object\n    \"\"\"\n    curve = edge.Curve\n    first = edge.FirstParameter\n    last = edge.LastParameter\n    if edge.Orientation == \"Reversed\":\n        first, last = last, first\n    output = None\n\n    if isinstance(curve, Part.Line):\n        output = Part.LineSegment(curve.value(first), curve.value(last))\n    elif isinstance(curve, Part.Ellipse):\n        output = Part.ArcOfEllipse(curve, first, last)\n        if edge.Orientation == \"Reversed\":\n            output.Axis = -output.Axis\n            p0 = curve.value(first)\n            p1 = curve.value(last)\n            output = Part.ArcOfEllipse(\n                output.Ellipse,\n                output.Ellipse.parameter(p0),\n                output.Ellipse.parameter(p1),\n            )\n    elif isinstance(curve, Part.Circle):\n        output = Part.ArcOfCircle(curve, first, last)\n        if edge.Orientation == \"Reversed\":\n            output.Axis = -output.Axis\n            p0 = curve.value(first)\n            p1 = curve.value(last)\n            output = Part.ArcOfCircle(\n                output.Circle,\n                output.Circle.parameter(p0),\n                output.Circle.parameter(p1),\n            )\n    elif isinstance(curve, Part.BezierCurve):\n        output = Part.BezierCurve()\n        poles = curve.getPoles()\n        if edge.Orientation == \"Reversed\":\n            poles.reverse()\n        output.setPoles(poles)\n        output.segment(first, last)\n    elif isinstance(curve, Part.BSplineCurve):\n        output = curve\n        # p = curve.discretize(100)\n        # if edge.Orientation == \"Reversed\":\n        #     p.reverse()\n        # output = Part.BSplineCurve()\n        # output.interpolate(p)\n    elif isinstance(curve, Part.OffsetCurve):\n        c = curve.toNurbs()\n        if isinstance(c, Part.BSplineCurve) and edge.Orientation == \"Reversed\":\n            c.reverse()\n        output = _convert_edge_to_curve(Part.Edge(c))\n    else:\n        bluemira_warn(\"Conversion of {} is still not supported!\".format(type(curve)))\n\n    return output",
  "def argswrap(func):\n        def wrapper(*args, **kwargs):\n            try:\n                return func(*args, **kwargs)\n            except FreeCADError as fe:\n                raise new_error_type(fe.args[0]) from fe\n\n        return wrapper",
  "def _apply_to_list(func):\n        def wrapper(*args, **kwargs):\n            output = []\n            objs = args[0]\n            is_list = isinstance(objs, list)\n            if not is_list:\n                objs = [objs]\n                if len(args) > 1:\n                    args = [objs, args[1:]]\n                else:\n                    args = [objs]\n            if all(isinstance(o, data_type) for o in objs):\n                output = func(*args, **kwargs)\n                if not is_list:\n                    output = output[0]\n            else:\n                raise TypeError(\n                    f\"Only {data_type} instances can be converted to {type(output)}\"\n                )\n            return output\n\n        return wrapper",
  "def warning_msg():\n        bluemira_warn(\n            \"Wire split operation only returning one wire; you are splitting at an end.\"\n        )",
  "def __new__(cls, *args, **kwds):\n        \"\"\"Create Enum from first half of tuple\"\"\"\n        obj = object.__new__(cls)\n        obj._value_ = args[0]\n        return obj",
  "def __init__(self, _, module: str = \"\"):\n        self.module = module",
  "def unitless_formats(cls) -> Tuple[CADFileType, ...]:\n        \"\"\"CAD formats that don't need to be converted because they are unitless\"\"\"\n        return (cls.OBJ_WAVE, *[form for form in cls if form.module == \"Mesh\"])",
  "def manual_mesh_formats(cls) -> Tuple[CADFileType, ...]:\n        \"\"\"CAD formats that need to have meshed objects.\"\"\"\n        return (\n            cls.GLTRANSMISSION,\n            cls.GLTRANSMISSION_2,\n            cls.PLY_STANFORD,\n            cls.SIMPLE_MODEL,\n        )",
  "def exporter(self) -> ExporterProtocol:\n        \"\"\"Get exporter module for each filetype\"\"\"\n        try:\n            export_func = __import__(self.module).export\n            if self in self.manual_mesh_formats():\n                return meshed_exporter(self, export_func)\n            return export_func\n        except AttributeError:\n            modlist = self.module.split(\".\")\n            if len(modlist) > 1:\n                return getattr(__import__(modlist[0]), modlist[1]).export\n            else:\n                raise FreeCADError(\n                    f\"Unable to save to {self.value} please try through the main FreeCAD GUI\"\n                )\n        except TypeError:\n            # Assume CADFileType.FREECAD\n            def FreeCADwriter(objs, filename, **kwargs):\n                doc = objs[0].Document\n                doc.saveAs(filename)\n\n            return FreeCADwriter",
  "def __call__(self, objs: List[Part.Feature], filename: str, **kwargs):\n        \"\"\"Export CAD protocol\"\"\"",
  "def wrapper(objs: Part.Feature, filename: str, *, tessellate: float = 0.5, **kwargs):\n        \"\"\"\n        Tessellation should happen on a copied object\n        \"\"\"\n        if cad_format in CADFileType.unitless_formats():\n            for no, obj in enumerate(objs):\n                objs[no].Shape = obj.Shape.copy()\n        for ob in objs:\n            ob.Shape.tessellate(tessellate)\n\n        export_func(objs, filename, **kwargs)",
  "def color(self) -> str:\n        \"\"\"See colour\"\"\"\n        return self.colour",
  "def color(self, value: Union[str, Tuple[float, float, float], ColorPalette]):\n        \"\"\"See colour\"\"\"\n        self.colour = value",
  "def wrapper(*args, **kwargs):\n        type_, attrs = func(*args, **kwargs)\n        output = {}\n        for k, v in attrs.items():\n            if k == \"type\":\n                output[k] = type(args[0])\n            else:\n                output[v] = getattr(args[0], k)\n                if callable(output[v]):\n                    output[v] = output[v]()\n        return {type_: output}",
  "def wrapper(*args, **kwargs):\n            try:\n                return func(*args, **kwargs)\n            except FreeCADError as fe:\n                raise new_error_type(fe.args[0]) from fe",
  "def wrapper(*args, **kwargs):\n            output = []\n            objs = args[0]\n            is_list = isinstance(objs, list)\n            if not is_list:\n                objs = [objs]\n                if len(args) > 1:\n                    args = [objs, args[1:]]\n                else:\n                    args = [objs]\n            if all(isinstance(o, data_type) for o in objs):\n                output = func(*args, **kwargs)\n                if not is_list:\n                    output = output[0]\n            else:\n                raise TypeError(\n                    f\"Only {data_type} instances can be converted to {type(output)}\"\n                )\n            return output",
  "def FreeCADwriter(objs, filename, **kwargs):\n                doc = objs[0].Document\n                doc.saveAs(filename)",
  "class Model(Enum):\n    \"\"\"\n    Base Model Enum\n    \"\"\"\n\n    @classmethod\n    def info(cls):\n        \"\"\"\n        Show Model options\n        \"\"\"\n        infostr = f\"{cls.__doc__}\\n\" + \"\\n\".join(repr(l_) for l_ in list(cls))\n        bluemira_print(infostr)",
  "def read_mock_json_or_raise(file_path: str, name: str) -> Dict[str, float]:\n    \"\"\"\n    Read json file or raise CodesError\n    \"\"\"\n    try:\n        with open(file_path, \"r\") as f:\n            return json.load(f)\n    except OSError as os_error:\n        raise CodesError(\n            f\"Cannot open mock {name} results file '{file_path}'.\"\n        ) from os_error",
  "def get_code_interface(module: str) -> ModuleType:\n    \"\"\"\n    Dynamically import code interface\n\n    Parameters\n    ----------\n    module:\n        module to import\n\n    Returns\n    -------\n    code module\n    \"\"\"\n    try:\n        return get_module(f\"bluemira.codes.{module.lower()}\")\n    except ImportError:\n        return get_module(module)",
  "def create_mapping(\n    in_mappings=None, out_mappings=None, io_mappings=None, none_mappings=None\n) -> Dict[str, Any]:\n    \"\"\"\n    Creates mappings for external codes\n\n    Returns\n    -------\n    A mapping from bluemira names to an external code ParameterMapping\n\n    \"\"\"\n    mappings = {}\n    ins = {\"send\": True, \"recv\": False}\n    outs = {\"send\": False, \"recv\": True}\n    inouts = {\"send\": True, \"recv\": True}\n    nones = {\"send\": False, \"recv\": False}\n\n    for puts, sr in [\n        [in_mappings, ins],\n        [out_mappings, outs],\n        [io_mappings, inouts],\n        [none_mappings, nones],\n    ]:\n        if puts is not None:\n            for bm_key, (ec_key, unit) in puts.items():\n                mappings[bm_key] = ParameterMapping(\n                    ec_key, send=sr[\"send\"], recv=sr[\"recv\"], unit=unit\n                )\n\n    return mappings",
  "class LogPipe(threading.Thread):\n    \"\"\"\n    Capture logs for subprocesses\n\n    https://codereview.stackexchange.com/questions/6567/redirecting-subprocesses-output-stdout-and-stderr-to-the-logging-module\n\n    Parameters\n    ----------\n    loglevel:\n        print or error flush printing\n\n    \"\"\"\n\n    def __init__(self, loglevel: str):\n        super().__init__(daemon=True)\n\n        self.logfunc = {\"print\": bluemira_print_clean, \"error\": bluemira_error_clean}[\n            loglevel\n        ]\n        self.logfunc_flush = _bluemira_clean_flush\n        self.fd_read, self.fd_write = os.pipe()\n        self.pipe = os.fdopen(self.fd_read, encoding=\"utf-8\", errors=\"ignore\")\n        self.start()\n\n    def fileno(self):\n        \"\"\"\n        Return the write file descriptor of the pipe\n        \"\"\"\n        return self.fd_write\n\n    def run(self):\n        \"\"\"\n        Run the thread and pipe it all into the logger.\n        \"\"\"\n        for line in iter(self.pipe.readline, \"\"):\n            if line.startswith(\"==>\"):\n                self.logfunc_flush(line.strip(\"\\n\"))\n            else:\n                self.logfunc(line)\n\n        self.pipe.close()\n\n    def close(self):\n        \"\"\"\n        Close the write end of the pipe.\n        \"\"\"\n        os.close(self.fd_write)",
  "def run_subprocess(command: List[str], run_directory: str = \".\", **kwargs) -> int:\n    \"\"\"\n    Run a subprocess terminal command piping the output into bluemira's\n    logs.\n\n    Parameters\n    ----------\n    command:\n        The arguments of the command to run.\n    run_directory:\n        The directory to run the command in. Default is current working\n        directory.\n    **kwargs:\n        Arguments passed directly to subprocess.Popen.\n\n    Returns\n    -------\n    return_code: int\n        The return code of the subprocess.\n    \"\"\"\n    stdout = LogPipe(\"print\")\n    stderr = LogPipe(\"error\")\n\n    kwargs[\"cwd\"] = run_directory\n    kwargs.pop(\"shell\", None)  # Protect against user input\n\n    with subprocess.Popen(  # noqa :S603\n        command, stdout=stdout, stderr=stderr, shell=False, **kwargs  # noqa :S603\n    ) as s:\n        stdout.close()\n        stderr.close()\n\n    return s.returncode",
  "def info(cls):\n        \"\"\"\n        Show Model options\n        \"\"\"\n        infostr = f\"{cls.__doc__}\\n\" + \"\\n\".join(repr(l_) for l_ in list(cls))\n        bluemira_print(infostr)",
  "def __init__(self, loglevel: str):\n        super().__init__(daemon=True)\n\n        self.logfunc = {\"print\": bluemira_print_clean, \"error\": bluemira_error_clean}[\n            loglevel\n        ]\n        self.logfunc_flush = _bluemira_clean_flush\n        self.fd_read, self.fd_write = os.pipe()\n        self.pipe = os.fdopen(self.fd_read, encoding=\"utf-8\", errors=\"ignore\")\n        self.start()",
  "def fileno(self):\n        \"\"\"\n        Return the write file descriptor of the pipe\n        \"\"\"\n        return self.fd_write",
  "def run(self):\n        \"\"\"\n        Run the thread and pipe it all into the logger.\n        \"\"\"\n        for line in iter(self.pipe.readline, \"\"):\n            if line.startswith(\"==>\"):\n                self.logfunc_flush(line.strip(\"\\n\"))\n            else:\n                self.logfunc(line)\n\n        self.pipe.close()",
  "def close(self):\n        \"\"\"\n        Close the write end of the pipe.\n        \"\"\"\n        os.close(self.fd_write)",
  "def freecad_message_removal():\n    \"\"\"\n    Remove annoying message about freecad libdir not being set\n    \"\"\"\n    import importlib\n    import os\n\n    if \"PATH_TO_FREECAD_LIBDIR\" in os.environ:\n        return os.environ[\"PATH_TO_FREECAD_LIBDIR\"]\n    freecad_default_path = None\n    with open(importlib.util.find_spec(\"freecad\").origin, \"r\") as rr:\n        for line in rr:\n            if '_path_to_freecad_libdir = \"' in line:\n                freecad_default_path = line.split('\"')[1]\n                break\n    if freecad_default_path is not None:\n        os.environ[\"PATH_TO_FREECAD_LIBDIR\"] = freecad_default_path\n\n    return freecad_default_path",
  "class CodesError(base_err.BluemiraError):\n    \"\"\"\n    Error class for use in the codes module\n    \"\"\"\n\n    pass",
  "class FreeCADError(base_err.BluemiraError):\n    \"\"\"\n    Error class for use in the geometry module where FreeCAD throws an error.\n    \"\"\"\n\n    pass",
  "class InvalidCADInputsError(base_err.BluemiraError):\n    \"\"\"\n    Error class for use in the geometry module where inputs are not valid.\n    \"\"\"\n\n    pass",
  "class MappedParameterFrame(ParameterFrame):\n    \"\"\"\n    Special ``ParameterFrame`` that contains a set of parameter mappings.\n\n    The mappings are intended to be used to map bluemira parameters to\n    parameters in an external code.\n\n    See :class:`bluemira.base.parameter_frame.ParameterFrame` for details\n    on how to declare parameters.\n    \"\"\"\n\n    @abc.abstractproperty\n    def defaults(self) -> Dict:\n        \"\"\"\n        Default values for the ParameterFrame\n        \"\"\"\n\n    @classmethod\n    def from_defaults(cls, data: Dict) -> MappedParameterFrame:\n        \"\"\"\n        Create ParameterFrame with default values for external codes.\n\n        External codes are likely to have variables that are not changed often\n        therefore in some cases sane defaults are needed.\n\n        If a default value is not found for a given mapping it is set to NaN\n\n        \"\"\"\n        new_param_dict = {}\n        for bm_map_name, param_map in cls._mappings.items():\n            new_param_dict[bm_map_name] = {\n                \"value\": data.get(param_map.name, None),\n                \"unit\": param_map.unit,\n                \"source\": \"bluemira codes default\",\n            }\n\n        return cls.from_dict(new_param_dict)\n\n    @abc.abstractproperty\n    def mappings(self) -> Dict[str, ParameterMapping]:\n        \"\"\"\n        The mappings associated with these frame's parameters.\n\n        The keys are names of parameters in this frame, the values\n        are ``ParameterMapping`` objects containing the name of the\n        corresponding parameter in some external code.\n        \"\"\"\n\n    def update_mappings(\n        self, new_send_recv: Dict[str, Dict[Literal[\"send\", \"recv\"], bool]]\n    ):\n        \"\"\"\n        Update the mappings in this frame with new send/recv values.\n\n        Parameters\n        ----------\n        new_send_recv:\n            The new send/recv values for all, or a subset, of the\n            parameter mappings.\n            Keys are parameter names (as defined in this class, not the\n            external code), the values are a dictionary, optionally\n            containing keys 'send' and/or 'recv'. The values for the\n            inner dictionary are a boolean.\n\n        Raises\n        ------\n        CodesError:\n            If a parameter name in the input does not match the name of\n            a parameter in this frame.\n        \"\"\"\n        for param_name, send_recv_mapping in new_send_recv.items():\n            try:\n                param_mapping = self.mappings[param_name]\n            except KeyError:\n                raise CodesError(\n                    \"Cannot update parameter mapping. \"\n                    f\"No parameter with name '{param_name}' in '{type(self).__name__}'.\"\n                )\n            if (send_mapping := send_recv_mapping.get(\"send\", None)) is not None:\n                param_mapping.send = send_mapping\n            if (recv_mapping := send_recv_mapping.get(\"recv\", None)) is not None:\n                param_mapping.recv = recv_mapping",
  "class ParameterMapping:\n    \"\"\"\n    Simple class containing information on mapping of a bluemira parameter to one in\n    external software.\n\n    Parameters\n    ----------\n    name:\n       name of mapped parameter\n    recv:\n        receive data from mapped parameter (to overwrite bluemira parameter)\n    send:\n        send data to mapped parameter (from bluemira parameter)\n    \"\"\"\n\n    name: str\n    send: bool = True\n    recv: bool = True\n    unit: Optional[str] = None\n\n    _frozen = ()\n\n    def __post_init__(self):\n        \"\"\"\n        Freeze the dataclass\n        \"\"\"\n        self._frozen = (\"name\", \"unit\", \"_frozen\")\n\n    def to_dict(self) -> Dict:\n        \"\"\"\n        Convert this object to a dictionary with attributes as values.\n        \"\"\"\n        return {\n            \"name\": self.name,\n            \"send\": self.send,\n            \"recv\": self.recv,\n            \"unit\": self.unit,\n        }\n\n    @classmethod\n    def from_dict(cls, the_dict: Dict) -> \"ParameterMapping\":\n        \"\"\"\n        Create a ParameterMapping using a dictionary with attributes as values.\n        \"\"\"\n        return cls(**the_dict)\n\n    def __str__(self):\n        \"\"\"\n        Create a string representation of of this object which is more compact than that\n        provided by the default `__repr__` method.\n        \"\"\"\n        return repr(self.to_dict())\n\n    def __setattr__(self, attr: str, value: Union[bool, str]):\n        \"\"\"\n        Protect against additional attributes\n        Parameters\n        ----------\n        attr:\n            Attribute to set (name can only be set on init)\n        value:\n            Value of attribute\n        \"\"\"\n        if (\n            attr not in [\"send\", \"recv\", \"name\", \"unit\", \"_frozen\"]\n            or attr in self._frozen\n        ):\n            raise KeyError(f\"{attr} cannot be set for a {self.__class__.__name__}\")\n        elif attr in [\"send\", \"recv\"] and not isinstance(value, bool):\n            raise ValueError(f\"{attr} must be a bool\")\n        else:\n            super().__setattr__(attr, value)",
  "def defaults(self) -> Dict:\n        \"\"\"\n        Default values for the ParameterFrame\n        \"\"\"",
  "def from_defaults(cls, data: Dict) -> MappedParameterFrame:\n        \"\"\"\n        Create ParameterFrame with default values for external codes.\n\n        External codes are likely to have variables that are not changed often\n        therefore in some cases sane defaults are needed.\n\n        If a default value is not found for a given mapping it is set to NaN\n\n        \"\"\"\n        new_param_dict = {}\n        for bm_map_name, param_map in cls._mappings.items():\n            new_param_dict[bm_map_name] = {\n                \"value\": data.get(param_map.name, None),\n                \"unit\": param_map.unit,\n                \"source\": \"bluemira codes default\",\n            }\n\n        return cls.from_dict(new_param_dict)",
  "def mappings(self) -> Dict[str, ParameterMapping]:\n        \"\"\"\n        The mappings associated with these frame's parameters.\n\n        The keys are names of parameters in this frame, the values\n        are ``ParameterMapping`` objects containing the name of the\n        corresponding parameter in some external code.\n        \"\"\"",
  "def update_mappings(\n        self, new_send_recv: Dict[str, Dict[Literal[\"send\", \"recv\"], bool]]\n    ):\n        \"\"\"\n        Update the mappings in this frame with new send/recv values.\n\n        Parameters\n        ----------\n        new_send_recv:\n            The new send/recv values for all, or a subset, of the\n            parameter mappings.\n            Keys are parameter names (as defined in this class, not the\n            external code), the values are a dictionary, optionally\n            containing keys 'send' and/or 'recv'. The values for the\n            inner dictionary are a boolean.\n\n        Raises\n        ------\n        CodesError:\n            If a parameter name in the input does not match the name of\n            a parameter in this frame.\n        \"\"\"\n        for param_name, send_recv_mapping in new_send_recv.items():\n            try:\n                param_mapping = self.mappings[param_name]\n            except KeyError:\n                raise CodesError(\n                    \"Cannot update parameter mapping. \"\n                    f\"No parameter with name '{param_name}' in '{type(self).__name__}'.\"\n                )\n            if (send_mapping := send_recv_mapping.get(\"send\", None)) is not None:\n                param_mapping.send = send_mapping\n            if (recv_mapping := send_recv_mapping.get(\"recv\", None)) is not None:\n                param_mapping.recv = recv_mapping",
  "def __post_init__(self):\n        \"\"\"\n        Freeze the dataclass\n        \"\"\"\n        self._frozen = (\"name\", \"unit\", \"_frozen\")",
  "def to_dict(self) -> Dict:\n        \"\"\"\n        Convert this object to a dictionary with attributes as values.\n        \"\"\"\n        return {\n            \"name\": self.name,\n            \"send\": self.send,\n            \"recv\": self.recv,\n            \"unit\": self.unit,\n        }",
  "def from_dict(cls, the_dict: Dict) -> \"ParameterMapping\":\n        \"\"\"\n        Create a ParameterMapping using a dictionary with attributes as values.\n        \"\"\"\n        return cls(**the_dict)",
  "def __str__(self):\n        \"\"\"\n        Create a string representation of of this object which is more compact than that\n        provided by the default `__repr__` method.\n        \"\"\"\n        return repr(self.to_dict())",
  "def __setattr__(self, attr: str, value: Union[bool, str]):\n        \"\"\"\n        Protect against additional attributes\n        Parameters\n        ----------\n        attr:\n            Attribute to set (name can only be set on init)\n        value:\n            Value of attribute\n        \"\"\"\n        if (\n            attr not in [\"send\", \"recv\", \"name\", \"unit\", \"_frozen\"]\n            or attr in self._frozen\n        ):\n            raise KeyError(f\"{attr} cannot be set for a {self.__class__.__name__}\")\n        elif attr in [\"send\", \"recv\"] and not isinstance(value, bool):\n            raise ValueError(f\"{attr} must be a bool\")\n        else:\n            super().__setattr__(attr, value)",
  "class BaseRunMode(enum.Enum):\n    \"\"\"\n    Base enum class for defining run modes within a solver.\n\n    Note that no two enumeration's names should be case-insensitively\n    equal.\n    \"\"\"\n\n    def to_string(self) -> str:\n        \"\"\"\n        Convert the enum name to a string; its name in lower-case.\n        \"\"\"\n        return self.name.lower()\n\n    @classmethod\n    def from_string(cls, mode_str: str):\n        \"\"\"\n        Retrieve an enum value from a case-insensitive string.\n\n        Parameters\n        ----------\n        mode_str:\n            The run mode's name.\n        \"\"\"\n        for run_mode_str, enum_value in cls.__members__.items():\n            if run_mode_str.lower() == mode_str.lower():\n                return enum_value\n        raise ValueError(f\"Unknown run mode '{mode_str}'.\")",
  "class CodesTask(abc.ABC):\n    \"\"\"\n    Base class for a task used by a solver for an external code.\n    \"\"\"\n\n    def __init__(self, params: MappedParameterFrame, codes_name: str) -> None:\n        super().__init__()\n        self.params = params\n        self._name = codes_name\n\n    @abc.abstractmethod\n    def run(self):\n        \"\"\"Run the task.\"\"\"\n        pass\n\n    def _run_subprocess(self, command: List[str], **kwargs):\n        \"\"\"\n        Run a subprocess command and raise a CodesError if it returns a\n        non-zero exit code.\n        \"\"\"\n        return_code = run_subprocess(command, **kwargs)\n        if return_code != 0:\n            raise CodesError(\n                f\"'{self._name}' subprocess task exited with non-zero error code \"\n                f\"'{return_code}'.\"\n            )",
  "class NoOpTask(CodesTask):\n    \"\"\"\n    A task that does nothing.\n\n    This can be assigned to a solver to skip any of the setup, run, or\n    teardown stages.\n    \"\"\"\n\n    def run(self) -> None:\n        \"\"\"Do nothing.\"\"\"\n        return",
  "class CodesSetup(CodesTask):\n    \"\"\"\n    Base class for setup tasks of a solver for an external code.\n    \"\"\"\n\n    def _get_new_inputs(\n        self, remapper: Optional[Union[Callable, Dict[str, str]]] = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Retrieve inputs values to the external code from this task's\n        ParameterFrame.\n\n        Convert the inputs' units to those used by the external code.\n\n        Parameters\n        ----------\n        remapper:\n            A function or dictionary for remapping variable names.\n            Useful for renaming old variables\n\n        Returns\n        -------\n        Keys are external code parameter names, values are the input\n        values for those parameters.\n        \"\"\"\n        _inputs = {}\n\n        if not (callable(remapper) or isinstance(remapper, (type(None), Dict))):\n            raise TypeError(\"remapper is not callable or a dictionary\")\n        if isinstance(remapper, Dict):\n            orig_remap = remapper.copy()\n\n            def remapper(x):\n                return orig_remap[x]\n\n        elif remapper is None:\n\n            def remapper(x):\n                return x\n\n        for bm_name, mapping in self.params.mappings.items():\n            if not mapping.send:\n                continue\n            external_name = remapper(mapping.name)\n            bm_param = getattr(self.params, bm_name)\n            target_unit = mapping.unit\n            if isinstance(external_name, list):\n                for name in external_name:\n                    _inputs[name] = self._convert_units(bm_param, target_unit)\n            else:\n                _inputs[external_name] = self._convert_units(bm_param, target_unit)\n        return _inputs\n\n    def _convert_units(self, param, target_unit: Union[str, None]):\n        value = (\n            param.value\n            if target_unit is None or param.value is None\n            else raw_uc(param.value, param.unit, target_unit)\n        )\n        if value is None:\n            bluemira_warn(\n                f\"{param.name} is set to None or unset, consider setting mapping.send=False\"\n            )\n        return value",
  "class CodesTeardown(CodesTask):\n    \"\"\"\n    Base class for teardown tasks of a solver for an external code.\n\n    Parameters\n    ----------\n    params:\n        The parameters for this task.\n    codes_name:\n        The name of the external code the task is associated with.\n    \"\"\"\n\n    def _update_params_with_outputs(\n        self, outputs: Dict[str, float], recv_all: bool = False\n    ):\n        \"\"\"\n        Update this task's parameters with the external code's outputs.\n\n        This implicitly performs any unit conversions.\n\n        Parameters\n        ----------\n        outputs:\n            Key are the external code's parameter names, the values are\n            the values for those parameters.\n        recv_all:\n            Whether to ignore the 'recv' attribute on the parameter\n            mapping, and update all output parameter values.\n\n        Raises\n        ------\n        CodesError:\n            If any output does not have a mapping to a bluemira\n            parameter, or the output maps to a bluemira parameter that\n            does not exist in this object's ParameterFrame.\n        \"\"\"\n        mapped_outputs = self._map_external_outputs_to_bluemira_params(outputs, recv_all)\n        self.params.update_values(mapped_outputs, source=self._name)\n\n    def _map_external_outputs_to_bluemira_params(\n        self, external_outputs: Dict[str, Any], recv_all: bool\n    ) -> Dict[str, Dict[str, Any]]:\n        \"\"\"\n        Loop through external outputs, find the corresponding bluemira\n        parameter name, and map it to the output's value and unit.\n\n        Parameters\n        ----------\n        external_outputs:\n            An output produced by an external code. The keys are the\n            outputs' names (not the bluemira version of the name), the\n            values are the output's value (in the external code's unit).\n        recv_all:\n            Whether to ignore the 'recv' attribute on the parameter\n            mapping, and update all output parameter values.\n\n        Returns\n        -------\n        The keys are bluemira parameter names and the values are the\n        external codes' outputs for those parameters (with necessary\n        unit conversions made).\n        \"\"\"\n        mapped_outputs = {}\n        for bm_name, mapping in self.params.mappings.items():\n            if not (mapping.recv or recv_all):\n                continue\n            output_value = self._get_output_or_raise(external_outputs, mapping.name)\n            if mapping.unit is None:\n                bluemira_warn(f\"{mapping.name} from code {self._name} has no known unit\")\n                value = output_value\n            elif output_value is None:\n                value = output_value\n            else:\n                value = raw_uc(\n                    output_value, mapping.unit, getattr(self.params, bm_name).unit\n                )\n            mapped_outputs[bm_name] = value\n        return mapped_outputs\n\n    def _get_output_or_raise(\n        self, external_outputs: Dict[str, Any], parameter_name: str\n    ):\n        output_value = external_outputs.get(parameter_name, None)\n        if output_value is None:\n            bluemira_warn(\n                f\"No value for output parameter '{parameter_name}' from code \"\n                f\"'{self._name}', setting value to None.\"\n            )\n        return output_value",
  "class CodesSolver(abc.ABC):\n    \"\"\"\n    Base class for solvers running an external code.\n    \"\"\"\n\n    params: MappedParameterFrame\n\n    def __init__(self, params: MappedParameterFrame):\n        self.params = params\n        self._setup = self.setup_cls(self.params, self.name)\n        self._run = self.run_cls(self.params, self.name)\n        self._teardown = self.teardown_cls(self.params, self.name)\n\n    @abc.abstractproperty\n    def name(self):\n        \"\"\"\n        The name of the solver.\n\n        In the base class, this is used to find mappings and specialise\n        error messages for the concrete solver.\n        \"\"\"\n        pass\n\n    @abc.abstractproperty\n    def setup_cls(self) -> Type[CodesTask]:\n        \"\"\"\n        Class defining the run modes for the setup stage of the solver.\n\n        Typically, this class performs parameter mappings for some\n        external code, or derives dependent parameters. But it can also\n        define any required non-computational set up.\n        \"\"\"\n        pass\n\n    @abc.abstractproperty\n    def run_cls(self) -> Type[CodesTask]:\n        \"\"\"\n        Class defining the run modes for the computational stage of the\n        solver.\n\n        This class is where computations should be defined. This may be\n        something like calling a Bluemira problem, or executing some\n        external code or process.\n        \"\"\"\n        pass\n\n    @abc.abstractproperty\n    def teardown_cls(self) -> Type[CodesTask]:\n        \"\"\"\n        Class defining the run modes for the teardown stage of the\n        solver.\n\n        This class should perform any clean-up operations required by\n        the solver. This may be deleting temporary files, or could\n        involve mapping parameters from some external code to Bluemira\n        parameters.\n        \"\"\"\n        pass\n\n    @abc.abstractproperty\n    def run_mode_cls(self) -> Type[BaseRunMode]:\n        \"\"\"\n        Class enumerating the run modes for this solver.\n\n        Common run modes are RUN, MOCK, READ, etc,.\n        \"\"\"\n        pass\n\n    def execute(self, run_mode: Union[str, BaseRunMode]) -> Any:\n        \"\"\"Execute the setup, run, and teardown tasks, in order.\"\"\"\n        if isinstance(run_mode, str):\n            run_mode = self.run_mode_cls.from_string(run_mode)\n        result = None\n        if setup := self._get_execution_method(self._setup, run_mode):\n            result = setup()\n        if run := self._get_execution_method(self._run, run_mode):\n            result = run(result)\n        if teardown := self._get_execution_method(self._teardown, run_mode):\n            result = teardown(result)\n        return result\n\n    def modify_mappings(self, send_recv: Dict[str, Dict[str, bool]]):\n        \"\"\"\n        Modify the send/receive truth values of a parameter.\n\n        If a parameter's 'send' is set to False, its value will not be\n        passed to the external code (a default will be used). Likewise,\n        if a parameter's 'recv' is False, its value will not be updated\n        from the external code's outputs.\n\n        Parameters\n        ----------\n        mappings:\n            A dictionary where keys are variables to change the mappings\n            of, and values specify 'send', and or, 'recv' booleans.\n\n            E.g.,\n\n            .. code-block:: python\n\n                {\n                    \"var1\": {\"send\": False, \"recv\": True},\n                    \"var2\": {\"recv\": False}\n                }\n        \"\"\"\n        param_mappings = self.params.mappings\n        for key, val in send_recv.items():\n            try:\n                p_map = param_mappings[key]\n            except KeyError:\n                bluemira_warn(f\"No mapping known for '{key}' in '{self.name}'.\")\n            else:\n                for sr_key, sr_val in val.items():\n                    setattr(p_map, sr_key, sr_val)\n\n    def _get_execution_method(\n        self, task: CodesTask, run_mode: BaseRunMode\n    ) -> Optional[Callable]:\n        \"\"\"\n        Return the method on the task corresponding to this solver's run\n        mode (e.g., :code:`task.run`).\n\n        If the method on the task does not exist, return :code:`None`.\n        \"\"\"\n        return getattr(task, run_mode.to_string(), None)",
  "def to_string(self) -> str:\n        \"\"\"\n        Convert the enum name to a string; its name in lower-case.\n        \"\"\"\n        return self.name.lower()",
  "def from_string(cls, mode_str: str):\n        \"\"\"\n        Retrieve an enum value from a case-insensitive string.\n\n        Parameters\n        ----------\n        mode_str:\n            The run mode's name.\n        \"\"\"\n        for run_mode_str, enum_value in cls.__members__.items():\n            if run_mode_str.lower() == mode_str.lower():\n                return enum_value\n        raise ValueError(f\"Unknown run mode '{mode_str}'.\")",
  "def __init__(self, params: MappedParameterFrame, codes_name: str) -> None:\n        super().__init__()\n        self.params = params\n        self._name = codes_name",
  "def run(self):\n        \"\"\"Run the task.\"\"\"\n        pass",
  "def _run_subprocess(self, command: List[str], **kwargs):\n        \"\"\"\n        Run a subprocess command and raise a CodesError if it returns a\n        non-zero exit code.\n        \"\"\"\n        return_code = run_subprocess(command, **kwargs)\n        if return_code != 0:\n            raise CodesError(\n                f\"'{self._name}' subprocess task exited with non-zero error code \"\n                f\"'{return_code}'.\"\n            )",
  "def run(self) -> None:\n        \"\"\"Do nothing.\"\"\"\n        return",
  "def _get_new_inputs(\n        self, remapper: Optional[Union[Callable, Dict[str, str]]] = None\n    ) -> Dict[str, float]:\n        \"\"\"\n        Retrieve inputs values to the external code from this task's\n        ParameterFrame.\n\n        Convert the inputs' units to those used by the external code.\n\n        Parameters\n        ----------\n        remapper:\n            A function or dictionary for remapping variable names.\n            Useful for renaming old variables\n\n        Returns\n        -------\n        Keys are external code parameter names, values are the input\n        values for those parameters.\n        \"\"\"\n        _inputs = {}\n\n        if not (callable(remapper) or isinstance(remapper, (type(None), Dict))):\n            raise TypeError(\"remapper is not callable or a dictionary\")\n        if isinstance(remapper, Dict):\n            orig_remap = remapper.copy()\n\n            def remapper(x):\n                return orig_remap[x]\n\n        elif remapper is None:\n\n            def remapper(x):\n                return x\n\n        for bm_name, mapping in self.params.mappings.items():\n            if not mapping.send:\n                continue\n            external_name = remapper(mapping.name)\n            bm_param = getattr(self.params, bm_name)\n            target_unit = mapping.unit\n            if isinstance(external_name, list):\n                for name in external_name:\n                    _inputs[name] = self._convert_units(bm_param, target_unit)\n            else:\n                _inputs[external_name] = self._convert_units(bm_param, target_unit)\n        return _inputs",
  "def _convert_units(self, param, target_unit: Union[str, None]):\n        value = (\n            param.value\n            if target_unit is None or param.value is None\n            else raw_uc(param.value, param.unit, target_unit)\n        )\n        if value is None:\n            bluemira_warn(\n                f\"{param.name} is set to None or unset, consider setting mapping.send=False\"\n            )\n        return value",
  "def _update_params_with_outputs(\n        self, outputs: Dict[str, float], recv_all: bool = False\n    ):\n        \"\"\"\n        Update this task's parameters with the external code's outputs.\n\n        This implicitly performs any unit conversions.\n\n        Parameters\n        ----------\n        outputs:\n            Key are the external code's parameter names, the values are\n            the values for those parameters.\n        recv_all:\n            Whether to ignore the 'recv' attribute on the parameter\n            mapping, and update all output parameter values.\n\n        Raises\n        ------\n        CodesError:\n            If any output does not have a mapping to a bluemira\n            parameter, or the output maps to a bluemira parameter that\n            does not exist in this object's ParameterFrame.\n        \"\"\"\n        mapped_outputs = self._map_external_outputs_to_bluemira_params(outputs, recv_all)\n        self.params.update_values(mapped_outputs, source=self._name)",
  "def _map_external_outputs_to_bluemira_params(\n        self, external_outputs: Dict[str, Any], recv_all: bool\n    ) -> Dict[str, Dict[str, Any]]:\n        \"\"\"\n        Loop through external outputs, find the corresponding bluemira\n        parameter name, and map it to the output's value and unit.\n\n        Parameters\n        ----------\n        external_outputs:\n            An output produced by an external code. The keys are the\n            outputs' names (not the bluemira version of the name), the\n            values are the output's value (in the external code's unit).\n        recv_all:\n            Whether to ignore the 'recv' attribute on the parameter\n            mapping, and update all output parameter values.\n\n        Returns\n        -------\n        The keys are bluemira parameter names and the values are the\n        external codes' outputs for those parameters (with necessary\n        unit conversions made).\n        \"\"\"\n        mapped_outputs = {}\n        for bm_name, mapping in self.params.mappings.items():\n            if not (mapping.recv or recv_all):\n                continue\n            output_value = self._get_output_or_raise(external_outputs, mapping.name)\n            if mapping.unit is None:\n                bluemira_warn(f\"{mapping.name} from code {self._name} has no known unit\")\n                value = output_value\n            elif output_value is None:\n                value = output_value\n            else:\n                value = raw_uc(\n                    output_value, mapping.unit, getattr(self.params, bm_name).unit\n                )\n            mapped_outputs[bm_name] = value\n        return mapped_outputs",
  "def _get_output_or_raise(\n        self, external_outputs: Dict[str, Any], parameter_name: str\n    ):\n        output_value = external_outputs.get(parameter_name, None)\n        if output_value is None:\n            bluemira_warn(\n                f\"No value for output parameter '{parameter_name}' from code \"\n                f\"'{self._name}', setting value to None.\"\n            )\n        return output_value",
  "def __init__(self, params: MappedParameterFrame):\n        self.params = params\n        self._setup = self.setup_cls(self.params, self.name)\n        self._run = self.run_cls(self.params, self.name)\n        self._teardown = self.teardown_cls(self.params, self.name)",
  "def name(self):\n        \"\"\"\n        The name of the solver.\n\n        In the base class, this is used to find mappings and specialise\n        error messages for the concrete solver.\n        \"\"\"\n        pass",
  "def setup_cls(self) -> Type[CodesTask]:\n        \"\"\"\n        Class defining the run modes for the setup stage of the solver.\n\n        Typically, this class performs parameter mappings for some\n        external code, or derives dependent parameters. But it can also\n        define any required non-computational set up.\n        \"\"\"\n        pass",
  "def run_cls(self) -> Type[CodesTask]:\n        \"\"\"\n        Class defining the run modes for the computational stage of the\n        solver.\n\n        This class is where computations should be defined. This may be\n        something like calling a Bluemira problem, or executing some\n        external code or process.\n        \"\"\"\n        pass",
  "def teardown_cls(self) -> Type[CodesTask]:\n        \"\"\"\n        Class defining the run modes for the teardown stage of the\n        solver.\n\n        This class should perform any clean-up operations required by\n        the solver. This may be deleting temporary files, or could\n        involve mapping parameters from some external code to Bluemira\n        parameters.\n        \"\"\"\n        pass",
  "def run_mode_cls(self) -> Type[BaseRunMode]:\n        \"\"\"\n        Class enumerating the run modes for this solver.\n\n        Common run modes are RUN, MOCK, READ, etc,.\n        \"\"\"\n        pass",
  "def execute(self, run_mode: Union[str, BaseRunMode]) -> Any:\n        \"\"\"Execute the setup, run, and teardown tasks, in order.\"\"\"\n        if isinstance(run_mode, str):\n            run_mode = self.run_mode_cls.from_string(run_mode)\n        result = None\n        if setup := self._get_execution_method(self._setup, run_mode):\n            result = setup()\n        if run := self._get_execution_method(self._run, run_mode):\n            result = run(result)\n        if teardown := self._get_execution_method(self._teardown, run_mode):\n            result = teardown(result)\n        return result",
  "def modify_mappings(self, send_recv: Dict[str, Dict[str, bool]]):\n        \"\"\"\n        Modify the send/receive truth values of a parameter.\n\n        If a parameter's 'send' is set to False, its value will not be\n        passed to the external code (a default will be used). Likewise,\n        if a parameter's 'recv' is False, its value will not be updated\n        from the external code's outputs.\n\n        Parameters\n        ----------\n        mappings:\n            A dictionary where keys are variables to change the mappings\n            of, and values specify 'send', and or, 'recv' booleans.\n\n            E.g.,\n\n            .. code-block:: python\n\n                {\n                    \"var1\": {\"send\": False, \"recv\": True},\n                    \"var2\": {\"recv\": False}\n                }\n        \"\"\"\n        param_mappings = self.params.mappings\n        for key, val in send_recv.items():\n            try:\n                p_map = param_mappings[key]\n            except KeyError:\n                bluemira_warn(f\"No mapping known for '{key}' in '{self.name}'.\")\n            else:\n                for sr_key, sr_val in val.items():\n                    setattr(p_map, sr_key, sr_val)",
  "def _get_execution_method(\n        self, task: CodesTask, run_mode: BaseRunMode\n    ) -> Optional[Callable]:\n        \"\"\"\n        Return the method on the task corresponding to this solver's run\n        mode (e.g., :code:`task.run`).\n\n        If the method on the task does not exist, return :code:`None`.\n        \"\"\"\n        return getattr(task, run_mode.to_string(), None)",
  "def remapper(x):\n                return orig_remap[x]",
  "def remapper(x):\n                return x",
  "class ImpurityModel(Model):\n    \"\"\"\n    Impurity Model selector\n\n    0 - fixed concentration,\n    1 - concentration fixed at pedestal top, then fixed density.\n\n    Plasmod variable name: \"i_impmodel\"\n    \"\"\"\n\n    FIXED = 0\n    PED_FIXED = 1",
  "class TransportModel(Model):\n    \"\"\"\n    Transport Model Selector\n\n    1 - simple gyrobohm scaling with imposed H factor,\n    555 - H factor scaling from F. Palermo\n    111 - another model based on gyro-Bohm transport\n    2 - no reference in the source code\n\n    Plasmod variable name: \"i_modeltype\"\n    \"\"\"\n\n    GYROBOHM_1 = 1\n    GYROBOHM_2 = 111\n    UNKNOWN = 2\n    H_FACTOR = 555",
  "class EquilibriumModel(Model):\n    \"\"\"\n    Equilibrium Model Selector\n\n    1 - EMEQ solves equilibrium with given q95, with sawteeth.\n    2 - EMEQ solves with given Ip, with sawteeth\n\n    Plasmod variable name: \"i_equiltype\"\n    \"\"\"\n\n    q95_sawtooth = 1\n    Ip_sawtooth = 2",
  "class SafetyProfileModel(Model):\n    \"\"\"\n    Safety Factor Profile Model Selector\n\n    0 - PLASMOD allows q < 1 in the core (fully relaxed q profile)\n    1 - PLASMOD clamps q >= 1 in the core (sawteeth forced)\n\n    Plasmod variable name: isawt\n\n    NOTE: Running with 1 means that p' and FF' will not correspond well\n    with jpar.\n    \"\"\"\n\n    FULLY_RELAXED = 0\n    SAWTEETH = 1",
  "class PedestalModel(Model):\n    \"\"\"\n    Pedestal Model Selector\n\n    1 - fixed pedestal temperature (Teped_in),\n    2 - Saarelma scaling\n\n    Plasmod variable name: \"i_pedestal\"\n    \"\"\"\n\n    FIX_TEMP = 1\n    SAARELMA = 2",
  "class SOLModel(Model):\n    \"\"\"\n    SOL Model Selector:\n\n    0 - fit based on Eich scaling\n    1 - Mattia Siccinio's model\n\n    Plasmod variable name: \"isiccir\"\n    \"\"\"\n\n    EICH_FIT = 0\n    SICCINIO = 1",
  "class PLHModel(Model):\n    \"\"\"\n    L-H transition power scaling model\n\n    6 - Martin\n\n    Plasmod variable name: \"plh\"\n    \"\"\"\n\n    MARTIN = 6",
  "class Profiles(Model):\n    \"\"\"\n    Profile Selector:\n\n    x       [-] normalized toroidal flux coordinate (Phi/Phi_b)\n    ne      [10\u00b9\u2079/m3] electron density profile\n    Te      [keV] Electron temperature profile\n    Ti      [keV] Ion temperature profile\n    psi     [Wb] Poloidal flux profile\n    phi     [Wb] Toroidal flux profile\n    press   [Pa] Plasma pressure profile\n    pprime  [Pa/Wb] p' profile\n    ffprime [(m*T) * (m*T) / Wb == T] FF' profile\n    kprof   [-] Elongation profile\n    dprof   [-] Triangularity profile\n    shif    [m] Grad-Shafranov shift profile\n    g2      [m\u00b2] < mod(grad V)\u00b2/r\u00b2> g2 metric coefficient's profile\n    g3      [m\u207b\u00b2] < 1/r\u00b2> g3 metric coefficient's profile\n    volprof [m\u00b3] Volume profile\n    vprime  [m\u00b3] Volume profile\n    ipol    [m*T] Poloidal current profile\n    qprof   [-] Safety factor profile\n    jpar    [A/m\u00b2] Parallel current density profile\n    jbs     [A/m\u00b2] Bootstrap parallel current density profile\n    jcd     [A/m\u00b2] CD parallel current density profile\n    nions   [10\u00b9\u2079/m\u00b3] ion density profile\n    nfuel   [10\u00b9\u2079/m\u00b3] fuel density profile\n    ndeut   [10\u00b9\u2079/m\u00b3] deuterium density profile\n    ntrit   [10\u00b9\u2079/m\u00b3] tritium density profile\n    nalf    [10\u00b9\u2079/m\u00b3] helium density profile\n\n    Not yet enabled in plasmod:\n     * qrad   radiation density profile\n     * qneut  neutron fusion power density profile\n\n    \"\"\"\n\n    x = \"x\"\n    ne = \"n_e\"\n    Te = \"Te\"\n    Ti = \"Ti\"\n    psi = \"psi\"\n    phi = \"phi\"\n    press = \"pressure\"\n    pprime = \"pprime\"\n    ffprime = \"ffprime\"\n    kprof = \"kappa\"\n    dprof = \"delta\"\n    shif = \"GS\"\n    g2 = \"g2\"\n    g3 = \"g3\"\n    volprof = \"V\"\n    vprime = \"Vprime\"\n    ipol = \"i_pol\"\n    qprof = \"q\"\n    jpar = \"jpar\"\n    jbs = \"jbs\"\n    jcd = \"jcd\"\n    nions = \"n_ion\"\n    nfuel = \"n_fuel\"\n    ndeut = \"n_D\"\n    ntrit = \"n_T\"\n    nalf = \"n_He\"",
  "class PlasmaFixedBoundaryParams:\n    \"\"\"Plasma Transport Fixed Boundary parameters\"\"\"\n\n    r_0: float\n    a: float\n    kappa_u: float\n    kappa_l: float\n    delta_u: float\n    delta_l: float\n\n    _fields = None\n\n    def tabulate(self) -> str:\n        \"\"\"\n        Tabulate dataclass\n        \"\"\"\n        return tabulate(\n            list(asdict(self).items()),\n            headers=[\"name\", \"value\"],\n            tablefmt=\"simple\",\n            numalign=\"right\",\n        )\n\n    @classmethod\n    def fields(cls) -> List:\n        \"\"\"List of fields in the dataclass\"\"\"\n        if cls._fields is None:\n            cls._fields = [k.name for k in fields(cls)]\n        return cls._fields",
  "class TransportSolverParams(ParameterFrame):\n    \"\"\"Transport Solver ParameterFrame\"\"\"\n\n    A: Parameter[float]\n    R_0: Parameter[float]\n    I_p: Parameter[float]\n    B_0: Parameter[float]\n    V_p: Parameter[float]\n    v_burn: Parameter[float]\n    kappa_95: Parameter[float]\n    delta_95: Parameter[float]\n    delta: Parameter[float]\n    kappa: Parameter[float]\n    q_95: Parameter[float]\n    f_ni: Parameter[float]",
  "def create_plasma_xz_cross_section(\n    parameterisation: GeometryParameterisation,\n    transport_params: ParameterFrame,\n    params: PlasmaFixedBoundaryParams,\n    kappa_95: float,\n    delta_95: float,\n    lcfs_options: Dict[str, Dict],\n    source: str,\n) -> PhysicalComponent:\n    \"\"\"\n    Build the plasma x-z cross-section, get its volume and update transport solver\n    parameters\n    \"\"\"\n    plasma = PhysicalComponent(\n        \"Plasma\", shape=BluemiraFace(parameterisation.create_shape())\n    )\n    lcfs = plasma.shape\n    plasma_volume = 2 * np.pi * lcfs.center_of_mass[0] * lcfs.area\n\n    # Update transport parameter valupes\n    transport_params.kappa.set_value((params.kappa_u + params.kappa_l) / 2, source)\n    transport_params.delta.set_value((params.delta_u + params.delta_l) / 2, source)\n\n    transport_params.V_p.set_value(plasma_volume, source)\n    transport_params.kappa_95.set_value(kappa_95, source)\n    transport_params.delta_95.set_value(delta_95, source)\n\n    # Set mesh options\n    lcfs.boundary[0].mesh_options = lcfs_options[\"lcfs\"]\n    lcfs.mesh_options = lcfs_options[\"face\"]\n\n    bluemira_debug(\n        f\"FB Params\\n\\n\"\n        f\"{params.tabulate()}\\n\\n\"\n        f\"Transport Params\\n\\n\"\n        f\"{transport_params.tabulate(keys=['name', 'value', 'unit'], tablefmt='simple')}\"\n    )\n    return plasma",
  "def _run_transport_solver(\n    transport_solver: CodesSolver,\n    transport_params: ParameterFrame,\n    transport_run_mode: Union[str, BaseRunMode],\n) -> Tuple[ParameterFrame, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Run transport solver\"\"\"\n    transport_solver.params.update_from_frame(transport_params)\n    transp_out_params = transport_solver.execute(transport_run_mode)\n\n    return (\n        transp_out_params,\n        transport_solver.get_profile(\"x\"),\n        transport_solver.get_profile(\"pprime\"),\n        transport_solver.get_profile(\"ffprime\"),\n    )",
  "def _update_delta_kappa(\n    params: PlasmaFixedBoundaryParams,\n    kappa_95: float,\n    kappa95_t: float,\n    delta_95: float,\n    delta95_t: float,\n    relaxation: float,\n) -> float:\n    \"\"\"\n    Recalculate Delta and Kappa and calculate the iteration error\n    \"\"\"\n    err_delta = abs(delta_95 - delta95_t) / delta95_t\n    err_kappa = abs(kappa_95 - kappa95_t) / kappa95_t\n    iter_err = max(err_delta, err_kappa)\n\n    # calculate the new kappa_u and delta_u\n    kappa_u_0 = params.kappa_u\n    delta_u_0 = params.delta_u\n\n    kappa_u = (1 - relaxation) * kappa_u_0 * (\n        kappa95_t / kappa_95\n    ) + relaxation * kappa_u_0\n    delta_u = (1 - relaxation) * delta_u_0 * (\n        delta95_t / delta_95\n    ) + relaxation * delta_u_0\n\n    bluemira_debug(\n        \"Previous shape parameters:\\n\\t\"\n        f\"{kappa_u_0=:.3e}, {delta_u_0=:.3e}\\n\"\n        \"Recalculated shape parameters:\\n\\t\"\n        f\"{kappa_u=:.3e}, {delta_u=:.3e}\\n\\n\"\n        f\"Target kappa 95, actual kappa 95 = {kappa95_t:.3e}, {kappa_95:.3e}\\n\"\n        f\"Target delta 95, actual delta 95 = {delta95_t:.3e}, {delta_95:.3e}\\n\"\n    )\n    params.kappa_u = kappa_u\n    params.delta_u = delta_u\n\n    return iter_err",
  "def solve_transport_fixed_boundary(\n    parameterisation: GeometryParameterisation,\n    transport_solver: CodesSolver,\n    gs_solver: FemGradShafranovFixedBoundary,\n    kappa95_t: float,\n    delta95_t: float,\n    lcar_mesh: float = 0.15,\n    max_iter: int = 30,\n    iter_err_max: float = 1e-5,\n    max_inner_iter: int = 20,\n    inner_iter_err_max: float = 1e-4,\n    relaxation: float = 0.2,\n    transport_run_mode: Union[str, BaseRunMode] = \"run\",\n    mesh_filename: str = \"FixedBoundaryEquilibriumMesh\",\n    plot: bool = False,\n    debug: bool = False,\n    gif: bool = False,\n    refine: bool = False,\n    num_levels: int = 2,\n    distance: float = 1.0,\n):\n    \"\"\"\n    Solve the plasma fixed boundary problem using delta95 and kappa95 as target\n    values and iterating on a transport solver to have consistency with pprime\n    and ffprime.\n\n    Parameters\n    ----------\n    parameterisation:\n        Geometry parameterisation class for the plasma\n    transport_solver:\n        Transport Solver to call\n    gs_solver:\n        Grad-Shafranov Solver instance\n    kappa95_t:\n        Target value for kappa at 95%\n    delta95_t:\n        Target value for delta at 95%\n    lcar_mesh:\n        Value of the characteristic length used to generate the mesh to solve the\n        Grad-Shafranov problem\n    max_iter:\n        Maximum number of iteration between Grad-Shafranov and the transport solver\n    iter_err_max:\n        Convergence maximum error to stop the iteration\n    max_inner_iter:\n        Maximum number of inner iterations on the flux functions\n    inner_iter_err_max:\n        Inner convergence error on when iterating flux functions\n    relaxation:\n        Iteration relaxing factor\n    transport_run_mode:\n        Run mode for transport solver\n    mesh_filename:\n        filename for mesh output file\n    plot:\n        Whether or not to plot\n    refine:\n        Whether or not the mesh should be refined around the magnetic axis\n    num_levels:\n        number of refinement levels\n    distance:\n        maximum distance from the magnetic axis to which the refinement will be applied\n\n    Returns\n    -------\n    equilibrium: FixedBoundaryEquilibrium\n        Final fixed boundary equilibrium result from the transport <-> fixed boundary\n        equilibrium solve\n    \"\"\"\n    kappa_95 = kappa95_t\n    delta_95 = delta95_t\n\n    directory = get_bluemira_path(\"\", subfolder=\"generated_data\")\n    mesh_name_msh = mesh_filename + \".msh\"\n\n    paramet_params = PlasmaFixedBoundaryParams(\n        **{\n            k: v\n            for k, v in zip(\n                parameterisation.variables.names, parameterisation.variables.values\n            )\n            if k in PlasmaFixedBoundaryParams.fields()\n        }\n    )\n\n    transport_params = TransportSolverParams.from_frame(\n        deepcopy(transport_solver.params)\n    )\n\n    lcfs_options = {\n        \"face\": {\"lcar\": lcar_mesh, \"physical_group\": \"plasma_face\"},\n        \"lcfs\": {\"lcar\": lcar_mesh, \"physical_group\": \"lcfs\"},\n    }\n\n    plot = any((plot, debug, gif))\n    folder = try_get_bluemira_path(\"\", subfolder=\"generated_data\", allow_missing=False)\n    figname = \"Transport iteration \"\n    f, ax = None, None\n\n    for n_iter in range(max_iter):\n        transp_out_params, x, pprime, ffprime = _run_transport_solver(\n            transport_solver, transport_params, transport_run_mode\n        )\n\n        f_pprime = interp1d(x, pprime, fill_value=\"extrapolate\")\n        f_ffprime = interp1d(x, ffprime, fill_value=\"extrapolate\")\n\n        psi_plasmod = transport_solver.get_profile(\"psi\")\n        x_psi_plasmod = np.sqrt(psi_plasmod / psi_plasmod[-1])\n\n        q = transport_solver.get_profile(\"q\")\n        press = transport_solver.get_profile(\"pressure\")\n        q_func = interp1d(x, q, fill_value=\"extrapolate\")\n        p_func = interp1d(x, press, fill_value=\"extrapolate\")\n\n        if plot:\n            if ax is not None:\n                for axis in ax.flat:\n                    axis.clear()\n            f, ax = plot_default_profiles(transport_solver, show=False, f=f, ax=ax)\n\n            f.suptitle(figname + str(n_iter))\n            plt.pause(PLT_PAUSE)\n            if debug or gif:\n                save_figure(\n                    f,\n                    figname + str(n_iter),\n                    save=True,\n                    folder=folder,\n                    dpi=DPI_GIF,\n                )\n\n        plasma = create_plasma_xz_cross_section(\n            parameterisation,\n            transport_params,\n            paramet_params,\n            kappa_95,\n            delta_95,\n            lcfs_options,\n            f\"from equilibrium iteration {n_iter}\",\n        )\n\n        mesh = create_mesh(\n            plasma,\n            directory,\n            mesh_filename,\n            mesh_name_msh,\n        )\n\n        # store the created mesh as coarse mesh\n        coarse_mesh = mesh\n\n        gs_solver.set_mesh(mesh)\n\n        points = gs_solver.mesh.coordinates()\n        psi2d_0 = np.zeros(len(points))\n\n        for n_iter_inner in range(max_inner_iter):\n            gs_solver.set_profiles(\n                f_pprime,\n                f_ffprime,\n                transp_out_params.I_p.value,\n                transp_out_params.B_0.value,\n                transp_out_params.R_0.value,\n            )\n\n            bluemira_print(\n                f\"Solving fixed boundary Grad-Shafranov...[inner iteration: {n_iter_inner}]\"\n            )\n\n            equilibrium = gs_solver.solve(\n                plot=plot,\n                debug=debug,\n                gif=gif,\n                figname=f\"{n_iter} Fixed boundary equilibrium iteration \",\n            )\n\n            x1d, flux_surfaces = get_flux_surfaces_from_mesh(\n                mesh, gs_solver.psi_norm_2d, x_1d=x_psi_plasmod\n            )\n\n            x1d, volume, _, g2, g3 = calc_metric_coefficients(\n                flux_surfaces, gs_solver.grad_psi, x1d, gs_solver.psi_ax\n            )\n            _, _, _, pprime, _, ffprime = calc_curr_dens_profiles(\n                x1d,\n                p_func(x1d),\n                q_func(x1d),\n                g2,\n                g3,\n                volume,\n                transp_out_params.I_p.value,\n                transp_out_params.B_0.value,\n                transp_out_params.R_0.value,\n                gs_solver.psi_ax,\n                gs_solver.psi_b,\n            )\n\n            f_pprime = interp1d(x1d, pprime, fill_value=\"extrapolate\")\n            f_ffprime = interp1d(x1d, ffprime, fill_value=\"extrapolate\")\n\n            psi2d = np.array([gs_solver.psi(p) for p in points])\n\n            eps_psi2d = np.linalg.norm(psi2d - psi2d_0, ord=2) / np.linalg.norm(\n                psi2d, ord=2\n            )\n\n            if eps_psi2d < inner_iter_err_max:\n                break\n            else:\n                bluemira_print(f\"Error on psi2d = {eps_psi2d} > {inner_iter_err_max}\")\n                psi2d_0 = psi2d\n                if refine:\n                    magnetic_axis = find_magnetic_axis(gs_solver.psi, gs_solver.mesh)\n                    magnetic_axis = np.array([magnetic_axis[0], magnetic_axis[1], 0])\n                    mesh = refine_mesh(coarse_mesh, magnetic_axis, distance, num_levels)\n                    bluemira_print(f\"Mesh refined on magnetic axis {magnetic_axis[:2]}\")\n                    gs_solver.set_mesh(mesh)\n\n        _, kappa_95, delta_95 = calculate_plasma_shape_params(\n            gs_solver.psi_norm_2d,\n            mesh,\n            np.sqrt(0.95),\n        )\n\n        iter_err = _update_delta_kappa(\n            paramet_params,\n            kappa_95,\n            kappa95_t,\n            delta_95,\n            delta95_t,\n            relaxation,\n        )\n\n        bluemira_print(\n            f\"{transport_solver.name} <-> Fixed boundary G-S iter {n_iter} : {iter_err:.3E}\"\n        )\n\n        if iter_err <= iter_err_max:\n            message = bluemira_print\n            line_1 = f\"successfully converged in {n_iter} iterations\"\n            ltgt = \"<\"\n            break\n\n        # update parameters\n        for name, value in asdict(paramet_params).items():\n            parameterisation.adjust_variable(name, value)\n\n    else:\n        # If we don't break we didn't converge\n        message = bluemira_warn\n        line_1 = f\"did not converge within {max_iter} iterations\"\n        ltgt = \">\"\n\n    message(\n        f\"{transport_solver.name} <-> Fixed boundary G-S {line_1}:\\n\\t\"\n        f\"Target kappa_95: {kappa95_t:.3f}\\n\\t\"\n        f\"Actual kappa_95: {kappa_95:.3f}\\n\\t\"\n        f\"Target delta_95: {delta95_t:.3f}\\n\\t\"\n        f\"Actual delta_95: {delta_95:.3f}\\n\\t\"\n        f\"Error: {iter_err:.3E} {ltgt} {iter_err_max:.3E}\\n\"\n    )\n\n    if gif:\n        make_gif(folder, figname, clean=not debug)\n    return equilibrium",
  "def calc_metric_coefficients(\n    flux_surfaces: List[ClosedFluxSurface],\n    grad_psi_2D_func: Callable[[np.ndarray], np.ndarray],\n    psi_norm_1D: np.ndarray,\n    psi_ax: float,\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Calculate metric coefficients of a set of flux surfaces.\n\n    Parameters\n    ----------\n    flux_surfaces: List[ClosedFluxSurface]\n        List of closed flux surfaces on which to calculate the coefficients\n    grad_psi_2D_func:\n        Callable which calculates grad psi of the form f(p: Iterable[2]) = float\n    psi_norm_1D:\n        Array of 1-D normalised psi values\n    psi_ax:\n        Poloidal magnetic flux at the magnetic axis\n\n    Returns\n    -------\n    psi_norm_1D:\n        1-D vector of normalised psi values at which the coefficients were calculated\n    volume:\n        1-D volume vector\n    g1:\n        1-D g1 vector\n    g2:\n        1-D g2 vector\n    g3:\n        1-D g3 vector\n    \"\"\"\n    if psi_norm_1D[0] != 0:\n        # Initialise with 0 at axis\n        psi_norm_1D = np.insert(psi_norm_1D, 0, 0)\n    nx = psi_norm_1D.size\n\n    g1, g2, g3, volume = np.zeros((4, nx))\n    volume[1:] = [fs.volume for fs in flux_surfaces]\n\n    volume_func = interp1d(psi_norm_1D, volume, fill_value=\"extrapolate\")\n    grad_vol_1D_array = approx_derivative(volume_func, psi_norm_1D).diagonal()\n\n    def grad_psi_norm(x: np.ndarray) -> np.ndarray:\n        return np.hypot(*grad_psi_2D_func(x))\n\n    for i, fs in enumerate(flux_surfaces):\n        points = fs.coords.xz.T\n        dx = np.diff(fs.coords.x)\n        dz = np.diff(fs.coords.z)\n        dl = np.hypot(dx, dz)\n        x_data = np.concatenate([np.array([0.0]), np.cumsum(dl)])\n\n        psi_norm_fs = psi_norm_1D[i + 1]\n\n        grad_psi_norm_points = np.array([grad_psi_norm(p) for p in points])\n        # Scale from grad_psi_norm to get the grad_psi_norm_norm\n        psi_fs = psi_ax * (1 - psi_norm_fs**2)\n        factor = 1 / (2 * psi_ax * np.sqrt(1 - psi_fs / psi_ax))\n        grad_psi_norm_norm_points = factor * grad_psi_norm_points\n\n        # Poloidal field\n        bp = grad_psi_norm_points / (2 * np.pi * fs.coords.x)\n\n        grad_vol_1D_fs = grad_vol_1D_array[i + 1]\n        grad_vol_norm_2 = (grad_psi_norm_norm_points * grad_vol_1D_fs) ** 2\n\n        y0_data = 1 / bp\n        y1_data = grad_vol_norm_2 * y0_data\n        y3_data = 1 / (fs.coords.x**2 * bp)\n        y2_data = grad_vol_norm_2 * y3_data\n\n        denom = np.trapz(y0_data, x_data)\n        g1[i + 1] = np.trapz(y1_data, x_data) / denom\n        g2[i + 1] = np.trapz(y2_data, x_data) / denom\n        g3[i + 1] = np.trapz(y3_data, x_data) / denom\n        # NOTE: To future self, g1 is not used (right now), and the calculation could\n        # be removed to speed things up.\n\n    g2_temp = interp1d(\n        psi_norm_1D[1:-1], g2[1:-1], \"quadratic\", fill_value=\"extrapolate\"\n    )\n    g2[-1] = g2_temp(psi_norm_1D[-1])\n\n    g3_temp = interp1d(psi_norm_1D[1:-1], g3[1:-1], fill_value=\"extrapolate\")\n    g3[0] = g3_temp(psi_norm_1D[0])\n    g3[-1] = g3_temp(psi_norm_1D[-1])\n\n    return psi_norm_1D, volume, g1, g2, g3",
  "def calc_curr_dens_profiles(\n    psi_norm_1D: np.ndarray,\n    p: np.ndarray,\n    q: np.ndarray,\n    g2: np.ndarray,\n    g3: np.ndarray,\n    volume: np.ndarray,\n    I_p: float,\n    B_0: float,\n    R_0: float,\n    psi_ax: float,\n    psi_b: float,\n) -> Tuple[float, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Calculate pprime and ffprime from metric coefficients, emulating behaviour\n    in PLASMOD.\n\n    Parameters\n    ----------\n    psi_norm_1D:\n        1-D normalised psi array\n    p:\n        1-D pressure array\n    q:\n        1-D safety factor array\n    g2:\n        1-D g2 metric array\n    g3:\n        1-D g3 metric array\n    volume:\n        1-D volume array\n    I_p:\n        Plasma current [A]. If 0.0, recalculated here.\n    B_0:\n        Toroidal field at R_0 [T]\n    R_0:\n        Major radius [m]\n    psi_ax:\n        Poloidal magnetic flux at the magnetic axis [V.s]\n    psi_b:\n        Poloidal magnetic flux at the boundary [V.s]\n\n    Returns\n    -------\n    I_p:\n        Plasma current [A] (calculated if I_p=0)\n    phi_1D:\n        Toroidal magnetic flux 1-D array\n    psi_1D:\n        Poloidal magnetic flux 1-D array\n    pprime:\n        p' 1-D array\n    F:\n        F 1-D array\n    ff_prime:\n        FF' 1-D array\n\n    Notes\n    -----\n    Fable et al., A stable scheme for computation of coupled transport and\n    equilibrium equations in tokamaks\n\n    https://pure.mpg.de/rest/items/item_2144754/component/file_2144753/content\n    \"\"\"\n    psi_1D = psi_ax - psi_norm_1D**2 * (psi_ax - psi_b)\n\n    psi_1D_0 = psi_1D\n    no_iter = 50\n    for _ in range(no_iter):\n        # calculate pprime profile from p\n        p_fun_psi1D = interp1d(psi_1D, p, \"linear\", fill_value=\"extrapolate\")\n        pprime = approx_derivative(p_fun_psi1D, psi_1D).diagonal()\n\n        # Here we preserve some PLASMOD notation, for future sanity\n        q3 = q / g3\n        AA = g2 / q3**2 + (16 * np.pi**4) * g3  # noqa: N806\n        C = -4 * np.pi**2 * MU_0 * np.gradient(p, psi_norm_1D) / AA  # noqa: N806\n        dum3 = g2 / q3\n        dum2 = np.gradient(dum3, psi_norm_1D)\n        B = -dum2 / q3 / AA  # noqa: N806\n        Fb = -R_0 * B_0 / (2 * np.pi)  # noqa: N806\n\n        dum2 = cumulative_trapezoid(B, psi_norm_1D, initial=0)\n        dum1 = np.exp(2.0 * dum2)\n        dum1 = dum1 / dum1[-1]\n        dum3 = cumulative_trapezoid(C / dum1, psi_norm_1D, initial=0)\n        dum3 = dum3 - dum3[-1]\n\n        y = dum1 * (dum3 + 0.5 * Fb**2)\n        dum2 = g2 / q3\n        dum3 = np.gradient(dum2, psi_1D)\n        betahat = dum3 / q3 / AA\n        chat = -4 * np.pi**2 * MU_0 * pprime / AA\n        # EPS clipping here otherwise DOLFIN crashes with index error in MeshEntity.cpp\n        FF = np.sqrt(2.0 * np.clip(y, EPS, None))  # noqa: N806\n\n        ff_prime = 4 * np.pi**2 * (chat - betahat * FF**2)\n\n        phi_1D = -cumulative_trapezoid(q, psi_1D, initial=0)\n\n        F = 2 * np.pi * FF\n        d_psi_dv = -FF / q * g3\n        psi_1D = np.flip(\n            cumulative_trapezoid(np.flip(d_psi_dv), np.flip(volume), initial=0)\n        )\n\n        rms_error = np.sqrt(np.mean((psi_1D - psi_1D_0) ** 2))\n\n        psi_1D_0 = psi_1D\n\n        if rms_error <= 1e-5:\n            break\n    else:\n        bluemira_warn(\n            f\"Jackpot, you've somehow found a set of inputs for which this calculation does not converge almost immediately.\"\n            f\"{rms_error=} after {no_iter} iterations.\"\n        )\n\n    if I_p == 0:\n        I_p = -g2[-1] * d_psi_dv[-1] / (4 * np.pi**2 * MU_0)\n\n    return I_p, phi_1D, psi_1D, pprime, F, ff_prime",
  "def tabulate(self) -> str:\n        \"\"\"\n        Tabulate dataclass\n        \"\"\"\n        return tabulate(\n            list(asdict(self).items()),\n            headers=[\"name\", \"value\"],\n            tablefmt=\"simple\",\n            numalign=\"right\",\n        )",
  "def fields(cls) -> List:\n        \"\"\"List of fields in the dataclass\"\"\"\n        if cls._fields is None:\n            cls._fields = [k.name for k in fields(cls)]\n        return cls._fields",
  "def grad_psi_norm(x: np.ndarray) -> np.ndarray:\n        return np.hypot(*grad_psi_2D_func(x))",
  "class PlasmodSolverParams(MappedParameterFrame):\n    \"\"\"Parameters required in :class:`bluemira.codes.plasmod.Solver`.\"\"\"\n\n    # Input parameters\n    A: Parameter[float]\n    \"\"\"Plasma aspect ratio [dimensionless].\"\"\"\n    B_0: Parameter[float]\n    \"\"\"Toroidal field at plasma center [T].\"\"\"\n    delta_95: Parameter[float]\n    \"\"\"Plasma triangularity at 95% flux [dimensionless].\"\"\"\n    kappa_95: Parameter[float]\n    \"\"\"Plasma elongation at 95% flux [dimensionless].\"\"\"\n    R_0: Parameter[float]\n    \"\"\"Plasma major radius [m].\"\"\"\n    V_p: Parameter[float]\n    \"\"\"\n    Constrained plasma volume (set negative value to disable volume constraining) [m3].\n    \"\"\"\n    e_nbi: Parameter[float]\n    \"\"\"NBI energy [keV].\"\"\"\n    f_ni: Parameter[float]\n    \"\"\"Required fraction of non inductive current, if 0, dont use CD [dimensionless].\"\"\"\n    q_control: Parameter[float]\n    \"\"\"Fixed auxiliary heating power required for control [MW].\"\"\"\n    PsepB_qAR_max: Parameter[float]\n    \"\"\"Divertor challenging criterion Psep * Bt / (q95 * A * R_0) [MW.T/m]\"\"\"\n\n    # In-out parameters\n    delta: Parameter[float]\n    \"\"\"\n    Plasma edge triangularity (used only for first iteration, then\n    iterated to constrain delta95) [dimensionless].\n    \"\"\"\n    kappa: Parameter[float]\n    \"\"\"\n    Plasma edge elongation (used only for first iteration, then\n    iterated to constrain kappa95) [dimensionless].\n    \"\"\"\n    I_p: Parameter[float]\n    \"\"\"\n    Plasma current (used if i_equiltype == 2. Otherwise Ip is\n    calculated and q95 is used as input) [MA].\n    \"\"\"\n    q_95: Parameter[float]\n    \"\"\"\n    Safety factor at 95% flux surface (used if i_equiltype == 1.\n    Otherwise q95 is calculated and Ip is used as input) [dimensionless].\n    \"\"\"\n    T_e_ped: Parameter[float]\n    \"\"\"Electrons/ions temperature at pedestal (ignored if i_pedestal = 2) [keV].\"\"\"\n\n    # Output parameters\n    beta_p: Parameter[float]\n    \"\"\"Poloidal beta [dimensionless].\"\"\"\n    beta_N: Parameter[float]  # noqa: N815\n    \"\"\"Normalized beta [dimensionless].\"\"\"\n    f_bs: Parameter[float]\n    \"\"\"Plasma bootstrap current fraction [dimensionless].\"\"\"\n    l_i: Parameter[float]\n    \"\"\"Normalised plasma internal inductance [dimensionless].\"\"\"\n    H_star: Parameter[float]\n    \"\"\"Radiation-corrected H-factor [dimensionless].\"\"\"\n    tau_e: Parameter[float]\n    \"\"\"Global energy confinement time [s].\"\"\"\n    res_plasma: Parameter[float]\n    \"\"\"Plasma resistance [Ohm].\"\"\"\n    P_fus_DD: Parameter[float]\n    \"\"\"DD fusion power [W].\"\"\"\n    P_fus_DT: Parameter[float]\n    \"\"\"DT fusion power [W].\"\"\"\n    P_fus: Parameter[float]\n    \"\"\"Fusion power [W].\"\"\"\n    P_rad: Parameter[float]\n    \"\"\"Total radiation power [W].\"\"\"\n    P_sep: Parameter[float]\n    \"\"\"Total power across plasma separatrix [W].\"\"\"\n    P_sync: Parameter[float]\n    \"\"\"Synchrotron radiation power [W].\"\"\"\n    P_brehms: Parameter[float]\n    \"\"\"Bremsstrahlung radiation power [W].\"\"\"\n    P_line: Parameter[float]\n    \"\"\"Line radiation power [W].\"\"\"\n    P_LH: Parameter[float]\n    \"\"\"LH transition power [W].\"\"\"\n    P_ohm: Parameter[float]\n    \"\"\"Ohmic heating power [W].\"\"\"\n    Z_eff: Parameter[float]\n    \"\"\"Plasma effective charge [dimensionless].\"\"\"\n    v_burn: Parameter[float]\n    \"\"\"Target loop voltage (if lower than -1e-3, ignored)-> plasma loop voltage [V].\"\"\"\n\n    _mappings = deepcopy(mappings)\n    _defaults = PlasmodInputs()\n\n    @property\n    def mappings(self) -> Dict[str, ParameterMapping]:\n        \"\"\"Define mappings between these parameters and Plasmod's.\"\"\"\n        return self._mappings\n\n    @property\n    def defaults(self) -> Dict[str, Union[float, Enum]]:\n        \"\"\"Defaults for Plasmod\"\"\"\n        return self._defaults.to_dict()\n\n    @classmethod\n    def from_defaults(cls) -> MappedParameterFrame:\n        \"\"\"\n        Initialise from defaults\n        \"\"\"\n        return super().from_defaults(asdict(cls._defaults))",
  "def mappings(self) -> Dict[str, ParameterMapping]:\n        \"\"\"Define mappings between these parameters and Plasmod's.\"\"\"\n        return self._mappings",
  "def defaults(self) -> Dict[str, Union[float, Enum]]:\n        \"\"\"Defaults for Plasmod\"\"\"\n        return self._defaults.to_dict()",
  "def from_defaults(cls) -> MappedParameterFrame:\n        \"\"\"\n        Initialise from defaults\n        \"\"\"\n        return super().from_defaults(asdict(cls._defaults))",
  "class Run(CodesTask):\n    \"\"\"\n    The 'Run' class for plasmod transport solver.\n\n    Parameters\n    ----------\n    params:\n        The bluemira parameters for the task. Note that this task does\n        not apply any mappings to the ParameterFrame, so they should\n        already be set. Most likely by a solver.\n    input_file:\n        The path to the plasmod input file.\n    output_file:\n        The path to which the plasmod scalar output file should be\n        written.\n    profiles_file:\n        The path to which the plasmod profiles output file should be\n        written.\n    directory:\n        The directory to run the code in\n    binary:\n        The name of, or path to, the plasmod binary. If this is not an\n        absolute path, the binary must be on the system path.\n    \"\"\"\n\n    params: PlasmodSolverParams\n\n    def __init__(\n        self,\n        params: PlasmodSolverParams,\n        input_file: str,\n        output_file: str,\n        profiles_file: str,\n        directory: str = \"./\",\n        binary=PLASMOD_BINARY,\n    ):\n        super().__init__(params, PLASMOD_NAME)\n        self.binary = binary\n        self.input_file = input_file\n        self.output_file = output_file\n        self.profiles_file = profiles_file\n        self.directory = directory\n\n    def run(self):\n        \"\"\"\n        Run the plasmod shell task.\n\n        Runs plasmod on the command line using the given input files and\n        output path.\n\n        Raises\n        ------\n        CodesError\n            If the subprocess returns a non-zero exit code or raises an\n            OSError (e.g., the plasmod binary does not exist).\n        \"\"\"\n        bluemira_print(f\"Running '{PLASMOD_NAME}' systems code\")\n        command = [self.binary, self.input_file, self.output_file, self.profiles_file]\n        with working_dir(self.directory):\n            try:\n                self._run_subprocess(command)\n            except OSError as os_error:\n                raise CodesError(f\"Failed to run plasmod: {os_error}\") from os_error",
  "def __init__(\n        self,\n        params: PlasmodSolverParams,\n        input_file: str,\n        output_file: str,\n        profiles_file: str,\n        directory: str = \"./\",\n        binary=PLASMOD_BINARY,\n    ):\n        super().__init__(params, PLASMOD_NAME)\n        self.binary = binary\n        self.input_file = input_file\n        self.output_file = output_file\n        self.profiles_file = profiles_file\n        self.directory = directory",
  "def run(self):\n        \"\"\"\n        Run the plasmod shell task.\n\n        Runs plasmod on the command line using the given input files and\n        output path.\n\n        Raises\n        ------\n        CodesError\n            If the subprocess returns a non-zero exit code or raises an\n            OSError (e.g., the plasmod binary does not exist).\n        \"\"\"\n        bluemira_print(f\"Running '{PLASMOD_NAME}' systems code\")\n        command = [self.binary, self.input_file, self.output_file, self.profiles_file]\n        with working_dir(self.directory):\n            try:\n                self._run_subprocess(command)\n            except OSError as os_error:\n                raise CodesError(f\"Failed to run plasmod: {os_error}\") from os_error",
  "class Setup(CodesSetup):\n    \"\"\"\n    Setup task for a plasmod solver.\n\n    On run, this task writes a plasmod input file using the input values\n    defined in this class.\n\n    Parameters\n    ----------\n    params:\n        The bluemira parameters for the task. Note that this task does\n        not apply any mappings to the ParameterFrame, so they should\n        already be set. Most likely by a solver.\n    problem_settings:\n        Any non-bluemira parameters that should be passed to plasmod.\n    plasmod_input_file:\n        The path where the plasmod input file should be written.\n    \"\"\"\n\n    params: PlasmodSolverParams\n\n    def __init__(\n        self,\n        params: PlasmodSolverParams,\n        problem_settings: Dict[str, Any],\n        plasmod_input_file: str,\n    ):\n        super().__init__(params, PLASMOD_NAME)\n\n        self.inputs = PlasmodInputs()\n        self.plasmod_input_file = plasmod_input_file\n        self.update_inputs(problem_settings)\n\n    def run(self):\n        \"\"\"\n        Run plasmod setup.\n        \"\"\"\n        self._write_input()\n\n    def mock(self):\n        \"\"\"\n        Run plasmod setup in mock mode.\n\n        No need to generate an input file as results will be mocked.\n        \"\"\"\n        pass\n\n    def read(self):\n        \"\"\"\n        Run plasmod setup in read mode.\n\n        No need to generate an input file as results will be read from\n        file.\n        \"\"\"\n        pass\n\n    def update_inputs(\n        self, new_inputs: Optional[Dict[str, Union[float, enum.Enum]]] = None\n    ):\n        \"\"\"\n        Update plasmod inputs using the given values.\n\n        This also pulls input values from the task's ParameterFrame and\n        uses them to update the inputs attributes. The inputs to this\n        method take precedence over inputs in the ParameterFrame.\n\n        Parameters\n        ----------\n        new_inputs:\n            The new inputs to update with.\n\n        Notes\n        -----\n        Updates this class's :code:`inputs` attribute.\n        \"\"\"\n        new_inputs = {} if new_inputs is None else new_inputs\n        new_inputs = self._remove_non_plasmod_inputs(new_inputs)\n        new = self._get_new_inputs()\n        new.update(new_inputs)\n        # Create a new PlasmodInputs object so we still benefit from\n        # the __post_init__ processing (converts models to enums)\n        self.inputs = PlasmodInputs(**new)\n\n    @staticmethod\n    def _remove_non_plasmod_inputs(_inputs: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Remove non-plasmod inputs from a dictionary. Warn that the\n        removed inputs will be ignored.\n\n        This copies the original dictionary, the input dictionary is not\n        modified.\n        \"\"\"\n        inputs = copy.deepcopy(_inputs)\n        fields = set(field.name for field in dataclasses.fields(PlasmodInputs))\n        # Convert to list to copy the keys, as we are changing the size\n        # of the dict during iteration.\n        for input_name in list(inputs.keys()):\n            if input_name not in fields:\n                bluemira_warn(f\"Ignoring unknown plasmod input '{input_name}'.\")\n                inputs.pop(input_name)\n        return inputs\n\n    def _write_input(self):\n        \"\"\"\n        Write inputs to file to be read by plasmod.\n        \"\"\"\n        try:\n            with open(self.plasmod_input_file, \"w\") as io_stream:\n                self.inputs.write(io_stream)\n        except OSError as os_error:\n            raise CodesError(\n                f\"Could not write plasmod input file: '{self.plasmod_input_file}': {os_error}\"\n            ) from os_error",
  "def __init__(\n        self,\n        params: PlasmodSolverParams,\n        problem_settings: Dict[str, Any],\n        plasmod_input_file: str,\n    ):\n        super().__init__(params, PLASMOD_NAME)\n\n        self.inputs = PlasmodInputs()\n        self.plasmod_input_file = plasmod_input_file\n        self.update_inputs(problem_settings)",
  "def run(self):\n        \"\"\"\n        Run plasmod setup.\n        \"\"\"\n        self._write_input()",
  "def mock(self):\n        \"\"\"\n        Run plasmod setup in mock mode.\n\n        No need to generate an input file as results will be mocked.\n        \"\"\"\n        pass",
  "def read(self):\n        \"\"\"\n        Run plasmod setup in read mode.\n\n        No need to generate an input file as results will be read from\n        file.\n        \"\"\"\n        pass",
  "def update_inputs(\n        self, new_inputs: Optional[Dict[str, Union[float, enum.Enum]]] = None\n    ):\n        \"\"\"\n        Update plasmod inputs using the given values.\n\n        This also pulls input values from the task's ParameterFrame and\n        uses them to update the inputs attributes. The inputs to this\n        method take precedence over inputs in the ParameterFrame.\n\n        Parameters\n        ----------\n        new_inputs:\n            The new inputs to update with.\n\n        Notes\n        -----\n        Updates this class's :code:`inputs` attribute.\n        \"\"\"\n        new_inputs = {} if new_inputs is None else new_inputs\n        new_inputs = self._remove_non_plasmod_inputs(new_inputs)\n        new = self._get_new_inputs()\n        new.update(new_inputs)\n        # Create a new PlasmodInputs object so we still benefit from\n        # the __post_init__ processing (converts models to enums)\n        self.inputs = PlasmodInputs(**new)",
  "def _remove_non_plasmod_inputs(_inputs: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Remove non-plasmod inputs from a dictionary. Warn that the\n        removed inputs will be ignored.\n\n        This copies the original dictionary, the input dictionary is not\n        modified.\n        \"\"\"\n        inputs = copy.deepcopy(_inputs)\n        fields = set(field.name for field in dataclasses.fields(PlasmodInputs))\n        # Convert to list to copy the keys, as we are changing the size\n        # of the dict during iteration.\n        for input_name in list(inputs.keys()):\n            if input_name not in fields:\n                bluemira_warn(f\"Ignoring unknown plasmod input '{input_name}'.\")\n                inputs.pop(input_name)\n        return inputs",
  "def _write_input(self):\n        \"\"\"\n        Write inputs to file to be read by plasmod.\n        \"\"\"\n        try:\n            with open(self.plasmod_input_file, \"w\") as io_stream:\n                self.inputs.write(io_stream)\n        except OSError as os_error:\n            raise CodesError(\n                f\"Could not write plasmod input file: '{self.plasmod_input_file}': {os_error}\"\n            ) from os_error",
  "class PlasmodOutputs:\n    \"\"\"\n    Dataclass of plasmod output values.\n    \"\"\"\n\n    # Scalars\n    amin: Optional[float] = None\n    av_nd: Optional[float] = None\n    av_nhe: Optional[float] = None\n    av_ni: Optional[float] = None\n    av_nz: Optional[float] = None\n    av_Te: Optional[float] = None\n    av_Ten: Optional[float] = None\n    av_Ti: Optional[float] = None\n    betan: Optional[float] = None\n    betapol: Optional[float] = None\n    betator: Optional[float] = None\n    bpolavg: Optional[float] = None\n    car: Optional[float] = None\n    che: Optional[float] = None\n    che3: Optional[float] = None\n    cprotium: Optional[float] = None\n    cwol: Optional[float] = None\n    cxe: Optional[float] = None\n    d: Optional[float] = None\n    f_gwpedtop: Optional[float] = None\n    f_ni: Optional[float] = None\n    fbs: Optional[float] = None\n    fcd: Optional[float] = None\n    Hcorr: Optional[float] = None\n    Hfact: Optional[float] = None\n    i_flag: Optional[int] = None\n    jiter: Optional[int] = None\n    Ip: Optional[float] = None\n    k: Optional[float] = None\n    nped: Optional[float] = None\n    nsep: Optional[float] = None\n    Palpha: Optional[float] = None\n    Paux: Optional[float] = None\n    Pbrehms: Optional[float] = None\n    Peaux: Optional[float] = None\n    perim: Optional[float] = None\n    Pfus: Optional[float] = None\n    Pfusdd: Optional[float] = None\n    Pfusdt: Optional[float] = None\n    Piaux: Optional[float] = None\n    PLH: Optional[float] = None\n    Pline: Optional[float] = None\n    Pneut: Optional[float] = None\n    Pohm: Optional[float] = None\n    Prad: Optional[float] = None\n    Pradcore: Optional[float] = None\n    Pradedge: Optional[float] = None\n    Psep: Optional[float] = None\n    psep_r: Optional[float] = None\n    psepb_q95AR: Optional[float] = None\n    Psync: Optional[float] = None\n    q_sep: Optional[float] = None\n    q95: Optional[float] = None\n    qcd: Optional[float] = None\n    qdivt: Optional[float] = None\n    qfus: Optional[float] = None\n    qheat: Optional[float] = None\n    qstar: Optional[float] = None\n    rli: Optional[float] = None\n    rplas: Optional[float] = None\n    Sp: Optional[float] = None\n    tauee: Optional[float] = None\n    taueff: Optional[float] = None\n    tauei: Optional[float] = None\n    teped: Optional[float] = None\n    torsurf: Optional[float] = None\n    v_loop: Optional[float] = None\n    Vp: Optional[float] = None\n    Wth: Optional[float] = None\n    Zeff: Optional[float] = None\n\n    # Profiles\n    dprof: Optional[np.ndarray] = None\n    ffprime: Optional[np.ndarray] = None\n    g2: Optional[np.ndarray] = None\n    g3: Optional[np.ndarray] = None\n    ipol: Optional[np.ndarray] = None\n    jbs: Optional[np.ndarray] = None\n    jcd: Optional[np.ndarray] = None\n    jpar: Optional[np.ndarray] = None\n    kprof: Optional[np.ndarray] = None\n    nalf: Optional[np.ndarray] = None\n    ndeut: Optional[np.ndarray] = None\n    ne: Optional[np.ndarray] = None\n    nfuel: Optional[np.ndarray] = None\n    nions: Optional[np.ndarray] = None\n    ntrit: Optional[np.ndarray] = None\n    phi: Optional[np.ndarray] = None\n    pprime: Optional[np.ndarray] = None\n    press: Optional[np.ndarray] = None\n    psi: Optional[np.ndarray] = None\n    qprof: Optional[np.ndarray] = None\n    shif: Optional[np.ndarray] = None\n    Te: Optional[np.ndarray] = None\n    Ti: Optional[np.ndarray] = None\n    volprof: Optional[np.ndarray] = None\n    vprime: Optional[np.ndarray] = None\n    x: Optional[np.ndarray] = None\n\n    @classmethod\n    def from_files(cls, scalar_stream: TextIO, profile_stream: TextIO) -> PlasmodOutputs:\n        \"\"\"\n        Initialize outputs from a scalar and a profiles file.\n        \"\"\"\n        scalars = read_plasmod_output(scalar_stream)\n        profiles = read_plasmod_output(profile_stream)\n        return cls(**scalars, **profiles)",
  "def read_plasmod_output(io_stream: TextIO) -> Dict[str, Union[np.ndarray, float]]:\n    \"\"\"Read an output file, generated by plasmod, into a dictionary.\"\"\"\n    output: Dict[str, Union[np.ndarray, float]] = {}\n    for row in csv.reader(io_stream, delimiter=\"\\t\"):\n        output_key, *output_value = row[0].split()\n        if len(output_value) > 1:\n            output[output_key] = np.array(output_value, dtype=float)\n        elif len(output_value) == 0:\n            output[output_key] = np.array([])\n        else:\n            output[output_key] = float(output_value[0])\n    return output",
  "def from_files(cls, scalar_stream: TextIO, profile_stream: TextIO) -> PlasmodOutputs:\n        \"\"\"\n        Initialize outputs from a scalar and a profiles file.\n        \"\"\"\n        scalars = read_plasmod_output(scalar_stream)\n        profiles = read_plasmod_output(profile_stream)\n        return cls(**scalars, **profiles)",
  "class PlasmodInputs:\n    \"\"\"Plasmod parameters with defaults.\"\"\"\n\n    A: float = 3.1\n    Ainc: float = 1.1\n    amin: float = 2.9039\n    Bt: float = 5.855\n    c_car: float = 10.0\n    capA: float = 0.1\n    car_qdivt: float = 1.0e-4\n    car: float = 0.0\n    che: float = 0.0\n    che3: float = 0.0\n    contrpovr: float = 0.0\n    contrpovs: float = 0.0\n    cprotium: float = 0.0\n    cwol: float = 0.0\n    cxe_psepfac: float = 1.0e-3\n    cxe: float = 0.0\n    d: float = 0.38491934960310104\n    d95: float = 0.333\n    dgy: float = 1e-5\n    dt: float = 0.01\n    dtinc: float = 2.0\n    dtmax: float = 1e-2\n    dtmaxmax: float = 1.0\n    dtmaxmin: float = 0.1\n    dtmin: float = 1e-2\n    dtminmax: float = 5.0\n    dx_cd_ech: float = 0.03\n    dx_cd_nbi: float = 0.2\n    dx_control_ech: float = 0.03\n    dx_control_nbi: float = 0.2\n    dx_fus_ech: float = 0.03\n    dx_fus_nbi: float = 0.2\n    dx_heat_ech: float = 0.03\n    dx_heat_nbi: float = 0.2\n    eccdeff: float = 0.3\n    eopt: float = 0.1\n    f_gw: float = 0.85\n    f_gws: float = 0.5\n    f_ni: float = 0.0\n    fcdp: float = -1.0\n    fcoreraditv: float = -1.0\n    fpion: float = 0.5\n    fuehe3: float = 0.0\n    fuelmix: float = 0.5\n    globtau_ar: float = 10.0\n    globtau_d: float = 10.0\n    globtau_he: float = 10.0\n    globtau_t: float = 10.0\n    globtau_xe: float = 10.0\n    Hfact: float = 1.1\n    i_diagz: int = 0\n    i_equiltype: EquilibriumModel = EquilibriumModel.Ip_sawtooth\n    i_impmodel: ImpurityModel = ImpurityModel.PED_FIXED\n    i_modeltype: TransportModel = TransportModel.GYROBOHM_1\n    i_pedestal: PedestalModel = PedestalModel.SAARELMA\n    Ip: float = 17.75\n    isawt: SafetyProfileModel = SafetyProfileModel.FULLY_RELAXED\n    isiccir: SOLModel = SOLModel.EICH_FIT\n    k: float = 1.6969830041844367\n    k95: float = 1.652\n    maxpauxor: float = 20.0\n    nbcdeff: float = 0.3\n    nbi_energy: float = 1000.0\n    nchannels: int = 3\n    ntglf: int = 11\n    nx: int = 41\n    nxt: int = 5\n    pech: float = 0.0\n    pedscal: float = 1.0\n    pfus_req: float = 0.0\n    pheat_max: float = 130.0\n    plh: PLHModel = PLHModel.MARTIN\n    pnbi: float = 0.0\n    pradfrac: float = 0.6\n    pradpos: float = 0.7\n    psep_r_sup: float = 230.0\n    psepb_q95AR_sup: float = 9.2\n    psepplh_inf: float = 0.1\n    psepplh_sup: float = 1000.0\n    q_cd: float = 0.0\n    q_control: float = 130.0\n    q_fus: float = 0.0\n    q_heat: float = 0.0\n    q95: float = 3.5\n    qdivt_sup: float = 0.0\n    qnbi_psepfac: float = 100.0\n    R: float = 9.002\n    rho_n: float = 0.94\n    rho_T: float = 0.94\n    teped: float = 5.5\n    tesep: float = 0.1\n    test: int = 10000\n    tol: float = 1e-10\n    tolmin: float = 10.1\n    v_loop: float = -1.0e-6\n    volume_in: int = -2500\n    x_cd_ech: float = 0.0\n    x_cd_nbi: float = 0.0\n    x_control_ech: float = 0.0\n    x_control_nbi: float = 0.0\n    x_fus_ech: float = 0.0\n    x_fus_nbi: float = 0.0\n    x_heat_ech: float = 0.0\n    x_heat_nbi: float = 0.0\n    xtglf_1: float = 0.1\n    xtglf_2: float = 0.15\n    xtglf_3: float = 0.2\n    xtglf_4: float = 0.25\n    xtglf_5: float = 0.3\n    xtglf_6: float = 0.4\n    xtglf_7: float = 0.5\n    xtglf_8: float = 0.6\n    xtglf_9: float = 0.7\n    xtglf_10: float = 0.75\n    xtglf_11: float = 0.8\n\n    _FORTRAN_INT_FORMAT = \"a20,  i10\"\n    _FORTRAN_FLOAT_FORMAT = \"a20, e17.9\"\n\n    def __post_init__(self):\n        \"\"\"\n        Perform post-init processing.\n\n        Convert some parameters to their corresponding enum type. This\n        allows us to load values from a config file stored as fortran\n        types, then convert the integers to their respective enums.\n        \"\"\"\n        self._convert_models_to_enums()\n\n    def write(self, io_stream: TextIO):\n        \"\"\"\n        Write plasmod inputs to stream in a format plasmod can read.\n\n        Parameters\n        ----------\n        io_stream:\n            A text stream. Usually created using :code:`open(..., \"r\")`.\n        \"\"\"\n        f_int = ff.FortranRecordWriter(self._FORTRAN_INT_FORMAT)\n        f_float = ff.FortranRecordWriter(self._FORTRAN_FLOAT_FORMAT)\n\n        for k, v in vars(self).items():\n            if isinstance(v, enum.Enum):\n                line = f_int.write([k, v.value])\n            elif isinstance(v, int):\n                line = f_int.write([k, v])\n            elif isinstance(v, float):\n                line = f_float.write([k, v])\n            else:\n                bluemira_warn(\n                    f\"Plasmod input '{k}' has unknown type, this may produce fortran \"\n                    f\"read errors, type: {type(v)}\"\n                )\n                line = f\"{k} {v}\"\n            io_stream.write(line)\n            io_stream.write(\"\\n\")\n\n    def _convert_models_to_enums(self):\n        \"\"\"\n        Convert plasmod model fortran values to their corresponding enum\n        values.\n        \"\"\"\n        for model, enum_cls in MODEL_MAP.items():\n            current_value = getattr(self, model)\n            if isinstance(current_value, enum_cls):\n                continue\n            try:\n                enum_value = self._convert_value_to_enum(enum_cls, current_value)\n            except ValueError as value_error:\n                raise CodesError(\n                    f\"Invalid value found for plasmod input '{model}': {value_error}\"\n                )\n            setattr(self, model, enum_value)\n\n    @staticmethod\n    def _convert_value_to_enum(enum_cls: Type[enum.Enum], value: Any) -> enum.Enum:\n        \"\"\"\n        Attempts to convert a value to an enum value of the given class.\n\n        Throw a value error if the given value does not correspond to an\n        enumeration value in the enum class.\n        \"\"\"\n        for enum_val in enum_cls:\n            # Let's us specify using the enum value (usually an int)\n            # or specify using the enum's name (e.g., q95_sawtooth)\n            if enum_val.value == value or enum_val.name == value:\n                return enum_val\n        raise ValueError(\n            f\"Cannot convert '{value}' to value enumerated by '{enum_cls.__name__}'.\"\n        )",
  "def __post_init__(self):\n        \"\"\"\n        Perform post-init processing.\n\n        Convert some parameters to their corresponding enum type. This\n        allows us to load values from a config file stored as fortran\n        types, then convert the integers to their respective enums.\n        \"\"\"\n        self._convert_models_to_enums()",
  "def write(self, io_stream: TextIO):\n        \"\"\"\n        Write plasmod inputs to stream in a format plasmod can read.\n\n        Parameters\n        ----------\n        io_stream:\n            A text stream. Usually created using :code:`open(..., \"r\")`.\n        \"\"\"\n        f_int = ff.FortranRecordWriter(self._FORTRAN_INT_FORMAT)\n        f_float = ff.FortranRecordWriter(self._FORTRAN_FLOAT_FORMAT)\n\n        for k, v in vars(self).items():\n            if isinstance(v, enum.Enum):\n                line = f_int.write([k, v.value])\n            elif isinstance(v, int):\n                line = f_int.write([k, v])\n            elif isinstance(v, float):\n                line = f_float.write([k, v])\n            else:\n                bluemira_warn(\n                    f\"Plasmod input '{k}' has unknown type, this may produce fortran \"\n                    f\"read errors, type: {type(v)}\"\n                )\n                line = f\"{k} {v}\"\n            io_stream.write(line)\n            io_stream.write(\"\\n\")",
  "def _convert_models_to_enums(self):\n        \"\"\"\n        Convert plasmod model fortran values to their corresponding enum\n        values.\n        \"\"\"\n        for model, enum_cls in MODEL_MAP.items():\n            current_value = getattr(self, model)\n            if isinstance(current_value, enum_cls):\n                continue\n            try:\n                enum_value = self._convert_value_to_enum(enum_cls, current_value)\n            except ValueError as value_error:\n                raise CodesError(\n                    f\"Invalid value found for plasmod input '{model}': {value_error}\"\n                )\n            setattr(self, model, enum_value)",
  "def _convert_value_to_enum(enum_cls: Type[enum.Enum], value: Any) -> enum.Enum:\n        \"\"\"\n        Attempts to convert a value to an enum value of the given class.\n\n        Throw a value error if the given value does not correspond to an\n        enumeration value in the enum class.\n        \"\"\"\n        for enum_val in enum_cls:\n            # Let's us specify using the enum value (usually an int)\n            # or specify using the enum's name (e.g., q95_sawtooth)\n            if enum_val.value == value or enum_val.name == value:\n                return enum_val\n        raise ValueError(\n            f\"Cannot convert '{value}' to value enumerated by '{enum_cls.__name__}'.\"\n        )",
  "class RunMode(BaseRunMode):\n    \"\"\"\n    RunModes for plasmod\n    \"\"\"\n\n    RUN = auto()\n    READ = auto()\n    MOCK = auto()",
  "class Solver(CodesSolver):\n    \"\"\"\n    Plasmod solver class.\n\n    Parameters\n    ----------\n    params:\n        ParameterFrame for plasmod.\n    build_config:\n        Build configuration dictionary.\n        Expected keys include:\n\n            - binary: str, path to the plasmod binary.\n            - problem_settings: Dict[str, Any], any plasmod specific\n              parameters (i.e., parameters that bluemira does not have\n              direct mappings to through the ParameterFrame).\n            - input_file: str, the path to write the plasmod input file\n              to, this can be a relative path.\n            - output_file: str, the path to write the plasmod scalar\n              output file to.\n            - profiles_file: str, the path to write the plasmod profiles\n              output file to.\n    \"\"\"\n\n    name = PLASMOD_NAME\n    setup_cls = Setup\n    run_cls = Run\n    teardown_cls = Teardown\n    run_mode_cls = RunMode\n\n    DEFAULT_INPUT_FILE = \"plasmod_input.dat\"\n    DEFAULT_OUTPUT_FILE = \"plasmod_output.dat\"\n    DEFAULT_PROFILES_FILE = \"plasmod_profiles.dat\"\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Dict[str, Any] = None,\n    ):\n        # Init task objects on execution so parameters can be edited\n        # between separate 'execute' calls.\n        self._setup: Setup\n        self._run: Run\n        self._teardown: Teardown\n\n        self.params = PlasmodSolverParams.from_defaults()\n\n        if isinstance(params, ParameterFrame):\n            self.params.update_from_frame(params)\n        else:\n            try:\n                self.params.update_from_dict(params)\n            except TypeError:\n                self.params.update_values(params)\n\n        self.build_config = {} if build_config is None else build_config\n        self.binary = self.build_config.get(\"binary\", PLASMOD_BINARY)\n        self.problem_settings = self.build_config.get(\"problem_settings\", {})\n        self.input_file = self.build_config.get(\"input_file\", self.DEFAULT_INPUT_FILE)\n        self.output_file = self.build_config.get(\"output_file\", self.DEFAULT_OUTPUT_FILE)\n        self.profiles_file = self.build_config.get(\n            \"profiles_file\", self.DEFAULT_PROFILES_FILE\n        )\n        self.run_directory = self.build_config.get(\n            \"run_directory\", self.build_config.get(\"directory\", \"./\")\n        )\n        self.read_directory = self.build_config.get(\n            \"read_directory\", self.build_config.get(\"directory\", \"./\")\n        )\n\n    def execute(self, run_mode: Union[str, RunMode]) -> ParameterFrame:\n        \"\"\"\n        Execute this plasmod solver.\n\n        This solver:\n\n            1. writes a plasmod input file using the given bluemira and\n               problem parameters.\n            2. processes that file using a shell call to plasmod.\n            3. reads the plasmod output files, and updates this object's\n               ParameterFrame with the results.\n\n        Parameters\n        ----------\n        run_mode:\n            The mode to execute this solver in.\n        \"\"\"\n        if isinstance(run_mode, str):\n            run_mode = self.run_mode_cls.from_string(run_mode)\n\n        self._setup = Setup(\n            self.params, self.problem_settings, Path(self.run_directory, self.input_file)\n        )\n        self._run = Run(\n            self.params,\n            self.input_file,\n            self.output_file,\n            self.profiles_file,\n            self.run_directory,\n            self.binary,\n        )\n        self._teardown = Teardown(\n            self.params,\n            self.output_file,\n            self.profiles_file,\n            self.read_directory,\n            self.run_directory,\n        )\n        if setup := self._get_execution_method(self._setup, run_mode):\n            setup()\n        if run := self._get_execution_method(self._run, run_mode):\n            run()\n        if teardown := self._get_execution_method(self._teardown, run_mode):\n            teardown()\n\n        self._scale_x_profile()\n\n        return self.params\n\n    def _scale_x_profile(self):\n        self._x_phi = getattr(self.plasmod_outputs(), Profiles.x.name)\n        self._x_phi /= np.max(self._x_phi)\n        psi = getattr(self.plasmod_outputs(), Profiles.psi.name)\n        self._x_psi = np.sqrt(psi / psi[-1])\n\n    def _from_phi_to_psi(self, profile_data):\n        \"\"\"\n        Convert the profile to the magnetic coordinate sqrt((psi - psi_ax)/(psi_b -\n        psi_ax))\n        \"\"\"\n        return interp1d(self._x_psi, profile_data, kind=\"linear\")(self._x_phi)\n\n    def get_profile(self, profile: Union[str, Profiles]) -> np.ndarray:\n        \"\"\"\n        Get a single plasmod profile.\n\n        Parameters\n        ----------\n        profile:\n            A profile to get the data for.\n\n        Returns\n        -------\n        A plasmod profile.\n\n        Notes\n        -----\n        pprime and ffprime profiles from PLASMOD are currently inconsistent with the\n        output jpar profile, even if isawt=FULLY_RELAXED. This is a known issue,\n        and is under investigation. In the meantime, a crude rescaling of the flux\n        functions is provided here.\n        \"\"\"\n        if isinstance(profile, str):\n            profile = Profiles(profile)\n\n        if profile is Profiles.x:\n            prof_data = self._x_phi\n        else:\n            prof_data = getattr(self.plasmod_outputs(), profile.name)\n            prof_data = self._from_phi_to_psi(prof_data)\n\n        return prof_data\n\n    def get_profiles(\n        self, profiles: Iterable[Union[str, Profiles]]\n    ) -> Dict[Profiles, np.ndarray]:\n        \"\"\"\n        Get a dictionary of plasmod profiles.\n\n        Parameters\n        ----------\n        profiles:\n            An iterable of Profiles enum values.\n\n        Returns\n        -------\n        A dictionary mapping profile enum to values.\n        \"\"\"\n        profiles_dict = {}\n        for profile in profiles:\n            profiles_dict[profile] = self.get_profile(profile)\n        return profiles_dict\n\n    def plasmod_outputs(self) -> PlasmodOutputs:\n        \"\"\"\n        Return a structure of unmapped plasmod outputs.\n\n        Use :code:`params` attribute for mapped outputs.\n\n        Returns\n        -------\n        The scalar plasmod outputs.\n        \"\"\"\n        try:\n            return self._teardown.outputs\n        except AttributeError as attr_error:\n            raise CodesError(\n                \"Cannot get outputs before the solver has been run.\"\n            ) from attr_error",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Dict[str, Any] = None,\n    ):\n        # Init task objects on execution so parameters can be edited\n        # between separate 'execute' calls.\n        self._setup: Setup\n        self._run: Run\n        self._teardown: Teardown\n\n        self.params = PlasmodSolverParams.from_defaults()\n\n        if isinstance(params, ParameterFrame):\n            self.params.update_from_frame(params)\n        else:\n            try:\n                self.params.update_from_dict(params)\n            except TypeError:\n                self.params.update_values(params)\n\n        self.build_config = {} if build_config is None else build_config\n        self.binary = self.build_config.get(\"binary\", PLASMOD_BINARY)\n        self.problem_settings = self.build_config.get(\"problem_settings\", {})\n        self.input_file = self.build_config.get(\"input_file\", self.DEFAULT_INPUT_FILE)\n        self.output_file = self.build_config.get(\"output_file\", self.DEFAULT_OUTPUT_FILE)\n        self.profiles_file = self.build_config.get(\n            \"profiles_file\", self.DEFAULT_PROFILES_FILE\n        )\n        self.run_directory = self.build_config.get(\n            \"run_directory\", self.build_config.get(\"directory\", \"./\")\n        )\n        self.read_directory = self.build_config.get(\n            \"read_directory\", self.build_config.get(\"directory\", \"./\")\n        )",
  "def execute(self, run_mode: Union[str, RunMode]) -> ParameterFrame:\n        \"\"\"\n        Execute this plasmod solver.\n\n        This solver:\n\n            1. writes a plasmod input file using the given bluemira and\n               problem parameters.\n            2. processes that file using a shell call to plasmod.\n            3. reads the plasmod output files, and updates this object's\n               ParameterFrame with the results.\n\n        Parameters\n        ----------\n        run_mode:\n            The mode to execute this solver in.\n        \"\"\"\n        if isinstance(run_mode, str):\n            run_mode = self.run_mode_cls.from_string(run_mode)\n\n        self._setup = Setup(\n            self.params, self.problem_settings, Path(self.run_directory, self.input_file)\n        )\n        self._run = Run(\n            self.params,\n            self.input_file,\n            self.output_file,\n            self.profiles_file,\n            self.run_directory,\n            self.binary,\n        )\n        self._teardown = Teardown(\n            self.params,\n            self.output_file,\n            self.profiles_file,\n            self.read_directory,\n            self.run_directory,\n        )\n        if setup := self._get_execution_method(self._setup, run_mode):\n            setup()\n        if run := self._get_execution_method(self._run, run_mode):\n            run()\n        if teardown := self._get_execution_method(self._teardown, run_mode):\n            teardown()\n\n        self._scale_x_profile()\n\n        return self.params",
  "def _scale_x_profile(self):\n        self._x_phi = getattr(self.plasmod_outputs(), Profiles.x.name)\n        self._x_phi /= np.max(self._x_phi)\n        psi = getattr(self.plasmod_outputs(), Profiles.psi.name)\n        self._x_psi = np.sqrt(psi / psi[-1])",
  "def _from_phi_to_psi(self, profile_data):\n        \"\"\"\n        Convert the profile to the magnetic coordinate sqrt((psi - psi_ax)/(psi_b -\n        psi_ax))\n        \"\"\"\n        return interp1d(self._x_psi, profile_data, kind=\"linear\")(self._x_phi)",
  "def get_profile(self, profile: Union[str, Profiles]) -> np.ndarray:\n        \"\"\"\n        Get a single plasmod profile.\n\n        Parameters\n        ----------\n        profile:\n            A profile to get the data for.\n\n        Returns\n        -------\n        A plasmod profile.\n\n        Notes\n        -----\n        pprime and ffprime profiles from PLASMOD are currently inconsistent with the\n        output jpar profile, even if isawt=FULLY_RELAXED. This is a known issue,\n        and is under investigation. In the meantime, a crude rescaling of the flux\n        functions is provided here.\n        \"\"\"\n        if isinstance(profile, str):\n            profile = Profiles(profile)\n\n        if profile is Profiles.x:\n            prof_data = self._x_phi\n        else:\n            prof_data = getattr(self.plasmod_outputs(), profile.name)\n            prof_data = self._from_phi_to_psi(prof_data)\n\n        return prof_data",
  "def get_profiles(\n        self, profiles: Iterable[Union[str, Profiles]]\n    ) -> Dict[Profiles, np.ndarray]:\n        \"\"\"\n        Get a dictionary of plasmod profiles.\n\n        Parameters\n        ----------\n        profiles:\n            An iterable of Profiles enum values.\n\n        Returns\n        -------\n        A dictionary mapping profile enum to values.\n        \"\"\"\n        profiles_dict = {}\n        for profile in profiles:\n            profiles_dict[profile] = self.get_profile(profile)\n        return profiles_dict",
  "def plasmod_outputs(self) -> PlasmodOutputs:\n        \"\"\"\n        Return a structure of unmapped plasmod outputs.\n\n        Use :code:`params` attribute for mapped outputs.\n\n        Returns\n        -------\n        The scalar plasmod outputs.\n        \"\"\"\n        try:\n            return self._teardown.outputs\n        except AttributeError as attr_error:\n            raise CodesError(\n                \"Cannot get outputs before the solver has been run.\"\n            ) from attr_error",
  "def plot_default_profiles(\n    plasmod_solver: Solver,\n    show: bool = True,\n    f: Optional[plt.Figure] = None,\n    ax: Optional[plt.Axes] = None,\n) -> Tuple[plt.Figure, plt.Axes]:\n    \"\"\"\n    Plot a default set of profiles from a PLASMOD solver.\n\n    Parameters\n    ----------\n    plasmod_solver:\n        Solver for which to plot profiles\n    show:\n        Whether or not to show the plot\n    f:\n        Matplotlib figure\n    ax:\n        Array of matplotlib Axes\n\n    Returns\n    -------\n    f:\n        Matplotlib figure\n    ax:\n        Array of matplotlib Axes\n    \"\"\"\n    plot_defaults()\n    if f is None and ax is None:\n        f, ax = plt.subplots(2, 3, figsize=(18, 10))\n\n    rho = plasmod_solver.get_profile(\"x\")\n    R_0 = plasmod_solver.params.R_0.value\n\n    # Corrected flux function profiles (used as output profiles)\n    pprime = plasmod_solver.get_profile(\"pprime\")\n    ffprime = plasmod_solver.get_profile(\"ffprime\")\n\n    # Current density profile reconstruction from flux functions\n    jpar_recon = 2 * np.pi * (R_0 * pprime + ffprime / (MU_0 * R_0))\n\n    # Temperature profiles\n    ti = plasmod_solver.get_profile(\"Ti\")\n    te = plasmod_solver.get_profile(\"Te\")\n    ax[0, 0].plot(rho, ti, label=\"$T_{i}$\")\n    ax[0, 0].plot(rho, te, label=\"$T_{e}$\")\n    ax[0, 0].set_ylabel(\"Temperature [keV]\")\n\n    # Current profiles\n    jpar = plasmod_solver.get_profile(\"jpar\")\n    jbs = plasmod_solver.get_profile(\"jbs\")\n    jcd = plasmod_solver.get_profile(\"jcd\")\n    ax[0, 1].plot(rho, jpar, label=\"$j_{||}$\")\n    ax[0, 1].plot(rho, jbs, label=\"$j_{BS}$\")\n    ax[0, 1].plot(rho, jcd, label=\"$j_{CD}$\")\n    ax[0, 1].plot(rho, jpar_recon, linestyle=\"--\", label=\"$j_{p', FF'}$\")\n    ax[0, 1].set_ylabel(\"Current density [A/m\u00b2]\")\n\n    # Density profiles\n    ni = plasmod_solver.get_profile(\"n_ion\")\n    ne = plasmod_solver.get_profile(\"n_e\")\n    ax[1, 0].plot(rho, ni, label=\"$n_{i}$\")\n    ax[1, 0].plot(rho, ne, label=\"$n_{e}$\")\n    ax[1, 0].set_ylabel(\"Density [10\u00b9\u2079/m\u00b3]\")\n\n    # q profile\n    qprof = plasmod_solver.get_profile(\"q\")\n    ax[1, 1].plot(rho, qprof, label=\"$q$\")\n    ax[1, 1].set_ylabel(\"Safety factor\")\n\n    # Flux functions\n    ax[0, 2].plot(rho, pprime, label=\"$p'_{*corr}$\")\n    ax[0, 2].set_ylabel(\"[Pa/Wb]\")\n    axi: plt.Axes = ax[0, 2]\n    axi.ticklabel_format(axis=\"y\", style=\"scientific\", scilimits=(0, 0))\n\n    ax[1, 2].plot(rho, ffprime, label=\"$FF'_{*corr}$\")\n    ax[1, 2].set_ylabel(\"[T]\")\n\n    for axe in ax.flat:\n        axe.grid()\n        axe.set_xlabel(\"$\\\\rho$\")\n        axe.set_xlim([0.0, 1.0])\n        axe.legend(loc=\"best\")\n\n    plt.subplots_adjust(hspace=0.3, wspace=0.3)\n\n    if show:\n        plt.show()\n    return f, ax",
  "class Teardown(CodesTeardown):\n    \"\"\"\n    Plasmod teardown task.\n\n    In \"RUN\" and \"READ\" mode, this loads in plasmod results files and\n    updates :code:`params` with the values.\n\n    Parameters\n    ----------\n    params:\n        The bluemira parameters for the task. Note that this task does\n        not apply any mappings to the ParameterFrame, so they should\n        already be set. Most likely by a solver.\n    output_file:\n        The path to the plasmod output file.\n    profiles_file:\n        The path to the plasmod profiles file.\n    \"\"\"\n\n    params: PlasmodSolverParams\n    MOCK_JSON_NAME = \"mockPLASMOD.json\"\n\n    def __init__(\n        self,\n        params: PlasmodSolverParams,\n        output_file: str,\n        profiles_file: str,\n        run_directory: str,\n        read_directory: str,\n    ):\n        super().__init__(params, PLASMOD_NAME)\n        self.read_directory = read_directory\n        self.run_directory = run_directory\n        self.output_file = output_file\n        self.profiles_file = profiles_file\n\n    def run(self):\n        \"\"\"\n        Load the plasmod results files and update this object's params\n        with the read values.\n        \"\"\"\n        self._get_data(\n            Path(self.run_directory, self.output_file),\n            Path(self.run_directory, self.profiles_file),\n        )\n\n    def mock(self):\n        \"\"\"\n        Update this object's plasmod params with default values.\n        \"\"\"\n        scalars = read_mock_json_or_raise(\n            Path(self.read_directory, self.MOCK_JSON_NAME), self._name\n        )\n        self.params.update_values(scalars, source=self._name)\n\n    def read(self):\n        \"\"\"\n        Load the plasmod results files and update this object's params\n        with the read values.\n\n        Raises\n        ------\n        CodesError\n            If any of the plasmod files cannot be opened.\n        \"\"\"\n        self._get_data(\n            Path(self.read_directory, self.output_file),\n            Path(self.read_directory, self.profiles_file),\n        )\n\n    def _get_data(self, output_file: Union[str, Path], profiles_file: Union[str, Path]):\n        \"\"\"\n        Get data for read or run modes\n        \"\"\"\n        try:\n            with open(output_file, \"r\") as scalar_file:\n                with open(profiles_file, \"r\") as profiles_file:\n                    self.outputs = PlasmodOutputs.from_files(scalar_file, profiles_file)\n        except OSError as os_error:\n            raise CodesError(\n                f\"Could not read plasmod output file: {os_error}.\"\n            ) from os_error\n        self._raise_on_plasmod_error_code(self.outputs.i_flag)\n        self._update_params_with_outputs(vars(self.outputs))\n\n    @staticmethod\n    def _raise_on_plasmod_error_code(exit_code: int):\n        \"\"\"\n        Check the returned exit code of plasmod.\n\n        1: PLASMOD converged successfully:\n\n        -1: Max number of iterations achieved:\n\n            Equilibrium oscillating, pressure too high, reduce H\n\n        0: transport solver crashed:\n\n            Abnormal parameters or too large dtmin and/or dtmin\n\n        -2: Equilibrium solver crashed:\n\n            Pressure too high\n\n        Raises\n        ------\n        CodesError\n            If the exit flag is an error code, or its value is not a known\n            code.\n        \"\"\"\n        if exit_code == 1:\n            bluemira_debug(\"plasmod converged successfully.\")\n        elif exit_code == -2:\n            raise CodesError(\n                \"plasmod error: Equilibrium solver crashed: too high pressure.\"\n            )\n        elif exit_code == -1:\n            raise CodesError(\n                \"plasmod error: \"\n                \"Max number of iterations reached equilibrium oscillating probably as a \"\n                \"result of the pressure being too high reducing H may help.\"\n            )\n        elif not exit_code:\n            raise CodesError(\n                \"plasmod error: Abnormal parameters, possibly dtmax/dtmin too large.\"\n            )\n        else:\n            raise CodesError(f\"plasmod error: Unknown error code '{exit_code}'.\")",
  "def __init__(\n        self,\n        params: PlasmodSolverParams,\n        output_file: str,\n        profiles_file: str,\n        run_directory: str,\n        read_directory: str,\n    ):\n        super().__init__(params, PLASMOD_NAME)\n        self.read_directory = read_directory\n        self.run_directory = run_directory\n        self.output_file = output_file\n        self.profiles_file = profiles_file",
  "def run(self):\n        \"\"\"\n        Load the plasmod results files and update this object's params\n        with the read values.\n        \"\"\"\n        self._get_data(\n            Path(self.run_directory, self.output_file),\n            Path(self.run_directory, self.profiles_file),\n        )",
  "def mock(self):\n        \"\"\"\n        Update this object's plasmod params with default values.\n        \"\"\"\n        scalars = read_mock_json_or_raise(\n            Path(self.read_directory, self.MOCK_JSON_NAME), self._name\n        )\n        self.params.update_values(scalars, source=self._name)",
  "def read(self):\n        \"\"\"\n        Load the plasmod results files and update this object's params\n        with the read values.\n\n        Raises\n        ------\n        CodesError\n            If any of the plasmod files cannot be opened.\n        \"\"\"\n        self._get_data(\n            Path(self.read_directory, self.output_file),\n            Path(self.read_directory, self.profiles_file),\n        )",
  "def _get_data(self, output_file: Union[str, Path], profiles_file: Union[str, Path]):\n        \"\"\"\n        Get data for read or run modes\n        \"\"\"\n        try:\n            with open(output_file, \"r\") as scalar_file:\n                with open(profiles_file, \"r\") as profiles_file:\n                    self.outputs = PlasmodOutputs.from_files(scalar_file, profiles_file)\n        except OSError as os_error:\n            raise CodesError(\n                f\"Could not read plasmod output file: {os_error}.\"\n            ) from os_error\n        self._raise_on_plasmod_error_code(self.outputs.i_flag)\n        self._update_params_with_outputs(vars(self.outputs))",
  "def _raise_on_plasmod_error_code(exit_code: int):\n        \"\"\"\n        Check the returned exit code of plasmod.\n\n        1: PLASMOD converged successfully:\n\n        -1: Max number of iterations achieved:\n\n            Equilibrium oscillating, pressure too high, reduce H\n\n        0: transport solver crashed:\n\n            Abnormal parameters or too large dtmin and/or dtmin\n\n        -2: Equilibrium solver crashed:\n\n            Pressure too high\n\n        Raises\n        ------\n        CodesError\n            If the exit flag is an error code, or its value is not a known\n            code.\n        \"\"\"\n        if exit_code == 1:\n            bluemira_debug(\"plasmod converged successfully.\")\n        elif exit_code == -2:\n            raise CodesError(\n                \"plasmod error: Equilibrium solver crashed: too high pressure.\"\n            )\n        elif exit_code == -1:\n            raise CodesError(\n                \"plasmod error: \"\n                \"Max number of iterations reached equilibrium oscillating probably as a \"\n                \"result of the pressure being too high reducing H may help.\"\n            )\n        elif not exit_code:\n            raise CodesError(\n                \"plasmod error: Abnormal parameters, possibly dtmax/dtmin too large.\"\n            )\n        else:\n            raise CodesError(f\"plasmod error: Unknown error code '{exit_code}'.\")",
  "class Run(CodesTask):\n    \"\"\"\n    Run task for PROCESS.\n\n    Parameters\n    ----------\n    params:\n        The bluemira parameters for this task.\n    in_dat_path:\n        The path to an existing PROCESS IN.DAT input file.\n    run_directory:\n        The directory in which to run PROCESS. This is where the output\n        files will be written to. Default is current working directory.\n    binary:\n        The path, or name, of the PROCESS executable. The default is\n        'process', which requires the executable to be on the system\n        path.\n    \"\"\"\n\n    def __init__(\n        self,\n        params: ProcessSolverParams,\n        in_dat_path: str,\n        binary: str = PROCESS_BINARY,\n    ):\n        super().__init__(params, PROCESS_NAME)\n\n        self.in_dat_path = in_dat_path\n        self.binary = binary\n\n    def run(self):\n        \"\"\"\n        Run the PROCESS executable on the IN.DAT file.\n\n        This will run process using the :code:`in_dat_path` file.\n        PROCESS's output files will be written to the same directory\n        that :code:`in_dat_path` is in.\n        \"\"\"\n        self._run_process()\n\n    def runinput(self):\n        \"\"\"\n        Run the PROCESS executable on the IN.DAT file, equivalent to\n        'run' method.\n        \"\"\"\n        self._run_process()\n\n    def _run_process(self):\n        bluemira_print(f\"Running '{PROCESS_NAME}' systems code\")\n        command = [self.binary, \"-i\", self.in_dat_path]\n        self._run_subprocess(command)",
  "def __init__(\n        self,\n        params: ProcessSolverParams,\n        in_dat_path: str,\n        binary: str = PROCESS_BINARY,\n    ):\n        super().__init__(params, PROCESS_NAME)\n\n        self.in_dat_path = in_dat_path\n        self.binary = binary",
  "def run(self):\n        \"\"\"\n        Run the PROCESS executable on the IN.DAT file.\n\n        This will run process using the :code:`in_dat_path` file.\n        PROCESS's output files will be written to the same directory\n        that :code:`in_dat_path` is in.\n        \"\"\"\n        self._run_process()",
  "def runinput(self):\n        \"\"\"\n        Run the PROCESS executable on the IN.DAT file, equivalent to\n        'run' method.\n        \"\"\"\n        self._run_process()",
  "def _run_process(self):\n        bluemira_print(f\"Running '{PROCESS_NAME}' systems code\")\n        command = [self.binary, \"-i\", self.in_dat_path]\n        self._run_subprocess(command)",
  "class Setup(CodesSetup):\n    \"\"\"\n    Setup Task for running PROCESS.\n\n    Parameters\n    ----------\n    params:\n        The bluemira parameters for this task.\n    in_dat_path:\n        The path to where the IN.DAT file should be written.\n    template_in_dat_path:\n        The path to a template PROCESS IN.DAT file. By default this\n        points to a sample one within the Bluemira repository.\n    problem_settings:\n        The PROCESS parameters that do not exist in Bluemira.\n    \"\"\"\n\n    MODELS = {\n        \"iefrf\": CurrentDriveEfficiencyModel,\n        \"i_tf_sup\": TFCoilConductorTechnology,\n    }\n\n    def __init__(\n        self,\n        params: ProcessSolverParams,\n        in_dat_path: str,\n        template_in_dat: Union[str, ProcessInputs] = None,\n        problem_settings: Dict[str, Union[float, str]] = None,\n    ):\n        super().__init__(params, PROCESS_NAME)\n\n        self.in_dat_path = in_dat_path\n        self.template_in_dat = (\n            self.params.template_defaults if template_in_dat is None else template_in_dat\n        )\n        self.problem_settings = problem_settings if problem_settings is not None else {}\n\n    def run(self):\n        \"\"\"\n        Write the IN.DAT file and store in the main PROCESS folder.\n\n        Bluemira params with :code:`param.mapping.send == True` will be\n        written to IN.DAT.\n        \"\"\"\n        self._write_in_dat(use_bp_inputs=True)\n\n    def runinput(self):\n        \"\"\"\n        Write the IN.DAT file and store in the main PROCESS folder.\n\n        Bluemira outputs will not be written to the file.\n        \"\"\"\n        self._write_in_dat(use_bp_inputs=False)\n\n    def _write_in_dat(self, use_bp_inputs: bool = True):\n        \"\"\"\n        Write the IN.DAT file and stores in the main PROCESS folder.\n\n        Parameters\n        ----------\n        use_bp_inputs:\n            Option to use bluemira values as PROCESS inputs. Used to re-run PROCESS\n            within a bluemira run. If False, runs PROCESS without modifying inputs.\n            Default, True\n        \"\"\"\n        # Load defaults in bluemira folder\n        writer = _make_writer(self.template_in_dat)\n\n        if use_bp_inputs:\n            inputs = self._get_new_inputs(remapper=update_obsolete_vars)\n            for key, value in inputs.items():\n                writer.add_parameter(key, value)\n            for key, value in self.problem_settings.items():\n                writer.add_parameter(key, value)\n\n            self._validate_models(writer)\n\n        writer.write_in_dat(output_filename=self.in_dat_path)\n\n    def _validate_models(self, writer):\n        \"\"\"\n        Loop through known models, find the PROCESS output value for the\n        model, and convert the type to its corresponding Enum value.\n        \"\"\"\n        for name, model_cls in self.MODELS.items():\n            try:\n                val = writer.data[name].get_value\n            except KeyError:\n                continue\n\n            model = model_cls[val] if isinstance(val, str) else model_cls(val)\n            writer.add_parameter(name, model.value)",
  "def _make_writer(template_in_dat: Union[str, Dict[str, _INVariable]]) -> InDat:\n    if isinstance(template_in_dat, Dict):\n        indat = InDat(filename=None)\n        indat.data = template_in_dat\n        return indat\n    elif isinstance(template_in_dat, str) and os.path.isfile(template_in_dat):\n        # InDat autoloads IN.DAT without checking for existence\n        return InDat(filename=template_in_dat)\n    else:\n        raise CodesError(f\"Template IN.DAT '{template_in_dat}' is not a file.\")",
  "def __init__(\n        self,\n        params: ProcessSolverParams,\n        in_dat_path: str,\n        template_in_dat: Union[str, ProcessInputs] = None,\n        problem_settings: Dict[str, Union[float, str]] = None,\n    ):\n        super().__init__(params, PROCESS_NAME)\n\n        self.in_dat_path = in_dat_path\n        self.template_in_dat = (\n            self.params.template_defaults if template_in_dat is None else template_in_dat\n        )\n        self.problem_settings = problem_settings if problem_settings is not None else {}",
  "def run(self):\n        \"\"\"\n        Write the IN.DAT file and store in the main PROCESS folder.\n\n        Bluemira params with :code:`param.mapping.send == True` will be\n        written to IN.DAT.\n        \"\"\"\n        self._write_in_dat(use_bp_inputs=True)",
  "def runinput(self):\n        \"\"\"\n        Write the IN.DAT file and store in the main PROCESS folder.\n\n        Bluemira outputs will not be written to the file.\n        \"\"\"\n        self._write_in_dat(use_bp_inputs=False)",
  "def _write_in_dat(self, use_bp_inputs: bool = True):\n        \"\"\"\n        Write the IN.DAT file and stores in the main PROCESS folder.\n\n        Parameters\n        ----------\n        use_bp_inputs:\n            Option to use bluemira values as PROCESS inputs. Used to re-run PROCESS\n            within a bluemira run. If False, runs PROCESS without modifying inputs.\n            Default, True\n        \"\"\"\n        # Load defaults in bluemira folder\n        writer = _make_writer(self.template_in_dat)\n\n        if use_bp_inputs:\n            inputs = self._get_new_inputs(remapper=update_obsolete_vars)\n            for key, value in inputs.items():\n                writer.add_parameter(key, value)\n            for key, value in self.problem_settings.items():\n                writer.add_parameter(key, value)\n\n            self._validate_models(writer)\n\n        writer.write_in_dat(output_filename=self.in_dat_path)",
  "def _validate_models(self, writer):\n        \"\"\"\n        Loop through known models, find the PROCESS output value for the\n        model, and convert the type to its corresponding Enum value.\n        \"\"\"\n        for name, model_cls in self.MODELS.items():\n            try:\n                val = writer.data[name].get_value\n            except KeyError:\n                continue\n\n            model = model_cls[val] if isinstance(val, str) else model_cls(val)\n            writer.add_parameter(name, model.value)",
  "class MFile:\n    \"\"\"\n    Dummy  MFile Class. Replaced by PROCESS import if PROCESS installed.\n    \"\"\"\n\n    def __init__(self, filename):\n        self.filename = filename",
  "class InDat:\n    \"\"\"\n    Dummy InDat Class. Replaced by PROCESS import if PROCESS installed.\n    \"\"\"\n\n    def __init__(self, filename):\n        self.filename = filename",
  "class _INVariable:\n    \"\"\"\n    Process io.in_dat.INVariable replica\n\n    Used to simulate what process does to input variables\n    for the InDat input file writer\n\n    This allows the defaults to imitate the same format as PROCESS'\n    InDat even if PROCESS isn't installed.\n    Therefore they will work the same in all cases and we dont always\n    need to be able to read a PROCESS input file.\n    \"\"\"\n\n    name: str\n    _value: Union[float, List, Dict]\n    v_type: TypeVar(\"InVarValueType\")\n    parameter_group: str\n    comment: str\n\n    @property\n    def get_value(self) -> Union[float, List, Dict]:\n        \"\"\"Return value in correct format\"\"\"\n        return self._value\n\n    @property\n    def value(self) -> Union[str, List, Dict]:\n        \"\"\"\n        Return the string of a value if not a Dict or a List\n        \"\"\"\n        if not isinstance(self._value, (List, Dict)):\n            return f\"{self._value}\"\n        else:\n            return self._value\n\n    @value.setter\n    def value(self, new_value):\n        \"\"\"\n        Value setter\n        \"\"\"\n        self._value = new_value",
  "class Impurities(Enum):\n    \"\"\"\n    PROCESS impurities Enum\n    \"\"\"\n\n    H = 1\n    He = 2\n    Be = 3\n    C = 4\n    N = 5\n    O = 6  # noqa: E741\n    Ne = 7\n    Si = 8\n    Ar = 9\n    Fe = 10\n    Ni = 11\n    Kr = 12\n    Xe = 13\n    W = 14\n\n    def file(self):\n        \"\"\"\n        Get PROCESS impurity data file path\n        \"\"\"\n        try:\n            return Path(Path(imp_data.__file__).parent, f\"{self.name:_<2}Lzdata.dat\")\n        except NameError:\n            raise CodesError(\"PROCESS impurity data directory not found\")\n\n    def id(self):\n        \"\"\"\n        Get variable string for impurity fraction\n        \"\"\"\n        return f\"fimp({self.value:02}\"",
  "def update_obsolete_vars(process_map_name: str) -> Union[str, List[str], None]:\n    \"\"\"\n    Check if the bluemira variable is up to date using the OBS_VAR dict.\n    If the PROCESS variable name has been updated in the installed version\n    this function will provide the updated variable name.\n\n    Parameters\n    ----------\n    process_map_name:\n        PROCESS variable name.\n\n    Returns\n    -------\n    PROCESS variable names valid for the install (if OBS_VAR is updated\n    correctly). Returns a list if an obsolete variable has been\n    split into more than one new variable (e.g., a thermal shield\n    thickness is split into ib/ob thickness). Returns `None` if there\n    is no alternative.\n    \"\"\"\n    process_name = _nested_check(process_map_name)\n\n    if process_name is not None and process_name != process_map_name:\n        bluemira_print(\n            f\"Obsolete {process_map_name} PROCESS mapping name.\"\n            f\"The current PROCESS name is {process_name}\"\n        )\n    return process_name",
  "def _nested_check(process_name):\n    \"\"\"\n    Recursively checks for obsolete variable names\n    \"\"\"\n    while process_name in OBS_VARS:\n        process_name = OBS_VARS[process_name]\n        if process_name == \"None\":\n            return None\n        if isinstance(process_name, list):\n            names = []\n            for p in process_name:\n                names += [_nested_check(p)]\n            return list(flatten_iterable(names))\n    return process_name",
  "def __init__(self, filename):\n        self.filename = filename",
  "def __init__(self, filename):\n        self.filename = filename",
  "def get_value(self) -> Union[float, List, Dict]:\n        \"\"\"Return value in correct format\"\"\"\n        return self._value",
  "def value(self) -> Union[str, List, Dict]:\n        \"\"\"\n        Return the string of a value if not a Dict or a List\n        \"\"\"\n        if not isinstance(self._value, (List, Dict)):\n            return f\"{self._value}\"\n        else:\n            return self._value",
  "def value(self, new_value):\n        \"\"\"\n        Value setter\n        \"\"\"\n        self._value = new_value",
  "def file(self):\n        \"\"\"\n        Get PROCESS impurity data file path\n        \"\"\"\n        try:\n            return Path(Path(imp_data.__file__).parent, f\"{self.name:_<2}Lzdata.dat\")\n        except NameError:\n            raise CodesError(\"PROCESS impurity data directory not found\")",
  "def id(self):\n        \"\"\"\n        Get variable string for impurity fraction\n        \"\"\"\n        return f\"fimp({self.value:02}\"",
  "class ProcessInputs:\n    \"\"\"\n    Process Inputs dataclass\n\n    Notes\n    -----\n    All entries get wrapped in an INVariable class to enable easy InDat writing.\n\n    Units for these are available in bluemira.codes.process.mapping for mapped\n    variables otherwise\n    `process.io.python_fortran_dicts.get_dicts()[\"DICT_DESCRIPTIONS\"]`\n    \"\"\"\n\n    bounds: Dict[str, Dict[str, str]] = field(\n        default_factory=lambda: {\n            \"2\": {\"u\": \"20.0\"},\n            \"3\": {\"u\": \"13\"},\n            \"4\": {\"u\": \"150.0\"},\n            \"9\": {\"u\": \"1.2\"},\n            \"18\": {\"l\": \"3.5\"},\n            \"29\": {\"l\": \"0.1\"},\n            \"38\": {\"u\": \"1.0\"},\n            \"39\": {\"u\": \"1.0\"},\n            \"42\": {\"l\": \"0.05\", \"u\": \"0.1\"},\n            \"50\": {\"u\": \"1.0\"},\n            \"52\": {\"u\": \"10.0\"},\n            \"61\": {\"l\": \"0.02\"},\n            \"103\": {\"u\": \"10.0\"},\n            \"60\": {\"l\": \"6.0e4\", \"u\": \"9.0e4\"},\n            \"59\": {\"l\": \"0.50\", \"u\": \"0.94\"},\n        }\n    )\n    # fmt: off\n    icc: List[int] = field(default_factory=lambda: [1, 2, 5, 8, 11, 13, 15, 16, 24, 25,\n                                                    26, 27, 30, 31, 32, 33, 34, 35, 36,\n                                                    60, 62, 65, 68, 72])\n    ixc: List[int] = field(default_factory=lambda: [2, 3, 4, 5, 6, 9, 13, 14, 16, 18,\n                                                    29, 36, 37, 38, 39, 41, 42, 44, 48,\n                                                    49, 50, 51, 52, 53, 54, 56, 57, 58,\n                                                    59, 60, 61, 102, 103, 106, 109, 110,\n                                                    113, 117, 122, 123])\n    # fmt: on\n    abktflnc: float = 15.0\n    adivflnc: float = 20.0\n    alphan: float = 1.0\n    alphat: float = 1.45\n    alstroh: float = 660000000.0\n    aspect: float = 3.1\n    beta: float = 0.031421\n    blnkith: float = 0.755\n    blnkoth: float = 0.982\n    bmxlim: float = 11.2\n    bore: float = 2.3322\n    bscfmax: float = 0.99\n    bt: float = 5.3292\n    casths: float = 0.05\n    cfactr: float = 0.75\n    coheof: float = 20726000.0\n    coreradiationfraction: float = 0.6\n    coreradius: float = 0.75\n    cost_model: int = 0\n    cptdin: List[float] = field(\n        default_factory=lambda: [*([42200.0] * 4), *([43000.0] * 4)]\n    )\n    cpttf: float = 65000.0\n    d_vv_bot: float = 0.6\n    d_vv_in: float = 0.6\n    d_vv_out: float = 1.1\n    d_vv_top: float = 0.6\n    ddwex: float = 0.15\n    dene: float = 7.4321e19\n    dhecoil: float = 0.01\n    dintrt: float = 0.0\n    discount_rate: float = 0.06\n    divdum: int = 1\n    divfix: float = 0.621\n    dnbeta: float = 3.0\n    dr_tf_case_in: float = 0.52465\n    dr_tf_case_out: float = 0.06\n    emult: float = 1.35\n    enbeam: float = 1e3\n    epsvmc: float = 1e-08\n    etaech: float = 0.4\n    etahtp: float = 0.87\n    etaiso: float = 0.9\n    etanbi: float = 0.3\n    etath: float = 0.375\n    fbetatry: float = 0.48251\n    fcap0: float = 1.15\n    fcap0cp: float = 1.06\n    fcohbop: float = 0.93176\n    fcontng: float = 0.15\n    fcr0: float = 0.065\n    fcuohsu: float = 0.7\n    fcutfsu: float = 0.80884\n    fdene: float = 1.2\n    ffuspow: float = 1.0\n    fgwped: float = 0.85\n    fimp: List[float] = field(\n        default_factory=lambda: [1.0, 0.1, *([0.0] * 10), 0.00044, 5e-05]\n    )\n    fimpvar: float = 0.00037786\n    fiooic: float = 0.63437\n    fjohc0: float = 0.53923\n    fjohc: float = 0.57941\n    fjprot: float = 1.0\n    fkind: float = 1.0\n    fkzohm: float = 1.0245\n    flhthresh: float = 1.4972\n    foh_stress: float = 1.0\n    fpeakb: float = 1.0\n    fpinj: float = 1.0\n    fpnetel: float = 1.0\n    fpsepbqar: float = 1.0\n    fstrcase: float = 1.0\n    fstrcond: float = 0.92007\n    ftaucq: float = 0.91874\n    ftaulimit: float = 1.0\n    ftburn: float = 1.0\n    ftmargoh: float = 1.0\n    ftmargtf: float = 1.0\n    fvdump: float = 1.0\n    fvsbrnni: float = 0.39566\n    fwalld: float = 0.131\n    gamma: float = 0.3\n    gamma_ecrh: float = 0.3\n    gapds: float = 0.02\n    gapoh: float = 0.05\n    gapomin: float = 0.2\n    hfact: float = 1.1\n    hldivlim: float = 10.0\n    i_single_null: int = 1\n    i_tf_sc_mat: int = 5\n    i_tf_turns_integer: int = 1\n    iavail: int = 0\n    ibss: int = 4\n    iculbl: int = 1\n    icurr: int = 4\n    idensl: int = 7\n    iefrf: int = 10\n    ieped: int = 1\n    ifalphap: int = 1\n    ifispact: int = 0\n    ifueltyp: int = 1\n    iinvqd: int = 1\n    impvar: int = 13\n    inuclear: int = 1\n    iohcl: int = 1\n    ioptimz: int = 1\n    ipedestal: int = 1\n    ipfloc: List[int] = field(default_factory=lambda: [2, 2, 3, 3])\n    ipowerflow: int = 0\n    iprimshld: int = 1\n    iprofile: int = 1\n    isc: int = 34\n    ishape: int = 0\n    isumatoh: int = 5\n    isumatpf: int = 3\n    kappa: float = 1.848\n    ksic: float = 1.4\n    lpulse: int = 1\n    lsa: int = 2\n    minmax: int = 1\n    n_layer: int = 10\n    n_pancake: int = 20\n    n_tf: int = 16\n    ncls: List[int] = field(default_factory=lambda: [1, 1, 2, 2])\n    neped: float = 6.78e19\n    nesep: float = 2e19\n    ngrp: int = 4\n    oacdcp: float = 8673900.0\n    oh_steel_frac: float = 0.57875\n    ohcth: float = 0.55242\n    ohhghf: float = 0.9\n    output_costs: int = 0\n    pheat: float = 50.0\n    pinjalw: float = 51.0\n    plasma_res_factor: float = 0.66\n    pnetelin: float = 500.0\n    primary_pumping: int = 3\n    prn1: float = 0.4\n    psepbqarmax: float = 9.2\n    pulsetimings: float = 0.0\n    q0: float = 1.0\n    q: float = 3.5\n    qnuc: float = 12920.0\n    ralpne: float = 0.06894\n    rhopedn: float = 0.94\n    rhopedt: float = 0.94\n    ripmax: float = 0.6\n    rjconpf: List[float] = field(\n        default_factory=lambda: [1.1e7, 1.1e7, 6e6, 6e6, 8e6, 8e6, 8e6, 8e6]\n    )\n    rmajor: float = 8.8901\n    rpf2: float = -1.825\n    scrapli: float = 0.225\n    scraplo: float = 0.225\n    secondary_cycle: int = 2\n    shldith: float = 1e-06\n    shldlth: float = 1e-06\n    shldoth: float = 1e-06\n    shldtth: float = 1e-06\n    sig_tf_case_max: float = 580000000.0\n    sig_tf_wp_max: float = 580000000.0\n    ssync: float = 0.6\n    tbeta: float = 2.0\n    tbrnmn: float = 7200.0\n    tburn: float = 10000.0\n    tdmptf: float = 25.829\n    tdwell: float = 0.0\n    te: float = 12.33\n    teped: float = 5.5\n    tesep: float = 0.1\n    tfcth: float = 1.208\n    tftmp: float = 4.75\n    tftsgap: float = 0.05\n    thicndut: float = 0.002\n    thshield: float = 0\n    thwcndut: float = 0.008\n    tinstf: float = 0.008\n    tlife: float = 40.0\n    tmargmin: float = 1.5\n    tramp: float = 500.0\n    triang: float = 0.5\n    ucblvd: float = 280.0\n    ucdiv: float = 500000.0\n    ucme: float = 300000000.0\n    vdalw: float = 10.0\n    vfshld: float = 0.6\n    vftf: float = 0.3\n    vgap2: float = 0.05\n    vvblgap: float = 0.02\n    walalw: float = 8.0\n    zeffdiv: float = 3.5\n    zref: List[float] = field(\n        default_factory=lambda: [3.6, 1.2, 1.0, 2.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n    )\n\n    def __iter__(self) -> Generator[Tuple[str, Union[float, List, Dict]], None, None]:\n        \"\"\"\n        Iterate over this dataclass\n\n        The order is based on the order in which the values were\n        declared.\n        \"\"\"\n        for _field in fields(self):\n            yield _field.name, getattr(self, _field.name)\n\n    def to_invariable(self) -> Dict[str, _INVariable]:\n        \"\"\"\n        Wrap each value in an INVariable object\n\n        Needed for compatibility with PROCESS InDat writer\n        \"\"\"\n        out_dict = {}\n        for name, value in self:\n            if name not in [\"icc\", \"ixc\", \"bounds\"]:\n                new_val = _INVariable(name, value, \"Parameter\", \"\", \"\")\n                out_dict[name] = new_val\n        out_dict[\"icc\"] = _INVariable(\n            \"icc\",\n            self.icc,\n            \"Constraint Equation\",\n            \"Constraint Equation\",\n            \"Constraint Equations\",\n        )\n        out_dict[\"ixc\"] = _INVariable(\n            \"ixc\",\n            self.ixc,\n            \"Iteration Variable\",\n            \"Iteration Variable\",\n            \"Iteration Variables\",\n        )\n        out_dict[\"bounds\"] = _INVariable(\n            \"bounds\", self.bounds, \"Bound\", \"Bound\", \"Bounds\"\n        )\n        return out_dict\n\n    def to_dict(self) -> Dict[str, Union[float, List, Dict]]:\n        \"\"\"\n        A dictionary representation of the dataclass\n\n        \"\"\"\n        return {name: value for name, value in self}",
  "def __iter__(self) -> Generator[Tuple[str, Union[float, List, Dict]], None, None]:\n        \"\"\"\n        Iterate over this dataclass\n\n        The order is based on the order in which the values were\n        declared.\n        \"\"\"\n        for _field in fields(self):\n            yield _field.name, getattr(self, _field.name)",
  "def to_invariable(self) -> Dict[str, _INVariable]:\n        \"\"\"\n        Wrap each value in an INVariable object\n\n        Needed for compatibility with PROCESS InDat writer\n        \"\"\"\n        out_dict = {}\n        for name, value in self:\n            if name not in [\"icc\", \"ixc\", \"bounds\"]:\n                new_val = _INVariable(name, value, \"Parameter\", \"\", \"\")\n                out_dict[name] = new_val\n        out_dict[\"icc\"] = _INVariable(\n            \"icc\",\n            self.icc,\n            \"Constraint Equation\",\n            \"Constraint Equation\",\n            \"Constraint Equations\",\n        )\n        out_dict[\"ixc\"] = _INVariable(\n            \"ixc\",\n            self.ixc,\n            \"Iteration Variable\",\n            \"Iteration Variable\",\n            \"Iteration Variables\",\n        )\n        out_dict[\"bounds\"] = _INVariable(\n            \"bounds\", self.bounds, \"Bound\", \"Bound\", \"Bounds\"\n        )\n        return out_dict",
  "def to_dict(self) -> Dict[str, Union[float, List, Dict]]:\n        \"\"\"\n        A dictionary representation of the dataclass\n\n        \"\"\"\n        return {name: value for name, value in self}",
  "class RunMode(BaseRunMode):\n    \"\"\"\n    Run modes for the PROCESS solver.\n    \"\"\"\n\n    RUN = auto()\n    RUNINPUT = auto()\n    READ = auto()\n    READALL = auto()\n    MOCK = auto()\n    NONE = auto()",
  "class Solver(CodesSolver):\n    \"\"\"\n    PROCESS solver. Runs, loads or mocks PROCESS to generate a reactor's\n    radial build.\n\n    Parameters\n    ----------\n    params:\n        ParameterFrame or dict containing parameters for running PROCESS.\n        See :class:`bluemira.codes.plasmod.params.ProcessSolverParams` for\n        parameter details.\n    build_config:\n        Dictionary containing the configuration for this solver.\n        Expected keys are:\n\n        * binary:\n            The path to the PROCESS binary. The default assumes the\n            PROCESS executable is on the system path.\n        * run_dir:\n            The directory in which to run PROCESS. It is also the\n            directory in which to look for PROCESS input and output\n            files. Default is current working directory.\n        * problem_settings:\n            Any PROCESS parameters that do not correspond to a bluemira\n            parameter.\n\n    Notes\n    -----\n    This solver has several run modes:\n\n    * run: Run PROCESS to generate a radial build.\n        Creates a new input file from the given template IN.DAT, which\n        is modified with bluemira parameters that are mapped with\n        :code:`send = True`.\n    * runinput: Run PROCESS with an unmodified template IN.DAT.\n        The template IN.DAT is not modified with bluemira parameters.\n        This is equivalent to all bluemira parameters mappings having\n        :code:`send = False`.\n    * read: Load the radial build from a PROCESS MFILE.DAT.\n        Loads only the parameters with :code:`send = True`.\n        A file named 'MFILE.DAT' must exist within 'run_directory'.\n    * readall: Load the radial build from a PROCESS MFILE.DAT.\n        Loads all mappable parameters from the PROCESS file.\n        A file named 'MFILE.DAT' must exist within 'run_directory'.\n    * mock: Load bluemira parameters directly from a JSON file in the\n        run directory. This does not run PROCESS.\n    * none: Does nothing.\n        PROCESS is not run and parameters are not updated. This is\n        useful loading results form previous runs of bluemira, where\n        overwriting data with PROCESS outputs would be undesirable.\n    \"\"\"\n\n    name = PROCESS_NAME\n    setup_cls = Setup\n    run_cls = Run\n    teardown_cls = Teardown\n    run_mode_cls = RunMode\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Mapping[str, Union[float, str, BuildConfig]],\n    ):\n        # Init task objects on execution so parameters can be edited\n        # between separate 'execute' calls.\n        self._setup: Union[Setup, None] = None\n        self._run: Union[Run, None] = None\n        self._teardown: Union[Teardown, None] = None\n\n        self.params = ProcessSolverParams.from_defaults()\n\n        if isinstance(params, ParameterFrame):\n            self.params.update_from_frame(params)\n        else:\n            try:\n                self.params.update_from_dict(params)\n            except TypeError:\n                self.params.update_values(params)\n\n        _build_config = copy.deepcopy(build_config)\n        self.binary = _build_config.pop(\"binary\", PROCESS_BINARY)\n        self.run_directory = _build_config.pop(\"run_dir\", os.getcwd())\n        self.read_directory = _build_config.pop(\"read_dir\", os.getcwd())\n        self.template_in_dat = _build_config.pop(\n            \"template_in_dat\", self.params.template_defaults\n        )\n        self.problem_settings = _build_config.pop(\"problem_settings\", {})\n        self.in_dat_path = _build_config.pop(\n            \"in_dat_path\", os.path.join(self.run_directory, \"IN.DAT\")\n        )\n        if len(_build_config) > 0:\n            quoted_delim = \"', '\"\n            bluemira_warn(\n                f\"'{self.name}' solver received unknown build_config arguments: \"\n                f\"'{quoted_delim.join(_build_config.keys())}'.\"\n            )\n\n    def execute(self, run_mode: Union[str, RunMode]) -> ParameterFrame:\n        \"\"\"\n        Execute the solver in the given run mode.\n\n        Parameters\n        ----------\n        run_mode:\n            The run mode to execute the solver in. See the\n            :func:`~bluemira.codes.process._solver.Solver.__init__`\n            docstring for details of the behaviour of each run mode.\n        \"\"\"\n        if isinstance(run_mode, str):\n            run_mode = self.run_mode_cls.from_string(run_mode)\n        self._setup = Setup(\n            self.params,\n            self.in_dat_path,\n            self.template_in_dat,\n            self.problem_settings,\n        )\n        self._run = Run(self.params, self.in_dat_path, self.binary)\n        self._teardown = Teardown(self.params, self.run_directory, self.read_directory)\n\n        if setup := self._get_execution_method(self._setup, run_mode):\n            setup()\n        if run := self._get_execution_method(self._run, run_mode):\n            run()\n        if teardown := self._get_execution_method(self._teardown, run_mode):\n            teardown()\n\n        return self.params\n\n    def get_raw_variables(self, params: Union[List, str]) -> List[float]:\n        \"\"\"\n        Get raw variables from this solver's associate MFile.\n\n        Mapped bluemira parameters will have bluemira names.\n\n        Parameters\n        ----------\n        params:\n            Names of parameters to access.\n\n        Returns\n        -------\n        The parameter values.\n        \"\"\"\n        if self._teardown:\n            return self._teardown.get_raw_outputs(params)\n        raise CodesError(\n            \"Cannot retrieve output from PROCESS MFile. \"\n            \"The solver has not been run, so no MFile is available to read.\"\n        )\n\n    @staticmethod\n    def get_species_data(impurity: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Get species data from PROCESS section of OPEN-ADAS database.\n\n        The data is taken with density $n_e = 10^{19} m^{-3}$.\n\n        Parameters\n        ----------\n        impurity:\n            The impurity to get the species data for. This string should\n            be one of the names in the\n            :class:`~bluemira.codes.process.api.Impurities` Enum.\n\n        Returns\n        -------\n        tref:\n            The temperature in keV.\n        l_ref:\n            The loss function value $L_z(n_e, T_e)$ in W.m3.\n        z_ref:\n            Average effective charge.\n        \"\"\"\n        t_ref, lz_ref, z_av_ref = np.genfromtxt(Impurities[impurity].file()).T\n        return t_ref, lz_ref, z_av_ref\n\n    def get_species_fraction(self, impurity: str) -> float:\n        \"\"\"\n        Get species fraction for the given impurity.\n\n        Parameters\n        ----------\n        impurity:\n            The impurity to get the species data for. This string should\n            be one of the names in the\n            :class:`~bluemira.codes.process.api.Impurities` Enum.\n\n        Returns\n        -------\n        The species fraction for the impurity taken from the PROCESS\n        output MFile.\n        \"\"\"\n        return self.get_raw_variables(Impurities[impurity].id())[0]",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame],\n        build_config: Mapping[str, Union[float, str, BuildConfig]],\n    ):\n        # Init task objects on execution so parameters can be edited\n        # between separate 'execute' calls.\n        self._setup: Union[Setup, None] = None\n        self._run: Union[Run, None] = None\n        self._teardown: Union[Teardown, None] = None\n\n        self.params = ProcessSolverParams.from_defaults()\n\n        if isinstance(params, ParameterFrame):\n            self.params.update_from_frame(params)\n        else:\n            try:\n                self.params.update_from_dict(params)\n            except TypeError:\n                self.params.update_values(params)\n\n        _build_config = copy.deepcopy(build_config)\n        self.binary = _build_config.pop(\"binary\", PROCESS_BINARY)\n        self.run_directory = _build_config.pop(\"run_dir\", os.getcwd())\n        self.read_directory = _build_config.pop(\"read_dir\", os.getcwd())\n        self.template_in_dat = _build_config.pop(\n            \"template_in_dat\", self.params.template_defaults\n        )\n        self.problem_settings = _build_config.pop(\"problem_settings\", {})\n        self.in_dat_path = _build_config.pop(\n            \"in_dat_path\", os.path.join(self.run_directory, \"IN.DAT\")\n        )\n        if len(_build_config) > 0:\n            quoted_delim = \"', '\"\n            bluemira_warn(\n                f\"'{self.name}' solver received unknown build_config arguments: \"\n                f\"'{quoted_delim.join(_build_config.keys())}'.\"\n            )",
  "def execute(self, run_mode: Union[str, RunMode]) -> ParameterFrame:\n        \"\"\"\n        Execute the solver in the given run mode.\n\n        Parameters\n        ----------\n        run_mode:\n            The run mode to execute the solver in. See the\n            :func:`~bluemira.codes.process._solver.Solver.__init__`\n            docstring for details of the behaviour of each run mode.\n        \"\"\"\n        if isinstance(run_mode, str):\n            run_mode = self.run_mode_cls.from_string(run_mode)\n        self._setup = Setup(\n            self.params,\n            self.in_dat_path,\n            self.template_in_dat,\n            self.problem_settings,\n        )\n        self._run = Run(self.params, self.in_dat_path, self.binary)\n        self._teardown = Teardown(self.params, self.run_directory, self.read_directory)\n\n        if setup := self._get_execution_method(self._setup, run_mode):\n            setup()\n        if run := self._get_execution_method(self._run, run_mode):\n            run()\n        if teardown := self._get_execution_method(self._teardown, run_mode):\n            teardown()\n\n        return self.params",
  "def get_raw_variables(self, params: Union[List, str]) -> List[float]:\n        \"\"\"\n        Get raw variables from this solver's associate MFile.\n\n        Mapped bluemira parameters will have bluemira names.\n\n        Parameters\n        ----------\n        params:\n            Names of parameters to access.\n\n        Returns\n        -------\n        The parameter values.\n        \"\"\"\n        if self._teardown:\n            return self._teardown.get_raw_outputs(params)\n        raise CodesError(\n            \"Cannot retrieve output from PROCESS MFile. \"\n            \"The solver has not been run, so no MFile is available to read.\"\n        )",
  "def get_species_data(impurity: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Get species data from PROCESS section of OPEN-ADAS database.\n\n        The data is taken with density $n_e = 10^{19} m^{-3}$.\n\n        Parameters\n        ----------\n        impurity:\n            The impurity to get the species data for. This string should\n            be one of the names in the\n            :class:`~bluemira.codes.process.api.Impurities` Enum.\n\n        Returns\n        -------\n        tref:\n            The temperature in keV.\n        l_ref:\n            The loss function value $L_z(n_e, T_e)$ in W.m3.\n        z_ref:\n            Average effective charge.\n        \"\"\"\n        t_ref, lz_ref, z_av_ref = np.genfromtxt(Impurities[impurity].file()).T\n        return t_ref, lz_ref, z_av_ref",
  "def get_species_fraction(self, impurity: str) -> float:\n        \"\"\"\n        Get species fraction for the given impurity.\n\n        Parameters\n        ----------\n        impurity:\n            The impurity to get the species data for. This string should\n            be one of the names in the\n            :class:`~bluemira.codes.process.api.Impurities` Enum.\n\n        Returns\n        -------\n        The species fraction for the impurity taken from the PROCESS\n        output MFile.\n        \"\"\"\n        return self.get_raw_variables(Impurities[impurity].id())[0]",
  "def boxr(\n    ri: float, ro: float, w: float, off: float = 0\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Generate coordinates for an arbitrary height radial width. Used in plotting.\n    \"\"\"\n    xc = [ri, ri, ro, ro, ri]\n    yc = [-w, w, w, -w, -w]\n    yc = [i + off for i in yc]\n    return xc, yc",
  "def read_rb_line(line: str):\n    \"\"\"\n    Inputs: a line from the PROCESS radial/vertical build\n    Outputs: the first three columns from that line\n    \"\"\"\n    line = line.split()\n    for i, v in enumerate(line):\n        if is_num(v) is False:\n            if i > 0:\n                line[0] = \" \".join([line[0], v])\n        elif is_num(v) is True:\n            line[1] = float(v)\n            line[2] = float(line[i + 1])\n            return line[:3]",
  "def strip_num(line: str, typ: str = \"float\", n: int = 0) -> int:\n    \"\"\"\n    Returns a single number in a line\n    \"\"\"\n    numb = [float(i) for i in line.split() if is_num(i) is True][n]\n    if typ == \"int\":\n        numb = int(numb)\n    return numb",
  "def read_n_line(line: str):\n    \"\"\"\n    Reads a line from the PROCESS output in the format below:\n    Major radius (m)   / (rmajor)     /           9.203  ITV\n    Returns the variable name [0], its value [1], and the rest [2]\n    \"\"\"\n    line = line.split()\n    out = [\"\"] * 3\n    for i, word in enumerate(line):\n        if word.startswith(\"(\") is True or word.endswith(\")\") is True:\n            out[2] = \" \".join([out[2], word]).lstrip()\n        elif is_num(word) is True:\n            out[1] = float(word)\n        elif word.isupper() is True:\n            out[2] = \" \".join([out[2], word]).lstrip()\n        else:\n            out[0] = \" \".join([out[0], word]).lstrip()\n    return out",
  "def setup_radial_build(run: Dict[str, Any], width: float = 1.0):\n    \"\"\"\n    Plots radial and vertical build of a PROCESS run.\n\n    Parameters\n    ----------\n    run:\n        Dictionary of PROCESS outputs.\n\n    Returns\n    -------\n    plots: Axes\n        The Matplotlib Axes object.\n    \"\"\"\n    from bluemira.display.plotter import plot_coordinates\n    from bluemira.geometry.coordinates import Coordinates\n\n    R_0 = run[\"R_0\"]\n\n    col = {\n        \"Gap\": \"w\",\n        \"blanket\": \"#edb120\",\n        \"TF coil\": \"#7e2f8e\",\n        \"Vacuum vessel\": \"k\",\n        \"Plasma\": \"#f77ec7\",\n        \"first wall\": \"#edb120\",\n        \"Machine bore\": \"w\",\n        \"precomp\": \"#0072bd\",\n        \"scrape-off\": \"#a2142f\",\n        \"solenoid\": \"#0072bd\",\n        \"Thermal shield\": \"#77ac30\",\n    }\n\n    f, ax = plt.subplots(figsize=[14, 10])\n\n    lpatches = []\n    gkeys = [\n        \"blanket\",\n        \"TF coil\",\n        \"Vacuum vessel\",\n        \"Plasma\",\n        \"scrape-off\",\n        \"solenoid\",\n        \"Thermal shield\",\n    ]\n    glabels = {\n        \"blanket\": \"Breeding blanket\",\n        \"TF coil\": \"TF coil\",\n        \"Plasma\": \"Plasma\",\n        \"Vacuum vessel\": \"Vacuum vessel\",\n        \"scrape-off\": \"Scrape-off layer\",\n        \"solenoid\": \"Central solenoid\",\n        \"Thermal shield\": \"Thermal shield\",\n    }\n    for comp in run[\"Radial Build\"]:\n        xc, yc = boxr(comp[2] - comp[1], comp[2], width)\n        yc = np.array(yc)\n        coords = Coordinates({\"x\": xc, \"y\": yc})\n        for key, c in col.items():\n            if key in comp[0]:\n                ax.plot(xc, yc, color=c, linewidth=0, label=key)\n                if comp[1] > 0:\n                    plot_coordinates(\n                        coords, ax=ax, facecolor=c, edgecolor=\"k\", linewidth=0\n                    )\n                if key in gkeys:\n                    gkeys.remove(key)\n                    lpatches.append(patches.Patch(color=c, label=glabels[key]))\n\n    ax.set_xlim([0, np.ceil(run[\"Radial Build\"][-1][-1])])\n    ax.set_ylim([-width * 0.5, width * 0.5])\n    ax.set_xticks(list(ax.get_xticks()) + [R_0])\n    ax.axes.set_axisbelow(False)\n\n    def tick_format(value, n):\n        if value == R_0:\n            return \"\\n$R_{0}$\"\n        else:\n            return int(value)\n\n    def tick_formaty(value, n):\n        if value == 0:\n            return int(value)\n        else:\n            return \"\"\n\n    ax.xaxis.set_major_formatter(plt.FuncFormatter(tick_format))\n    ax.yaxis.set_major_formatter(plt.FuncFormatter(tick_formaty))\n    ax.set_xlabel(\"$x$ [m]\")\n    ax.set_aspect(\"equal\")\n    ax.legend(\n        handles=lpatches,\n        ncol=3,\n        loc=\"lower left\",\n        bbox_to_anchor=(0.0, 1.0),\n        frameon=False,\n    )\n    return ax",
  "def process_RB_fromOUT(f):  # noqa :N802\n    \"\"\"\n    Parse PROCESS radial build from an OUT.DAT file.\n    \"\"\"\n    # If the input is a string, treat as file name, and ensure it is closed.\n    if isinstance(f, str):\n        with open(f) as fh:\n            return process_RB_fromOUT(fh)  # Recursive call with file object\n    raw = f.readlines()\n    raw = raw[1:]\n    if not raw:\n        raise IOError(\"Cannot read from input file.\")\n    if PROCESS not in raw[1] and PROCESS not in raw[2]:\n        bluemira_warn(\n            \"Either this ain't a PROCESS OUT.DAT file, or those hijos \"\n            \"changed the format.\"\n        )\n\n    def read_radial_build(num):  # Be careful that the numbers don't change\n        rb = []\n        num += 1\n        while \"***\" not in raw[num]:\n            if read_rb_line(raw[num]) is None:\n                pass\n            else:\n                rb.append(read_rb_line(raw[num]))\n            num += 1\n        return rb\n\n    flag1, flag2, flag3 = False, False, False\n    for num, line in enumerate(raw):\n        if \"* Radial Build *\" in line:\n            flag1 = True\n            rb = read_radial_build(num)\n        if \"n_tf\" in line:\n            flag2 = True\n            n_TF = strip_num(line, typ=\"int\")\n        if \"Major radius\" in line:\n            flag3 = True\n            R_0 = strip_num(line)\n        if flag1 and flag2 and flag3:\n            break\n    return {\"Radial Build\": rb, \"n_TF\": n_TF, \"R_0\": R_0}",
  "def plot_radial_build(\n    sys_code_dir: str, width: float = 1.0, show: bool = True\n) -> plt.Axes:\n    \"\"\"\n    Plot PROCESS radial build.\n\n    Parameters\n    ----------\n    sys_code_dir:\n        OUT.DAT directory location\n    width:\n        The relative width of the plot.\n    show:\n        If True then immediately display the plot, else delay displaying the plot until\n        the user shows it, by default True.\n\n    Returns\n    -------\n    The plot Axes object.\n    \"\"\"\n    filename = os.path.join(sys_code_dir, \"OUT.DAT\")\n\n    if not os.path.isfile(filename):\n        raise CodesError(f\"Could not find PROCESS OUT.DAT file '{filename}'.\")\n\n    radial_build = process_RB_fromOUT(filename)\n    ax = setup_radial_build(radial_build, width=width)\n    if show:\n        plt.show()\n    return ax",
  "def tick_format(value, n):\n        if value == R_0:\n            return \"\\n$R_{0}$\"\n        else:\n            return int(value)",
  "def tick_formaty(value, n):\n        if value == 0:\n            return int(value)\n        else:\n            return \"\"",
  "def read_radial_build(num):  # Be careful that the numbers don't change\n        rb = []\n        num += 1\n        while \"***\" not in raw[num]:\n            if read_rb_line(raw[num]) is None:\n                pass\n            else:\n                rb.append(read_rb_line(raw[num]))\n            num += 1\n        return rb",
  "class CurrentDriveEfficiencyModel(Model):\n    \"\"\"\n    Switch for current drive efficiency model:\n\n    1 - Fenstermacher Lower Hybrid\n    2 - Ion Cyclotron current drive\n    3 - Fenstermacher ECH\n    4 - Ehst Lower Hybrid\n    5 - ITER Neutral Beam\n    6 - new Culham Lower Hybrid model\n    7 - new Culham ECCD model\n    8 - new Culham Neutral Beam model\n    10 - ECRH user input gamma\n    11 - ECRH \"HARE\" model (E. Poli, Physics of Plasmas 2019)\n    12 - EBW user scaling input. Scaling (S. Freethy)\n\n    PROCESS variable name: \"iefrf\"\n    \"\"\"\n\n    FENSTER_LH = 1\n    ICYCCD = 2\n    FENSTER_ECH = 3\n    EHST_LH = 4\n    ITER_NB = 5\n    CUL_LH = 6\n    CUL_ECCD = 7\n    CUL_NB = 8\n    ECRH_UI_GAM = 10\n    ECRH_HARE = 11\n    EBW_UI = 12",
  "class TFCoilConductorTechnology(Model):\n    \"\"\"\n    Switch for TF coil conductor model:\n\n    0 - copper\n    1 - superconductor\n    2 - Cryogenic aluminium\n\n    PROCESS variable name: \"i_tf_sup\"\n    \"\"\"\n\n    COPPER = 0\n    SC = 1\n    CRYO_AL = 2",
  "class Teardown(CodesTeardown):\n    \"\"\"\n    Teardown task for PROCESS solver.\n\n    Parameters\n    ----------\n    params:\n        The parameters for this task.\n    run_directory:\n        The directory in which to run PROCESS. Used in run, and runinput\n        functions.\n    read_directory:\n        The directory to read PROCESS output files from. Used in read,\n        readall, and mock functions.\n    \"\"\"\n\n    params: ProcessSolverParams\n\n    MOCK_JSON_NAME = \"mockPROCESS.json\"\n\n    def __init__(\n        self, params: ProcessSolverParams, run_directory: str, read_directory: str\n    ):\n        super().__init__(params, PROCESS_NAME)\n        self.run_directory = run_directory\n        self.read_directory = read_directory\n        self._mfile_wrapper: _MFileWrapper = None\n\n    def run(self):\n        \"\"\"\n        Teardown the PROCESS solver.\n\n        This loads the MFile in the run directory and maps its outputs\n        to bluemira parameters.\n        \"\"\"\n        self._load_mfile(os.path.join(self.run_directory, \"MFILE.DAT\"), recv_all=False)\n\n    def runinput(self):\n        \"\"\"\n        Teardown the PROCESS solver.\n\n        This loads the MFile in the run directory and maps its outputs\n        to bluemira parameters.\n        \"\"\"\n        self._load_mfile(os.path.join(self.run_directory, \"MFILE.DAT\"), recv_all=True)\n\n    def read(self):\n        \"\"\"\n        Teardown the PROCESS solver.\n\n        This loads the MFile in the run directory and maps its outputs\n        to bluemira parameters.\n        \"\"\"\n        self._load_mfile(os.path.join(self.read_directory, \"MFILE.DAT\"), recv_all=False)\n\n    def readall(self):\n        \"\"\"\n        Teardown the PROCESS solver.\n\n        This loads the MFile in the run directory and maps its outputs\n        to bluemira parameters.\n        \"\"\"\n        self._load_mfile(os.path.join(self.read_directory, \"MFILE.DAT\"), recv_all=True)\n\n    def mock(self):\n        \"\"\"\n        Mock teardown the PROCESS solver.\n\n        This loads a mockProcess.json file from the run directory and\n        loads the values into this task's params.\n        \"\"\"\n        bluemira_print(\"Mocking PROCESS systems code run\")\n        mock_file_path = os.path.join(self.read_directory, self.MOCK_JSON_NAME)\n        outputs = read_mock_json_or_raise(mock_file_path, self._name)\n        self.params.update_values(outputs, source=self._name)\n\n    def get_raw_outputs(self, params: Union[Iterable, str]) -> List[float]:\n        \"\"\"\n        Get raw variables from an MFILE.\n\n        Mapped bluemira parameters will have bluemira names.\n\n        Parameters\n        ----------\n        params:\n            Names of parameters to access.\n\n        Returns\n        -------\n        The parameter values.\n        \"\"\"\n        if not self._mfile_wrapper:\n            raise CodesError(\n                f\"Cannot retrieve output from {self._name} MFile. \"\n                \"The solver has not been run, so no MFile is available to read.\"\n            )\n        if isinstance(params, str):\n            params = [params]\n        outputs = []\n        data = self._mfile_wrapper.data\n        for param_name in params:\n            if mapping := self.params.mappings.get(param_name, None):\n                process_name = mapping.name\n            else:\n                process_name = param_name\n            try:\n                value = data[process_name]\n            except KeyError:\n                raise CodesError(\n                    f\"No {self._name} output, or bluemira parameter mapped to a {self._name} \"\n                    f\"output, with name '{param_name}'.\"\n                )\n            outputs.append(value)\n        return outputs\n\n    def _load_mfile(self, path: str, recv_all: bool):\n        \"\"\"\n        Load the MFile at the given path, and update this object's\n        params with the MFile's values.\n\n        If recv_all, then ignore existing mappings and update all the\n        params that correspond to a PROCESS output. If recv_all is\n        False, then only update a parameter if its mapping has\n        ``recv == True``.\n        \"\"\"\n        mfile = self._read_mfile(path)\n        self._update_params_with_outputs(mfile.data, recv_all)\n\n    def _read_mfile(self, path: str):\n        \"\"\"\n        Read an MFile, applying the given mappings, and performing unit\n        conversions.\n        \"\"\"\n        self._mfile_wrapper = _MFileWrapper(path, self._name)\n        self._mfile_wrapper.read()\n        return self._mfile_wrapper",
  "class _MFileWrapper:\n    \"\"\"\n    Utility class to wrap a PROCESS MFile, and map its data to bluemira\n    parameters.\n\n    Parameters\n    ----------\n    file_path:\n        Path to an MFile.\n    \"\"\"\n\n    def __init__(self, file_path: str, name: str = \"PROCESS\"):\n        if not os.path.isfile(file_path):\n            raise CodesError(f\"Path '{file_path}' is not a file.\")\n        self._name = name\n        self.file_path = file_path\n        self.mfile = MFile(file_path)\n        _raise_on_infeasible_solution(self)\n        self.data = {}\n\n    def read(self) -> Dict:\n        \"\"\"\n        Read the data from the PROCESS MFile.\n\n        Store the result in ``data`` attribute.\n        \"\"\"\n        self.data = {}\n        for process_param_name, value in self.mfile.data.items():\n            param_name = update_obsolete_vars(process_param_name)\n            if param_name is None:\n                bluemira_warn(\n                    f\"{self._name} parameter '{process_param_name}' is obsolete and has no \"\n                    \" alternative. Setting value to NaN\"\n                )\n                self.data[process_param_name] = np.nan\n            elif isinstance(param_name, list):\n                for name in param_name:\n                    self.data[name] = value[\"scan01\"]\n            else:\n                self.data[param_name] = value[\"scan01\"]\n\n        self.data.update(self._derive_radial_build_params(self.data))\n\n    def _derive_radial_build_params(self, data: Dict) -> Dict[str, float]:\n        \"\"\"\n        Derive radial build parameters that PROCESS does not directly calculate.\n\n        Notes\n        -----\n        The PROCESS radial build is taken along the diagonal (maximum\n        length) of the TF coil, so this must be taken into consideration\n        when translating the geometry into the mid-plane.\n        \"\"\"\n        try:\n            shield_th = data[\"thshield\"]\n        except KeyError:\n            # PROCESS updated their parameter names in v2.4.0, splitting\n            # 'thshield' into 'thshield_ib', 'thshield_ob', and 'thshield_vb'\n            shield_th = data[\"thshield_ib\"] + data[\"thshield_ib\"]\n\n        try:\n            rtfin = data[\"bore\"] + data[\"ohcth\"] + data[\"precomp\"] + data[\"gapoh\"]\n            r_ts_ib_in = rtfin + data[\"tfcth\"] + data[\"tftsgap\"] + shield_th\n            r_vv_ib_in = r_ts_ib_in + data[\"gapds\"] + data[\"d_vv_in\"] + data[\"shldith\"]\n            r_fw_ib_in = r_vv_ib_in + data[\"vvblgap\"] + data[\"blnkith\"] + data[\"fwith\"]\n            r_fw_ob_in = (\n                r_fw_ib_in + data[\"scrapli\"] + 2 * data[\"rminor\"] + data[\"scraplo\"]\n            )\n            r_vv_ob_in = r_fw_ob_in + data[\"fwoth\"] + data[\"blnkoth\"] + data[\"vvblgap\"]\n        except KeyError as key_error:\n            raise CodesError(\n                f\"Missing PROCESS parameter in '{self.file_path}': {key_error}\\n\"\n                \"Cannot derive required bluemira parameters.\"\n            )\n        return {\n            \"rtfin\": rtfin,\n            \"r_ts_ib_in\": r_ts_ib_in,\n            \"r_vv_ib_in\": r_vv_ib_in,\n            \"r_fw_ib_in\": r_fw_ib_in,\n            \"r_fw_ob_in\": r_fw_ob_in,\n            \"r_vv_ob_in\": r_vv_ob_in,\n        }",
  "def _raise_on_infeasible_solution(m_file: _MFileWrapper):\n    \"\"\"\n    Check that PROCESS found a feasible solution.\n\n    Parameters\n    ----------\n    m_file:\n        The PROCESS MFILE to check for a feasible solution\n\n    Raises\n    ------\n    CodesError\n        If a feasible solution was not found.\n    \"\"\"\n    error_code = int(m_file.mfile.data[\"ifail\"][\"scan01\"])\n    if error_code != 1:\n        message = (\n            f\"{m_file._name} did not find a feasible solution. ifail = {error_code}.\"\n            \" Check PROCESS logs.\"\n        )\n        raise CodesError(message)",
  "def __init__(\n        self, params: ProcessSolverParams, run_directory: str, read_directory: str\n    ):\n        super().__init__(params, PROCESS_NAME)\n        self.run_directory = run_directory\n        self.read_directory = read_directory\n        self._mfile_wrapper: _MFileWrapper = None",
  "def run(self):\n        \"\"\"\n        Teardown the PROCESS solver.\n\n        This loads the MFile in the run directory and maps its outputs\n        to bluemira parameters.\n        \"\"\"\n        self._load_mfile(os.path.join(self.run_directory, \"MFILE.DAT\"), recv_all=False)",
  "def runinput(self):\n        \"\"\"\n        Teardown the PROCESS solver.\n\n        This loads the MFile in the run directory and maps its outputs\n        to bluemira parameters.\n        \"\"\"\n        self._load_mfile(os.path.join(self.run_directory, \"MFILE.DAT\"), recv_all=True)",
  "def read(self):\n        \"\"\"\n        Teardown the PROCESS solver.\n\n        This loads the MFile in the run directory and maps its outputs\n        to bluemira parameters.\n        \"\"\"\n        self._load_mfile(os.path.join(self.read_directory, \"MFILE.DAT\"), recv_all=False)",
  "def readall(self):\n        \"\"\"\n        Teardown the PROCESS solver.\n\n        This loads the MFile in the run directory and maps its outputs\n        to bluemira parameters.\n        \"\"\"\n        self._load_mfile(os.path.join(self.read_directory, \"MFILE.DAT\"), recv_all=True)",
  "def mock(self):\n        \"\"\"\n        Mock teardown the PROCESS solver.\n\n        This loads a mockProcess.json file from the run directory and\n        loads the values into this task's params.\n        \"\"\"\n        bluemira_print(\"Mocking PROCESS systems code run\")\n        mock_file_path = os.path.join(self.read_directory, self.MOCK_JSON_NAME)\n        outputs = read_mock_json_or_raise(mock_file_path, self._name)\n        self.params.update_values(outputs, source=self._name)",
  "def get_raw_outputs(self, params: Union[Iterable, str]) -> List[float]:\n        \"\"\"\n        Get raw variables from an MFILE.\n\n        Mapped bluemira parameters will have bluemira names.\n\n        Parameters\n        ----------\n        params:\n            Names of parameters to access.\n\n        Returns\n        -------\n        The parameter values.\n        \"\"\"\n        if not self._mfile_wrapper:\n            raise CodesError(\n                f\"Cannot retrieve output from {self._name} MFile. \"\n                \"The solver has not been run, so no MFile is available to read.\"\n            )\n        if isinstance(params, str):\n            params = [params]\n        outputs = []\n        data = self._mfile_wrapper.data\n        for param_name in params:\n            if mapping := self.params.mappings.get(param_name, None):\n                process_name = mapping.name\n            else:\n                process_name = param_name\n            try:\n                value = data[process_name]\n            except KeyError:\n                raise CodesError(\n                    f\"No {self._name} output, or bluemira parameter mapped to a {self._name} \"\n                    f\"output, with name '{param_name}'.\"\n                )\n            outputs.append(value)\n        return outputs",
  "def _load_mfile(self, path: str, recv_all: bool):\n        \"\"\"\n        Load the MFile at the given path, and update this object's\n        params with the MFile's values.\n\n        If recv_all, then ignore existing mappings and update all the\n        params that correspond to a PROCESS output. If recv_all is\n        False, then only update a parameter if its mapping has\n        ``recv == True``.\n        \"\"\"\n        mfile = self._read_mfile(path)\n        self._update_params_with_outputs(mfile.data, recv_all)",
  "def _read_mfile(self, path: str):\n        \"\"\"\n        Read an MFile, applying the given mappings, and performing unit\n        conversions.\n        \"\"\"\n        self._mfile_wrapper = _MFileWrapper(path, self._name)\n        self._mfile_wrapper.read()\n        return self._mfile_wrapper",
  "def __init__(self, file_path: str, name: str = \"PROCESS\"):\n        if not os.path.isfile(file_path):\n            raise CodesError(f\"Path '{file_path}' is not a file.\")\n        self._name = name\n        self.file_path = file_path\n        self.mfile = MFile(file_path)\n        _raise_on_infeasible_solution(self)\n        self.data = {}",
  "def read(self) -> Dict:\n        \"\"\"\n        Read the data from the PROCESS MFile.\n\n        Store the result in ``data`` attribute.\n        \"\"\"\n        self.data = {}\n        for process_param_name, value in self.mfile.data.items():\n            param_name = update_obsolete_vars(process_param_name)\n            if param_name is None:\n                bluemira_warn(\n                    f\"{self._name} parameter '{process_param_name}' is obsolete and has no \"\n                    \" alternative. Setting value to NaN\"\n                )\n                self.data[process_param_name] = np.nan\n            elif isinstance(param_name, list):\n                for name in param_name:\n                    self.data[name] = value[\"scan01\"]\n            else:\n                self.data[param_name] = value[\"scan01\"]\n\n        self.data.update(self._derive_radial_build_params(self.data))",
  "def _derive_radial_build_params(self, data: Dict) -> Dict[str, float]:\n        \"\"\"\n        Derive radial build parameters that PROCESS does not directly calculate.\n\n        Notes\n        -----\n        The PROCESS radial build is taken along the diagonal (maximum\n        length) of the TF coil, so this must be taken into consideration\n        when translating the geometry into the mid-plane.\n        \"\"\"\n        try:\n            shield_th = data[\"thshield\"]\n        except KeyError:\n            # PROCESS updated their parameter names in v2.4.0, splitting\n            # 'thshield' into 'thshield_ib', 'thshield_ob', and 'thshield_vb'\n            shield_th = data[\"thshield_ib\"] + data[\"thshield_ib\"]\n\n        try:\n            rtfin = data[\"bore\"] + data[\"ohcth\"] + data[\"precomp\"] + data[\"gapoh\"]\n            r_ts_ib_in = rtfin + data[\"tfcth\"] + data[\"tftsgap\"] + shield_th\n            r_vv_ib_in = r_ts_ib_in + data[\"gapds\"] + data[\"d_vv_in\"] + data[\"shldith\"]\n            r_fw_ib_in = r_vv_ib_in + data[\"vvblgap\"] + data[\"blnkith\"] + data[\"fwith\"]\n            r_fw_ob_in = (\n                r_fw_ib_in + data[\"scrapli\"] + 2 * data[\"rminor\"] + data[\"scraplo\"]\n            )\n            r_vv_ob_in = r_fw_ob_in + data[\"fwoth\"] + data[\"blnkoth\"] + data[\"vvblgap\"]\n        except KeyError as key_error:\n            raise CodesError(\n                f\"Missing PROCESS parameter in '{self.file_path}': {key_error}\\n\"\n                \"Cannot derive required bluemira parameters.\"\n            )\n        return {\n            \"rtfin\": rtfin,\n            \"r_ts_ib_in\": r_ts_ib_in,\n            \"r_vv_ib_in\": r_vv_ib_in,\n            \"r_fw_ib_in\": r_fw_ib_in,\n            \"r_fw_ob_in\": r_fw_ob_in,\n            \"r_vv_ob_in\": r_vv_ob_in,\n        }",
  "class ProcessSolverParams(MappedParameterFrame):\n    \"\"\"Parameters required in :class:`bluemira.codes.process.Solver`.\"\"\"\n\n    # In parameters\n    C_Ejima: Parameter[float]\n    \"\"\"Ejima constant [dimensionless].\"\"\"\n\n    e_mult: Parameter[float]\n    \"\"\"\n    Energy multiplication factor [dimensionless]. Instantaneous energy\n    multiplication due to neutron multiplication and the like.\n    \"\"\"\n\n    e_nbi: Parameter[float]\n    \"\"\"Neutral beam energy [kiloelectron_volt].\"\"\"\n\n    eta_nb: Parameter[float]\n    \"\"\"NB electrical efficiency [dimensionless]. Check units!.\"\"\"\n\n    n_TF: Parameter[int]\n    \"\"\"Number of TF coils [dimensionless].\"\"\"\n\n    P_el_net: Parameter[float]\n    \"\"\"Net electrical power output [megawatt].\"\"\"\n\n    P_hcd_ss: Parameter[float]\n    \"\"\"Steady-state HCD power [megawatt].\"\"\"\n\n    TF_ripple_limit: Parameter[float]\n    \"\"\"TF coil ripple limit [percent].\"\"\"\n\n    tk_cr_vv: Parameter[float]\n    \"\"\"Cryostat VV thickness [meter].\"\"\"\n\n    tk_sh_bot: Parameter[float]\n    \"\"\"Lower shield thickness [meter]. DO NOT USE - PROCESS has VV = VV + shield.\"\"\"\n\n    tk_sh_out: Parameter[float]\n    \"\"\"Outboard shield thickness [meter]. DO NOT USE - PROCESS has VV = VV + shield.\"\"\"\n\n    tk_sh_top: Parameter[float]\n    \"\"\"Upper shield thickness [meter]. DO NOT USE - PROCESS has VV = VV + shield.\"\"\"\n\n    tk_tf_front_ib: Parameter[float]\n    \"\"\"TF coil inboard steel front plasma-facing [meter].\"\"\"\n\n    tk_tf_side: Parameter[float]\n    \"\"\"TF coil inboard case minimum side wall thickness [meter].\"\"\"\n\n    tk_vv_bot: Parameter[float]\n    \"\"\"Lower vacuum vessel thickness [meter].\"\"\"\n\n    tk_vv_out: Parameter[float]\n    \"\"\"Outboard vacuum vessel thickness [meter].\"\"\"\n\n    tk_vv_top: Parameter[float]\n    \"\"\"Upper vacuum vessel thickness [meter].\"\"\"\n\n    PsepB_qAR_max: Parameter[float]\n    \"\"\"Maximum PsepB/q95AR vale [MW.T/m]\"\"\"\n\n    # Out parameters\n    B_0: Parameter[float]\n    \"\"\"Toroidal field at R_0 [tesla].\"\"\"\n\n    beta_p: Parameter[float]\n    \"\"\"Ratio of plasma pressure to poloidal magnetic pressure [dimensionless].\"\"\"\n\n    beta: Parameter[float]\n    \"\"\"Total ratio of plasma pressure to magnetic pressure [dimensionless].\"\"\"\n\n    condrad_cryo_heat: Parameter[float]\n    \"\"\"Conduction and radiation heat loads on cryogenic components [megawatt].\"\"\"\n\n    delta_95: Parameter[float]\n    \"\"\"95th percentile plasma triangularity [dimensionless].\"\"\"\n\n    delta: Parameter[float]\n    \"\"\"Last closed surface plasma triangularity [dimensionless].\"\"\"\n\n    f_bs: Parameter[float]\n    \"\"\"Bootstrap fraction [dimensionless].\"\"\"\n\n    g_vv_ts: Parameter[float]\n    \"\"\"Gap between VV and TS [meter].\"\"\"\n\n    H_star: Parameter[float]\n    \"\"\"H factor (radiation corrected) [dimensionless].\"\"\"\n\n    I_p: Parameter[float]\n    \"\"\"Plasma current [megaampere].\"\"\"\n\n    kappa_95: Parameter[float]\n    \"\"\"95th percentile plasma elongation [dimensionless].\"\"\"\n\n    kappa: Parameter[float]\n    \"\"\"Last closed surface plasma elongation [dimensionless].\"\"\"\n\n    P_bd_in: Parameter[float]\n    \"\"\"total auxiliary injected power [megawatt].\"\"\"\n\n    P_brehms: Parameter[float]\n    \"\"\"Bremsstrahlung [megawatt].\"\"\"\n\n    P_el_net_process: Parameter[float]\n    \"\"\"Net electrical power output as provided by PROCESS [megawatt].\"\"\"\n\n    P_fus_DD: Parameter[float]\n    \"\"\"D-D fusion power [megawatt].\"\"\"\n\n    P_fus_DT: Parameter[float]\n    \"\"\"D-T fusion power [megawatt].\"\"\"\n\n    P_fus: Parameter[float]\n    \"\"\"Total fusion power [megawatt].\"\"\"\n\n    P_line: Parameter[float]\n    \"\"\"Line radiation [megawatt].\"\"\"\n\n    P_rad_core: Parameter[float]\n    \"\"\"Core radiation power [megawatt].\"\"\"\n\n    P_rad_edge: Parameter[float]\n    \"\"\"Edge radiation power [megawatt].\"\"\"\n\n    P_rad: Parameter[float]\n    \"\"\"Radiation power [megawatt].\"\"\"\n\n    P_sep: Parameter[float]\n    \"\"\"Separatrix power [megawatt].\"\"\"\n\n    P_sync: Parameter[float]\n    \"\"\"Synchrotron radiation [megawatt].\"\"\"\n\n    R_0: Parameter[float]\n    \"\"\"Major radius [meter].\"\"\"\n\n    r_cp_top: Parameter[float]\n    \"\"\"Radial Position of Top of TF coil taper [meter].\"\"\"\n\n    r_cs_in: Parameter[float]\n    \"\"\"Central Solenoid inner radius [meter].\"\"\"\n\n    r_fw_ib_in: Parameter[float]\n    \"\"\"Inboard first wall inner radius [meter].\"\"\"\n\n    r_fw_ob_in: Parameter[float]\n    \"\"\"Outboard first wall inner radius [meter].\"\"\"\n\n    r_tf_in_centre: Parameter[float]\n    \"\"\"Inboard TF leg centre radius [meter].\"\"\"\n\n    r_tf_in: Parameter[float]\n    \"\"\"Inboard radius of the TF coil inboard leg [meter].\"\"\"\n\n    r_tf_out_centre: Parameter[float]\n    \"\"\"Outboard TF leg centre radius [meter].\"\"\"\n\n    r_ts_ib_in: Parameter[float]\n    \"\"\"Inboard TS inner radius [meter].\"\"\"\n\n    r_vv_ib_in: Parameter[float]\n    \"\"\"Inboard vessel inner radius [meter].\"\"\"\n\n    r_vv_ob_in: Parameter[float]\n    \"\"\"Outboard vessel inner radius [meter].\"\"\"\n\n    tau_e: Parameter[float]\n    \"\"\"Energy confinement time [second].\"\"\"\n\n    TF_currpt_ob: Parameter[float]\n    \"\"\"TF coil current per turn [ampere].\"\"\"\n\n    TF_E_stored: Parameter[float]\n    \"\"\"total stored energy in the toroidal field [gigajoule].\"\"\"\n\n    TF_res_bus: Parameter[float]\n    \"\"\"TF Bus resistance [meter].\"\"\"\n\n    TF_res_tot: Parameter[float]\n    \"\"\"Total resistance for TF coil set [ohm].\"\"\"\n\n    TF_respc_ob: Parameter[float]\n    \"\"\"TF coil leg resistance [ohm].\"\"\"\n\n    tf_wp_depth: Parameter[float]\n    \"\"\"TF coil winding pack depth (in y) [meter]. Including insulation.\"\"\"\n\n    tf_wp_width: Parameter[float]\n    \"\"\"TF coil winding pack radial width [meter]. Including insulation.\"\"\"\n\n    tk_cs: Parameter[float]\n    \"\"\"Central Solenoid radial thickness [meter].\"\"\"\n\n    tk_fw_in: Parameter[float]\n    \"\"\"Inboard first wall thickness [meter].\"\"\"\n\n    tk_fw_out: Parameter[float]\n    \"\"\"Outboard first wall thickness [meter].\"\"\"\n\n    tk_tf_inboard: Parameter[float]\n    \"\"\"TF coil inboard thickness [meter].\"\"\"\n\n    tk_tf_ins: Parameter[float]\n    \"\"\"TF coil ground insulation thickness [meter].\"\"\"\n\n    tk_tf_insgap: Parameter[float]\n    \"\"\"\n    TF coil WP insertion gap [meter]. Backfilled with epoxy resin (impregnation).\n    This is an average value; can be less or more due to manufacturing tolerances.\n    \"\"\"\n\n    tk_tf_nose: Parameter[float]\n    \"\"\"TF coil inboard nose thickness [meter].\"\"\"\n\n    v_burn: Parameter[float]\n    \"\"\"Loop voltage during burn [volt].\"\"\"\n\n    # In-out parameters\n    A: Parameter[float]\n    \"\"\"Plasma aspect ratio [dimensionless].\"\"\"\n\n    g_cs_tf: Parameter[float]\n    \"\"\"Gap between CS and TF [meter].\"\"\"\n\n    g_ts_tf: Parameter[float]\n    \"\"\"Gap between TS and TF [meter].\"\"\"\n\n    g_vv_bb: Parameter[float]\n    \"\"\"Gap between VV and BB [meter].\"\"\"\n\n    tk_bb_ib: Parameter[float]\n    \"\"\"Inboard blanket thickness [meter].\"\"\"\n\n    tk_bb_ob: Parameter[float]\n    \"\"\"Outboard blanket thickness [meter].\"\"\"\n\n    tk_sh_in: Parameter[float]\n    \"\"\"Inboard shield thickness [meter]. DO NOT USE - PROCESS has VV = VV + shield.\"\"\"\n\n    tk_sol_ib: Parameter[float]\n    \"\"\"Inboard SOL thickness [meter].\"\"\"\n\n    tk_sol_ob: Parameter[float]\n    \"\"\"Outboard SOL thickness [meter].\"\"\"\n\n    tk_ts: Parameter[float]\n    \"\"\"TS thickness [meter].\"\"\"\n\n    tk_vv_in: Parameter[float]\n    \"\"\"Inboard vacuum vessel thickness [meter].\"\"\"\n\n    # Other parameters\n    B_tf_peak: Parameter[float]\n    \"\"\"Peak field inside the TF coil winding pack [tesla].\"\"\"\n\n    f_ni: Parameter[float]\n    \"\"\"Non-inductive current drive fraction [dimensionless].\"\"\"\n\n    h_cp_top: Parameter[float]\n    \"\"\"Height of the TF coil inboard Tapered section end [meter].\"\"\"\n\n    h_tf_max_in: Parameter[float]\n    \"\"\"Plasma side TF coil maximum height [meter].\"\"\"\n\n    l_i: Parameter[float]\n    \"\"\"Normalised internal plasma inductance [dimensionless].\"\"\"\n\n    q_95: Parameter[float]\n    \"\"\"Plasma safety factor [dimensionless].\"\"\"\n\n    r_tf_inboard_out: Parameter[float]\n    \"\"\"Outboard Radius of the TF coil inboard leg tapered region [meter].\"\"\"\n\n    sigma_tf_case_max: Parameter[float]\n    \"\"\"Maximum von Mises stress in the TF coil case nose [pascal].\"\"\"\n\n    sigma_tf_wp_max: Parameter[float]\n    \"\"\"Maximum von Mises stress in the TF coil winding pack nose [pascal].\"\"\"\n\n    T_e: Parameter[float]\n    \"\"\"Average plasma electron temperature [kiloelectron_volt].\"\"\"\n\n    tau_flattop: Parameter[float]\n    \"\"\"Flat-top duration [second].\"\"\"\n\n    tk_tf_outboard: Parameter[float]\n    \"\"\"TF coil outboard thickness [meter].\"\"\"\n\n    V_p: Parameter[float]\n    \"\"\"Plasma volume [meter ** 3].\"\"\"\n\n    Z_eff: Parameter[float]\n    \"\"\"Effective particle radiation atomic mass [unified_atomic_mass_unit].\"\"\"\n\n    _mappings = deepcopy(mappings)\n    _defaults = ProcessInputs()\n\n    @property\n    def mappings(self) -> Dict[str, ParameterMapping]:\n        \"\"\"Define mappings between these parameters and PROCESS's.\"\"\"\n        return self._mappings\n\n    @property\n    def defaults(self) -> Dict[str, Union[float, List, Dict]]:\n        \"\"\"\n        Default values for Process\n        \"\"\"\n        return self._defaults.to_dict()\n\n    @property\n    def template_defaults(self) -> Dict[str, _INVariable]:\n        \"\"\"\n        Template defaults for process\n        \"\"\"\n        return self._defaults.to_invariable()\n\n    @classmethod\n    def from_defaults(cls) -> MappedParameterFrame:\n        \"\"\"\n        Initialise from defaults\n        \"\"\"\n        return super().from_defaults(cls._defaults.to_dict())",
  "def mappings(self) -> Dict[str, ParameterMapping]:\n        \"\"\"Define mappings between these parameters and PROCESS's.\"\"\"\n        return self._mappings",
  "def defaults(self) -> Dict[str, Union[float, List, Dict]]:\n        \"\"\"\n        Default values for Process\n        \"\"\"\n        return self._defaults.to_dict()",
  "def template_defaults(self) -> Dict[str, _INVariable]:\n        \"\"\"\n        Template defaults for process\n        \"\"\"\n        return self._defaults.to_invariable()",
  "def from_defaults(cls) -> MappedParameterFrame:\n        \"\"\"\n        Initialise from defaults\n        \"\"\"\n        return super().from_defaults(cls._defaults.to_dict())",
  "class HomogenisedMixture(SerialisedMaterial, nmm.MultiMaterial):\n    \"\"\"\n    Inherits and does some dropping of 0 fractions (avoid touching nmm)\n    \"\"\"\n\n    materials: Dict[str, float]\n    temperature_in_K: float  # noqa :N815\n    enrichment: float\n\n    default_temperature = T_DEFAULT\n    _material_classes = []\n\n    def __init__(\n        self,\n        name: str,\n        materials: Dict[str, float],\n        temperature_in_K: Optional[float] = None,  # noqa :N803\n        enrichment: Optional[float] = None,\n        zaid_suffix: Optional[str] = None,\n        material_id: Optional[str] = None,\n    ):\n        if temperature_in_K is None:\n            temperature_in_K = self.default_temperature  # noqa :N803\n\n        mats = []\n        for mat in materials.keys():\n            mat.temperature = temperature_in_K\n            if \"enrichment\" in mat.__class__.__annotations__:\n                mat.enrichment = enrichment\n            mats += [mat]\n\n        super().__init__(\n            material_tag=name,\n            materials=mats,\n            fracs=list(materials.values()),\n            percent_type=\"vo\",\n            temperature_in_K=temperature_in_K,\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n        )\n\n        self.name = name\n\n    def __str__(self) -> str:\n        \"\"\"\n        Get the name of the mixture.\n        \"\"\"\n        return self.name\n\n    def _calc_homogenised_property(self, prop: str, temperature: float):\n        \"\"\"\n        Calculate an mass-fraction-averaged property for the homogenised mixture.\n        \"\"\"\n        warn = []\n        values, fractions = [], []\n        # Calculate property mixtures, ignoring liquids and voids\n        # for certain properties\n        for mat, vf in zip(self.materials, self.fracs):\n            try:\n                v = getattr(mat, prop)(temperature)\n                values.append(v)\n                fractions.append(vf)\n            except (NotImplementedError, AttributeError, MaterialsError):\n                warn.append([mat, prop])\n\n        f = np.array(fractions) / sum(fractions)  # Normalised\n        value = np.dot(values, f)\n\n        if warn:\n            txt = (\n                f\"Materials::{self.__class__.__name__}: The following \"\n                + \"mat.prop calls failed:\\n\"\n            )\n            for w in warn:\n                txt += f\"{w[0]}: {w[1]}\" + \"\\n\"\n            bluemira_warn(txt)\n\n        return value\n\n    def E(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Young's modulus.\n\n        Parameters\n        ----------\n        temperature:\n            The optional temperature [K].\n\n        Returns\n        -------\n        The Young's modulus of the material at the given temperature.\n        \"\"\"\n        return self._calc_homogenised_property(\"E\", temperature)\n\n    def mu(self, temperature: float) -> float:\n        \"\"\"\n        Poisson's ratio.\n\n        Parameters\n        ----------\n        temperature:\n            The optional temperature [K].\n\n        Returns\n        -------\n        Poisson's ratio for the material at the given temperature.\n        \"\"\"\n        return self._calc_homogenised_property(\"mu\", temperature)\n\n    def CTE(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Mean coefficient of thermal expansion in 10**-6/T\n\n        Parameters\n        ----------\n        temperature:\n            The temperature in Kelvin\n\n        Returns\n        -------\n        Mean coefficient of thermal expansion in 10**-6/T at the given temperature.\n        \"\"\"\n        return self._calc_homogenised_property(\"CTE\", temperature)\n\n    def rho(self, temperature: float) -> float:\n        \"\"\"\n        Density.\n\n        Parameters\n        ----------\n        temperature:\n            The optional temperature [K].\n\n        Returns\n        -------\n        The density of the material at the given temperature.\n        \"\"\"\n        return self._calc_homogenised_property(\"rho\", temperature)\n\n    def Sy(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Minimum yield stress in MPa\n\n        Parameters\n        ----------\n        temperature:\n            The temperature in Kelvin\n\n        Returns\n        -------\n        Minimum yield stress in MPa at the given temperature.\n        \"\"\"\n        return self._calc_homogenised_property(\"Sy\", temperature)\n\n    @classmethod\n    def from_dict(\n        cls, name: str, material_dict: Dict[str, Any], material_cache: MaterialCache\n    ) -> SerialisedMaterial:\n        \"\"\"\n        Generate an instance of the mixture from a dictionary of materials.\n\n        Parameters\n        ----------\n        name:\n            The name of the mixture\n        materials_dict:\n            The dictionary defining this and any additional mixtures\n        material_cache:\n            The cache to load the constituent materials from\n\n        Returns\n        -------\n        The mixture\n        \"\"\"\n        mat_dict = copy.deepcopy(material_dict[name])\n        if \"materials\" not in material_dict[name].keys():\n            raise MaterialsError(\"Mixture must define constituent materials.\")\n\n        for mat in material_dict[name][\"materials\"]:\n            if isinstance(mat, str):\n                del mat_dict[\"materials\"][mat]\n                material_inst = material_cache.get_material(mat, False)\n                material_value = material_dict[name][\"materials\"][mat]\n                mat_dict[\"materials\"][material_inst] = material_value\n\n        return super().from_dict(name, {name: mat_dict})",
  "def __init__(\n        self,\n        name: str,\n        materials: Dict[str, float],\n        temperature_in_K: Optional[float] = None,  # noqa :N803\n        enrichment: Optional[float] = None,\n        zaid_suffix: Optional[str] = None,\n        material_id: Optional[str] = None,\n    ):\n        if temperature_in_K is None:\n            temperature_in_K = self.default_temperature  # noqa :N803\n\n        mats = []\n        for mat in materials.keys():\n            mat.temperature = temperature_in_K\n            if \"enrichment\" in mat.__class__.__annotations__:\n                mat.enrichment = enrichment\n            mats += [mat]\n\n        super().__init__(\n            material_tag=name,\n            materials=mats,\n            fracs=list(materials.values()),\n            percent_type=\"vo\",\n            temperature_in_K=temperature_in_K,\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n        )\n\n        self.name = name",
  "def __str__(self) -> str:\n        \"\"\"\n        Get the name of the mixture.\n        \"\"\"\n        return self.name",
  "def _calc_homogenised_property(self, prop: str, temperature: float):\n        \"\"\"\n        Calculate an mass-fraction-averaged property for the homogenised mixture.\n        \"\"\"\n        warn = []\n        values, fractions = [], []\n        # Calculate property mixtures, ignoring liquids and voids\n        # for certain properties\n        for mat, vf in zip(self.materials, self.fracs):\n            try:\n                v = getattr(mat, prop)(temperature)\n                values.append(v)\n                fractions.append(vf)\n            except (NotImplementedError, AttributeError, MaterialsError):\n                warn.append([mat, prop])\n\n        f = np.array(fractions) / sum(fractions)  # Normalised\n        value = np.dot(values, f)\n\n        if warn:\n            txt = (\n                f\"Materials::{self.__class__.__name__}: The following \"\n                + \"mat.prop calls failed:\\n\"\n            )\n            for w in warn:\n                txt += f\"{w[0]}: {w[1]}\" + \"\\n\"\n            bluemira_warn(txt)\n\n        return value",
  "def E(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Young's modulus.\n\n        Parameters\n        ----------\n        temperature:\n            The optional temperature [K].\n\n        Returns\n        -------\n        The Young's modulus of the material at the given temperature.\n        \"\"\"\n        return self._calc_homogenised_property(\"E\", temperature)",
  "def mu(self, temperature: float) -> float:\n        \"\"\"\n        Poisson's ratio.\n\n        Parameters\n        ----------\n        temperature:\n            The optional temperature [K].\n\n        Returns\n        -------\n        Poisson's ratio for the material at the given temperature.\n        \"\"\"\n        return self._calc_homogenised_property(\"mu\", temperature)",
  "def CTE(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Mean coefficient of thermal expansion in 10**-6/T\n\n        Parameters\n        ----------\n        temperature:\n            The temperature in Kelvin\n\n        Returns\n        -------\n        Mean coefficient of thermal expansion in 10**-6/T at the given temperature.\n        \"\"\"\n        return self._calc_homogenised_property(\"CTE\", temperature)",
  "def rho(self, temperature: float) -> float:\n        \"\"\"\n        Density.\n\n        Parameters\n        ----------\n        temperature:\n            The optional temperature [K].\n\n        Returns\n        -------\n        The density of the material at the given temperature.\n        \"\"\"\n        return self._calc_homogenised_property(\"rho\", temperature)",
  "def Sy(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Minimum yield stress in MPa\n\n        Parameters\n        ----------\n        temperature:\n            The temperature in Kelvin\n\n        Returns\n        -------\n        Minimum yield stress in MPa at the given temperature.\n        \"\"\"\n        return self._calc_homogenised_property(\"Sy\", temperature)",
  "def from_dict(\n        cls, name: str, material_dict: Dict[str, Any], material_cache: MaterialCache\n    ) -> SerialisedMaterial:\n        \"\"\"\n        Generate an instance of the mixture from a dictionary of materials.\n\n        Parameters\n        ----------\n        name:\n            The name of the mixture\n        materials_dict:\n            The dictionary defining this and any additional mixtures\n        material_cache:\n            The cache to load the constituent materials from\n\n        Returns\n        -------\n        The mixture\n        \"\"\"\n        mat_dict = copy.deepcopy(material_dict[name])\n        if \"materials\" not in material_dict[name].keys():\n            raise MaterialsError(\"Mixture must define constituent materials.\")\n\n        for mat in material_dict[name][\"materials\"]:\n            if isinstance(mat, str):\n                del mat_dict[\"materials\"][mat]\n                material_inst = material_cache.get_material(mat, False)\n                material_value = material_dict[name][\"materials\"][mat]\n                mat_dict[\"materials\"][material_inst] = material_value\n\n        return super().from_dict(name, {name: mat_dict})",
  "def matproperty(t_min: float, t_max: float):\n    \"\"\"\n    Material property decorator object.\n\n    Checks that input T vector is within bounds. Handles floats and arrays.\n    \"\"\"\n\n    def decorator(f):\n        def wrapper(*args, **kwargs):\n            temperatures = list_array(args[1])\n\n            if not (temperatures <= t_max).all():\n                raise ValueError(\n                    \"Material property not valid outside of tempe\"\n                    f\"rature range: {temperatures} > T_max = {t_max}\"\n                )\n            if not (temperatures >= t_min).all():\n                raise ValueError(\n                    \"Material property not valid outside of tempe\"\n                    f\"rature range: {temperatures} < T_min = {t_min}\"\n                )\n            temperatures = array_or_num(temperatures)\n            return f(args[0], temperatures, **kwargs)\n\n        return wrapper\n\n    return decorator",
  "def _raise_error():\n    raise NotImplementedError(\n        \"This Material has not yet been given this property. Please add it.\"\n    )",
  "def _try_calc_property(mat, prop_name, *args, **kwargs):\n    if not hasattr(mat, prop_name):\n        raise MaterialsError(\n            f\"Property {prop_name} does not exist for material {mat.name}\"\n        )\n\n    if getattr(mat, prop_name) is not None:\n        return getattr(mat, prop_name)(*args, **kwargs)\n    else:\n        raise MaterialsError(\n            f\"Property {prop_name} has not been defined for material {mat.name}\"\n        )",
  "class MaterialProperty:\n    \"\"\"\n    Defines a property of a material within a valid temperature range.\n\n    Parameters\n    ----------\n    value:\n        If supplied as a string then this will define a temperature-, pressure-, and/or\n        eps_vol-dependent calculation to be evaluated when the property is retrieved,\n        otherwise it will define a constant value.\n    temp_max_kelvin:\n        The maximum temperature [K] at which the property is valid. If not provided\n        and no temp_max_celsius then all temperatures above 0K are valid.\n    temp_min_kelvin:\n        The maximum temperature [K] at which the property is valid. If not\n        provided and no temp_min_celsius then properties will be valid down to 0K.\n    temp_max_celsius:\n        The maximum temperature [\u00b0C] at which the property is valid. If not provided\n        and no temp_max_kelvin then all temperatures above 0K are valid.\n    temp_min_celsius:\n        The optional maximum temperature [\u00b0C] at which the property is valid. If not\n        provided and no temp_min_kelvin then properties will be valid down to 0K.\n    reference:\n        The optional reference e.g. paper/database/website for the property.\n    \"\"\"\n\n    def __init__(\n        self,\n        value: Union[float, str],\n        temp_max_kelvin: Optional[float] = None,\n        temp_min_kelvin: Optional[float] = None,\n        temp_max_celsius: Optional[float] = None,\n        temp_min_celsius: Optional[float] = None,\n        reference: Optional[str] = None,\n    ):\n        if (temp_max_kelvin is not None or temp_min_kelvin is not None) and (\n            temp_max_celsius is not None or temp_min_celsius is not None\n        ):\n            raise MaterialsError(\n                \"Material property temperature ranges must be set by either K or C, not both.\"\n            )\n\n        self.value = value\n        self.reference = reference\n\n        self.temp_max = None\n        if temp_max_kelvin is not None:\n            self.temp_max = temp_max_kelvin\n        elif temp_max_celsius is not None:\n            self.temp_max = to_kelvin(temp_max_celsius)\n\n        self.temp_min = None\n        if temp_min_kelvin is not None:\n            self.temp_min = temp_min_kelvin\n        elif temp_min_celsius is not None:\n            self.temp_min = to_kelvin(temp_min_celsius)\n\n    def __call__(\n        self,\n        temperature: float,\n        pressure: Optional[float] = None,\n        eps_vol: Optional[float] = None,\n    ) -> float:\n        \"\"\"\n        Evaluates the property at a given temperature, pressure, and/or eps_vol.\n\n        Parameters\n        ----------\n        temperature:\n            The temperature [K].\n        pressure:\n            The optional pressure [Pa].\n        esp_vol:\n            The optional cell volume [m^3].\n\n        Returns\n        -------\n        The property evaluated at the given temperature, pressure, and/or eps_vol.\n        \"\"\"\n        if isinstance(self.value, str):\n            aeval = asteval.Interpreter(usersyms=asteval_user_symbols)\n            temperature = list_array(temperature)\n            self._validate_temperature(temperature)\n            aeval.symtable[\"temperature\"] = temperature\n            aeval.symtable[\"temperature_in_K\"] = temperature\n            aeval.symtable[\"temperature_in_C\"] = to_celsius(temperature)\n\n            if pressure is not None:\n                aeval.symtable[\"pressure\"] = pressure\n                aeval.symtable[\"pressure_in_Pa\"] = pressure\n\n            if eps_vol is not None:\n                aeval.symtable[\"eps_vol\"] = eps_vol\n            else:\n                aeval.symtable[\"eps_vol\"] = 0.0\n\n            prop_val = aeval.eval(self.value)\n            prop_val = array_or_num(prop_val)\n\n            if len(aeval.error) > 0:\n                raise aeval.error[0].exc(aeval.error[0].msg)\n\n            return prop_val\n        else:\n            self._validate_temperature(temperature)\n            return self.value\n\n    @classmethod\n    def deserialise(cls, prop_rep: Union[Dict[str, Any], float, str]):\n        \"\"\"\n        Deserialise the provided property representation.\n\n        Parameters\n        ----------\n        prop_rep:\n            The representation of the property. Can be just the value that the property\n            defines, or can be a dictionary containing the value and any of the optional\n            properties.\n\n        Returns\n        -------\n        The `MaterialProperty` corresponding to the provided representation.\n        \"\"\"\n        if isinstance(prop_rep, dict):\n            return cls(**prop_rep)\n        else:\n            return cls(value=prop_rep)\n\n    def serialise(self):\n        \"\"\"\n        Serialise the material property to a value or dictionary.\n\n        Returns\n        -------\n        serialised_prop: Union[Dict[str, Any], float, str]\n            The serialised representation of the property. Represented by a dictionary\n            mapping attributes to their values, if more attributes than the value are\n            defined, otherwise just returns the value.\n        \"\"\"\n        if self.temp_max is None and self.temp_min is None and self.reference is None:\n            return self.value\n        else:\n            prop_dict = {\"value\": self.value}\n            if self.temp_max is not None:\n                prop_dict[\"temp_max_kelvin\"] = self.temp_max\n            if self.temp_min is not None:\n                prop_dict[\"temp_min_kelvin\"] = self.temp_min\n            if self.reference is not None:\n                prop_dict[\"reference\"] = self.reference\n            return prop_dict\n\n    def _validate_temperature(self, temperature: Union[float, List[float], np.ndarray]):\n        \"\"\"\n        Check that the property is valid for the requested temperature range.\n\n        Parameters\n        ----------\n        temperature:\n            The temperatures requested to value the property at.\n\n        Raises\n        ------\n        ValueError\n            If any of the requested temperatures are outside of the valid range\n        \"\"\"\n        temperatures = list_array(temperature)\n        if self.temp_min is not None and (temperatures < self.temp_min).any():\n            raise ValueError(\n                \"Material property not valid outside of temperature range: \"\n                f\"{temperatures} < T_min = {self.temp_min}\"\n            )\n        if self.temp_max is not None and (temperatures > self.temp_max).any():\n            raise ValueError(\n                \"Material property not valid outside of temperature range: \"\n                f\"{temperature} > T_max = {self.temp_max}\"\n            )",
  "class SerialisedMaterial:\n    \"\"\"\n    A mix-in class to make a material serialisable.\n\n    The class must provide attributes to be serialised as annotations.\n    \"\"\"\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Get a dictionary representation of the material.\n\n        Returns\n        -------\n        The dictionary representation of the material.\n        \"\"\"\n        attr_dict = {}\n        for attr in [attr for attr in self.__annotations__.keys() if attr != \"name\"]:\n            attr_val = getattr(self, attr, None)\n            if attr_val is not None:\n                if isinstance(attr_val, MaterialProperty):\n                    attr_dict[attr] = attr_val.serialise()\n                else:\n                    attr_dict[attr] = attr_val\n        mat_dict = {self.name: attr_dict}\n        return mat_dict\n\n    @classmethod\n    def from_dict(cls, name: str, materials_dict: Dict[str, Any]):\n        \"\"\"\n        Generate an instance of the material from a dictionary of materials.\n\n        Returns\n        -------\n        material : SerialisedMaterial\n            The material.\n        \"\"\"\n        mat_dict = materials_dict[name]\n        type_hints = get_type_hints(cls)\n        for attr_name, attr_type in type_hints.items():\n            if (\n                attr_name in mat_dict\n                and not hasattr(attr_type, \"__origin__\")\n                and issubclass(attr_type, MaterialProperty)\n            ):\n                mat_dict[attr_name] = attr_type.deserialise(mat_dict[attr_name])\n        return cls(name, **mat_dict)\n\n    def to_json(self, **kwargs) -> str:\n        \"\"\"\n        Get a JSON representation of the material.\n\n        Parameters\n        ----------\n        kwargs:\n            passed to json writer\n\n        Returns\n        -------\n        The JSON representation of the material.\n        \"\"\"\n        mat_dict = self.to_dict()\n        mat_dict[self.name][\"material_class\"] = self.__class__.__name__\n        return json_writer(mat_dict, return_output=True, **kwargs)\n\n    @classmethod\n    def from_json(cls, data: str) -> str:\n        \"\"\"\n        Generate an instance of the material from JSON.\n\n        Returns\n        -------\n        The JSON representation of the material.\n        \"\"\"\n        mat_dict = json.loads(data)\n        mat_name = list(mat_dict.keys())[0]\n        return cls.from_dict(mat_name, mat_dict)\n\n    def __hash__(self) -> int:\n        \"\"\"\n        Hash the material by it's name.\n\n        Returns\n        -------\n        The hashed material name\n        \"\"\"\n        return hash(self.name)\n\n    def __eq__(self, other) -> bool:\n        \"\"\"\n        Two materials are equal if their attributes have the same values.\n\n        Returns\n        -------\n        True if the two materials have the same attribute values, else false.\n        \"\"\"\n        return self.to_dict() == other.to_dict()\n\n    def __neq__(self, other) -> bool:\n        \"\"\"\n        Two materials are not equal if their attributes have different values.\n\n        Returns\n        -------\n        True if the two materials have different attribute values, else false.\n        \"\"\"\n        return self != other",
  "class Void(SerialisedMaterial, nmm.Material):\n    \"\"\"\n    Void material class.\n\n    Parameters\n    ----------\n    name:\n        The material's name.\n    temperature_in_K:\n        The temperature [K].\n    zaid_suffix:\n        The nuclear library to apply to the zaid, for example \".31c\", this is used in\n        MCNP and Serpent material cards.\n    material_id:\n        The id number or mat number used in the MCNP and OpenMC material cards.\n    \"\"\"\n\n    name: str\n    temperature_in_K: float  # noqa :N815\n    zaid_suffix: str\n    material_id: str\n\n    def __init__(\n        self,\n        name: str,\n        temperature_in_K: float = T_DEFAULT,  # noqa :N803\n        zaid_suffix: Optional[str] = None,\n        material_id: Optional[str] = None,\n    ):\n        super().__init__(\n            material_tag=name,\n            density=1,\n            density_unit=\"atom/cm3\",\n            elements={\"H\": 1},\n            percent_type=\"ao\",\n            temperature_in_K=temperature_in_K,\n            temperature_in_C=to_celsius(temperature_in_K),\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n        )\n\n        self.name = name\n\n    def __str__(self) -> str:\n        \"\"\"\n        Get a string representation of the Void.\n        \"\"\"\n        return self.name\n\n    def E(self, temperature: Optional[float] = None) -> float:  # noqa :N802\n        \"\"\"\n        Young's modulus.\n\n        Parameters\n        ----------\n        temperature:\n            The optional temperature [K].\n\n        Returns\n        -------\n        The Young's modulus of the material at the given temperature.\n        \"\"\"\n        return 0.0\n\n    def mu(self, temperature: Optional[float] = None) -> float:\n        \"\"\"\n        Poisson's ratio.\n\n        Parameters\n        ----------\n        temperature:\n            The optional temperature [K].\n\n        Returns\n        -------\n        Poisson's ratio for the material at the given temperature.\n        \"\"\"\n        return 0.0\n\n    def rho(self, temperature: Optional[float] = None) -> float:  # noqa :N802\n        \"\"\"\n        Density.\n\n        Parameters\n        ----------\n        temperature:\n            The optional temperature [K].\n\n        Returns\n        -------\n        The density of the material at the given temperature.\n        \"\"\"\n        return 0.0",
  "class MassFractionMaterial(SerialisedMaterial, nmm.Material):\n    \"\"\"\n    Mass fraction material\n\n    Parameters\n    ----------\n    name:\n        The material's name.\n    elements:\n        The constituent elements and their corresponding mass fractions.\n    density:\n        The density. If supplied as a string then this will define a\n        temperature-dependent calculation, otherwise it will define a constant value.\n    density_unit:\n        The unit that the density is supplied in, may be any one of kg/m3, g/cm3, g/cc,\n        by default kg/m3.\n    temperature_in_K:\n        The temperature [K].\n    zaid_suffix:\n        The nuclear library to apply to the zaid, for example \".31c\", this is used in\n        MCNP and Serpent material cards.\n    material_id:\n        The id number or mat number used in the MCNP and OpenMC material cards.\n    poissons_ratio:\n        Poisson's ratio. If supplied as a string then this will define a\n        temperature-dependent calculation, otherwise it will define a constant value.\n    thermal_conductivity:\n        Thermal conductivity [W.m/K]. If supplied as a string then this will define a\n        temperature-dependent calculation, otherwise it will define a constant value.\n    youngs_modulus:\n        Young's modulus [GPa]. If supplied as a string then this will define a\n        temperature-dependent calculation, otherwise it will define a constant value.\n    specific_heat:\n        Specific heat [J/kg/K]. If supplied as a string then this will define a\n        temperature-dependent calculation, otherwise it will define a constant value.\n    coefficient_thermal_expansion:\n        CTE [10^-6/T]. If supplied as a string then this will define a\n        temperature-dependent calculation, otherwise it will define a constant value.\n    electrical_resistivity:\n        Electrical resistivity [(10^-8)Ohm.m]. If supplied as a string then this will\n        define a temperature-dependent calculation, otherwise it will define a constant\n        value.\n    magnetic_saturation:\n        Magnetic saturation [Am^2/kg]. If supplied as a string then this will define a\n        temperature-dependent calculation, otherwise it will define a constant value.\n    viscous_remanent_magnetisation:\n        Viscous remanent magnetisation [Am^2/kg]. If supplied as a string then this will\n        define a temperature-dependent calculation, otherwise it will define a constant\n        value.\n    coercive_field:\n        Coercive field [A/m]. If supplied as a string then this will define a\n        temperature-dependent calculation, otherwise it will define a constant value.\n    minimum_yield_stress:\n        Minimum yield stress [MPa]. If supplied as a string then this will define a\n        temperature-dependent calculation, otherwise it will define a constant value.\n    average_yield_stress:\n        Average yield stress [MPa]. If supplied as a string then this will define a\n        temperature-dependent calculation, otherwise it will define a constant value.\n    minimum_ultimate_tensile_stress:\n        Minimum ultimate tensile stress [MPa]. If supplied as a string then this will\n        define a temperature-dependent calculation, otherwise it will define a constant\n        value.\n    average_ultimate_tensile_stress:\n        Average ultimate tensile stress [MPa]. If supplied as a string then this will\n        define a temperature-dependent calculation, otherwise it will define a constant\n        value.\n    \"\"\"\n\n    # Properties to interface with neutronics material maker\n    name: str\n    elements: Dict[str, float]\n    density: MaterialProperty\n    density_unit: str\n    temperature_in_K: float  # noqa :N815\n    zaid_suffix: str\n    material_id: str\n\n    # Engineering properties\n    poissons_ratio: MaterialProperty\n    thermal_conductivity: MaterialProperty\n    youngs_modulus: MaterialProperty\n    specific_heat: MaterialProperty\n    coefficient_thermal_expansion: MaterialProperty\n    electrical_resistivity: MaterialProperty\n    magnetic_saturation: MaterialProperty\n    viscous_remanent_magnetisation: MaterialProperty\n    coercive_field: MaterialProperty\n    minimum_yield_stress: MaterialProperty\n    average_yield_stress: MaterialProperty\n    minimum_ultimate_tensile_stress: MaterialProperty\n    average_ultimate_tensile_stress: MaterialProperty\n\n    def __init__(\n        self,\n        name: str,\n        elements: Dict[str, float],\n        density: Optional[MaterialProperty] = None,\n        density_unit: str = \"kg/m3\",\n        temperature_in_K: float = T_DEFAULT,  # noqa :N803\n        zaid_suffix: Optional[str] = None,\n        material_id: Optional[float] = None,\n        poissons_ratio: Optional[MaterialProperty] = None,\n        thermal_conductivity: Optional[MaterialProperty] = None,\n        youngs_modulus: Optional[MaterialProperty] = None,\n        specific_heat: Optional[MaterialProperty] = None,\n        coefficient_thermal_expansion: Optional[MaterialProperty] = None,\n        electrical_resistivity: Optional[MaterialProperty] = None,\n        magnetic_saturation: Optional[MaterialProperty] = None,\n        viscous_remanent_magnetisation: Optional[MaterialProperty] = None,\n        coercive_field: Optional[MaterialProperty] = None,\n        minimum_yield_stress: Optional[MaterialProperty] = None,\n        average_yield_stress: Optional[MaterialProperty] = None,\n        minimum_ultimate_tensile_stress: Optional[MaterialProperty] = None,\n        average_ultimate_tensile_stress: Optional[MaterialProperty] = None,\n    ):\n        if density is None:\n            raise MaterialsError(\"No density (value or T-function) specified.\")\n\n        if density_unit not in [\"kg/m3\", \"g/cm3\", \"g/cc\"]:\n            raise MaterialsError(\"Density unit must be one of kg/m3, g/cm3, or g/cc\")\n\n        if isinstance(density.value, (int, float)):\n            density_val = density.value\n            density_equation = None\n        else:\n            density_val = None\n            density_equation = density.value\n\n        super().__init__(\n            material_tag=name,\n            elements=elements,\n            density=density_val,\n            density_equation=density_equation,\n            density_unit=density_unit,\n            percent_type=\"wo\",\n            temperature_in_K=temperature_in_K,\n            temperature_in_C=to_celsius(temperature_in_K),\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n        )\n\n        self.name = name\n\n        self.density_prop = density\n        self.poissons_ratio = poissons_ratio\n        self.thermal_conductivity = thermal_conductivity\n        self.youngs_modulus = youngs_modulus\n        self.specific_heat = specific_heat\n        self.coefficient_thermal_expansion = coefficient_thermal_expansion\n        self.electrical_resistivity = electrical_resistivity\n        self.magnetic_saturation = magnetic_saturation\n        self.viscous_remanent_magnetisation = viscous_remanent_magnetisation\n        self.coercive_field = coercive_field\n        self.minimum_yield_stress = minimum_yield_stress\n        self.average_yield_stress = average_yield_stress\n        self.minimum_ultimate_tensile_stress = minimum_ultimate_tensile_stress\n        self.average_ultimate_tensile_stress = average_ultimate_tensile_stress\n\n        if self.density is None:\n            self.density = _try_calc_property(self, \"density_prop\", temperature_in_K)\n\n    def __str__(self) -> str:\n        \"\"\"\n        Get a string representation of the MfMaterial.\n        \"\"\"\n        return self.name\n\n    def mu(self, temperature: float) -> float:\n        \"\"\"\n        Poisson's ratio\n        \"\"\"\n        return _try_calc_property(self, \"poissons_ratio\", temperature)\n\n    def k(self, temperature: float) -> float:\n        \"\"\"\n        Thermal conductivity in W.m/K\n        \"\"\"\n        return _try_calc_property(self, \"thermal_conductivity\", temperature)\n\n    def E(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Young's modulus in GPa\n        \"\"\"\n        return _try_calc_property(self, \"youngs_modulus\", temperature)\n\n    def Cp(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Specific heat in J/kg/K\n        \"\"\"\n        return _try_calc_property(self, \"specific_heat\", temperature)\n\n    def CTE(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Mean coefficient of thermal expansion in 10**-6/T\n        \"\"\"\n        return _try_calc_property(self, \"coefficient_thermal_expansion\", temperature)\n\n    def rho(self, temperature: float) -> float:\n        \"\"\"\n        Mass density in kg/m**3\n        \"\"\"\n        density = _try_calc_property(self, \"density_prop\", temperature)\n\n        if self.density_unit in [\"g/cm3\", \"g/cc\"]:\n            density = gcm3_to_kgm3(density)\n\n        return density\n\n    def erho(self, temperature: float) -> float:\n        \"\"\"\n        Electrical resistivity in 10^(-8)Ohm.m\n        \"\"\"\n        return _try_calc_property(self, \"electrical_resistivity\", temperature)\n\n    def Ms(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Magnetic saturation in Am^2/kg\n        \"\"\"\n        return _try_calc_property(self, \"magnetic_saturation\", temperature)\n\n    def Mt(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Viscous remanent magnetisation in Am^2/kg\n        \"\"\"\n        return _try_calc_property(self, \"viscous_remanent_magnetisation\", temperature)\n\n    def Hc(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Coercive field in A/m\n        \"\"\"\n        return _try_calc_property(self, \"coercive_field\", temperature)\n\n    def Sy(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Minimum yield stress in MPa\n        \"\"\"\n        return _try_calc_property(self, \"minimum_yield_stress\", temperature)\n\n    def Syavg(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Average yield stress in MPa\n        \"\"\"\n        return _try_calc_property(self, \"average_yield_stress\", temperature)\n\n    def Su(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Minimum ultimate tensile stress in MPa\n        \"\"\"\n        return _try_calc_property(self, \"minimum_ultimate_tensile_stress\", temperature)\n\n    def Suavg(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Average ultimate tensile stress in MPa\n        \"\"\"\n        return _try_calc_property(self, \"average_ultimate_tensile_stress\", temperature)\n\n    @property\n    def temperature(self) -> float:\n        \"\"\"\n        Temperature: this is a pythonic property, but not an actual material\n        property!\n\n        Returns\n        -------\n        The temperature in Kelvin\n        \"\"\"\n        return self.temperature_in_K\n\n    @temperature.setter\n    def temperature(self, value: float):\n        \"\"\"\n        Sets the temperature of the material\n\n        Parameters\n        ----------\n        value:\n            The temperature in Kelvin\n        \"\"\"\n        try:\n            self.density = self.rho(value)\n        except NotImplementedError:\n            pass\n        self.temperature_in_K = value\n        self.temperature_in_C = to_celsius(value)",
  "class Superconductor:\n    \"\"\"\n    Presently gratuitous use of multiple inheritance to convey plot function\n    and avoid repetition. In future perhaps also a useful thing.\n    \"\"\"\n\n    def plot(\n        self,\n        b_min: float,\n        b_max: float,\n        t_min: float,\n        t_max: float,\n        eps: Optional[float] = None,\n        n: int = 101,\n        m: int = 100,\n    ):\n        \"\"\"\n        Plots superconducting surface parameterisation\n        strain `eps` only used for Nb3Sn\n        \"\"\"\n        jc = np.zeros([m, n])\n        fields = np.linspace(b_min, b_max, n)\n        temperatures = np.linspace(t_min, t_max, m)\n        for j, b in enumerate(fields):\n            for i, t in enumerate(temperatures):\n                args = (b, t, eps) if eps else (b, t)\n                jc[i, j] = self.Jc(*args)\n        fig = plt.figure()\n        fields, temperatures = np.meshgrid(fields, temperatures)\n        ax = fig.add_subplot(111, projection=\"3d\")\n        ax.set_title(self.name)\n        ax.set_xlabel(\"B [T]\")\n        ax.set_ylabel(\"T [K]\")\n        ax.set_zlabel(\"$j_{c}$ [A/mm^2]\")\n        ax.plot_surface(fields, temperatures, jc, cmap=plt.cm.viridis)\n        ax.view_init(30, 45)\n\n    def Jc(self):  # noqa :N802\n        _raise_error()\n\n    @staticmethod\n    def _handle_ij(number):\n        \"\"\"\n        Takes the real part of the imaginary number that results from the\n        exponentiation of a negative number with a fraction.\n        \"\"\"\n        return number.real",
  "class NbTiSuperconductor(MassFractionMaterial, Superconductor):\n    \"\"\"\n    Niobium-Titanium superconductor class.\n    \"\"\"\n\n    __annotations__ = MassFractionMaterial.__annotations__.copy()\n    c_0: float\n    bc_20: float\n    tc_0: float\n    alpha: float\n    beta: float\n    gamma: float\n\n    def __init__(\n        self,\n        name,\n        elements,\n        c_0=None,\n        bc_20=None,\n        tc_0=None,\n        alpha=None,\n        beta=None,\n        gamma=None,\n        density=None,\n        density_unit=\"kg/m3\",\n        temperature_in_K=T_DEFAULT,  # noqa :N803\n        zaid_suffix=None,\n        material_id=None,\n        poissons_ratio=None,\n        thermal_conductivity=None,\n        youngs_modulus=None,\n        specific_heat=None,\n        coefficient_thermal_expansion=None,\n        electrical_resistivity=None,\n        magnetic_saturation=None,\n        viscous_remanent_magnetisation=None,\n        coercive_field=None,\n        minimum_yield_stress=None,\n        average_yield_stress=None,\n        minimum_ultimate_tensile_stress=None,\n        average_ultimate_tensile_stress=None,\n    ):\n        super().__init__(\n            name=name,\n            elements=elements,\n            density=density,\n            density_unit=density_unit,\n            temperature_in_K=temperature_in_K,\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n            poissons_ratio=poissons_ratio,\n            thermal_conductivity=thermal_conductivity,\n            youngs_modulus=youngs_modulus,\n            specific_heat=specific_heat,\n            coefficient_thermal_expansion=coefficient_thermal_expansion,\n            electrical_resistivity=electrical_resistivity,\n            magnetic_saturation=magnetic_saturation,\n            viscous_remanent_magnetisation=viscous_remanent_magnetisation,\n            coercive_field=coercive_field,\n            minimum_yield_stress=minimum_yield_stress,\n            average_yield_stress=average_yield_stress,\n            minimum_ultimate_tensile_stress=minimum_ultimate_tensile_stress,\n            average_ultimate_tensile_stress=average_ultimate_tensile_stress,\n        )\n\n        self.c_0 = c_0\n        self.bc_20 = bc_20\n        self.tc_0 = tc_0\n        self.alpha = alpha\n        self.beta = beta\n        self.gamma = gamma\n\n    def Bc2(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Critical field \\n\n        :math:`B_{C2}^{*}(T) = B_{C20}(1-(\\\\frac{T}{T_{C0}})^{1.7})`\n        \"\"\"\n        return self.bc_20 * (1 - (temperature / self.tc_0) ** 1.7)\n\n    def Jc(self, B: float, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Critical current \\n\n        :math:`j_{c}(B, T) = \\\\frac{C_{0}}{B}(1-(\\\\frac{T}{T_{C0}})^{1.7})\n        ^{\\\\gamma}(\\\\frac{B}{B_{C2}(T)})^{\\\\alpha}(1-(\\\\frac{B}{B_{C2}(T)}))\n        ^{\\\\beta}`\n        \"\"\"\n        a = self.c_0 / B * (1 - (temperature / self.tc_0) ** 1.7) ** self.gamma\n        ii = B / self.Bc2(temperature)\n        b = ii**self.alpha\n        # The below is an \"elegant\" dodge of numpy RuntimeWarnings encountered\n        # when raising a negative number to a fractional power, which in this\n        # parameterisation only occurs if a non-physical (<0) current density\n        # is returned.\n        # TODO: Check the above..\n        c = (1 - ii) ** self.beta if 1 - ii > 0 else 0\n        return a * b * c",
  "class NbSnSuperconductor(MassFractionMaterial, Superconductor):\n    \"\"\"\n    Niobium-Tin Superconductor class.\n\n    Parameters\n    ----------\n    temperature_in_K: float\n        The temperature [K].\n    density: float\n        The optional density [kg/m3]. If supplied then this will override the calculated\n        density for the material.\n    zaid_suffix: str\n        The nuclear library to apply to the zaid, for example \".31c\", this is used in\n        MCNP and Serpent material cards.\n    material_id: int\n        The id number or mat number used in the MCNP and OpenMC material cards.\n    \"\"\"\n\n    __annotations__ = MassFractionMaterial.__annotations__.copy()\n    c_a1: float\n    c_a2: float\n    eps_0a: float\n    eps_m: float\n    b_c20m: float\n    t_c0max: float\n    c: float\n    p: float\n    q: float\n\n    def __init__(\n        self,\n        name,\n        elements,\n        c_a1=None,\n        c_a2=None,\n        eps_0a=None,\n        eps_m=None,\n        b_c20m=None,\n        t_c0max=None,\n        c=None,\n        p=None,\n        q=None,\n        density=None,\n        density_unit=\"kg/m3\",\n        temperature_in_K=T_DEFAULT,  # noqa :N803\n        zaid_suffix=None,\n        material_id=None,\n        poissons_ratio=None,\n        thermal_conductivity=None,\n        youngs_modulus=None,\n        specific_heat=None,\n        coefficient_thermal_expansion=None,\n        electrical_resistivity=None,\n        magnetic_saturation=None,\n        viscous_remanent_magnetisation=None,\n        coercive_field=None,\n        minimum_yield_stress=None,\n        average_yield_stress=None,\n        minimum_ultimate_tensile_stress=None,\n        average_ultimate_tensile_stress=None,\n    ):\n        super().__init__(\n            name=name,\n            elements=elements,\n            density=density,\n            density_unit=density_unit,\n            temperature_in_K=temperature_in_K,\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n            poissons_ratio=poissons_ratio,\n            thermal_conductivity=thermal_conductivity,\n            youngs_modulus=youngs_modulus,\n            specific_heat=specific_heat,\n            coefficient_thermal_expansion=coefficient_thermal_expansion,\n            electrical_resistivity=electrical_resistivity,\n            magnetic_saturation=magnetic_saturation,\n            viscous_remanent_magnetisation=viscous_remanent_magnetisation,\n            coercive_field=coercive_field,\n            minimum_yield_stress=minimum_yield_stress,\n            average_yield_stress=average_yield_stress,\n            minimum_ultimate_tensile_stress=minimum_ultimate_tensile_stress,\n            average_ultimate_tensile_stress=average_ultimate_tensile_stress,\n        )\n\n        self.c_a1 = c_a1\n        self.c_a2 = c_a2\n        self.eps_0a = eps_0a\n        self.eps_m = eps_m\n        self.b_c20m = b_c20m\n        self.t_c0max = t_c0max\n        self.c = c\n        self.p = p\n        self.q = q\n\n        self.eps_sh = self.c_a2 * self.eps_0a / np.sqrt(self.c_a1**2 - self.c_a2**2)\n\n    def Tc_star(self, B: float, eps: float) -> float:  # noqa :N802\n        \"\"\"\n        Critical temperature\n\n        :math:`T_{C}^{*}(B, {\\\\epsilon}) = T_{C0max}^{*}s({\\\\epsilon})^{1/3}\n        (1-b_{0})^{1/1.52}`\n        \"\"\"\n        if B == 0:\n            return self.t_c0max * self.s(eps) ** (1 / 3)\n        else:\n            b = (1 - self.Bc2_star(0, eps)) ** (1 / 1.52j)\n            b = self._handle_ij(b)\n            return self.t_c0max * self.s(eps) ** (1 / 3) * b\n\n    def Bc2_star(self, temperature: float, eps: float) -> float:  # noqa :N802\n        \"\"\"\n        Critical field\n\n        :math:`B_{C}^{*}(T, {\\\\epsilon}) = B_{C20max}^{*}s({\\\\epsilon})\n        (1-t^{1.52})`\n        \"\"\"\n        if temperature == 0:\n            return self.b_c20m * self.s(eps)\n        else:\n            return self.b_c20m * self.s(eps) * (1 - (self._t152(temperature, eps)))\n\n    def Jc(self, B: float, temperature: float, eps: float) -> float:  # noqa :N802\n        \"\"\"\n        Critical current\n\n        :math:`j_{c} = \\\\frac{C}{B}s({\\\\epsilon})(1-t^{1.52})(1-t^{2})b^{p}\n        (1-b)^{q}`\n        \"\"\"\n        b = self.b(B, temperature, eps)\n        t = self.reduced_t(temperature, eps)\n        # Ensure physical current density with max (j, 0)\n        # Limits of parameterisation likely to be encountered sooner\n        return max(\n            (\n                self.c\n                / B\n                * self.s(eps)\n                * (1 - self._t152(temperature, eps))\n                * (1 - t**2)\n                * b**self.p\n            )\n            * (1 - b**self.q),\n            0,\n        )\n\n    def _t152(self, temperature: float, eps: float) -> float:\n        # 1.52 = 30000/19736\n        t = self.reduced_t(temperature, eps) ** 1.52j\n        t = self._handle_ij(t)\n        return t\n\n    def reduced_t(self, temperature: float, eps: float) -> float:\n        \"\"\"\n        Reduced temperature \\n\n        :math:`t = \\\\frac{T}{T_{C}^{*}(0, {\\\\epsilon})}`\n        \"\"\"\n        return temperature / self.Tc_star(0, eps)\n\n    def b(self, field: float, temperature: float, eps: float) -> float:\n        \"\"\"\n        Reduced magnetic field \\n\n        :math:`b = \\\\frac{B}{B_{C2}^{*}(0,{\\\\epsilon})}`\n        \"\"\"\n        return field / self.Bc2_star(temperature, eps)\n\n    def s(self, eps: float) -> float:\n        \"\"\"\n        Strain function \\n\n        :math:`s({\\\\epsilon}) = 1+ \\\\frac{1}{1-C_{a1}{\\\\epsilon}_{0,a}}[C_{a1}\n        (\\\\sqrt{{\\\\epsilon}_{sk}^{2}+{\\\\epsilon}_{0,a}^{2}}-\\\\sqrt{({\\\\epsilon}-\n        {\\\\epsilon}_{sk})^{2}+{\\\\epsilon}_{0,a}^{2}})-C_{a2}{\\\\epsilon}]`\n        \"\"\"\n        return 1 + 1 / (1 - self.c_a1 * self.eps_0a) * (\n            self.c_a1\n            * (\n                np.sqrt(self.eps_sh**2 + self.eps_0a**2)\n                - np.sqrt((eps - self.eps_sh) ** 2 + self.eps_0a**2)\n            )\n            - self.c_a2 * eps\n        )",
  "class Liquid(SerialisedMaterial, nmm.Material):\n    \"\"\"\n    Liquid material base class.\n\n    Parameters\n    ----------\n    temperature_in_K: float\n        The temperature [K].\n    pressure_in_Pa: float\n        The pressure [Pa].\n    zaid_suffix: str\n        The nuclear library to apply to the zaid, for example \".31c\", this is used in\n        MCNP and Serpent material cards.\n    material_id: int\n        The id number or mat number used in the MCNP and OpenMC material cards.\n    \"\"\"\n\n    name: str\n    symbol: str\n    density: MaterialProperty\n    density_unit: str\n    temperature_in_K: float  # noqa :N815\n    pressure_in_Pa: float  # noqa :N815\n    zaid_suffix: str\n    material_id: str\n\n    def __init__(\n        self,\n        name: str,\n        symbol: str,\n        density: Optional[MaterialProperty] = None,\n        density_unit: str = \"kg/m3\",\n        temperature_in_K: float = T_DEFAULT,  # noqa :N803\n        pressure_in_Pa: float = P_DEFAULT,  # noqa :N803\n        zaid_suffix: Optional[str] = None,\n        material_id: Optional[str] = None,\n    ):\n        if density is None:\n            raise MaterialsError(\"No density (value or T/P-function) specified.\")\n\n        if density_unit not in [\"kg/m3\", \"g/cm3\", \"g/cc\"]:\n            raise MaterialsError(\"Density unit must be one of kg/m3, g/cm3, or g/cc\")\n\n        if isinstance(density.value, (int, float)):\n            density_val = density.value\n            density_equation = None\n        else:\n            density_val = None\n            density_equation = density.value\n\n        super().__init__(\n            material_tag=symbol,\n            chemical_equation=symbol,\n            density=density_val,\n            density_equation=density_equation,\n            density_unit=density_unit,\n            percent_type=\"ao\",\n            temperature_in_K=temperature_in_K,\n            temperature_in_C=to_celsius(temperature_in_K),\n            pressure_in_Pa=pressure_in_Pa,\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n        )\n\n        self.name = name\n        self.density_prop = density\n\n        if self.density is None:\n            self.density = _try_calc_property(\n                self, \"density_prop\", temperature_in_K, pressure_in_Pa\n            )\n\n    def __str__(self) -> str:\n        \"\"\"\n        Get a string representation of the Liquid.\n        \"\"\"\n        return self.name\n\n    def rho(self, temperature: float, pressure: Optional[float] = None) -> float:\n        \"\"\"\n        Mass density in kg/m**3\n        \"\"\"\n        if pressure is None:\n            pressure = self.pressure_in_Pa\n\n        density = _try_calc_property(self, \"density_prop\", temperature, pressure)\n\n        if self.density_unit in [\"g/cm3\", \"g/cc\"]:\n            density = gcm3_to_kgm3(density)\n\n        return density\n\n    def E(self, temperature: Optional[float] = None) -> float:  # noqa :N802\n        \"\"\"\n        Youngs modulus (0 for all liquids)\n        \"\"\"\n        return 0\n\n    def mu(self, temperature: Optional[float] = None) -> float:\n        \"\"\"\n        Hmm... not sure about this one\n        \"\"\"\n        return 0\n\n    @property\n    def pressure(self) -> float:\n        \"\"\"\n        The pressure of the material in Pascals\n\n        Returns\n        -------\n        The pressure [Pa]\n        \"\"\"\n        return self.pressure_in_Pa\n\n    @pressure.setter\n    def pressure(self, value: float):\n        \"\"\"\n        Sets the pressure of the material\n\n        Parameters\n        ----------\n        value:\n            The value of the pressure in Pascals\n        \"\"\"\n        try:\n            self.density = self.rho(self.temperature_in_K, value)\n        except NotImplementedError:\n            pass\n        self.pressure_in_Pa = value\n\n    @property\n    def temperature(self) -> float:\n        \"\"\"\n        Temperature: this is a pythonic property, but not an actual material\n        property!\n\n        Returns\n        -------\n        The temperature in Kelvin\n        \"\"\"\n        return self.temperature_in_K\n\n    @temperature.setter\n    def temperature(self, value: float):\n        \"\"\"\n        Sets the temperature of the material\n\n        Parameters\n        ----------\n        value:\n            The temperature in Kelvin\n        \"\"\"\n        try:\n            self.density = self.rho(value, self.pressure)\n        except NotImplementedError:\n            pass\n        self.temperature_in_K = value",
  "class UnitCellCompound(SerialisedMaterial, nmm.Material):\n    \"\"\"\n    Unit cell compound\n\n    Parameters\n    ----------\n    temperature_in_K:\n        The temperature [K].\n    packing_fraction:\n        Compound packing fraction (filled with Void). 0  <= float <= 1\n    enrichment:\n        Li6 absolute enrichment fraction. 0 <= float <= 1\n    zaid_suffix:\n        The nuclear library to apply to the zaid, for example \".31c\", this is used in\n        MCNP and Serpent material cards.\n    material_id:\n        The id number or mat number used in the MCNP and OpenMC material cards.\n    \"\"\"\n\n    # Properties to interface with neutronics material maker\n    name: str\n    symbol: str\n    volume_of_unit_cell_cm3: float\n    atoms_per_unit_cell: float\n    packing_fraction: float\n    enrichment: float\n    temperature_in_K: float  # noqa :N815\n    zaid_suffix: str\n    material_id: str\n\n    # Engineering properties\n    specific_heat: MaterialProperty\n    coefficient_thermal_expansion: MaterialProperty\n\n    def __init__(\n        self,\n        name: str,\n        symbol: str,\n        volume_of_unit_cell_cm3: float,\n        atoms_per_unit_cell: float,\n        packing_fraction: float = 1.0,\n        enrichment: Optional[float] = None,\n        temperature_in_K: float = T_DEFAULT,  # noqa :N803\n        zaid_suffix: Optional[str] = None,\n        material_id: Optional[str] = None,\n        specific_heat: Optional[MaterialProperty] = None,\n        coefficient_thermal_expansion: Optional[MaterialProperty] = None,\n    ):\n        self.is_enrichable = True\n        try:\n            import openmc  # type: ignore # noqa :F401\n        except ImportError:\n            self.is_enrichable = False\n        if enrichment is not None:\n            bluemira_warn(\n                f\"Enrichment set for {self.name} but OpenMC is not available, so \"\n                \"enrichment properties will not be ignored.\"\n            )\n\n        super().__init__(\n            material_tag=name,\n            chemical_equation=symbol,\n            volume_of_unit_cell_cm3=volume_of_unit_cell_cm3,\n            atoms_per_unit_cell=atoms_per_unit_cell,\n            percent_type=\"ao\",\n            temperature_in_K=temperature_in_K,\n            temperature_in_C=to_celsius(temperature_in_K),\n            packing_fraction=packing_fraction,\n            enrichment=enrichment if self.is_enrichable else None,\n            enrichment_target=\"Li6\" if self.is_enrichable else None,\n            enrichment_type=\"ao\" if self.is_enrichable else None,\n            density_unit=\"g/cm3\",\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n        )\n\n        self.name = name\n\n        self.specific_heat = specific_heat\n        self.coefficient_thermal_expansion = coefficient_thermal_expansion\n\n    def __str__(self):\n        \"\"\"\n        Get a string representation of the UcCompound.\n        \"\"\"\n        return self.name\n\n    def Cp(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Specific heat in J/kg/K\n        \"\"\"\n        return _try_calc_property(self, \"specific_heat\", temperature)\n\n    def CTE(  # noqa :N802\n        self, temperature: float, eps_vol: Optional[float] = None\n    ) -> float:\n        \"\"\"\n        Mean coefficient of thermal expansion in 10**-6/T\n        \"\"\"\n        return _try_calc_property(\n            self, \"coefficient_thermal_expansion\", temperature, eps_vol\n        )",
  "class BePebbleBed(UnitCellCompound):\n    \"\"\"\n    Beryllium Pebble Bed.\n    \"\"\"\n\n    @matproperty(t_min=to_kelvin(25), t_max=to_kelvin(800))\n    def CTE(self, temperature: float, eps_vol: float = 0) -> float:  # noqa :N802\n        \"\"\"\n        https://www.sciencedirect.com/science/article/pii/S0920379602001655\n        \"\"\"\n        # NOTE: Effect of inelastic volumetric strains [%] not negligible\n        # esp_vol calculated roughly as f(T), as per 2M2BH9\n        temperature = to_celsius(temperature)\n        if eps_vol == 0:\n\n            def calc_eps_vol(temp):\n                \"\"\"\n                Calculates inelastic volumetric strains [%] based on T (C)\n                \"\"\"\n                if temp >= 600:\n                    return 0.5\n                elif temp >= 500:\n                    return 0.3\n                elif temp < 500:\n                    return 0.2\n\n            eps_vol = np.vectorize(calc_eps_vol)(temperature)\n        if is_num(eps_vol):\n            eps_vol = eps_vol * np.ones_like(temperature)\n        return (\n            1.81\n            + 0.0012 * temperature\n            - 5e-7 * temperature**2\n            + eps_vol\n            * (\n                9.03\n                - 1.386e-3 * temperature\n                - 7.6e-6 * temperature**2\n                + 2.1e-9 * temperature**3\n            )\n        )",
  "class Plasma(SerialisedMaterial, nmm.Material):\n    \"\"\"\n    A generic plasma material.\n    \"\"\"\n\n    name: str\n    isotopes: Dict[str, float]\n    density: MaterialProperty\n    density_unit: str\n    temperature_in_K: float  # noqa :N815\n    zaid_suffix: str\n    material_id: str\n\n    def __init__(\n        self,\n        name: str,\n        isotopes: Dict[str, float],\n        density: MaterialProperty = MaterialProperty(1e-6),\n        density_unit: str = \"g/cm3\",\n        temperature_in_K: Optional[float] = None,  # noqa :N803\n        zaid_suffix: Optional[str] = None,\n        material_id: Optional[str] = None,\n    ):\n        temperature_in_C = None  # noqa :N806\n        if temperature_in_K is not None:\n            temperature_in_C = to_celsius(temperature_in_K)  # noqa :N806\n\n        density_val = None\n        if isinstance(density.value, (int, float)):\n            density_val = density.value\n\n        super().__init__(\n            material_tag=name,\n            density=density_val,\n            density_unit=density_unit,\n            isotopes=isotopes,\n            percent_type=\"ao\",\n            temperature_in_K=temperature_in_K,\n            temperature_in_C=temperature_in_C,\n            material_id=material_id,\n            zaid_suffix=zaid_suffix,\n        )\n\n        self.name = name\n\n    def __str__(self) -> str:\n        \"\"\"\n        Get a string representation of the plasma.\n        \"\"\"\n        return self.name\n\n    def E(self, temperature: Optional[float] = None) -> float:  # noqa :N802\n        \"\"\"\n        Young's modulus.\n        \"\"\"\n        return 0\n\n    def mu(self, temperature: Optional[float] = None) -> float:\n        \"\"\"\n        Poisson's ratio.\n        \"\"\"\n        return 0",
  "def decorator(f):\n        def wrapper(*args, **kwargs):\n            temperatures = list_array(args[1])\n\n            if not (temperatures <= t_max).all():\n                raise ValueError(\n                    \"Material property not valid outside of tempe\"\n                    f\"rature range: {temperatures} > T_max = {t_max}\"\n                )\n            if not (temperatures >= t_min).all():\n                raise ValueError(\n                    \"Material property not valid outside of tempe\"\n                    f\"rature range: {temperatures} < T_min = {t_min}\"\n                )\n            temperatures = array_or_num(temperatures)\n            return f(args[0], temperatures, **kwargs)\n\n        return wrapper",
  "def __init__(\n        self,\n        value: Union[float, str],\n        temp_max_kelvin: Optional[float] = None,\n        temp_min_kelvin: Optional[float] = None,\n        temp_max_celsius: Optional[float] = None,\n        temp_min_celsius: Optional[float] = None,\n        reference: Optional[str] = None,\n    ):\n        if (temp_max_kelvin is not None or temp_min_kelvin is not None) and (\n            temp_max_celsius is not None or temp_min_celsius is not None\n        ):\n            raise MaterialsError(\n                \"Material property temperature ranges must be set by either K or C, not both.\"\n            )\n\n        self.value = value\n        self.reference = reference\n\n        self.temp_max = None\n        if temp_max_kelvin is not None:\n            self.temp_max = temp_max_kelvin\n        elif temp_max_celsius is not None:\n            self.temp_max = to_kelvin(temp_max_celsius)\n\n        self.temp_min = None\n        if temp_min_kelvin is not None:\n            self.temp_min = temp_min_kelvin\n        elif temp_min_celsius is not None:\n            self.temp_min = to_kelvin(temp_min_celsius)",
  "def __call__(\n        self,\n        temperature: float,\n        pressure: Optional[float] = None,\n        eps_vol: Optional[float] = None,\n    ) -> float:\n        \"\"\"\n        Evaluates the property at a given temperature, pressure, and/or eps_vol.\n\n        Parameters\n        ----------\n        temperature:\n            The temperature [K].\n        pressure:\n            The optional pressure [Pa].\n        esp_vol:\n            The optional cell volume [m^3].\n\n        Returns\n        -------\n        The property evaluated at the given temperature, pressure, and/or eps_vol.\n        \"\"\"\n        if isinstance(self.value, str):\n            aeval = asteval.Interpreter(usersyms=asteval_user_symbols)\n            temperature = list_array(temperature)\n            self._validate_temperature(temperature)\n            aeval.symtable[\"temperature\"] = temperature\n            aeval.symtable[\"temperature_in_K\"] = temperature\n            aeval.symtable[\"temperature_in_C\"] = to_celsius(temperature)\n\n            if pressure is not None:\n                aeval.symtable[\"pressure\"] = pressure\n                aeval.symtable[\"pressure_in_Pa\"] = pressure\n\n            if eps_vol is not None:\n                aeval.symtable[\"eps_vol\"] = eps_vol\n            else:\n                aeval.symtable[\"eps_vol\"] = 0.0\n\n            prop_val = aeval.eval(self.value)\n            prop_val = array_or_num(prop_val)\n\n            if len(aeval.error) > 0:\n                raise aeval.error[0].exc(aeval.error[0].msg)\n\n            return prop_val\n        else:\n            self._validate_temperature(temperature)\n            return self.value",
  "def deserialise(cls, prop_rep: Union[Dict[str, Any], float, str]):\n        \"\"\"\n        Deserialise the provided property representation.\n\n        Parameters\n        ----------\n        prop_rep:\n            The representation of the property. Can be just the value that the property\n            defines, or can be a dictionary containing the value and any of the optional\n            properties.\n\n        Returns\n        -------\n        The `MaterialProperty` corresponding to the provided representation.\n        \"\"\"\n        if isinstance(prop_rep, dict):\n            return cls(**prop_rep)\n        else:\n            return cls(value=prop_rep)",
  "def serialise(self):\n        \"\"\"\n        Serialise the material property to a value or dictionary.\n\n        Returns\n        -------\n        serialised_prop: Union[Dict[str, Any], float, str]\n            The serialised representation of the property. Represented by a dictionary\n            mapping attributes to their values, if more attributes than the value are\n            defined, otherwise just returns the value.\n        \"\"\"\n        if self.temp_max is None and self.temp_min is None and self.reference is None:\n            return self.value\n        else:\n            prop_dict = {\"value\": self.value}\n            if self.temp_max is not None:\n                prop_dict[\"temp_max_kelvin\"] = self.temp_max\n            if self.temp_min is not None:\n                prop_dict[\"temp_min_kelvin\"] = self.temp_min\n            if self.reference is not None:\n                prop_dict[\"reference\"] = self.reference\n            return prop_dict",
  "def _validate_temperature(self, temperature: Union[float, List[float], np.ndarray]):\n        \"\"\"\n        Check that the property is valid for the requested temperature range.\n\n        Parameters\n        ----------\n        temperature:\n            The temperatures requested to value the property at.\n\n        Raises\n        ------\n        ValueError\n            If any of the requested temperatures are outside of the valid range\n        \"\"\"\n        temperatures = list_array(temperature)\n        if self.temp_min is not None and (temperatures < self.temp_min).any():\n            raise ValueError(\n                \"Material property not valid outside of temperature range: \"\n                f\"{temperatures} < T_min = {self.temp_min}\"\n            )\n        if self.temp_max is not None and (temperatures > self.temp_max).any():\n            raise ValueError(\n                \"Material property not valid outside of temperature range: \"\n                f\"{temperature} > T_max = {self.temp_max}\"\n            )",
  "def to_dict(self) -> Dict[str, Any]:\n        \"\"\"\n        Get a dictionary representation of the material.\n\n        Returns\n        -------\n        The dictionary representation of the material.\n        \"\"\"\n        attr_dict = {}\n        for attr in [attr for attr in self.__annotations__.keys() if attr != \"name\"]:\n            attr_val = getattr(self, attr, None)\n            if attr_val is not None:\n                if isinstance(attr_val, MaterialProperty):\n                    attr_dict[attr] = attr_val.serialise()\n                else:\n                    attr_dict[attr] = attr_val\n        mat_dict = {self.name: attr_dict}\n        return mat_dict",
  "def from_dict(cls, name: str, materials_dict: Dict[str, Any]):\n        \"\"\"\n        Generate an instance of the material from a dictionary of materials.\n\n        Returns\n        -------\n        material : SerialisedMaterial\n            The material.\n        \"\"\"\n        mat_dict = materials_dict[name]\n        type_hints = get_type_hints(cls)\n        for attr_name, attr_type in type_hints.items():\n            if (\n                attr_name in mat_dict\n                and not hasattr(attr_type, \"__origin__\")\n                and issubclass(attr_type, MaterialProperty)\n            ):\n                mat_dict[attr_name] = attr_type.deserialise(mat_dict[attr_name])\n        return cls(name, **mat_dict)",
  "def to_json(self, **kwargs) -> str:\n        \"\"\"\n        Get a JSON representation of the material.\n\n        Parameters\n        ----------\n        kwargs:\n            passed to json writer\n\n        Returns\n        -------\n        The JSON representation of the material.\n        \"\"\"\n        mat_dict = self.to_dict()\n        mat_dict[self.name][\"material_class\"] = self.__class__.__name__\n        return json_writer(mat_dict, return_output=True, **kwargs)",
  "def from_json(cls, data: str) -> str:\n        \"\"\"\n        Generate an instance of the material from JSON.\n\n        Returns\n        -------\n        The JSON representation of the material.\n        \"\"\"\n        mat_dict = json.loads(data)\n        mat_name = list(mat_dict.keys())[0]\n        return cls.from_dict(mat_name, mat_dict)",
  "def __hash__(self) -> int:\n        \"\"\"\n        Hash the material by it's name.\n\n        Returns\n        -------\n        The hashed material name\n        \"\"\"\n        return hash(self.name)",
  "def __eq__(self, other) -> bool:\n        \"\"\"\n        Two materials are equal if their attributes have the same values.\n\n        Returns\n        -------\n        True if the two materials have the same attribute values, else false.\n        \"\"\"\n        return self.to_dict() == other.to_dict()",
  "def __neq__(self, other) -> bool:\n        \"\"\"\n        Two materials are not equal if their attributes have different values.\n\n        Returns\n        -------\n        True if the two materials have different attribute values, else false.\n        \"\"\"\n        return self != other",
  "def __init__(\n        self,\n        name: str,\n        temperature_in_K: float = T_DEFAULT,  # noqa :N803\n        zaid_suffix: Optional[str] = None,\n        material_id: Optional[str] = None,\n    ):\n        super().__init__(\n            material_tag=name,\n            density=1,\n            density_unit=\"atom/cm3\",\n            elements={\"H\": 1},\n            percent_type=\"ao\",\n            temperature_in_K=temperature_in_K,\n            temperature_in_C=to_celsius(temperature_in_K),\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n        )\n\n        self.name = name",
  "def __str__(self) -> str:\n        \"\"\"\n        Get a string representation of the Void.\n        \"\"\"\n        return self.name",
  "def E(self, temperature: Optional[float] = None) -> float:  # noqa :N802\n        \"\"\"\n        Young's modulus.\n\n        Parameters\n        ----------\n        temperature:\n            The optional temperature [K].\n\n        Returns\n        -------\n        The Young's modulus of the material at the given temperature.\n        \"\"\"\n        return 0.0",
  "def mu(self, temperature: Optional[float] = None) -> float:\n        \"\"\"\n        Poisson's ratio.\n\n        Parameters\n        ----------\n        temperature:\n            The optional temperature [K].\n\n        Returns\n        -------\n        Poisson's ratio for the material at the given temperature.\n        \"\"\"\n        return 0.0",
  "def rho(self, temperature: Optional[float] = None) -> float:  # noqa :N802\n        \"\"\"\n        Density.\n\n        Parameters\n        ----------\n        temperature:\n            The optional temperature [K].\n\n        Returns\n        -------\n        The density of the material at the given temperature.\n        \"\"\"\n        return 0.0",
  "def __init__(\n        self,\n        name: str,\n        elements: Dict[str, float],\n        density: Optional[MaterialProperty] = None,\n        density_unit: str = \"kg/m3\",\n        temperature_in_K: float = T_DEFAULT,  # noqa :N803\n        zaid_suffix: Optional[str] = None,\n        material_id: Optional[float] = None,\n        poissons_ratio: Optional[MaterialProperty] = None,\n        thermal_conductivity: Optional[MaterialProperty] = None,\n        youngs_modulus: Optional[MaterialProperty] = None,\n        specific_heat: Optional[MaterialProperty] = None,\n        coefficient_thermal_expansion: Optional[MaterialProperty] = None,\n        electrical_resistivity: Optional[MaterialProperty] = None,\n        magnetic_saturation: Optional[MaterialProperty] = None,\n        viscous_remanent_magnetisation: Optional[MaterialProperty] = None,\n        coercive_field: Optional[MaterialProperty] = None,\n        minimum_yield_stress: Optional[MaterialProperty] = None,\n        average_yield_stress: Optional[MaterialProperty] = None,\n        minimum_ultimate_tensile_stress: Optional[MaterialProperty] = None,\n        average_ultimate_tensile_stress: Optional[MaterialProperty] = None,\n    ):\n        if density is None:\n            raise MaterialsError(\"No density (value or T-function) specified.\")\n\n        if density_unit not in [\"kg/m3\", \"g/cm3\", \"g/cc\"]:\n            raise MaterialsError(\"Density unit must be one of kg/m3, g/cm3, or g/cc\")\n\n        if isinstance(density.value, (int, float)):\n            density_val = density.value\n            density_equation = None\n        else:\n            density_val = None\n            density_equation = density.value\n\n        super().__init__(\n            material_tag=name,\n            elements=elements,\n            density=density_val,\n            density_equation=density_equation,\n            density_unit=density_unit,\n            percent_type=\"wo\",\n            temperature_in_K=temperature_in_K,\n            temperature_in_C=to_celsius(temperature_in_K),\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n        )\n\n        self.name = name\n\n        self.density_prop = density\n        self.poissons_ratio = poissons_ratio\n        self.thermal_conductivity = thermal_conductivity\n        self.youngs_modulus = youngs_modulus\n        self.specific_heat = specific_heat\n        self.coefficient_thermal_expansion = coefficient_thermal_expansion\n        self.electrical_resistivity = electrical_resistivity\n        self.magnetic_saturation = magnetic_saturation\n        self.viscous_remanent_magnetisation = viscous_remanent_magnetisation\n        self.coercive_field = coercive_field\n        self.minimum_yield_stress = minimum_yield_stress\n        self.average_yield_stress = average_yield_stress\n        self.minimum_ultimate_tensile_stress = minimum_ultimate_tensile_stress\n        self.average_ultimate_tensile_stress = average_ultimate_tensile_stress\n\n        if self.density is None:\n            self.density = _try_calc_property(self, \"density_prop\", temperature_in_K)",
  "def __str__(self) -> str:\n        \"\"\"\n        Get a string representation of the MfMaterial.\n        \"\"\"\n        return self.name",
  "def mu(self, temperature: float) -> float:\n        \"\"\"\n        Poisson's ratio\n        \"\"\"\n        return _try_calc_property(self, \"poissons_ratio\", temperature)",
  "def k(self, temperature: float) -> float:\n        \"\"\"\n        Thermal conductivity in W.m/K\n        \"\"\"\n        return _try_calc_property(self, \"thermal_conductivity\", temperature)",
  "def E(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Young's modulus in GPa\n        \"\"\"\n        return _try_calc_property(self, \"youngs_modulus\", temperature)",
  "def Cp(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Specific heat in J/kg/K\n        \"\"\"\n        return _try_calc_property(self, \"specific_heat\", temperature)",
  "def CTE(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Mean coefficient of thermal expansion in 10**-6/T\n        \"\"\"\n        return _try_calc_property(self, \"coefficient_thermal_expansion\", temperature)",
  "def rho(self, temperature: float) -> float:\n        \"\"\"\n        Mass density in kg/m**3\n        \"\"\"\n        density = _try_calc_property(self, \"density_prop\", temperature)\n\n        if self.density_unit in [\"g/cm3\", \"g/cc\"]:\n            density = gcm3_to_kgm3(density)\n\n        return density",
  "def erho(self, temperature: float) -> float:\n        \"\"\"\n        Electrical resistivity in 10^(-8)Ohm.m\n        \"\"\"\n        return _try_calc_property(self, \"electrical_resistivity\", temperature)",
  "def Ms(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Magnetic saturation in Am^2/kg\n        \"\"\"\n        return _try_calc_property(self, \"magnetic_saturation\", temperature)",
  "def Mt(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Viscous remanent magnetisation in Am^2/kg\n        \"\"\"\n        return _try_calc_property(self, \"viscous_remanent_magnetisation\", temperature)",
  "def Hc(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Coercive field in A/m\n        \"\"\"\n        return _try_calc_property(self, \"coercive_field\", temperature)",
  "def Sy(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Minimum yield stress in MPa\n        \"\"\"\n        return _try_calc_property(self, \"minimum_yield_stress\", temperature)",
  "def Syavg(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Average yield stress in MPa\n        \"\"\"\n        return _try_calc_property(self, \"average_yield_stress\", temperature)",
  "def Su(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Minimum ultimate tensile stress in MPa\n        \"\"\"\n        return _try_calc_property(self, \"minimum_ultimate_tensile_stress\", temperature)",
  "def Suavg(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Average ultimate tensile stress in MPa\n        \"\"\"\n        return _try_calc_property(self, \"average_ultimate_tensile_stress\", temperature)",
  "def temperature(self) -> float:\n        \"\"\"\n        Temperature: this is a pythonic property, but not an actual material\n        property!\n\n        Returns\n        -------\n        The temperature in Kelvin\n        \"\"\"\n        return self.temperature_in_K",
  "def temperature(self, value: float):\n        \"\"\"\n        Sets the temperature of the material\n\n        Parameters\n        ----------\n        value:\n            The temperature in Kelvin\n        \"\"\"\n        try:\n            self.density = self.rho(value)\n        except NotImplementedError:\n            pass\n        self.temperature_in_K = value\n        self.temperature_in_C = to_celsius(value)",
  "def plot(\n        self,\n        b_min: float,\n        b_max: float,\n        t_min: float,\n        t_max: float,\n        eps: Optional[float] = None,\n        n: int = 101,\n        m: int = 100,\n    ):\n        \"\"\"\n        Plots superconducting surface parameterisation\n        strain `eps` only used for Nb3Sn\n        \"\"\"\n        jc = np.zeros([m, n])\n        fields = np.linspace(b_min, b_max, n)\n        temperatures = np.linspace(t_min, t_max, m)\n        for j, b in enumerate(fields):\n            for i, t in enumerate(temperatures):\n                args = (b, t, eps) if eps else (b, t)\n                jc[i, j] = self.Jc(*args)\n        fig = plt.figure()\n        fields, temperatures = np.meshgrid(fields, temperatures)\n        ax = fig.add_subplot(111, projection=\"3d\")\n        ax.set_title(self.name)\n        ax.set_xlabel(\"B [T]\")\n        ax.set_ylabel(\"T [K]\")\n        ax.set_zlabel(\"$j_{c}$ [A/mm^2]\")\n        ax.plot_surface(fields, temperatures, jc, cmap=plt.cm.viridis)\n        ax.view_init(30, 45)",
  "def Jc(self):  # noqa :N802\n        _raise_error()",
  "def _handle_ij(number):\n        \"\"\"\n        Takes the real part of the imaginary number that results from the\n        exponentiation of a negative number with a fraction.\n        \"\"\"\n        return number.real",
  "def __init__(\n        self,\n        name,\n        elements,\n        c_0=None,\n        bc_20=None,\n        tc_0=None,\n        alpha=None,\n        beta=None,\n        gamma=None,\n        density=None,\n        density_unit=\"kg/m3\",\n        temperature_in_K=T_DEFAULT,  # noqa :N803\n        zaid_suffix=None,\n        material_id=None,\n        poissons_ratio=None,\n        thermal_conductivity=None,\n        youngs_modulus=None,\n        specific_heat=None,\n        coefficient_thermal_expansion=None,\n        electrical_resistivity=None,\n        magnetic_saturation=None,\n        viscous_remanent_magnetisation=None,\n        coercive_field=None,\n        minimum_yield_stress=None,\n        average_yield_stress=None,\n        minimum_ultimate_tensile_stress=None,\n        average_ultimate_tensile_stress=None,\n    ):\n        super().__init__(\n            name=name,\n            elements=elements,\n            density=density,\n            density_unit=density_unit,\n            temperature_in_K=temperature_in_K,\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n            poissons_ratio=poissons_ratio,\n            thermal_conductivity=thermal_conductivity,\n            youngs_modulus=youngs_modulus,\n            specific_heat=specific_heat,\n            coefficient_thermal_expansion=coefficient_thermal_expansion,\n            electrical_resistivity=electrical_resistivity,\n            magnetic_saturation=magnetic_saturation,\n            viscous_remanent_magnetisation=viscous_remanent_magnetisation,\n            coercive_field=coercive_field,\n            minimum_yield_stress=minimum_yield_stress,\n            average_yield_stress=average_yield_stress,\n            minimum_ultimate_tensile_stress=minimum_ultimate_tensile_stress,\n            average_ultimate_tensile_stress=average_ultimate_tensile_stress,\n        )\n\n        self.c_0 = c_0\n        self.bc_20 = bc_20\n        self.tc_0 = tc_0\n        self.alpha = alpha\n        self.beta = beta\n        self.gamma = gamma",
  "def Bc2(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Critical field \\n\n        :math:`B_{C2}^{*}(T) = B_{C20}(1-(\\\\frac{T}{T_{C0}})^{1.7})`\n        \"\"\"\n        return self.bc_20 * (1 - (temperature / self.tc_0) ** 1.7)",
  "def Jc(self, B: float, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Critical current \\n\n        :math:`j_{c}(B, T) = \\\\frac{C_{0}}{B}(1-(\\\\frac{T}{T_{C0}})^{1.7})\n        ^{\\\\gamma}(\\\\frac{B}{B_{C2}(T)})^{\\\\alpha}(1-(\\\\frac{B}{B_{C2}(T)}))\n        ^{\\\\beta}`\n        \"\"\"\n        a = self.c_0 / B * (1 - (temperature / self.tc_0) ** 1.7) ** self.gamma\n        ii = B / self.Bc2(temperature)\n        b = ii**self.alpha\n        # The below is an \"elegant\" dodge of numpy RuntimeWarnings encountered\n        # when raising a negative number to a fractional power, which in this\n        # parameterisation only occurs if a non-physical (<0) current density\n        # is returned.\n        # TODO: Check the above..\n        c = (1 - ii) ** self.beta if 1 - ii > 0 else 0\n        return a * b * c",
  "def __init__(\n        self,\n        name,\n        elements,\n        c_a1=None,\n        c_a2=None,\n        eps_0a=None,\n        eps_m=None,\n        b_c20m=None,\n        t_c0max=None,\n        c=None,\n        p=None,\n        q=None,\n        density=None,\n        density_unit=\"kg/m3\",\n        temperature_in_K=T_DEFAULT,  # noqa :N803\n        zaid_suffix=None,\n        material_id=None,\n        poissons_ratio=None,\n        thermal_conductivity=None,\n        youngs_modulus=None,\n        specific_heat=None,\n        coefficient_thermal_expansion=None,\n        electrical_resistivity=None,\n        magnetic_saturation=None,\n        viscous_remanent_magnetisation=None,\n        coercive_field=None,\n        minimum_yield_stress=None,\n        average_yield_stress=None,\n        minimum_ultimate_tensile_stress=None,\n        average_ultimate_tensile_stress=None,\n    ):\n        super().__init__(\n            name=name,\n            elements=elements,\n            density=density,\n            density_unit=density_unit,\n            temperature_in_K=temperature_in_K,\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n            poissons_ratio=poissons_ratio,\n            thermal_conductivity=thermal_conductivity,\n            youngs_modulus=youngs_modulus,\n            specific_heat=specific_heat,\n            coefficient_thermal_expansion=coefficient_thermal_expansion,\n            electrical_resistivity=electrical_resistivity,\n            magnetic_saturation=magnetic_saturation,\n            viscous_remanent_magnetisation=viscous_remanent_magnetisation,\n            coercive_field=coercive_field,\n            minimum_yield_stress=minimum_yield_stress,\n            average_yield_stress=average_yield_stress,\n            minimum_ultimate_tensile_stress=minimum_ultimate_tensile_stress,\n            average_ultimate_tensile_stress=average_ultimate_tensile_stress,\n        )\n\n        self.c_a1 = c_a1\n        self.c_a2 = c_a2\n        self.eps_0a = eps_0a\n        self.eps_m = eps_m\n        self.b_c20m = b_c20m\n        self.t_c0max = t_c0max\n        self.c = c\n        self.p = p\n        self.q = q\n\n        self.eps_sh = self.c_a2 * self.eps_0a / np.sqrt(self.c_a1**2 - self.c_a2**2)",
  "def Tc_star(self, B: float, eps: float) -> float:  # noqa :N802\n        \"\"\"\n        Critical temperature\n\n        :math:`T_{C}^{*}(B, {\\\\epsilon}) = T_{C0max}^{*}s({\\\\epsilon})^{1/3}\n        (1-b_{0})^{1/1.52}`\n        \"\"\"\n        if B == 0:\n            return self.t_c0max * self.s(eps) ** (1 / 3)\n        else:\n            b = (1 - self.Bc2_star(0, eps)) ** (1 / 1.52j)\n            b = self._handle_ij(b)\n            return self.t_c0max * self.s(eps) ** (1 / 3) * b",
  "def Bc2_star(self, temperature: float, eps: float) -> float:  # noqa :N802\n        \"\"\"\n        Critical field\n\n        :math:`B_{C}^{*}(T, {\\\\epsilon}) = B_{C20max}^{*}s({\\\\epsilon})\n        (1-t^{1.52})`\n        \"\"\"\n        if temperature == 0:\n            return self.b_c20m * self.s(eps)\n        else:\n            return self.b_c20m * self.s(eps) * (1 - (self._t152(temperature, eps)))",
  "def Jc(self, B: float, temperature: float, eps: float) -> float:  # noqa :N802\n        \"\"\"\n        Critical current\n\n        :math:`j_{c} = \\\\frac{C}{B}s({\\\\epsilon})(1-t^{1.52})(1-t^{2})b^{p}\n        (1-b)^{q}`\n        \"\"\"\n        b = self.b(B, temperature, eps)\n        t = self.reduced_t(temperature, eps)\n        # Ensure physical current density with max (j, 0)\n        # Limits of parameterisation likely to be encountered sooner\n        return max(\n            (\n                self.c\n                / B\n                * self.s(eps)\n                * (1 - self._t152(temperature, eps))\n                * (1 - t**2)\n                * b**self.p\n            )\n            * (1 - b**self.q),\n            0,\n        )",
  "def _t152(self, temperature: float, eps: float) -> float:\n        # 1.52 = 30000/19736\n        t = self.reduced_t(temperature, eps) ** 1.52j\n        t = self._handle_ij(t)\n        return t",
  "def reduced_t(self, temperature: float, eps: float) -> float:\n        \"\"\"\n        Reduced temperature \\n\n        :math:`t = \\\\frac{T}{T_{C}^{*}(0, {\\\\epsilon})}`\n        \"\"\"\n        return temperature / self.Tc_star(0, eps)",
  "def b(self, field: float, temperature: float, eps: float) -> float:\n        \"\"\"\n        Reduced magnetic field \\n\n        :math:`b = \\\\frac{B}{B_{C2}^{*}(0,{\\\\epsilon})}`\n        \"\"\"\n        return field / self.Bc2_star(temperature, eps)",
  "def s(self, eps: float) -> float:\n        \"\"\"\n        Strain function \\n\n        :math:`s({\\\\epsilon}) = 1+ \\\\frac{1}{1-C_{a1}{\\\\epsilon}_{0,a}}[C_{a1}\n        (\\\\sqrt{{\\\\epsilon}_{sk}^{2}+{\\\\epsilon}_{0,a}^{2}}-\\\\sqrt{({\\\\epsilon}-\n        {\\\\epsilon}_{sk})^{2}+{\\\\epsilon}_{0,a}^{2}})-C_{a2}{\\\\epsilon}]`\n        \"\"\"\n        return 1 + 1 / (1 - self.c_a1 * self.eps_0a) * (\n            self.c_a1\n            * (\n                np.sqrt(self.eps_sh**2 + self.eps_0a**2)\n                - np.sqrt((eps - self.eps_sh) ** 2 + self.eps_0a**2)\n            )\n            - self.c_a2 * eps\n        )",
  "def __init__(\n        self,\n        name: str,\n        symbol: str,\n        density: Optional[MaterialProperty] = None,\n        density_unit: str = \"kg/m3\",\n        temperature_in_K: float = T_DEFAULT,  # noqa :N803\n        pressure_in_Pa: float = P_DEFAULT,  # noqa :N803\n        zaid_suffix: Optional[str] = None,\n        material_id: Optional[str] = None,\n    ):\n        if density is None:\n            raise MaterialsError(\"No density (value or T/P-function) specified.\")\n\n        if density_unit not in [\"kg/m3\", \"g/cm3\", \"g/cc\"]:\n            raise MaterialsError(\"Density unit must be one of kg/m3, g/cm3, or g/cc\")\n\n        if isinstance(density.value, (int, float)):\n            density_val = density.value\n            density_equation = None\n        else:\n            density_val = None\n            density_equation = density.value\n\n        super().__init__(\n            material_tag=symbol,\n            chemical_equation=symbol,\n            density=density_val,\n            density_equation=density_equation,\n            density_unit=density_unit,\n            percent_type=\"ao\",\n            temperature_in_K=temperature_in_K,\n            temperature_in_C=to_celsius(temperature_in_K),\n            pressure_in_Pa=pressure_in_Pa,\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n        )\n\n        self.name = name\n        self.density_prop = density\n\n        if self.density is None:\n            self.density = _try_calc_property(\n                self, \"density_prop\", temperature_in_K, pressure_in_Pa\n            )",
  "def __str__(self) -> str:\n        \"\"\"\n        Get a string representation of the Liquid.\n        \"\"\"\n        return self.name",
  "def rho(self, temperature: float, pressure: Optional[float] = None) -> float:\n        \"\"\"\n        Mass density in kg/m**3\n        \"\"\"\n        if pressure is None:\n            pressure = self.pressure_in_Pa\n\n        density = _try_calc_property(self, \"density_prop\", temperature, pressure)\n\n        if self.density_unit in [\"g/cm3\", \"g/cc\"]:\n            density = gcm3_to_kgm3(density)\n\n        return density",
  "def E(self, temperature: Optional[float] = None) -> float:  # noqa :N802\n        \"\"\"\n        Youngs modulus (0 for all liquids)\n        \"\"\"\n        return 0",
  "def mu(self, temperature: Optional[float] = None) -> float:\n        \"\"\"\n        Hmm... not sure about this one\n        \"\"\"\n        return 0",
  "def pressure(self) -> float:\n        \"\"\"\n        The pressure of the material in Pascals\n\n        Returns\n        -------\n        The pressure [Pa]\n        \"\"\"\n        return self.pressure_in_Pa",
  "def pressure(self, value: float):\n        \"\"\"\n        Sets the pressure of the material\n\n        Parameters\n        ----------\n        value:\n            The value of the pressure in Pascals\n        \"\"\"\n        try:\n            self.density = self.rho(self.temperature_in_K, value)\n        except NotImplementedError:\n            pass\n        self.pressure_in_Pa = value",
  "def temperature(self) -> float:\n        \"\"\"\n        Temperature: this is a pythonic property, but not an actual material\n        property!\n\n        Returns\n        -------\n        The temperature in Kelvin\n        \"\"\"\n        return self.temperature_in_K",
  "def temperature(self, value: float):\n        \"\"\"\n        Sets the temperature of the material\n\n        Parameters\n        ----------\n        value:\n            The temperature in Kelvin\n        \"\"\"\n        try:\n            self.density = self.rho(value, self.pressure)\n        except NotImplementedError:\n            pass\n        self.temperature_in_K = value",
  "def __init__(\n        self,\n        name: str,\n        symbol: str,\n        volume_of_unit_cell_cm3: float,\n        atoms_per_unit_cell: float,\n        packing_fraction: float = 1.0,\n        enrichment: Optional[float] = None,\n        temperature_in_K: float = T_DEFAULT,  # noqa :N803\n        zaid_suffix: Optional[str] = None,\n        material_id: Optional[str] = None,\n        specific_heat: Optional[MaterialProperty] = None,\n        coefficient_thermal_expansion: Optional[MaterialProperty] = None,\n    ):\n        self.is_enrichable = True\n        try:\n            import openmc  # type: ignore # noqa :F401\n        except ImportError:\n            self.is_enrichable = False\n        if enrichment is not None:\n            bluemira_warn(\n                f\"Enrichment set for {self.name} but OpenMC is not available, so \"\n                \"enrichment properties will not be ignored.\"\n            )\n\n        super().__init__(\n            material_tag=name,\n            chemical_equation=symbol,\n            volume_of_unit_cell_cm3=volume_of_unit_cell_cm3,\n            atoms_per_unit_cell=atoms_per_unit_cell,\n            percent_type=\"ao\",\n            temperature_in_K=temperature_in_K,\n            temperature_in_C=to_celsius(temperature_in_K),\n            packing_fraction=packing_fraction,\n            enrichment=enrichment if self.is_enrichable else None,\n            enrichment_target=\"Li6\" if self.is_enrichable else None,\n            enrichment_type=\"ao\" if self.is_enrichable else None,\n            density_unit=\"g/cm3\",\n            zaid_suffix=zaid_suffix,\n            material_id=material_id,\n        )\n\n        self.name = name\n\n        self.specific_heat = specific_heat\n        self.coefficient_thermal_expansion = coefficient_thermal_expansion",
  "def __str__(self):\n        \"\"\"\n        Get a string representation of the UcCompound.\n        \"\"\"\n        return self.name",
  "def Cp(self, temperature: float) -> float:  # noqa :N802\n        \"\"\"\n        Specific heat in J/kg/K\n        \"\"\"\n        return _try_calc_property(self, \"specific_heat\", temperature)",
  "def CTE(  # noqa :N802\n        self, temperature: float, eps_vol: Optional[float] = None\n    ) -> float:\n        \"\"\"\n        Mean coefficient of thermal expansion in 10**-6/T\n        \"\"\"\n        return _try_calc_property(\n            self, \"coefficient_thermal_expansion\", temperature, eps_vol\n        )",
  "def CTE(self, temperature: float, eps_vol: float = 0) -> float:  # noqa :N802\n        \"\"\"\n        https://www.sciencedirect.com/science/article/pii/S0920379602001655\n        \"\"\"\n        # NOTE: Effect of inelastic volumetric strains [%] not negligible\n        # esp_vol calculated roughly as f(T), as per 2M2BH9\n        temperature = to_celsius(temperature)\n        if eps_vol == 0:\n\n            def calc_eps_vol(temp):\n                \"\"\"\n                Calculates inelastic volumetric strains [%] based on T (C)\n                \"\"\"\n                if temp >= 600:\n                    return 0.5\n                elif temp >= 500:\n                    return 0.3\n                elif temp < 500:\n                    return 0.2\n\n            eps_vol = np.vectorize(calc_eps_vol)(temperature)\n        if is_num(eps_vol):\n            eps_vol = eps_vol * np.ones_like(temperature)\n        return (\n            1.81\n            + 0.0012 * temperature\n            - 5e-7 * temperature**2\n            + eps_vol\n            * (\n                9.03\n                - 1.386e-3 * temperature\n                - 7.6e-6 * temperature**2\n                + 2.1e-9 * temperature**3\n            )\n        )",
  "def __init__(\n        self,\n        name: str,\n        isotopes: Dict[str, float],\n        density: MaterialProperty = MaterialProperty(1e-6),\n        density_unit: str = \"g/cm3\",\n        temperature_in_K: Optional[float] = None,  # noqa :N803\n        zaid_suffix: Optional[str] = None,\n        material_id: Optional[str] = None,\n    ):\n        temperature_in_C = None  # noqa :N806\n        if temperature_in_K is not None:\n            temperature_in_C = to_celsius(temperature_in_K)  # noqa :N806\n\n        density_val = None\n        if isinstance(density.value, (int, float)):\n            density_val = density.value\n\n        super().__init__(\n            material_tag=name,\n            density=density_val,\n            density_unit=density_unit,\n            isotopes=isotopes,\n            percent_type=\"ao\",\n            temperature_in_K=temperature_in_K,\n            temperature_in_C=temperature_in_C,\n            material_id=material_id,\n            zaid_suffix=zaid_suffix,\n        )\n\n        self.name = name",
  "def __str__(self) -> str:\n        \"\"\"\n        Get a string representation of the plasma.\n        \"\"\"\n        return self.name",
  "def E(self, temperature: Optional[float] = None) -> float:  # noqa :N802\n        \"\"\"\n        Young's modulus.\n        \"\"\"\n        return 0",
  "def mu(self, temperature: Optional[float] = None) -> float:\n        \"\"\"\n        Poisson's ratio.\n        \"\"\"\n        return 0",
  "def wrapper(*args, **kwargs):\n            temperatures = list_array(args[1])\n\n            if not (temperatures <= t_max).all():\n                raise ValueError(\n                    \"Material property not valid outside of tempe\"\n                    f\"rature range: {temperatures} > T_max = {t_max}\"\n                )\n            if not (temperatures >= t_min).all():\n                raise ValueError(\n                    \"Material property not valid outside of tempe\"\n                    f\"rature range: {temperatures} < T_min = {t_min}\"\n                )\n            temperatures = array_or_num(temperatures)\n            return f(args[0], temperatures, **kwargs)",
  "def calc_eps_vol(temp):\n                \"\"\"\n                Calculates inelastic volumetric strains [%] based on T (C)\n                \"\"\"\n                if temp >= 600:\n                    return 0.5\n                elif temp >= 500:\n                    return 0.3\n                elif temp < 500:\n                    return 0.2",
  "class MaterialCache:\n    \"\"\"\n    A helper class for loading and caching materials.\n\n    Notes\n    -----\n    Extend the `available_classes` attribute to load custom classes.\n    \"\"\"\n\n    _material_dict = {}\n\n    default_classes = [\n        Void,\n        MassFractionMaterial,\n        NbTiSuperconductor,\n        NbSnSuperconductor,\n        Liquid,\n        UnitCellCompound,\n        BePebbleBed,\n        Plasma,\n        HomogenisedMixture,\n    ]\n\n    def __init__(self):\n        self.available_classes = {\n            mat_class.__name__: mat_class for mat_class in self.default_classes\n        }\n\n    def load_from_file(self, path: str) -> Dict[str, Any]:\n        \"\"\"\n        Load materials from a file.\n\n        Parameters\n        ----------\n        path:\n            The path to the file from which to load the materials.\n\n        Returns\n        -------\n        The dictionary containing the loaded materials.\n        \"\"\"\n        with open(path, \"r\") as fh:\n            mats_dict = json.load(fh)\n        return {name: self.load_from_dict(name, mats_dict) for name in mats_dict.keys()}\n\n    def load_from_dict(\n        self, mat_name: str, mats_dict: Dict[str, Any], overwrite: bool = True\n    ):\n        \"\"\"\n        Load a material or mixture from a dictionary.\n\n        Parameters\n        ----------\n        mat_name:\n            The name of the material or mixture.\n        mat_dict:\n            The dictionary containing the material or mixture attributes to be loaded.\n        \"\"\"\n        material_class = mats_dict[mat_name][\"material_class\"]\n        if material_class not in self.available_classes:\n            raise MaterialsError(\n                f\"Request to load unknown material class {material_class}\"\n            )\n\n        if issubclass(self.available_classes[material_class], HomogenisedMixture):\n            self.mixture_from_dict(mat_name, mats_dict)\n        else:\n            self.material_from_dict(mat_name, mats_dict)\n\n    def mixture_from_dict(\n        self, mat_name: str, mats_dict: Dict[str, Any], overwrite: bool = True\n    ):\n        \"\"\"\n        Load a mixture from a dictionary.\n\n        Parameters\n        ----------\n        mat_name:\n            The name of the mixture.\n        mat_dict:\n            The dictionary containing the mixture attributes to be loaded.\n        \"\"\"\n        class_name = mats_dict[mat_name].pop(\"material_class\")\n        mat_class = self.available_classes[class_name]\n        mat = mat_class.from_dict(mat_name, mats_dict, self)\n        self._update_cache(mat_name, mat, overwrite=overwrite)\n\n    def material_from_dict(\n        self, mat_name: str, mats_dict: Dict[str, Any], overwrite: bool = True\n    ):\n        \"\"\"\n        Load a material from a dictionary.\n\n        Parameters\n        ----------\n        mat_name:\n            The name of the material.\n        mat_dict:\n            The dictionary containing the material attributes to be loaded.\n        \"\"\"\n        class_name = mats_dict[mat_name].pop(\"material_class\")\n        mat_class = self.available_classes[class_name]\n        mat = mat_class.from_dict(mat_name, mats_dict)\n        self._update_cache(mat_name, mat, overwrite=overwrite)\n\n    def get_material(self, name: str, clone: bool = True) -> SerialisedMaterial:\n        \"\"\"\n        Get the named material from the material dictionary\n\n        Parameters\n        ----------\n        name:\n            The name of the material to retrieve from the dictionary\n        clone:\n            If True, get a clone (deepcopy) of the material, else get the actual material\n            as stored in the material dictionary. By default True.\n\n        Returns\n        -------\n        The requested material.\n        \"\"\"\n        if clone:\n            return copy.deepcopy(self._material_dict[name])\n        else:\n            return self._material_dict[name]\n\n    def _update_cache(\n        self, mat_name: str, mat: SerialisedMaterial, overwrite: bool = True\n    ):\n        if not overwrite and mat_name in self._material_dict:\n            raise MaterialsError(\n                f\"Attempt to load material {mat_name}, which already \"\n                \"exists in the cache.\"\n            )\n        self._material_dict[mat_name] = mat",
  "def __init__(self):\n        self.available_classes = {\n            mat_class.__name__: mat_class for mat_class in self.default_classes\n        }",
  "def load_from_file(self, path: str) -> Dict[str, Any]:\n        \"\"\"\n        Load materials from a file.\n\n        Parameters\n        ----------\n        path:\n            The path to the file from which to load the materials.\n\n        Returns\n        -------\n        The dictionary containing the loaded materials.\n        \"\"\"\n        with open(path, \"r\") as fh:\n            mats_dict = json.load(fh)\n        return {name: self.load_from_dict(name, mats_dict) for name in mats_dict.keys()}",
  "def load_from_dict(\n        self, mat_name: str, mats_dict: Dict[str, Any], overwrite: bool = True\n    ):\n        \"\"\"\n        Load a material or mixture from a dictionary.\n\n        Parameters\n        ----------\n        mat_name:\n            The name of the material or mixture.\n        mat_dict:\n            The dictionary containing the material or mixture attributes to be loaded.\n        \"\"\"\n        material_class = mats_dict[mat_name][\"material_class\"]\n        if material_class not in self.available_classes:\n            raise MaterialsError(\n                f\"Request to load unknown material class {material_class}\"\n            )\n\n        if issubclass(self.available_classes[material_class], HomogenisedMixture):\n            self.mixture_from_dict(mat_name, mats_dict)\n        else:\n            self.material_from_dict(mat_name, mats_dict)",
  "def mixture_from_dict(\n        self, mat_name: str, mats_dict: Dict[str, Any], overwrite: bool = True\n    ):\n        \"\"\"\n        Load a mixture from a dictionary.\n\n        Parameters\n        ----------\n        mat_name:\n            The name of the mixture.\n        mat_dict:\n            The dictionary containing the mixture attributes to be loaded.\n        \"\"\"\n        class_name = mats_dict[mat_name].pop(\"material_class\")\n        mat_class = self.available_classes[class_name]\n        mat = mat_class.from_dict(mat_name, mats_dict, self)\n        self._update_cache(mat_name, mat, overwrite=overwrite)",
  "def material_from_dict(\n        self, mat_name: str, mats_dict: Dict[str, Any], overwrite: bool = True\n    ):\n        \"\"\"\n        Load a material from a dictionary.\n\n        Parameters\n        ----------\n        mat_name:\n            The name of the material.\n        mat_dict:\n            The dictionary containing the material attributes to be loaded.\n        \"\"\"\n        class_name = mats_dict[mat_name].pop(\"material_class\")\n        mat_class = self.available_classes[class_name]\n        mat = mat_class.from_dict(mat_name, mats_dict)\n        self._update_cache(mat_name, mat, overwrite=overwrite)",
  "def get_material(self, name: str, clone: bool = True) -> SerialisedMaterial:\n        \"\"\"\n        Get the named material from the material dictionary\n\n        Parameters\n        ----------\n        name:\n            The name of the material to retrieve from the dictionary\n        clone:\n            If True, get a clone (deepcopy) of the material, else get the actual material\n            as stored in the material dictionary. By default True.\n\n        Returns\n        -------\n        The requested material.\n        \"\"\"\n        if clone:\n            return copy.deepcopy(self._material_dict[name])\n        else:\n            return self._material_dict[name]",
  "def _update_cache(\n        self, mat_name: str, mat: SerialisedMaterial, overwrite: bool = True\n    ):\n        if not overwrite and mat_name in self._material_dict:\n            raise MaterialsError(\n                f\"Attempt to load material {mat_name}, which already \"\n                \"exists in the cache.\"\n            )\n        self._material_dict[mat_name] = mat",
  "class MaterialsError(BluemiraError):\n    \"\"\"\n    Error type for the materials module.\n    \"\"\"\n\n    pass",
  "class XZGeometryInterpolator(abc.ABC):\n    \"\"\"\n    Abstract base class for 2-D x-z geometry interpolation to normalised [0, 1] space.\n\n    By convention, normalised x-z space is oriented counter-clockwise w.r.t. [0, 1, 0].\n\n    Parameters\n    ----------\n    geometry:\n        Geometry to interpolate with\n    \"\"\"\n\n    def __init__(self, geometry: BluemiraWire):\n        self.geometry = geometry\n\n    def _get_xz_coordinates(self):\n        \"\"\"\n        Get discretised x-z coordinates of the geometry.\n        \"\"\"\n        coordinates = self.geometry.discretize(\n            byedges=True, dl=self.geometry.length / 1000\n        )\n        coordinates.set_ccw([0, 1, 0])\n        return coordinates.xz\n\n    @abc.abstractmethod\n    def to_xz(\n        self, l_value: Union[float, np.ndarray]\n    ) -> Union[Tuple[float, float], Tuple[np.ndarray, np.ndarray]]:\n        \"\"\"\n        Convert parametric-space 'L' values to physical x-z space.\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def to_L(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Convert physical x-z space values to parametric-space 'L' values.\n        \"\"\"\n        pass\n\n    @abc.abstractproperty\n    def dimension(self) -> int:\n        \"\"\"\n        The dimension of the parametric space\n        \"\"\"\n        pass",
  "class PathInterpolator(XZGeometryInterpolator):\n    \"\"\"\n    Sets up an x-z path for a point to move along.\n\n    The path is treated as flat in the x-z plane.\n    \"\"\"\n\n    def to_xz(\n        self, l_values: Union[float, np.ndarray]\n    ) -> Union[Tuple[float, float], Tuple[np.ndarray, np.ndarray]]:\n        \"\"\"\n        Convert parametric-space 'L' values to physical x-z space.\n        \"\"\"\n        l_values = np.clip(l_values, 0.0, 1.0)\n        if is_num(l_values):\n            return self.geometry.value_at(alpha=l_values)[[0, 2]]\n\n        x, z = np.zeros(len(l_values)), np.zeros(len(l_values))\n        for i, lv in enumerate(l_values):\n            x[i], z[i] = self.geometry.value_at(alpha=lv)[[0, 2]]\n\n        return x, z\n\n    def to_L(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Convert physical x-z space values to parametric-space 'L' values.\n        \"\"\"\n        if is_num(x):\n            return self.geometry.parameter_at([x, 0, z], tolerance=VERY_BIG)\n\n        l_values = np.zeros(len(x))\n        for i, (xi, zi) in enumerate(zip(x, z)):\n            l_values[i] = self.geometry.parameter_at([xi, 0, zi], tolerance=VERY_BIG)\n        return l_values\n\n    @property\n    def dimension(self) -> int:\n        \"\"\"\n        Dimension of the parametric space of the PathInterpolator\n        \"\"\"\n        return 1",
  "class RegionInterpolator(XZGeometryInterpolator):\n    \"\"\"\n    Sets up an x-z region for a point to move within.\n\n    The region is treated as a flat x-z surface.\n\n    The normalisation occurs by cutting the shape in two axes and\n    normalising over the cut length within the region.\n\n    Currently this is limited to convex polygons.\n\n    Generalisation to all polygons is possible but unimplemented\n    and possibly quite slow when converting from normalised to real coordinates.\n\n    When the point position provided is outside the given region the point will\n    be moved to the closest edge of the region.\n\n    The mapping from outside to the edge of the region is not strictly defined.\n    The only certainty is that the point will be moved into the region.\n\n    Parameters\n    ----------\n    geometry:\n        Region to interpolate within\n    \"\"\"\n\n    def __init__(self, geometry: BluemiraWire):\n        super().__init__(geometry)\n        self._check_geometry_feasibility(geometry)\n        self.z_min = geometry.bounding_box.z_min\n        self.z_max = geometry.bounding_box.z_max\n\n    def _check_geometry_feasibility(self, geometry: BluemiraWire):\n        \"\"\"\n        Checks the provided region is convex.\n\n        This is a current limitation of RegionInterpolator\n        not providing a 'smooth' interpolation surface.\n\n        Parameters\n        ----------\n        geometry:\n            Region to check\n\n        Raises\n        ------\n        PositionerError\n            When geometry is not a convex\n        \"\"\"\n        if not self.geometry.is_closed:\n            raise PositionerError(\"RegionInterpolator can only handle closed wires.\")\n\n        xz_coordinates = self._get_xz_coordinates()\n        hull = ConvexHull(xz_coordinates.T)\n        # Yes, the \"area\" of a 2-D scipy ConvexHull is its perimeter...\n        if not np.allclose(hull.area, geometry.length, atol=EPS):\n            raise PositionerError(\n                \"RegionInterpolator can only handle convex geometries. Perimeter \"\n                f\"difference between convex hull and geometry: {hull.area - geometry.length}\"\n            )\n\n    def to_xz(\n        self, l_values: Union[Tuple[float, float], Tuple[np.ndarray, np.ndarray]]\n    ) -> Union[Tuple[float, float], Tuple[np.ndarray, np.ndarray]]:\n        \"\"\"\n        Convert parametric-space 'L' values to physical x-z space.\n\n        Parameters\n        ----------\n        l_values:\n            Coordinates in normalised space\n\n        Returns\n        -------\n        x:\n            x coordinate in real space\n        z:\n            z coordinate in real space\n\n        Raises\n        ------\n        GeometryError\n            When loop is not a Convex Hull\n\n        \"\"\"\n        l_0, l_1 = l_values\n        z = self.z_min + (self.z_max - self.z_min) * l_1\n\n        plane = BluemiraPlane.from_3_points([0, 0, z], [1, 0, z], [0, 1, z])\n\n        intersect = slice_shape(self.geometry, plane)\n        if len(intersect) == 1:\n            x = intersect[0][0]\n        elif len(intersect) == 2:\n            x_min, x_max = sorted([intersect[0][0], intersect[1][0]])\n            x = x_min + (x_max - x_min) * l_0\n        else:\n            raise PositionerError(\n                \"Unexpected number of intersections in x-z conversion.\"\n            )\n\n        return x, z\n\n    def to_L(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[Tuple[float, float], Tuple[np.ndarray, np.ndarray]]:\n        \"\"\"\n        Convert physical x-z space values to parametric-space 'L' values.\n\n        Parameters\n        ----------\n        x:\n            x coordinate in real space\n        z:\n            z coordinate in real space\n\n        Returns\n        -------\n        l_1:\n            Coordinate 1 in normalised space\n        l_2:\n            Coordinate 2 in normalised space\n\n        Raises\n        ------\n        GeometryError\n            When loop is not a Convex Hull\n\n        \"\"\"\n        l_1 = (z - self.z_min) / (self.z_max - self.z_min)\n        l_1 = np.clip(l_1, 0.0, 1.0)\n\n        plane = BluemiraPlane.from_3_points([x, 0, z], [x + 1, 0, z], [x, 1, z])\n        intersect = slice_shape(self.geometry, plane)\n\n        return self._intersect_filter(x, l_1, intersect)\n\n    def _intersect_filter(\n        self, x: float, l_1: float, intersect: BluemiraPlane\n    ) -> Tuple[float, float]:\n        \"\"\"\n        Checks where points are based on number of intersections\n        with a plane. Should initially be called with a plane involving z.\n\n        No intersection could mean above 1 edge therefore a plane in xy\n        is checked before recalling this function.\n        If there is one intersection point we are on an edge (either bottom or top),\n        if there is two intersection points we are in the region,\n        otherwise the region is not a convex hull.\n\n        Parameters\n        ----------\n        x:\n            x coordinate\n        l_1:\n            Normalised z coordinate\n        intersect:\n            A plane through xz\n\n        Returns\n        -------\n        l_1:\n            Coordinate 1 in normalised space\n        l_2:\n            Coordinate 2 in normalised space\n\n        Raises\n        ------\n        PositionerError\n            When geometry is not a convex\n        \"\"\"\n        if intersect is None:\n            plane = BluemiraPlane.from_3_points([x, 0, 0], [x + 1, 0, 0], [x, 1, 0])\n            intersect = slice_shape(self.geometry, plane)\n            l_0, l_1 = self._intersect_filter(\n                x, l_1, [False] if intersect is None else intersect\n            )\n        elif len(intersect) == 2:\n            x_min, x_max = sorted([intersect[0][0], intersect[1][0]])\n            l_0 = np.clip((x - x_min) / (x_max - x_min), 0.0, 1.0)\n        elif len(intersect) == 1:\n            l_0 = float(l_1 == 1.0)\n        else:\n            raise PositionerError(\"Unexpected number of intersections in L conversion.\")\n        return l_0, l_1\n\n    @property\n    def dimension(self):\n        \"\"\"\n        Dimension of the parametric space of the RegionInterpolator\n        \"\"\"\n        return 2",
  "class PositionMapper:\n    \"\"\"\n    Positioning tool for use in optimisation\n\n    Parameters\n    ----------\n    interpolators:\n        The ordered list of geometry interpolators\n    \"\"\"\n\n    def __init__(self, interpolators: Dict[str, XZGeometryInterpolator]):\n        self.interpolators = interpolators\n\n    def _check_length(self, thing):\n        \"\"\"\n        Check that something is the same length as the number of available interpolators.\n        \"\"\"\n        if len(thing) != len(self.interpolators):\n            raise PositionerError(\n                f\"Object of length: {len(thing)} not of length {len(self.interpolators)}\"\n            )\n\n    def _vector_to_list(self, l_values):\n        \"\"\"\n        Convert a vector of l_values into a ragged list if necessary\n        \"\"\"\n        list_values = []\n        for i, interpolator in enumerate(self.interpolators.values()):\n            values = l_values[i : i + interpolator.dimension]\n            list_values.append(values)\n        return list_values\n\n    def to_xz(self, l_values: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Convert a set of parametric-space values to physical x-z coordinates.\n\n        Parameters\n        ----------\n        l_values:\n            The set of parametric-space values to convert\n\n        Returns\n        -------\n        x:\n            Array of x coordinates\n        z:\n            Array of z coordinates\n        \"\"\"\n        l_values = self._vector_to_list(l_values)\n        self._check_length(l_values)\n        return np.array(\n            [\n                tool.to_xz(l_values[i])\n                for i, tool, in enumerate(self.interpolators.values())\n            ]\n        ).T\n\n    def to_xz_dict(self, l_values: np.ndarray) -> Dict[str, np.ndarray]:\n        \"\"\"\n        Convert a set of parametric space values to physical coordinates in a dictionary\n        form.\n\n        Parameters\n        ----------\n        l_values:\n            The set of parametric-space values to convert\n\n        Returns\n        -------\n        Dictionary of x-z values corresponding to each interpolator\n        \"\"\"\n        l_values = self._vector_to_list(l_values)\n        self._check_length(l_values)\n        xz_dict = {}\n        for i, (key, tool) in enumerate(self.interpolators.items()):\n            xz_dict[key] = tool.to_xz(l_values[i])\n        return xz_dict\n\n    def to_L(self, x: np.ndarray, z: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Convert a set of physical x-z coordinates to parametric-space values.\n\n        Parameters\n        ----------\n        x:\n            The x coordinates to convert\n        z:\n            The z coordinates to convert\n\n        Returns\n        -------\n        l_values:\n            The set of parametric-space values\n        \"\"\"\n        self._check_length(x)\n        self._check_length(z)\n        l_values = np.zeros(self.dimension)\n        for i, tool in enumerate(self.interpolators.values()):\n            l_values[i : i + tool.dimension] = tool.to_L(x[i], z[i])\n        return np.array(l_values)\n\n    @property\n    def dimension(self) -> int:\n        \"\"\"\n        The total dimension of the parametric space\n        \"\"\"\n        return sum([interp.dimension for interp in self.interpolators.values()])",
  "def __init__(self, geometry: BluemiraWire):\n        self.geometry = geometry",
  "def _get_xz_coordinates(self):\n        \"\"\"\n        Get discretised x-z coordinates of the geometry.\n        \"\"\"\n        coordinates = self.geometry.discretize(\n            byedges=True, dl=self.geometry.length / 1000\n        )\n        coordinates.set_ccw([0, 1, 0])\n        return coordinates.xz",
  "def to_xz(\n        self, l_value: Union[float, np.ndarray]\n    ) -> Union[Tuple[float, float], Tuple[np.ndarray, np.ndarray]]:\n        \"\"\"\n        Convert parametric-space 'L' values to physical x-z space.\n        \"\"\"\n        pass",
  "def to_L(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Convert physical x-z space values to parametric-space 'L' values.\n        \"\"\"\n        pass",
  "def dimension(self) -> int:\n        \"\"\"\n        The dimension of the parametric space\n        \"\"\"\n        pass",
  "def to_xz(\n        self, l_values: Union[float, np.ndarray]\n    ) -> Union[Tuple[float, float], Tuple[np.ndarray, np.ndarray]]:\n        \"\"\"\n        Convert parametric-space 'L' values to physical x-z space.\n        \"\"\"\n        l_values = np.clip(l_values, 0.0, 1.0)\n        if is_num(l_values):\n            return self.geometry.value_at(alpha=l_values)[[0, 2]]\n\n        x, z = np.zeros(len(l_values)), np.zeros(len(l_values))\n        for i, lv in enumerate(l_values):\n            x[i], z[i] = self.geometry.value_at(alpha=lv)[[0, 2]]\n\n        return x, z",
  "def to_L(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Convert physical x-z space values to parametric-space 'L' values.\n        \"\"\"\n        if is_num(x):\n            return self.geometry.parameter_at([x, 0, z], tolerance=VERY_BIG)\n\n        l_values = np.zeros(len(x))\n        for i, (xi, zi) in enumerate(zip(x, z)):\n            l_values[i] = self.geometry.parameter_at([xi, 0, zi], tolerance=VERY_BIG)\n        return l_values",
  "def dimension(self) -> int:\n        \"\"\"\n        Dimension of the parametric space of the PathInterpolator\n        \"\"\"\n        return 1",
  "def __init__(self, geometry: BluemiraWire):\n        super().__init__(geometry)\n        self._check_geometry_feasibility(geometry)\n        self.z_min = geometry.bounding_box.z_min\n        self.z_max = geometry.bounding_box.z_max",
  "def _check_geometry_feasibility(self, geometry: BluemiraWire):\n        \"\"\"\n        Checks the provided region is convex.\n\n        This is a current limitation of RegionInterpolator\n        not providing a 'smooth' interpolation surface.\n\n        Parameters\n        ----------\n        geometry:\n            Region to check\n\n        Raises\n        ------\n        PositionerError\n            When geometry is not a convex\n        \"\"\"\n        if not self.geometry.is_closed:\n            raise PositionerError(\"RegionInterpolator can only handle closed wires.\")\n\n        xz_coordinates = self._get_xz_coordinates()\n        hull = ConvexHull(xz_coordinates.T)\n        # Yes, the \"area\" of a 2-D scipy ConvexHull is its perimeter...\n        if not np.allclose(hull.area, geometry.length, atol=EPS):\n            raise PositionerError(\n                \"RegionInterpolator can only handle convex geometries. Perimeter \"\n                f\"difference between convex hull and geometry: {hull.area - geometry.length}\"\n            )",
  "def to_xz(\n        self, l_values: Union[Tuple[float, float], Tuple[np.ndarray, np.ndarray]]\n    ) -> Union[Tuple[float, float], Tuple[np.ndarray, np.ndarray]]:\n        \"\"\"\n        Convert parametric-space 'L' values to physical x-z space.\n\n        Parameters\n        ----------\n        l_values:\n            Coordinates in normalised space\n\n        Returns\n        -------\n        x:\n            x coordinate in real space\n        z:\n            z coordinate in real space\n\n        Raises\n        ------\n        GeometryError\n            When loop is not a Convex Hull\n\n        \"\"\"\n        l_0, l_1 = l_values\n        z = self.z_min + (self.z_max - self.z_min) * l_1\n\n        plane = BluemiraPlane.from_3_points([0, 0, z], [1, 0, z], [0, 1, z])\n\n        intersect = slice_shape(self.geometry, plane)\n        if len(intersect) == 1:\n            x = intersect[0][0]\n        elif len(intersect) == 2:\n            x_min, x_max = sorted([intersect[0][0], intersect[1][0]])\n            x = x_min + (x_max - x_min) * l_0\n        else:\n            raise PositionerError(\n                \"Unexpected number of intersections in x-z conversion.\"\n            )\n\n        return x, z",
  "def to_L(\n        self, x: Union[float, np.ndarray], z: Union[float, np.ndarray]\n    ) -> Union[Tuple[float, float], Tuple[np.ndarray, np.ndarray]]:\n        \"\"\"\n        Convert physical x-z space values to parametric-space 'L' values.\n\n        Parameters\n        ----------\n        x:\n            x coordinate in real space\n        z:\n            z coordinate in real space\n\n        Returns\n        -------\n        l_1:\n            Coordinate 1 in normalised space\n        l_2:\n            Coordinate 2 in normalised space\n\n        Raises\n        ------\n        GeometryError\n            When loop is not a Convex Hull\n\n        \"\"\"\n        l_1 = (z - self.z_min) / (self.z_max - self.z_min)\n        l_1 = np.clip(l_1, 0.0, 1.0)\n\n        plane = BluemiraPlane.from_3_points([x, 0, z], [x + 1, 0, z], [x, 1, z])\n        intersect = slice_shape(self.geometry, plane)\n\n        return self._intersect_filter(x, l_1, intersect)",
  "def _intersect_filter(\n        self, x: float, l_1: float, intersect: BluemiraPlane\n    ) -> Tuple[float, float]:\n        \"\"\"\n        Checks where points are based on number of intersections\n        with a plane. Should initially be called with a plane involving z.\n\n        No intersection could mean above 1 edge therefore a plane in xy\n        is checked before recalling this function.\n        If there is one intersection point we are on an edge (either bottom or top),\n        if there is two intersection points we are in the region,\n        otherwise the region is not a convex hull.\n\n        Parameters\n        ----------\n        x:\n            x coordinate\n        l_1:\n            Normalised z coordinate\n        intersect:\n            A plane through xz\n\n        Returns\n        -------\n        l_1:\n            Coordinate 1 in normalised space\n        l_2:\n            Coordinate 2 in normalised space\n\n        Raises\n        ------\n        PositionerError\n            When geometry is not a convex\n        \"\"\"\n        if intersect is None:\n            plane = BluemiraPlane.from_3_points([x, 0, 0], [x + 1, 0, 0], [x, 1, 0])\n            intersect = slice_shape(self.geometry, plane)\n            l_0, l_1 = self._intersect_filter(\n                x, l_1, [False] if intersect is None else intersect\n            )\n        elif len(intersect) == 2:\n            x_min, x_max = sorted([intersect[0][0], intersect[1][0]])\n            l_0 = np.clip((x - x_min) / (x_max - x_min), 0.0, 1.0)\n        elif len(intersect) == 1:\n            l_0 = float(l_1 == 1.0)\n        else:\n            raise PositionerError(\"Unexpected number of intersections in L conversion.\")\n        return l_0, l_1",
  "def dimension(self):\n        \"\"\"\n        Dimension of the parametric space of the RegionInterpolator\n        \"\"\"\n        return 2",
  "def __init__(self, interpolators: Dict[str, XZGeometryInterpolator]):\n        self.interpolators = interpolators",
  "def _check_length(self, thing):\n        \"\"\"\n        Check that something is the same length as the number of available interpolators.\n        \"\"\"\n        if len(thing) != len(self.interpolators):\n            raise PositionerError(\n                f\"Object of length: {len(thing)} not of length {len(self.interpolators)}\"\n            )",
  "def _vector_to_list(self, l_values):\n        \"\"\"\n        Convert a vector of l_values into a ragged list if necessary\n        \"\"\"\n        list_values = []\n        for i, interpolator in enumerate(self.interpolators.values()):\n            values = l_values[i : i + interpolator.dimension]\n            list_values.append(values)\n        return list_values",
  "def to_xz(self, l_values: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Convert a set of parametric-space values to physical x-z coordinates.\n\n        Parameters\n        ----------\n        l_values:\n            The set of parametric-space values to convert\n\n        Returns\n        -------\n        x:\n            Array of x coordinates\n        z:\n            Array of z coordinates\n        \"\"\"\n        l_values = self._vector_to_list(l_values)\n        self._check_length(l_values)\n        return np.array(\n            [\n                tool.to_xz(l_values[i])\n                for i, tool, in enumerate(self.interpolators.values())\n            ]\n        ).T",
  "def to_xz_dict(self, l_values: np.ndarray) -> Dict[str, np.ndarray]:\n        \"\"\"\n        Convert a set of parametric space values to physical coordinates in a dictionary\n        form.\n\n        Parameters\n        ----------\n        l_values:\n            The set of parametric-space values to convert\n\n        Returns\n        -------\n        Dictionary of x-z values corresponding to each interpolator\n        \"\"\"\n        l_values = self._vector_to_list(l_values)\n        self._check_length(l_values)\n        xz_dict = {}\n        for i, (key, tool) in enumerate(self.interpolators.items()):\n            xz_dict[key] = tool.to_xz(l_values[i])\n        return xz_dict",
  "def to_L(self, x: np.ndarray, z: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Convert a set of physical x-z coordinates to parametric-space values.\n\n        Parameters\n        ----------\n        x:\n            The x coordinates to convert\n        z:\n            The z coordinates to convert\n\n        Returns\n        -------\n        l_values:\n            The set of parametric-space values\n        \"\"\"\n        self._check_length(x)\n        self._check_length(z)\n        l_values = np.zeros(self.dimension)\n        for i, tool in enumerate(self.interpolators.values()):\n            l_values[i : i + tool.dimension] = tool.to_L(x[i], z[i])\n        return np.array(l_values)",
  "def dimension(self) -> int:\n        \"\"\"\n        The total dimension of the parametric space\n        \"\"\"\n        return sum([interp.dimension for interp in self.interpolators.values()])",
  "class OptVarVarDictValueT(TypedDict, total=False):\n    \"\"\"Typed dictionary for a the values of an OptVariable from a var_dict.\"\"\"\n\n    value: float\n    lower_bound: float\n    upper_bound: float\n    fixed: bool",
  "class OptVarDictT(TypedDict):\n    \"\"\"Typed dictionary representation of an OptVariable.\"\"\"\n\n    name: str\n    value: float\n    lower_bound: float\n    upper_bound: float\n    fixed: bool\n    description: str",
  "class OptVarSerializedT(TypedDict):\n    \"\"\"Typed dictionary for a serialised OptVariable.\"\"\"\n\n    value: float\n    lower_bound: float\n    upper_bound: float\n    fixed: bool\n    description: str",
  "class OptVariable:\n    \"\"\"\n    A bounded variable, uniformly normalised from 0 to 1 w.r.t. its bounds.\n\n    Parameters\n    ----------\n    name:\n        Name of the variable\n    value: float\n        Value of the variable\n    lower_bound:\n        Lower bound of the variable\n    upper_bound:\n        Upper bound of the variable\n    fixed:\n        Whether or not the variable is to be held constant\n    description:\n        Description of the variable\n    \"\"\"\n\n    __slots__ = (\"name\", \"_value\", \"lower_bound\", \"upper_bound\", \"fixed\", \"description\")\n\n    def __init__(\n        self,\n        name: str,\n        value: float,\n        lower_bound: float,\n        upper_bound: float,\n        fixed: bool = False,\n        description: Optional[str] = None,\n    ):\n        self.name = name\n\n        self._value = value\n        self.lower_bound = lower_bound\n        self.upper_bound = upper_bound\n        self.fixed = fixed\n        self.description = description\n\n        self._validate_bounds()\n        self._validate_value(value)\n\n    @property\n    def value(self) -> float:\n        \"\"\"\n        The value of the variable.\n        \"\"\"\n        return self._value\n\n    @value.setter\n    def value(self, value):\n        \"\"\"\n        Set the value of the variable, enforcing bounds.\n        \"\"\"\n        if self.fixed:\n            raise OptVariablesError(\"Cannot set the value of a fixed variable.\")\n\n        self._validate_value(value)\n        self._value = value\n\n    @property\n    def normalised_value(self) -> float:\n        \"\"\"\n        The value uniformly normalised between 0 and 1 w.r.t. its bounds\n        \"\"\"\n        return (self.value - self.lower_bound) / (self.upper_bound - self.lower_bound)\n\n    def from_normalised(self, norm: float) -> float:\n        \"\"\"\n        The value from a normalised value between [0 -> 1], w.r.t its bounds\n        \"\"\"\n        return self.lower_bound + norm * (self.upper_bound - self.lower_bound)\n\n    def fix(self, value: Optional[float] = None):\n        \"\"\"\n        Fix the variable at a specified value. Ignores bounds.\n\n        Parameters\n        ----------\n        value:\n            Value at which to fix the variable.\n        \"\"\"\n        self.fixed = True\n        if value is not None:\n            self._value = value\n\n    def adjust(\n        self,\n        value: Optional[float] = None,\n        lower_bound: Optional[float] = None,\n        upper_bound: Optional[float] = None,\n        strict_bounds: bool = True,\n    ):\n        \"\"\"\n        Adjust the OptVariable.\n\n        Parameters\n        ----------\n        value:\n            Value of the variable to set\n        lower_bound:\n            Value of the lower bound to set\n        upper_bound:\n            Value of the upper to set\n        strict_bounds:\n            If True, will raise errors if values are outside the bounds. If False, the\n            bounds are dynamically adjusted to match the value.\n        \"\"\"\n        if self.fixed:\n            raise OptVariablesError(f\"'{self.name}' is fixed and cannot be adjusted.\")\n\n        if lower_bound is not None:\n            self.lower_bound = lower_bound\n\n        if upper_bound is not None:\n            self.upper_bound = upper_bound\n\n        if value is not None:\n            if not strict_bounds:\n                self._adjust_bounds_to(value)\n            self.value = value\n\n        self._validate_bounds()\n\n    def as_dict(self) -> OptVarDictT:\n        \"\"\"Dictionary representation of OptVariable, can be used for serialisation\"\"\"\n        return {\n            \"name\": self.name,\n            \"value\": self.value,\n            \"lower_bound\": self.lower_bound,\n            \"upper_bound\": self.upper_bound,\n            \"fixed\": self.fixed,\n            \"description\": self.description or \"\",\n        }\n\n    def as_serializable(self) -> OptVarSerializedT:\n        \"\"\"Dictionary representation of OptVariable\"\"\"\n        return {\n            \"value\": self.value,\n            \"lower_bound\": self.lower_bound,\n            \"upper_bound\": self.upper_bound,\n            \"fixed\": self.fixed,\n            \"description\": self.description or \"\",\n        }\n\n    @classmethod\n    def from_serialized(cls, name: str, data: OptVarSerializedT):\n        \"\"\"Create an OptVariable from a dictionary\"\"\"\n        return cls(\n            name=name,\n            value=data[\"value\"],\n            lower_bound=data[\"lower_bound\"],\n            upper_bound=data[\"upper_bound\"],\n            fixed=data[\"fixed\"],\n            description=data[\"description\"],\n        )\n\n    def _adjust_bounds_to(self, value):\n        \"\"\"\n        Adjust the bounds to the value\n        \"\"\"\n        if value < self.lower_bound:\n            bluemira_warn(\n                f\"OptVariable '{self.name}': value was set to below its lower bound. Adjusting bound.\"\n            )\n            self.lower_bound = value\n\n        if value > self.upper_bound:\n            bluemira_warn(\n                f\"OptVariable '{self.name}': value was set to above its upper bound. Adjusting bound.\"\n            )\n            self.upper_bound = value\n\n    def _validate_bounds(self):\n        if self.lower_bound > self.upper_bound:\n            raise OptVariablesError(\n                f\"OptVariable '{self.name}' - lower bound is higher than upper bound.\"\n            )\n\n    def _validate_value(self, value):\n        if not self.lower_bound <= value <= self.upper_bound:\n            raise OptVariablesError(\n                f\"OptVariable '{self.name}' - value {value} is out of bounds: [{self.lower_bound}, {self.upper_bound}]\"\n            )\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Representation of OptVariable\n        \"\"\"\n        lower_bound, upper_bound, fixed = (\n            self.lower_bound,\n            self.upper_bound,\n            self.fixed,\n        )\n        return f\"{self.__class__.__name__}({self.name}, {self.value}, {lower_bound=}, {upper_bound=}, {fixed=})\"\n\n    def __str__(self) -> str:\n        \"\"\"\n        Pretty representation of OptVariable\n        \"\"\"\n        bound = (\n            f\" Bounds: ({self.lower_bound}, {self.upper_bound})\"\n            if not self.fixed\n            else \"\"\n        )\n        descr = f' \"{self.description}\"' if self.description is not None else \"\"\n\n        return f\"{self.name} = {self.value}{bound}{descr}\"\n\n    def __add__(self, other: OptVariable):\n        \"\"\"The sum of two OptVariables is the sum of their values\"\"\"\n        if isinstance(other, OptVariable):\n            return self.value + other.value\n        elif isinstance(other, (int, float, np.floating)):\n            return self.value + other\n        else:\n            raise TypeError(f\"Cannot add OptVariable with {type(other)}\")\n\n    def __sub__(self, other: OptVariable):\n        \"\"\"The subtraction of two OptVariables is the subtraction of their values\"\"\"\n        if isinstance(other, OptVariable):\n            return self.value - other.value\n        elif isinstance(other, (int, float, np.floating)):\n            return self.value - other\n        else:\n            raise TypeError(f\"Cannot subtract OptVariable with {type(other)}\")\n\n    def __mul__(self, other: OptVariable):\n        \"\"\"\n        The multiplication of two OptVariables is\n        the multiplication of their values\n        \"\"\"\n        if isinstance(other, OptVariable):\n            return self.value * other.value\n        elif isinstance(other, (int, float, np.floating)):\n            return self.value * other\n        else:\n            raise TypeError(f\"Cannot multiply OptVariable with {type(other)}\")",
  "def ov(\n    name: str,\n    value: float,\n    lower_bound: float,\n    upper_bound: float,\n    fixed: bool = False,\n    description: Optional[str] = None,\n):\n    \"\"\"Field factory for OptVariable\"\"\"\n    return field(\n        default_factory=lambda: OptVariable(\n            name, value, lower_bound, upper_bound, fixed, description\n        )\n    )",
  "class OptVariablesFrame:\n    \"\"\"\n    Class to model the variables for an optimisation\n    \"\"\"\n\n    def __new__(cls, *args, **kwargs):\n        \"\"\"\n        Prevent instantiation of this class.\n        \"\"\"\n        if cls == OptVariablesFrame:\n            raise TypeError(\n                \"Cannot instantiate an OptVariablesFrame directly. It must be subclassed.\"\n            )\n        if not hasattr(cls, \"__dataclass_fields__\"):\n            raise TypeError(f\"{cls} must be annotated with '@dataclass'\")\n        for field_name in cls.__dataclass_fields__:  # type: ignore\n            dcf: Field = cls.__dataclass_fields__[field_name]  # type: ignore\n            fact_inst = dcf.default_factory() if dcf.default_factory != MISSING else None\n            if fact_inst is None:\n                raise TypeError(\n                    f\"{field_name} must be wrapped in with 'ov' field factory\"\n                )\n            if not isinstance(fact_inst, OptVariable):\n                raise TypeError(\n                    f\"OptVariablesFrame contains non-OptVariable object '{field_name}: {type(fact_inst)}'\"\n                )\n            if field_name != fact_inst.name:\n                raise TypeError(\n                    f\"OptVariablesFrame contains OptVariable with incorrect name '{fact_inst.name}', defined as '{field_name}'\"\n                )\n\n        return super().__new__(cls)\n\n    def __iter__(self) -> Generator[OptVariable, None, None]:\n        \"\"\"\n        Iterate over this frame's parameters.\n\n        The order is based on the order in which the parameters were\n        declared.\n        \"\"\"\n        for field_name in self.__dataclass_fields__:  # type: ignore\n            yield getattr(self, field_name)\n\n    def __getitem__(self, name: str) -> OptVariable:\n        \"\"\"\n        Dictionary-like access to variables.\n\n        Parameters\n        ----------\n        name:\n            Name of the variable to get\n        \"\"\"\n        return getattr(self, name)\n\n    def adjust_variable(\n        self,\n        name: str,\n        value: Optional[float] = None,\n        lower_bound: Optional[float] = None,\n        upper_bound: Optional[float] = None,\n        fixed: bool = False,\n        strict_bounds: bool = True,\n    ):\n        \"\"\"\n        Adjust a variable in the frame.\n\n        Parameters\n        ----------\n        name:\n            Name of the variable to adjust\n        value:\n            Value of the variable to set\n        lower_bound:\n            Value of the lower bound to set\n        upper_bound:\n            Value of the upper to set\n        fixed:\n            Whether or not the variable is to be held constant\n        strict_bounds: bool\n            If True, will raise errors if values are outside the bounds. If False, the\n            bounds are dynamically adjusted to match the value.\n        \"\"\"\n        opt_var = self[name]\n        if fixed:\n            # sets the bounds and fixes the var ignoring them\n            opt_var.adjust(\n                lower_bound=lower_bound,\n                upper_bound=upper_bound,\n                strict_bounds=strict_bounds,\n            )\n            opt_var.fix(value)\n        else:\n            opt_var.adjust(value, lower_bound, upper_bound, strict_bounds)\n\n    def adjust_variables(\n        self,\n        var_dict: Optional[VarDictT] = None,\n        strict_bounds=True,\n    ):\n        \"\"\"\n        Adjust multiple variables in the frame.\n\n        Parameters\n        ----------\n        var_dict:\n            Dictionary with which to update the set, of the form\n            {\"var_name\": {\"value\": v, \"lower_bound\": lb, \"upper_bound\": ub}, ...}\n        strict_bounds: bool\n            If True, will raise errors if values are outside the bounds. If False, the\n            bounds are dynamically adjusted to match the value.\n        \"\"\"\n        if var_dict is not None:\n            for k, v in var_dict.items():\n                args = [\n                    v.get(\"value\", None),\n                    v.get(\"lower_bound\", None),\n                    v.get(\"upper_bound\", None),\n                    v.get(\"fixed\", None),\n                ]\n                if all([i is None for i in args]):\n                    raise OptVariablesError(\n                        \"When adjusting variables in an OptVariableFrame instance, the dictionary\"\n                        \" must be of the form: {'var_name': {'value': v, 'lower_bound': lb, 'upper_bound': ub}, ...}\"\n                    )\n                self.adjust_variable(k, *args, strict_bounds=strict_bounds)\n\n    def fix_variable(self, name: str, value: Optional[float] = None):\n        \"\"\"\n        Fix a variable in the frame, removing it from optimisation but preserving a\n        constant value.\n\n        Parameters\n        ----------\n        name:\n            Name of the variable to fix\n        value:\n            Value at which to fix the variable (will default to present value)\n        \"\"\"\n        self[name].fix(value)\n\n    def get_normalised_values(self):\n        \"\"\"\n        Get the normalised values of all free variables.\n\n        Returns\n        -------\n        x_norm: np.ndarray\n            Array of normalised values\n        \"\"\"\n        return np.array([opv.normalised_value for opv in self._opt_vars])\n\n    def set_values_from_norm(self, x_norm):\n        \"\"\"\n        Set values from a normalised vector.\n\n        Parameters\n        ----------\n        x_norm: np.ndarray\n            Array of normalised values\n        \"\"\"\n        true_values = self.get_values_from_norm(x_norm)\n        for opv, value in zip(self._opt_vars, true_values):\n            opv.value = value\n\n    def get_values_from_norm(self, x_norm):\n        \"\"\"\n        Get actual values from a normalised vector.\n\n        Parameters\n        ----------\n        x_norm: np.ndarray\n            Array of normalised values\n\n        Returns\n        -------\n        x_true: np.ndarray\n            Array of actual values in units\n        \"\"\"\n        if len(x_norm) != self.n_free_variables:\n            raise OptVariablesError(\n                f\"Number of normalised variables {len(x_norm)} != {self.n_free_variables}.\"\n            )\n        return [\n            opv.from_normalised(v_norm) for opv, v_norm in zip(self._opt_vars, x_norm)\n        ]\n\n    @property\n    def names(self):\n        \"\"\"\n        All variable names of the variable set.\n        \"\"\"\n        return [opv.name for opv in self]\n\n    @property\n    def values(self):\n        \"\"\"\n        All un-normalised values of the variable set (including fixed variable values).\n        \"\"\"\n        return np.array([v.value for v in self])\n\n    @property\n    def n_free_variables(self) -> int:\n        \"\"\"\n        Number of free variables in the set.\n        \"\"\"\n        return len(self._opt_vars)\n\n    @property\n    def _opt_vars(self):\n        return [v for v in self if not v.fixed]\n\n    @property\n    def _fixed_vars(self):\n        return [v for v in self if v.fixed]\n\n    @property\n    def _fixed_variable_indices(self) -> list:\n        \"\"\"\n        Indices of fixed variables in the set.\n        \"\"\"\n        # specfically not useing self._fixed_vars here\n        # as you need the correct index for the variable\n        return [i for i, v in enumerate(self) if v.fixed]\n\n    def as_dict(self) -> Dict[str, OptVarDictT]:\n        \"\"\"\n        Dictionary Representation of the frame\n        \"\"\"\n        return {opv.name: opv.as_dict() for opv in self}\n\n    def as_serializable(self) -> Dict[str, OptVarSerializedT]:\n        \"\"\"\n        Dictionary Representation of the frame\n        \"\"\"\n        return {opv.name: opv.as_serializable() for opv in self}\n\n    def to_json(self, file: str, **kwargs):\n        \"\"\"\n        Save the OptVariablesFrame to a json file.\n\n        Parameters\n        ----------\n        path: str\n            Path to save the json file to.\n        \"\"\"\n        json_writer(self.as_serializable(), file, **kwargs)\n\n    @classmethod\n    def from_json(cls, file: Union[str, TextIO], frozen=False):\n        \"\"\"\n        Create an OptVariablesFrame instance from a json file.\n\n        Parameters\n        ----------\n        file: Union[str, TextIO]\n            The path to the file, or an open file handle that supports reading.\n        \"\"\"\n        if isinstance(file, str):\n            with open(file, \"r\") as fh:\n                return cls.from_json(fh)\n\n        d = json.load(file)\n        opt_vars = {\n            name: OptVariable.from_serialized(name, val) for name, val in d.items()\n        }\n        return cls(**opt_vars)\n\n    def tabulate(self, tablefmt: str = \"fancy_grid\") -> str:\n        \"\"\"\n        Tabulate OptVariablesFrame\n\n        Parameters\n        ----------\n        keys: Optional[List]\n            table column keys\n        tablefmt: str (default=\"fancy_grid\")\n            The format of the table - see\n            https://github.com/astanin/python-tabulate#table-format\n\n        Returns\n        -------\n        tabulated: str\n            The tabulated data\n        \"\"\"\n        records = sorted([val.as_dict() for val in self], key=lambda x: x[\"name\"])\n\n        return f\"{self.__class__.__name__}\\n\" + tabulate(\n            records,\n            headers=\"keys\",\n            tablefmt=tablefmt,\n            showindex=False,\n            numalign=\"right\",\n        )\n\n    def __str__(self) -> str:\n        \"\"\"\n        Pretty prints a representation of the OptVariablesFrame inside the console\n        \"\"\"\n        return self.tabulate()\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Prints a representation of the OptVariablesFrame inside the console\n        \"\"\"\n        return (\n            f\"{self.__class__.__name__}(\\n    \"\n            + \"\\n    \".join([repr(var) for var in self])\n            + \"\\n)\"\n        )",
  "def __init__(\n        self,\n        name: str,\n        value: float,\n        lower_bound: float,\n        upper_bound: float,\n        fixed: bool = False,\n        description: Optional[str] = None,\n    ):\n        self.name = name\n\n        self._value = value\n        self.lower_bound = lower_bound\n        self.upper_bound = upper_bound\n        self.fixed = fixed\n        self.description = description\n\n        self._validate_bounds()\n        self._validate_value(value)",
  "def value(self) -> float:\n        \"\"\"\n        The value of the variable.\n        \"\"\"\n        return self._value",
  "def value(self, value):\n        \"\"\"\n        Set the value of the variable, enforcing bounds.\n        \"\"\"\n        if self.fixed:\n            raise OptVariablesError(\"Cannot set the value of a fixed variable.\")\n\n        self._validate_value(value)\n        self._value = value",
  "def normalised_value(self) -> float:\n        \"\"\"\n        The value uniformly normalised between 0 and 1 w.r.t. its bounds\n        \"\"\"\n        return (self.value - self.lower_bound) / (self.upper_bound - self.lower_bound)",
  "def from_normalised(self, norm: float) -> float:\n        \"\"\"\n        The value from a normalised value between [0 -> 1], w.r.t its bounds\n        \"\"\"\n        return self.lower_bound + norm * (self.upper_bound - self.lower_bound)",
  "def fix(self, value: Optional[float] = None):\n        \"\"\"\n        Fix the variable at a specified value. Ignores bounds.\n\n        Parameters\n        ----------\n        value:\n            Value at which to fix the variable.\n        \"\"\"\n        self.fixed = True\n        if value is not None:\n            self._value = value",
  "def adjust(\n        self,\n        value: Optional[float] = None,\n        lower_bound: Optional[float] = None,\n        upper_bound: Optional[float] = None,\n        strict_bounds: bool = True,\n    ):\n        \"\"\"\n        Adjust the OptVariable.\n\n        Parameters\n        ----------\n        value:\n            Value of the variable to set\n        lower_bound:\n            Value of the lower bound to set\n        upper_bound:\n            Value of the upper to set\n        strict_bounds:\n            If True, will raise errors if values are outside the bounds. If False, the\n            bounds are dynamically adjusted to match the value.\n        \"\"\"\n        if self.fixed:\n            raise OptVariablesError(f\"'{self.name}' is fixed and cannot be adjusted.\")\n\n        if lower_bound is not None:\n            self.lower_bound = lower_bound\n\n        if upper_bound is not None:\n            self.upper_bound = upper_bound\n\n        if value is not None:\n            if not strict_bounds:\n                self._adjust_bounds_to(value)\n            self.value = value\n\n        self._validate_bounds()",
  "def as_dict(self) -> OptVarDictT:\n        \"\"\"Dictionary representation of OptVariable, can be used for serialisation\"\"\"\n        return {\n            \"name\": self.name,\n            \"value\": self.value,\n            \"lower_bound\": self.lower_bound,\n            \"upper_bound\": self.upper_bound,\n            \"fixed\": self.fixed,\n            \"description\": self.description or \"\",\n        }",
  "def as_serializable(self) -> OptVarSerializedT:\n        \"\"\"Dictionary representation of OptVariable\"\"\"\n        return {\n            \"value\": self.value,\n            \"lower_bound\": self.lower_bound,\n            \"upper_bound\": self.upper_bound,\n            \"fixed\": self.fixed,\n            \"description\": self.description or \"\",\n        }",
  "def from_serialized(cls, name: str, data: OptVarSerializedT):\n        \"\"\"Create an OptVariable from a dictionary\"\"\"\n        return cls(\n            name=name,\n            value=data[\"value\"],\n            lower_bound=data[\"lower_bound\"],\n            upper_bound=data[\"upper_bound\"],\n            fixed=data[\"fixed\"],\n            description=data[\"description\"],\n        )",
  "def _adjust_bounds_to(self, value):\n        \"\"\"\n        Adjust the bounds to the value\n        \"\"\"\n        if value < self.lower_bound:\n            bluemira_warn(\n                f\"OptVariable '{self.name}': value was set to below its lower bound. Adjusting bound.\"\n            )\n            self.lower_bound = value\n\n        if value > self.upper_bound:\n            bluemira_warn(\n                f\"OptVariable '{self.name}': value was set to above its upper bound. Adjusting bound.\"\n            )\n            self.upper_bound = value",
  "def _validate_bounds(self):\n        if self.lower_bound > self.upper_bound:\n            raise OptVariablesError(\n                f\"OptVariable '{self.name}' - lower bound is higher than upper bound.\"\n            )",
  "def _validate_value(self, value):\n        if not self.lower_bound <= value <= self.upper_bound:\n            raise OptVariablesError(\n                f\"OptVariable '{self.name}' - value {value} is out of bounds: [{self.lower_bound}, {self.upper_bound}]\"\n            )",
  "def __repr__(self) -> str:\n        \"\"\"\n        Representation of OptVariable\n        \"\"\"\n        lower_bound, upper_bound, fixed = (\n            self.lower_bound,\n            self.upper_bound,\n            self.fixed,\n        )\n        return f\"{self.__class__.__name__}({self.name}, {self.value}, {lower_bound=}, {upper_bound=}, {fixed=})\"",
  "def __str__(self) -> str:\n        \"\"\"\n        Pretty representation of OptVariable\n        \"\"\"\n        bound = (\n            f\" Bounds: ({self.lower_bound}, {self.upper_bound})\"\n            if not self.fixed\n            else \"\"\n        )\n        descr = f' \"{self.description}\"' if self.description is not None else \"\"\n\n        return f\"{self.name} = {self.value}{bound}{descr}\"",
  "def __add__(self, other: OptVariable):\n        \"\"\"The sum of two OptVariables is the sum of their values\"\"\"\n        if isinstance(other, OptVariable):\n            return self.value + other.value\n        elif isinstance(other, (int, float, np.floating)):\n            return self.value + other\n        else:\n            raise TypeError(f\"Cannot add OptVariable with {type(other)}\")",
  "def __sub__(self, other: OptVariable):\n        \"\"\"The subtraction of two OptVariables is the subtraction of their values\"\"\"\n        if isinstance(other, OptVariable):\n            return self.value - other.value\n        elif isinstance(other, (int, float, np.floating)):\n            return self.value - other\n        else:\n            raise TypeError(f\"Cannot subtract OptVariable with {type(other)}\")",
  "def __mul__(self, other: OptVariable):\n        \"\"\"\n        The multiplication of two OptVariables is\n        the multiplication of their values\n        \"\"\"\n        if isinstance(other, OptVariable):\n            return self.value * other.value\n        elif isinstance(other, (int, float, np.floating)):\n            return self.value * other\n        else:\n            raise TypeError(f\"Cannot multiply OptVariable with {type(other)}\")",
  "def __new__(cls, *args, **kwargs):\n        \"\"\"\n        Prevent instantiation of this class.\n        \"\"\"\n        if cls == OptVariablesFrame:\n            raise TypeError(\n                \"Cannot instantiate an OptVariablesFrame directly. It must be subclassed.\"\n            )\n        if not hasattr(cls, \"__dataclass_fields__\"):\n            raise TypeError(f\"{cls} must be annotated with '@dataclass'\")\n        for field_name in cls.__dataclass_fields__:  # type: ignore\n            dcf: Field = cls.__dataclass_fields__[field_name]  # type: ignore\n            fact_inst = dcf.default_factory() if dcf.default_factory != MISSING else None\n            if fact_inst is None:\n                raise TypeError(\n                    f\"{field_name} must be wrapped in with 'ov' field factory\"\n                )\n            if not isinstance(fact_inst, OptVariable):\n                raise TypeError(\n                    f\"OptVariablesFrame contains non-OptVariable object '{field_name}: {type(fact_inst)}'\"\n                )\n            if field_name != fact_inst.name:\n                raise TypeError(\n                    f\"OptVariablesFrame contains OptVariable with incorrect name '{fact_inst.name}', defined as '{field_name}'\"\n                )\n\n        return super().__new__(cls)",
  "def __iter__(self) -> Generator[OptVariable, None, None]:\n        \"\"\"\n        Iterate over this frame's parameters.\n\n        The order is based on the order in which the parameters were\n        declared.\n        \"\"\"\n        for field_name in self.__dataclass_fields__:  # type: ignore\n            yield getattr(self, field_name)",
  "def __getitem__(self, name: str) -> OptVariable:\n        \"\"\"\n        Dictionary-like access to variables.\n\n        Parameters\n        ----------\n        name:\n            Name of the variable to get\n        \"\"\"\n        return getattr(self, name)",
  "def adjust_variable(\n        self,\n        name: str,\n        value: Optional[float] = None,\n        lower_bound: Optional[float] = None,\n        upper_bound: Optional[float] = None,\n        fixed: bool = False,\n        strict_bounds: bool = True,\n    ):\n        \"\"\"\n        Adjust a variable in the frame.\n\n        Parameters\n        ----------\n        name:\n            Name of the variable to adjust\n        value:\n            Value of the variable to set\n        lower_bound:\n            Value of the lower bound to set\n        upper_bound:\n            Value of the upper to set\n        fixed:\n            Whether or not the variable is to be held constant\n        strict_bounds: bool\n            If True, will raise errors if values are outside the bounds. If False, the\n            bounds are dynamically adjusted to match the value.\n        \"\"\"\n        opt_var = self[name]\n        if fixed:\n            # sets the bounds and fixes the var ignoring them\n            opt_var.adjust(\n                lower_bound=lower_bound,\n                upper_bound=upper_bound,\n                strict_bounds=strict_bounds,\n            )\n            opt_var.fix(value)\n        else:\n            opt_var.adjust(value, lower_bound, upper_bound, strict_bounds)",
  "def adjust_variables(\n        self,\n        var_dict: Optional[VarDictT] = None,\n        strict_bounds=True,\n    ):\n        \"\"\"\n        Adjust multiple variables in the frame.\n\n        Parameters\n        ----------\n        var_dict:\n            Dictionary with which to update the set, of the form\n            {\"var_name\": {\"value\": v, \"lower_bound\": lb, \"upper_bound\": ub}, ...}\n        strict_bounds: bool\n            If True, will raise errors if values are outside the bounds. If False, the\n            bounds are dynamically adjusted to match the value.\n        \"\"\"\n        if var_dict is not None:\n            for k, v in var_dict.items():\n                args = [\n                    v.get(\"value\", None),\n                    v.get(\"lower_bound\", None),\n                    v.get(\"upper_bound\", None),\n                    v.get(\"fixed\", None),\n                ]\n                if all([i is None for i in args]):\n                    raise OptVariablesError(\n                        \"When adjusting variables in an OptVariableFrame instance, the dictionary\"\n                        \" must be of the form: {'var_name': {'value': v, 'lower_bound': lb, 'upper_bound': ub}, ...}\"\n                    )\n                self.adjust_variable(k, *args, strict_bounds=strict_bounds)",
  "def fix_variable(self, name: str, value: Optional[float] = None):\n        \"\"\"\n        Fix a variable in the frame, removing it from optimisation but preserving a\n        constant value.\n\n        Parameters\n        ----------\n        name:\n            Name of the variable to fix\n        value:\n            Value at which to fix the variable (will default to present value)\n        \"\"\"\n        self[name].fix(value)",
  "def get_normalised_values(self):\n        \"\"\"\n        Get the normalised values of all free variables.\n\n        Returns\n        -------\n        x_norm: np.ndarray\n            Array of normalised values\n        \"\"\"\n        return np.array([opv.normalised_value for opv in self._opt_vars])",
  "def set_values_from_norm(self, x_norm):\n        \"\"\"\n        Set values from a normalised vector.\n\n        Parameters\n        ----------\n        x_norm: np.ndarray\n            Array of normalised values\n        \"\"\"\n        true_values = self.get_values_from_norm(x_norm)\n        for opv, value in zip(self._opt_vars, true_values):\n            opv.value = value",
  "def get_values_from_norm(self, x_norm):\n        \"\"\"\n        Get actual values from a normalised vector.\n\n        Parameters\n        ----------\n        x_norm: np.ndarray\n            Array of normalised values\n\n        Returns\n        -------\n        x_true: np.ndarray\n            Array of actual values in units\n        \"\"\"\n        if len(x_norm) != self.n_free_variables:\n            raise OptVariablesError(\n                f\"Number of normalised variables {len(x_norm)} != {self.n_free_variables}.\"\n            )\n        return [\n            opv.from_normalised(v_norm) for opv, v_norm in zip(self._opt_vars, x_norm)\n        ]",
  "def names(self):\n        \"\"\"\n        All variable names of the variable set.\n        \"\"\"\n        return [opv.name for opv in self]",
  "def values(self):\n        \"\"\"\n        All un-normalised values of the variable set (including fixed variable values).\n        \"\"\"\n        return np.array([v.value for v in self])",
  "def n_free_variables(self) -> int:\n        \"\"\"\n        Number of free variables in the set.\n        \"\"\"\n        return len(self._opt_vars)",
  "def _opt_vars(self):\n        return [v for v in self if not v.fixed]",
  "def _fixed_vars(self):\n        return [v for v in self if v.fixed]",
  "def _fixed_variable_indices(self) -> list:\n        \"\"\"\n        Indices of fixed variables in the set.\n        \"\"\"\n        # specfically not useing self._fixed_vars here\n        # as you need the correct index for the variable\n        return [i for i, v in enumerate(self) if v.fixed]",
  "def as_dict(self) -> Dict[str, OptVarDictT]:\n        \"\"\"\n        Dictionary Representation of the frame\n        \"\"\"\n        return {opv.name: opv.as_dict() for opv in self}",
  "def as_serializable(self) -> Dict[str, OptVarSerializedT]:\n        \"\"\"\n        Dictionary Representation of the frame\n        \"\"\"\n        return {opv.name: opv.as_serializable() for opv in self}",
  "def to_json(self, file: str, **kwargs):\n        \"\"\"\n        Save the OptVariablesFrame to a json file.\n\n        Parameters\n        ----------\n        path: str\n            Path to save the json file to.\n        \"\"\"\n        json_writer(self.as_serializable(), file, **kwargs)",
  "def from_json(cls, file: Union[str, TextIO], frozen=False):\n        \"\"\"\n        Create an OptVariablesFrame instance from a json file.\n\n        Parameters\n        ----------\n        file: Union[str, TextIO]\n            The path to the file, or an open file handle that supports reading.\n        \"\"\"\n        if isinstance(file, str):\n            with open(file, \"r\") as fh:\n                return cls.from_json(fh)\n\n        d = json.load(file)\n        opt_vars = {\n            name: OptVariable.from_serialized(name, val) for name, val in d.items()\n        }\n        return cls(**opt_vars)",
  "def tabulate(self, tablefmt: str = \"fancy_grid\") -> str:\n        \"\"\"\n        Tabulate OptVariablesFrame\n\n        Parameters\n        ----------\n        keys: Optional[List]\n            table column keys\n        tablefmt: str (default=\"fancy_grid\")\n            The format of the table - see\n            https://github.com/astanin/python-tabulate#table-format\n\n        Returns\n        -------\n        tabulated: str\n            The tabulated data\n        \"\"\"\n        records = sorted([val.as_dict() for val in self], key=lambda x: x[\"name\"])\n\n        return f\"{self.__class__.__name__}\\n\" + tabulate(\n            records,\n            headers=\"keys\",\n            tablefmt=tablefmt,\n            showindex=False,\n            numalign=\"right\",\n        )",
  "def __str__(self) -> str:\n        \"\"\"\n        Pretty prints a representation of the OptVariablesFrame inside the console\n        \"\"\"\n        return self.tabulate()",
  "def __repr__(self) -> str:\n        \"\"\"\n        Prints a representation of the OptVariablesFrame inside the console\n        \"\"\"\n        return (\n            f\"{self.__class__.__name__}(\\n    \"\n            + \"\\n    \".join([repr(var) for var in self])\n            + \"\\n)\"\n        )",
  "def gsymbolify(string: str) -> str:\n    \"\"\"\n    Convert a string to a LaTEX printable greek letter if detected.\n\n    Parameters\n    ----------\n    string:\n        The string to add Greek symbols to\n\n    Returns\n    -------\n    The modified string. Returns input if no changes made\n    \"\"\"\n    if string in GREEK_ALPHABET or string in GREEK_ALPHABET_CAPS:\n        return \"\\\\\" + string\n    else:\n        return string",
  "def str_to_latex(string: str) -> str:\n    \"\"\"\n    Create a new string which can be printed in LaTEX nicely.\n\n    Parameters\n    ----------\n    string:\n        The string to be converted\n\n    Returns\n    -------\n    The mathified string\n\n    'I_m_p' ==> '$I_{m_{p}}$'\n    \"\"\"\n    s = string.split(\"_\")\n    s = [gsymbolify(sec) for sec in s]\n    ss = \"\".join([\"_\" + \"{\" + lab for i, lab in enumerate(s[1:])])\n    return \"$\" + s[0] + ss + \"}\" * (len(s) - 1) + \"$\"",
  "def make_gif(\n    folder: str, figname: str, file_format: str = \"png\", clean: bool = True, **kwargs\n):\n    \"\"\"\n    Make a GIF image from a set of images with similar names in a folder.\n    Figures are sorted in increasing order based on a trailing number, e.g.\n    'figure_A[1, 2, 3, ..].png'\n    Cleans up the temporary figure files (deletes!)\n    Creates a GIF file in the folder directory\n\n    Parameters\n    ----------\n    folder:\n        Full path folder name\n    figname:\n        Figure name prefix\n    file_format:\n        Figure filename extension\n    clean:\n        Delete figures after completion?\n    \"\"\"\n    if kw_formatt := kwargs.pop(\"formatt\", None):\n        warn(\n            \"Using kwarg 'formatt' is no longer supported. Use file_format instead.\",\n            category=DeprecationWarning,\n        )\n        file_format = kw_formatt\n\n    ims = []\n    for filename in os.listdir(folder):\n        if filename.startswith(figname) and filename.endswith(file_format):\n            fp = os.path.join(folder, filename)\n            ims.append(fp)\n\n    find_digit = re.compile(\"(\\\\d+)\")\n    ims = sorted(ims, key=lambda x: int(find_digit.findall(x)[-1]))\n    images = [imageio.imread(fp) for fp in ims]\n    if clean:\n        for fp in ims:\n            os.remove(fp)\n    gifname = os.path.join(folder, figname) + \".gif\"\n    kwargs = {\"duration\": 0.5, \"loop\": 3}\n    imageio.mimsave(gifname, images, \"GIF-FI\", **kwargs)",
  "def save_figure(\n    fig, name, save=False, folder=None, dpi=600, file_format=\"png\", **kwargs\n):\n    \"\"\"\n    Saves a figure to the directory if save flag active\n    \"\"\"\n    if kw_formatt := kwargs.pop(\"formatt\", None):\n        warn(\n            \"Using kwarg 'formatt' is no longer supported. Use file_format instead.\",\n            category=DeprecationWarning,\n        )\n        file_format = kw_formatt\n\n    if save is True:\n        if folder is None:\n            folder = get_bluemira_path(\"plots\", subfolder=\"data\")\n        name = os.sep.join([folder, name]) + \".\" + file_format\n        if os.path.isfile(name):\n            os.remove(name)  # f.savefig will otherwise not overwrite\n        fig.savefig(name, dpi=dpi, bbox_inches=\"tight\", format=file_format, **kwargs)",
  "def ring_coding(n: int) -> np.ndarray:\n    \"\"\"\n    The codes will be all \"LINETO\" commands, except for \"MOVETO\"s at the\n    beginning of each subpath\n    \"\"\"\n    codes = np.ones(n, dtype=Path.code_type) * Path.LINETO\n    codes[0] = Path.MOVETO\n    return codes",
  "def coordinates_to_path(x: np.ndarray, z: np.ndarray) -> Path:\n    \"\"\"\n    Convert coordinates to path vertices.\n    \"\"\"\n    if not check_ccw(x, z):\n        x = x[::-1]\n        z = z[::-1]\n    vertices = np.array([x, z]).T\n    codes = ring_coding(len(x))\n    return Path(vertices, codes)",
  "def set_component_view(comp: Component, placement: Union[str, BluemiraPlacement]):\n    if placement not in [\"xy\", \"xz\", \"yz\"] and not isinstance(\n        placement, BluemiraPlacement\n    ):\n        raise bm_display_error.DisplayError(\n            f\"Not a valid view {placement} - select either xy, xz, yz, \"\n            f\"or a BluemiraPlacement\"\n        )\n\n    comp.plot_options.view = placement\n    for child in comp.children:\n        set_component_view(child, placement)",
  "class Plot3D(Axes3D):\n    \"\"\"\n    Cheap and cheerful\n    \"\"\"\n\n    def __init__(self):\n        fig = plt.figure(figsize=[14, 14])\n        super().__init__(fig, auto_add_to_figure=False)\n        fig.add_axes(self)\n        # \\n to offset labels from axes\n        self.set_xlabel(\"\\n\\nx [m]\")\n        self.set_ylabel(\"\\n\\ny [m]\")\n        self.set_zlabel(\"\\n\\nz [m]\")",
  "class BluemiraPathPatch3D(PathPatch3D):\n    \"\"\"\n    Class for a 3-D PathPatch which can actually be filled properly!\n\n    Parameters\n    ----------\n    path:\n        The path object to plot in 3-D\n    normal:\n        The 3-D normal vector of the face\n    translation:\n        Translation vector to apply to the face\n    color:\n        The color to plot the fill\n    \"\"\"\n\n    # Thank you StackOverflow\n    # https://stackoverflow.com/questions/18228966/how-can-matplotlib-2d-patches-be-transformed-to-3d-with-arbitrary-normals\n    def __init__(\n        self,\n        path: Path,\n        normal: np.ndarray,\n        translation: Optional[np.ndarray] = None,\n        color: str = \"b\",\n        **kwargs,\n    ):\n        # Initialise the patch first, or we can get into nasty recursive\n        # calls in __getattr__\n        self._patch2d = PathPatch(path, color=color, **kwargs)\n\n        Patch.__init__(self, **kwargs)\n\n        if translation is None:\n            translation = [0, 0, 0]\n\n        self._path2d = path\n        self._code3d = path.codes\n        self._facecolor3d = self._patch2d.get_facecolor\n\n        r_matrix = rotation_matrix_v1v2(normal, (0, 0, 1))\n        t_matrix = np.array(translation)\n\n        points = path.vertices\n\n        new_points = np.array([np.dot(r_matrix, np.array([x, y, 0])) for x, y in points])\n\n        self._segment3d = new_points + t_matrix\n\n    def __getattr__(self, key: str):\n        \"\"\"\n        Transfer the key getattr to underlying PathPatch object.\n        \"\"\"\n        return getattr(self._patch2d, key)",
  "def __init__(self):\n        fig = plt.figure(figsize=[14, 14])\n        super().__init__(fig, auto_add_to_figure=False)\n        fig.add_axes(self)\n        # \\n to offset labels from axes\n        self.set_xlabel(\"\\n\\nx [m]\")\n        self.set_ylabel(\"\\n\\ny [m]\")\n        self.set_zlabel(\"\\n\\nz [m]\")",
  "def __init__(\n        self,\n        path: Path,\n        normal: np.ndarray,\n        translation: Optional[np.ndarray] = None,\n        color: str = \"b\",\n        **kwargs,\n    ):\n        # Initialise the patch first, or we can get into nasty recursive\n        # calls in __getattr__\n        self._patch2d = PathPatch(path, color=color, **kwargs)\n\n        Patch.__init__(self, **kwargs)\n\n        if translation is None:\n            translation = [0, 0, 0]\n\n        self._path2d = path\n        self._code3d = path.codes\n        self._facecolor3d = self._patch2d.get_facecolor\n\n        r_matrix = rotation_matrix_v1v2(normal, (0, 0, 1))\n        t_matrix = np.array(translation)\n\n        points = path.vertices\n\n        new_points = np.array([np.dot(r_matrix, np.array([x, y, 0])) for x, y in points])\n\n        self._segment3d = new_points + t_matrix",
  "def __getattr__(self, key: str):\n        \"\"\"\n        Transfer the key getattr to underlying PathPatch object.\n        \"\"\"\n        return getattr(self._patch2d, key)",
  "def approx_derivative(\n    func, x0, method=\"3-point\", rel_step=None, f0=None, bounds=None, args=()\n):\n    \"\"\"\n    Approximate the gradient of a function about a point.\n\n    Parameters\n    ----------\n    func: callable\n        Function for which to calculate the gradient\n    x0: np.ndarray\n        Point about which to calculate the gradient\n    method: str\n        Finite difference method to use\n    rel_step: Optional[float, np.ndarray]\n        Relative step size to use\n    f0: Optional[float, np.ndarray]\n        Result of func(x0). If None, this is recomputed\n    bounds: Optional[Iterable]\n        Lower and upper bounds on individual variables\n    args: tuple\n        Additional arguments to func\n    \"\"\"\n    if bounds is None:\n        bounds = (-np.inf, np.inf)\n    return _approx_derivative(\n        func, x0, method=method, rel_step=rel_step, f0=f0, bounds=bounds, args=args\n    )",
  "class Optimiser(NLOPTOptimiser):\n    \"\"\"\n    Optimiser interface class.\n\n\n    Objective functions must be of the form:\n\n    .. code-block:: python\n\n        def f_objective(x, grad, args):\n            if grad.size > 0:\n                grad[:] = my_gradient_calc(x)\n            return my_objective_calc(x)\n\n    The objective function is minimised, so lower values are \"better\".\n\n    Note that the gradient of the objective function is of the form:\n\n    :math:`\\\\nabla f = \\\\bigg[\\\\dfrac{\\\\partial f}{\\\\partial x_0}, \\\\dfrac{\\\\partial f}{\\\\partial x_1}, ...\\\\bigg]`\n\n\n    Constraint functions must be of the form:\n\n    .. code-block:: python\n\n        def f_constraint(constraint, x, grad, args):\n            constraint[:] = my_constraint_calc(x)\n            if grad.size > 0:\n                grad[:] = my_gradient_calc(x)\n            return constraint\n\n    The constraint function convention is such that c <= 0 is sought. I.e. all constraint\n    values must be negative.\n\n    Note that the gradient (Jacobian) of the constraint function is of the form:\n\n    .. math::\n\n        \\\\nabla \\\\mathbf{c} = \\\\begin{bmatrix}\n                \\\\dfrac{\\\\partial c_{0}}{\\\\partial x_0} & \\\\dfrac{\\\\partial c_{0}}{\\\\partial x_1} & ... \\n\n                \\\\dfrac{\\\\partial c_{1}}{\\\\partial x_0} & \\\\dfrac{\\\\partial c_{1}}{\\\\partial x_1} & ... \\n\n                ... & ... & ... \\n\n                \\\\end{bmatrix}\n\n\n    The grad and constraint matrices must be assigned in place.\n    \"\"\"  # noqa :W505\n\n    def optimise(self, x0=None, check_constraints: bool = True):\n        \"\"\"\n        Run the optimisation problem.\n\n        Parameters\n        ----------\n        x0: Optional[np.ndarray]\n            Starting solution vector\n\n        Returns\n        -------\n        x_star: np.ndarray\n            Optimal solution vector\n        \"\"\"\n        if x0 is None:\n            x0 = 0.5 * np.ones(self.n_variables)\n\n        x_star = super().optimise(x0)\n        if self.constraints and check_constraints:\n            self.check_constraints(x_star)\n        return x_star\n\n    def approx_derivative(self, function, x, f0=None):\n        \"\"\"\n        Utility function to numerical approximate the derivative of a function.\n\n        Parameters\n        ----------\n        function: callable\n            Function to get a numerical derivative for\n        x: np.ndarray\n            Point about which to calculate the derivative\n        f0: Optional[float]\n            Objective function value at x (speed optimisation)\n\n        Notes\n        -----\n        Use with caution... numerical approximations of gradients can often lead to\n        headaches.\n        \"\"\"\n        return approx_derivative(\n            function, x, bounds=[self.lower_bounds, self.upper_bounds], f0=f0\n        )\n\n    def set_objective_function(self, f_objective):\n        \"\"\"\n        Set the objective function (minimisation).\n\n        Parameters\n        ----------\n        f_objective: callable\n            Objective function to minimise\n        \"\"\"\n        if f_objective is None:\n            return\n\n        super().set_objective_function(f_objective)\n\n    def add_eq_constraints(\n        self, f_constraint: callable, tolerance: Union[float, np.ndarray]\n    ):\n        \"\"\"\n        Add a vector-valued equality constraint.\n\n        Parameters\n        ----------\n        f_constraint: callable\n            Constraint function\n        tolerance: Union[float, np.ndarray]\n            Tolerance with which to enforce the constraint\n        \"\"\"\n        if f_constraint is None:\n            return\n        if is_num(tolerance) and not isinstance(tolerance, np.ndarray):\n            tolerance = np.array([tolerance])\n        super().add_eq_constraints(f_constraint, tolerance)\n\n    def add_ineq_constraints(\n        self, f_constraint: callable, tolerance: Union[float, np.ndarray]\n    ):\n        \"\"\"\n        Add a vector-valued inequality constraint.\n\n        Parameters\n        ----------\n        f_constraint: callable\n            Constraint function\n        tolerance: Union[float, np.ndarray]\n            Tolerance array with which to enforce the constraint\n        \"\"\"\n        if f_constraint is None:\n            return\n        if is_num(tolerance) and not isinstance(tolerance, np.ndarray):\n            tolerance = np.array([tolerance])\n        super().add_ineq_constraints(f_constraint, tolerance)\n\n    def check_constraints(self, x: np.ndarray, warn: bool = True):\n        \"\"\"\n        Check that the constraints have been met.\n\n        Parameters\n        ----------\n        x: np.ndarray\n            Solution vector to check the constraints for\n\n        Returns\n        -------\n        check: bool\n            Whether or not the constraints have been satisfied within the tolerances\n        \"\"\"\n        c_values = []\n        tolerances = []\n        for constraint, tolerance in zip(self.constraints, self.constraint_tols):\n            c_values.extend(constraint(np.zeros(len(tolerance)), x, np.empty(0)))\n            tolerances.extend(tolerance)\n\n        c_values = np.array(c_values)\n        tolerances = np.array(tolerances)\n\n        if not np.all(c_values < tolerances):\n            if warn:\n                indices = np.where(c_values > tolerances)[0]\n                message = \"\\n\".join(\n                    [\n                        f\"constraint number {i}: {pformat(c_values[i])} !< \"\n                        f\"{pformat(tolerances[i])}\"\n                        for i in indices\n                    ]\n                )\n                bluemira_warn(\n                    \"Some constraints have not been adequately satisfied.\\n\" f\"{message}\"\n                )\n            return False\n        return True",
  "def optimise(self, x0=None, check_constraints: bool = True):\n        \"\"\"\n        Run the optimisation problem.\n\n        Parameters\n        ----------\n        x0: Optional[np.ndarray]\n            Starting solution vector\n\n        Returns\n        -------\n        x_star: np.ndarray\n            Optimal solution vector\n        \"\"\"\n        if x0 is None:\n            x0 = 0.5 * np.ones(self.n_variables)\n\n        x_star = super().optimise(x0)\n        if self.constraints and check_constraints:\n            self.check_constraints(x_star)\n        return x_star",
  "def approx_derivative(self, function, x, f0=None):\n        \"\"\"\n        Utility function to numerical approximate the derivative of a function.\n\n        Parameters\n        ----------\n        function: callable\n            Function to get a numerical derivative for\n        x: np.ndarray\n            Point about which to calculate the derivative\n        f0: Optional[float]\n            Objective function value at x (speed optimisation)\n\n        Notes\n        -----\n        Use with caution... numerical approximations of gradients can often lead to\n        headaches.\n        \"\"\"\n        return approx_derivative(\n            function, x, bounds=[self.lower_bounds, self.upper_bounds], f0=f0\n        )",
  "def set_objective_function(self, f_objective):\n        \"\"\"\n        Set the objective function (minimisation).\n\n        Parameters\n        ----------\n        f_objective: callable\n            Objective function to minimise\n        \"\"\"\n        if f_objective is None:\n            return\n\n        super().set_objective_function(f_objective)",
  "def add_eq_constraints(\n        self, f_constraint: callable, tolerance: Union[float, np.ndarray]\n    ):\n        \"\"\"\n        Add a vector-valued equality constraint.\n\n        Parameters\n        ----------\n        f_constraint: callable\n            Constraint function\n        tolerance: Union[float, np.ndarray]\n            Tolerance with which to enforce the constraint\n        \"\"\"\n        if f_constraint is None:\n            return\n        if is_num(tolerance) and not isinstance(tolerance, np.ndarray):\n            tolerance = np.array([tolerance])\n        super().add_eq_constraints(f_constraint, tolerance)",
  "def add_ineq_constraints(\n        self, f_constraint: callable, tolerance: Union[float, np.ndarray]\n    ):\n        \"\"\"\n        Add a vector-valued inequality constraint.\n\n        Parameters\n        ----------\n        f_constraint: callable\n            Constraint function\n        tolerance: Union[float, np.ndarray]\n            Tolerance array with which to enforce the constraint\n        \"\"\"\n        if f_constraint is None:\n            return\n        if is_num(tolerance) and not isinstance(tolerance, np.ndarray):\n            tolerance = np.array([tolerance])\n        super().add_ineq_constraints(f_constraint, tolerance)",
  "def check_constraints(self, x: np.ndarray, warn: bool = True):\n        \"\"\"\n        Check that the constraints have been met.\n\n        Parameters\n        ----------\n        x: np.ndarray\n            Solution vector to check the constraints for\n\n        Returns\n        -------\n        check: bool\n            Whether or not the constraints have been satisfied within the tolerances\n        \"\"\"\n        c_values = []\n        tolerances = []\n        for constraint, tolerance in zip(self.constraints, self.constraint_tols):\n            c_values.extend(constraint(np.zeros(len(tolerance)), x, np.empty(0)))\n            tolerances.extend(tolerance)\n\n        c_values = np.array(c_values)\n        tolerances = np.array(tolerances)\n\n        if not np.all(c_values < tolerances):\n            if warn:\n                indices = np.where(c_values > tolerances)[0]\n                message = \"\\n\".join(\n                    [\n                        f\"constraint number {i}: {pformat(c_values[i])} !< \"\n                        f\"{pformat(tolerances[i])}\"\n                        for i in indices\n                    ]\n                )\n                bluemira_warn(\n                    \"Some constraints have not been adequately satisfied.\\n\" f\"{message}\"\n                )\n            return False\n        return True",
  "class UtilitiesError(BluemiraError):\n    \"\"\"\n    The base class for utilities errors.\n    \"\"\"\n\n    pass",
  "class PositionerError(UtilitiesError):\n    \"\"\"\n    Error for positioner utilities.\n    \"\"\"\n\n    pass",
  "class OptUtilitiesError(UtilitiesError):\n    \"\"\"\n    Error for optimisation utilities.\n    \"\"\"\n\n    pass",
  "class OptVariablesError(OptUtilitiesError):\n    \"\"\"\n    Error for optimisation utilities.\n    \"\"\"\n\n    pass",
  "class InternalOptError(OptUtilitiesError):\n    \"\"\"\n    Error class for errors inside the optimisation algorithms.\n    \"\"\"\n\n    pass",
  "class ExternalOptError(OptUtilitiesError):\n    \"\"\"\n    Error class for errors relating to the optimisation, but not originating\n    inside the optimisers.\n    \"\"\"\n\n    pass",
  "def tikhonov(A, b, gamma):\n    \"\"\"\n    Tikhonov regularisation of Ax-b problem.\n\n    \\t:math:`\\\\textrm{minimise} || Ax - b ||^2 + ||{\\\\gamma} \\\\cdot x ||^2`\\n\n    \\t:math:`x = (A^T A + {\\\\gamma}^2 I)^{-1}A^T b`\n\n    Parameters\n    ----------\n    A: np.array(n, m)\n        The 2-D A matrix of responses\n    b: np.array(n)\n        The 1-D b vector of values\n    gamma: float\n        The Tikhonov regularisation parameter\n\n    Returns\n    -------\n    x: np.array(m)\n        The result vector\n    \"\"\"\n    try:\n        return np.dot(\n            np.linalg.inv(np.dot(A.T, A) + gamma**2 * np.eye(A.shape[1])),\n            np.dot(A.T, b),\n        )\n    except np.linalg.LinAlgError:\n        bluemira_warn(\"Tikhonov singular matrix..!\")\n        return np.dot(\n            np.linalg.pinv(np.dot(A.T, A) + gamma**2 * np.eye(A.shape[1])),\n            np.dot(A.T, b),\n        )",
  "def regularised_lsq_fom(x, A, b, gamma):\n    \"\"\"\n    Figure of merit for the least squares problem Ax = b, with\n    Tikhonov regularisation term. Normalised for the number of\n    targets.\n\n    ||(Ax - b)||\u00b2/ len(b)] + ||\u0393x||\u00b2\n\n    Parameters\n    ----------\n    x : np.array(m)\n        The 1-D x state vector.\n    A: np.array(n, m)\n        The 2-D A control matrix\n    b: np.array(n)\n        The 1-D b vector of target values\n    gamma: float\n        The Tikhonov regularisation parameter.\n\n    Returns\n    -------\n    fom: float\n        Figure of merit, explicitly given by\n        ||(Ax - b)||\u00b2/ len(b)] + ||\u0393x||\u00b2\n    residual: np.array(n)\n        Residual vector (Ax - b)\n    \"\"\"\n    residual = np.dot(A, x) - b\n    number_of_targets = np.float(len(residual))\n    fom = residual.T @ residual / number_of_targets + gamma * gamma * x.T @ x\n\n    if fom <= 0:\n        raise bluemira_warn(\"Least-squares objective function less than zero or nan.\")\n    return fom, residual",
  "def least_squares(A, b):\n    \"\"\"\n    Least squares optimisation.\n\n    \\t:math:`\\\\textrm{minimise} || Ax - b ||^{2}_{2}`\\n\n    \\t:math:`x = (A^T A)^{-1}A^T b`\n\n    Parameters\n    ----------\n    A: np.array(n, m)\n        The 2-D A matrix of responses\n    b: np.array(n)\n        The 1-D b vector of values\n\n    Returns\n    -------\n    x: np.array(m)\n        The result vector\n    \"\"\"\n    return np.linalg.solve(A, b)",
  "def process_scipy_result(res):\n    \"\"\"\n    Handle a scipy.minimize OptimizeResult object. Process error codes, if any.\n\n    Parameters\n    ----------\n    res: OptimizeResult\n\n    Returns\n    -------\n    x: np.array\n        The optimal set of parameters (result of the optimisation)\n\n    Raises\n    ------\n    InternalOptError if an error code returned without a usable result.\n    \"\"\"\n    if res.success:\n        return res.x\n\n    if not hasattr(res, \"status\"):\n        bluemira_warn(\"Scipy optimisation was not succesful. Failed without status.\")\n        raise InternalOptError(\"\\n\".join([res.message, res.__str__()]))\n\n    elif res.status == 8:\n        # This can happen when scipy is not convinced that it has found a minimum.\n        bluemira_warn(\n            \"\\nOptimiser (scipy) found a positive directional derivative,\\n\"\n            \"returning suboptimal result. \\n\"\n            \"\\n\".join([res.message, res.__str__()])\n        )\n        return res.x\n\n    elif res.status == 9:\n        bluemira_warn(\n            \"\\nOptimiser (scipy) exceeded number of iterations, returning \"\n            \"suboptimal result. \\n\"\n            \"\\n\".join([res.message, res.__str__()])\n        )\n        return res.x\n\n    else:\n        raise InternalOptError(\"\\n\".join([res.message, res.__str__()]))",
  "def surface_fit(\n    x: np.ndarray, y: np.ndarray, z: np.ndarray, order: int = 2, n_grid: int = 30\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray, List[float], float]:\n    \"\"\"\n    Fit a polynomial surface to a 3-D data set.\n\n    Parameters\n    ----------\n    x:\n        The x values of the data set\n    y:\n        The y values of the data set\n    z:\n        The z values of the data set\n    order:\n        The order of the fitting polynomial\n    n_grid:\n        The number of gridding points to use on the x and y data\n\n    Returns\n    -------\n    x2d:\n        The gridded x data (i, j indexed)\n    y2d:\n        The gridded y data (i, j indexed)\n    zz:\n        The gridded z fit data (i, j indexed)\n    coeffs:\n        The list of polynomial coefficents\n    r2:\n        The R^2 score of the fit\n\n    Notes\n    -----\n    The coefficients are ordered by power, and by x and y. For an order = 2\n    polynomial, the resultant equation would be:\n\n    \\t:math:`c_{1}x^{2}+c_{2}y^{2}+c_{3}xy+c_{4}x+c_{5}y+c_{6}`\n    \"\"\"\n    x, y, z = np.array(x), np.array(y), np.array(z)\n    if len(x) != len(y) != len(z):\n        raise ValueError(\"x, y, and z must be of equal length.\")\n\n    n = len(x)\n    poly = PolynomialFeatures(order)\n\n    eq_matrix = poly.fit_transform(np.c_[x, y])\n\n    index = powers_arange(poly.powers_)\n    eq_matrix = eq_matrix[:, index]\n\n    coeffs, _, _, _ = lstsq(eq_matrix, z)\n\n    x_min, x_max = np.min(x), np.max(x)\n    y_min, y_max = np.min(y), np.max(y)\n\n    # Grid the x and y arrays\n    x2d, y2d = np.meshgrid(\n        np.linspace(x_min, x_max, n_grid),\n        np.linspace(y_min, y_max, n_grid),\n        indexing=\"ij\",\n    )\n    xx = x2d.flatten()\n    yy = y2d.flatten()\n\n    zz = np.dot(poly.fit_transform(np.c_[xx, yy])[:, index], coeffs).reshape(x2d.shape)\n\n    z_predicted = np.dot(eq_matrix, coeffs).reshape(n)\n\n    return x2d, y2d, zz, coeffs, r2_score(z, z_predicted)",
  "def powers_arange(powers: np.ndarray) -> List:\n    \"\"\"\n    Reorder powers index to order by power from 1st to nth index.\n\n    Parameters\n    ----------\n    powers:\n        array of powers\n\n    Returns\n    -------\n    index to rearrange array\n\n    \"\"\"\n    return sorted(\n        range(powers.shape[0]),\n        key=lambda x: (np.sum(powers[x]), np.max(powers[x])),\n        reverse=True,\n    )",
  "class NumpyJSONEncoder(JSONEncoder):\n    \"\"\"\n    A JSON encoder that can handle numpy arrays.\n    \"\"\"\n\n    def default(self, obj):\n        \"\"\"\n        Override the JSONEncoder default object handling behaviour for np.arrays.\n        \"\"\"\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        return super().default(obj)",
  "def json_writer(\n    data: Dict[str, Any],\n    file: Optional[str] = None,\n    return_output: bool = False,\n    *,\n    cls: JSONEncoder = NumpyJSONEncoder,\n    **kwargs,\n):\n    \"\"\"\n    Write json in the bluemria style.\n\n    Parameters\n    ----------\n    data:\n        dictionary to write to json\n    filename:\n        filename to write to\n    return_output:\n        return the json as a string\n    cls:\n        json encoder child class\n    kwargs:\n        all further kwargs passed to the json writer\n\n    \"\"\"\n    if file is None and not return_output:\n        bluemira_warn(\"No json action to take\")\n        return\n\n    if \"indent\" not in kwargs:\n        kwargs[\"indent\"] = 4\n\n    the_json = dumps(data, cls=cls, **kwargs)\n\n    if file is not None:\n        with open(file, \"w\") as fh:\n            fh.write(the_json)\n            fh.write(\"\\n\")\n\n    if return_output:\n        return the_json",
  "def asciistr(length: int) -> str:\n    \"\"\"\n    Get a string of characters of desired length.\n\n    Current max is 52 characters\n\n    Parameters\n    ----------\n    length:\n        number of characters to return\n\n    Returns\n    -------\n    str of length specified\n\n    \"\"\"\n    if length > 52:\n        raise ValueError(\"Unsupported string length\")\n\n    return string.ascii_letters[:length]",
  "def levi_civita_tensor(dim: int = 3) -> np.ndarray:\n    \"\"\"\n    N dimensional Levi-Civita Tensor.\n\n    For dim=3 this looks like:\n\n    e_ijk = np.zeros((3, 3, 3))\n    e_ijk[0, 1, 2] = e_ijk[1, 2, 0] = e_ijk[2, 0, 1] = 1\n    e_ijk[0, 2, 1] = e_ijk[2, 1, 0] = e_ijk[1, 0, 2] = -1\n\n    Parameters\n    ----------\n    dim:\n        The number of dimensions for the LCT\n\n    Returns\n    -------\n    np.array (n_0,n_1,...n_n)\n\n    \"\"\"\n    perms = np.array(list(set(permutations(np.arange(dim)))))\n\n    e_ijk = np.zeros([dim for d in range(dim)])\n\n    idx = np.triu_indices(n=dim, k=1)\n\n    for perm in perms:\n        e_ijk[tuple(perm)] = np.prod(np.sign(perm[idx[1]] - perm[idx[0]]))\n\n    return e_ijk",
  "class EinsumWrapper:\n    \"\"\"\n    Preallocator for einsum versions of dot, cross and norm.\n    \"\"\"\n\n    def __init__(self):\n        norm_a0 = \"ij, ij -> j\"\n        norm_a1 = \"ij, ij -> i\"\n\n        self.norm_strs = [norm_a0, norm_a1]\n\n        # Not fool proof for huge no's of dims\n        self.dot_1x1 = \"i, i -> ...\"\n        self.dot_1x2 = \"i, ik -> k\"\n        self.dot_2x1 = \"ij, j -> i\"\n        self.dot_2x2 = \"ij, jk -> ik\"\n        self.dot_1xn = \"y, {}yz -> {}z\"\n        self.dot_nx1 = \"{}z, z -> {}\"\n        self.dot_nxn = \"{}y, {}yz -> {}z\"\n\n        cross_2x1 = \"i, i, i -> i\"\n        cross_2x2 = \"xy, ix, iy -> i\"\n        cross_2x3 = \"xyz, ix, iy -> iz\"\n\n        self.cross_strs = [cross_2x1, cross_2x2, cross_2x3]\n        self.cross_lcts = [E_I, E_IJ, E_IJK]\n\n    def norm(self, ix: np.ndarray, axis: int = 0) -> np.ndarray:\n        \"\"\"\n        Emulates some of the functionality of np.linalg.norm for 2D arrays.\n\n        Specifically:\n        np.linalg.norm(ix, axis=0)\n        np.linalg.norm(ix, axis=1)\n\n        For optimum speed and customisation use np.einsum modified for your use case.\n\n        Parameters\n        ----------\n        ix:\n            Array to perform norm on\n        axis:\n            axis for the norm to occur on\n        \"\"\"\n        try:\n            return np.sqrt(np.einsum(self.norm_strs[axis], ix, ix))\n        except IndexError:\n            raise ValueError(\"matrices dimensions >2d Unsupported\")\n\n    def dot(\n        self, ix: np.ndarray, iy: np.ndarray, out: Optional[np.ndarray] = None\n    ) -> np.ndarray:\n        \"\"\"\n        A dot product emulation using np.einsum.\n\n        For optimum speed and customisation use np.einsum modified for your use case.\n\n        Should follow the same mechanics as np.dot, a few examples:\n\n        ein_str = 'i, i -> ...'\n        ein_str = 'ij, jk -> ik' # Classic dot product\n        ein_str = 'ij, j -> i'\n        ein_str = 'i, ik -> k'\n        ein_str = 'aij, ajk -> aik' # for loop needed with np.dot\n\n        Parameters\n        ----------\n        ix:\n            First array\n        iy:\n            Second array\n        out:\n            output array for inplace dot product\n        \"\"\"\n        # Ordered hopefully by most used\n        if ix.ndim == 2 and iy.ndim == 2:\n            out_str = self.dot_2x2\n        elif ix.ndim > 2 and iy.ndim > 2:\n            ix_str = asciistr(ix.ndim - 1)\n            iy_str = asciistr(iy.ndim - 2)\n            out_str = self.dot_nxn.format(ix_str, iy_str, ix_str)\n        elif ix.ndim < 2 and iy.ndim == 2:\n            out_str = self.dot_1x2\n        elif ix.ndim >= 2 and iy.ndim < 2:\n            ix_str = asciistr(ix.ndim - 1)\n            out_str = self.dot_nx1.format(ix_str, ix_str)\n        elif iy.ndim >= 2 or ix.ndim == 2:\n            raise ValueError(\n                f\"Undefined behaviour ix.shape:{ix.shape}, iy.shape:{iy.shape}\"\n            )\n        else:\n            out_str = self.dot_1x1\n\n        return np.einsum(out_str, ix, iy, out=out)\n\n    def cross(\n        self, ix: np.ndarray, iy: np.ndarray, out: Optional[np.ndarray] = None\n    ) -> np.ndarray:\n        \"\"\"\n        A row-wise cross product of a 2D matrices of vectors.\n\n        This function mirrors the properties of np.cross\n        such as vectors of 2 or 3 elements. 1D is also accepted\n        but just do x * y.\n        Only 7D has similar orthogonal properties above 3D.\n\n        For optimum speed and customisation use np.einsum modified for your use case.\n\n        Parameters\n        ----------\n        ix:\n            1st array to cross\n        iy:\n            2nd array to cross\n        out:\n            output array for inplace cross product\n\n        Raises\n        ------\n        ValueError\n            If the dimensions of the cross product are > 3\n\n        \"\"\"\n        dim = ix.shape[-1] - 1 if ix.ndim > 1 else 0\n\n        try:\n            return np.einsum(self.cross_strs[dim], self.cross_lcts[dim], ix, iy, out=out)\n        except IndexError:\n            raise ValueError(\"Incompatible dimension for cross product\")",
  "class ColourDescriptor:\n    \"\"\"Colour Descriptor for use with dataclasses\"\"\"\n\n    def __init__(self):\n        self._default = colors.to_hex((0.5, 0.5, 0.5))\n\n    def __set_name__(self, _, name: str):\n        \"\"\"Set the attribute name from a dataclass\"\"\"\n        self._name = \"_\" + name\n\n    def __get__(self, obj: Any, _) -> str:\n        \"\"\"Get the hex colour\"\"\"\n        if obj is None:\n            return self._default\n\n        return colors.to_hex(getattr(obj, self._name, self._default))\n\n    def __set__(self, obj: Any, value: Union[str, Tuple[float, ...], ColorPalette]):\n        \"\"\"\n        Set the colour\n\n        Notes\n        -----\n        The value can be anything accepted by matplotlib.colors.to_hex\n        \"\"\"\n        if hasattr(value, \"as_hex\"):\n            value = value.as_hex()\n            if isinstance(value, list):\n                value = value[0]\n        setattr(obj, self._name, value)",
  "def is_num(thing: Any) -> bool:\n    \"\"\"\n    Determine whether or not the input is a number.\n\n    Parameters\n    ----------\n    thing: unknown type\n        The input which we need to determine is a number or not\n\n    Returns\n    -------\n    Whether or not the input is a number\n    \"\"\"\n    if thing is True or thing is False:\n        return False\n    if thing is np.nan:\n        return False\n    try:\n        float(thing)\n        return True\n    except (ValueError, TypeError):\n        return False",
  "def is_num_array(thing: Any) -> bool:\n    \"\"\"\n    :func:is_num but also includes arrays\n    \"\"\"\n    if isinstance(thing, np.ndarray) and thing.dtype in [float, int, complex]:\n        return ~np.isnan(thing)\n    else:\n        return is_num(thing)",
  "def abs_rel_difference(v2: float, v1_ref: float) -> float:\n    \"\"\"\n    Calculate the absolute relative difference between a new value and an old\n    reference value.\n\n    Parameters\n    ----------\n    v2:\n        The new value to compare to the old\n    v1_ref:\n        The old reference value\n\n    Returns\n    -------\n    The absolute relative difference between v2 and v1ref\n    \"\"\"\n    return abs((v2 - v1_ref) / v1_ref)",
  "def set_random_seed(seed_number: int):\n    \"\"\"\n    Sets the random seed number in numpy and NLopt. Useful when repeatable\n    results are desired in Monte Carlo methods and stochastic optimisation\n    methods.\n\n    Parameters\n    ----------\n    seed_number:\n        The random seed number, preferably a very large integer\n    \"\"\"\n    np.random.seed(seed_number)\n    nlopt.srand(seed_number)",
  "def compare_dicts(\n    d1: Dict[str, Any],\n    d2: Dict[str, Any],\n    almost_equal: bool = False,\n    verbose: bool = True,\n    rtol: float = 1e-5,\n    atol: float = 1e-8,\n) -> bool:\n    \"\"\"\n    Compares two dictionaries. Will print information about the differences\n    between the two to the console. Dictionaries are compared by length, keys,\n    and values per common keys\n\n    Parameters\n    ----------\n    d1:\n        The reference dictionary\n    d2:\n        The dictionary to be compared with the reference\n    almost_equal:\n        Whether or not to use np.isclose and np.allclose for numbers and arrays\n    verbose:\n        Whether or not to print to the console\n    rtol:\n        The relative tolerance parameter, used if ``almost_equal`` is True\n    atol:\n        The absolute tolerance parameter, used if ``almost_equal`` is True\n\n    Returns\n    -------\n    Whether or not the dictionaries are the same\n    \"\"\"\n    nkey_diff = len(d1) - len(d2)\n    k1 = set(d1.keys())\n    k2 = set(d2.keys())\n    intersect = k1.intersection(k2)\n    new_diff = k1 - k2\n    old_diff = k2 - k1\n    same, different = [], []\n\n    # Define functions to use for comparison in either the array, dict, or\n    # numeric cases.\n    def dict_eq(value_1, value_2):\n        return compare_dicts(value_1, value_2, almost_equal, verbose, rtol, atol)\n\n    def array_almost_eq(val1, val2):\n        return np.allclose(val1, val2, rtol, atol)\n\n    def num_almost_eq(val1, val2):\n        return np.isclose(val1, val2, rtol, atol)\n\n    def array_is_eq(val1, val2):\n        return (np.asarray(val1) == np.asarray(val2)).all()\n\n    if almost_equal:\n        array_eq = array_almost_eq\n        num_eq = num_almost_eq\n    else:\n        array_eq = array_is_eq\n        num_eq = operator.eq\n\n    # Map the comparison functions to the keys based on the type of value in d1.\n    comp_map = {\n        key: array_eq\n        if isinstance(val, (np.ndarray, list))\n        else dict_eq\n        if isinstance(val, dict)\n        else num_eq\n        if is_num(val)\n        else operator.eq\n        for key, val in d1.items()\n    }\n\n    # Do the comparison\n    for k in intersect:\n        v1, v2 = d1[k], d2[k]\n        try:\n            if comp_map[k](v1, v2):\n                same.append(k)\n            else:\n                different.append(k)\n        except ValueError:  # One is an array and the other not\n            different.append(k)\n\n    the_same = False\n    result = \"===========================================================\\n\"\n    if nkey_diff != 0:\n        compare = \"more\" if nkey_diff > 0 else \"fewer\"\n        result += f\"d1 has {nkey_diff} {compare} keys than d2\" + \"\\n\"\n    if new_diff != set():\n        result += \"d1 has the following keys which d2 does not have:\\n\"\n        new_diff = [\"\\t\" + str(i) for i in new_diff]\n        result += \"\\n\".join(new_diff) + \"\\n\"\n    if old_diff != set():\n        result += \"d2 has the following keys which d1 does not have:\\n\"\n        old_diff = [\"\\t\" + str(i) for i in old_diff]\n        result += \"\\n\".join(old_diff) + \"\\n\"\n    if different:\n        result += \"the following shared keys have different values:\\n\"\n        different = [\"\\t\" + str(i) for i in different]\n        result += \"\\n\".join(different) + \"\\n\"\n    if nkey_diff == 0 and new_diff == set() and old_diff == set() and different == []:\n        the_same = True\n    else:\n        result += \"===========================================================\"\n        if verbose:\n            print(result)\n    return the_same",
  "def clip(\n    val: Union[float, np.ndarray],\n    val_min: Union[float, np.ndarray],\n    val_max: Union[float, np.ndarray],\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Clips (limits) val between val_min and val_max.\n    This function wraps the numpy core umath minimum and maximum functions\n    in order to avoid the standard numpy clip function, as described in:\n    https://github.com/numpy/numpy/issues/14281\n\n    Handles scalars using built-ins.\n\n    Parameters\n    ----------\n    val:\n        The value to be clipped.\n    val_min:\n        The minimum value.\n    val_max:\n        The maximum value.\n\n    Returns\n    -------\n    The clipped values.\n    \"\"\"\n    if isinstance(val, np.ndarray):\n        np.core.umath.clip(val, val_min, val_max, out=val)\n    else:\n        val = val_min if val < val_min else val_max if val > val_max else val\n    return val",
  "def flatten_iterable(iters):\n    \"\"\"\n    Expands a nested iterable structure, flattening it into one iterable\n\n    Parameters\n    ----------\n    lists: set of Iterables\n        The object(s) to de-nest\n\n    Yields\n    ------\n        elements of iterable\n\n    Notes\n    -----\n    Does not cater for nested dictionaries\n\n    \"\"\"\n    for _iter in iters:\n        if isinstance(_iter, Iterable) and not isinstance(_iter, (str, bytes, dict)):\n            for _it in flatten_iterable(_iter):\n                yield _it\n        else:\n            yield _iter",
  "def consec_repeat_elem(arr: np.ndarray, num_rep: int) -> np.ndarray:\n    \"\"\"\n    Get array of repeated elements with n or more repeats\n\n    Parameters\n    ----------\n    arr:\n        array to find repeats in\n    num_rep:\n        number of repetitions to find\n    \"\"\"\n    if num_rep <= 1:\n        raise NotImplementedError(\"Not implemented for less than 2 repeat elements\")\n    n = num_rep - 1\n    m = arr[:-1] == arr[1:]\n    return np.flatnonzero(np.convolve(m, np.ones(n, dtype=int)) == n) - n + 1",
  "def slope(arr: np.ndarray) -> float:\n    \"\"\"Calculate gradient of a 2x2 point array\"\"\"\n    b = arr[1, 0] - arr[0, 0]\n    return np.inf if b == 0 else (arr[1, 1] - arr[0, 1]) / b",
  "def yintercept(arr: np.ndarray) -> Tuple[float]:\n    \"\"\"Calculate the y intercept and gradient of an array\"\"\"\n    s = slope(arr)\n    return arr[0, 1] - s * arr[0, 0], s",
  "def cartesian_to_polar(\n    x: np.ndarray, z: np.ndarray, x_ref: float = 0.0, z_ref: float = 0.0\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Convert from 2-D Cartesian coordinates to polar coordinates about a reference point.\n\n    Parameters\n    ----------\n    x:\n        Radial coordinates\n    z:\n        Vertical coordinates\n    x_ref:\n        Reference radial coordinate\n    z_ref:\n        Reference vertical coordinate\n\n    Returns\n    -------\n    r:\n        Polar radial coordinates\n    phi:\n        Polar angle coordinates\n    \"\"\"\n    xi, zi = x - x_ref, z - z_ref\n    r = np.hypot(xi, zi)\n    phi = np.arctan2(zi, xi)\n    return r, phi",
  "def polar_to_cartesian(\n    r: np.ndarray, phi: np.ndarray, x_ref: float = 0.0, z_ref: float = 0.0\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Convert from 2-D polar to Cartesian coordinates about a reference point.\n\n    Parameters\n    ----------\n    r:\n        Polar radial coordinates\n    phi:\n        Polar angle coordinates\n    x_ref:\n        Reference radial coordinate\n    z_ref:\n        Reference vertical coordinate\n\n    Returns\n    -------\n    x:\n        Radial coordinates\n    z:\n        Vertical coordinate\n    \"\"\"\n    x = x_ref + r * np.cos(phi)\n    z = z_ref + r * np.sin(phi)\n    return x, z",
  "def get_module(name: str) -> ModuleType:\n    \"\"\"\n    Load module dynamically.\n\n    Parameters\n    ----------\n    name:\n        Filename or python path (a.b.c) of module to import\n\n    Returns\n    -------\n    Loaded module\n    \"\"\"\n    try:\n        module = imp(name)\n    except ImportError:\n        module = _loadfromspec(name)\n    bluemira_debug(f\"Loaded module {module.__name__}\")\n    return module",
  "def _loadfromspec(name: str) -> ModuleType:\n    \"\"\"\n    Load module from filename.\n\n    Parameters\n    ----------\n    name:\n        Filename of module to import\n\n    Returns\n    -------\n    Loaded module\n    \"\"\"\n    full_dirname = name.rsplit(\"/\", 1)\n    dirname = \".\" if len(full_dirname[0]) == 0 else full_dirname[0]\n\n    try:\n        mod_files = [\n            file for file in listdir(dirname) if file.startswith(full_dirname[1])\n        ]\n    except FileNotFoundError:\n        raise FileNotFoundError(\"Can't find module file '{}'\".format(name))\n\n    if len(mod_files) == 0:\n        raise FileNotFoundError(\"Can't find module file '{}'\".format(name))\n\n    requested = full_dirname[1] if full_dirname[1] in mod_files else mod_files[0]\n\n    if len(mod_files) > 1:\n        bluemira_warn(\n            \"{}{}\".format(\n                \"Multiple files start with '{}'\\n\".format(full_dirname[1]),\n                \"Assuming module is '{}'\".format(requested),\n            )\n        )\n\n    mod_file = f\"{dirname}/{requested}\"\n\n    name, ext = requested.rsplit(\".\", 1) if \".\" in requested else (requested, \"\")\n    if ext not in imp_mach.SOURCE_SUFFIXES:\n        if ext != \"\" and not ext.startswith(\".\"):\n            ext = f\".{ext}\"\n        n_suffix = True\n        imp_mach.SOURCE_SUFFIXES.append(ext)\n    else:\n        n_suffix = False\n\n    try:\n        spec = imp_u.spec_from_file_location(name, mod_file)\n        module = imp_u.module_from_spec(spec)\n        spec.loader.exec_module(module)\n    except ModuleNotFoundError as mnfe:\n        raise mnfe\n    except (AttributeError, ImportError, SyntaxError):\n        raise ImportError(f\"File '{mod_files[0]}' is not a module\")\n\n    if n_suffix:\n        imp_mach.SOURCE_SUFFIXES.pop()\n\n    return module",
  "def get_class_from_module(name: str, default_module: str = \"\") -> Type:\n    \"\"\"\n    Load a class from a module dynamically.\n\n    Parameters\n    ----------\n    name:\n        Filename or python path (a.b.c) of module to import, with specific class to load\n        appended following :: e.g. my_package.my_module::my_class. If the default_module\n        is provided then only the class name (e.g. my_class) needs to be provided.\n    default_module:\n        The default module to search for the class, by default \"\". If provided then if\n        name does not contain a module path then this the default module will be used to\n        search for the class. Can be overridden if the name provides a module path.\n\n    Returns\n    -------\n    Loaded class\n    \"\"\"\n    module = default_module\n    class_name = name\n    if \"::\" in class_name:\n        module, class_name = class_name.split(\"::\")\n    try:\n        output = getattr(get_module(module), class_name)\n    except AttributeError:\n        raise ImportError(f\"Unable to load class {class_name} - not in module {module}\")\n\n    bluemira_debug(f\"Loaded class {output.__name__}\")\n    return output",
  "def list_array(list_: Any) -> np.ndarray:\n    \"\"\"\n    Always returns a numpy array\n    Can handle int, float, list, np.ndarray\n\n    Parameters\n    ----------\n    list_:\n        The value to convert into a numpy array.\n\n    Returns\n    -------\n    he value as a numpy array.\n\n    Raises\n    ------\n    TypeError\n        If the value cannot be converted to a numpy array.\n    \"\"\"\n    if isinstance(list_, list):\n        return np.array(list_)\n    elif isinstance(list_, np.ndarray):\n        try:  # This catches the odd np.array(8) instead of np.array([8])\n            len(list_)\n            return list_\n        except TypeError:\n            return np.array([list_])\n    elif is_num(list_):\n        return np.array([list_])\n    else:\n        raise TypeError(\"Could not convert input type to list_array to a np.array.\")",
  "def array_or_num(array: Any) -> Union[np.ndarray, float]:\n    \"\"\"\n    Always returns a numpy array or a float\n\n    Parameters\n    ----------\n    array:\n        The value to convert into a numpy array or number.\n\n    Returns\n    -------\n    The value as a numpy array or number.\n\n    Raises\n    ------\n    TypeError\n        If the value cannot be converted to a numpy or number.\n    \"\"\"\n    if is_num(array):\n        return float(array)\n    elif isinstance(array, np.ndarray):\n        return array\n    else:\n        raise TypeError",
  "def deprecation_wrapper(\n    message: Union[Optional[Callable[[Any], Any]], Optional[str]]\n) -> Callable[[Any], Any]:\n    \"\"\"Deprecate any callable.\n\n    Parameters\n    ----------\n    message:\n        The callable to deprecate or the message to show\n    \"\"\"\n\n    def _decorate(func: Callable[[Any], Any]) -> Callable[[Any], Any]:\n        \"\"\"Deprecate any callable.\n\n        Parameters\n        ----------\n        func:\n            The callable to deprecate\n        \"\"\"\n\n        @wraps(func)\n        def deprecator(*args, **kwargs) -> Any:\n            warnings.warn(\n                message\n                if isinstance(message, str)\n                else f\"'{func.__name__}' is deprecated and will be removed in the next major release\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            return func(*args, **kwargs)\n\n        return deprecator\n\n    if callable(message):\n        return _decorate(message)\n\n    return _decorate",
  "def default(self, obj):\n        \"\"\"\n        Override the JSONEncoder default object handling behaviour for np.arrays.\n        \"\"\"\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        return super().default(obj)",
  "def __init__(self):\n        norm_a0 = \"ij, ij -> j\"\n        norm_a1 = \"ij, ij -> i\"\n\n        self.norm_strs = [norm_a0, norm_a1]\n\n        # Not fool proof for huge no's of dims\n        self.dot_1x1 = \"i, i -> ...\"\n        self.dot_1x2 = \"i, ik -> k\"\n        self.dot_2x1 = \"ij, j -> i\"\n        self.dot_2x2 = \"ij, jk -> ik\"\n        self.dot_1xn = \"y, {}yz -> {}z\"\n        self.dot_nx1 = \"{}z, z -> {}\"\n        self.dot_nxn = \"{}y, {}yz -> {}z\"\n\n        cross_2x1 = \"i, i, i -> i\"\n        cross_2x2 = \"xy, ix, iy -> i\"\n        cross_2x3 = \"xyz, ix, iy -> iz\"\n\n        self.cross_strs = [cross_2x1, cross_2x2, cross_2x3]\n        self.cross_lcts = [E_I, E_IJ, E_IJK]",
  "def norm(self, ix: np.ndarray, axis: int = 0) -> np.ndarray:\n        \"\"\"\n        Emulates some of the functionality of np.linalg.norm for 2D arrays.\n\n        Specifically:\n        np.linalg.norm(ix, axis=0)\n        np.linalg.norm(ix, axis=1)\n\n        For optimum speed and customisation use np.einsum modified for your use case.\n\n        Parameters\n        ----------\n        ix:\n            Array to perform norm on\n        axis:\n            axis for the norm to occur on\n        \"\"\"\n        try:\n            return np.sqrt(np.einsum(self.norm_strs[axis], ix, ix))\n        except IndexError:\n            raise ValueError(\"matrices dimensions >2d Unsupported\")",
  "def dot(\n        self, ix: np.ndarray, iy: np.ndarray, out: Optional[np.ndarray] = None\n    ) -> np.ndarray:\n        \"\"\"\n        A dot product emulation using np.einsum.\n\n        For optimum speed and customisation use np.einsum modified for your use case.\n\n        Should follow the same mechanics as np.dot, a few examples:\n\n        ein_str = 'i, i -> ...'\n        ein_str = 'ij, jk -> ik' # Classic dot product\n        ein_str = 'ij, j -> i'\n        ein_str = 'i, ik -> k'\n        ein_str = 'aij, ajk -> aik' # for loop needed with np.dot\n\n        Parameters\n        ----------\n        ix:\n            First array\n        iy:\n            Second array\n        out:\n            output array for inplace dot product\n        \"\"\"\n        # Ordered hopefully by most used\n        if ix.ndim == 2 and iy.ndim == 2:\n            out_str = self.dot_2x2\n        elif ix.ndim > 2 and iy.ndim > 2:\n            ix_str = asciistr(ix.ndim - 1)\n            iy_str = asciistr(iy.ndim - 2)\n            out_str = self.dot_nxn.format(ix_str, iy_str, ix_str)\n        elif ix.ndim < 2 and iy.ndim == 2:\n            out_str = self.dot_1x2\n        elif ix.ndim >= 2 and iy.ndim < 2:\n            ix_str = asciistr(ix.ndim - 1)\n            out_str = self.dot_nx1.format(ix_str, ix_str)\n        elif iy.ndim >= 2 or ix.ndim == 2:\n            raise ValueError(\n                f\"Undefined behaviour ix.shape:{ix.shape}, iy.shape:{iy.shape}\"\n            )\n        else:\n            out_str = self.dot_1x1\n\n        return np.einsum(out_str, ix, iy, out=out)",
  "def cross(\n        self, ix: np.ndarray, iy: np.ndarray, out: Optional[np.ndarray] = None\n    ) -> np.ndarray:\n        \"\"\"\n        A row-wise cross product of a 2D matrices of vectors.\n\n        This function mirrors the properties of np.cross\n        such as vectors of 2 or 3 elements. 1D is also accepted\n        but just do x * y.\n        Only 7D has similar orthogonal properties above 3D.\n\n        For optimum speed and customisation use np.einsum modified for your use case.\n\n        Parameters\n        ----------\n        ix:\n            1st array to cross\n        iy:\n            2nd array to cross\n        out:\n            output array for inplace cross product\n\n        Raises\n        ------\n        ValueError\n            If the dimensions of the cross product are > 3\n\n        \"\"\"\n        dim = ix.shape[-1] - 1 if ix.ndim > 1 else 0\n\n        try:\n            return np.einsum(self.cross_strs[dim], self.cross_lcts[dim], ix, iy, out=out)\n        except IndexError:\n            raise ValueError(\"Incompatible dimension for cross product\")",
  "def __init__(self):\n        self._default = colors.to_hex((0.5, 0.5, 0.5))",
  "def __set_name__(self, _, name: str):\n        \"\"\"Set the attribute name from a dataclass\"\"\"\n        self._name = \"_\" + name",
  "def __get__(self, obj: Any, _) -> str:\n        \"\"\"Get the hex colour\"\"\"\n        if obj is None:\n            return self._default\n\n        return colors.to_hex(getattr(obj, self._name, self._default))",
  "def __set__(self, obj: Any, value: Union[str, Tuple[float, ...], ColorPalette]):\n        \"\"\"\n        Set the colour\n\n        Notes\n        -----\n        The value can be anything accepted by matplotlib.colors.to_hex\n        \"\"\"\n        if hasattr(value, \"as_hex\"):\n            value = value.as_hex()\n            if isinstance(value, list):\n                value = value[0]\n        setattr(obj, self._name, value)",
  "def dict_eq(value_1, value_2):\n        return compare_dicts(value_1, value_2, almost_equal, verbose, rtol, atol)",
  "def array_almost_eq(val1, val2):\n        return np.allclose(val1, val2, rtol, atol)",
  "def num_almost_eq(val1, val2):\n        return np.isclose(val1, val2, rtol, atol)",
  "def array_is_eq(val1, val2):\n        return (np.asarray(val1) == np.asarray(val2)).all()",
  "def _decorate(func: Callable[[Any], Any]) -> Callable[[Any], Any]:\n        \"\"\"Deprecate any callable.\n\n        Parameters\n        ----------\n        func:\n            The callable to deprecate\n        \"\"\"\n\n        @wraps(func)\n        def deprecator(*args, **kwargs) -> Any:\n            warnings.warn(\n                message\n                if isinstance(message, str)\n                else f\"'{func.__name__}' is deprecated and will be removed in the next major release\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            return func(*args, **kwargs)\n\n        return deprecator",
  "def deprecator(*args, **kwargs) -> Any:\n            warnings.warn(\n                message\n                if isinstance(message, str)\n                else f\"'{func.__name__}' is deprecated and will be removed in the next major release\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            return func(*args, **kwargs)",
  "class OptimisationConstraint:\n    \"\"\"\n    Data class to store information needed to apply a constraint\n    to an optimisation problem.\n\n    Parameters\n    ----------\n    f_constraint: callable\n        Constraint function to apply to problem.\n        For NLOpt constraints, constraint functions should be of the form\n        f_constraint(constraint, x, grad, f_constraint_args)\n    f_constraint_args: dict (default = None)\n        Additional arguments to pass to NLOpt constraint function when called.\n    tolerance: array\n        Array of tolerances to use when applying the optimisation constraint.\n    constraint_type: string (default: \"inequality\")\n        Type of constraint to apply, either \"inequality\" or \"equality\".\n    \"\"\"\n\n    def __init__(\n        self,\n        f_constraint,\n        f_constraint_args=None,\n        tolerance=np.array([1e-6]),\n        constraint_type=\"inequality\",\n    ):\n        self._tolerance = tolerance\n        self._constraint_type = constraint_type\n        self._f_constraint = f_constraint\n        self._args = f_constraint_args\n\n    def __call__(self, constraint, vector, grad):\n        \"\"\"\n        Call to constraint function used by NLOpt, passing in arguments.\n        \"\"\"\n        return self._f_constraint(constraint, vector, grad, **self._args)\n\n    def apply_constraint(self, opt_problem):\n        \"\"\"\n        Apply constraint to a specified OptimisationProblem.\n        \"\"\"\n        # Add optimisation problem to constraint arguments if needed by\n        # constraint function\n        if \"opt_problem\" in inspect.getfullargspec(self._f_constraint).args:\n            self._args[\"opt_problem\"] = opt_problem\n\n        # Apply constraint to optimiser\n        if self._constraint_type == \"inequality\":\n            opt_problem.opt.add_ineq_constraints(self, self._tolerance)\n        elif self._constraint_type == \"equality\":\n            opt_problem.opt.add_eq_constraints(self, self._tolerance)",
  "class OptimisationObjective:\n    \"\"\"\n    Data class to store information needed to apply a constraint\n    to an optimisation problem.\n\n    Parameters\n    ----------\n    f_objective: callable\n        Objective function to apply to problem.\n        For NLOpt objectives, objective functions should be of the form\n        f_objective(x, grad, f_objective_args)\n    f_objective_args: dict (default = None)\n        Additional arguments to pass to NLOpt objective function when called.\n    \"\"\"\n\n    def __init__(self, f_objective, f_objective_args=None):\n        self._f_objective = f_objective\n        self._args = f_objective_args if f_objective_args is not None else {}\n\n    def __call__(self, vector, grad):\n        \"\"\"\n        Call to objective function used by NLOpt, passing in arguments.\n        \"\"\"\n        return self._f_objective(vector, grad, **self._args)\n\n    def apply_objective(self, opt_problem):\n        \"\"\"\n        Apply objective to a specified OptimisationProblem.\n        \"\"\"\n        # Add optimisation problem to objective arguments if needed by\n        # objective function\n        if \"opt_problem\" in inspect.getfullargspec(self._f_objective).args:\n            self._args[\"opt_problem\"] = opt_problem\n\n        # Apply objective to optimiser\n        opt_problem.opt.set_objective_function(self)",
  "class OptimisationProblem(ABC):\n    \"\"\"\n    Abstract base class to be subclassed for defining optimisation\n    routines in bluemira.\n\n    Subclasses should provide an optimise() method that\n    returns an optimised parameterisation object, optimised according\n    to a specific objective function for that subclass.\n\n    Parameters\n    ----------\n    parameterisation: any\n        Object storing parameterisation data to be optimised.\n    optimiser: bluemira.utilities.optimiser.Optimiser (default: None)\n        Optimiser object to use for constrained optimisation.\n        Does not need to be provided if not used by\n        optimise(), such as for purely unconstrained\n        optimisation.\n    objective: OptimisationObjective (default: None)\n        OptimisationObjective storing objective information to\n        provide to the Optimiser.\n    constraints: List[OptimisationConstraint]\n        Optional list of OptimisationConstraint objects storing\n        information about constraints that must be satisfied\n        during the optimisation, to be provided to the\n        Optimiser.\n    \"\"\"\n\n    def __init__(\n        self,\n        parameterisation,\n        optimiser: Optimiser,\n        objective: OptimisationObjective,\n        constraints: List[OptimisationConstraint],\n    ):\n        self._parameterisation = parameterisation\n        self.opt = optimiser\n        self._objective = objective\n        self._constraints = constraints\n\n    def set_up_optimiser(self, dimension: int, bounds: np.ndarray):\n        \"\"\"\n        Set up NLOpt-based optimiser with algorithm,  bounds, tolerances, and\n        constraint & objective functions.\n\n        Parameters\n        ----------\n        dimension: int\n            Number of independent variables in the state vector to be optimised.\n        bounds: tuple\n            Tuple containing lower and upper bounds on the state vector.\n        \"\"\"\n        # Build NLOpt optimiser, with optimisation strategy and length\n        # of state vector\n        self.opt.build_optimiser(n_variables=dimension)\n\n        # Apply objective function to optimiser\n        self._objective.apply_objective(self)\n\n        # Apply constraints\n        if self._constraints is not None:\n            self.apply_constraints(self.opt, self._constraints)\n\n        # Set state vector bounds\n        self.opt.set_lower_bounds(bounds[0])\n        self.opt.set_upper_bounds(bounds[1])\n\n    def apply_constraints(\n        self, opt: Optimiser, opt_constraints: List[OptimisationConstraint]\n    ):\n        \"\"\"\n        Updates the optimiser in-place to apply problem constraints.\n        To be overridden by child classes to apply specific constraints.\n\n        Parameters\n        ----------\n        opt: bluemira.utilities.optimiser.Optimiser\n            Optimiser on which to apply the constraints. Updated in place.\n        opt_constraints: iterable\n            Iterable of OptimisationConstraint objects containing optimisation\n            constraints to be applied to the Optimiser.\n        \"\"\"\n        for _opt_constraint in opt_constraints:\n            _opt_constraint.apply_constraint(self)\n        return opt\n\n    def initialise_state(self, parameterisation) -> np.array:\n        \"\"\"\n        Initialises state vector to be passed to optimiser from object used\n        in parameterisation, at each optimise() call.\n        To be overridden as needed.\n        \"\"\"\n        initial_state = parameterisation\n        return initial_state\n\n    def update_parametrisation(self, state: np.ndarray):\n        \"\"\"\n        Update parameterisation object using the state vector.\n        To be overridden as needed.\n        \"\"\"\n        parameterisation = state\n        return parameterisation\n\n    @abstractmethod\n    def optimise(self):\n        \"\"\"\n        Optimisation routine used to return an optimised parameterisation.\n\n        Returns\n        -------\n        self._parameterisation:\n            Optimised parameterisation object.\n        \"\"\"\n        initial_state = self.initialise_state(self._parameterisation)\n        opt_state = self.opt.optimise(initial_state)\n        self._parameterisation = self.update_parametrisation(opt_state)\n        return self._parameterisation",
  "def __init__(\n        self,\n        f_constraint,\n        f_constraint_args=None,\n        tolerance=np.array([1e-6]),\n        constraint_type=\"inequality\",\n    ):\n        self._tolerance = tolerance\n        self._constraint_type = constraint_type\n        self._f_constraint = f_constraint\n        self._args = f_constraint_args",
  "def __call__(self, constraint, vector, grad):\n        \"\"\"\n        Call to constraint function used by NLOpt, passing in arguments.\n        \"\"\"\n        return self._f_constraint(constraint, vector, grad, **self._args)",
  "def apply_constraint(self, opt_problem):\n        \"\"\"\n        Apply constraint to a specified OptimisationProblem.\n        \"\"\"\n        # Add optimisation problem to constraint arguments if needed by\n        # constraint function\n        if \"opt_problem\" in inspect.getfullargspec(self._f_constraint).args:\n            self._args[\"opt_problem\"] = opt_problem\n\n        # Apply constraint to optimiser\n        if self._constraint_type == \"inequality\":\n            opt_problem.opt.add_ineq_constraints(self, self._tolerance)\n        elif self._constraint_type == \"equality\":\n            opt_problem.opt.add_eq_constraints(self, self._tolerance)",
  "def __init__(self, f_objective, f_objective_args=None):\n        self._f_objective = f_objective\n        self._args = f_objective_args if f_objective_args is not None else {}",
  "def __call__(self, vector, grad):\n        \"\"\"\n        Call to objective function used by NLOpt, passing in arguments.\n        \"\"\"\n        return self._f_objective(vector, grad, **self._args)",
  "def apply_objective(self, opt_problem):\n        \"\"\"\n        Apply objective to a specified OptimisationProblem.\n        \"\"\"\n        # Add optimisation problem to objective arguments if needed by\n        # objective function\n        if \"opt_problem\" in inspect.getfullargspec(self._f_objective).args:\n            self._args[\"opt_problem\"] = opt_problem\n\n        # Apply objective to optimiser\n        opt_problem.opt.set_objective_function(self)",
  "def __init__(\n        self,\n        parameterisation,\n        optimiser: Optimiser,\n        objective: OptimisationObjective,\n        constraints: List[OptimisationConstraint],\n    ):\n        self._parameterisation = parameterisation\n        self.opt = optimiser\n        self._objective = objective\n        self._constraints = constraints",
  "def set_up_optimiser(self, dimension: int, bounds: np.ndarray):\n        \"\"\"\n        Set up NLOpt-based optimiser with algorithm,  bounds, tolerances, and\n        constraint & objective functions.\n\n        Parameters\n        ----------\n        dimension: int\n            Number of independent variables in the state vector to be optimised.\n        bounds: tuple\n            Tuple containing lower and upper bounds on the state vector.\n        \"\"\"\n        # Build NLOpt optimiser, with optimisation strategy and length\n        # of state vector\n        self.opt.build_optimiser(n_variables=dimension)\n\n        # Apply objective function to optimiser\n        self._objective.apply_objective(self)\n\n        # Apply constraints\n        if self._constraints is not None:\n            self.apply_constraints(self.opt, self._constraints)\n\n        # Set state vector bounds\n        self.opt.set_lower_bounds(bounds[0])\n        self.opt.set_upper_bounds(bounds[1])",
  "def apply_constraints(\n        self, opt: Optimiser, opt_constraints: List[OptimisationConstraint]\n    ):\n        \"\"\"\n        Updates the optimiser in-place to apply problem constraints.\n        To be overridden by child classes to apply specific constraints.\n\n        Parameters\n        ----------\n        opt: bluemira.utilities.optimiser.Optimiser\n            Optimiser on which to apply the constraints. Updated in place.\n        opt_constraints: iterable\n            Iterable of OptimisationConstraint objects containing optimisation\n            constraints to be applied to the Optimiser.\n        \"\"\"\n        for _opt_constraint in opt_constraints:\n            _opt_constraint.apply_constraint(self)\n        return opt",
  "def initialise_state(self, parameterisation) -> np.array:\n        \"\"\"\n        Initialises state vector to be passed to optimiser from object used\n        in parameterisation, at each optimise() call.\n        To be overridden as needed.\n        \"\"\"\n        initial_state = parameterisation\n        return initial_state",
  "def update_parametrisation(self, state: np.ndarray):\n        \"\"\"\n        Update parameterisation object using the state vector.\n        To be overridden as needed.\n        \"\"\"\n        parameterisation = state\n        return parameterisation",
  "def optimise(self):\n        \"\"\"\n        Optimisation routine used to return an optimised parameterisation.\n\n        Returns\n        -------\n        self._parameterisation:\n            Optimised parameterisation object.\n        \"\"\"\n        initial_state = self.initialise_state(self._parameterisation)\n        opt_state = self.opt.optimise(initial_state)\n        self._parameterisation = self.update_parametrisation(opt_state)\n        return self._parameterisation",
  "class ConfigParams:\n    \"\"\"Container for the global and local parameters of a `ReactorConfig`.\"\"\"\n\n    global_params: ParameterFrame\n    local_params: Dict",
  "class ReactorConfig:\n    \"\"\"\n    Class that provides a simple interface over config JSON files and\n    handles overwriting multiply defined attributes.\n\n    If an attribute is defined more than once in a component,\n    the more globally scoped value is used (global overwrites local).\n\n    Parameters\n    ----------\n    config_path:\n        The path to the config JSON file or a dict of the data.\n    global_params_type:\n        The ParameterFrame type for the global params.\n    warn_on_duplicate_keys:\n        Print a warning when duplicate keys are found,\n        whose value will be overwritten.\n    warn_on_empty_local_params:\n        Print a warning when the local params for some args are empty,\n        when calling params_for(args)\n    warn_on_empty_config:\n        Print a warning when the config for some args are empty,\n        when calling config_for(args)\n\n    Example\n    -------\n\n    .. code-block:: python\n\n        @dataclass\n        class GlobalParams(ParameterFrame):\n            a: Parameter[int]\n\n\n        reactor_config = ReactorConfig(\n            {\n                \"params\": {\"a\": 10},\n                \"comp A\": {\n                    \"params\": {\"a\": 5, \"b\": 5},\n                    \"designer\": {\n                        \"params\": {\"a\": 1},\n                        \"some_config\": \"some_value\",\n                    },\n                    \"builder\": {\n                        \"params\": {\"b\": 1, \"c\": 1},\n                        \"another_config\": \"another_value\",\n                    },\n                },\n                \"comp B\": {\n                    \"params\": {\"b\": 5},\n                    \"builder\": {\n                        \"third_config\": \"third_value\",\n                    },\n                },\n            },\n            GlobalParams,\n        )\n\n    \"\"\"\n\n    def __init__(\n        self,\n        config_path: Union[str, Path, dict],\n        global_params_type: Type[_PfT],\n        warn_on_duplicate_keys: bool = False,\n        warn_on_empty_local_params: bool = False,\n        warn_on_empty_config: bool = False,\n    ):\n        self.warn_on_duplicate_keys = warn_on_duplicate_keys\n        self.warn_on_empty_local_params = warn_on_empty_local_params\n        self.warn_on_empty_config = warn_on_empty_config\n\n        config_data = self._read_or_return(config_path)\n        if isinstance(config_path, (Path, str)):\n            self._expand_paths_in_dict(config_data, Path(config_path).parent)\n\n        self.config_data = config_data\n        self.global_params = make_parameter_frame(\n            self.config_data.get(_PARAMETERS_KEY, {}),\n            global_params_type,\n        )\n\n        if not self.global_params:\n            bluemira_warn(\"Empty global params\")\n\n    def __str__(self) -> str:\n        \"\"\"Returns config_data as a nicely pretty formatted string\"\"\"\n        return self._pprint_dict(self.config_data)\n\n    @staticmethod\n    def _warn_or_debug_log(msg: str, warn: bool) -> None:\n        if warn:\n            bluemira_warn(msg)\n        else:\n            bluemira_debug(msg)\n\n    def params_for(self, component_name: str, *args: str) -> ConfigParams:\n        \"\"\"\n        Gets the params for the `component_name` from the config file.\n\n        These are all the values defined by a \"params\"\n        key in the config file.\n\n        This will merge all multiply defined params,\n        with global overwriting local.\n\n        Parameters\n        ----------\n        component_name:\n            The component name, must match a key in the config\n        *args:\n            Optionally, specify the keys of nested attributes.\n\n            This will hoist the values defined in the nested attributes\n            to the top level of the `local_params` dict\n            in the returned `ConfigParams` object.\n\n            The args must be in the order that they appear in the config.\n\n        Returns\n        -------\n        Holds the global_params (from `self.global_params`)\n        and the extracted local_params.\n\n        Use the\n        :func:`~bluemira.base.parameter_frame._frame.make_parameter_frame`\n        helper function to convert it into a typed ParameterFrame.\n        \"\"\"\n        args = (component_name,) + args\n        self._check_args_are_strings(args)\n\n        local_params = self._extract(args, is_config=False)\n        if not local_params:\n            self._warn_or_debug_log(\n                f\"Empty local params for args: {args}\", self.warn_on_empty_local_params\n            )\n\n        return ConfigParams(\n            global_params=self.global_params,\n            local_params=local_params,\n        )\n\n    def config_for(self, component_name: str, *args: str) -> dict:\n        \"\"\"\n        Gets the config for the `component_name` from the config file.\n\n        These are all the values other than\n        those defined by a \"params\" key in the config file.\n\n        This will merge all multiply defined values,\n        with global overwriting local.\n\n        Parameters\n        ----------\n        component_name:\n            The component name, must match a key in the config\n        *args:\n            Optionally, specify the keys of nested attributes.\n\n            This will hoist the values defined in the nested attributes\n            to the top level of the returned dict.\n\n            The args must be in the order that they appear in the config.\n\n        Returns\n        -------\n        The extracted config.\n        \"\"\"\n        args = (component_name,) + args\n        self._check_args_are_strings(args)\n\n        _return = self._extract(args, is_config=True)\n        if not _return:\n            self._warn_or_debug_log(\n                f\"Empty config for args: {args}\", self.warn_on_empty_config\n            )\n\n        return _return\n\n    @staticmethod\n    def _read_or_return(config_path: Union[str, Path, dict]) -> Dict:\n        if isinstance(config_path, (str, Path)):\n            return ReactorConfig._read_json_file(config_path)\n        elif isinstance(config_path, dict):\n            return config_path\n        raise ReactorConfigError(\n            f\"config_path must be either a dict, a Path object, or a string, found {type(config_path)}.\"\n        )\n\n    @staticmethod\n    def _read_json_file(path: Union[Path, str]) -> dict:\n        with open(path, \"r\") as f:\n            return json.load(f)\n\n    def _pprint_dict(self, d: dict) -> str:\n        return pprint.pformat(d, sort_dicts=False, indent=1)\n\n    def _warn_on_duplicate_keys(\n        self,\n        shared_key: str,\n        arg: str,\n        existing_value,\n    ):\n        self._warn_or_debug_log(\n            \"duplicate config key: \"\n            f\"'{shared_key}' in {arg} wil be overwritten with {existing_value}\",\n            self.warn_on_duplicate_keys,\n        )\n\n    def _check_args_are_strings(self, args: Iterable[str]):\n        for a in args:\n            if not isinstance(a, str):\n                raise ReactorConfigError(\"args must be strings\")\n\n    def _expand_paths_in_dict(self, d: Dict[str, Any], rel_path: Path):\n        \"\"\"\n        Expand all file paths by replacing their values with the json file's contents.\n\n        Notes\n        -----\n            This mutates the passed in dict.\n        \"\"\"\n        for k in d:\n            d[k], rel_path_from = self._extract_and_expand_file_data_if_needed(\n                d[k], rel_path\n            )\n            if isinstance(d[k], dict):\n                self._expand_paths_in_dict(d[k], rel_path_from)\n\n    def _extract_and_expand_file_data_if_needed(\n        self, value: Any, rel_path: Path\n    ) -> Tuple[Union[Any, dict], str]:\n        \"\"\"\n        Returns the file data and the path to the file if value is a path.\n\n        Otherwise, returns value and rel_path that was passed in.\n\n        rel_path is the path to the file that the value is in.\n\n        Notes\n        -----\n        If the value is not a path, returns the value and the passed in rel_path.\n        \"\"\"\n        if not isinstance(value, str):\n            return value, rel_path\n        if not value.startswith(_FILEPATH_PREFIX):\n            return value, rel_path\n\n        # remove _FILEPATH_PREFIX\n        f_path = value[len(_FILEPATH_PREFIX) :]\n\n        # if the path does not start with a /, it is considered a relative path,\n        # relative to the file the path is in (i.e. rel_path)\n        if not f_path.startswith(\"/\"):\n            f_path = rel_path / f_path\n        else:\n            f_path = Path(f_path)\n\n        # check if file exists\n        if not f_path.is_file():\n            raise FileNotFoundError(f\"Cannot find file {f_path}\")\n\n        f_data = self._read_json_file(f_path)\n        return f_data, f_path.parent\n\n    def _extract(self, arg_keys: Tuple[str], is_config: bool) -> dict:\n        extracted = {}\n\n        # this routine is designed not to copy any dict's while parsing\n\n        current_layer = self.config_data\n\n        for next_idx, current_arg_key in enumerate(arg_keys, start=1):\n            current_layer = current_layer.get(current_arg_key, {})\n            next_arg_key = arg_keys[next_idx] if next_idx < len(arg_keys) else None\n\n            to_extract = current_layer\n            if not is_config:\n                # if doing a params extraction,\n                # get the values from the _PARAMETERS_KEY\n                to_extract = current_layer.get(_PARAMETERS_KEY, {})\n\n            if not isinstance(to_extract, dict):\n                raise ReactorConfigError(\n                    f\"Arg {current_arg_key} is too specific, \"\n                    \"it must either be another JSON object \"\n                    \"or a path to a JSON file.\"\n                )\n\n            # add all keys not in extracted already\n            # if doing a config, ignore the \"params\" (_PARAMETERS_KEY)\n            # and don't add the next arg key\n            for k, v in to_extract.items():\n                if k in extracted:\n                    self._warn_on_duplicate_keys(k, current_arg_key, extracted[k])\n                    continue\n                if is_config:\n                    if k == _PARAMETERS_KEY:\n                        continue\n                    if next_arg_key and k == next_arg_key:\n                        continue\n                extracted[k] = v\n\n        return extracted",
  "def __init__(\n        self,\n        config_path: Union[str, Path, dict],\n        global_params_type: Type[_PfT],\n        warn_on_duplicate_keys: bool = False,\n        warn_on_empty_local_params: bool = False,\n        warn_on_empty_config: bool = False,\n    ):\n        self.warn_on_duplicate_keys = warn_on_duplicate_keys\n        self.warn_on_empty_local_params = warn_on_empty_local_params\n        self.warn_on_empty_config = warn_on_empty_config\n\n        config_data = self._read_or_return(config_path)\n        if isinstance(config_path, (Path, str)):\n            self._expand_paths_in_dict(config_data, Path(config_path).parent)\n\n        self.config_data = config_data\n        self.global_params = make_parameter_frame(\n            self.config_data.get(_PARAMETERS_KEY, {}),\n            global_params_type,\n        )\n\n        if not self.global_params:\n            bluemira_warn(\"Empty global params\")",
  "def __str__(self) -> str:\n        \"\"\"Returns config_data as a nicely pretty formatted string\"\"\"\n        return self._pprint_dict(self.config_data)",
  "def _warn_or_debug_log(msg: str, warn: bool) -> None:\n        if warn:\n            bluemira_warn(msg)\n        else:\n            bluemira_debug(msg)",
  "def params_for(self, component_name: str, *args: str) -> ConfigParams:\n        \"\"\"\n        Gets the params for the `component_name` from the config file.\n\n        These are all the values defined by a \"params\"\n        key in the config file.\n\n        This will merge all multiply defined params,\n        with global overwriting local.\n\n        Parameters\n        ----------\n        component_name:\n            The component name, must match a key in the config\n        *args:\n            Optionally, specify the keys of nested attributes.\n\n            This will hoist the values defined in the nested attributes\n            to the top level of the `local_params` dict\n            in the returned `ConfigParams` object.\n\n            The args must be in the order that they appear in the config.\n\n        Returns\n        -------\n        Holds the global_params (from `self.global_params`)\n        and the extracted local_params.\n\n        Use the\n        :func:`~bluemira.base.parameter_frame._frame.make_parameter_frame`\n        helper function to convert it into a typed ParameterFrame.\n        \"\"\"\n        args = (component_name,) + args\n        self._check_args_are_strings(args)\n\n        local_params = self._extract(args, is_config=False)\n        if not local_params:\n            self._warn_or_debug_log(\n                f\"Empty local params for args: {args}\", self.warn_on_empty_local_params\n            )\n\n        return ConfigParams(\n            global_params=self.global_params,\n            local_params=local_params,\n        )",
  "def config_for(self, component_name: str, *args: str) -> dict:\n        \"\"\"\n        Gets the config for the `component_name` from the config file.\n\n        These are all the values other than\n        those defined by a \"params\" key in the config file.\n\n        This will merge all multiply defined values,\n        with global overwriting local.\n\n        Parameters\n        ----------\n        component_name:\n            The component name, must match a key in the config\n        *args:\n            Optionally, specify the keys of nested attributes.\n\n            This will hoist the values defined in the nested attributes\n            to the top level of the returned dict.\n\n            The args must be in the order that they appear in the config.\n\n        Returns\n        -------\n        The extracted config.\n        \"\"\"\n        args = (component_name,) + args\n        self._check_args_are_strings(args)\n\n        _return = self._extract(args, is_config=True)\n        if not _return:\n            self._warn_or_debug_log(\n                f\"Empty config for args: {args}\", self.warn_on_empty_config\n            )\n\n        return _return",
  "def _read_or_return(config_path: Union[str, Path, dict]) -> Dict:\n        if isinstance(config_path, (str, Path)):\n            return ReactorConfig._read_json_file(config_path)\n        elif isinstance(config_path, dict):\n            return config_path\n        raise ReactorConfigError(\n            f\"config_path must be either a dict, a Path object, or a string, found {type(config_path)}.\"\n        )",
  "def _read_json_file(path: Union[Path, str]) -> dict:\n        with open(path, \"r\") as f:\n            return json.load(f)",
  "def _pprint_dict(self, d: dict) -> str:\n        return pprint.pformat(d, sort_dicts=False, indent=1)",
  "def _warn_on_duplicate_keys(\n        self,\n        shared_key: str,\n        arg: str,\n        existing_value,\n    ):\n        self._warn_or_debug_log(\n            \"duplicate config key: \"\n            f\"'{shared_key}' in {arg} wil be overwritten with {existing_value}\",\n            self.warn_on_duplicate_keys,\n        )",
  "def _check_args_are_strings(self, args: Iterable[str]):\n        for a in args:\n            if not isinstance(a, str):\n                raise ReactorConfigError(\"args must be strings\")",
  "def _expand_paths_in_dict(self, d: Dict[str, Any], rel_path: Path):\n        \"\"\"\n        Expand all file paths by replacing their values with the json file's contents.\n\n        Notes\n        -----\n            This mutates the passed in dict.\n        \"\"\"\n        for k in d:\n            d[k], rel_path_from = self._extract_and_expand_file_data_if_needed(\n                d[k], rel_path\n            )\n            if isinstance(d[k], dict):\n                self._expand_paths_in_dict(d[k], rel_path_from)",
  "def _extract_and_expand_file_data_if_needed(\n        self, value: Any, rel_path: Path\n    ) -> Tuple[Union[Any, dict], str]:\n        \"\"\"\n        Returns the file data and the path to the file if value is a path.\n\n        Otherwise, returns value and rel_path that was passed in.\n\n        rel_path is the path to the file that the value is in.\n\n        Notes\n        -----\n        If the value is not a path, returns the value and the passed in rel_path.\n        \"\"\"\n        if not isinstance(value, str):\n            return value, rel_path\n        if not value.startswith(_FILEPATH_PREFIX):\n            return value, rel_path\n\n        # remove _FILEPATH_PREFIX\n        f_path = value[len(_FILEPATH_PREFIX) :]\n\n        # if the path does not start with a /, it is considered a relative path,\n        # relative to the file the path is in (i.e. rel_path)\n        if not f_path.startswith(\"/\"):\n            f_path = rel_path / f_path\n        else:\n            f_path = Path(f_path)\n\n        # check if file exists\n        if not f_path.is_file():\n            raise FileNotFoundError(f\"Cannot find file {f_path}\")\n\n        f_data = self._read_json_file(f_path)\n        return f_data, f_path.parent",
  "def _extract(self, arg_keys: Tuple[str], is_config: bool) -> dict:\n        extracted = {}\n\n        # this routine is designed not to copy any dict's while parsing\n\n        current_layer = self.config_data\n\n        for next_idx, current_arg_key in enumerate(arg_keys, start=1):\n            current_layer = current_layer.get(current_arg_key, {})\n            next_arg_key = arg_keys[next_idx] if next_idx < len(arg_keys) else None\n\n            to_extract = current_layer\n            if not is_config:\n                # if doing a params extraction,\n                # get the values from the _PARAMETERS_KEY\n                to_extract = current_layer.get(_PARAMETERS_KEY, {})\n\n            if not isinstance(to_extract, dict):\n                raise ReactorConfigError(\n                    f\"Arg {current_arg_key} is too specific, \"\n                    \"it must either be another JSON object \"\n                    \"or a path to a JSON file.\"\n                )\n\n            # add all keys not in extracted already\n            # if doing a config, ignore the \"params\" (_PARAMETERS_KEY)\n            # and don't add the next arg key\n            for k, v in to_extract.items():\n                if k in extracted:\n                    self._warn_on_duplicate_keys(k, current_arg_key, extracted[k])\n                    continue\n                if is_config:\n                    if k == _PARAMETERS_KEY:\n                        continue\n                    if next_arg_key and k == next_arg_key:\n                        continue\n                extracted[k] = v\n\n        return extracted",
  "class BaseManager(abc.ABC):\n    \"\"\"\n    A base wrapper around a component tree or component trees.\n\n    The purpose of the classes deriving from this is to abstract away\n    the structure of the component tree and provide access to a set of\n    its features. This way a reactor build procedure can be completely\n    agnostic of the structure of component trees.\n\n    \"\"\"\n\n    @abc.abstractmethod\n    def component(self) -> Component:\n        \"\"\"\n        Return the component tree wrapped by this manager.\n        \"\"\"\n\n    @abc.abstractmethod\n    def save_cad(\n        self,\n        components: Union[Component, Iterable[Component]],\n        filename: str,\n        cad_format: Union[str, cadapi.CADFileType] = \"stp\",\n        **kwargs,\n    ):\n        \"\"\"\n        Save the CAD build of the component.\n\n        Parameters\n        ----------\n        components:\n            components to save\n        filename:\n            the filename to save\n        cad_format:\n            CAD file format\n        \"\"\"\n        if kw_formatt := kwargs.pop(\"formatt\", None):\n            warn(\n                \"Using kwarg 'formatt' is no longer supported. \"\n                \"Use cad_format instead.\",\n                category=DeprecationWarning,\n            )\n            cad_format = kw_formatt\n\n        shapes, names = get_properties_from_components(components, (\"shape\", \"name\"))\n\n        save_cad(shapes, filename, cad_format, names, **kwargs)\n\n    @abc.abstractmethod\n    def show_cad(\n        self,\n        *dims: str,\n        component_filter: Optional[Callable[[Component], bool]],\n        **kwargs,\n    ):\n        \"\"\"\n        Show the CAD build of the component.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension of the reactor to show, typically one of\n            'xz', 'xy', or 'xyz'. (default: 'xyz')\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        \"\"\"\n\n    @abc.abstractmethod\n    def plot(self, *dims: str, component_filter: Optional[Callable[[Component], bool]]):\n        \"\"\"\n        Plot the component.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension(s) of the reactor to show, 'xz' and/or 'xy'.\n            (default: 'xz')\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        \"\"\"\n\n    def tree(self) -> str:\n        \"\"\"\n        Get the component tree\n        \"\"\"\n        return self.component().tree()\n\n    def _validate_cad_dims(self, *dims: str, **kwargs) -> Tuple[str, ...]:\n        \"\"\"\n        Validate showable CAD dimensions\n        \"\"\"\n        # give dims_to_show a default value\n        dims_to_show = (\"xyz\",) if len(dims) == 0 else dims\n\n        # if a kw \"dim\" is given, it is only used\n        if kw_dim := kwargs.pop(\"dim\", None):\n            warn(\n                \"Using kwarg 'dim' is no longer supported. \"\n                \"Simply pass in the dimensions you would like to show, e.g. show_cad('xz')\",\n                category=DeprecationWarning,\n            )\n            dims_to_show = (kw_dim,)\n        for dim in dims_to_show:\n            if dim not in _CAD_DIMS:\n                raise ComponentError(\n                    f\"Invalid plotting dimension '{dim}'.\"\n                    f\"Must be one of {str(_CAD_DIMS)}\"\n                )\n\n        return dims_to_show\n\n    def _validate_plot_dims(self, *dims) -> Tuple[str, ...]:\n        \"\"\"\n        Validate showable plot dimensions\n        \"\"\"\n        # give dims_to_show a default value\n        dims_to_show = (\"xz\",) if len(dims) == 0 else dims\n\n        for dim in dims_to_show:\n            if dim not in _PLOT_DIMS:\n                raise ComponentError(\n                    f\"Invalid plotting dimension '{dim}'.\"\n                    f\"Must be one of {str(_PLOT_DIMS)}\"\n                )\n\n        return dims_to_show\n\n    def _filter_tree(\n        self,\n        comp: Component,\n        dims_to_show: Tuple[str, ...],\n        component_filter: Optional[Callable[[Component], bool]],\n    ) -> Component:\n        \"\"\"\n        Filter a component tree\n\n        Notes\n        -----\n        A copy of the component tree must be made\n        as filtering would mutate the ComponentMangers' underlying component trees\n        \"\"\"\n        comp_copy = comp.copy()\n        comp_copy.filter_components(dims_to_show, component_filter)\n        return comp_copy\n\n    def _plot_dims(\n        self,\n        comp: Component,\n        dims_to_show: Tuple[str, ...],\n        component_filter: Optional[Callable[[Component], bool]],\n    ):\n        for i, dim in enumerate(dims_to_show):\n            ComponentPlotter(view=dim).plot_2d(\n                self._filter_tree(comp, dims_to_show, component_filter),\n                show=i == len(dims_to_show) - 1,\n            )",
  "class FilterMaterial:\n    \"\"\"\n    Filter nodes by material\n\n    Parameters\n    ----------\n    keep_material:\n       materials to include\n    reject_material:\n       materials to exclude\n\n    \"\"\"\n\n    def __init__(\n        self,\n        keep_material: Union[\n            Type[SerialisedMaterial], Tuple[Type[SerialisedMaterial]], None\n        ] = None,\n        reject_material: Union[\n            Type[SerialisedMaterial], Tuple[Type[SerialisedMaterial]], None\n        ] = Void,\n    ):\n        super().__setattr__(\"keep_material\", keep_material)\n        super().__setattr__(\"reject_material\", reject_material)\n\n    def __call__(self, node: anytree.Node) -> bool:\n        \"\"\"Filter node based on material include and exclude rules\"\"\"\n        if not hasattr(node, \"material\"):\n            return True\n        return self._apply_filters(node.material)\n\n    def __setattr__(self, name: str, value: Any):\n        \"\"\"\n        Override setattr to force immutability\n\n        This method makes the class nearly immutable as no new attributes\n        can be modified or added by standard methods.\n\n        See #2236 discussion_r1191246003 for further details\n        \"\"\"\n        raise AttributeError(f\"{type(self).__name__} is immutable\")\n\n    def _apply_filters(\n        self, material: Union[SerialisedMaterial, Tuple[SerialisedMaterial]]\n    ) -> bool:\n        bool_store = True\n\n        if self.keep_material is not None:\n            bool_store = isinstance(material, self.keep_material)\n\n        if self.reject_material is not None:\n            bool_store = not isinstance(material, self.reject_material)\n\n        return bool_store",
  "class ComponentManager(BaseManager):\n    \"\"\"\n    A wrapper around a component tree.\n\n    The purpose of the classes deriving from this is to abstract away\n    the structure of the component tree and provide access to a set of\n    its features. This way a reactor build procedure can be completely\n    agnostic of the structure of component trees, relying instead on\n    a set of methods implemented on concrete `ComponentManager`\n    instances.\n\n    This class can also be used to hold 'construction geometry' that may\n    not be part of the component tree, but was useful in construction\n    of the tree, and could be subsequently useful (e.g., an equilibrium\n    can be solved to get a plasma shape, the equilibrium is not\n    derivable from the plasma component tree, but can be useful in\n    other stages of a reactor build procedure).\n\n    Parameters\n    ----------\n    component_tree:\n        The component tree this manager should wrap.\n    \"\"\"\n\n    def __init__(self, component_tree: Component) -> None:\n        self._component = component_tree\n\n    def component(self) -> Component:\n        \"\"\"\n        Return the component tree wrapped by this manager.\n        \"\"\"\n        return self._component\n\n    def save_cad(\n        self,\n        *dims: str,\n        component_filter: Optional[Callable[[Component], bool]] = FilterMaterial(),\n        filename: Optional[str] = None,\n        cad_format: Union[str, cadapi.CADFileType] = \"stp\",\n        directory: Union[str, Path] = \"\",\n        **kwargs,\n    ):\n        \"\"\"\n        Save the CAD build of the component.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension of the reactor to show, typically one of\n            'xz', 'xy', or 'xyz'. (default: 'xyz')\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        filename:\n            the filename to save, will default to the component name\n        cad_format:\n            CAD file format\n        directory:\n            Directory to save into, defaults to the current directory\n        kwargs:\n            passed to the :func:`bluemira.geometry.tools.save_cad` function\n        \"\"\"\n        if kw_filter_ := kwargs.pop(\"filter_\", None):\n            warn(\n                \"Using kwarg 'filter_' is no longer supported. \"\n                \"Use component_filter instead.\",\n                category=DeprecationWarning,\n            )\n            component_filter = kw_filter_\n\n        comp = self.component()\n        if filename is None:\n            filename = comp.name\n\n        super().save_cad(\n            self._filter_tree(\n                comp, self._validate_cad_dims(*dims, **kwargs), component_filter\n            ),\n            filename=Path(directory, filename).as_posix(),\n            cad_format=cad_format,\n            **kwargs,\n        )\n\n    def show_cad(\n        self,\n        *dims: str,\n        component_filter: Optional[Callable[[Component], bool]] = FilterMaterial(),\n        **kwargs,\n    ):\n        \"\"\"\n        Show the CAD build of the component.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension of the reactor to show, typically one of\n            'xz', 'xy', or 'xyz'. (default: 'xyz')\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        kwargs:\n            passed to the `~bluemira.display.displayer.show_cad` function\n        \"\"\"\n        if kw_filter_ := kwargs.pop(\"filter_\", None):\n            warn(\n                \"Using kwarg 'filter_' is no longer supported. \"\n                \"Use component_filter instead.\",\n                category=DeprecationWarning,\n            )\n            component_filter = kw_filter_\n\n        ComponentDisplayer().show_cad(\n            self._filter_tree(\n                self.component(),\n                self._validate_cad_dims(*dims, **kwargs),\n                component_filter,\n            ),\n            **kwargs,\n        )\n\n    def plot(\n        self,\n        *dims: str,\n        component_filter: Optional[Callable[[Component], bool]] = FilterMaterial(),\n        **kwargs,\n    ):\n        \"\"\"\n        Plot the component.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension(s) of the reactor to show, 'xz' and/or 'xy'.\n            (default: 'xz')\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        \"\"\"\n        if kw_filter_ := kwargs.pop(\"filter_\", None):\n            warn(\n                \"Using kwarg 'filter_' is no longer supported. \"\n                \"Use component_filter instead.\",\n                category=DeprecationWarning,\n            )\n            component_filter = kw_filter_\n\n        self._plot_dims(\n            self.component(), self._validate_plot_dims(*dims), component_filter\n        )",
  "class Reactor(BaseManager):\n    \"\"\"\n    Base class for reactor definitions.\n\n    Assign :obj:`bluemira.base.builder.ComponentManager` instances to\n    fields defined on the reactor, and this class acts as a container\n    to group those components' trees. It is also a place to define any\n    methods to calculate/derive properties that require information\n    about multiple reactor components.\n\n    Components should be defined on the reactor as class properties\n    annotated with a type (similar to a ``dataclass``). A type that\n    subclasses ``ComponentManager`` must be given, or it will not be\n    recognised as part of the reactor tree. Note that a declared\n    component is not required to be set for the reactor to be valid.\n    So it is possible to just add a reactor's plasma, but not its\n    TF coils, for example.\n\n    Parameters\n    ----------\n    name:\n        The name of the reactor. This will be the label for the top\n        level :obj:`bluemira.base.components.Component` in the reactor\n        tree.\n    n_sectors:\n        Number of sectors in a reactor\n\n    Example\n    -------\n\n    .. code-block:: python\n\n        class MyReactor(Reactor):\n            '''An example of how to declare a reactor structure.'''\n\n            plasma: MyPlasma\n            tf_coils: MyTfCoils\n\n            def get_ripple(self):\n                '''Calculate the ripple in the TF coils.'''\n\n        reactor = MyReactor(\"My Reactor\")\n        reactor.plasma = build_plasma()\n        reactor.tf_coils = build_tf_coils()\n        reactor.show_cad()\n\n    \"\"\"\n\n    def __init__(self, name: str, n_sectors: int):\n        self.name = name\n        self.n_sectors = n_sectors\n        self.start_time = time.perf_counter()\n\n    def component(\n        self,\n        with_components: Optional[List[ComponentManager]] = None,\n    ) -> Component:\n        \"\"\"Return the component tree.\"\"\"\n        return self._build_component_tree(with_components)\n\n    def time_since_init(self) -> float:\n        \"\"\"\n        Get time since initialisation\n        \"\"\"\n        return time.perf_counter() - self.start_time\n\n    def _build_component_tree(\n        self,\n        with_components: Optional[List[ComponentManager]] = None,\n    ) -> Component:\n        \"\"\"Build the component tree from this class's annotations.\"\"\"\n        component = Component(self.name)\n        comp_type: Type\n        for comp_name, comp_type in self.__annotations__.items():\n            if not issubclass(comp_type, ComponentManager):\n                continue\n            try:\n                component_manager = getattr(self, comp_name)\n                if (\n                    with_components is not None\n                    and component_manager not in with_components\n                ):\n                    continue\n            except AttributeError:\n                # We don't mind if a reactor component is not set, it\n                # just won't be part of the tree\n                continue\n\n            component.add_child(component_manager.component())\n        return component\n\n    def _construct_xyz_cad(\n        self,\n        reactor_component: Component,\n        with_components: Optional[List[ComponentManager]] = None,\n        n_sectors: int = 1,\n    ):\n        xyzs = reactor_component.get_component(\n            \"xyz\",\n            first=False,\n        )\n        xyzs = [xyzs] if isinstance(xyzs, Component) else xyzs\n\n        comp_names = (\n            \"all\"\n            if not with_components\n            else \", \".join([cm.component().name for cm in with_components])\n        )\n        bluemira_print(\n            f\"Constructing xyz CAD for display with {n_sectors} sectors and components: {comp_names}\"\n        )\n        for xyz in track(xyzs):\n            xyz.children = circular_pattern_component(\n                list(xyz.children),\n                n_sectors,\n                degree=(360 / self.n_sectors) * n_sectors,\n            )\n\n    def _filter_and_reconstruct(\n        self,\n        dims_to_show: Tuple[str, ...],\n        with_components: Optional[List[ComponentManager]],\n        n_sectors: Optional[int],\n        component_filter: Optional[Callable[[Component], bool]],\n        **kwargs,\n    ) -> Component:\n        # We filter because self.component (above) only creates\n        # a new root node for this reactor, not a new component tree.\n        comp_copy = self._filter_tree(\n            self.component(with_components), dims_to_show, component_filter\n        )\n        # if \"xyz\" is requested, construct the 3d cad\n        # from each xyz component in the tree,\n        # as it's assumed that the cad is only built for 1 sector\n        # and is sector symmetric, therefore can be patterned\n        if \"xyz\" in dims_to_show:\n            self._construct_xyz_cad(\n                comp_copy,\n                with_components,\n                self.n_sectors if n_sectors is None else n_sectors,\n            )\n        return comp_copy\n\n    def save_cad(\n        self,\n        *dims: str,\n        with_components: Optional[List[ComponentManager]] = None,\n        n_sectors: Optional[int] = None,\n        component_filter: Optional[Callable[[Component], bool]] = FilterMaterial(),\n        filename: Optional[str] = None,\n        cad_format: Union[str, cadapi.CADFileType] = \"stp\",\n        directory: Union[str, Path] = \"\",\n        **kwargs,\n    ):\n        \"\"\"\n        Save the CAD build of the reactor.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension of the reactor to show, typically one of\n            'xz', 'xy', or 'xyz'. (default: 'xyz')\n        with_components:\n            The components to construct when displaying CAD for xyz.\n            Defaults to None, which means show \"all\" components.\n        n_sectors:\n            The number of sectors to construct when displaying CAD for xyz\n            Defaults to None, which means show \"all\" sectors.\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        filename:\n            the filename to save, will default to the component name\n        cad_format:\n            CAD file format\n        directory:\n            Directory to save into, defaults to the current directory\n        kwargs:\n            passed to the :func:`bluemira.geometry.tools.save_cad` function\n        \"\"\"\n        if kw_filter_ := kwargs.pop(\"filter_\", None):\n            warn(\n                \"Using kwarg 'filter_' is no longer supported. \"\n                \"Use component_filter instead.\",\n                category=DeprecationWarning,\n            )\n            component_filter = kw_filter_\n\n        if filename is None:\n            filename = self.name\n\n        super().save_cad(\n            self._filter_and_reconstruct(\n                self._validate_cad_dims(*dims),\n                with_components,\n                n_sectors,\n                component_filter,\n            ),\n            Path(directory, filename).as_posix(),\n            cad_format,\n            **kwargs,\n        )\n\n    def show_cad(\n        self,\n        *dims: str,\n        with_components: Optional[List[ComponentManager]] = None,\n        n_sectors: Optional[int] = None,\n        component_filter: Optional[Callable[[Component], bool]] = FilterMaterial(),\n        **kwargs,\n    ):\n        \"\"\"\n        Show the CAD build of the reactor.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension of the reactor to show, typically one of\n            'xz', 'xy', or 'xyz'. (default: 'xyz')\n        with_components:\n            The components to construct when displaying CAD for xyz.\n            Defaults to None, which means show \"all\" components.\n        n_sectors:\n            The number of sectors to construct when displaying CAD for xyz\n            Defaults to None, which means show \"all\" sectors.\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        kwargs:\n            passed to the `~bluemira.display.displayer.show_cad` function\n        \"\"\"\n        if kw_filter_ := kwargs.pop(\"filter_\", None):\n            warn(\n                \"Using kwarg 'filter_' is no longer supported. \"\n                \"Use component_filter instead.\",\n                category=DeprecationWarning,\n            )\n            component_filter = kw_filter_\n\n        ComponentDisplayer().show_cad(\n            self._filter_and_reconstruct(\n                self._validate_cad_dims(*dims, **kwargs),\n                with_components,\n                n_sectors,\n                component_filter,\n            ),\n            **kwargs,\n        )\n\n    def plot(\n        self,\n        *dims: str,\n        with_components: Optional[List[ComponentManager]] = None,\n        component_filter: Optional[Callable[[Component], bool]] = FilterMaterial(),\n        **kwargs,\n    ):\n        \"\"\"\n        Plot the reactor.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension(s) of the reactor to show, 'xz' and/or 'xy'.\n            (default: 'xz')\n        with_components:\n            The components to construct when displaying CAD for xyz.\n            Defaults to None, which means show \"all\" components.\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        \"\"\"\n        if kw_filter_ := kwargs.pop(\"filter_\", None):\n            warn(\n                \"Using kwarg 'filter_' is no longer supported. \"\n                \"Use component_filter instead.\",\n                category=DeprecationWarning,\n            )\n            component_filter = kw_filter_\n\n        self._plot_dims(\n            self.component(with_components),\n            self._validate_plot_dims(*dims),\n            component_filter,\n        )",
  "def component(self) -> Component:\n        \"\"\"\n        Return the component tree wrapped by this manager.\n        \"\"\"",
  "def save_cad(\n        self,\n        components: Union[Component, Iterable[Component]],\n        filename: str,\n        cad_format: Union[str, cadapi.CADFileType] = \"stp\",\n        **kwargs,\n    ):\n        \"\"\"\n        Save the CAD build of the component.\n\n        Parameters\n        ----------\n        components:\n            components to save\n        filename:\n            the filename to save\n        cad_format:\n            CAD file format\n        \"\"\"\n        if kw_formatt := kwargs.pop(\"formatt\", None):\n            warn(\n                \"Using kwarg 'formatt' is no longer supported. \"\n                \"Use cad_format instead.\",\n                category=DeprecationWarning,\n            )\n            cad_format = kw_formatt\n\n        shapes, names = get_properties_from_components(components, (\"shape\", \"name\"))\n\n        save_cad(shapes, filename, cad_format, names, **kwargs)",
  "def show_cad(\n        self,\n        *dims: str,\n        component_filter: Optional[Callable[[Component], bool]],\n        **kwargs,\n    ):\n        \"\"\"\n        Show the CAD build of the component.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension of the reactor to show, typically one of\n            'xz', 'xy', or 'xyz'. (default: 'xyz')\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        \"\"\"",
  "def plot(self, *dims: str, component_filter: Optional[Callable[[Component], bool]]):\n        \"\"\"\n        Plot the component.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension(s) of the reactor to show, 'xz' and/or 'xy'.\n            (default: 'xz')\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        \"\"\"",
  "def tree(self) -> str:\n        \"\"\"\n        Get the component tree\n        \"\"\"\n        return self.component().tree()",
  "def _validate_cad_dims(self, *dims: str, **kwargs) -> Tuple[str, ...]:\n        \"\"\"\n        Validate showable CAD dimensions\n        \"\"\"\n        # give dims_to_show a default value\n        dims_to_show = (\"xyz\",) if len(dims) == 0 else dims\n\n        # if a kw \"dim\" is given, it is only used\n        if kw_dim := kwargs.pop(\"dim\", None):\n            warn(\n                \"Using kwarg 'dim' is no longer supported. \"\n                \"Simply pass in the dimensions you would like to show, e.g. show_cad('xz')\",\n                category=DeprecationWarning,\n            )\n            dims_to_show = (kw_dim,)\n        for dim in dims_to_show:\n            if dim not in _CAD_DIMS:\n                raise ComponentError(\n                    f\"Invalid plotting dimension '{dim}'.\"\n                    f\"Must be one of {str(_CAD_DIMS)}\"\n                )\n\n        return dims_to_show",
  "def _validate_plot_dims(self, *dims) -> Tuple[str, ...]:\n        \"\"\"\n        Validate showable plot dimensions\n        \"\"\"\n        # give dims_to_show a default value\n        dims_to_show = (\"xz\",) if len(dims) == 0 else dims\n\n        for dim in dims_to_show:\n            if dim not in _PLOT_DIMS:\n                raise ComponentError(\n                    f\"Invalid plotting dimension '{dim}'.\"\n                    f\"Must be one of {str(_PLOT_DIMS)}\"\n                )\n\n        return dims_to_show",
  "def _filter_tree(\n        self,\n        comp: Component,\n        dims_to_show: Tuple[str, ...],\n        component_filter: Optional[Callable[[Component], bool]],\n    ) -> Component:\n        \"\"\"\n        Filter a component tree\n\n        Notes\n        -----\n        A copy of the component tree must be made\n        as filtering would mutate the ComponentMangers' underlying component trees\n        \"\"\"\n        comp_copy = comp.copy()\n        comp_copy.filter_components(dims_to_show, component_filter)\n        return comp_copy",
  "def _plot_dims(\n        self,\n        comp: Component,\n        dims_to_show: Tuple[str, ...],\n        component_filter: Optional[Callable[[Component], bool]],\n    ):\n        for i, dim in enumerate(dims_to_show):\n            ComponentPlotter(view=dim).plot_2d(\n                self._filter_tree(comp, dims_to_show, component_filter),\n                show=i == len(dims_to_show) - 1,\n            )",
  "def __init__(\n        self,\n        keep_material: Union[\n            Type[SerialisedMaterial], Tuple[Type[SerialisedMaterial]], None\n        ] = None,\n        reject_material: Union[\n            Type[SerialisedMaterial], Tuple[Type[SerialisedMaterial]], None\n        ] = Void,\n    ):\n        super().__setattr__(\"keep_material\", keep_material)\n        super().__setattr__(\"reject_material\", reject_material)",
  "def __call__(self, node: anytree.Node) -> bool:\n        \"\"\"Filter node based on material include and exclude rules\"\"\"\n        if not hasattr(node, \"material\"):\n            return True\n        return self._apply_filters(node.material)",
  "def __setattr__(self, name: str, value: Any):\n        \"\"\"\n        Override setattr to force immutability\n\n        This method makes the class nearly immutable as no new attributes\n        can be modified or added by standard methods.\n\n        See #2236 discussion_r1191246003 for further details\n        \"\"\"\n        raise AttributeError(f\"{type(self).__name__} is immutable\")",
  "def _apply_filters(\n        self, material: Union[SerialisedMaterial, Tuple[SerialisedMaterial]]\n    ) -> bool:\n        bool_store = True\n\n        if self.keep_material is not None:\n            bool_store = isinstance(material, self.keep_material)\n\n        if self.reject_material is not None:\n            bool_store = not isinstance(material, self.reject_material)\n\n        return bool_store",
  "def __init__(self, component_tree: Component) -> None:\n        self._component = component_tree",
  "def component(self) -> Component:\n        \"\"\"\n        Return the component tree wrapped by this manager.\n        \"\"\"\n        return self._component",
  "def save_cad(\n        self,\n        *dims: str,\n        component_filter: Optional[Callable[[Component], bool]] = FilterMaterial(),\n        filename: Optional[str] = None,\n        cad_format: Union[str, cadapi.CADFileType] = \"stp\",\n        directory: Union[str, Path] = \"\",\n        **kwargs,\n    ):\n        \"\"\"\n        Save the CAD build of the component.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension of the reactor to show, typically one of\n            'xz', 'xy', or 'xyz'. (default: 'xyz')\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        filename:\n            the filename to save, will default to the component name\n        cad_format:\n            CAD file format\n        directory:\n            Directory to save into, defaults to the current directory\n        kwargs:\n            passed to the :func:`bluemira.geometry.tools.save_cad` function\n        \"\"\"\n        if kw_filter_ := kwargs.pop(\"filter_\", None):\n            warn(\n                \"Using kwarg 'filter_' is no longer supported. \"\n                \"Use component_filter instead.\",\n                category=DeprecationWarning,\n            )\n            component_filter = kw_filter_\n\n        comp = self.component()\n        if filename is None:\n            filename = comp.name\n\n        super().save_cad(\n            self._filter_tree(\n                comp, self._validate_cad_dims(*dims, **kwargs), component_filter\n            ),\n            filename=Path(directory, filename).as_posix(),\n            cad_format=cad_format,\n            **kwargs,\n        )",
  "def show_cad(\n        self,\n        *dims: str,\n        component_filter: Optional[Callable[[Component], bool]] = FilterMaterial(),\n        **kwargs,\n    ):\n        \"\"\"\n        Show the CAD build of the component.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension of the reactor to show, typically one of\n            'xz', 'xy', or 'xyz'. (default: 'xyz')\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        kwargs:\n            passed to the `~bluemira.display.displayer.show_cad` function\n        \"\"\"\n        if kw_filter_ := kwargs.pop(\"filter_\", None):\n            warn(\n                \"Using kwarg 'filter_' is no longer supported. \"\n                \"Use component_filter instead.\",\n                category=DeprecationWarning,\n            )\n            component_filter = kw_filter_\n\n        ComponentDisplayer().show_cad(\n            self._filter_tree(\n                self.component(),\n                self._validate_cad_dims(*dims, **kwargs),\n                component_filter,\n            ),\n            **kwargs,\n        )",
  "def plot(\n        self,\n        *dims: str,\n        component_filter: Optional[Callable[[Component], bool]] = FilterMaterial(),\n        **kwargs,\n    ):\n        \"\"\"\n        Plot the component.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension(s) of the reactor to show, 'xz' and/or 'xy'.\n            (default: 'xz')\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        \"\"\"\n        if kw_filter_ := kwargs.pop(\"filter_\", None):\n            warn(\n                \"Using kwarg 'filter_' is no longer supported. \"\n                \"Use component_filter instead.\",\n                category=DeprecationWarning,\n            )\n            component_filter = kw_filter_\n\n        self._plot_dims(\n            self.component(), self._validate_plot_dims(*dims), component_filter\n        )",
  "def __init__(self, name: str, n_sectors: int):\n        self.name = name\n        self.n_sectors = n_sectors\n        self.start_time = time.perf_counter()",
  "def component(\n        self,\n        with_components: Optional[List[ComponentManager]] = None,\n    ) -> Component:\n        \"\"\"Return the component tree.\"\"\"\n        return self._build_component_tree(with_components)",
  "def time_since_init(self) -> float:\n        \"\"\"\n        Get time since initialisation\n        \"\"\"\n        return time.perf_counter() - self.start_time",
  "def _build_component_tree(\n        self,\n        with_components: Optional[List[ComponentManager]] = None,\n    ) -> Component:\n        \"\"\"Build the component tree from this class's annotations.\"\"\"\n        component = Component(self.name)\n        comp_type: Type\n        for comp_name, comp_type in self.__annotations__.items():\n            if not issubclass(comp_type, ComponentManager):\n                continue\n            try:\n                component_manager = getattr(self, comp_name)\n                if (\n                    with_components is not None\n                    and component_manager not in with_components\n                ):\n                    continue\n            except AttributeError:\n                # We don't mind if a reactor component is not set, it\n                # just won't be part of the tree\n                continue\n\n            component.add_child(component_manager.component())\n        return component",
  "def _construct_xyz_cad(\n        self,\n        reactor_component: Component,\n        with_components: Optional[List[ComponentManager]] = None,\n        n_sectors: int = 1,\n    ):\n        xyzs = reactor_component.get_component(\n            \"xyz\",\n            first=False,\n        )\n        xyzs = [xyzs] if isinstance(xyzs, Component) else xyzs\n\n        comp_names = (\n            \"all\"\n            if not with_components\n            else \", \".join([cm.component().name for cm in with_components])\n        )\n        bluemira_print(\n            f\"Constructing xyz CAD for display with {n_sectors} sectors and components: {comp_names}\"\n        )\n        for xyz in track(xyzs):\n            xyz.children = circular_pattern_component(\n                list(xyz.children),\n                n_sectors,\n                degree=(360 / self.n_sectors) * n_sectors,\n            )",
  "def _filter_and_reconstruct(\n        self,\n        dims_to_show: Tuple[str, ...],\n        with_components: Optional[List[ComponentManager]],\n        n_sectors: Optional[int],\n        component_filter: Optional[Callable[[Component], bool]],\n        **kwargs,\n    ) -> Component:\n        # We filter because self.component (above) only creates\n        # a new root node for this reactor, not a new component tree.\n        comp_copy = self._filter_tree(\n            self.component(with_components), dims_to_show, component_filter\n        )\n        # if \"xyz\" is requested, construct the 3d cad\n        # from each xyz component in the tree,\n        # as it's assumed that the cad is only built for 1 sector\n        # and is sector symmetric, therefore can be patterned\n        if \"xyz\" in dims_to_show:\n            self._construct_xyz_cad(\n                comp_copy,\n                with_components,\n                self.n_sectors if n_sectors is None else n_sectors,\n            )\n        return comp_copy",
  "def save_cad(\n        self,\n        *dims: str,\n        with_components: Optional[List[ComponentManager]] = None,\n        n_sectors: Optional[int] = None,\n        component_filter: Optional[Callable[[Component], bool]] = FilterMaterial(),\n        filename: Optional[str] = None,\n        cad_format: Union[str, cadapi.CADFileType] = \"stp\",\n        directory: Union[str, Path] = \"\",\n        **kwargs,\n    ):\n        \"\"\"\n        Save the CAD build of the reactor.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension of the reactor to show, typically one of\n            'xz', 'xy', or 'xyz'. (default: 'xyz')\n        with_components:\n            The components to construct when displaying CAD for xyz.\n            Defaults to None, which means show \"all\" components.\n        n_sectors:\n            The number of sectors to construct when displaying CAD for xyz\n            Defaults to None, which means show \"all\" sectors.\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        filename:\n            the filename to save, will default to the component name\n        cad_format:\n            CAD file format\n        directory:\n            Directory to save into, defaults to the current directory\n        kwargs:\n            passed to the :func:`bluemira.geometry.tools.save_cad` function\n        \"\"\"\n        if kw_filter_ := kwargs.pop(\"filter_\", None):\n            warn(\n                \"Using kwarg 'filter_' is no longer supported. \"\n                \"Use component_filter instead.\",\n                category=DeprecationWarning,\n            )\n            component_filter = kw_filter_\n\n        if filename is None:\n            filename = self.name\n\n        super().save_cad(\n            self._filter_and_reconstruct(\n                self._validate_cad_dims(*dims),\n                with_components,\n                n_sectors,\n                component_filter,\n            ),\n            Path(directory, filename).as_posix(),\n            cad_format,\n            **kwargs,\n        )",
  "def show_cad(\n        self,\n        *dims: str,\n        with_components: Optional[List[ComponentManager]] = None,\n        n_sectors: Optional[int] = None,\n        component_filter: Optional[Callable[[Component], bool]] = FilterMaterial(),\n        **kwargs,\n    ):\n        \"\"\"\n        Show the CAD build of the reactor.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension of the reactor to show, typically one of\n            'xz', 'xy', or 'xyz'. (default: 'xyz')\n        with_components:\n            The components to construct when displaying CAD for xyz.\n            Defaults to None, which means show \"all\" components.\n        n_sectors:\n            The number of sectors to construct when displaying CAD for xyz\n            Defaults to None, which means show \"all\" sectors.\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        kwargs:\n            passed to the `~bluemira.display.displayer.show_cad` function\n        \"\"\"\n        if kw_filter_ := kwargs.pop(\"filter_\", None):\n            warn(\n                \"Using kwarg 'filter_' is no longer supported. \"\n                \"Use component_filter instead.\",\n                category=DeprecationWarning,\n            )\n            component_filter = kw_filter_\n\n        ComponentDisplayer().show_cad(\n            self._filter_and_reconstruct(\n                self._validate_cad_dims(*dims, **kwargs),\n                with_components,\n                n_sectors,\n                component_filter,\n            ),\n            **kwargs,\n        )",
  "def plot(\n        self,\n        *dims: str,\n        with_components: Optional[List[ComponentManager]] = None,\n        component_filter: Optional[Callable[[Component], bool]] = FilterMaterial(),\n        **kwargs,\n    ):\n        \"\"\"\n        Plot the reactor.\n\n        Parameters\n        ----------\n        *dims:\n            The dimension(s) of the reactor to show, 'xz' and/or 'xy'.\n            (default: 'xz')\n        with_components:\n            The components to construct when displaying CAD for xyz.\n            Defaults to None, which means show \"all\" components.\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n        \"\"\"\n        if kw_filter_ := kwargs.pop(\"filter_\", None):\n            warn(\n                \"Using kwarg 'filter_' is no longer supported. \"\n                \"Use component_filter instead.\",\n                category=DeprecationWarning,\n            )\n            component_filter = kw_filter_\n\n        self._plot_dims(\n            self.component(with_components),\n            self._validate_plot_dims(*dims),\n            component_filter,\n        )",
  "def _get_relpath(folder: str, subfolder: str) -> str:\n    path = os.sep.join([folder, subfolder])\n    if os.path.isdir(path):\n        return path\n    else:\n        raise ValueError(f\"{path} Not a valid folder.\")",
  "def get_bluemira_root() -> str:\n    \"\"\"\n    Get the bluemira root install folder.\n\n    Returns\n    -------\n        The full path to the bluemira root folder, e.g.:\n            '/home/user/code/bluemira'\n    \"\"\"\n    import bluemira\n\n    path = list(bluemira.__path__)[0]\n    root = os.path.split(path)[0]\n    return root",
  "def try_get_bluemira_private_data_root() -> Union[str, None]:\n    \"\"\"\n    Get the bluemira-private-data root install folder.\n\n    Returns\n    -------\n    The full path to the bluemira root folder, e.g.:\n        '/home/user/code/bluemira-private-data'\n\n    Notes\n    -----\n    Normal users will not have access to bluemira-private-data; it will be used\n    exclusively for tests which require private data and files.\n    \"\"\"\n    root = get_bluemira_root()\n    code_root = os.path.split(root)[0]\n    try:\n        return _get_relpath(code_root, \"bluemira-private-data\")\n    except ValueError:\n        return None",
  "def get_bluemira_path(path: str = \"\", subfolder: str = \"bluemira\") -> str:\n    \"\"\"\n    Get a bluemira path of a module subfolder. Defaults to root folder.\n\n    Parameters\n    ----------\n    path:\n        The desired path from which to create a full path\n    subfolder:\n        The subfolder (from the bluemira root) in which to create a path\n        Defaults to the source code folder, but can be e.g. 'tests', or 'data'\n\n    Returns\n    -------\n    The full path to the desired `path` in the subfolder specified\n    \"\"\"\n    root = get_bluemira_root()\n    if \"egg\" in root:\n        return f\"/{subfolder}\"\n\n    path = path.replace(\"/\", os.sep)\n    bpath = _get_relpath(root, subfolder)\n    return _get_relpath(bpath, path)",
  "def try_get_bluemira_path(\n    path: str = \"\", subfolder: str = \"bluemira\", allow_missing: bool = True\n) -> Optional[str]:\n    \"\"\"\n    Try to get the bluemira path of a module subfolder.\n\n    If the path doesn't exist then optionally carry on regardless or raise an error.\n\n    Parameters\n    ----------\n    path:\n        The desired path from which to create a full path\n    subfolder:\n        The subfolder (from the bluemira root) in which to create a path\n        Defaults to the source code folder, but can be e.g. 'tests', or 'data'\n    allow_missing:\n        Whether or not to raise an error if the path does not exist\n\n    Returns\n    -------\n    The full path to the desired `path` in the subfolder specified, or None if the\n    requested path doesn't exist.\n\n    Raises\n    ------\n    ValueError\n        If the requested path doesn't exist and the `allow_missing` flag is False.\n    \"\"\"\n    try:\n        return get_bluemira_path(path, subfolder)\n    except ValueError as error:\n        if allow_missing:\n            return None\n        else:\n            raise error",
  "def make_bluemira_path(path: str = \"\", subfolder: str = \"bluemira\") -> str:\n    \"\"\"\n    Create a new folder in the path, provided one does not already exist.\n    \"\"\"\n    root = get_bluemira_root()\n    if \"egg\" in root:\n        root = \"/\"\n    path = path.replace(\"/\", os.sep)\n    bpath = _get_relpath(root, subfolder)\n    if bpath in path:\n        path = path[len(bpath) :]  # Remove leading edge rootpath\n    try:\n        return _get_relpath(bpath, path)\n    except ValueError:\n        os.makedirs(os.sep.join([bpath, path]))\n        return _get_relpath(bpath, path)",
  "def force_file_extension(file_path: str, valid_extensions: Union[str, List[str]]) -> str:\n    \"\"\"\n    If the file path does not have one of the valid extensions, append the first\n    valid one\n\n    Parameters\n    ----------\n    file_path:\n        path to file\n    valid_extensions:\n        collection of valid extensions\n\n    Returns\n    -------\n    File path\n    \"\"\"\n    if isinstance(valid_extensions, str):\n        valid_extensions = [valid_extensions]\n\n    if not os.path.splitext(file_path)[1].casefold() in valid_extensions:\n        file_path += valid_extensions[0]\n\n    return file_path",
  "def get_files_by_ext(folder: str, extension: str) -> List[str]:\n    \"\"\"\n    Get filenames of files in folder with the specified extension.\n\n    Parameters\n    ----------\n    folder:\n        The full path directory in which to look for files\n    extension:\n        The extension of the desired file-type\n\n    Returns\n    -------\n    The list of full path filenames found in the folder\n    \"\"\"\n    files = []\n    for file in os.listdir(folder):\n        if file.endswith(extension):\n            files.append(file)\n    if len(files) == 0:\n        from bluemira.base.look_and_feel import bluemira_warn\n\n        bluemira_warn(f\"No files with extension {extension} found in folder {folder}\")\n    return files",
  "def file_name_maker(filename: str, lowercase: bool = False) -> str:\n    \"\"\"\n    Ensure the file name is acceptable.\n\n    Parameters\n    ----------\n    filename:\n        Full filename or path\n    lowercase:\n        Whether or not to force lowercase filenames\n\n    Returns\n    -------\n    Full filename or path, corrected\n    \"\"\"\n    filename = filename.replace(\" \", \"_\")\n    if lowercase:\n        split = filename.split(os.sep)\n        filename = os.sep.join(split[:-1])\n        filename = os.sep.join([filename, split[-1].lower()])\n    return filename",
  "def working_dir(directory: str):\n    \"\"\"Change working directory\"\"\"\n    current_dir = os.getcwd()\n    try:\n        os.chdir(directory)\n        yield\n    finally:\n        os.chdir(current_dir)",
  "class FileManager:\n    \"\"\"\n    A class for managing file operations.\n    \"\"\"\n\n    _reactor_name: str\n    _reference_data_root: str\n    _generated_data_root: str\n\n    reference_data_dirs: Dict[str, str]\n    generated_data_dirs: Dict[str, str]\n\n    def __init__(\n        self,\n        reactor_name: str,\n        reference_data_root: str = \"data/bluemira\",\n        generated_data_root: str = \"data/bluemira\",\n    ):\n        self._reactor_name = reactor_name\n        self._reference_data_root = reference_data_root\n        self._generated_data_root = generated_data_root\n        self.replace_bm_root()\n\n    @property\n    def reactor_name(self):\n        \"\"\"\n        Gets the reactor name for this instance.\n        \"\"\"\n        return self._reactor_name\n\n    @property\n    def generated_data_root(self) -> str:\n        \"\"\"\n        Gets the generated data root directory for this instance.\n        \"\"\"\n        return self._generated_data_root\n\n    @property\n    def reference_data_root(self) -> str:\n        \"\"\"\n        Get the reference data root directory for this instance.\n        \"\"\"\n        return self._reference_data_root\n\n    def replace_bm_root(self, keyword: str = BM_ROOT):\n        \"\"\"\n        Replace the keyword in input paths with path to local bluemira installation.\n        \"\"\"\n        bm_root = get_bluemira_root()\n        self._reference_data_root = self.reference_data_root.replace(keyword, bm_root)\n        self._generated_data_root = self.generated_data_root.replace(keyword, bm_root)\n\n    def _verify_reference_data_root(self):\n        \"\"\"\n        Check that the reference data root defined in this instance is a valid\n        directory.\n\n        Raises\n        ------\n        ValueError\n            If the reference data root for this instance is not a valid directory.\n        \"\"\"\n        _get_relpath(self._reference_data_root, subfolder=\"\")\n\n    def make_reactor_folder(self, subfolder: str) -> Dict[str, str]:\n        \"\"\"\n        Initialise a data storage folder tree.\n\n        Parameters\n        ----------\n        subfolder:\n            The subfolder of the bluemira directory in which to add the data structure\n\n        Returns\n        -------\n        The dictionary of subfolder names to full paths (useful shorthand)\n        \"\"\"\n        root = os.path.join(subfolder, \"reactors\", self.reactor_name)\n        pathlib.Path(root).mkdir(parents=True, exist_ok=True)\n\n        mapping = {\"root\": root}\n        for sub in SUB_DIRS:\n            folder = os.sep.join([root, sub])\n            pathlib.Path(folder).mkdir(exist_ok=True)\n\n            mapping[sub] = folder\n\n        return mapping\n\n    def set_reference_data_paths(self):\n        \"\"\"\n        Generate the reference data paths for this instance, based on the reactor name.\n        \"\"\"\n        self._verify_reference_data_root()\n        self.reference_data_dirs = self.make_reactor_folder(self._reference_data_root)\n\n    def create_reference_data_paths(self):\n        \"\"\"\n        Generate the reference data paths for this instance, based on the reactor name.\n\n        Also builds the relevant directory structure.\n        \"\"\"\n        pathlib.Path(self._reference_data_root).mkdir(parents=True, exist_ok=True)\n        self.reference_data_dirs = self.make_reactor_folder(self._reference_data_root)\n\n    def create_generated_data_paths(self):\n        \"\"\"\n        Generate the generated data paths for this instance, based on the reactor name.\n\n        Also builds the relevant directory structure.\n        \"\"\"\n        pathlib.Path(self._generated_data_root).mkdir(parents=True, exist_ok=True)\n        self.generated_data_dirs = self.make_reactor_folder(self._generated_data_root)\n\n    def build_dirs(self, create_reference_data_paths: bool = False):\n        \"\"\"\n        Create the directory structures for this instance and sets the path references.\n        \"\"\"\n        if create_reference_data_paths:\n            self.create_reference_data_paths()\n        else:\n            self.set_reference_data_paths()\n        self.create_generated_data_paths()\n\n    def get_path(self, sub_dir_name: str, path: str, make_dir: bool = False) -> str:\n        \"\"\"\n        Get a path within the generated data sub-sdirectories.\n\n        If the path does not exist then it will optionally be created as a directory.\n\n        Parameters\n        ----------\n        sub_dir_name:\n            The name of the sub-directory to create the path under. Must be one of the\n            names in bluemira.base.file.SUB_DIRS.\n        path:\n            The path to create under the sub-directory.\n        make_dir:\n            Optionally create a directory at the path, by default False.\n\n        Returns\n        -------\n        The path within the data sub-directories.\n        \"\"\"\n        path = os.sep.join(\n            [self.generated_data_dirs[sub_dir_name], path.replace(\"/\", os.sep)]\n        )\n        if make_dir and not os.path.isdir(path):\n            os.makedirs(path)\n        return path",
  "def __init__(\n        self,\n        reactor_name: str,\n        reference_data_root: str = \"data/bluemira\",\n        generated_data_root: str = \"data/bluemira\",\n    ):\n        self._reactor_name = reactor_name\n        self._reference_data_root = reference_data_root\n        self._generated_data_root = generated_data_root\n        self.replace_bm_root()",
  "def reactor_name(self):\n        \"\"\"\n        Gets the reactor name for this instance.\n        \"\"\"\n        return self._reactor_name",
  "def generated_data_root(self) -> str:\n        \"\"\"\n        Gets the generated data root directory for this instance.\n        \"\"\"\n        return self._generated_data_root",
  "def reference_data_root(self) -> str:\n        \"\"\"\n        Get the reference data root directory for this instance.\n        \"\"\"\n        return self._reference_data_root",
  "def replace_bm_root(self, keyword: str = BM_ROOT):\n        \"\"\"\n        Replace the keyword in input paths with path to local bluemira installation.\n        \"\"\"\n        bm_root = get_bluemira_root()\n        self._reference_data_root = self.reference_data_root.replace(keyword, bm_root)\n        self._generated_data_root = self.generated_data_root.replace(keyword, bm_root)",
  "def _verify_reference_data_root(self):\n        \"\"\"\n        Check that the reference data root defined in this instance is a valid\n        directory.\n\n        Raises\n        ------\n        ValueError\n            If the reference data root for this instance is not a valid directory.\n        \"\"\"\n        _get_relpath(self._reference_data_root, subfolder=\"\")",
  "def make_reactor_folder(self, subfolder: str) -> Dict[str, str]:\n        \"\"\"\n        Initialise a data storage folder tree.\n\n        Parameters\n        ----------\n        subfolder:\n            The subfolder of the bluemira directory in which to add the data structure\n\n        Returns\n        -------\n        The dictionary of subfolder names to full paths (useful shorthand)\n        \"\"\"\n        root = os.path.join(subfolder, \"reactors\", self.reactor_name)\n        pathlib.Path(root).mkdir(parents=True, exist_ok=True)\n\n        mapping = {\"root\": root}\n        for sub in SUB_DIRS:\n            folder = os.sep.join([root, sub])\n            pathlib.Path(folder).mkdir(exist_ok=True)\n\n            mapping[sub] = folder\n\n        return mapping",
  "def set_reference_data_paths(self):\n        \"\"\"\n        Generate the reference data paths for this instance, based on the reactor name.\n        \"\"\"\n        self._verify_reference_data_root()\n        self.reference_data_dirs = self.make_reactor_folder(self._reference_data_root)",
  "def create_reference_data_paths(self):\n        \"\"\"\n        Generate the reference data paths for this instance, based on the reactor name.\n\n        Also builds the relevant directory structure.\n        \"\"\"\n        pathlib.Path(self._reference_data_root).mkdir(parents=True, exist_ok=True)\n        self.reference_data_dirs = self.make_reactor_folder(self._reference_data_root)",
  "def create_generated_data_paths(self):\n        \"\"\"\n        Generate the generated data paths for this instance, based on the reactor name.\n\n        Also builds the relevant directory structure.\n        \"\"\"\n        pathlib.Path(self._generated_data_root).mkdir(parents=True, exist_ok=True)\n        self.generated_data_dirs = self.make_reactor_folder(self._generated_data_root)",
  "def build_dirs(self, create_reference_data_paths: bool = False):\n        \"\"\"\n        Create the directory structures for this instance and sets the path references.\n        \"\"\"\n        if create_reference_data_paths:\n            self.create_reference_data_paths()\n        else:\n            self.set_reference_data_paths()\n        self.create_generated_data_paths()",
  "def get_path(self, sub_dir_name: str, path: str, make_dir: bool = False) -> str:\n        \"\"\"\n        Get a path within the generated data sub-sdirectories.\n\n        If the path does not exist then it will optionally be created as a directory.\n\n        Parameters\n        ----------\n        sub_dir_name:\n            The name of the sub-directory to create the path under. Must be one of the\n            names in bluemira.base.file.SUB_DIRS.\n        path:\n            The path to create under the sub-directory.\n        make_dir:\n            Optionally create a directory at the path, by default False.\n\n        Returns\n        -------\n        The path within the data sub-directories.\n        \"\"\"\n        path = os.sep.join(\n            [self.generated_data_dirs[sub_dir_name], path.replace(\"/\", os.sep)]\n        )\n        if make_dir and not os.path.isdir(path):\n            os.makedirs(path)\n        return path",
  "class Designer(abc.ABC, Generic[_DesignerReturnT]):\n    \"\"\"\n    Base class for 'Designers' that solver design problems as part of\n    building a reactor component.\n\n    Parameters\n    ----------\n    params:\n        The parameters required by the designer.\n    build_config:\n        The build configuration options for the designer.\n    verbose:\n        control how much logging the designer will output\n\n    Notes\n    -----\n    If there are no parameters associated with a concrete builder, set\n    `param_cls` to `None` and pass `None` into this class's constructor.\n    \"\"\"\n\n    KEY_RUN_MODE = \"run_mode\"\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, ConfigParams, None],\n        build_config: Optional[Dict] = None,\n        *,\n        verbose=True,\n    ):\n        self.params = make_parameter_frame(params, self.param_cls)\n        self.build_config = build_config if build_config is not None else {}\n        self._verbose = verbose\n\n    def execute(self) -> _DesignerReturnT:\n        \"\"\"\n        Execute the designer with the run mode specified by the build config.\n\n        By default the run mode is 'run'.\n        \"\"\"\n        return _timing(\n            self._get_run_func(self.run_mode),\n            \"Executed in\",\n            f\"Executing {type(self).__name__}\",\n            debug_info_str=not self._verbose,\n        )()\n\n    @abc.abstractmethod\n    def run(self) -> _DesignerReturnT:\n        \"\"\"Run the design problem.\"\"\"\n\n    def mock(self) -> _DesignerReturnT:\n        \"\"\"\n        Return a mock of a design.\n\n        Optionally implemented.\n        \"\"\"\n        raise NotImplementedError\n\n    def read(self) -> _DesignerReturnT:\n        \"\"\"\n        Read a design from a file.\n\n        The file path should be specified in the build config.\n\n        Optionally implemented.\n        \"\"\"\n        raise NotImplementedError\n\n    @abc.abstractproperty\n    def param_cls(self) -> Type[ParameterFrame]:\n        \"\"\"The ParameterFrame class defining this designer's parameters.\"\"\"\n\n    @property\n    def run_mode(self) -> str:\n        \"\"\"Get the run mode of this designer.\"\"\"\n        return self.build_config.get(self.KEY_RUN_MODE, \"run\")\n\n    def _get_run_func(self, mode: str) -> Callable:\n        \"\"\"Retrieve the function corresponding to the given run mode.\"\"\"\n        try:\n            return getattr(self, mode)\n        except AttributeError:\n            raise ValueError(f\"{type(self).__name__} has no run mode '{mode}'.\")",
  "def run_designer(\n    designer_cls: Type[Designer[_DesignerReturnT]],\n    params: Union[ParameterFrame, Dict],\n    build_config: Dict,\n    **kwargs,\n) -> _DesignerReturnT:\n    \"\"\"Make and run a designer, returning the result.\"\"\"\n    designer = designer_cls(params, build_config, **kwargs)\n    return designer.execute()",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, ConfigParams, None],\n        build_config: Optional[Dict] = None,\n        *,\n        verbose=True,\n    ):\n        self.params = make_parameter_frame(params, self.param_cls)\n        self.build_config = build_config if build_config is not None else {}\n        self._verbose = verbose",
  "def execute(self) -> _DesignerReturnT:\n        \"\"\"\n        Execute the designer with the run mode specified by the build config.\n\n        By default the run mode is 'run'.\n        \"\"\"\n        return _timing(\n            self._get_run_func(self.run_mode),\n            \"Executed in\",\n            f\"Executing {type(self).__name__}\",\n            debug_info_str=not self._verbose,\n        )()",
  "def run(self) -> _DesignerReturnT:\n        \"\"\"Run the design problem.\"\"\"",
  "def mock(self) -> _DesignerReturnT:\n        \"\"\"\n        Return a mock of a design.\n\n        Optionally implemented.\n        \"\"\"\n        raise NotImplementedError",
  "def read(self) -> _DesignerReturnT:\n        \"\"\"\n        Read a design from a file.\n\n        The file path should be specified in the build config.\n\n        Optionally implemented.\n        \"\"\"\n        raise NotImplementedError",
  "def param_cls(self) -> Type[ParameterFrame]:\n        \"\"\"The ParameterFrame class defining this designer's parameters.\"\"\"",
  "def run_mode(self) -> str:\n        \"\"\"Get the run mode of this designer.\"\"\"\n        return self.build_config.get(self.KEY_RUN_MODE, \"run\")",
  "def _get_run_func(self, mode: str) -> Callable:\n        \"\"\"Retrieve the function corresponding to the given run mode.\"\"\"\n        try:\n            return getattr(self, mode)\n        except AttributeError:\n            raise ValueError(f\"{type(self).__name__} has no run mode '{mode}'.\")",
  "class LogLevel(Enum):\n    \"\"\"Linking level names and corresponding numbers.\"\"\"\n\n    CRITICAL = 50\n    ERROR = 40\n    WARNING = 30\n    INFO = 20\n    DEBUG = 10\n    NOTSET = 0",
  "def logger_setup(\n    logfilename: str = \"bluemira.log\", *, level: Union[str, int] = \"INFO\"\n) -> logging.Logger:\n    \"\"\"\n    Create logger with two handlers.\n\n    Parameters\n    ----------\n    logfilename:\n        Name of file to write logs to, default = bluemira.log\n    level:\n        The initial logging level to be printed to the console, default = INFO.\n\n    Returns\n    -------\n    The logger to be used\n\n    Notes\n    -----\n    set to debug initially\n    \"\"\"\n    root_logger = logging.getLogger(\"\")\n    bm_logger = logging.getLogger(\"bluemira\")\n\n    py_level = _convert_log_level(level).value\n\n    # what will be shown on screen\n\n    on_screen_handler = logging.StreamHandler(stream=sys.stderr)\n    on_screen_handler.setLevel(py_level)\n\n    # what will be written to a file\n\n    recorded_handler = logging.FileHandler(logfilename)\n    recorded_formatter = logging.Formatter(\n        fmt=\"%(asctime)s %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n    )\n    recorded_handler.setLevel(logging.DEBUG)\n    recorded_handler.setFormatter(recorded_formatter)\n\n    bm_logger.setLevel(logging.DEBUG)\n\n    root_logger.addHandler(on_screen_handler)\n    root_logger.addHandler(recorded_handler)\n\n    return bm_logger",
  "def set_log_level(\n    verbose: Union[int, str] = 1,\n    increase: bool = False,\n    logger_names: Iterable[str] = (\"bluemira\"),\n):\n    \"\"\"\n    Get new log level and check if it is possible.\n\n    Parameters\n    ----------\n    verbose:\n        Amount the severity level of the logger should be changed by or to\n    increase:\n        Whether level should be increased by specified amount or changed to it\n    logger_names:\n        The loggers for which to set the level, default = (\"bluemira\")\n    \"\"\"\n    # change loggers level\n    for logger_name in logger_names:\n        logger = logging.getLogger(logger_name)\n\n        current_level = logger.getEffectiveLevel() if increase else 0\n        new_level = _convert_log_level(verbose, current_level)\n        _modify_handler(new_level, logger)",
  "def get_log_level(logger_name: str = \"bluemira\", as_str: bool = True) -> Union[str, int]:\n    \"\"\"\n    Return the current logging level.\n\n    Parameters\n    ----------\n    logger_name\n        The named logger to get the level for.\n    as_str\n        If True then return the logging level as a string, else as an int.\n    \"\"\"\n    logger = logging.getLogger(logger_name)\n\n    max_level = 0\n    for handler in logger.handlers or logger.parent.handlers:\n        if not isinstance(handler, logging.FileHandler):\n            if handler.level > max_level:\n                max_level = handler.level\n    if as_str:\n        return LogLevel(max_level).name\n    else:\n        return max_level // 10",
  "def _convert_log_level(level: Union[str, int], current_level: int = 0) -> LogLevel:\n    \"\"\"\n    Convert the provided logging level to a LogLevel objects.\n\n    Parameters\n    ----------\n    level:\n        The bluemira logging level.\n    current_level:\n        The current bluemira logging level to increment from.\n\n    Returns\n    -------\n    The LogLevel corresponding to the requested level.\n    \"\"\"\n    try:\n        if isinstance(level, str):\n            new_level = LogLevel[level]\n        else:\n            value = int(current_level + (level * 10))\n            new_level = LogLevel(value)\n    except ValueError:\n        raise LogsError(f\"Unknown severity level - {value}\")\n    except KeyError:\n        raise LogsError(f\"Unknown severity level - {level}\")\n    return new_level",
  "def _modify_handler(new_level: LogLevel, logger: logging.Logger):\n    \"\"\"\n    Change level of the logger from user's input.\n\n    Parameters\n    ----------\n    new_level:\n        Severity level for handler to be changed to, from set_log_level\n    logger:\n        Logger to be used\n    \"\"\"\n    for handler in logger.handlers or logger.parent.handlers:\n        if not isinstance(handler, logging.FileHandler):\n            handler.setLevel(new_level.value)",
  "class LoggingContext:\n    \"\"\"\n    A context manager for temporarily adjusting the logging level\n\n    Parameters\n    ----------\n    level:\n        The bluemira logging level to set within the context.\n    \"\"\"\n\n    def __init__(self, level: Union[str, int]):\n        self.level = level\n        self.original_level = get_log_level()\n\n    def __enter__(self):\n        \"\"\"\n        Set the logging level to the new level when we enter the context.\n        \"\"\"\n        set_log_level(self.level)\n\n    def __exit__(self, type, value, traceback):\n        \"\"\"\n        Set the logging level to the original level when we exit the context.\n        \"\"\"\n        set_log_level(self.original_level)",
  "def __init__(self, level: Union[str, int]):\n        self.level = level\n        self.original_level = get_log_level()",
  "def __enter__(self):\n        \"\"\"\n        Set the logging level to the new level when we enter the context.\n        \"\"\"\n        set_log_level(self.level)",
  "def __exit__(self, type, value, traceback):\n        \"\"\"\n        Set the logging level to the original level when we exit the context.\n        \"\"\"\n        set_log_level(self.original_level)",
  "class BMUnitRegistry(UnitRegistry):\n    \"\"\"\n    Bluemira UnitRegistry\n\n    Extra conversions:\n\n    eV <-> Kelvin\n    Pa m^3 <-> mol\n\n    Extra units:\n\n    displacements_per_atom (dpa)\n    full_power_year (fpy)\n    atomic_parts_per_million (appm)\n    USD ($)\n\n    \"\"\"\n\n    def __init__(self):\n        # Preprocessor replacements have spaces so\n        # the units dont become prefixes or get prefixed\n        # space before on % so that M% is not a thing\n        # M$ makes sense if a bit non-standard\n        super().__init__(\n            fmt_locale=\"en_GB\",\n            preprocessors=[\n                lambda x: x.replace(\"$\", \"USD \"),\n            ],\n        )\n\n        # Extra units\n        self.define(\"displacements_per_atom  = count = dpa\")\n        self.define(\"full_power_year = year = fpy\")\n        self.define(\"atomic_parts_per_million = appm = ppm\")\n        # Other currencies need to be set up in a new context\n        self.define(\"USD = [currency]\")\n\n        self._gas_flow_temperature = None\n        self._contexts_added = False\n\n    def _add_contexts(self, contexts: Optional[List[Context]] = None):\n        \"\"\"\n        Add new contexts to registry\n        \"\"\"\n        if not self._contexts_added:\n            self.contexts = [self._energy_temperature_context(), self._flow_context()]\n\n            for c in self.contexts:\n                self.add_context(c)\n\n            self._contexts_added = True\n\n        if contexts:\n            for c in contexts:\n                self.add_context(c)\n\n    def enable_contexts(self, *contexts: List[Context], **kwargs):\n        \"\"\"\n        Enable contexts\n        \"\"\"\n        self._add_contexts(contexts)\n\n        super().enable_contexts(*[*self.contexts, *contexts], **kwargs)\n\n    def _energy_temperature_context(self):\n        \"\"\"\n        Converter between energy and temperature\n\n        temperature = energy / k_B\n\n        Returns\n        -------\n        pint context\n\n        \"\"\"\n        e_to_t = Context(\"Energy_to_Temperature\")\n\n        t_units = \"[temperature]\"\n        ev_units = \"[energy]\"\n\n        conversion = self.Quantity(\"k_B\")\n\n        return self._transform(\n            e_to_t,\n            t_units,\n            ev_units,\n            lambda _, x: x * conversion,\n            lambda _, x: x / conversion,\n        )\n\n    @property\n    def flow_conversion(self):\n        \"\"\"Gas flow conversion factor R * T\"\"\"\n        return self.Quantity(\"molar_gas_constant\") * self.gas_flow_temperature\n\n    @property\n    def gas_flow_temperature(self):\n        \"\"\"\n        Gas flow temperature in kelvin\n\n        If Quantity provided to setter it will convert units (na\u00efvely)\n        \"\"\"\n        if self._gas_flow_temperature is None:\n            self._gas_flow_temperature = self.Quantity(0, \"celsius\").to(\"kelvin\")\n        return self._gas_flow_temperature\n\n    @gas_flow_temperature.setter\n    def gas_flow_temperature(self, value: Union[float, None, Quantity]):\n        self._gas_flow_temperature = (\n            value.to(\"kelvin\")\n            if isinstance(value, Quantity)\n            else value\n            if value is None\n            else self.Quantity(value, \"kelvin\")\n        )\n\n    def _flow_context(self):\n        \"\"\"\n        Convert between flow in mol and Pa m^3\n\n        Pa m^3 = R * temperature * mol\n\n        https://en.wikipedia.org/wiki/Standard_temperature_and_pressure#Molar_volume_of_a_gas\n\n        Returns\n        -------\n        pint context\n\n        \"\"\"\n        mols_to_pam3 = Context(\"Mol to Pa.m^3 for a gas\")\n\n        mol_units = \"[substance]\"\n        pam3_units = \"[energy]\"\n\n        return self._transform(\n            mols_to_pam3,\n            mol_units,\n            pam3_units,\n            lambda ureg, x: x * ureg.flow_conversion,\n            lambda ureg, x: x / ureg.flow_conversion,\n        )\n\n    @staticmethod\n    def _transform(\n        context: Context,\n        units_from: str,\n        units_to: str,\n        forward_transform: Callable[\n            [UnitRegistry, Union[float, complex, Quantity]], float\n        ],\n        reverse_transform: Callable[\n            [UnitRegistry, Union[float, complex, Quantity]], float\n        ],\n    ):\n        formatters = [\"{}\", \"{} / [time]\"]\n\n        for form in formatters:\n            context.add_transformation(\n                form.format(units_from), form.format(units_to), forward_transform\n            )\n            context.add_transformation(\n                form.format(units_to), form.format(units_from), reverse_transform\n            )\n\n        return context",
  "def units_compatible(unit_1: str, unit_2: str) -> bool:\n    \"\"\"\n    Test if units are compatible\n    \"\"\"\n    try:\n        raw_uc(1, unit_1, unit_2)\n        return True\n    except PintError:\n        return False",
  "def raw_uc(\n    value: Union[float, np.ndarray, List[float]],\n    unit_from: Union[str, ureg.Unit],\n    unit_to: Union[str, ureg.Unit],\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Raw unit converter\n\n    Converts a value from one unit to another\n\n    Parameters\n    ----------\n    value:\n        value to convert\n    unit_from:\n        unit to convert from\n    unit_to:\n        unit to convert to\n\n    Returns\n    -------\n    converted value\n    \"\"\"\n    try:\n        return (\n            ureg.Quantity(value, ureg.Unit(unit_from)).to(ureg.Unit(unit_to)).magnitude\n        )\n    except ValueError:\n        # Catch scales on units eg the ridculousness of this unit: 10^19/m^3\n        unit_from_q = ureg.Quantity(unit_from)\n        unit_to_q = ureg.Quantity(unit_to)\n        return (\n            ureg.Quantity(value * unit_from_q).to(unit_to_q.units).magnitude\n            / unit_to_q.magnitude\n        )",
  "def gas_flow_uc(\n    value: Union[float, np.ndarray],\n    unit_from: Union[str, ureg.Unit],\n    unit_to: Union[str, ureg.Unit],\n    gas_flow_temperature: Optional[Union[float, Quantity]] = None,\n) -> Union[int, float, np.ndarray]:\n    \"\"\"\n    Converts around Standard temperature and pressure for gas unit conversion.\n    Accurate for Ideal gases.\n\n    https://en.wikipedia.org/wiki/Standard_temperature_and_pressure#Molar_volume_of_a_gas\n\n    Parameters\n    ----------\n    value:\n        value to convert\n    unit_from:\n        unit to convert from\n    unit_to:\n        unit to convert to\n    gas_flow_temperature:\n        Gas flow temperature if not provided is 273.15 K,\n        if not a `Quantity` the units are assumed to be kelvin\n\n    Returns\n    -------\n    converted value\n    \"\"\"\n    if gas_flow_temperature is not None:\n        ureg.gas_flow_temperature = gas_flow_temperature\n    try:\n        return raw_uc(value, unit_from, unit_to)\n    finally:\n        ureg.gas_flow_temperature = None",
  "def to_celsius(\n    temp: Union[float, np.ndarray, List[float]], unit: Union[str, Unit] = ureg.kelvin\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Convert a temperature in Kelvin to Celsius.\n\n    Parameters\n    ----------\n    temp:\n        The temperature to convert, default [K]\n    unit:\n        change the unit of the incoming value\n\n    Returns\n    -------\n    The temperature [\u00b0C]\n    \"\"\"\n    converted_val = raw_uc(temp, unit, ureg.celsius)\n    _temp_check(ureg.celsius, converted_val)\n    return converted_val",
  "def to_kelvin(\n    temp: Union[float, np.ndarray, List[float]], unit: Union[str, Unit] = ureg.celsius\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Convert a temperature in Celsius to Kelvin.\n\n    Parameters\n    ----------\n    temp:\n        The temperature to convert, default [\u00b0C]\n    unit:\n        change the unit of the incoming value\n\n\n    Returns\n    -------\n    The temperature [K]\n    \"\"\"\n    converted_val = raw_uc(temp, unit, ureg.kelvin)\n    _temp_check(ureg.kelvin, converted_val)\n    return converted_val",
  "def _temp_check(unit: Unit, val: Union[float, int, complex, Quantity]):\n    \"\"\"\n    Check temperature is above absolute zero\n\n    Parameters\n    ----------\n    unit:\n        pint Unit\n    val:\n        value to check\n\n    Raises\n    ------\n    ValueError if below absolute zero\n\n    \"\"\"\n    if unit.dimensionality == UnitsContainer({\"[temperature]\": 1}) and np.any(\n        np.less(\n            val,\n            ABS_ZERO.get(unit, ureg.Quantity(0, ureg.kelvin).to(unit).magnitude),\n        )\n    ):\n        raise ValueError(\"Negative temperature in K specified.\")",
  "def kgm3_to_gcm3(\n    density: Union[float, np.ndarray, List[float]]\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Convert a density in kg/m3 to g/cm3\n\n    Parameters\n    ----------\n    density:\n        The density [kg/m3]\n\n    Returns\n    -------\n    The density [g/cm3]\n    \"\"\"\n    return raw_uc(density, \"kg.m^-3\", \"g.cm^-3\")",
  "def gcm3_to_kgm3(\n    density: Union[float, np.ndarray, List[float]]\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Convert a density in g/cm3 to kg/m3\n\n    Parameters\n    ----------\n    density:\n        The density [g/cm3]\n\n    Returns\n    -------\n    The density [kg/m3]\n    \"\"\"\n    return raw_uc(density, \"g.cm^-3\", \"kg.m^-3\")",
  "def __init__(self):\n        # Preprocessor replacements have spaces so\n        # the units dont become prefixes or get prefixed\n        # space before on % so that M% is not a thing\n        # M$ makes sense if a bit non-standard\n        super().__init__(\n            fmt_locale=\"en_GB\",\n            preprocessors=[\n                lambda x: x.replace(\"$\", \"USD \"),\n            ],\n        )\n\n        # Extra units\n        self.define(\"displacements_per_atom  = count = dpa\")\n        self.define(\"full_power_year = year = fpy\")\n        self.define(\"atomic_parts_per_million = appm = ppm\")\n        # Other currencies need to be set up in a new context\n        self.define(\"USD = [currency]\")\n\n        self._gas_flow_temperature = None\n        self._contexts_added = False",
  "def _add_contexts(self, contexts: Optional[List[Context]] = None):\n        \"\"\"\n        Add new contexts to registry\n        \"\"\"\n        if not self._contexts_added:\n            self.contexts = [self._energy_temperature_context(), self._flow_context()]\n\n            for c in self.contexts:\n                self.add_context(c)\n\n            self._contexts_added = True\n\n        if contexts:\n            for c in contexts:\n                self.add_context(c)",
  "def enable_contexts(self, *contexts: List[Context], **kwargs):\n        \"\"\"\n        Enable contexts\n        \"\"\"\n        self._add_contexts(contexts)\n\n        super().enable_contexts(*[*self.contexts, *contexts], **kwargs)",
  "def _energy_temperature_context(self):\n        \"\"\"\n        Converter between energy and temperature\n\n        temperature = energy / k_B\n\n        Returns\n        -------\n        pint context\n\n        \"\"\"\n        e_to_t = Context(\"Energy_to_Temperature\")\n\n        t_units = \"[temperature]\"\n        ev_units = \"[energy]\"\n\n        conversion = self.Quantity(\"k_B\")\n\n        return self._transform(\n            e_to_t,\n            t_units,\n            ev_units,\n            lambda _, x: x * conversion,\n            lambda _, x: x / conversion,\n        )",
  "def flow_conversion(self):\n        \"\"\"Gas flow conversion factor R * T\"\"\"\n        return self.Quantity(\"molar_gas_constant\") * self.gas_flow_temperature",
  "def gas_flow_temperature(self):\n        \"\"\"\n        Gas flow temperature in kelvin\n\n        If Quantity provided to setter it will convert units (na\u00efvely)\n        \"\"\"\n        if self._gas_flow_temperature is None:\n            self._gas_flow_temperature = self.Quantity(0, \"celsius\").to(\"kelvin\")\n        return self._gas_flow_temperature",
  "def gas_flow_temperature(self, value: Union[float, None, Quantity]):\n        self._gas_flow_temperature = (\n            value.to(\"kelvin\")\n            if isinstance(value, Quantity)\n            else value\n            if value is None\n            else self.Quantity(value, \"kelvin\")\n        )",
  "def _flow_context(self):\n        \"\"\"\n        Convert between flow in mol and Pa m^3\n\n        Pa m^3 = R * temperature * mol\n\n        https://en.wikipedia.org/wiki/Standard_temperature_and_pressure#Molar_volume_of_a_gas\n\n        Returns\n        -------\n        pint context\n\n        \"\"\"\n        mols_to_pam3 = Context(\"Mol to Pa.m^3 for a gas\")\n\n        mol_units = \"[substance]\"\n        pam3_units = \"[energy]\"\n\n        return self._transform(\n            mols_to_pam3,\n            mol_units,\n            pam3_units,\n            lambda ureg, x: x * ureg.flow_conversion,\n            lambda ureg, x: x / ureg.flow_conversion,\n        )",
  "def _transform(\n        context: Context,\n        units_from: str,\n        units_to: str,\n        forward_transform: Callable[\n            [UnitRegistry, Union[float, complex, Quantity]], float\n        ],\n        reverse_transform: Callable[\n            [UnitRegistry, Union[float, complex, Quantity]], float\n        ],\n    ):\n        formatters = [\"{}\", \"{} / [time]\"]\n\n        for form in formatters:\n            context.add_transformation(\n                form.format(units_from), form.format(units_to), forward_transform\n            )\n            context.add_transformation(\n                form.format(units_to), form.format(units_from), reverse_transform\n            )\n\n        return context",
  "def _remove_suffix(s: str, suffix: str) -> str:\n    # Python 3.9 has str.removesuffix()\n    if suffix and s.endswith(suffix):\n        return s[: -len(suffix)]\n    return s",
  "class Builder(abc.ABC):\n    \"\"\"\n    Base class for component builders.\n\n    Parameters\n    ----------\n    params:\n        The parameters required by the builder.\n    build_config:\n        The build configuration for the builder.\n    verbose:\n        control how much logging the designer will output\n\n    Notes\n    -----\n    If there are no parameters associated with a concrete builder, set\n    `param_cls` to `None` and pass `None` into this class's constructor.\n    \"\"\"\n\n    def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, ConfigParams, None],\n        build_config: Optional[Dict] = None,\n        *,\n        verbose=True,\n    ):\n        super().__init__()\n        self.params = make_parameter_frame(params, self.param_cls)\n        self.build_config = build_config if build_config is not None else {}\n        self.name = self.build_config.get(\n            \"name\", _remove_suffix(self.__class__.__name__, \"Builder\")\n        )\n        self.build = _timing(\n            self.build, \"Built in\", f\"Building {self.name}\", debug_info_str=not verbose\n        )\n\n    @abc.abstractproperty\n    def param_cls(self) -> Union[Type[ParameterFrame], None]:\n        \"\"\"The class to hold this Builders's parameters.\"\"\"\n        pass\n\n    @abc.abstractmethod\n    def build(self) -> Component:\n        \"\"\"Build the component.\"\"\"\n        pass\n\n    def component_tree(\n        self, xz: List[Component], xy: List[Component], xyz: List[Component]\n    ) -> Component:\n        \"\"\"\n        Adds views of components to an overall component tree.\n\n        Parameters\n        ----------\n        xz:\n            xz view of component\n        xy:\n            xy view of component\n        xyz:\n            xyz view of component\n        \"\"\"\n        component = Component(self.name)\n        component.add_child(Component(\"xz\", children=xz))\n        component.add_child(Component(\"xy\", children=xy))\n        component.add_child(Component(\"xyz\", children=xyz))\n\n        set_component_view(component.get_component(\"xz\"), \"xz\")\n        set_component_view(component.get_component(\"xy\"), \"xy\")\n\n        return component",
  "def __init__(\n        self,\n        params: Union[Dict, ParameterFrame, ConfigParams, None],\n        build_config: Optional[Dict] = None,\n        *,\n        verbose=True,\n    ):\n        super().__init__()\n        self.params = make_parameter_frame(params, self.param_cls)\n        self.build_config = build_config if build_config is not None else {}\n        self.name = self.build_config.get(\n            \"name\", _remove_suffix(self.__class__.__name__, \"Builder\")\n        )\n        self.build = _timing(\n            self.build, \"Built in\", f\"Building {self.name}\", debug_info_str=not verbose\n        )",
  "def param_cls(self) -> Union[Type[ParameterFrame], None]:\n        \"\"\"The class to hold this Builders's parameters.\"\"\"\n        pass",
  "def build(self) -> Component:\n        \"\"\"Build the component.\"\"\"\n        pass",
  "def component_tree(\n        self, xz: List[Component], xy: List[Component], xyz: List[Component]\n    ) -> Component:\n        \"\"\"\n        Adds views of components to an overall component tree.\n\n        Parameters\n        ----------\n        xz:\n            xz view of component\n        xy:\n            xy view of component\n        xyz:\n            xyz view of component\n        \"\"\"\n        component = Component(self.name)\n        component.add_child(Component(\"xz\", children=xz))\n        component.add_child(Component(\"xy\", children=xy))\n        component.add_child(Component(\"xyz\", children=xyz))\n\n        set_component_view(component.get_component(\"xz\"), \"xz\")\n        set_component_view(component.get_component(\"xy\"), \"xy\")\n\n        return component",
  "class BluemiraError(Exception):\n    \"\"\"\n    Base exception class. Sub-class from this for module level Errors.\n    \"\"\"\n\n    def __str__(self) -> str:\n        \"\"\"\n        Prettier handling of the Exception strings\n        \"\"\"\n        return fill(dedent(self.args[0]))",
  "class BuilderError(BluemiraError):\n    \"\"\"\n    Exception class for Builders.\n    \"\"\"\n\n    pass",
  "class ComponentError(BluemiraError):\n    \"\"\"\n    Exception class for Components.\n    \"\"\"\n\n    pass",
  "class LogsError(BluemiraError):\n    \"\"\"\n    Exception class for Components.\n    \"\"\"\n\n    pass",
  "class ParameterError(BluemiraError):\n    \"\"\"\n    Exception class for Parameters.\n    \"\"\"\n\n    pass",
  "class DesignError(BluemiraError):\n    \"\"\"\n    Exception class for Designs.\n    \"\"\"\n\n    pass",
  "class ReactorError(BluemiraError):\n    \"\"\"Exceptions related to :class:`bluemira.base.reactor.Reactor` objects.\"\"\"",
  "class ReactorConfigError(BluemiraError):\n    \"\"\"\n    Exceptions related to\n    :class:`bluemira.base.reactor_config.ReactorConfig` objects.\n    \"\"\"",
  "def __str__(self) -> str:\n        \"\"\"\n        Prettier handling of the Exception strings\n        \"\"\"\n        return fill(dedent(self.args[0]))",
  "def get_git_version(directory: str) -> str:\n    \"\"\"\n    Get the version string of the current git branch, e.g.: '0.0.3-74-g70d48be'.\n\n    Parameters\n    ----------\n    directory:\n        The full path directory of the folder to get git information from\n\n    Returns\n    -------\n    The git version bytestring\n    \"\"\"\n    return subprocess.check_output(  # noqa :S603, S607\n        [\"git\", \"describe\", \"--tags\", \"--always\"], cwd=directory\n    ).strip()",
  "def get_git_branch(directory: str) -> str:\n    \"\"\"\n    Get the name of the current git branch, e.g. 'develop'.\n\n    Parameters\n    ----------\n    directory:\n        The full path directory of the folder to get git information from\n\n    Returns\n    -------\n    The git branch string\n    \"\"\"\n    out = subprocess.check_output(  # noqa :S603, S607\n        [\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"], cwd=directory\n    )\n    return out.strip().decode(\"utf-8\")",
  "def get_git_files(directory: str, branch: str) -> List[str]:\n    \"\"\"\n    Get the names of the files in the directory of the specified branch name.\n\n    Parameters\n    ----------\n    directory:\n        The full path directory of the folder to get git information from\n    branch:\n        The name of the git branch to retrieve the filenames from\n\n    Returns\n    -------\n    The list of git-controlled path strings\n    \"\"\"\n    return (\n        subprocess.check_output(  # noqa :S603, S607\n            [\"git\", \"ls-tree\", \"-r\", branch, \"--name-only\"], cwd=directory\n        )\n        .decode(\"utf-8\")\n        .splitlines()\n    )",
  "def get_platform() -> str:\n    \"\"\"\n    Get the OS platform.\n\n    Returns\n    -------\n    The generic name of the platform (e.g. Linux, Windows)\n    \"\"\"\n    return platform.uname()[0]",
  "def count_slocs(\n    directory: str,\n    branch: str,\n    exts: Optional[List[str]] = None,\n    ignore: Optional[List[str]] = None,\n) -> Dict:\n    \"\"\"\n    Counts lines of code within a given directory for a given git branch\n\n    Parameters\n    ----------\n    directory:\n        The full path directory of the folder to get git information from\n    branch:\n        The git branch string\n    exts:\n        The list of file extensions to search the directory for\n    ignore:\n        The list of extensions and filenames to ignore\n\n    Returns\n    -------\n    The dictionary of number of lines of code per file extension, and the\n    total linecount\n    \"\"\"\n    if ignore is None:\n        ignore = [\".git\", \".txt\", \"look_and_feel.py\"]\n\n    if exts is None:\n        exts = [\".py\"]\n\n    lines = {}\n    for k in exts:\n        lines[k] = 0\n    files = get_git_files(directory, branch)\n    for name in files:\n        if name.split(os.sep)[-1] not in ignore and name not in ignore:\n            for e in exts:\n                if name.endswith(e):\n                    path = os.sep.join([directory, name])\n                    try:\n                        with open(path, \"r\", encoding=\"utf-8\") as file:\n                            lines[e] += len(file.read().splitlines())\n\n                    except FileNotFoundError:\n                        bluemira_warn(\n                            \"count_slocs: Probably not on the right git branch\"\n                        )\n                        continue\n\n    lines[\".py\"] += LOCAL_LINES\n    lines[\"total\"] = sum([lines[k] for k in lines.keys()])\n    return lines",
  "def _print_color(string: str, color: str) -> str:\n    \"\"\"\n    Create text to print. NOTE: Does not call print command\n\n    Parameters\n    ----------\n    string:\n        The text to colour\n    color:\n        The color to make the color-string for\n\n    Returns\n    -------\n    The string with ANSI color decoration\n    \"\"\"\n    return f\"{ANSI_COLOR[color]}{string}{EXIT_COLOR}\"",
  "def _bm_print(string: str, width: int = 73):\n    \"\"\"\n    Create the text string for boxed text to print to the console.\n\n    Parameters\n    ----------\n    string:\n        The string of text to colour and box\n    width:\n        The width of the box, default = 73 (leave this alone for best results)\n\n    Returns\n    -------\n    The text string of the boxed text\n    \"\"\"\n    strings = [\n        \" \" if s == \"\\n\" and i != 0 else s[:-1] if s.endswith(\"\\n\") else s\n        for i, s in enumerate(string.splitlines(keepends=True))\n    ]\n    bw = width - 4\n    t = [\n        wrap(s, width=bw, replace_whitespace=False, drop_whitespace=False)\n        for s in strings\n    ]\n\n    s = [dedent(item) for sublist in t for item in sublist]\n    lines = [\"\".join([\"| \"] + [i] + [\" \"] * (width - 2 - len(i)) + [\" |\"]) for i in s]\n    h = \"\".join([\"+\"] + [\"-\" * width] + [\"+\"])\n    return h + \"\\n\" + \"\\n\".join(lines) + \"\\n\" + h",
  "def colourise(string: str, width: int = 73, color: str = \"blue\") -> str:\n    \"\"\"\n    Print coloured, boxed text to the console. Default template for bluemira\n    information.\n\n    Parameters\n    ----------\n    string:\n        The string of text to colour and box\n    width:\n        The width of the box, default = 73 (leave this alone for best results)\n    color:\n        The color to print the text in from `bluemira.base.constants.ANSI_COLOR`\n    \"\"\"\n    text = _bm_print(string, width=width)\n    color_text = _print_color(text, color)\n    return color_text",
  "def bluemira_critical(string: str):\n    \"\"\"\n    Standard template for bluemira critical errors.\n    \"\"\"\n    return LOGGER.critical(colourise(f\"CRITICAL: {string}\", color=\"darkred\"))",
  "def bluemira_error(string: str):\n    \"\"\"\n    Standard template for bluemira errors.\n    \"\"\"\n    return LOGGER.error(colourise(f\"ERROR: {string}\", color=\"red\"))",
  "def bluemira_warn(string: str):\n    \"\"\"\n    Standard template for bluemira warnings.\n    \"\"\"\n    return LOGGER.warning(colourise(f\"WARNING: {string}\", color=\"orange\"))",
  "def bluemira_print(string: str):\n    \"\"\"\n    Standard template for bluemira information messages.\n    \"\"\"\n    return LOGGER.info(colourise(string, color=\"blue\"))",
  "def bluemira_debug(string: str):\n    \"\"\"\n    Standard template for bluemira debugging.\n    \"\"\"\n    return LOGGER.debug(colourise(string, color=\"green\"))",
  "def _bm_print_singleflush(string: str, width: int = 73, color: str = \"blue\"):\n    \"\"\"\n    Create the text string for coloured, boxed text to flush print to the\n    console.\n\n    Parameters\n    ----------\n    string:\n        The string of text to colour and box\n    width:\n        The width of the box, default = 73 (leave this alone for best results)\n    color:\n        The color to print the text in, one of ['blue', 'red', 'green']\n\n    Returns\n    -------\n        The text string of the boxed coloured text to flush print\n    \"\"\"\n    a = width - len(string) - 2\n    text = \"| \" + string + a * \" \" + \" |\"\n    return _print_color(text, color)",
  "def _bluemira_clean_flush(string, func: Callable[[str], None] = LOGGER.info):\n    \"\"\"\n    Print and flush string. Useful for updating information.\n\n    Parameters\n    ----------\n    string:\n        The string to colour flush print\n    func:\n        The function to use for logging, by default LOGGER.info\n    \"\"\"\n    _terminator_handler(func, \"\\r\" + string, fhterm=logging.StreamHandler.terminator)",
  "def _terminator_handler(func: Callable[[str], None], string: str, *, fhterm: str = \"\"):\n    \"\"\"\n    Log string allowing modification to handler terminator\n\n    Parameters\n    ----------\n    func:\n        The function to use for logging (e.g LOGGER.info)\n    string:\n        The string to colour flush print\n    fhterm:\n        FileHandler Terminator\n    \"\"\"\n    original_terminator = logging.StreamHandler.terminator\n    logging.StreamHandler.terminator = \"\"\n    logging.FileHandler.terminator = fhterm\n    try:\n        func(string)\n    finally:\n        logging.StreamHandler.terminator = original_terminator\n        logging.FileHandler.terminator = original_terminator",
  "def bluemira_print_flush(string: str):\n    \"\"\"\n    Print a coloured, boxed line to the console and flushes it. Useful for\n    updating information.\n\n    Parameters\n    ----------\n    string:\n        The string to colour flush print\n    \"\"\"\n    _bluemira_clean_flush(_bm_print_singleflush(string), func=LOGGER.info)",
  "def bluemira_debug_flush(string: str):\n    \"\"\"\n    Print a coloured, boxed line to the console and flushes it. Useful for\n    updating information when running at the debug logging level.\n\n    Parameters\n    ----------\n    string:\n        The string to colour flush print for debug messages.\n    \"\"\"\n    _bluemira_clean_flush(\n        _bm_print_singleflush(string, color=\"green\"), func=LOGGER.debug\n    )",
  "def bluemira_print_clean(string: str):\n    \"\"\"\n    Print to the logging info console with no modification.\n    Useful for external programs\n\n    Parameters\n    ----------\n    string:\n        The string to print\n    \"\"\"\n    _terminator_handler(LOGGER.info, string)",
  "def bluemira_error_clean(string: str):\n    \"\"\"\n    Print to the logging error console, colouring the output red.\n    No other modification is made. Useful for external programs\n\n    Parameters\n    ----------\n    string:\n        The string to colour print\n    \"\"\"\n    _terminator_handler(LOGGER.error, _print_color(string, \"red\"))",
  "def print_banner():\n    \"\"\"\n    Print the initial banner to the console upon running the bluemira code.\n    \"\"\"\n    LOGGER.info(_print_color(BLUEMIRA_ASCII, color=\"blue\"))\n    v = version_banner()\n    v.extend(user_banner())\n    bluemira_print(\"\\n\".join(v))",
  "def version_banner() -> List[str]:\n    \"\"\"\n    Get the string for the version banner.\n\n    Returns\n    -------\n    The list of strings of text describing the version and code information\n    \"\"\"\n    mapping = {\n        \"SLOC\": \"total\",\n    }\n    root = get_bluemira_root()\n    if not os.path.isdir(f\"{root}/.git\") or shutil.which(\"git\") is None:\n        return [\n            f\"Version    : {__version__}\",\n            \"git branch : docker\",\n            \"SLOC      : N/A\",\n        ]\n    branch = get_git_branch(root)\n    sloc = count_slocs(get_bluemira_path().rstrip(os.sep), branch)\n    v = str(get_git_version(root))\n\n    output = [f\"Version    : {v[2:-1]}\", f\"git branch : {branch}\"]\n\n    for k, v in mapping.items():\n        if sloc[v] > 0:\n            line = k + \" \" * (11 - len(k)) + f\": {int(sloc[v])}\"\n            output.append(line)\n    return output",
  "def user_banner() -> List[str]:\n    \"\"\"\n    Get user and platform info and create text to print to banner.\n\n    Returns\n    -------\n    The text for the banner containing user and platform information\n    \"\"\"\n    return [\n        f\"User       : {getuser()}\",\n        f\"Platform   : {get_platform()}\",\n    ]",
  "class Component(NodeMixin, Plottable, DisplayableCAD):\n    \"\"\"\n    The Component is the fundamental building block for a bluemira reactor design. It\n    encodes the way that the corresponding part of the reactor will be built, along with\n    any other derived properties that relate to that component.\n\n    Components define a tree structure, based on the parent and children properties. This\n    allows the nodes on that tree to be passed around within bluemira so that\n    operations can be performed on the child branches of that structure.\n\n    For example, a reactor design including just a TFCoilSystem may look as below:\n\n    .. digraph:: base_component_tree\n\n      \"FusionPowerPlant\" -> \"TFCoilSystem\" -> {\"TFWindingPack\" \"TFCasing\"}\n\n    A Component cannot be used directly - only subclasses should be instantiated.\n    \"\"\"\n\n    name: str\n\n    def __init__(\n        self,\n        name: str,\n        parent: Optional[Component] = None,\n        children: Optional[List[Component]] = None,\n    ):\n        super().__init__()\n        self.name = name\n\n        if parent is not None and name in (ch.name for ch in parent.children):\n            raise ComponentError(f\"Component {name} is already a child of {parent}\")\n\n        if children is not None:\n            ch_names = [ch.name for ch in children]\n            if len(ch_names) != len(set(ch_names)):\n                raise ComponentError(\n                    f\"Children have duplicate names for Component {name}\",\n                )\n\n        self.parent = parent\n\n        if children:\n            self.children = children\n\n    def __repr__(self) -> str:\n        \"\"\"\n        The string representation of the instance\n        \"\"\"\n        return self.name + \" (\" + self.__class__.__name__ + \")\"\n\n    def filter_components(\n        self,\n        names: Iterable[str],\n        component_filter: Optional[Callable[[Component], bool]] = None,\n    ):\n        \"\"\"\n        Removes all components from the tree, starting at this component,\n        that are siblings of each component specified in `names`\n        and that aren't in `names` themselves.\n\n        Parameters\n        ----------\n        names:\n            The list of names of each component to search for.\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n\n        Notes\n        -----\n            This function mutates components in the subtree\n        \"\"\"\n        for n in names:\n            descendent_comps = self.get_component(\n                n,\n                first=False,\n            )\n\n            if descendent_comps is None:\n                continue\n            if not isinstance(descendent_comps, Iterable):\n                descendent_comps = [descendent_comps]\n\n            # Filter out all siblings that are not in names\n            for c in descendent_comps:\n                for c_sib in c.siblings:\n                    if c_sib.name not in names:\n                        c_sib.parent = None\n\n                for c_child in c.descendants:\n                    if component_filter is not None and not component_filter(c_child):\n                        c_child.parent = None\n\n    def tree(self) -> str:\n        \"\"\"\n        Get the tree of descendants of this instance.\n        \"\"\"\n        return str(RenderTree(self))\n\n    def copy(\n        self,\n        parent: Optional[Component] = None,\n    ) -> Component:\n        \"\"\"\n        Copies this component and its children (recursively)\n        and sets `parent` as this copy's parent.\n        This only creates copies of each Component,\n        the shape and material instances (for a PhysicalComponent for ex.)\n        are shared (i.e. are the same instance).\n\n        Parameters\n        ----------\n        parent:\n            The component to set as the copy's parent\n\n        Returns\n        -------\n        The copied component\n\n        Notes\n        -----\n            This function should be overridden by implementors\n        \"\"\"\n        # Initially copy self with None children\n        self_copy = Component(\n            name=self.name,\n            parent=parent,\n            children=None,\n        )\n        self_copy._plot_options = self._plot_options\n        self_copy._display_cad_options = self._display_cad_options\n        # Attaches children to parent\n        self.copy_children(parent=self_copy)\n\n        return self_copy\n\n    def copy_children(\n        self,\n        parent: Component,\n    ) -> list[Component]:\n        \"\"\"\n        Copies this component's children (recursively)\n        and sets `parent` as the copied children's parent.\n\n        Parameters\n        ----------\n        parent:\n            The component to set as the copied children's parent\n\n        Returns\n        -------\n        The copied children components\n\n        Notes\n        -----\n            This function should *not* be overridden by implementors\n        \"\"\"\n        return [] if len(self.children) == 0 else [c.copy(parent) for c in self.children]\n\n    def get_component(\n        self, name: str, first: bool = True, full_tree: bool = False\n    ) -> Union[Component, Tuple[Component], None]:\n        \"\"\"\n        Find the components with the specified name.\n\n        Parameters\n        ----------\n        name:\n            The name of the component to search for.\n        first:\n            If True, only the first element is returned, by default True.\n        full_tree:\n            If True, searches the tree from the root, else searches from this node, by\n            default False.\n\n        Returns\n        -------\n        The first component of the search if first is True, else all components\n        matching the search.\n\n        Notes\n        -----\n            This function is just a wrapper of the anytree.search.findall\n            function.\n        \"\"\"\n        return self._get_thing(\n            lambda n: anytree.search._filter_by_name(n, \"name\", name), first, full_tree\n        )\n\n    def get_component_properties(\n        self,\n        properties: Union[Iterable[str], str],\n        first: bool = True,\n        full_tree: bool = False,\n    ) -> Union[Tuple[List[Any]], List[Any], Any]:\n        \"\"\"\n        Get properties from a component\n\n        Parameters\n        ----------\n        properties:\n            properties to extract from component tree\n        first:\n            If True, only the first element is returned, by default True.\n        full_tree:\n            If True, searches the tree from the root, else searches from this node, by\n            default False.\n\n        Returns\n        -------\n        If multiple properties specified returns a tuple of the list of properties,\n        otherwise returns a list of the property.\n        If only one node has the property returns the value(s).\n\n        Notes\n        -----\n            This function is just a wrapper of the anytree.search.findall or find\n            functions.\n        \"\"\"\n        if isinstance(properties, str):\n            properties = [properties]\n\n        def filter_(node, properties):\n            return all(hasattr(node, prop) for prop in properties)\n\n        found_nodes = self._get_thing(lambda n: filter_(n, properties), first, full_tree)\n\n        if found_nodes is None:\n            return tuple([] for _ in properties)\n\n        if not isinstance(found_nodes, Iterable):\n            if len(properties) == 1:\n                return getattr(found_nodes, properties[0])\n            return [getattr(found_nodes, prop) for prop in properties]\n        else:\n            # Collect values by property instead of by node\n            node_properties = [\n                [getattr(node, prop) for prop in properties] for node in found_nodes\n            ]\n            return tuple(map(list, zip(*node_properties)))\n\n    def _get_thing(\n        self, filter_: Union[Callable, None], first: bool, full_tree: bool\n    ) -> Union[Component, Tuple[Component], None]:\n        found_nodes = anytree.search.findall(\n            self.root if full_tree else self, filter_=filter_\n        )\n        if found_nodes in (None, ()):\n            return None\n        if first and isinstance(found_nodes, Iterable):\n            found_nodes = found_nodes[0]\n        return found_nodes\n\n    def add_child(self, child: Component) -> Component:\n        \"\"\"\n        Add a single child to this node\n\n        Parameters\n        ----------\n        child:\n            The child to be added\n\n        Returns\n        -------\n        This component.\n        \"\"\"\n        # TODO: Support merge_trees here too.\n        if child in self.children or child.name in (ch.name for ch in self.children):\n            raise ComponentError(f\"Component {child} is already a child of {self}\")\n        self.children = list(self.children) + [child]\n\n        return self\n\n    def add_children(\n        self,\n        children: Optional[Union[Component, List[Component]]],\n        merge_trees: bool = False,\n    ) -> Optional[Component]:\n        \"\"\"\n        Add multiple children to this node\n\n        Parameters\n        ----------\n        children:\n            The children to be added\n\n        Returns\n        -------\n        This component.\n        \"\"\"\n        if children is None:\n            return\n        if isinstance(children, Component):\n            return self.add_child(children)\n        if not isinstance(children, list):\n            return\n        if len(children) == 0:\n            return\n\n        duplicates = []\n        for idx, child in reversed(list(enumerate(children))):\n            existing = self.get_component(child.name)\n            if existing is not None:\n                if merge_trees:\n                    existing.children = list(existing.children) + list(child.children)\n                    children.pop(idx)\n                else:\n                    duplicates += [child]\n        if duplicates != []:\n            raise ComponentError(\n                f\"Components {duplicates} are already children of {self}\"\n            )\n        self.children = list(self.children) + children\n\n        return self\n\n    def prune_child(self, name: str):\n        \"\"\"\n        Remove the child with the given name, and all its children.\n        \"\"\"\n        found_component = anytree.search.find_by_attr(self, name)\n        if found_component:\n            # Method of deleting a node suggested by library author\n            # https://github.com/c0fec0de/anytree/issues/152\n            found_component.parent = None",
  "class PhysicalComponent(Component):\n    \"\"\"\n    A physical component. It includes shape and materials.\n\n    Parameters\n    ----------\n    name:\n        Name of the PhysicalComponent\n    shape:\n        Geometry of the PhysicalComponent\n    material:\n        Material of the PhysicalComponent\n    parent:\n        Parent of the PhysicalComponent\n    children:\n        Children of the PhysicalComponent\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        shape: BluemiraGeo,\n        material: Any = None,\n        parent: Optional[Component] = None,\n        children: Optional[List[Component]] = None,\n    ):\n        super().__init__(name, parent, children)\n        self.shape = shape\n        self.material = material\n\n    def copy(\n        self,\n        parent: Optional[Component] = None,\n    ) -> Component:\n        \"\"\"\n        Copies this component and its children (recursively)\n        and sets `parent` as this copy's parent.\n        This only creates copies of each Component,\n        the shape and material instances (for a PhysicalComponent for ex.)\n        are shared (i.e. are the same instance).\n        \"\"\"\n        # Initially copy self with None children\n        self_copy = PhysicalComponent(\n            name=self.name,\n            parent=parent,\n            children=None,\n            shape=self.shape,\n            material=self.material,\n        )\n        self_copy._plot_options = self._plot_options\n        self_copy._display_cad_options = self._display_cad_options\n        # Attaches children to parent\n        self.copy_children(parent=self_copy)\n\n        return self_copy\n\n    @property\n    def shape(self) -> BluemiraGeo:\n        \"\"\"\n        The geometric shape of the Component.\n        \"\"\"\n        return self._shape\n\n    @shape.setter\n    def shape(self, value: BluemiraGeo):\n        self._shape = value\n\n    @property\n    def material(self):\n        \"\"\"\n        The material that the Component is built from.\n        \"\"\"\n        return self._material\n\n    @material.setter\n    def material(self, value):\n        self._material = value",
  "class MagneticComponent(PhysicalComponent):\n    \"\"\"\n    A magnetic component. It includes a shape, a material, and a source conductor.\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        shape: BluemiraGeo,\n        material: Any = None,\n        conductor: Any = None,\n        parent: Optional[Component] = None,\n        children: Optional[List[Component]] = None,\n    ):\n        super().__init__(name, shape, material, parent, children)\n        self.conductor = conductor\n\n    def copy(\n        self,\n        parent: Optional[Component] = None,\n    ) -> Component:\n        \"\"\"\n        Copies this component and its children (recursively)\n        and sets `parent` as this copy's parent.\n        This only creates copies of each Component,\n        the shape and material instances (for a PhysicalComponent for ex.)\n        are shared (i.e. are the same instance).\n        \"\"\"\n        # Initially copy self with None children\n        self_copy = MagneticComponent(\n            name=self.name,\n            parent=parent,\n            children=None,\n            shape=self.shape,\n            material=self.material,\n            conductor=self.conductor,\n        )\n        self_copy._plot_options = self._plot_options\n        self_copy._display_cad_options = self._display_cad_options\n\n        # Attaches children to parent\n        self.copy_children(parent=self_copy)\n\n        return self_copy\n\n    @property\n    def conductor(self):\n        \"\"\"\n        The conductor used by current-carrying filaments.\n        \"\"\"\n        return self._conductor\n\n    @conductor.setter\n    def conductor(self, value):\n        self._conductor = value",
  "def get_properties_from_components(\n    comps: Union[Component, Iterable[Component]], properties: Union[str, Iterable[str]]\n) -> Union[Tuple[List[Any]], List[Any], Any]:\n    \"\"\"\n    Get properties from Components\n\n    Parameters\n    ----------\n    comps:\n        A component or list of components\n    properties:\n        properties to collect\n\n    Returns\n    -------\n    If multiple properties specified returns a tuple of the list of properties,\n    otherwise returns a list of the property.\n    If only one node has the property returns the value(s).\n    \"\"\"\n    if isinstance(properties, str):\n        properties = [properties]\n\n    property_lists = tuple([] for _ in properties)\n\n    if not isinstance(comps, Iterable):\n        comps = [comps]\n\n    for comp in comps:\n        props = comp.get_component_properties(properties, first=False)\n        if not isinstance(props, tuple):\n            props = tuple(props)\n        for i, prop in enumerate(props):\n            property_lists[i].extend(prop)\n\n    if len(property_lists[0]) == 1:\n        property_lists = [p[0] for p in property_lists]\n\n    if len(property_lists) == 1:\n        property_lists = property_lists[0]\n\n    return property_lists",
  "def __init__(\n        self,\n        name: str,\n        parent: Optional[Component] = None,\n        children: Optional[List[Component]] = None,\n    ):\n        super().__init__()\n        self.name = name\n\n        if parent is not None and name in (ch.name for ch in parent.children):\n            raise ComponentError(f\"Component {name} is already a child of {parent}\")\n\n        if children is not None:\n            ch_names = [ch.name for ch in children]\n            if len(ch_names) != len(set(ch_names)):\n                raise ComponentError(\n                    f\"Children have duplicate names for Component {name}\",\n                )\n\n        self.parent = parent\n\n        if children:\n            self.children = children",
  "def __repr__(self) -> str:\n        \"\"\"\n        The string representation of the instance\n        \"\"\"\n        return self.name + \" (\" + self.__class__.__name__ + \")\"",
  "def filter_components(\n        self,\n        names: Iterable[str],\n        component_filter: Optional[Callable[[Component], bool]] = None,\n    ):\n        \"\"\"\n        Removes all components from the tree, starting at this component,\n        that are siblings of each component specified in `names`\n        and that aren't in `names` themselves.\n\n        Parameters\n        ----------\n        names:\n            The list of names of each component to search for.\n        component_filter:\n            A callable to filter Components from the Component tree,\n            returning True keeps the node False removes it\n\n        Notes\n        -----\n            This function mutates components in the subtree\n        \"\"\"\n        for n in names:\n            descendent_comps = self.get_component(\n                n,\n                first=False,\n            )\n\n            if descendent_comps is None:\n                continue\n            if not isinstance(descendent_comps, Iterable):\n                descendent_comps = [descendent_comps]\n\n            # Filter out all siblings that are not in names\n            for c in descendent_comps:\n                for c_sib in c.siblings:\n                    if c_sib.name not in names:\n                        c_sib.parent = None\n\n                for c_child in c.descendants:\n                    if component_filter is not None and not component_filter(c_child):\n                        c_child.parent = None",
  "def tree(self) -> str:\n        \"\"\"\n        Get the tree of descendants of this instance.\n        \"\"\"\n        return str(RenderTree(self))",
  "def copy(\n        self,\n        parent: Optional[Component] = None,\n    ) -> Component:\n        \"\"\"\n        Copies this component and its children (recursively)\n        and sets `parent` as this copy's parent.\n        This only creates copies of each Component,\n        the shape and material instances (for a PhysicalComponent for ex.)\n        are shared (i.e. are the same instance).\n\n        Parameters\n        ----------\n        parent:\n            The component to set as the copy's parent\n\n        Returns\n        -------\n        The copied component\n\n        Notes\n        -----\n            This function should be overridden by implementors\n        \"\"\"\n        # Initially copy self with None children\n        self_copy = Component(\n            name=self.name,\n            parent=parent,\n            children=None,\n        )\n        self_copy._plot_options = self._plot_options\n        self_copy._display_cad_options = self._display_cad_options\n        # Attaches children to parent\n        self.copy_children(parent=self_copy)\n\n        return self_copy",
  "def copy_children(\n        self,\n        parent: Component,\n    ) -> list[Component]:\n        \"\"\"\n        Copies this component's children (recursively)\n        and sets `parent` as the copied children's parent.\n\n        Parameters\n        ----------\n        parent:\n            The component to set as the copied children's parent\n\n        Returns\n        -------\n        The copied children components\n\n        Notes\n        -----\n            This function should *not* be overridden by implementors\n        \"\"\"\n        return [] if len(self.children) == 0 else [c.copy(parent) for c in self.children]",
  "def get_component(\n        self, name: str, first: bool = True, full_tree: bool = False\n    ) -> Union[Component, Tuple[Component], None]:\n        \"\"\"\n        Find the components with the specified name.\n\n        Parameters\n        ----------\n        name:\n            The name of the component to search for.\n        first:\n            If True, only the first element is returned, by default True.\n        full_tree:\n            If True, searches the tree from the root, else searches from this node, by\n            default False.\n\n        Returns\n        -------\n        The first component of the search if first is True, else all components\n        matching the search.\n\n        Notes\n        -----\n            This function is just a wrapper of the anytree.search.findall\n            function.\n        \"\"\"\n        return self._get_thing(\n            lambda n: anytree.search._filter_by_name(n, \"name\", name), first, full_tree\n        )",
  "def get_component_properties(\n        self,\n        properties: Union[Iterable[str], str],\n        first: bool = True,\n        full_tree: bool = False,\n    ) -> Union[Tuple[List[Any]], List[Any], Any]:\n        \"\"\"\n        Get properties from a component\n\n        Parameters\n        ----------\n        properties:\n            properties to extract from component tree\n        first:\n            If True, only the first element is returned, by default True.\n        full_tree:\n            If True, searches the tree from the root, else searches from this node, by\n            default False.\n\n        Returns\n        -------\n        If multiple properties specified returns a tuple of the list of properties,\n        otherwise returns a list of the property.\n        If only one node has the property returns the value(s).\n\n        Notes\n        -----\n            This function is just a wrapper of the anytree.search.findall or find\n            functions.\n        \"\"\"\n        if isinstance(properties, str):\n            properties = [properties]\n\n        def filter_(node, properties):\n            return all(hasattr(node, prop) for prop in properties)\n\n        found_nodes = self._get_thing(lambda n: filter_(n, properties), first, full_tree)\n\n        if found_nodes is None:\n            return tuple([] for _ in properties)\n\n        if not isinstance(found_nodes, Iterable):\n            if len(properties) == 1:\n                return getattr(found_nodes, properties[0])\n            return [getattr(found_nodes, prop) for prop in properties]\n        else:\n            # Collect values by property instead of by node\n            node_properties = [\n                [getattr(node, prop) for prop in properties] for node in found_nodes\n            ]\n            return tuple(map(list, zip(*node_properties)))",
  "def _get_thing(\n        self, filter_: Union[Callable, None], first: bool, full_tree: bool\n    ) -> Union[Component, Tuple[Component], None]:\n        found_nodes = anytree.search.findall(\n            self.root if full_tree else self, filter_=filter_\n        )\n        if found_nodes in (None, ()):\n            return None\n        if first and isinstance(found_nodes, Iterable):\n            found_nodes = found_nodes[0]\n        return found_nodes",
  "def add_child(self, child: Component) -> Component:\n        \"\"\"\n        Add a single child to this node\n\n        Parameters\n        ----------\n        child:\n            The child to be added\n\n        Returns\n        -------\n        This component.\n        \"\"\"\n        # TODO: Support merge_trees here too.\n        if child in self.children or child.name in (ch.name for ch in self.children):\n            raise ComponentError(f\"Component {child} is already a child of {self}\")\n        self.children = list(self.children) + [child]\n\n        return self",
  "def add_children(\n        self,\n        children: Optional[Union[Component, List[Component]]],\n        merge_trees: bool = False,\n    ) -> Optional[Component]:\n        \"\"\"\n        Add multiple children to this node\n\n        Parameters\n        ----------\n        children:\n            The children to be added\n\n        Returns\n        -------\n        This component.\n        \"\"\"\n        if children is None:\n            return\n        if isinstance(children, Component):\n            return self.add_child(children)\n        if not isinstance(children, list):\n            return\n        if len(children) == 0:\n            return\n\n        duplicates = []\n        for idx, child in reversed(list(enumerate(children))):\n            existing = self.get_component(child.name)\n            if existing is not None:\n                if merge_trees:\n                    existing.children = list(existing.children) + list(child.children)\n                    children.pop(idx)\n                else:\n                    duplicates += [child]\n        if duplicates != []:\n            raise ComponentError(\n                f\"Components {duplicates} are already children of {self}\"\n            )\n        self.children = list(self.children) + children\n\n        return self",
  "def prune_child(self, name: str):\n        \"\"\"\n        Remove the child with the given name, and all its children.\n        \"\"\"\n        found_component = anytree.search.find_by_attr(self, name)\n        if found_component:\n            # Method of deleting a node suggested by library author\n            # https://github.com/c0fec0de/anytree/issues/152\n            found_component.parent = None",
  "def __init__(\n        self,\n        name: str,\n        shape: BluemiraGeo,\n        material: Any = None,\n        parent: Optional[Component] = None,\n        children: Optional[List[Component]] = None,\n    ):\n        super().__init__(name, parent, children)\n        self.shape = shape\n        self.material = material",
  "def copy(\n        self,\n        parent: Optional[Component] = None,\n    ) -> Component:\n        \"\"\"\n        Copies this component and its children (recursively)\n        and sets `parent` as this copy's parent.\n        This only creates copies of each Component,\n        the shape and material instances (for a PhysicalComponent for ex.)\n        are shared (i.e. are the same instance).\n        \"\"\"\n        # Initially copy self with None children\n        self_copy = PhysicalComponent(\n            name=self.name,\n            parent=parent,\n            children=None,\n            shape=self.shape,\n            material=self.material,\n        )\n        self_copy._plot_options = self._plot_options\n        self_copy._display_cad_options = self._display_cad_options\n        # Attaches children to parent\n        self.copy_children(parent=self_copy)\n\n        return self_copy",
  "def shape(self) -> BluemiraGeo:\n        \"\"\"\n        The geometric shape of the Component.\n        \"\"\"\n        return self._shape",
  "def shape(self, value: BluemiraGeo):\n        self._shape = value",
  "def material(self):\n        \"\"\"\n        The material that the Component is built from.\n        \"\"\"\n        return self._material",
  "def material(self, value):\n        self._material = value",
  "def __init__(\n        self,\n        name: str,\n        shape: BluemiraGeo,\n        material: Any = None,\n        conductor: Any = None,\n        parent: Optional[Component] = None,\n        children: Optional[List[Component]] = None,\n    ):\n        super().__init__(name, shape, material, parent, children)\n        self.conductor = conductor",
  "def copy(\n        self,\n        parent: Optional[Component] = None,\n    ) -> Component:\n        \"\"\"\n        Copies this component and its children (recursively)\n        and sets `parent` as this copy's parent.\n        This only creates copies of each Component,\n        the shape and material instances (for a PhysicalComponent for ex.)\n        are shared (i.e. are the same instance).\n        \"\"\"\n        # Initially copy self with None children\n        self_copy = MagneticComponent(\n            name=self.name,\n            parent=parent,\n            children=None,\n            shape=self.shape,\n            material=self.material,\n            conductor=self.conductor,\n        )\n        self_copy._plot_options = self._plot_options\n        self_copy._display_cad_options = self._display_cad_options\n\n        # Attaches children to parent\n        self.copy_children(parent=self_copy)\n\n        return self_copy",
  "def conductor(self):\n        \"\"\"\n        The conductor used by current-carrying filaments.\n        \"\"\"\n        return self._conductor",
  "def conductor(self, value):\n        self._conductor = value",
  "def filter_(node, properties):\n            return all(hasattr(node, prop) for prop in properties)",
  "def _timing(\n    func: Callable[..., _T],\n    timing_prefix: str,\n    info_str: str = \"\",\n    debug_info_str: bool = False,\n) -> Callable[..., _T]:\n    \"\"\"\n    Time a function and push to logging\n\n    Parameters\n    ----------\n    func:\n        Function to time\n    timing_prefix:\n        Prefix to print before time duration\n    info_str:\n        information to print before running function\n    debug_info_str:\n        send info_str to debug logger instead of info logger\n    \"\"\"\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        \"\"\"Time a function wrapper\"\"\"\n        if debug_info_str:\n            bluemira_debug(info_str)\n        else:\n            bluemira_print(info_str)\n        t1 = time.perf_counter()\n        out = func(*args, **kwargs)\n        t2 = time.perf_counter()\n        bluemira_debug(f\"{timing_prefix} {t2 - t1:.5g} s\")\n        return out\n\n    return wrapper",
  "def create_compound_from_component(comp: Component) -> BluemiraCompound:\n    \"\"\"\n    Creates a BluemiraCompound from the children's shapes of a component.\n    \"\"\"\n    boundary = []\n    if comp.is_leaf and hasattr(comp, \"shape\") and comp.shape:\n        boundary.append(comp.shape)\n    else:\n        for c in comp.leaves:\n            if hasattr(c, \"shape\") and c.shape:\n                boundary.append(c.shape)\n    return BluemiraCompound(label=comp.name, boundary=boundary)",
  "def serialize_component(comp: Component) -> Dict:\n    \"\"\"\n    Serialize a Component object.\n    \"\"\"\n    type_ = type(comp)\n\n    output = []\n    if isinstance(comp, Component):\n        cdict = {\"label\": comp.name, \"children\": output}\n        for child in comp.children:\n            output.append(serialize_component(child))\n        if isinstance(comp, PhysicalComponent):\n            cdict[\"shape\"] = serialize_shape(comp.shape)\n        return {str(type(comp).__name__): cdict}\n    else:\n        raise NotImplementedError(f\"Serialization non implemented for {type_}\")",
  "def wrapper(*args, **kwargs):\n        \"\"\"Time a function wrapper\"\"\"\n        if debug_info_str:\n            bluemira_debug(info_str)\n        else:\n            bluemira_print(info_str)\n        t1 = time.perf_counter()\n        out = func(*args, **kwargs)\n        t2 = time.perf_counter()\n        bluemira_debug(f\"{timing_prefix} {t2 - t1:.5g} s\")\n        return out",
  "class ParameterFrame:\n    \"\"\"\n    A data class to hold a collection of `Parameter` objects.\n\n    The class should be declared using the following form:\n\n    .. code-block:: python\n\n        @dataclass\n        class AnotherFrame(ParameterFrame):\n            param_1: Parameter[float]\n            param_2: Parameter[int]\n\n    \"\"\"\n\n    def __new__(cls, *args, **kwargs):\n        \"\"\"\n        Prevent instantiation of this class.\n        \"\"\"\n        if cls == ParameterFrame:\n            raise TypeError(\n                \"Cannot instantiate a ParameterFrame directly. It must be subclassed.\"\n            )\n\n        if cls != EmptyFrame and not cls.__dataclass_fields__:\n            bluemira_warn(f\"{cls} is empty, @dataclass is possibly missing\")\n\n        return super().__new__(cls)\n\n    def __post_init__(self):\n        \"\"\"Get types from frame\"\"\"\n        self._types = self._get_types()\n\n        for field, field_name, value_type in zip(\n            self, self.__dataclass_fields__, self._types.values()\n        ):\n            if not isinstance(field, Parameter):\n                raise TypeError(\n                    f\"ParameterFrame contains non-Parameter object '{field_name}: {type(field)}'\"\n                )\n            if field_name != field.name:\n                raise TypeError(\n                    f\"ParameterFrame contains Parameter with incorrect name '{field.name}', defined as '{field_name}'\"\n                )\n            vt = _validate_parameter_field(field, value_type)\n\n            val_unit = {\n                \"value\": Parameter._type_check(field.name, field.value, vt),\n                \"unit\": field.unit,\n            }\n            _validate_units(val_unit, vt)\n            if field.unit != val_unit[\"unit\"]:\n                field.set_value(val_unit[\"value\"], \"unit enforcement\")\n                field._unit = pint.Unit(val_unit[\"unit\"])\n            else:\n                # ensure int-> float conversion\n                field._value = val_unit[\"value\"]\n\n    @classmethod\n    def _get_types(cls) -> Dict[str, GenericAlias]:\n        \"\"\"Gets types for the frame even with annotations imported\"\"\"\n        frame_type_hints = get_type_hints(cls)\n        return {f.name: frame_type_hints[f.name] for f in fields(cls)}\n\n    def __iter__(self) -> Generator[Parameter, None, None]:\n        \"\"\"\n        Iterate over this frame's parameters.\n\n        The order is based on the order in which the parameters were\n        declared.\n        \"\"\"\n        for field in fields(self):\n            yield getattr(self, field.name)\n\n    def update(\n        self,\n        new_values: Union[Dict[str, ParameterValueType], ParamDictT, ParameterFrame],\n    ):\n        \"\"\"Update the given frame\"\"\"\n        if isinstance(new_values, ParameterFrame):\n            self.update_from_frame(new_values)\n        else:\n            try:\n                self.update_from_dict(new_values)\n            except TypeError:\n                self.update_values(new_values)\n\n    def get_values(self, *names: str) -> Tuple[ParameterValueType, ...]:\n        \"\"\"Get values of a set of Parameters\"\"\"\n        try:\n            return tuple(getattr(self, n).value for n in names)\n        except AttributeError:\n            raise AttributeError(\n                f\"Parameters {[n for n in names if not hasattr(self, n)]} not in ParameterFrame\"\n            )\n\n    def update_values(self, new_values: Dict[str, ParameterValueType], source: str = \"\"):\n        \"\"\"Update the given parameter values.\"\"\"\n        for key, value in new_values.items():\n            param: Parameter = getattr(self, key)\n            param.set_value(value, source)\n\n    def update_from_dict(self, new_values: ParamDictT):\n        \"\"\"Update from a dictionary representation of a ``ParameterFrame``\"\"\"\n        for key, value in new_values.items():\n            if \"name\" in value:\n                del value[\"name\"]\n            self._set_param(\n                key,\n                Parameter(\n                    name=key,\n                    **value,\n                    _value_types=_validate_parameter_field(key, self._types[key]),\n                ),\n            )\n\n    def update_from_frame(self, frame: ParameterFrame):\n        \"\"\"Update the frame with the values of another frame\"\"\"\n        for o_param in frame:\n            if hasattr(self, o_param.name):\n                self._set_param(o_param.name, o_param)\n\n    def _set_param(self, name: str, o_param: Parameter):\n        \"\"\"\n        Sets the information from a Parameter to an existing Parameter in this frame.\n        \"\"\"\n        param = getattr(self, name)\n        param.set_value(\n            o_param.value\n            if param.unit == \"\" or o_param.value is None\n            else o_param.value_as(param.unit),\n            o_param.source,\n        )\n        if o_param.long_name != \"\":\n            param._long_name = o_param.long_name\n        if o_param.description != \"\":\n            param._description = o_param.description\n\n    @classmethod\n    def from_dict(\n        cls: Type[_PfT],\n        data: Dict[str, ParamDictT],\n        allow_unknown=False,\n    ) -> _PfT:\n        \"\"\"Initialize an instance from a dictionary.\"\"\"\n        data = copy.deepcopy(data)\n        kwargs: Dict[str, Parameter] = {}\n        for member in cls.__dataclass_fields__:\n            try:\n                param_data = data.pop(member)\n            except KeyError as e:\n                raise ValueError(f\"Data for parameter '{member}' not found.\") from e\n\n            kwargs[member] = cls._member_data_to_parameter(\n                member,\n                param_data,\n            )\n\n        if not allow_unknown and len(data) > 0:\n            raise ValueError(f\"Unknown parameter(s) {str(list(data))[1:-1]} in dict.\")\n        return cls(**kwargs)\n\n    @classmethod\n    def from_frame(cls: Type[_PfT], frame: ParameterFrame) -> _PfT:\n        \"\"\"Initialise an instance from another ParameterFrame.\"\"\"\n        kwargs = {}\n        for field in cls.__dataclass_fields__:\n            try:\n                kwargs[field] = getattr(frame, field)\n            except AttributeError:\n                raise ValueError(\n                    \"Cannot create ParameterFrame from other. \"\n                    f\"Other frame does not contain field '{field}'.\"\n                )\n        return cls(**kwargs)\n\n    @classmethod\n    def from_json(cls: Type[_PfT], json_in: Union[str, json.SupportsRead]) -> _PfT:\n        \"\"\"Initialise an instance from a JSON file, string, or reader.\"\"\"\n        if hasattr(json_in, \"read\"):\n            # load from file stream\n            return cls.from_dict(json.load(json_in))\n        elif not isinstance(json_in, str):\n            raise ValueError(f\"Cannot read JSON from type '{type(json_in).__name__}'.\")\n        elif not json_in.startswith(\"{\"):\n            # load from file\n            with open(json_in, \"r\") as f:\n                return cls.from_dict(json.load(f))\n        # load from a JSON string\n        return cls.from_dict(json.loads(json_in))\n\n    @classmethod\n    def from_config_params(cls: Type[_PfT], config_params: ConfigParams) -> _PfT:\n        \"\"\"\n        Initialise an instance from a\n        :class:`~bluemira.base.reactor_config.ConfigParams` object.\n\n        A ConfigParams objects holds a ParameterFrame of global_params\n        and a dict of local_params. This function merges the two together\n        to form a unified ParameterFrame.\n\n        Parameters in global_params will overwrite those in\n        local_params, when defined in both.\n        All references to Parameters in global_params are maintained\n        (i.e. there's no copying).\n        \"\"\"\n        kwargs = {}\n\n        lp = config_params.local_params\n        for member in cls.__dataclass_fields__:\n            if member not in lp:\n                continue\n            kwargs[member] = cls._member_data_to_parameter(\n                member,\n                lp[member],\n            )\n\n        gp = config_params.global_params\n        for member in cls.__dataclass_fields__:\n            if member not in gp.__dataclass_fields__:\n                continue\n            kwargs[member] = getattr(gp, member)\n\n        # now validate all dataclass_fields are in kwargs\n        # (which could be super set)\n        for member in cls.__dataclass_fields__:\n            try:\n                kwargs[member]\n            except KeyError as e:\n                raise ValueError(f\"Data for parameter '{member}' not found.\") from e\n\n        return cls(**kwargs)\n\n    @classmethod\n    def _member_data_to_parameter(\n        cls,\n        member: str,\n        member_param_data: Dict,\n    ) -> Parameter:\n        value_type = _validate_parameter_field(member, cls._get_types()[member])\n        try:\n            _validate_units(member_param_data, value_type)\n        except pint.errors.PintError as pe:\n            raise ValueError(\"Unit conversion failed\") from pe\n        return Parameter(\n            name=member,\n            **member_param_data,\n            _value_types=value_type,\n        )\n\n    def to_dict(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Serialize this ParameterFrame to a dictionary.\"\"\"\n        out = {}\n        for param_name in self.__dataclass_fields__:\n            param_data = getattr(self, param_name).to_dict()\n            # We already have the name of the param, and use it as a\n            # key. No need to repeat the name in the data, so pop it.\n            param_data.pop(\"name\")\n            out[param_name] = param_data\n        return out\n\n    def tabulate(\n        self,\n        keys: Optional[List] = None,\n        tablefmt: str = \"fancy_grid\",\n        floatfmt: str = \".5g\",\n    ) -> str:\n        \"\"\"\n        Tabulate the ParameterFrame\n\n        Parameters\n        ----------\n        keys\n            table column keys\n        tablefmt\n            The format of the table (default=\"fancy_grid\") - see\n            https://github.com/astanin/python-tabulate#table-format\n        floatfmt\n            Format floats to this precision\n\n        Returns\n        -------\n        The tabulated data\n        \"\"\"\n        column_widths = dict(\n            zip(list(ParamDictT.__annotations__.keys()), [20, None, 20, 20, 20, 20])\n        )\n        columns = list(ParamDictT.__annotations__.keys()) if keys is None else keys\n        rec_col = copy.deepcopy(columns)\n        rec_col.pop(columns.index(\"name\"))\n        records = sorted(\n            [\n                [key, *[param.get(col, \"N/A\") for col in rec_col]]\n                for key, param in self.to_dict().items()\n            ]\n        )\n        # tabulate's floatfmt only works if the whole column is a float\n        for r in records:\n            if isinstance(r[1], float):\n                r[1] = f\"{r[1]: {floatfmt}}\"\n\n        return tabulate(\n            records,\n            headers=columns,\n            tablefmt=tablefmt,\n            showindex=False,\n            numalign=\"right\",\n            maxcolwidths=list(itemgetter(*columns)(column_widths)),\n        )\n\n    def __str__(self) -> str:\n        \"\"\"\n        Pretty print ParameterFrame\n        \"\"\"\n        return self.tabulate()",
  "def _validate_parameter_field(field, member_type: Type) -> Tuple[Type, ...]:\n    if (member_type is not Parameter) and (\n        not hasattr(member_type, \"__origin__\") or member_type.__origin__ is not Parameter\n    ):\n        raise TypeError(f\"Field '{field}' does not have type Parameter.\")\n    return get_args(member_type)",
  "def _validate_units(param_data: Dict, value_type: Iterable[Type]):\n    try:\n        quantity = pint.Quantity(param_data[\"value\"], param_data[\"unit\"])\n    except KeyError as ke:\n        raise ValueError(\"Parameters need a value and a unit\") from ke\n    except TypeError as te:\n        if param_data[\"value\"] is None:\n            # dummy for None values\n            quantity = pint.Quantity(\n                1 if param_data[\"unit\"] in (None, \"\") else param_data[\"unit\"]\n            )\n        elif isinstance(param_data[\"value\"], (bool, str)):\n            param_data[\"unit\"] = \"dimensionless\"\n            return\n        else:\n            raise te\n\n    if dimensionality := quantity.units.dimensionality:\n        unit = _fix_combined_units(_remake_units(dimensionality))\n    else:\n        unit = quantity.units\n\n    unit = _fix_weird_units(unit, quantity.units)\n\n    if unit != quantity.units and param_data[\"value\"] is not None:\n        val = raw_uc(quantity.magnitude, quantity.units, unit)\n        if isinstance(param_data[\"value\"], int) and int in value_type:\n            val = int(val)\n        param_data[\"value\"] = val\n\n    param_data[\"unit\"] = f\"{unit:~P}\"",
  "def _remake_units(dimensionality: Union[Dict, pint.util.UnitsContainer]) -> pint.Unit:\n    \"\"\"Reconstruct unit from its dimensionality\"\"\"\n    dim_list = list(map(base_unit_defaults.get, dimensionality.keys()))\n    dim_pow = list(dimensionality.values())\n    return pint.Unit(\".\".join([f\"{j[0]}^{j[1]}\" for j in zip(dim_list, dim_pow)]))",
  "def _fix_combined_units(unit: pint.Unit) -> pint.Unit:\n    \"\"\"Converts base unit to a composite unit if they exist in the defaults\"\"\"\n    dim_keys = list(combined_unit_dimensions.keys())\n    dim_val = list(combined_unit_dimensions.values())\n    with suppress(ValueError):\n        return pint.Unit(\n            combined_unit_defaults[dim_keys[dim_val.index(unit.dimensionality)]]\n        )\n    return pint.Unit(unit)",
  "def _convert_angle_units(\n    modified_unit: pint.Unit, orig_unit_str: str, angle_unit: str\n) -> pint.Unit:\n    \"\"\"\n    Converts angle units to the base unit default for angles.\n\n    Angles are dimensionless therefore dimensionality conversion\n    from pint doesn't work. Conversions between angle units is also not\n    very robust.\n\n    Parameters\n    ----------\n    modified_unit\n        reconstructed unit without the angle\n    orig_unit_str\n        the user supplied unit (without spaces)\n    angle_unit\n        the angle unit in `orig_unit`\n\n    Returns\n    -------\n        the new unit\n\n    \"\"\"\n    breaking_units = [\"steradian\", \"square_degree\"]\n    new_angle_unit = base_unit_defaults[\"[angle]\"]\n    for b in breaking_units:\n        if b in orig_unit_str:\n            raise NotImplementedError(f\"{breaking_units} not supported for conversion\")\n    if f\"{angle_unit}**\" in orig_unit_str:\n        raise NotImplementedError(\"Exponent angles >1, <-1 are not supported\")\n    unit_list = orig_unit_str.split(\"/\", 1)\n    exp = \".\" if angle_unit in unit_list[0] else \"/\"\n    modified_unit = \"\".join(str(modified_unit).split(angle_unit))\n    return pint.Unit(f\"{modified_unit}{exp}{new_angle_unit}\")",
  "def _fix_weird_units(modified_unit: pint.Unit, orig_unit: pint.Unit) -> pint.Unit:\n    \"\"\"\n    Essentially a crude unit parser for when we have no dimensions\n    or non-commutative dimensions.\n\n    Full power years (dimension [time]) and displacements per atom (dimensionless)\n    need to be readded to units as they will be removed by the dimensionality conversion.\n\n    Angle units are dimensionless and conversions between them are not robust\n\n    \"\"\"\n    unit_str = f\"{orig_unit:C}\"\n\n    ang_unit = [ang for ang in ANGLE_UNITS if ang in unit_str]\n    if len(ang_unit) > 1:\n        raise ValueError(f\"More than one angle unit not supported...\ud83e\udd2f {orig_unit}\")\n    elif len(ang_unit) == 1:\n        ang_unit = ang_unit[0]\n    else:\n        ang_unit = None\n\n    fpy = \"full_power_year\" in unit_str\n    dpa = \"displacements_per_atom\" in unit_str\n\n    if not (fpy or dpa) and ang_unit is None:\n        return pint.Unit(modified_unit)\n\n    new_unit = _non_comutative_unit_conversion(\n        dict(modified_unit.dimensionality), unit_str.split(\"/\")[0], dpa, fpy\n    )\n\n    # Deal with angles\n    return _convert_angle_units(new_unit, unit_str, ang_unit) if ang_unit else new_unit",
  "def _non_comutative_unit_conversion(dimensionality, numerator, dpa, fpy):\n    \"\"\"\n    Full power years (dimension [time]) and displacements per atom (dimensionless)\n    need to be readded to units as they will be removed by the dimensionality conversion.\n\n    Full power years even though time based is not the same as straight 'time' and\n    is therefore dealt with after other standard unit conversions.\n\n    Only first order of both of these units is dealt with.\n    \"\"\"\n    dpa_str = (\n        (\"dpa.\" if \"displacements_per_atom\" in numerator else \"dpa^-1.\") if dpa else \"\"\n    )\n    if fpy:\n        if \"full_power_year\" in numerator:\n            dimensionality[\"[time]\"] += -1\n            fpy_str = \"fpy.\"\n        else:\n            dimensionality[\"[time]\"] += 1\n            fpy_str = \"fpy^-1.\"\n\n        if dimensionality[\"[time]\"] == 0:\n            del dimensionality[\"[time]\"]\n    else:\n        fpy_str = \"\"\n\n    return pint.Unit(\n        f\"{dpa_str}{fpy_str}{_fix_combined_units(_remake_units(dimensionality))}\"\n    )",
  "class EmptyFrame(ParameterFrame):\n    \"\"\"\n    Class to represent an empty `ParameterFrame` (one with no Parameters).\n\n    Can be used when initializing a\n    :class:`~bluemira.base.reactor_config.ConfigParams` object with no global params.\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()",
  "def make_parameter_frame(\n    params: Union[Dict[str, ParamDictT], ParameterFrame, ConfigParams, str, None],\n    param_cls: Type[_PfT],\n) -> Union[_PfT, None]:\n    \"\"\"\n    Factory function to generate a `ParameterFrame` of a specific type.\n\n    Parameters\n    ----------\n    params: Union[Dict[str, ParamDictT], ParameterFrame, ConfigParams str, None]\n        The parameters to initialise the class with.\n        This parameter can be several types:\n\n            * Dict[str, ParamDictT]:\n                A dict where the keys are parameter names, and the\n                values are the data associated with the corresponding\n                name.\n            * ParameterFrame:\n                A reference to the parameters on this frame will be\n                assigned to the new ParameterFrame's parameters. Note\n                that this makes no copies, so updates to parameters in\n                the new frame will propagate to the old, and vice versa.\n            * :class:`~bluemira.base.reactor_config.ConfigParams`:\n                An object that holds a `global_params` ParameterFrame\n                and a `local_params` dict, which are merged to create\n                a new ParameterFrame. Values defined in `local_params`\n                will be overwritten by those in `global_params` when\n                defined in both.\n            * str:\n                The path to a JSON file, or, if the string starts with\n                '{', a JSON string.\n            * None:\n                For the case where no parameters are actually required.\n                This is intended for internal use, to aid in validation\n                of parameters in `Builder`\\\\s and `Designer`\\\\s.\n\n    param_cls: Type[ParameterFrame]\n        The `ParameterFrame` class to create a new instance of.\n\n    Returns\n    -------\n        A frame of the type `param_cls`, or `None` if `params` and\n        `param_cls` are both `None`.\n    \"\"\"\n    from bluemira.base.reactor_config import ConfigParams\n\n    if param_cls is None:\n        if params is None:\n            # Case for where there are no parameters associated with the object\n            return params\n        raise ValueError(\"Cannot process parameters, 'param_cls' is None.\")\n    elif isinstance(params, dict):\n        return param_cls.from_dict(params)\n    elif isinstance(params, param_cls):\n        return params\n    elif isinstance(params, str):\n        return param_cls.from_json(params)\n    elif isinstance(params, ParameterFrame):\n        return param_cls.from_frame(params)\n    elif isinstance(params, ConfigParams):\n        return param_cls.from_config_params(params)\n    raise TypeError(f\"Cannot interpret type '{type(params)}' as {param_cls.__name__}.\")",
  "def __new__(cls, *args, **kwargs):\n        \"\"\"\n        Prevent instantiation of this class.\n        \"\"\"\n        if cls == ParameterFrame:\n            raise TypeError(\n                \"Cannot instantiate a ParameterFrame directly. It must be subclassed.\"\n            )\n\n        if cls != EmptyFrame and not cls.__dataclass_fields__:\n            bluemira_warn(f\"{cls} is empty, @dataclass is possibly missing\")\n\n        return super().__new__(cls)",
  "def __post_init__(self):\n        \"\"\"Get types from frame\"\"\"\n        self._types = self._get_types()\n\n        for field, field_name, value_type in zip(\n            self, self.__dataclass_fields__, self._types.values()\n        ):\n            if not isinstance(field, Parameter):\n                raise TypeError(\n                    f\"ParameterFrame contains non-Parameter object '{field_name}: {type(field)}'\"\n                )\n            if field_name != field.name:\n                raise TypeError(\n                    f\"ParameterFrame contains Parameter with incorrect name '{field.name}', defined as '{field_name}'\"\n                )\n            vt = _validate_parameter_field(field, value_type)\n\n            val_unit = {\n                \"value\": Parameter._type_check(field.name, field.value, vt),\n                \"unit\": field.unit,\n            }\n            _validate_units(val_unit, vt)\n            if field.unit != val_unit[\"unit\"]:\n                field.set_value(val_unit[\"value\"], \"unit enforcement\")\n                field._unit = pint.Unit(val_unit[\"unit\"])\n            else:\n                # ensure int-> float conversion\n                field._value = val_unit[\"value\"]",
  "def _get_types(cls) -> Dict[str, GenericAlias]:\n        \"\"\"Gets types for the frame even with annotations imported\"\"\"\n        frame_type_hints = get_type_hints(cls)\n        return {f.name: frame_type_hints[f.name] for f in fields(cls)}",
  "def __iter__(self) -> Generator[Parameter, None, None]:\n        \"\"\"\n        Iterate over this frame's parameters.\n\n        The order is based on the order in which the parameters were\n        declared.\n        \"\"\"\n        for field in fields(self):\n            yield getattr(self, field.name)",
  "def update(\n        self,\n        new_values: Union[Dict[str, ParameterValueType], ParamDictT, ParameterFrame],\n    ):\n        \"\"\"Update the given frame\"\"\"\n        if isinstance(new_values, ParameterFrame):\n            self.update_from_frame(new_values)\n        else:\n            try:\n                self.update_from_dict(new_values)\n            except TypeError:\n                self.update_values(new_values)",
  "def get_values(self, *names: str) -> Tuple[ParameterValueType, ...]:\n        \"\"\"Get values of a set of Parameters\"\"\"\n        try:\n            return tuple(getattr(self, n).value for n in names)\n        except AttributeError:\n            raise AttributeError(\n                f\"Parameters {[n for n in names if not hasattr(self, n)]} not in ParameterFrame\"\n            )",
  "def update_values(self, new_values: Dict[str, ParameterValueType], source: str = \"\"):\n        \"\"\"Update the given parameter values.\"\"\"\n        for key, value in new_values.items():\n            param: Parameter = getattr(self, key)\n            param.set_value(value, source)",
  "def update_from_dict(self, new_values: ParamDictT):\n        \"\"\"Update from a dictionary representation of a ``ParameterFrame``\"\"\"\n        for key, value in new_values.items():\n            if \"name\" in value:\n                del value[\"name\"]\n            self._set_param(\n                key,\n                Parameter(\n                    name=key,\n                    **value,\n                    _value_types=_validate_parameter_field(key, self._types[key]),\n                ),\n            )",
  "def update_from_frame(self, frame: ParameterFrame):\n        \"\"\"Update the frame with the values of another frame\"\"\"\n        for o_param in frame:\n            if hasattr(self, o_param.name):\n                self._set_param(o_param.name, o_param)",
  "def _set_param(self, name: str, o_param: Parameter):\n        \"\"\"\n        Sets the information from a Parameter to an existing Parameter in this frame.\n        \"\"\"\n        param = getattr(self, name)\n        param.set_value(\n            o_param.value\n            if param.unit == \"\" or o_param.value is None\n            else o_param.value_as(param.unit),\n            o_param.source,\n        )\n        if o_param.long_name != \"\":\n            param._long_name = o_param.long_name\n        if o_param.description != \"\":\n            param._description = o_param.description",
  "def from_dict(\n        cls: Type[_PfT],\n        data: Dict[str, ParamDictT],\n        allow_unknown=False,\n    ) -> _PfT:\n        \"\"\"Initialize an instance from a dictionary.\"\"\"\n        data = copy.deepcopy(data)\n        kwargs: Dict[str, Parameter] = {}\n        for member in cls.__dataclass_fields__:\n            try:\n                param_data = data.pop(member)\n            except KeyError as e:\n                raise ValueError(f\"Data for parameter '{member}' not found.\") from e\n\n            kwargs[member] = cls._member_data_to_parameter(\n                member,\n                param_data,\n            )\n\n        if not allow_unknown and len(data) > 0:\n            raise ValueError(f\"Unknown parameter(s) {str(list(data))[1:-1]} in dict.\")\n        return cls(**kwargs)",
  "def from_frame(cls: Type[_PfT], frame: ParameterFrame) -> _PfT:\n        \"\"\"Initialise an instance from another ParameterFrame.\"\"\"\n        kwargs = {}\n        for field in cls.__dataclass_fields__:\n            try:\n                kwargs[field] = getattr(frame, field)\n            except AttributeError:\n                raise ValueError(\n                    \"Cannot create ParameterFrame from other. \"\n                    f\"Other frame does not contain field '{field}'.\"\n                )\n        return cls(**kwargs)",
  "def from_json(cls: Type[_PfT], json_in: Union[str, json.SupportsRead]) -> _PfT:\n        \"\"\"Initialise an instance from a JSON file, string, or reader.\"\"\"\n        if hasattr(json_in, \"read\"):\n            # load from file stream\n            return cls.from_dict(json.load(json_in))\n        elif not isinstance(json_in, str):\n            raise ValueError(f\"Cannot read JSON from type '{type(json_in).__name__}'.\")\n        elif not json_in.startswith(\"{\"):\n            # load from file\n            with open(json_in, \"r\") as f:\n                return cls.from_dict(json.load(f))\n        # load from a JSON string\n        return cls.from_dict(json.loads(json_in))",
  "def from_config_params(cls: Type[_PfT], config_params: ConfigParams) -> _PfT:\n        \"\"\"\n        Initialise an instance from a\n        :class:`~bluemira.base.reactor_config.ConfigParams` object.\n\n        A ConfigParams objects holds a ParameterFrame of global_params\n        and a dict of local_params. This function merges the two together\n        to form a unified ParameterFrame.\n\n        Parameters in global_params will overwrite those in\n        local_params, when defined in both.\n        All references to Parameters in global_params are maintained\n        (i.e. there's no copying).\n        \"\"\"\n        kwargs = {}\n\n        lp = config_params.local_params\n        for member in cls.__dataclass_fields__:\n            if member not in lp:\n                continue\n            kwargs[member] = cls._member_data_to_parameter(\n                member,\n                lp[member],\n            )\n\n        gp = config_params.global_params\n        for member in cls.__dataclass_fields__:\n            if member not in gp.__dataclass_fields__:\n                continue\n            kwargs[member] = getattr(gp, member)\n\n        # now validate all dataclass_fields are in kwargs\n        # (which could be super set)\n        for member in cls.__dataclass_fields__:\n            try:\n                kwargs[member]\n            except KeyError as e:\n                raise ValueError(f\"Data for parameter '{member}' not found.\") from e\n\n        return cls(**kwargs)",
  "def _member_data_to_parameter(\n        cls,\n        member: str,\n        member_param_data: Dict,\n    ) -> Parameter:\n        value_type = _validate_parameter_field(member, cls._get_types()[member])\n        try:\n            _validate_units(member_param_data, value_type)\n        except pint.errors.PintError as pe:\n            raise ValueError(\"Unit conversion failed\") from pe\n        return Parameter(\n            name=member,\n            **member_param_data,\n            _value_types=value_type,\n        )",
  "def to_dict(self) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Serialize this ParameterFrame to a dictionary.\"\"\"\n        out = {}\n        for param_name in self.__dataclass_fields__:\n            param_data = getattr(self, param_name).to_dict()\n            # We already have the name of the param, and use it as a\n            # key. No need to repeat the name in the data, so pop it.\n            param_data.pop(\"name\")\n            out[param_name] = param_data\n        return out",
  "def tabulate(\n        self,\n        keys: Optional[List] = None,\n        tablefmt: str = \"fancy_grid\",\n        floatfmt: str = \".5g\",\n    ) -> str:\n        \"\"\"\n        Tabulate the ParameterFrame\n\n        Parameters\n        ----------\n        keys\n            table column keys\n        tablefmt\n            The format of the table (default=\"fancy_grid\") - see\n            https://github.com/astanin/python-tabulate#table-format\n        floatfmt\n            Format floats to this precision\n\n        Returns\n        -------\n        The tabulated data\n        \"\"\"\n        column_widths = dict(\n            zip(list(ParamDictT.__annotations__.keys()), [20, None, 20, 20, 20, 20])\n        )\n        columns = list(ParamDictT.__annotations__.keys()) if keys is None else keys\n        rec_col = copy.deepcopy(columns)\n        rec_col.pop(columns.index(\"name\"))\n        records = sorted(\n            [\n                [key, *[param.get(col, \"N/A\") for col in rec_col]]\n                for key, param in self.to_dict().items()\n            ]\n        )\n        # tabulate's floatfmt only works if the whole column is a float\n        for r in records:\n            if isinstance(r[1], float):\n                r[1] = f\"{r[1]: {floatfmt}}\"\n\n        return tabulate(\n            records,\n            headers=columns,\n            tablefmt=tablefmt,\n            showindex=False,\n            numalign=\"right\",\n            maxcolwidths=list(itemgetter(*columns)(column_widths)),\n        )",
  "def __str__(self) -> str:\n        \"\"\"\n        Pretty print ParameterFrame\n        \"\"\"\n        return self.tabulate()",
  "def __init__(self) -> None:\n        super().__init__()",
  "def type_fail(exc, memo):\n    \"\"\"\n    Raise TypeError on wrong type\n\n    Notes\n    -----\n    typeguard by default raises a TypeCheckError\n    may want to have a custom checker in future\n\n    \"\"\"\n    raise TypeError(f\"{exc._path[0]} {exc.args[0]}\")",
  "class ParamDictT(TypedDict):\n    \"\"\"Typed dictionary for a Parameter.\"\"\"\n\n    name: str\n    value: ParameterValueType\n    unit: str\n    source: str\n    description: str\n    long_name: str",
  "class ParameterValue(Generic[ParameterValueType]):\n    \"\"\"Holds parameter value information.\"\"\"\n\n    value: ParameterValueType\n    source: str",
  "class Parameter(Generic[ParameterValueType]):\n    \"\"\"\n    Represents a parameter with physical units.\n\n    Parameters\n    ----------\n    name\n        The name of the parameter.\n    value\n        The parameter's value.\n    unit\n        The parameter's unit.\n    source\n        The origin of the parameter's value.\n    description\n        A description of the parameter.\n    long_name\n        A longer name for the parameter.\n    \"\"\"\n\n    @typechecked\n    def __init__(\n        self,\n        name: str,\n        value: ParameterValueType,\n        unit: str = \"\",\n        source: str = \"\",\n        description: str = \"\",\n        long_name: str = \"\",\n        _value_types: Optional[Tuple[Type, ...]] = None,\n    ):\n        value = self._type_check(name, value, _value_types)\n        self._name = name\n        self._value = value\n        self._unit = pint.Unit(unit)\n        self._source = source\n        self._description = description\n        self._long_name = long_name\n\n        self._history: List[ParameterValue[ParameterValueType]] = []\n        self._add_history_record()\n\n    @staticmethod\n    def _type_check(\n        name: str, value: ParameterValueType, value_types: Optional[Tuple[Type, ...]]\n    ) -> ParameterValueType:\n        if value_types and value is not None:\n            if float in value_types and isinstance(value, int):\n                value = float(value)\n            elif (\n                int in value_types\n                and isinstance(value, float)\n                and np.isclose(value, int(value), rtol=0)\n            ):\n                value = int(value)\n            elif not isinstance(value, value_types):\n                raise TypeError(\n                    f'{name}: type of \"value\" must be one of {value_types}; '\n                    f\"got {type(value)} (value: {value}) instead\"\n                )\n        return value\n\n    def __repr__(self) -> str:\n        \"\"\"String repr of class instance.\"\"\"\n        return f\"<{type(self).__name__}({self.name}={self.value} {self.unit})>\"\n\n    def __eq__(self, __o: object) -> bool:\n        \"\"\"\n        Check if this parameter is equal to another.\n\n        Parameters are equal if their names and values (with matching\n        units) are equal.\n        \"\"\"\n        if not isinstance(__o, Parameter):\n            return NotImplemented\n        try:\n            o_value_with_correct_unit = raw_uc(__o.value, __o.unit, self.unit)\n        except pint.DimensionalityError:\n            # incompatible units\n            return False\n        return (self.name == __o.name) and (self.value == o_value_with_correct_unit)\n\n    def history(self) -> List[ParameterValue[ParameterValueType]]:\n        \"\"\"Return the history of this parameter's value.\"\"\"\n        return copy.deepcopy(self._history)\n\n    @typechecked\n    def set_value(self, new_value: ParameterValueType, source: str = \"\"):\n        \"\"\"Set the parameter's value and update the source.\"\"\"\n        self._value = new_value\n        self._source = source\n        self._add_history_record()\n\n    def to_dict(self) -> Dict:\n        \"\"\"Serialize the parameter to a dictionary.\"\"\"\n        out = {\n            \"name\": self.name,\n            \"value\": self.value,\n            \"unit\": \"dimensionless\" if self.unit == \"\" else self.unit,\n        }\n        for field in [\"source\", \"description\", \"long_name\"]:\n            if value := getattr(self, field):\n                out[field] = value\n        return out\n\n    @property\n    def name(self) -> str:\n        \"\"\"Return the name of the parameter.\"\"\"\n        return self._name\n\n    @property\n    def value(self) -> ParameterValueType:\n        \"\"\"Return the current value of the parameter.\"\"\"\n        return self._value\n\n    @value.setter\n    def value(self, new_value: ParameterValueType):\n        self.set_value(new_value, source=\"\")\n\n    def value_as(self, unit: Union[str, pint.Unit]) -> Union[ParameterValueType, None]:\n        \"\"\"\n        Return the current value in a given unit\n\n        Notes\n        -----\n        If the current value of the parameter is None the function checks for\n        a valid unit conversion\n        \"\"\"\n        try:\n            return raw_uc(self.value, self.unit, unit)\n        except pint.errors.PintError as pe:\n            raise ValueError(\"Unit conversion failed\") from pe\n        except TypeError:\n            if self.value is None:\n                if units_compatible(self.unit, unit):\n                    return None\n                else:\n                    raise ValueError(\"Unit conversion failed\")\n            else:\n                raise\n\n    @property\n    def unit(self) -> str:\n        \"\"\"Return the physical unit of the parameter.\"\"\"\n        return f\"{self._unit:~P}\"\n\n    @property\n    def source(self) -> str:\n        \"\"\"Return the source that last set the value of this parameter.\"\"\"\n        return self._source\n\n    @property\n    def long_name(self) -> str:\n        \"\"\"Return a long name for this parameter.\"\"\"\n        return self._long_name\n\n    @property\n    def description(self) -> str:\n        \"\"\"Return a description for the parameter.\"\"\"\n        return self._description\n\n    def _add_history_record(self):\n        history_entry = ParameterValue(self.value, self.source)\n        self._history.append(history_entry)",
  "def __init__(\n        self,\n        name: str,\n        value: ParameterValueType,\n        unit: str = \"\",\n        source: str = \"\",\n        description: str = \"\",\n        long_name: str = \"\",\n        _value_types: Optional[Tuple[Type, ...]] = None,\n    ):\n        value = self._type_check(name, value, _value_types)\n        self._name = name\n        self._value = value\n        self._unit = pint.Unit(unit)\n        self._source = source\n        self._description = description\n        self._long_name = long_name\n\n        self._history: List[ParameterValue[ParameterValueType]] = []\n        self._add_history_record()",
  "def _type_check(\n        name: str, value: ParameterValueType, value_types: Optional[Tuple[Type, ...]]\n    ) -> ParameterValueType:\n        if value_types and value is not None:\n            if float in value_types and isinstance(value, int):\n                value = float(value)\n            elif (\n                int in value_types\n                and isinstance(value, float)\n                and np.isclose(value, int(value), rtol=0)\n            ):\n                value = int(value)\n            elif not isinstance(value, value_types):\n                raise TypeError(\n                    f'{name}: type of \"value\" must be one of {value_types}; '\n                    f\"got {type(value)} (value: {value}) instead\"\n                )\n        return value",
  "def __repr__(self) -> str:\n        \"\"\"String repr of class instance.\"\"\"\n        return f\"<{type(self).__name__}({self.name}={self.value} {self.unit})>\"",
  "def __eq__(self, __o: object) -> bool:\n        \"\"\"\n        Check if this parameter is equal to another.\n\n        Parameters are equal if their names and values (with matching\n        units) are equal.\n        \"\"\"\n        if not isinstance(__o, Parameter):\n            return NotImplemented\n        try:\n            o_value_with_correct_unit = raw_uc(__o.value, __o.unit, self.unit)\n        except pint.DimensionalityError:\n            # incompatible units\n            return False\n        return (self.name == __o.name) and (self.value == o_value_with_correct_unit)",
  "def history(self) -> List[ParameterValue[ParameterValueType]]:\n        \"\"\"Return the history of this parameter's value.\"\"\"\n        return copy.deepcopy(self._history)",
  "def set_value(self, new_value: ParameterValueType, source: str = \"\"):\n        \"\"\"Set the parameter's value and update the source.\"\"\"\n        self._value = new_value\n        self._source = source\n        self._add_history_record()",
  "def to_dict(self) -> Dict:\n        \"\"\"Serialize the parameter to a dictionary.\"\"\"\n        out = {\n            \"name\": self.name,\n            \"value\": self.value,\n            \"unit\": \"dimensionless\" if self.unit == \"\" else self.unit,\n        }\n        for field in [\"source\", \"description\", \"long_name\"]:\n            if value := getattr(self, field):\n                out[field] = value\n        return out",
  "def name(self) -> str:\n        \"\"\"Return the name of the parameter.\"\"\"\n        return self._name",
  "def value(self) -> ParameterValueType:\n        \"\"\"Return the current value of the parameter.\"\"\"\n        return self._value",
  "def value(self, new_value: ParameterValueType):\n        self.set_value(new_value, source=\"\")",
  "def value_as(self, unit: Union[str, pint.Unit]) -> Union[ParameterValueType, None]:\n        \"\"\"\n        Return the current value in a given unit\n\n        Notes\n        -----\n        If the current value of the parameter is None the function checks for\n        a valid unit conversion\n        \"\"\"\n        try:\n            return raw_uc(self.value, self.unit, unit)\n        except pint.errors.PintError as pe:\n            raise ValueError(\"Unit conversion failed\") from pe\n        except TypeError:\n            if self.value is None:\n                if units_compatible(self.unit, unit):\n                    return None\n                else:\n                    raise ValueError(\"Unit conversion failed\")\n            else:\n                raise",
  "def unit(self) -> str:\n        \"\"\"Return the physical unit of the parameter.\"\"\"\n        return f\"{self._unit:~P}\"",
  "def source(self) -> str:\n        \"\"\"Return the source that last set the value of this parameter.\"\"\"\n        return self._source",
  "def long_name(self) -> str:\n        \"\"\"Return a long name for this parameter.\"\"\"\n        return self._long_name",
  "def description(self) -> str:\n        \"\"\"Return a description for the parameter.\"\"\"\n        return self._description",
  "def _add_history_record(self):\n        history_entry = ParameterValue(self.value, self.source)\n        self._history.append(history_entry)",
  "class ArbitraryPlanarRectangularXSCircuit(SourceGroup):\n    \"\"\"\n    An arbitrary, planar current loop of constant rectangular cross-section\n    and uniform current density.\n\n    Parameters\n    ----------\n    shape:\n        The geometry from which to form an ArbitraryPlanarRectangularXSCircuit\n    breadth:\n        The breadth of the current source (half-width) [m]\n    depth:\n        The depth of the current source (half-height) [m]\n    current:\n        The current flowing through the source [A]\n\n    Notes\n    -----\n    Works best with planar x-z geometries.\n    \"\"\"\n\n    shape: np.array\n    breadth: float\n    depth: float\n    current: float\n\n    def __init__(\n        self,\n        shape: Union[np.ndarray, Coordinates],\n        breadth: float,\n        depth: float,\n        current: float,\n    ):\n        shape = process_to_coordinates(shape)\n        if not shape.is_planar:\n            raise MagnetostaticsError(\n                f\"The input shape for {self.__class__.__name__} must be planar.\"\n            )\n\n        betas, alphas = self._get_betas_alphas(shape)\n\n        normal = shape.normal_vector\n\n        # Set up geometry, calculating all trapezoidal prism sources\n        self.shape = shape.T\n        self.d_l = np.diff(self.shape, axis=0)\n        self.midpoints = self.shape[:-1, :] + 0.5 * self.d_l\n        sources = []\n\n        for midpoint, d_l, beta, alpha in zip(self.midpoints, self.d_l, betas, alphas):\n            d_l_norm = d_l / np.linalg.norm(d_l)\n            t_vec = np.cross(d_l_norm, normal)\n\n            source = TrapezoidalPrismCurrentSource(\n                midpoint,\n                d_l,\n                normal,\n                t_vec,\n                breadth,\n                depth,\n                alpha,\n                beta,\n                current,\n            )\n            sources.append(source)\n\n        super().__init__(sources)\n\n    def _get_betas_alphas(self, shape):\n        \"\"\"\n        Get the first and second half-angles (transformed to the x-z plane)\n        \"\"\"\n        shape = self._transform_to_xz(deepcopy(shape))\n        self._t_shape = shape\n        closed = shape.closed\n        self._clockwise = shape.check_ccw((0, 1, 0))\n        d_l = np.diff(shape.T, axis=0)\n        midpoints = shape.T[:-1, :] + 0.5 * d_l\n        betas = (\n            [self._get_half_angle(midpoints[-1], shape.points[0], midpoints[0])]\n            if closed\n            else [0.0]\n        )\n        alphas = []\n\n        for i, (midpoint, d_l) in enumerate(zip(midpoints, d_l)):\n            if i != len(midpoints) - 1:\n                alpha = self._get_half_angle(\n                    midpoint, shape.points[i + 1], midpoints[i + 1]\n                )\n            elif closed:\n                alpha = self._get_half_angle(midpoint, shape.points[-1], midpoints[0])\n            else:\n                alpha = 0.0\n            alphas.append(alpha)\n            beta = alpha\n            betas.append(beta)\n\n        return np.rad2deg(betas), np.rad2deg(alphas)\n\n    def _transform_to_xz(self, shape):\n        normal_vector = shape.normal_vector\n        if abs(normal_vector[1]) == 1.0:\n            return shape\n        shape.translate(-np.array(shape.center_of_mass))\n\n        rot_mat = rotation_matrix_v1v2(normal_vector, np.array([0.0, -1.0, 0.0]))\n        return Coordinates(rot_mat @ shape._array)\n\n    def _get_half_angle(self, p0, p1, p2):\n        \"\"\"\n        Get the half angle between three points, respecting winding direction.\n        \"\"\"\n        v1 = p1 - p0\n        v2 = p2 - p1\n        v1 /= np.linalg.norm(v1)\n        v2 /= np.linalg.norm(v2)\n        cos_angle = np.dot(v1, v2)\n        angle = 0.5 * np.arccos(np.clip(cos_angle, -1, 1))\n\n        v_norm = np.linalg.norm(v1 - v2)\n        if np.isclose(v_norm, 0):\n            return 0.0\n\n        v3 = p2 - p0\n        v3 /= np.linalg.norm(v3)\n        project_point = p0 + np.dot(p1 - p0, v3) * v3\n        d = np.linalg.norm(p1 - project_point)\n        if np.isclose(d, 0.0):\n            return 0.0\n\n        point_in_poly = self._point_inside_xz(project_point)\n\n        if not point_in_poly:\n            angle *= -1\n\n        if self._clockwise:\n            angle *= -1\n\n        if abs(angle) > 0.25 * np.pi:\n            # We're actually concerned with (pi/2 - angle) < pi/4\n            # If this is the case, two consecutive sources will have sharp corners that\n            # will overlap\n            bluemira_warn(\n                f\"{self.__class__.__name__} cannot handle acute angles, as there will be overlaps in the sources.\"\n            )\n        return angle\n\n    def _point_inside_xz(self, point):\n        # reverse second axis if clockwise\n        ind = (slice(None), slice(None, None, -1)) if self._clockwise else slice(None)\n        return in_polygon(point[0], point[2], self._t_shape.xz[ind].T)",
  "class HelmholtzCage(SourceGroup):\n    \"\"\"\n    Axisymmetric arrangement of current sources about the z-axis.\n\n    Parameters\n    ----------\n    circuit:\n        Current source to pattern\n    n_TF:\n        Number of sources to pattern\n\n    Notes\n    -----\n    The plane at 0 degrees is set to be between two circuits.\n    \"\"\"\n\n    def __init__(self, circuit: CurrentSource, n_TF: int):\n        self.n_TF = n_TF\n        sources = self._pattern(circuit)\n\n        super().__init__(sources)\n\n    def _pattern(self, circuit: CurrentSource) -> List[CurrentSource]:\n        \"\"\"\n        Pattern the CurrentSource axisymmetrically.\n        \"\"\"\n        sources = []\n        for angle in np.linspace(0, 360, int(self.n_TF), endpoint=False):\n            source = circuit.copy()\n            source.rotate(angle, axis=\"z\")\n            sources.append(source)\n        return sources\n\n    @process_xyz_array\n    def ripple(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> float:\n        \"\"\"\n        Get the toroidal field ripple at a point.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the ripple\n        y:\n            The y coordinate(s) of the points at which to calculate the ripple\n        z:\n            The z coordinate(s) of the points at which to calculate the ripple\n\n        Returns\n        -------\n        The value of the TF ripple at the point(s) [%]\n        \"\"\"\n        point = np.array([x, y, z])\n        ripple_field = np.zeros(2)\n        n = np.array([0, 1, 0])\n        planes = [0, np.pi / self.n_TF]  # rotate (inline, ingap)\n\n        for i, theta in enumerate(planes):\n            r_matrix = rotation_matrix(theta).T\n            sr = np.dot(point, r_matrix)\n            nr = np.dot(n, r_matrix)\n            field = self.field(*sr)\n            ripple_field[i] = np.dot(nr, field)\n\n        return 1e2 * (ripple_field[0] - ripple_field[1]) / np.sum(ripple_field)",
  "def __init__(\n        self,\n        shape: Union[np.ndarray, Coordinates],\n        breadth: float,\n        depth: float,\n        current: float,\n    ):\n        shape = process_to_coordinates(shape)\n        if not shape.is_planar:\n            raise MagnetostaticsError(\n                f\"The input shape for {self.__class__.__name__} must be planar.\"\n            )\n\n        betas, alphas = self._get_betas_alphas(shape)\n\n        normal = shape.normal_vector\n\n        # Set up geometry, calculating all trapezoidal prism sources\n        self.shape = shape.T\n        self.d_l = np.diff(self.shape, axis=0)\n        self.midpoints = self.shape[:-1, :] + 0.5 * self.d_l\n        sources = []\n\n        for midpoint, d_l, beta, alpha in zip(self.midpoints, self.d_l, betas, alphas):\n            d_l_norm = d_l / np.linalg.norm(d_l)\n            t_vec = np.cross(d_l_norm, normal)\n\n            source = TrapezoidalPrismCurrentSource(\n                midpoint,\n                d_l,\n                normal,\n                t_vec,\n                breadth,\n                depth,\n                alpha,\n                beta,\n                current,\n            )\n            sources.append(source)\n\n        super().__init__(sources)",
  "def _get_betas_alphas(self, shape):\n        \"\"\"\n        Get the first and second half-angles (transformed to the x-z plane)\n        \"\"\"\n        shape = self._transform_to_xz(deepcopy(shape))\n        self._t_shape = shape\n        closed = shape.closed\n        self._clockwise = shape.check_ccw((0, 1, 0))\n        d_l = np.diff(shape.T, axis=0)\n        midpoints = shape.T[:-1, :] + 0.5 * d_l\n        betas = (\n            [self._get_half_angle(midpoints[-1], shape.points[0], midpoints[0])]\n            if closed\n            else [0.0]\n        )\n        alphas = []\n\n        for i, (midpoint, d_l) in enumerate(zip(midpoints, d_l)):\n            if i != len(midpoints) - 1:\n                alpha = self._get_half_angle(\n                    midpoint, shape.points[i + 1], midpoints[i + 1]\n                )\n            elif closed:\n                alpha = self._get_half_angle(midpoint, shape.points[-1], midpoints[0])\n            else:\n                alpha = 0.0\n            alphas.append(alpha)\n            beta = alpha\n            betas.append(beta)\n\n        return np.rad2deg(betas), np.rad2deg(alphas)",
  "def _transform_to_xz(self, shape):\n        normal_vector = shape.normal_vector\n        if abs(normal_vector[1]) == 1.0:\n            return shape\n        shape.translate(-np.array(shape.center_of_mass))\n\n        rot_mat = rotation_matrix_v1v2(normal_vector, np.array([0.0, -1.0, 0.0]))\n        return Coordinates(rot_mat @ shape._array)",
  "def _get_half_angle(self, p0, p1, p2):\n        \"\"\"\n        Get the half angle between three points, respecting winding direction.\n        \"\"\"\n        v1 = p1 - p0\n        v2 = p2 - p1\n        v1 /= np.linalg.norm(v1)\n        v2 /= np.linalg.norm(v2)\n        cos_angle = np.dot(v1, v2)\n        angle = 0.5 * np.arccos(np.clip(cos_angle, -1, 1))\n\n        v_norm = np.linalg.norm(v1 - v2)\n        if np.isclose(v_norm, 0):\n            return 0.0\n\n        v3 = p2 - p0\n        v3 /= np.linalg.norm(v3)\n        project_point = p0 + np.dot(p1 - p0, v3) * v3\n        d = np.linalg.norm(p1 - project_point)\n        if np.isclose(d, 0.0):\n            return 0.0\n\n        point_in_poly = self._point_inside_xz(project_point)\n\n        if not point_in_poly:\n            angle *= -1\n\n        if self._clockwise:\n            angle *= -1\n\n        if abs(angle) > 0.25 * np.pi:\n            # We're actually concerned with (pi/2 - angle) < pi/4\n            # If this is the case, two consecutive sources will have sharp corners that\n            # will overlap\n            bluemira_warn(\n                f\"{self.__class__.__name__} cannot handle acute angles, as there will be overlaps in the sources.\"\n            )\n        return angle",
  "def _point_inside_xz(self, point):\n        # reverse second axis if clockwise\n        ind = (slice(None), slice(None, None, -1)) if self._clockwise else slice(None)\n        return in_polygon(point[0], point[2], self._t_shape.xz[ind].T)",
  "def __init__(self, circuit: CurrentSource, n_TF: int):\n        self.n_TF = n_TF\n        sources = self._pattern(circuit)\n\n        super().__init__(sources)",
  "def _pattern(self, circuit: CurrentSource) -> List[CurrentSource]:\n        \"\"\"\n        Pattern the CurrentSource axisymmetrically.\n        \"\"\"\n        sources = []\n        for angle in np.linspace(0, 360, int(self.n_TF), endpoint=False):\n            source = circuit.copy()\n            source.rotate(angle, axis=\"z\")\n            sources.append(source)\n        return sources",
  "def ripple(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> float:\n        \"\"\"\n        Get the toroidal field ripple at a point.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the ripple\n        y:\n            The y coordinate(s) of the points at which to calculate the ripple\n        z:\n            The z coordinate(s) of the points at which to calculate the ripple\n\n        Returns\n        -------\n        The value of the TF ripple at the point(s) [%]\n        \"\"\"\n        point = np.array([x, y, z])\n        ripple_field = np.zeros(2)\n        n = np.array([0, 1, 0])\n        planes = [0, np.pi / self.n_TF]  # rotate (inline, ingap)\n\n        for i, theta in enumerate(planes):\n            r_matrix = rotation_matrix(theta).T\n            sr = np.dot(point, r_matrix)\n            nr = np.dot(n, r_matrix)\n            field = self.field(*sr)\n            ripple_field[i] = np.dot(nr, field)\n\n        return 1e2 * (ripple_field[0] - ripple_field[1]) / np.sum(ripple_field)",
  "def Bz_coil_axis(\n    r: float,\n    z: Optional[float] = 0,\n    pz: Optional[float] = 0,\n    current: Optional[float] = 1,\n) -> float:\n    \"\"\"\n    Calculate the theoretical vertical magnetic field of a filament coil\n    (of radius r and centred in (0, z)) on a point on the coil axis at\n    a distance pz from the axis origin.\n\n    Parameters\n    ----------\n    r:\n        Coil radius [m]\n    z:\n        Vertical position of the coil centroid [m]\n    pz:\n        Vertical position of the point on the axis on which the magnetic field\n        shall be calculated [m]\n    current:\n        Current of the coil [A]\n\n    Returns\n    -------\n    Vertical magnetic field on the axis [T]\n\n    Notes\n    -----\n    \\t:math:`\\\\dfrac{1}{2}\\\\dfrac{\\\\mu_{0}Ir^2}{(r^{2}+(pz-z)^{2})^{3/2}}`\n    \"\"\"\n    return 0.5 * MU_0 * current * r**2 / (r**2 + (pz - z) ** 2) ** 1.5",
  "def _convert_const_to_dolfin(value: float):\n    \"\"\"Convert a constant value to a dolfin function\"\"\"\n    if not isinstance(value, (int, float)):\n        raise ValueError(\"Value must be integer or float.\")\n\n    return dolfin.Constant(value)",
  "class ScalarSubFunc(dolfin.UserExpression):\n    \"\"\"\n    Create a dolfin UserExpression from a set of functions defined in the subdomains\n\n    Parameters\n    ----------\n    func_list:\n        list of functions to be interpolated into the subdomains. Int and float values\n        are considered as constant functions. Any other callable function must return\n        a single value.\n    mark_list:\n        list of markers that identify the subdomain in which the respective functions\n        of func_list must to be applied.\n    subdomains:\n        the whole subdomains mesh function\n    \"\"\"\n\n    def __init__(\n        self,\n        func_list: Union[\n            Iterable[Union[float, Callable[[Any], float]]], float, Callable[[Any], float]\n        ],\n        mark_list: Optional[Iterable[int]] = None,\n        subdomains: Optional[dolfin.cpp.mesh.MeshFunctionSizet] = None,\n        **kwargs,\n    ):\n        super().__init__(**kwargs)\n        self.functions = self.check_functions(func_list)\n        self.markers = mark_list\n        self.subdomains = subdomains\n\n    def check_functions(\n        self,\n        functions: Union[Iterable[Union[float, Callable]], float, Callable],\n    ) -> Iterable[Union[float, Callable]]:\n        \"\"\"Check if the argument is a function or a list of functions\"\"\"\n        if not isinstance(functions, Iterable):\n            functions = [functions]\n        if all(isinstance(f, (float, Callable)) for f in functions):\n            return functions\n        raise ValueError(\n            \"Accepted functions are instance of (int, float, Callable)\"\n            \"or a list of them.\"\n        )\n\n    def eval_cell(self, values: List, x: float, cell):\n        \"\"\"Evaluate the value on each cell\"\"\"\n        if self.markers is None or self.subdomains is None:\n            func = self.functions[0]\n        else:\n            m = self.subdomains[cell.index]\n            func = (\n                self.functions[np.where(np.array(self.markers) == m)[0][0]]\n                if m in self.markers\n                else 0\n            )\n        if callable(func):\n            values[0] = func(x)\n        elif isinstance(func, (int, float)):\n            values[0] = func\n        else:\n            raise ValueError(f\"{func} is not callable or is not a constant\")\n\n    def value_shape(self) -> Tuple:\n        \"\"\"\n        Value_shape function (necessary for a UserExpression)\n        https://fenicsproject.discourse.group/t/problems-interpolating-a-userexpression-and-plotting-it/1303\n        \"\"\"\n        return ()",
  "class FemMagnetostatic2d:\n    \"\"\"\n    A 2D magnetostatic solver. The solver is thought as support for the fem fixed\n    boundary module and it is limited to axisymmetric magnetostatic problem\n    with toroidal current sources. The Maxwell equations, as function of the poloidal\n    magnetic flux (:math:`\\\\Psi`), are then reduced to the form ([Zohm]_, page 25):\n\n    .. math::\n        r^2 \\\\nabla\\\\cdot\\\\left(\\\\frac{\\\\nabla\\\\Psi}{r^2}\\\\right) = 2\n        \\\\pi r \\\\mu_0 J_{\\\\Phi}\n\n    whose weak formulation is defined as ([Villone]_):\n\n    .. math::\n        \\\\int_{D_p} {\\\\frac{1}{r}}{\\\\nabla}{\\\\Psi}{\\\\cdot}{\\\\nabla} v \\\\,dr\\\\,dz = 2\n        \\\\pi \\\\mu_0 \\\\int_{D_p} J_{\\\\Phi} v \\\\,dr\\\\,dz\n\n    where :math:`v` is the basis element function of the defined functional subspace\n    :math:`V`.\n\n    .. [Zohm] H. Zohm, Magnetohydrodynamic Stability of Tokamaks, Wiley-VCH, Germany,\n       2015\n    .. [Villone] VILLONE, F. et al. Plasma Phys. Control. Fusion 55 (2013) 095008,\n       https://doi.org/10.1088/0741-3335/55/9/095008\n\n    Parameters\n    ----------\n    p_order:\n        Order of the approximating polynomial basis functions\n    \"\"\"\n\n    def __init__(self, p_order: int = 2):\n        self.p_order = p_order\n        self.mesh = None\n        self.a = None\n        self.u = None\n        self.v = None\n        self.V = None\n        self.g = None\n        self.L = None\n        self.boundaries = None\n        self.bcs = None\n\n        self.psi = None\n        self.B = None\n\n    def set_mesh(\n        self,\n        mesh: Union[dolfin.Mesh, str],\n        boundaries: Optional[Union[dolfin.Mesh, str]] = None,\n    ):\n        \"\"\"\n        Set the mesh for the solver\n\n        Parameters\n        ----------\n        mesh:\n            Filename of the xml file with the mesh definition or a dolfin mesh\n        boundaries:\n            Filename of the xml file with the boundaries definition or a MeshFunction\n            that defines the boundaries\n        \"\"\"\n        # check whether mesh is a filename or a mesh, then load it or use it\n        self.mesh = dolfin.Mesh(mesh) if isinstance(mesh, str) else mesh\n\n        # define boundaries\n        if boundaries is None:\n            # initialize the MeshFunction\n            self.boundaries = dolfin.MeshFunction(\n                \"size_t\", mesh, mesh.topology().dim() - 1\n            )\n        elif isinstance(boundaries, str):\n            # check weather boundaries is a filename or a MeshFunction,\n            # then load it or use it\n            self.boundaries = dolfin.MeshFunction(\n                \"size_t\", self.mesh, boundaries\n            )  # define the boundaries\n        else:\n            self.boundaries = boundaries\n\n        # define the function space and bilinear forms\n        # the Continuos Galerkin function space has been chosen as suitable for the\n        # solution of the magnetostatic weak formulation in a Soblev Space H1(D)\n        self.V = dolfin.FunctionSpace(self.mesh, \"CG\", self.p_order)\n\n        # define trial and test functions\n        self.u = dolfin.TrialFunction(self.V)\n        self.v = dolfin.TestFunction(self.V)\n\n        # Define r\n        r = dolfin.Expression(\"x[0]\", degree=self.p_order)\n\n        self.a = (\n            1\n            / (2.0 * dolfin.pi * MU_0)\n            * (1 / r * dolfin.dot(dolfin.grad(self.u), dolfin.grad(self.v)))\n            * dolfin.dx\n        )\n\n        # initialize solution\n        self.psi = dolfin.Function(self.V)\n        self.psi.set_allow_extrapolation(True)\n\n        # initialize g to zero\n        self.g = dolfin.Function(self.V)\n\n    def define_g(self, g: Union[dolfin.Expression, dolfin.Function]):\n        \"\"\"\n        Define g, the right hand side function of the Poisson problem\n\n        Parameters\n        ----------\n        g:\n            Right hand side function of the Poisson problem\n        \"\"\"\n        self.g = g\n\n    def solve(\n        self,\n        dirichlet_bc_function: Optional[\n            Union[dolfin.Expression, dolfin.Function]\n        ] = None,\n        dirichlet_marker: Optional[int] = None,\n        neumann_bc_function: Optional[Union[dolfin.Expression, dolfin.Function]] = None,\n    ) -> dolfin.Function:\n        \"\"\"\n        Solve the weak formulation maxwell equation given a right hand side g,\n        Dirichlet and Neumann boundary conditions.\n\n        Parameters\n        ----------\n        dirichlet_bc_function:\n            Dirichlet boundary condition function\n        dirichlet_marker:\n            Identification number for the dirichlet boundary\n        neumann_bc_function:\n            Neumann boundary condition function\n\n        Returns\n        -------\n        Poloidal magnetic flux function as solution of the magnetostatic problem\n        \"\"\"\n        if neumann_bc_function is None:\n            neumann_bc_function = dolfin.Expression(\"0.0\", degree=self.p_order)\n\n        # define the right hand side\n        self.L = self.g * self.v * dolfin.dx - neumann_bc_function * self.v * dolfin.ds\n\n        # define the Dirichlet boundary conditions\n        if dirichlet_bc_function is None:\n            dirichlet_bc_function = dolfin.Expression(\"0.0\", degree=self.p_order)\n            dirichlet_bc = dolfin.DirichletBC(\n                self.V, dirichlet_bc_function, \"on_boundary\"\n            )\n        else:\n            dirichlet_bc = dolfin.DirichletBC(\n                self.V, dirichlet_bc_function, self.boundaries, dirichlet_marker\n            )\n        self.bcs = [dirichlet_bc]\n\n        # solve the system taking into account the boundary conditions\n        dolfin.solve(\n            self.a == self.L,\n            self.psi,\n            self.bcs,\n            solver_parameters={\"linear_solver\": \"default\"},\n        )\n\n        return self.psi\n\n    def calculate_b(self) -> dolfin.Function:\n        \"\"\"\n        Calculates the magnetic field intensity from psi\n\n        Note: code from Fenics_tutorial (\n        https://link.springer.com/book/10.1007/978-3-319-52462-7), pag. 104\n        \"\"\"\n        # new function space for mapping B as vector\n        w = dolfin.VectorFunctionSpace(self.mesh, \"CG\", 1)\n\n        r = dolfin.Expression(\"x[0]\", degree=1)\n\n        # calculate derivatives\n        Bx = -self.psi.dx(1) / (2 * dolfin.pi * r)\n        Bz = self.psi.dx(0) / (2 * dolfin.pi * r)\n\n        # project B as vector to new function space\n        self.B = dolfin.project(dolfin.as_vector((Bx, Bz)), w)\n\n        return self.B",
  "def __init__(\n        self,\n        func_list: Union[\n            Iterable[Union[float, Callable[[Any], float]]], float, Callable[[Any], float]\n        ],\n        mark_list: Optional[Iterable[int]] = None,\n        subdomains: Optional[dolfin.cpp.mesh.MeshFunctionSizet] = None,\n        **kwargs,\n    ):\n        super().__init__(**kwargs)\n        self.functions = self.check_functions(func_list)\n        self.markers = mark_list\n        self.subdomains = subdomains",
  "def check_functions(\n        self,\n        functions: Union[Iterable[Union[float, Callable]], float, Callable],\n    ) -> Iterable[Union[float, Callable]]:\n        \"\"\"Check if the argument is a function or a list of functions\"\"\"\n        if not isinstance(functions, Iterable):\n            functions = [functions]\n        if all(isinstance(f, (float, Callable)) for f in functions):\n            return functions\n        raise ValueError(\n            \"Accepted functions are instance of (int, float, Callable)\"\n            \"or a list of them.\"\n        )",
  "def eval_cell(self, values: List, x: float, cell):\n        \"\"\"Evaluate the value on each cell\"\"\"\n        if self.markers is None or self.subdomains is None:\n            func = self.functions[0]\n        else:\n            m = self.subdomains[cell.index]\n            func = (\n                self.functions[np.where(np.array(self.markers) == m)[0][0]]\n                if m in self.markers\n                else 0\n            )\n        if callable(func):\n            values[0] = func(x)\n        elif isinstance(func, (int, float)):\n            values[0] = func\n        else:\n            raise ValueError(f\"{func} is not callable or is not a constant\")",
  "def value_shape(self) -> Tuple:\n        \"\"\"\n        Value_shape function (necessary for a UserExpression)\n        https://fenicsproject.discourse.group/t/problems-interpolating-a-userexpression-and-plotting-it/1303\n        \"\"\"\n        return ()",
  "def __init__(self, p_order: int = 2):\n        self.p_order = p_order\n        self.mesh = None\n        self.a = None\n        self.u = None\n        self.v = None\n        self.V = None\n        self.g = None\n        self.L = None\n        self.boundaries = None\n        self.bcs = None\n\n        self.psi = None\n        self.B = None",
  "def set_mesh(\n        self,\n        mesh: Union[dolfin.Mesh, str],\n        boundaries: Optional[Union[dolfin.Mesh, str]] = None,\n    ):\n        \"\"\"\n        Set the mesh for the solver\n\n        Parameters\n        ----------\n        mesh:\n            Filename of the xml file with the mesh definition or a dolfin mesh\n        boundaries:\n            Filename of the xml file with the boundaries definition or a MeshFunction\n            that defines the boundaries\n        \"\"\"\n        # check whether mesh is a filename or a mesh, then load it or use it\n        self.mesh = dolfin.Mesh(mesh) if isinstance(mesh, str) else mesh\n\n        # define boundaries\n        if boundaries is None:\n            # initialize the MeshFunction\n            self.boundaries = dolfin.MeshFunction(\n                \"size_t\", mesh, mesh.topology().dim() - 1\n            )\n        elif isinstance(boundaries, str):\n            # check weather boundaries is a filename or a MeshFunction,\n            # then load it or use it\n            self.boundaries = dolfin.MeshFunction(\n                \"size_t\", self.mesh, boundaries\n            )  # define the boundaries\n        else:\n            self.boundaries = boundaries\n\n        # define the function space and bilinear forms\n        # the Continuos Galerkin function space has been chosen as suitable for the\n        # solution of the magnetostatic weak formulation in a Soblev Space H1(D)\n        self.V = dolfin.FunctionSpace(self.mesh, \"CG\", self.p_order)\n\n        # define trial and test functions\n        self.u = dolfin.TrialFunction(self.V)\n        self.v = dolfin.TestFunction(self.V)\n\n        # Define r\n        r = dolfin.Expression(\"x[0]\", degree=self.p_order)\n\n        self.a = (\n            1\n            / (2.0 * dolfin.pi * MU_0)\n            * (1 / r * dolfin.dot(dolfin.grad(self.u), dolfin.grad(self.v)))\n            * dolfin.dx\n        )\n\n        # initialize solution\n        self.psi = dolfin.Function(self.V)\n        self.psi.set_allow_extrapolation(True)\n\n        # initialize g to zero\n        self.g = dolfin.Function(self.V)",
  "def define_g(self, g: Union[dolfin.Expression, dolfin.Function]):\n        \"\"\"\n        Define g, the right hand side function of the Poisson problem\n\n        Parameters\n        ----------\n        g:\n            Right hand side function of the Poisson problem\n        \"\"\"\n        self.g = g",
  "def solve(\n        self,\n        dirichlet_bc_function: Optional[\n            Union[dolfin.Expression, dolfin.Function]\n        ] = None,\n        dirichlet_marker: Optional[int] = None,\n        neumann_bc_function: Optional[Union[dolfin.Expression, dolfin.Function]] = None,\n    ) -> dolfin.Function:\n        \"\"\"\n        Solve the weak formulation maxwell equation given a right hand side g,\n        Dirichlet and Neumann boundary conditions.\n\n        Parameters\n        ----------\n        dirichlet_bc_function:\n            Dirichlet boundary condition function\n        dirichlet_marker:\n            Identification number for the dirichlet boundary\n        neumann_bc_function:\n            Neumann boundary condition function\n\n        Returns\n        -------\n        Poloidal magnetic flux function as solution of the magnetostatic problem\n        \"\"\"\n        if neumann_bc_function is None:\n            neumann_bc_function = dolfin.Expression(\"0.0\", degree=self.p_order)\n\n        # define the right hand side\n        self.L = self.g * self.v * dolfin.dx - neumann_bc_function * self.v * dolfin.ds\n\n        # define the Dirichlet boundary conditions\n        if dirichlet_bc_function is None:\n            dirichlet_bc_function = dolfin.Expression(\"0.0\", degree=self.p_order)\n            dirichlet_bc = dolfin.DirichletBC(\n                self.V, dirichlet_bc_function, \"on_boundary\"\n            )\n        else:\n            dirichlet_bc = dolfin.DirichletBC(\n                self.V, dirichlet_bc_function, self.boundaries, dirichlet_marker\n            )\n        self.bcs = [dirichlet_bc]\n\n        # solve the system taking into account the boundary conditions\n        dolfin.solve(\n            self.a == self.L,\n            self.psi,\n            self.bcs,\n            solver_parameters={\"linear_solver\": \"default\"},\n        )\n\n        return self.psi",
  "def calculate_b(self) -> dolfin.Function:\n        \"\"\"\n        Calculates the magnetic field intensity from psi\n\n        Note: code from Fenics_tutorial (\n        https://link.springer.com/book/10.1007/978-3-319-52462-7), pag. 104\n        \"\"\"\n        # new function space for mapping B as vector\n        w = dolfin.VectorFunctionSpace(self.mesh, \"CG\", 1)\n\n        r = dolfin.Expression(\"x[0]\", degree=1)\n\n        # calculate derivatives\n        Bx = -self.psi.dx(1) / (2 * dolfin.pi * r)\n        Bz = self.psi.dx(0) / (2 * dolfin.pi * r)\n\n        # project B as vector to new function space\n        self.B = dolfin.project(dolfin.as_vector((Bx, Bz)), w)\n\n        return self.B",
  "class CurrentSource(ABC):\n    \"\"\"\n    Abstract base class for a current source.\n    \"\"\"\n\n    current: float\n\n    def set_current(self, current: float):\n        \"\"\"\n        Set the current inside each of the circuits.\n\n        Parameters\n        ----------\n        current:\n            The current of each circuit [A]\n        \"\"\"\n        self.current = current\n\n    @abstractmethod\n    def field(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate the magnetic field at a set of coordinates.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the field\n        y:\n            The y coordinate(s) of the points at which to calculate the field\n        z:\n            The z coordinate(s) of the points at which to calculate the field\n\n        Returns\n        -------\n        The magnetic field vector {Bx, By, Bz} in [T]\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def plot(self, ax: Optional[Axes], **kwargs):\n        \"\"\"\n        Plot the CurrentSource.\n\n        Parameters\n        ----------\n        ax:\n            The matplotlib axes to plot on\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def rotate(self, angle: float, axis: Union[np.ndarray, str]):\n        \"\"\"\n        Rotate the CurrentSource about an axis.\n\n        Parameters\n        ----------\n        angle:\n            The rotation degree [rad]\n        axis:\n            The axis of rotation\n        \"\"\"\n        pass\n\n    def copy(self):\n        \"\"\"\n        Get a deepcopy of the CurrentSource.\n        \"\"\"\n        return deepcopy(self)",
  "class RectangularCrossSectionCurrentSource(CurrentSource):\n    \"\"\"\n    Abstract base class for a current source with a rectangular cross-section.\n    \"\"\"\n\n    origin: np.array\n    dcm: np.array\n    points: np.array\n    breadth: float\n    depth: float\n    length: float\n\n    def set_current(self, current: float):\n        \"\"\"\n        Set the current inside the source, adjusting current density.\n\n        Parameters\n        ----------\n        current:\n            The current of the source [A]\n        \"\"\"\n        super().set_current(current)\n        self.rho = current / (4 * self.breadth * self.depth)\n\n    def rotate(self, angle: float, axis: Union[np.ndarray, str]):\n        \"\"\"\n        Rotate the CurrentSource about an axis.\n\n        Parameters\n        ----------\n        angle:\n            The rotation degree [degree]\n        axis:\n            The axis of rotation\n        \"\"\"\n        r = rotation_matrix(np.deg2rad(angle), axis).T\n        self.origin = self.origin @ r\n        self.points = np.array([p @ r for p in self.points], dtype=object)\n        self.dcm = self.dcm @ r\n\n    def _local_to_global(self, points: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Convert local x', y', z' point coordinates to global x, y, z point coordinates.\n        \"\"\"\n        return np.array([self.origin + self.dcm.T @ p for p in points])\n\n    def _global_to_local(self, points: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Convert global x, y, z point coordinates to local x', y', z' point coordinates.\n        \"\"\"\n        return np.array([(self.dcm @ (p - self.origin)) for p in points])\n\n    def plot(self, ax: Optional[Axes] = None, show_coord_sys: bool = False):\n        \"\"\"\n        Plot the CurrentSource.\n\n        Parameters\n        ----------\n        ax: Union[None, Axes]\n            The matplotlib axes to plot on\n        show_coord_sys: bool\n            Whether or not to plot the coordinate systems\n        \"\"\"\n        if ax is None:\n            ax = Plot3D()\n            # If no ax provided, we assume that we want to plot only this source,\n            # and thus set aspect ratio equality on this term only\n            edge_points = np.concatenate(self.points)\n\n            # Invisible bounding box to set equal aspect ratio plot\n            xbox, ybox, zbox = BoundingBox.from_xyz(*edge_points.T).get_box_arrays()\n            ax.plot(1.1 * xbox, 1.1 * ybox, 1.1 * zbox, \"s\", alpha=0)\n\n        for points in self.points:\n            ax.plot(*points.T, color=\"b\", linewidth=1)\n\n        # Plot local coordinate system\n        if show_coord_sys:\n            ax.scatter(*self.origin, color=\"k\")\n            ax.quiver(*self.origin, *self.dcm[0], length=self.breadth, color=\"r\")\n            ax.quiver(*self.origin, *self.dcm[1], length=self.length, color=\"r\")\n            ax.quiver(*self.origin, *self.dcm[2], length=self.depth, color=\"r\")",
  "class SourceGroup(ABC):\n    \"\"\"\n    Abstract base class for multiple current sources.\n    \"\"\"\n\n    sources: List[CurrentSource]\n    points: np.array\n\n    def __init__(self, sources: List[CurrentSource]):\n        self.sources = sources\n        self.points = np.vstack([np.vstack(s.points) for s in self.sources])\n\n    def set_current(self, current: float):\n        \"\"\"\n        Set the current inside each of the circuits.\n\n        Parameters\n        ----------\n        current:\n            The current of each circuit [A]\n        \"\"\"\n        for source in self.sources:\n            source.set_current(current)\n\n    def field(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate the magnetic field at a point.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the field\n        y:\n            The y coordinate(s) of the points at which to calculate the field\n        z:\n            The z coordinate(s) of the points at which to calculate the field\n\n        Returns\n        -------\n        The magnetic field vector {Bx, By, Bz} in [T]\n        \"\"\"\n        return np.sum([source.field(x, y, z) for source in self.sources], axis=0)\n\n    def rotate(self, angle: float, axis: Union[np.ndarray, str]):\n        \"\"\"\n        Rotate the CurrentSource about an axis.\n\n        Parameters\n        ----------\n        angle:\n            The rotation degree [rad]\n        axis:\n            The axis of rotation\n        \"\"\"\n        for source in self.sources:\n            source.rotate(angle, axis)\n        self.points = self.points @ rotation_matrix(angle, axis)\n\n    def plot(self, ax: Optional[Axes] = None, show_coord_sys: bool = False):\n        \"\"\"\n        Plot the MultiCurrentSource.\n\n        Parameters\n        ----------\n        ax:\n            The matplotlib axes to plot on\n        show_coord_sys:\n            Whether or not to plot the coordinate systems\n        \"\"\"\n        if ax is None:\n            ax = Plot3D()\n\n        # Invisible bounding box to set equal aspect ratio plot\n        xbox, ybox, zbox = BoundingBox.from_xyz(*self.points.T).get_box_arrays()\n        ax.plot(1.1 * xbox, 1.1 * ybox, 1.1 * zbox, \"s\", alpha=0)\n\n        for source in self.sources:\n            source.plot(ax=ax, show_coord_sys=show_coord_sys)\n\n    def copy(self):\n        \"\"\"\n        Get a deepcopy of the SourceGroup.\n        \"\"\"\n        return deepcopy(self)",
  "def set_current(self, current: float):\n        \"\"\"\n        Set the current inside each of the circuits.\n\n        Parameters\n        ----------\n        current:\n            The current of each circuit [A]\n        \"\"\"\n        self.current = current",
  "def field(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate the magnetic field at a set of coordinates.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the field\n        y:\n            The y coordinate(s) of the points at which to calculate the field\n        z:\n            The z coordinate(s) of the points at which to calculate the field\n\n        Returns\n        -------\n        The magnetic field vector {Bx, By, Bz} in [T]\n        \"\"\"\n        pass",
  "def plot(self, ax: Optional[Axes], **kwargs):\n        \"\"\"\n        Plot the CurrentSource.\n\n        Parameters\n        ----------\n        ax:\n            The matplotlib axes to plot on\n        \"\"\"\n        pass",
  "def rotate(self, angle: float, axis: Union[np.ndarray, str]):\n        \"\"\"\n        Rotate the CurrentSource about an axis.\n\n        Parameters\n        ----------\n        angle:\n            The rotation degree [rad]\n        axis:\n            The axis of rotation\n        \"\"\"\n        pass",
  "def copy(self):\n        \"\"\"\n        Get a deepcopy of the CurrentSource.\n        \"\"\"\n        return deepcopy(self)",
  "def set_current(self, current: float):\n        \"\"\"\n        Set the current inside the source, adjusting current density.\n\n        Parameters\n        ----------\n        current:\n            The current of the source [A]\n        \"\"\"\n        super().set_current(current)\n        self.rho = current / (4 * self.breadth * self.depth)",
  "def rotate(self, angle: float, axis: Union[np.ndarray, str]):\n        \"\"\"\n        Rotate the CurrentSource about an axis.\n\n        Parameters\n        ----------\n        angle:\n            The rotation degree [degree]\n        axis:\n            The axis of rotation\n        \"\"\"\n        r = rotation_matrix(np.deg2rad(angle), axis).T\n        self.origin = self.origin @ r\n        self.points = np.array([p @ r for p in self.points], dtype=object)\n        self.dcm = self.dcm @ r",
  "def _local_to_global(self, points: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Convert local x', y', z' point coordinates to global x, y, z point coordinates.\n        \"\"\"\n        return np.array([self.origin + self.dcm.T @ p for p in points])",
  "def _global_to_local(self, points: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Convert global x, y, z point coordinates to local x', y', z' point coordinates.\n        \"\"\"\n        return np.array([(self.dcm @ (p - self.origin)) for p in points])",
  "def plot(self, ax: Optional[Axes] = None, show_coord_sys: bool = False):\n        \"\"\"\n        Plot the CurrentSource.\n\n        Parameters\n        ----------\n        ax: Union[None, Axes]\n            The matplotlib axes to plot on\n        show_coord_sys: bool\n            Whether or not to plot the coordinate systems\n        \"\"\"\n        if ax is None:\n            ax = Plot3D()\n            # If no ax provided, we assume that we want to plot only this source,\n            # and thus set aspect ratio equality on this term only\n            edge_points = np.concatenate(self.points)\n\n            # Invisible bounding box to set equal aspect ratio plot\n            xbox, ybox, zbox = BoundingBox.from_xyz(*edge_points.T).get_box_arrays()\n            ax.plot(1.1 * xbox, 1.1 * ybox, 1.1 * zbox, \"s\", alpha=0)\n\n        for points in self.points:\n            ax.plot(*points.T, color=\"b\", linewidth=1)\n\n        # Plot local coordinate system\n        if show_coord_sys:\n            ax.scatter(*self.origin, color=\"k\")\n            ax.quiver(*self.origin, *self.dcm[0], length=self.breadth, color=\"r\")\n            ax.quiver(*self.origin, *self.dcm[1], length=self.length, color=\"r\")\n            ax.quiver(*self.origin, *self.dcm[2], length=self.depth, color=\"r\")",
  "def __init__(self, sources: List[CurrentSource]):\n        self.sources = sources\n        self.points = np.vstack([np.vstack(s.points) for s in self.sources])",
  "def set_current(self, current: float):\n        \"\"\"\n        Set the current inside each of the circuits.\n\n        Parameters\n        ----------\n        current:\n            The current of each circuit [A]\n        \"\"\"\n        for source in self.sources:\n            source.set_current(current)",
  "def field(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate the magnetic field at a point.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the field\n        y:\n            The y coordinate(s) of the points at which to calculate the field\n        z:\n            The z coordinate(s) of the points at which to calculate the field\n\n        Returns\n        -------\n        The magnetic field vector {Bx, By, Bz} in [T]\n        \"\"\"\n        return np.sum([source.field(x, y, z) for source in self.sources], axis=0)",
  "def rotate(self, angle: float, axis: Union[np.ndarray, str]):\n        \"\"\"\n        Rotate the CurrentSource about an axis.\n\n        Parameters\n        ----------\n        angle:\n            The rotation degree [rad]\n        axis:\n            The axis of rotation\n        \"\"\"\n        for source in self.sources:\n            source.rotate(angle, axis)\n        self.points = self.points @ rotation_matrix(angle, axis)",
  "def plot(self, ax: Optional[Axes] = None, show_coord_sys: bool = False):\n        \"\"\"\n        Plot the MultiCurrentSource.\n\n        Parameters\n        ----------\n        ax:\n            The matplotlib axes to plot on\n        show_coord_sys:\n            Whether or not to plot the coordinate systems\n        \"\"\"\n        if ax is None:\n            ax = Plot3D()\n\n        # Invisible bounding box to set equal aspect ratio plot\n        xbox, ybox, zbox = BoundingBox.from_xyz(*self.points.T).get_box_arrays()\n        ax.plot(1.1 * xbox, 1.1 * ybox, 1.1 * zbox, \"s\", alpha=0)\n\n        for source in self.sources:\n            source.plot(ax=ax, show_coord_sys=show_coord_sys)",
  "def copy(self):\n        \"\"\"\n        Get a deepcopy of the SourceGroup.\n        \"\"\"\n        return deepcopy(self)",
  "def _partial_x_integrand(phi: float, rr: float, zz: float) -> float:\n    \"\"\"\n    Integrand edge cases derived to constant integrals. Much faster than\n    splitting up the integrands.\n    \"\"\"\n    cos_phi = np.cos(phi)\n    r0 = np.sqrt(rr**2 + 1 - 2 * rr * cos_phi + zz**2)\n\n    if abs(zz) < EPS:\n        if abs(rr - 1.0) < EPS:\n            return -1.042258937608 / np.pi\n        elif rr < 1.0:\n            return cos_phi * (\n                r0 + cos_phi * np.log((r0 + 1 + rr) / (r0 + 1 - rr))\n            ) - 0.25 * (1 + np.log(4))\n\n    return (r0 + cos_phi * np.log(r0 + rr - cos_phi)) * cos_phi",
  "def _full_x_integrand(phi: float, r1: float, r2: float, z1: float, z2: float) -> float:\n    \"\"\"\n    Calculate the P_x primitive integral.\n\n    \\t:math:`P_{x}(R, Z) = \\\\int_{0}^{\\\\pi}[R_{0}+cos(\\\\phi)ln(R_{0}+R`\n    \\t:math:`-cos(\\\\phi))]cos(\\\\phi)d\\\\phi`\n    \"\"\"\n    return (\n        _partial_x_integrand(phi, r1, z1)\n        - _partial_x_integrand(phi, r1, z2)\n        - _partial_x_integrand(phi, r2, z1)\n        + _partial_x_integrand(phi, r2, z2)\n    )",
  "def _partial_z_integrand_nojit(phi: float, rr: float, zz: float) -> float:\n    \"\"\"\n    Integrand edge cases derived to constant integrals. Much faster than\n    splitting up the integrands.\n    \"\"\"\n    if abs(zz) < EPS:\n        return 0.0\n\n    sin_phi = np.sin(phi)\n    cos_phi = np.cos(phi)\n    r0 = np.sqrt(rr**2 + 1 - 2 * rr * cos_phi + zz**2)\n\n    # F1\n    result = zz * np.log(r0 + rr - cos_phi) - cos_phi * np.log(r0 + zz)\n\n    # F2\n    if rr - 1 < EPS:\n        result = result - 0.5 * rr\n    else:\n        result = result - 0.5 / rr\n    # F3\n    if 0.5 * np.pi * sin_phi > 1e-9:\n        result = result - sin_phi * np.arctan(zz * (rr - cos_phi) / (r0 * sin_phi))\n    return result",
  "def _full_z_integrand(phi: float, r1: float, r2: float, z1: float, z2: float) -> float:\n    \"\"\"\n    Calculate the P_z primitive integral at all 4 corner combinations\n\n    \\t:math:`P_{z}(R, Z) = \\\\int_{0}^{\\\\pi} [Zln(R_{0}+R-cos(\\\\phi)`\n    \\t:math:`+\\\\dfrac{1}{2}cos(\\\\phi)ln(\\\\dfrac{R_{0}-Z}{R_{0}+Z})`\n    \\t:math:`-sin(\\\\phi)arctan(\\\\dfrac{Z[R-cos(\\\\phi)]}{R_{0}sin(\\\\phi)})]d\\\\phi`\n    \"\"\"\n    return (\n        _partial_z_integrand(phi, r1, z1)\n        - _partial_z_integrand(phi, r1, z2)\n        - _partial_z_integrand(phi, r2, z1)\n        + _partial_z_integrand(phi, r2, z2)\n    )",
  "def _integrate_z_by_parts(r1: float, r2: float, z1: float, z2: float) -> float:\n    \"\"\"\n    Integrate the Bz integrand by parts.\n\n    This can be used as a fallback if the full integration fails.\n    \"\"\"\n    return (\n        integrate(_partial_z_integrand_llc, (r1, z1), 0, np.pi)\n        - integrate(_partial_z_integrand_llc, (r1, z2), 0, np.pi)\n        - integrate(_partial_z_integrand_llc, (r2, z1), 0, np.pi)\n        + integrate(_partial_z_integrand_llc, (r2, z2), 0, np.pi)\n    )",
  "def _get_working_coords(\n    xc: float, zc: float, x: float, z: float, d_xc: float, d_zc: float\n) -> Tuple[float, float, float, float, float]:\n    \"\"\"\n    Convert coil and global coordinates to working coordinates.\n    \"\"\"\n    z = z - zc\n    r1, r2 = (xc - d_xc) / x, (xc + d_xc) / x\n    z1, z2 = (-d_zc - z) / x, (d_zc - z) / x\n    j_tor = 1 / (4 * d_xc * d_zc)  # Keep current out of the equation\n    return r1, r2, z1, z2, j_tor",
  "def _array_dispatcher(func):\n    \"\"\"\n    Decorator for float and array handling.\n    \"\"\"\n\n    def wrapper(xc, zc, x, z, d_xc, d_zc):\n        # Handle floats\n        if is_num(x):\n            return func(xc, zc, x, z, d_xc, d_zc)\n\n        # Handle arrays\n        if len(x.shape) == 1:\n            if not isinstance(xc, np.ndarray) or len(xc.shape) == 1:\n                result = np.zeros(len(x))\n                for i in range(len(x)):\n                    result[i] = func(xc, zc, x[i], z[i], d_xc, d_zc)\n            else:\n                result = np.zeros((len(x), len(xc)))\n                for j in range(xc.shape[1]):\n                    for i in range(len(x)):\n                        result[i, j] = func(\n                            xc[:, j], zc[:, j], x[i], z[i], d_xc[:, j], d_zc[:, j]\n                        )\n\n        else:\n            # 2-D arrays\n            if not isinstance(xc, np.ndarray) or len(xc.shape) == 1:\n                result = np.zeros(x.shape)\n                for i in range(x.shape[0]):\n                    for j in range(z.shape[1]):\n                        result[i, j] = func(xc, zc, x[i, j], z[i, j], d_xc, d_zc)\n            else:\n                result = np.zeros((list(x.shape) + [xc.shape[1]]))\n                for k in range(xc.shape[1]):\n                    for i in range(x.shape[0]):\n                        for j in range(z.shape[1]):\n                            result[i, j, ..., k] = func(\n                                xc[:, k],\n                                zc[:, k],\n                                x[i, j],\n                                z[i, j],\n                                d_xc[:, k],\n                                d_zc[:, k],\n                            )\n        return result\n\n    return wrapper",
  "def semianalytic_Bx(\n    xc: float,\n    zc: float,\n    x: Union[float, np.ndarray],\n    z: Union[float, np.ndarray],\n    d_xc: float,\n    d_zc: float,\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Calculate the Bx and Bz fields from a rectangular cross-section circular\n    coil with a unit current using a semi-analytic reduction of the Biot-Savart\n    law.\n\n    Parameters\n    ----------\n    xc:\n        Coil x coordinate [m]\n    zc:\n        Coil z coordinate [m]\n    x:\n        Calculation x location\n    z:\n        Calculation z location\n    d_xc:\n        The half-width of the coil\n    d_zc:\n        The half-height of the coil\n\n    Returns\n    -------\n    Radial magnetic field response (x, z)\n\n    Notes\n    -----\n    \\t:math:`B_{x}=\\\\dfrac{\\\\mu_{0}Jx}{2\\\\pi}\\\\sum^{2}_{i=1}(-1)^{i+j}`\n    \\t:math:`P_x(R_{i},Z_{j})`\n\n    References\n    ----------\n    https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6019053\n    \"\"\"\n    r1, r2, z1, z2, j_tor = _get_working_coords(xc, zc, x, z, d_xc, d_zc)\n\n    Bx = integrate(_full_x_integrand, (r1, r2, z1, z2), 0, np.pi)\n\n    fac = 2e-7 * j_tor * x  # MU_0/(2*np.pi)\n    return fac * Bx",
  "def semianalytic_Bz(\n    xc: float,\n    zc: float,\n    x: Union[float, np.ndarray],\n    z: Union[float, np.ndarray],\n    d_xc: float,\n    d_zc: float,\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Calculate the Bx and Bz fields from a rectangular cross-section circular\n    coil with a unit current using a semi-analytic reduction of the Biot-Savart\n    law.\n\n    Parameters\n    ----------\n    xc:\n        Coil x coordinate [m]\n    zc:\n        Coil z coordinate [m]\n    x:\n        Calculation x location\n    z:\n        Calculation z location\n    d_xc:\n        The half-width of the coil\n    d_zc:\n        The half-height of the coil\n\n    Returns\n    -------\n    Vertical magnetic field response at (x, z)\n\n    Notes\n    -----\n    \\t:math:`B_{z}=\\\\dfrac{\\\\mu_{0}Jx}{2\\\\pi}\\\\sum^{2}_{i=1}(-1)^{i+j}`\n    \\t:math:`P_z(R_{i},Z_{j})`\n\n    References\n    ----------\n    https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6019053\n    \"\"\"\n    r1, r2, z1, z2, j_tor = _get_working_coords(xc, zc, x, z, d_xc, d_zc)\n\n    try:\n        Bz = integrate(_full_z_integrand, (r1, r2, z1, z2), 0, np.pi)\n    except MagnetostaticsIntegrationError:\n        # If all else fails, fall back to integration by parts\n        Bz = _integrate_z_by_parts(r1, r2, z1, z2)\n    fac = 2e-7 * j_tor * x  # MU_0/(2*np.pi)\n    return fac * Bz",
  "def _full_psi_integrand(x, phi, xc, zc, z, d_xc, d_zc):\n    \"\"\"\n    Integrand for psi = xBz\n    \"\"\"\n    z = z - zc\n    r1, r2 = (xc - d_xc) / x, (xc + d_xc) / x\n    z1, z2 = (-d_zc - z) / x, (d_zc - z) / x\n    return x**2 * (\n        _partial_z_integrand(phi, r1, z1)\n        - _partial_z_integrand(phi, r1, z2)\n        - _partial_z_integrand(phi, r2, z1)\n        + _partial_z_integrand(phi, r2, z2)\n    )",
  "def semianalytic_psi(\n    xc: float,\n    zc: float,\n    x: Union[float, np.ndarray],\n    z: Union[float, np.ndarray],\n    d_xc: float,\n    d_zc: float,\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Calculate the poloidal magnetic flux from a rectangular cross-section circular\n    coil with a unit current using a semi-analytic reduction of the Biot-Savart\n    law.\n\n    Parameters\n    ----------\n    xc:\n        Coil x coordinate [m]\n    zc:\n        Coil z coordinate [m]\n    x:\n        Calculation x location\n    z:\n        Calculation z location\n    d_xc:\n        The half-width of the coil\n    d_zc:\n        The half-height of the coil\n\n    Returns\n    -------\n    Poloidal magnetic flux response at (x, z)\n\n    Notes\n    -----\n    Integrates x*Bz to resolve psi. More analytical approaches are possible and\n    will no doubt be faster.\n    \"\"\"\n    j_tor = 1 / (4 * d_xc * d_zc)  # Keep current out of the equation\n    psi = n_integrate(_full_psi_integrand, (xc, zc, z, d_xc, d_zc), [[0, x], [0, np.pi]])\n\n    return 2e-7 * j_tor * psi",
  "def wrapper(xc, zc, x, z, d_xc, d_zc):\n        # Handle floats\n        if is_num(x):\n            return func(xc, zc, x, z, d_xc, d_zc)\n\n        # Handle arrays\n        if len(x.shape) == 1:\n            if not isinstance(xc, np.ndarray) or len(xc.shape) == 1:\n                result = np.zeros(len(x))\n                for i in range(len(x)):\n                    result[i] = func(xc, zc, x[i], z[i], d_xc, d_zc)\n            else:\n                result = np.zeros((len(x), len(xc)))\n                for j in range(xc.shape[1]):\n                    for i in range(len(x)):\n                        result[i, j] = func(\n                            xc[:, j], zc[:, j], x[i], z[i], d_xc[:, j], d_zc[:, j]\n                        )\n\n        else:\n            # 2-D arrays\n            if not isinstance(xc, np.ndarray) or len(xc.shape) == 1:\n                result = np.zeros(x.shape)\n                for i in range(x.shape[0]):\n                    for j in range(z.shape[1]):\n                        result[i, j] = func(xc, zc, x[i, j], z[i, j], d_xc, d_zc)\n            else:\n                result = np.zeros((list(x.shape) + [xc.shape[1]]))\n                for k in range(xc.shape[1]):\n                    for i in range(x.shape[0]):\n                        for j in range(z.shape[1]):\n                            result[i, j, ..., k] = func(\n                                xc[:, k],\n                                zc[:, k],\n                                x[i, j],\n                                z[i, j],\n                                d_xc[:, k],\n                                d_zc[:, k],\n                            )\n        return result",
  "def brc_integrand_full(psi: float, r_pc: float, r_j: float, z_k: float) -> float:\n    \"\"\"\n    Calculate the Brc integrand without singularities.\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    r_j:\n        The radius (inner or outer) of the coil [m]\n    z_k:\n        The z coordinate (upper or lower) of the coil [m]\n    psi:\n        Angle [rad]\n\n    Returns\n    -------\n    The result of the integrand at a single point\n    \"\"\"\n    cos_psi = np.cos(psi)\n    sqrt_term = np.sqrt(r_pc**2 - 2 * r_pc * r_j * cos_psi + r_j**2 + z_k**2)\n    return cos_psi * sqrt_term + r_pc * cos_psi**2 * np.log(\n        r_j - r_pc * cos_psi + sqrt_term\n    )",
  "def bzc_integrand_full_p1(psi: float, r_pc: float, r_j: float, z_k: float) -> float:\n    \"\"\"\n    Calculate the Bzc integrand without singularities.\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    r_j:\n        The radius (inner or outer) of the coil [m]\n    z_k:\n        The z coordinate (upper or lower) of the coil [m]\n    psi:\n        Angle [rad]\n\n    Returns\n    -------\n    The result of the integrand at a single point\n    \"\"\"\n    cos_psi = np.cos(psi)\n    sqrt_term = np.sqrt(r_pc**2 - 2 * r_pc * r_j * cos_psi + r_j**2 + z_k**2)\n    return -z_k * np.log(r_j - r_pc * cos_psi + sqrt_term) - r_pc * cos_psi * np.log(\n        -z_k + sqrt_term\n    )",
  "def brc_integrand_p1(psi: float, r_pc: float, r_j: float, z_k: float) -> float:\n    \"\"\"\n    Calculate the first part of the Brc integrand (no singularities)\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    r_j:\n        The radius (inner or outer) of the coil [m]\n    z_k:\n        The z coordinate (upper or lower) of the coil [m]\n    psi:\n        Angle [rad]\n\n    Returns\n    -------\n    The result of the integrand at a single point\n    \"\"\"\n    cos_psi = np.cos(psi)\n    sqrt_term = np.sqrt(r_pc**2 - 2 * r_pc * r_j * cos_psi + r_j**2 + z_k**2)\n    return cos_psi * sqrt_term",
  "def bf1_r_pccos2_integrand(psi: float, r_pc: float, r_j: float, z_k: float) -> float:\n    \"\"\"\n    Calculate the BF1(r_pc*cos(psi)^2) integrand\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    r_j:\n        The radius (inner or outer) of the coil [m]\n    z_k:\n        The z coordinate (upper or lower) of the coil [m]\n    psi:\n        Angle [rad]\n\n    Returns\n    -------\n    The result of the integrand at a single point\n    \"\"\"\n    cos_psi = np.cos(psi)\n    sqrt_term = np.sqrt(r_pc**2 - 2 * r_pc * r_j * cos_psi + r_j**2 + z_k**2)\n    return r_pc * cos_psi**2 * np.log(r_j - r_pc * cos_psi + sqrt_term)",
  "def bf1_r_pccos2_0_pi_integrand_p1(psi: float, r_pc: float, r_j: float) -> float:\n    \"\"\"\n    Calculate the BF1(r_pc*cos(psi)^2) integrand for a 0 to pi integral\n\n    From 0 to pi for r_j < r_pc and z_k == 0. Part 1\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    r_j:\n        The radius (inner or outer) of the coil [m]\n    psi:\n        Angle [rad]\n\n    Returns\n    -------\n    The result of the integrand at a single point for 0 to pi integral\n    \"\"\"\n    cos_psi = np.cos(psi)\n    return (\n        r_pc\n        * cos_psi**2\n        * np.log(\n            (r_pc * cos_psi - r_j)\n            + np.sqrt((r_pc * cos_psi - r_j) ** 2 + r_pc**2 * np.sin(psi) ** 2)\n        )\n    )",
  "def bf1_r_pccos2_0_pi_integrand_p2(psi: float, r_pc: float, r_j: float) -> float:\n    \"\"\"\n    Calculate the BF1(r_pc*cos(psi)^2) integrand for a 0 to pi integral\n\n    From 0 to pi for r_j < r_pc and z_k == 0. Part 2\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    r_j:\n        The radius (inner or outer) of the coil [m]\n    psi:\n        Angle [rad]\n\n    Returns\n    -------\n    The result of the integrand at a single point for 0 to pi integral\n    \"\"\"\n    cos_psi = np.cos(psi)\n    return (\n        r_pc\n        * cos_psi**2\n        * np.log(\n            (r_j - r_pc * cos_psi)\n            + np.sqrt((r_j - r_pc * cos_psi) ** 2 + r_pc**2 * np.sin(psi) ** 2)\n        )\n    )",
  "def bf1_zk_integrand(psi: float, r_pc: float, r_j: float, z_k: float) -> float:\n    \"\"\"\n    Calculate the BF1(-z_k) integrand for a 0 to pi integral\n\n    From 0 to pi for r_j < r_pc and z_k == 0.\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    r_j:\n        The radius (inner or outer) of the coil [m]\n    z_k:\n        The z coordinate (upper or lower) of the coil [m]\n    psi:\n        Angle [rad]\n\n    Returns\n    -------\n    The result of the integrand at a single point\n    \"\"\"\n    cos_psi = np.cos(psi)\n    sqrt_term = np.sqrt(r_pc**2 - 2 * r_pc * r_j * cos_psi + r_j**2 + z_k**2)\n    return -z_k * np.log(r_j - r_pc * cos_psi + sqrt_term)",
  "def bf2_integrand(psi: float, r_pc: float, r_j: float, z_k: float) -> float:\n    \"\"\"\n    Calculate the BF2 integrand.\n\n    For r_j == r_pc and z_k >= 0.\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    r_j:\n        The radius (inner or outer) of the coil [m]\n    z_k:\n        The z coordinate (upper or lower) of the coil [m]\n    psi:\n        Angle [rad]\n\n    Returns\n    -------\n    The result of the integrand at a single point\n    \"\"\"\n    cos_psi = np.cos(psi)\n    sqrt_term = np.sqrt(r_pc**2 - 2 * r_pc * r_j * cos_psi + r_j**2 + z_k**2)\n    return -r_pc * cos_psi * np.log(-z_k + sqrt_term)",
  "def bf2_0_pi_integrand(psi: float, r_pc: float, z_k: float) -> float:\n    \"\"\"\n    Calculate the BF2 integrand for a 0 to pi integral\n\n    From 0 to pi for r_j == r_pc and z_k >= 0.\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    z_k:\n        The z coordinate (upper or lower) of the coil [m]\n    psi:\n        Angle [rad]\n\n    Returns\n    -------\n    The result of the integrand at a single point for 0 to pi integral\n    \"\"\"\n    cos_psi = np.cos(psi)\n    return (\n        r_pc * cos_psi * np.log(z_k + np.sqrt(2 * r_pc**2 * (1 - cos_psi) + z_k**2))\n    )",
  "def bf3_integrand(psi: float, r_pc: float, r_j: float, z_k: float) -> float:\n    \"\"\"\n    Calculate the BF3 integrand\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    r_j:\n        The radius (inner or outer) of the coil [m]\n    z_k:\n        The z coordinate (upper or lower) of the coil [m]\n    psi:\n        Angle [rad]\n\n    Returns\n    -------\n    The result of the integrand at a single point\n\n    Notes\n    -----\n    Treats the sin(psi) = 0 singularity\n    \"\"\"\n    cos_psi = np.cos(psi)\n    sin_psi = np.sin(psi)\n    if sin_psi != 0:\n        sqrt_term = np.sqrt(r_pc**2 - 2 * r_pc * r_j * cos_psi + r_j**2 + z_k**2)\n        return (\n            r_pc\n            * sin_psi\n            * np.arctan((z_k * (r_j - r_pc * cos_psi)) / (r_pc * sin_psi * sqrt_term))\n        )\n    return 0",
  "def bf1_r_pccos2_zk0_0_pi(r_pc: float, r_j: float) -> float:\n    \"\"\"\n    Calculate the BF1(r_pc*cos(psi)^2) integral for 0 to pi.\n\n    From 0 to pi for r_j <= r_pc and z_k == 0\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    r_j:\n        The radius (inner or outer) of the coil [m]\n\n    Returns\n    -------\n    The result of the integral at a single point for 0 to pi integral\n    \"\"\"\n    if r_pc == r_j:\n        return r_pc * (0.5 * np.pi * np.log(r_pc) + 0.2910733)\n    # r_j < r_pc\n    result = 0.5 * np.pi * r_pc * (np.log(r_pc) - np.log(2) - 0.5)\n    result -= integrate(bf1_r_pccos2_0_pi_integrand_p1, (r_pc, r_j), 0, 0.5 * np.pi)\n    result += integrate(bf1_r_pccos2_0_pi_integrand_p2, (r_pc, r_j), 0.5 * np.pi, np.pi)\n    return result",
  "def bf2_rj_rpc_0_pi(r_pc: float, z_k: float) -> float:\n    \"\"\"\n    Calculate the BF2 integrand for a 0 to pi integral\n\n    From 0 to pi for r_j < r_pc and z_k == 0.\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    z_k:\n        The z coordinate (upper or lower) of the coil [m]\n\n    Returns\n    -------\n    The result of the integral for 0 to pi\n    \"\"\"\n    return np.pi * r_pc + integrate(bf2_0_pi_integrand, (r_pc, z_k), 0, np.pi)",
  "def primitive_brc(\n    r_pc: float, r_j: float, z_k: float, phi_pc: float, theta: float\n) -> float:\n    \"\"\"\n    Calculate the Brc primitives and treat singularities.\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    r_j:\n        The radius (inner or outer) of the coil [m]\n    z_k:\n        The z coordinate (upper or lower) of the coil [m]\n    phi_pc:\n        Angle of the point at which to evaluate field [rad]\n    theta:\n        Azimuthal angle of the circular arc\n\n    Returns\n    -------\n    The result of the Brc primitive\n    \"\"\"\n    args = (r_pc, r_j, z_k)  # The function arguments for integration\n    singularities = (z_k == 0) and (r_j <= r_pc) and (0 <= phi_pc <= theta)\n    if not singularities:\n        # No singularities\n        return integrate(brc_integrand_full, args, -phi_pc, theta - phi_pc)\n\n    # Treat singularities\n    # Singularity free treatment of first term\n    result = integrate(brc_integrand_p1, args, -phi_pc, theta - phi_pc)\n\n    # Dodge singularities in second term\n    if phi_pc == 0:\n        if theta == np.pi:\n            result += bf1_r_pccos2_zk0_0_pi(r_pc, r_j)\n\n        if theta == 2 * np.pi:\n            # cos(-psi)^2 == cos(psi)^2\n            result += 2 * bf1_r_pccos2_zk0_0_pi(r_pc, r_j)\n        else:\n            result += bf1_r_pccos2_zk0_0_pi(r_pc, r_j)\n            result -= integrate(bf1_r_pccos2_integrand, args, -theta, np.pi - theta)\n\n    elif phi_pc == theta:\n        if phi_pc == np.pi:\n            result += bf1_r_pccos2_zk0_0_pi(r_pc, r_j)\n        else:\n            # cos(-psi)^2 == cos(psi)^2\n            result += bf1_r_pccos2_zk0_0_pi(r_pc, r_j)\n            result -= integrate(bf1_r_pccos2_integrand, args, np.pi, np.pi - theta)\n    else:\n        # cos(-psi)^2 == cos(psi)^2\n        result += 2 * bf1_r_pccos2_zk0_0_pi(r_pc, r_j)\n        result -= integrate(\n            bf1_r_pccos2_integrand, args, phi_pc - theta, 2 * np.pi - theta\n        )\n\n    return result",
  "def primitive_bzc(\n    r_pc: float, r_j: float, z_k: float, phi_pc: float, theta: float\n) -> float:\n    \"\"\"\n    Calculate the Bzc primitives and treat singularities.\n\n    Parameters\n    ----------\n    r_pc:\n        The radius of the point at which to evaluate field [m]\n    r_j:\n        The radius (inner or outer) of the coil [m]\n    z_k:\n        The z coordinate (upper or lower) of the coil [m]\n    phi_pc:\n        Angle of the point at which to evaluate field [rad]\n    theta:\n        Azimuthal angle of the circular arc\n\n    Returns\n    -------\n    The result of the Bzc primitive\n    \"\"\"\n    args = (r_pc, r_j, z_k)  # The function arguments for integration\n    bf1_singularities = (z_k == 0) and (r_j <= r_pc) and (0 <= phi_pc <= theta)\n    bf2_singularities = (r_j == r_pc) and (z_k >= 0) and (0 <= phi_pc <= theta)\n    bf3_singularities = r_pc == 0\n    if not bf1_singularities and not bf2_singularities and not bf3_singularities:\n        # No singularities (almost)\n        return integrate(\n            bzc_integrand_full_p1, args, -phi_pc, theta - phi_pc\n        ) + integrate(bf3_integrand, args, -phi_pc, theta - phi_pc)\n\n    # Treat singularities\n    result = 0\n    if bf1_singularities:\n        # Treat BF1(-z_k)\n        if phi_pc == 0 and theta != np.pi and theta != 2 * np.pi:\n            # At pi and 2 * pi the BF1 integral is 0\n            # Elsewhere:\n            # result += 0 (the first part of BF1 is 0)\n            result -= integrate(bf1_zk_integrand, args, -theta, np.pi - theta)\n\n        if phi_pc == theta:\n            # result += 0 (the first part of BF1 is 0)\n            result -= integrate(bf1_zk_integrand, args, np.pi, np.pi - theta)\n\n        else:\n            # result += 0 (the first part of BF1 is 0)\n            result -= integrate(\n                bf1_zk_integrand, args, phi_pc - theta, 2 * np.pi - theta\n            )\n\n    else:\n        # BF1 is normal\n        result += integrate(bf1_zk_integrand, args, -phi_pc, theta - phi_pc)\n\n    if bf2_singularities:\n        # Treat BF2\n        if phi_pc == 0:\n            result += bf2_rj_rpc_0_pi(r_pc, z_k)\n            result -= integrate(bf2_integrand, args, -theta, np.pi - theta)\n\n        if phi_pc == theta:\n            result += bf2_rj_rpc_0_pi(r_pc, z_k)\n            result -= integrate(bf2_integrand, args, np.pi, np.pi - theta)\n\n        else:\n            result += 2 * bf2_rj_rpc_0_pi(r_pc, z_k)\n            result -= integrate(bf2_integrand, args, phi_pc - theta, 2 * np.pi - theta)\n\n    else:\n        # BF2 is normal\n        result += integrate(bf2_integrand, args, -phi_pc, theta - phi_pc)\n\n    if r_pc != 0:\n        # r_pc = 0, BF3 evaluates to 0\n        result += integrate(bf3_integrand, args, -phi_pc, theta - phi_pc)\n\n    return result",
  "def Bx_analytical_circular(\n    r1: float, r2: float, z1: float, z2: float, theta: float, r_p: float, theta_p: float\n) -> float:\n    \"\"\"\n    Calculate magnetic field in the local x coordinate direction due to a\n    circular arc current source.\n\n    Parameters\n    ----------\n    r1:\n        Inner coil radius [m]\n    r2:\n        Outer coil radius [m]\n    z1:\n        The first modified z coordinate [m]\n    z2:\n        The second modified z coordinate [m]\n    theta:\n        Azimuthal angle of the circular arc [rad]\n    r_p:\n        The radius of the point at which to evaluate the field [m]\n    theta_p:\n        The angle of the point at which to evaluate the field [rad]\n\n    Returns\n    -------\n    The magnetic field response in the x coordinate direction\n    \"\"\"\n    return (\n        primitive_brc(r_p, r1, z1, theta_p, theta)\n        - primitive_brc(r_p, r1, z2, theta_p, theta)\n        - primitive_brc(r_p, r2, z1, theta_p, theta)\n        + primitive_brc(r_p, r2, z2, theta_p, theta)\n    )",
  "def Bz_analytical_circular(\n    r1: float, r2: float, z1: float, z2: float, theta: float, r_p: float, theta_p: float\n) -> float:\n    \"\"\"\n    Calculate magnetic field in the local z coordinate direction due to a\n    circular arc current source.\n\n    Parameters\n    ----------\n    r1:\n        Inner coil radius [m]\n    r2:\n        Outer coil radius [m]\n    z1:\n        The first modified z coordinate [m]\n    z2:\n        The second modified z coordinate [m]\n    theta:\n        Azimuthal angle of the circular arc [rad]\n    r_p:\n        The radius of the point at which to evaluate the field [m]\n    theta_p:\n        The angle of the point at which to evaluate the field [rad]\n\n    Returns\n    -------\n    The magnetic field response in the z coordinate direction\n    \"\"\"\n    return (\n        primitive_bzc(r_p, r1, z1, theta_p, theta)\n        - primitive_bzc(r_p, r1, z2, theta_p, theta)\n        - primitive_bzc(r_p, r2, z1, theta_p, theta)\n        + primitive_bzc(r_p, r2, z2, theta_p, theta)\n    )",
  "class CircularArcCurrentSource(RectangularCrossSectionCurrentSource):\n    \"\"\"\n    3-D circular arc prism current source with a rectangular cross-section and\n    uniform current distribution.\n\n    Parameters\n    ----------\n    origin:\n        The origin of the current source in global coordinates [m]\n    ds:\n        The direction vector of the current source in global coordinates [m]\n    normal:\n        The normalised normal vector of the current source in global coordinates [m]\n    t_vec:\n        The normalised tangent vector of the current source in global coordinates [m]\n    breadth:\n        The breadth of the current source (half-width) [m]\n    depth:\n        The depth of the current source (half-height) [m]\n    radius:\n        The radius of the circular arc from the origin [m]\n    dtheta:\n        The azimuthal width of the arc [\u00b0]\n    current:\n        The current flowing through the source [A]\n\n    Notes\n    -----\n    The origin is at the centre of the circular arc, with the ds vector pointing\n    towards the start of the circular arc.\n\n    Cylindrical coordinates are used for calculations under the hood.\n    \"\"\"\n\n    def __init__(\n        self,\n        origin: np.ndarray,\n        ds: np.ndarray,\n        normal: np.ndarray,\n        t_vec: np.ndarray,\n        breadth: float,\n        depth: float,\n        radius: float,\n        dtheta: float,\n        current: float,\n    ):\n        self.origin = origin\n        self._breadth = breadth\n        self.depth = depth\n        self.length = 0.5 * (breadth + depth)  # For plotting only\n        self._radius = radius\n        self._update_r1r2()\n\n        self.dtheta = np.deg2rad(dtheta)\n        self.rho = current / (4 * breadth * depth)\n        self.dcm = np.array([ds, normal, t_vec])\n        self.points = self._calculate_points()\n\n    @property\n    def radius(self) -> float:\n        \"\"\"\n        Get the radius of the CircularArcCurrentSource\n        \"\"\"\n        return self._radius\n\n    @radius.setter\n    def radius(self, radius: float):\n        \"\"\"\n        Set the radius.\n\n        Parameters\n        ----------\n        radius:\n            The radius of the CircularArcCurrentSource\n        \"\"\"\n        self._radius = radius\n        self._update_r1r2()\n\n    @property\n    def breadth(self) -> float:\n        \"\"\"\n        Get the breadth of the CircularArcCurrentSource.\n        \"\"\"\n        return self._breadth\n\n    @breadth.setter\n    def breadth(self, breadth: float):\n        \"\"\"\n        Set the breadth of the CircularArcCurrentSource.\n\n        Parameters\n        ----------\n        breadth:\n            The breadth of the CircularArcCurrentSource\n        \"\"\"\n        self._breadth = breadth\n        self._update_r1r2()\n\n    def _update_r1r2(self):\n        \"\"\"\n        Update\n        \"\"\"\n        self._r1 = self.radius - self.breadth\n        self._r2 = self.radius + self.breadth\n\n    @staticmethod\n    def _local_to_cylindrical(point: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Convert from local to cylindrical coordinates.\n        \"\"\"\n        x, y, z = point\n        rho = np.sqrt(x**2 + y**2)\n        theta = np.arctan2(y, x)\n        return np.array([rho, theta, z])\n\n    def _cylindrical_to_working(self, zp: float) -> Tuple[float, float, float, float]:\n        \"\"\"\n        Convert from local cylindrical coordinates to working coordinates.\n        \"\"\"\n        z1 = zp + self.depth\n        z2 = zp - self.depth\n        return self._r1, self._r2, z1, z2\n\n    def _BxByBz(self, rp: float, tp: float, zp: float) -> np.ndarray:\n        \"\"\"\n        Calculate the field at a point in local coordinates.\n        \"\"\"\n        r1, r2, z1, z2 = self._cylindrical_to_working(zp)\n        bx = Bx_analytical_circular(r1, r2, z1, z2, self.dtheta, rp, tp)\n        bz = Bz_analytical_circular(r1, r2, z1, z2, self.dtheta, rp, tp)\n        return np.array([bx, 0, bz])\n\n    @process_xyz_array\n    def field(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate the magnetic field at a point due to the current source.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the field\n        y:\n            The y coordinate(s) of the points at which to calculate the field\n        z:\n            The z coordinate(s) of the points at which to calculate the field\n\n        Returns\n        -------\n        The magnetic field vector {Bx, By, Bz} in [T]\n        \"\"\"\n        point = np.array([x, y, z])\n        # Convert to local cylindrical coordinates\n        point = self._global_to_local([point])[0]\n        rp, tp, zp = self._local_to_cylindrical(point)\n        # Calculate field in local coordinates\n        b_local = MU_0_4PI * self.rho * self._BxByBz(rp, tp, zp)\n        # Convert field to global coordinates\n        return self.dcm.T @ b_local\n\n    def _calculate_points(self):\n        \"\"\"\n        Calculate extrema points of the current source for plotting and debugging.\n        \"\"\"\n        r = self.radius\n        a = self.breadth\n        b = self.depth\n\n        # Circle arcs\n        n = 200\n        theta = self.dtheta\n        ones = np.ones(n)\n        arc_1x, arc_1y = make_circle_arc(r - a, 0, 0, angle=theta, n_points=n)\n        arc_2x, arc_2y = make_circle_arc(r + a, 0, 0, angle=theta, n_points=n)\n        arc_3x, arc_3y = make_circle_arc(r + a, 0, 0, angle=theta, n_points=n)\n        arc_4x, arc_4y = make_circle_arc(r - a, 0, 0, angle=theta, n_points=n)\n        arc_1 = np.array([arc_1x, arc_1y, -b * ones]).T\n        arc_2 = np.array([arc_2x, arc_2y, -b * ones]).T\n        arc_3 = np.array([arc_3x, arc_3y, b * ones]).T\n        arc_4 = np.array([arc_4x, arc_4y, b * ones]).T\n\n        n_slices = int(2 + self.dtheta // (0.25 * np.pi))\n        slices = np.linspace(0, n - 1, n_slices, endpoint=True, dtype=int)\n        points = [arc_1, arc_2, arc_3, arc_4]\n\n        # Rectangles\n        for s in slices:\n            points.append(np.vstack([arc_1[s], arc_2[s], arc_3[s], arc_4[s], arc_1[s]]))\n\n        points_array = []\n        for p in points:\n            points_array.append(self._local_to_global(p))\n\n        return np.array(points_array, dtype=object)\n\n    def plot(self, ax: Optional[plt.Axes] = None, show_coord_sys: bool = False):\n        \"\"\"\n        Plot the CircularArcCurrentSource.\n\n        Parameters\n        ----------\n        ax: Union[None, Axes]\n            The matplotlib axes to plot on\n        show_coord_sys: bool\n            Whether or not to plot the coordinate systems\n        \"\"\"\n        super().plot(ax=ax, show_coord_sys=show_coord_sys)\n        ax = plt.gca()\n        theta = self.dtheta\n        x, y = make_circle_arc(\n            self.radius, 0, 0, angle=theta / 2, start_angle=theta / 4, n_points=200\n        )\n        centre_arc = np.array([x, y, np.zeros(200)]).T\n        points = self._local_to_global(centre_arc)\n        ax.plot(*points.T, color=\"r\")\n        ax.plot([points[-1][0]], [points[-1][1]], [points[-1][2]], marker=\"^\", color=\"r\")",
  "def __init__(\n        self,\n        origin: np.ndarray,\n        ds: np.ndarray,\n        normal: np.ndarray,\n        t_vec: np.ndarray,\n        breadth: float,\n        depth: float,\n        radius: float,\n        dtheta: float,\n        current: float,\n    ):\n        self.origin = origin\n        self._breadth = breadth\n        self.depth = depth\n        self.length = 0.5 * (breadth + depth)  # For plotting only\n        self._radius = radius\n        self._update_r1r2()\n\n        self.dtheta = np.deg2rad(dtheta)\n        self.rho = current / (4 * breadth * depth)\n        self.dcm = np.array([ds, normal, t_vec])\n        self.points = self._calculate_points()",
  "def radius(self) -> float:\n        \"\"\"\n        Get the radius of the CircularArcCurrentSource\n        \"\"\"\n        return self._radius",
  "def radius(self, radius: float):\n        \"\"\"\n        Set the radius.\n\n        Parameters\n        ----------\n        radius:\n            The radius of the CircularArcCurrentSource\n        \"\"\"\n        self._radius = radius\n        self._update_r1r2()",
  "def breadth(self) -> float:\n        \"\"\"\n        Get the breadth of the CircularArcCurrentSource.\n        \"\"\"\n        return self._breadth",
  "def breadth(self, breadth: float):\n        \"\"\"\n        Set the breadth of the CircularArcCurrentSource.\n\n        Parameters\n        ----------\n        breadth:\n            The breadth of the CircularArcCurrentSource\n        \"\"\"\n        self._breadth = breadth\n        self._update_r1r2()",
  "def _update_r1r2(self):\n        \"\"\"\n        Update\n        \"\"\"\n        self._r1 = self.radius - self.breadth\n        self._r2 = self.radius + self.breadth",
  "def _local_to_cylindrical(point: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Convert from local to cylindrical coordinates.\n        \"\"\"\n        x, y, z = point\n        rho = np.sqrt(x**2 + y**2)\n        theta = np.arctan2(y, x)\n        return np.array([rho, theta, z])",
  "def _cylindrical_to_working(self, zp: float) -> Tuple[float, float, float, float]:\n        \"\"\"\n        Convert from local cylindrical coordinates to working coordinates.\n        \"\"\"\n        z1 = zp + self.depth\n        z2 = zp - self.depth\n        return self._r1, self._r2, z1, z2",
  "def _BxByBz(self, rp: float, tp: float, zp: float) -> np.ndarray:\n        \"\"\"\n        Calculate the field at a point in local coordinates.\n        \"\"\"\n        r1, r2, z1, z2 = self._cylindrical_to_working(zp)\n        bx = Bx_analytical_circular(r1, r2, z1, z2, self.dtheta, rp, tp)\n        bz = Bz_analytical_circular(r1, r2, z1, z2, self.dtheta, rp, tp)\n        return np.array([bx, 0, bz])",
  "def field(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate the magnetic field at a point due to the current source.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the field\n        y:\n            The y coordinate(s) of the points at which to calculate the field\n        z:\n            The z coordinate(s) of the points at which to calculate the field\n\n        Returns\n        -------\n        The magnetic field vector {Bx, By, Bz} in [T]\n        \"\"\"\n        point = np.array([x, y, z])\n        # Convert to local cylindrical coordinates\n        point = self._global_to_local([point])[0]\n        rp, tp, zp = self._local_to_cylindrical(point)\n        # Calculate field in local coordinates\n        b_local = MU_0_4PI * self.rho * self._BxByBz(rp, tp, zp)\n        # Convert field to global coordinates\n        return self.dcm.T @ b_local",
  "def _calculate_points(self):\n        \"\"\"\n        Calculate extrema points of the current source for plotting and debugging.\n        \"\"\"\n        r = self.radius\n        a = self.breadth\n        b = self.depth\n\n        # Circle arcs\n        n = 200\n        theta = self.dtheta\n        ones = np.ones(n)\n        arc_1x, arc_1y = make_circle_arc(r - a, 0, 0, angle=theta, n_points=n)\n        arc_2x, arc_2y = make_circle_arc(r + a, 0, 0, angle=theta, n_points=n)\n        arc_3x, arc_3y = make_circle_arc(r + a, 0, 0, angle=theta, n_points=n)\n        arc_4x, arc_4y = make_circle_arc(r - a, 0, 0, angle=theta, n_points=n)\n        arc_1 = np.array([arc_1x, arc_1y, -b * ones]).T\n        arc_2 = np.array([arc_2x, arc_2y, -b * ones]).T\n        arc_3 = np.array([arc_3x, arc_3y, b * ones]).T\n        arc_4 = np.array([arc_4x, arc_4y, b * ones]).T\n\n        n_slices = int(2 + self.dtheta // (0.25 * np.pi))\n        slices = np.linspace(0, n - 1, n_slices, endpoint=True, dtype=int)\n        points = [arc_1, arc_2, arc_3, arc_4]\n\n        # Rectangles\n        for s in slices:\n            points.append(np.vstack([arc_1[s], arc_2[s], arc_3[s], arc_4[s], arc_1[s]]))\n\n        points_array = []\n        for p in points:\n            points_array.append(self._local_to_global(p))\n\n        return np.array(points_array, dtype=object)",
  "def plot(self, ax: Optional[plt.Axes] = None, show_coord_sys: bool = False):\n        \"\"\"\n        Plot the CircularArcCurrentSource.\n\n        Parameters\n        ----------\n        ax: Union[None, Axes]\n            The matplotlib axes to plot on\n        show_coord_sys: bool\n            Whether or not to plot the coordinate systems\n        \"\"\"\n        super().plot(ax=ax, show_coord_sys=show_coord_sys)\n        ax = plt.gca()\n        theta = self.dtheta\n        x, y = make_circle_arc(\n            self.radius, 0, 0, angle=theta / 2, start_angle=theta / 4, n_points=200\n        )\n        centre_arc = np.array([x, y, np.zeros(200)]).T\n        points = self._local_to_global(centre_arc)\n        ax.plot(*points.T, color=\"r\")\n        ax.plot([points[-1][0]], [points[-1][1]], [points[-1][2]], marker=\"^\", color=\"r\")",
  "def clip_nb(\n    val: Union[float, np.ndarray], val_min: float, val_max: float\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Clips (limits) val between val_min and val_max. Vectorised for speed and\n    compatibility with numba.\n\n    Parameters\n    ----------\n    val:\n        The value to be clipped.\n    val_min:\n        The minimum value.\n    val_max:\n        The maximum value.\n\n    Returns\n    -------\n    The clipped values.\n    \"\"\"\n    if val < val_min:\n        return val_min\n    elif val > val_max:\n        return val_max\n    return val",
  "def ellipe_nb(k: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n    \"\"\"\n    Vectorised scipy ellipe\n\n    Notes\n    -----\n    K, E in scipy are set as K(k^2), E(k^2)\n    \"\"\"\n    return ellipe(k)",
  "def ellipk_nb(k: Union[float, np.ndarray]) -> Union[float, np.ndarray]:\n    \"\"\"\n    Vectorised scipy ellipk\n\n    Notes\n    -----\n    K, E in scipy are set as K(k^2), E(k^2)\n    \"\"\"\n    return ellipk(k)",
  "def circular_coil_inductance_elliptic(radius: float, rc: float) -> float:\n    \"\"\"\n    Calculate the inductance of a circular coil by elliptic integrals.\n\n    Parameters\n    ----------\n    radius:\n        The radius of the circular coil\n    rc:\n        The radius of the coil cross-section\n\n    Returns\n    -------\n    The self-inductance of the circular coil [H]\n    \"\"\"\n    k = 4 * radius * (radius - rc) / (2 * radius - rc) ** 2\n    args = (\n        np.array(arg, dtype=np.float64) for arg in (k, GREENS_ZERO, 1.0 - GREENS_ZERO)\n    )\n    k = clip_nb(*args)\n    return MU_0 * (2 * radius - rc) * ((1 - k**2 / 2) * ellipk(k) - ellipe(k))",
  "def circular_coil_inductance_kirchhoff(radius: float, rc: float) -> float:\n    \"\"\"\n    Calculate the inductance of a circular coil by Kirchhoff's approximation.\n\n    radius:\n        The radius of the circular coil\n    rc:\n        The radius of the coil cross-section\n\n    Returns\n    -------\n    The self-inductance of the circular coil [H]\n    \"\"\"\n    return MU_0 * radius * (np.log(8 * radius / rc) - 2 + 0.25)",
  "def greens_psi(\n    xc: Union[float, np.ndarray],\n    zc: Union[float, np.ndarray],\n    x: Union[float, np.ndarray],\n    z: Union[float, np.ndarray],\n    d_xc: float = 0,\n    d_zc: float = 0,\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Calculate poloidal flux at (x, z) due to a unit current at (xc, zc)\n    using a Greens function.\n\n    Parameters\n    ----------\n    xc:\n        Coil x coordinates [m]\n    zc:\n        Coil z coordinates [m]\n    x:\n        Calculation x locations\n    z:\n        Calculation z locations\n    d_xc:\n        The coil half-width (overload argument)\n    d_zc:\n        The coil half-height (overload argument)\n\n    Returns\n    -------\n    Poloidal magnetic flux per radian response at (x, z)\n\n    Raises\n    ------\n    ZeroDivisionError\n        if xc <= 0\n\n    Notes\n    -----\n    \\t:math:`G_{\\\\psi}(x_{c}, z_{c}; x, z) = \\\\dfrac{{\\\\mu}_{0}}{2{\\\\pi}}`\n    \\t:math:`\\\\dfrac{\\\\sqrt{xx_{c}}}{k}`\n    \\t:math:`[(2-\\\\mathbf{K}(k^2)-2\\\\mathbf{E}(k^2)]`\\n\n    Where:\n    \\t:math:`k^{2}\\\\equiv\\\\dfrac{4xx_{c}}{(x+x_{c})^{2}+(z-z_{c})^{2}}`\\n\n    \\t:math:`\\\\mathbf{K} \\\\equiv` complete elliptic integral of the first kind\\n\n    \\t:math:`\\\\mathbf{E} \\\\equiv` complete elliptic integral of the second kind\n    \"\"\"\n    k2 = 4 * x * xc / ((x + xc) ** 2 + (z - zc) ** 2)\n    # Avoid NaN when coil on grid point\n    k2 = clip_nb(k2, GREENS_ZERO, 1.0 - GREENS_ZERO)\n    return (\n        MU_0_2PI\n        * np.sqrt(x * xc)\n        * ((2 - k2) * ellipk_nb(k2) - 2 * ellipe_nb(k2))\n        / np.sqrt(k2)\n    )",
  "def greens_dpsi_dx(\n    xc: Union[float, np.ndarray],\n    zc: Union[float, np.ndarray],\n    x: Union[float, np.ndarray],\n    z: Union[float, np.ndarray],\n    d_xc: float = 0,\n    d_zc: float = 0,\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Calculate the radial derivative of the poloidal flux at (x, z)\n    due to a unit current at (xc, zc) using a Greens function.\n\n    Parameters\n    ----------\n    xc:\n        Coil x coordinates [m]\n    zc:\n        Coil z coordinates [m]\n    x:\n        Calculation x locations\n    z:\n        Calculation z locations\n    d_xc:\n        The coil half-width (overload argument)\n    d_zc:\n        The coil half-height (overload argument)\n\n    Returns\n    -------\n    Radial derivative of the poloidal flux response at (x, z)\n\n    Notes\n    -----\n    \\t:math:`G_{\\\\dfrac{\\\\partial \\\\psi}{\\\\partial x}}(x_{c}, z_{c}; x, z) =`\n    \\t:math:`\\\\dfrac{\\\\mu_0}{2\\\\pi}`\n    \\t:math:`\\\\dfrac{1}{u}`\n    \\t:math:`[\\\\dfrac{w^2}{d^2}\\\\mathbf{E}(k^2)+\\\\mathbf{K}(k^2)]`\\n\n    Where:\n    \\t:math:`h^{2}\\\\equiv z_{c}-z`\\n\n    \\t:math:`u^2\\\\equiv(x+x_{c})^2+h^2`\\n\n    \\t:math:`d^{2}\\\\equiv (x - x_{c})^2 + h^2`\\n\n    \\t:math:`w^{2}\\\\equiv x^2 -x_{c}^2 - h^2`\\n\n    \\t:math:`k^{2}\\\\equiv\\\\dfrac{4xx_{c}}{(x+x_{c})^{2}+(z-z_{c})^{2}}`\\n\n    \\t:math:`\\\\mathbf{K} \\\\equiv` complete elliptic integral of the first kind\\n\n    \\t:math:`\\\\mathbf{E} \\\\equiv` complete elliptic integral of the second kind\n\n    The implementation used here refactors the above to avoid some zero divisions.\n    \"\"\"\n    a = ((x + xc) ** 2 + (z - zc) ** 2) ** 0.5\n    k2 = 4 * x * xc / a**2\n    # Avoid NaN when coil on grid point\n    k2 = clip_nb(k2, GREENS_ZERO, 1.0 - GREENS_ZERO)\n    i1 = ellipk_nb(k2) / a\n    i2 = ellipe_nb(k2) / (a**3 * (1 - k2))\n    return MU_0_2PI * x * ((xc**2 - (z - zc) ** 2 - x**2) * i2 + i1)",
  "def greens_dpsi_dz(\n    xc: Union[float, np.ndarray],\n    zc: Union[float, np.ndarray],\n    x: Union[float, np.ndarray],\n    z: Union[float, np.ndarray],\n    d_xc: float = 0,\n    d_zc: float = 0,\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Calculate the vertical derivative of the poloidal flux at (x, z)\n    due to a unit current at (xc, zc) using a Greens function.\n\n    Parameters\n    ----------\n    xc:\n        Coil x coordinates [m]\n    zc:\n        Coil z coordinates [m]\n    x:\n        Calculation x locations\n    z:\n        Calculation z locations\n    d_xc:\n        The coil half-width (overload argument)\n    d_zc:\n        The coil half-height (overload argument)\n\n    Returns\n    -------\n    Vertical derivative of the poloidal flux response at (x, z)\n\n    Notes\n    -----\n    \\t:math:`G_{\\\\dfrac{\\\\partial \\\\psi}{\\\\partial z}}(x_{c}, z_{c}; x, z) =`\n    \\t:math:`\\\\dfrac{\\\\mu_0}{2\\\\pi}`\n    \\t:math:`\\\\dfrac{h}{u}`\n    \\t:math:`[\\\\mathbf{K}(k^2) - \\\\dfrac{v^2}{d^2}\\\\mathbf{E}(k^2)]`\\n\n    Where:\n    \\t:math:`h^{2}\\\\equiv z_{c}-z`\\n\n    \\t:math:`u^2\\\\equiv(x+x_{c})^2+h^2`\\n\n    \\t:math:`d^{2}\\\\equiv (x - x_{c})^2 + h^2`\\n\n    \\t:math:`v^{2}\\\\equiv x^2 +x_{c}^2 + h^2`\\n\n    \\t:math:`k^{2}\\\\equiv\\\\dfrac{4xx_{c}}{(x+x_{c})^{2}+(z-z_{c})^{2}}`\\n\n    \\t:math:`\\\\mathbf{K} \\\\equiv` complete elliptic integral of the first kind\\n\n    \\t:math:`\\\\mathbf{E} \\\\equiv` complete elliptic integral of the second kind\n\n    The implementation used here refactors the above to avoid some zero divisions.\n    \"\"\"\n    a = ((x + xc) ** 2 + (z - zc) ** 2) ** 0.5\n    k2 = 4 * x * xc / a**2\n    k2 = clip_nb(k2, GREENS_ZERO, 1.0 - GREENS_ZERO)\n    i1 = ellipk_nb(k2) / a\n    i2 = ellipe_nb(k2) / (a**3 * (1 - k2))\n    return MU_0_2PI * ((z - zc) * (i1 - i2 * ((z - zc) ** 2 + x**2 + xc**2)))",
  "def greens_Bx(\n    xc: Union[float, np.ndarray],\n    zc: Union[float, np.ndarray],\n    x: Union[float, np.ndarray],\n    z: Union[float, np.ndarray],\n    d_xc: float = 0,\n    d_zc: float = 0,\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Calculate radial magnetic field at (x, z) due to unit current at (xc, zc)\n    using a Greens function.\n\n    Parameters\n    ----------\n    xc:\n        Coil x coordinates [m]\n    zc:\n        Coil z coordinates [m]\n    x:\n        Calculation x locations\n    z:\n        Calculation z locations\n    d_xc:\n        The coil half-width (overload argument)\n    d_zc:\n        The coil half-height (overload argument)\n\n    Returns\n    -------\n    Radial magnetic field response at (x, z)\n\n    Raises\n    ------\n    ZeroDivisionError\n        if x == 0\n\n    Notes\n    -----\n    \\t:math:`G_{B_{x}}(x_{c}, z_{c}; x, z) = -\\\\dfrac{1}{x}`\n    \\t:math:`G_{\\\\dfrac{\\\\partial \\\\psi}{\\\\partial z}}`\n    \\t:math:`(x_{c}, z_{c}; x, z)`\n    \"\"\"\n    return -1 / x * greens_dpsi_dz(xc, zc, x, z, d_xc, d_zc)",
  "def greens_Bz(\n    xc: Union[float, np.ndarray],\n    zc: Union[float, np.ndarray],\n    x: Union[float, np.ndarray],\n    z: Union[float, np.ndarray],\n    d_xc: float = 0,\n    d_zc: float = 0,\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Calculate vertical magnetic field at (x, z) due to unit current at (xc, zc)\n    using a Greens function.\n\n    Parameters\n    ----------\n    xc:\n        Coil x coordinates [m]\n    zc:\n        Coil z coordinates [m]\n    x:\n        Calculation x locations\n    z:\n        Calculation z locations\n    d_xc:\n        The coil half-width (overload argument)\n    d_zc:\n        The coil half-height (overload argument)\n\n    Returns\n    -------\n    Vertical magnetic field response at (x, z)\n\n    Raises\n    ------\n    ZeroDivisionError\n        if x == 0\n\n    Notes\n    -----\n    \\t:math:`G_{B_{z}}(x_{c}, z_{c}; x, z) = \\\\dfrac{1}{x}`\n    \\t:math:`G_{\\\\dfrac{\\\\partial \\\\psi}{\\\\partial x}}`\n    \\t:math:`(x_{c}, z_{c}; x, z)`\n    \"\"\"\n    return 1 / x * greens_dpsi_dx(xc, zc, x, z, d_xc, d_zc)",
  "def greens_all(\n    xc: Union[float, np.ndarray],\n    zc: Union[float, np.ndarray],\n    x: Union[float, np.ndarray],\n    z: Union[float, np.ndarray],\n) -> Tuple[Union[float, np.ndarray], Union[float, np.ndarray], Union[float, np.ndarray]]:\n    \"\"\"\n    Speed optimisation of Green's functions for psi, Bx, and Bz\n\n    Parameters\n    ----------\n    xc:\n        Coil x coordinates [m]\n    zc:\n        Coil z coordinates [m]\n    x:\n        Calculation x locations\n    z:\n        Calculation z locations\n\n    Returns\n    -------\n    psi:\n        Poloidal magnetic flux per radian response at (x, z)\n    Bx:\n        Radial magnetic field response at (x, z)\n    Bz:\n        Vertical magnetic field response at (x, z)\n\n    Raises\n    ------\n    ZeroDivisionError\n        if xc <= 0\n        if x <= 0\n    \"\"\"\n    a = np.hypot((x + xc), (z - zc))\n    k2 = 4 * x * xc / a**2\n    # Avoid NaN when coil on grid point\n    k2 = clip_nb(k2, GREENS_ZERO, 1.0 - GREENS_ZERO)\n    e, k = ellipe_nb(k2), ellipk_nb(k2)\n    i_1 = 4 * k / a\n    i_2 = 4 * e / (a**3 * (1 - k2))\n    a_part = (z - zc) ** 2 + x**2 + xc**2\n    b_part = -2 * x * xc\n    g_bx = MU_0_4PI * xc * (z - zc) * (i_1 - i_2 * a_part) / b_part\n    g_bz = MU_0_4PI * xc * ((xc + x * a_part / b_part) * i_2 - i_1 * x / b_part)\n    g_psi = MU_0_4PI * a * ((2 - k2) * k - 2 * e)\n    return g_psi, g_bx, g_bz",
  "class MagnetostaticsError(BluemiraError):\n    \"\"\"\n    The base class for magnetostatics errors.\n    \"\"\"\n\n    pass",
  "class MagnetostaticsIntegrationError(MagnetostaticsError):\n    \"\"\"\n    Error class for integration errors in magnetostatics.\n    \"\"\"\n\n    pass",
  "def primitive_sxn_bound(\n    cos_theta: float, sin_theta: float, r: float, q: float, t: float\n) -> float:\n    \"\"\"\n    Function primitive of Bx evaluated at a bound.\n\n    Parameters\n    ----------\n    cos_theta:\n        The cosine of theta in radians\n    sin_theta:\n        The sine of theta in radians\n    r:\n        The r local coordinate value\n    q:\n        The q local coordinate value\n    t:\n        The t local coordinate value\n\n    Returns\n    -------\n    The value of the primitive function at integral bound t\n\n    Notes\n    -----\n    Uses corrected formulae available at:\n    https://onlinelibrary.wiley.com/doi/abs/10.1002/jnm.675\n\n    Singularities all resolve to: lim(ln(1)) --> 0\n    \"\"\"\n    # First compute the divisors of each of the terms to determine if there\n    # are singularities\n    divisor_1 = cos_theta * np.sqrt(t**2 + q**2)\n    divisor_2 = cos_theta * np.sqrt(r**2 * cos_theta**2 + q**2)\n    divisor_3 = q * np.sqrt(\n        t**2 + 2 * r * t * sin_theta * cos_theta + (r**2 + q**2) * cos_theta**2\n    )\n\n    # All singularities resolve to 0?\n    result = 0\n    if divisor_1 != 0:\n        result += t * np.arcsinh((t * sin_theta + r * cos_theta) / divisor_1)\n    if divisor_2 != 0:\n        result += r * cos_theta * np.arcsinh((t + r * cos_theta * sin_theta) / divisor_2)\n    if divisor_3 != 0:\n        result += q * np.arctan((q**2 * sin_theta - t * r * cos_theta) / divisor_3)\n\n    return result",
  "def primitive_sxn(theta: float, r: float, q: float, l1: float, l2: float) -> float:\n    \"\"\"\n    Analytical integral of Bx function primitive.\n\n    Parameters\n    ----------\n    theta:\n        The angle in radians\n    r:\n        The r local coordinate value\n    q:\n        The q local coordinate value\n    l1:\n        The first local coordinate bound\n    l2:\n        The second local coordinate bound\n\n    Returns\n    -------\n    The value of the integral of the Bx function primitive\n    \"\"\"\n    cos_theta, sin_theta = np.cos(theta), np.sin(theta)\n    return primitive_sxn_bound(cos_theta, sin_theta, r, q, l2) - primitive_sxn_bound(\n        cos_theta, sin_theta, r, q, l1\n    )",
  "def primitive_szn_bound(\n    cos_theta: float, sin_theta: float, r: float, ll: float, t: float\n) -> float:\n    \"\"\"\n    Function primitive of Bz evaluated at a bound.\n\n    Parameters\n    ----------\n    cos_theta:\n        The cosine of theta\n    sin_theta:\n        The sine of theta\n    r:\n        The r local coordinate value\n    ll:\n        The l local coordinate value\n    t:\n        The t local coordinate value\n\n    Returns\n    -------\n    The value of the primitive function at integral bound t\n\n    Notes\n    -----\n    Singularities all resolve to: lim(ln(1)) --> 0\n    \"\"\"\n    sqrt_term = np.sqrt(\n        t**2 * cos_theta**2\n        + ll**2\n        + 2 * r * ll * sin_theta * cos_theta\n        + r**2 * cos_theta**2\n    )\n\n    # First compute the divisors of each of the terms to determine if there\n    # are singularities\n    divisor_1 = cos_theta * np.sqrt(t**2 + r**2 * cos_theta**2)\n    divisor_2 = cos_theta * np.sqrt(t**2 + ll**2)\n    divisor_3 = np.sqrt(\n        ll**2 + 2 * ll * r * sin_theta * cos_theta + r**2 * cos_theta**2\n    )\n    divisor_4 = r * cos_theta * sqrt_term\n    divisor_5 = ll * sqrt_term\n\n    # All singularities resolve to 0?\n    result = 0\n    if divisor_1 != 0:\n        result += (\n            t * sin_theta * np.arcsinh((ll + r * sin_theta * cos_theta) / divisor_1)\n        )\n    if divisor_2 != 0:\n        result -= t * np.arcsinh((ll * sin_theta + r * cos_theta) / divisor_2)\n    if divisor_3 != 0:\n        result -= r * cos_theta**2 * np.arcsinh((t * cos_theta) / divisor_3)\n    if divisor_4 != 0:\n        result -= (\n            r\n            * cos_theta\n            * sin_theta\n            * np.arctan((t * (ll + r * sin_theta * cos_theta)) / divisor_4)\n        )\n    if divisor_5 != 0:\n        result += ll * np.arctan((t * (ll * sin_theta + r * cos_theta)) / divisor_5)\n\n    return result",
  "def primitive_szn(theta: float, r: float, ll: float, q1: float, q2: float) -> float:\n    \"\"\"\n    Analytical integral of Bz function primitive.\n\n    Parameters\n    ----------\n    theta:\n        The angle in radians\n    r:\n        The r local coordinate value\n    ll:\n        The l local coordinate value\n    q1:\n        The first local coordinate bound\n    q2:\n        The second local coordinate bound\n\n    Returns\n    -------\n    The value of the integral of the Bx function primitive\n    \"\"\"\n    cos_theta, sin_theta = np.cos(theta), np.sin(theta)\n    return primitive_szn_bound(cos_theta, sin_theta, r, ll, q2) - primitive_szn_bound(\n        cos_theta, sin_theta, r, ll, q1\n    )",
  "def Bx_analytical_prism(\n    alpha: float,\n    beta: float,\n    l1: float,\n    l2: float,\n    q1: float,\n    q2: float,\n    r1: float,\n    r2: float,\n) -> float:\n    \"\"\"\n    Calculate magnetic field in the local x coordinate direction due to a\n    trapezoidal prism current source.\n\n    Parameters\n    ----------\n    alpha:\n        The first trapezoidal angle [rad]\n    beta:\n        The second trapezoidal angle [rad]\n    l1:\n        The local l1 coordinate [m]\n    l2:\n        The local l2 coordinate [m]\n    q1:\n        The local q1 coordinate [m]\n    q2:\n        The local q2 coordinate [m]\n    r1:\n        The local r1 coordinate [m]\n    r2: float\n        The local r2 coordinate [m]\n\n    Returns\n    -------\n    The magnetic field response in the x coordinate direction\n    \"\"\"\n    return (\n        primitive_sxn(alpha, r1, q2, l1, l2)\n        - primitive_sxn(alpha, r1, q1, l1, l2)\n        + primitive_sxn(beta, r2, q2, l1, l2)\n        - primitive_sxn(beta, r2, q1, l1, l2)\n    )",
  "def Bz_analytical_prism(\n    alpha: float,\n    beta: float,\n    l1: float,\n    l2: float,\n    q1: float,\n    q2: float,\n    r1: float,\n    r2: float,\n) -> float:\n    \"\"\"\n    Calculate magnetic field in the local z coordinate direction due to a\n    trapezoidal prism current source.\n\n    Parameters\n    ----------\n    alpha:\n        The first trapezoidal angle [rad]\n    beta:\n        The second trapezoidal angle [rad]\n    l1:\n        The local l1 coordinate [m]\n    l2:\n        The local l2 coordinate [m]\n    q1:\n        The local q1 coordinate [m]\n    q2:\n        The local q2 coordinate [m]\n    r1:\n        The local r1 coordinate [m]\n    r2:\n        The local r2 coordinate [m]\n\n    Returns\n    -------\n    The magnetic field response in the z coordinate direction\n    \"\"\"\n    return (\n        primitive_szn(alpha, r1, l2, q1, q2)\n        - primitive_szn(alpha, r1, l1, q1, q2)\n        + primitive_szn(beta, r2, l2, q1, q2)\n        - primitive_szn(beta, r2, l1, q1, q2)\n    )",
  "class TrapezoidalPrismCurrentSource(RectangularCrossSectionCurrentSource):\n    \"\"\"\n    3-D trapezoidal prism current source with a rectangular cross-section and\n    uniform current distribution.\n\n    The current direction is along the local y coordinate.\n\n    Parameters\n    ----------\n    origin:\n        The origin of the current source in global coordinates [m]\n    ds:\n        The direction vector of the current source in global coordinates [m]\n    normal:\n        The normalised normal vector of the current source in global coordinates [m]\n    t_vec:\n        The normalised tangent vector of the current source in global coordinates [m]\n    breadth:\n        The breadth of the current source (half-width) [m]\n    depth:\n        The depth of the current source (half-height) [m]\n    alpha:\n        The first angle of the trapezoidal prism [\u00b0] [0, 180)\n    beta:\n        The second angle of the trapezoidal prism [\u00b0] [0, 180)\n    current:\n        The current flowing through the source [A]\n\n    Notes\n    -----\n    Negative angles are allowed, but both angles must be either 0 or negative.\n    \"\"\"\n\n    def __init__(\n        self,\n        origin: np.ndarray,\n        ds: np.ndarray,\n        normal: np.ndarray,\n        t_vec: np.ndarray,\n        breadth: float,\n        depth: float,\n        alpha: float,\n        beta: float,\n        current: float,\n    ):\n        alpha, beta = np.deg2rad(alpha), np.deg2rad(beta)\n        self.origin = origin\n\n        length = np.linalg.norm(ds)\n        self._check_angle_values(alpha, beta)\n        self._check_raise_self_intersection(length, breadth, alpha, beta)\n        self._halflength = 0.5 * length\n        # Normalised direction cosine matrix\n        self.dcm = np.array([t_vec, ds / length, normal])\n        self.length = 0.5 * (length - breadth * np.tan(alpha) - breadth * np.tan(beta))\n        self.breadth = breadth\n        self.depth = depth\n        self.alpha = alpha\n        self.beta = beta\n        # Current density\n        self.rho = current / (4 * breadth * depth)\n        self.points = self._calculate_points()\n\n    def _check_angle_values(self, alpha, beta):\n        \"\"\"\n        Check that end-cap angles are acceptable.\n        \"\"\"\n        sign_alpha = np.sign(alpha)\n        sign_beta = np.sign(beta)\n        one_zero = np.any(np.array([sign_alpha, sign_beta]) == 0.0)\n        if not one_zero and sign_alpha != sign_beta:\n            raise MagnetostaticsError(\n                f\"{self.__class__.__name__} instantiation error: end-cap angles \"\n                f\"must have the same sign {alpha=:.3f}, {beta=:.3f}.\"\n            )\n        if not (0 <= abs(alpha) < 0.5 * np.pi):\n            raise MagnetostaticsError(\n                f\"{self.__class__.__name__} instantiation error: {alpha=:.3f} is outside \"\n                \"bounds of [0, 180\u00b0).\"\n            )\n        if not (0 <= abs(beta) < 0.5 * np.pi):\n            raise MagnetostaticsError(\n                f\"{self.__class__.__name__} instantiation error: {beta=:.3f} is outside \"\n                \"bounds of [0, 180\u00b0).\"\n            )\n\n    def _check_raise_self_intersection(\n        self, length: float, breadth: float, alpha: float, beta: float\n    ):\n        \"\"\"\n        Check for bad combinations of source length and end-cap angles.\n        \"\"\"\n        a = np.tan(alpha) * breadth\n        b = np.tan(beta) * breadth\n        if (a + b) > length:\n            raise MagnetostaticsError(\n                f\"{self.__class__.__name__} instantiation error: source length and \"\n                \"angles imply a self-intersecting trapezoidal prism.\"\n            )\n\n    def _xyzlocal_to_rql(self, x_local, y_local, z_local):\n        \"\"\"\n        Convert local x, y, z coordinates to working coordinates.\n        \"\"\"\n        b = self.length\n        c = self.depth\n        d = self.breadth\n\n        l1 = -d - x_local\n        l2 = d - x_local\n        q1 = -c - z_local\n        q2 = c - z_local\n        r1 = (d + x_local) * np.tan(self.alpha) + b - y_local\n        r2 = (d + x_local) * np.tan(self.beta) + b + y_local\n        return l1, l2, q1, q2, r1, r2\n\n    def _BxByBz(self, point):\n        \"\"\"\n        Calculate the field at a point in local coordinates.\n        \"\"\"\n        l1, l2, q1, q2, r1, r2 = self._xyzlocal_to_rql(*point)\n        bx = Bx_analytical_prism(self.alpha, self.beta, l1, l2, q1, q2, r1, r2)\n        bz = Bz_analytical_prism(self.alpha, self.beta, l1, l2, q1, q2, r1, r2)\n        return np.array([bx, 0, bz])\n\n    @process_xyz_array\n    def field(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate the magnetic field at a point due to the current source.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the field\n        y:\n            The y coordinate(s) of the points at which to calculate the field\n        z:\n            The z coordinate(s) of the points at which to calculate the field\n\n        Returns\n        -------\n        The magnetic field vector {Bx, By, Bz} in [T]\n        \"\"\"\n        point = np.array([x, y, z])\n        # Convert to local coordinates\n        point = self._global_to_local([point])[0]\n        # Evaluate field in local coordinates\n        b_local = MU_0_4PI * self.rho * self._BxByBz(point)\n        # Convert vector back to global coordinates\n        return self.dcm.T @ b_local\n\n    def _calculate_points(self):\n        \"\"\"\n        Calculate extrema points of the current source for plotting and debugging.\n        \"\"\"\n        b = self._halflength\n        c = self.depth\n        d = self.breadth\n        # Lower rectangle\n        p1 = np.array([-d, -b + d * np.tan(self.beta), -c])\n        p2 = np.array([d, -b - d * np.tan(self.beta), -c])\n        p3 = np.array([d, -b - d * np.tan(self.beta), c])\n        p4 = np.array([-d, -b + d * np.tan(self.beta), c])\n\n        # Upper rectangle\n        p5 = np.array([-d, b - d * np.tan(self.alpha), -c])\n        p6 = np.array([d, b + d * np.tan(self.alpha), -c])\n        p7 = np.array([d, b + d * np.tan(self.alpha), c])\n        p8 = np.array([-d, b - d * np.tan(self.alpha), c])\n\n        points_array = []\n        points = [\n            np.vstack([p1, p2, p3, p4, p1]),\n            np.vstack([p5, p6, p7, p8, p5]),\n            # Lines between rectangle corners\n            np.vstack([p1, p5]),\n            np.vstack([p2, p6]),\n            np.vstack([p3, p7]),\n            np.vstack([p4, p8]),\n        ]\n\n        for p in points:\n            points_array.append(self._local_to_global(p))\n\n        return np.array(points_array, dtype=object)",
  "def __init__(\n        self,\n        origin: np.ndarray,\n        ds: np.ndarray,\n        normal: np.ndarray,\n        t_vec: np.ndarray,\n        breadth: float,\n        depth: float,\n        alpha: float,\n        beta: float,\n        current: float,\n    ):\n        alpha, beta = np.deg2rad(alpha), np.deg2rad(beta)\n        self.origin = origin\n\n        length = np.linalg.norm(ds)\n        self._check_angle_values(alpha, beta)\n        self._check_raise_self_intersection(length, breadth, alpha, beta)\n        self._halflength = 0.5 * length\n        # Normalised direction cosine matrix\n        self.dcm = np.array([t_vec, ds / length, normal])\n        self.length = 0.5 * (length - breadth * np.tan(alpha) - breadth * np.tan(beta))\n        self.breadth = breadth\n        self.depth = depth\n        self.alpha = alpha\n        self.beta = beta\n        # Current density\n        self.rho = current / (4 * breadth * depth)\n        self.points = self._calculate_points()",
  "def _check_angle_values(self, alpha, beta):\n        \"\"\"\n        Check that end-cap angles are acceptable.\n        \"\"\"\n        sign_alpha = np.sign(alpha)\n        sign_beta = np.sign(beta)\n        one_zero = np.any(np.array([sign_alpha, sign_beta]) == 0.0)\n        if not one_zero and sign_alpha != sign_beta:\n            raise MagnetostaticsError(\n                f\"{self.__class__.__name__} instantiation error: end-cap angles \"\n                f\"must have the same sign {alpha=:.3f}, {beta=:.3f}.\"\n            )\n        if not (0 <= abs(alpha) < 0.5 * np.pi):\n            raise MagnetostaticsError(\n                f\"{self.__class__.__name__} instantiation error: {alpha=:.3f} is outside \"\n                \"bounds of [0, 180\u00b0).\"\n            )\n        if not (0 <= abs(beta) < 0.5 * np.pi):\n            raise MagnetostaticsError(\n                f\"{self.__class__.__name__} instantiation error: {beta=:.3f} is outside \"\n                \"bounds of [0, 180\u00b0).\"\n            )",
  "def _check_raise_self_intersection(\n        self, length: float, breadth: float, alpha: float, beta: float\n    ):\n        \"\"\"\n        Check for bad combinations of source length and end-cap angles.\n        \"\"\"\n        a = np.tan(alpha) * breadth\n        b = np.tan(beta) * breadth\n        if (a + b) > length:\n            raise MagnetostaticsError(\n                f\"{self.__class__.__name__} instantiation error: source length and \"\n                \"angles imply a self-intersecting trapezoidal prism.\"\n            )",
  "def _xyzlocal_to_rql(self, x_local, y_local, z_local):\n        \"\"\"\n        Convert local x, y, z coordinates to working coordinates.\n        \"\"\"\n        b = self.length\n        c = self.depth\n        d = self.breadth\n\n        l1 = -d - x_local\n        l2 = d - x_local\n        q1 = -c - z_local\n        q2 = c - z_local\n        r1 = (d + x_local) * np.tan(self.alpha) + b - y_local\n        r2 = (d + x_local) * np.tan(self.beta) + b + y_local\n        return l1, l2, q1, q2, r1, r2",
  "def _BxByBz(self, point):\n        \"\"\"\n        Calculate the field at a point in local coordinates.\n        \"\"\"\n        l1, l2, q1, q2, r1, r2 = self._xyzlocal_to_rql(*point)\n        bx = Bx_analytical_prism(self.alpha, self.beta, l1, l2, q1, q2, r1, r2)\n        bz = Bz_analytical_prism(self.alpha, self.beta, l1, l2, q1, q2, r1, r2)\n        return np.array([bx, 0, bz])",
  "def field(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> Union[float, np.ndarray]:\n        \"\"\"\n        Calculate the magnetic field at a point due to the current source.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the field\n        y:\n            The y coordinate(s) of the points at which to calculate the field\n        z:\n            The z coordinate(s) of the points at which to calculate the field\n\n        Returns\n        -------\n        The magnetic field vector {Bx, By, Bz} in [T]\n        \"\"\"\n        point = np.array([x, y, z])\n        # Convert to local coordinates\n        point = self._global_to_local([point])[0]\n        # Evaluate field in local coordinates\n        b_local = MU_0_4PI * self.rho * self._BxByBz(point)\n        # Convert vector back to global coordinates\n        return self.dcm.T @ b_local",
  "def _calculate_points(self):\n        \"\"\"\n        Calculate extrema points of the current source for plotting and debugging.\n        \"\"\"\n        b = self._halflength\n        c = self.depth\n        d = self.breadth\n        # Lower rectangle\n        p1 = np.array([-d, -b + d * np.tan(self.beta), -c])\n        p2 = np.array([d, -b - d * np.tan(self.beta), -c])\n        p3 = np.array([d, -b - d * np.tan(self.beta), c])\n        p4 = np.array([-d, -b + d * np.tan(self.beta), c])\n\n        # Upper rectangle\n        p5 = np.array([-d, b - d * np.tan(self.alpha), -c])\n        p6 = np.array([d, b + d * np.tan(self.alpha), -c])\n        p7 = np.array([d, b + d * np.tan(self.alpha), c])\n        p8 = np.array([-d, b - d * np.tan(self.alpha), c])\n\n        points_array = []\n        points = [\n            np.vstack([p1, p2, p3, p4, p1]),\n            np.vstack([p5, p6, p7, p8, p5]),\n            # Lines between rectangle corners\n            np.vstack([p1, p5]),\n            np.vstack([p2, p6]),\n            np.vstack([p3, p7]),\n            np.vstack([p4, p8]),\n        ]\n\n        for p in points:\n            points_array.append(self._local_to_global(p))\n\n        return np.array(points_array, dtype=object)",
  "class BiotSavartFilament(CurrentSource):\n    \"\"\"\n    Class to calculate field and vector potential from an arbitrary filament.\n\n    Parameters\n    ----------\n    arrays:\n        The arbitrarily shaped closed current Coordinates. Alternatively provide the\n        list of Coordinates objects.\n    radius:\n        The nominal radius of the coil [m].\n    current:\n        The current flowing through the filament [A]. Defaults to 1 A to enable\n        current to be optimised separately from the field response.\n    \"\"\"\n\n    def __init__(\n        self,\n        arrays: Union[Coordinates, np.ndarray, List[Coordinates], List[np.ndarray]],\n        radius: float,\n        current: float = 1.0,\n    ):\n        if not isinstance(arrays, list):\n            # Handle single Coordinates/array\n            arrays = [arrays]\n        arrays = [process_coords_array(array) for array in arrays]\n\n        # Handle list of Coordinates/arrays (potentially of different sizes)\n        d_ls, mids_points = [], []\n        points = []\n        for i, xyz in enumerate(arrays):\n            d_l = np.diff(xyz, axis=0)\n            self._check_discretisation(d_l)\n\n            mid_points = xyz[:-1, :] + 0.5 * d_l\n            d_ls.append(d_l)\n            points.append(xyz[:-1, :])\n            mids_points.append(mid_points)\n            if i == 0:\n                # Take the first Coordinates as a reference for inductance calculation\n                self.ref_mid_points = mid_points\n                self.ref_d_l = d_l\n\n                lengths = np.sqrt(np.sum(d_l**2, axis=1))\n                self.length = np.sum(lengths)\n                self.length_scale = np.min(lengths)\n\n        # Assemble arrays and vector\n        self.d_l = np.vstack(d_ls)\n        self.d_l_hat = np.linalg.norm(self.d_l, axis=1)\n        self.mid_points = np.vstack(mids_points)\n        self.points = np.vstack(points)\n        self._arrays = arrays\n        self.radius = radius\n        self.current = current\n\n    def _check_discretisation(self, d_l: np.ndarray):\n        \"\"\"\n        Check the discretisation of the array.\n        \"\"\"\n        lengths = np.sqrt(np.sum(d_l**2, axis=1))\n        total = np.sum(lengths)\n        max_d_l = np.max(lengths)\n        if max_d_l > 0.03 * total:\n            bluemira_warn(\"Biot-Savart discretisation possibly insufficient.\")\n        # TODO: Improve check and modify discretisation\n\n    @process_xyz_array\n    def potential(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate the vector potential of an arbitrarily shaped Coordinates.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the potential\n        y:\n            The y coordinate(s) of the points at which to calculate the potential\n        z:\n            The z coordinate(s) of the points at which to calculate the potential\n\n\n        Returns\n        -------\n        The vector potential at the point due to the arbitrarily shaped Coordinates\n        \"\"\"\n        point = np.array([x, y, z])\n        r = point - self.points\n        r_mag = tools.norm(r, axis=1)\n        r_mag[r_mag < EPS] = EPS\n        core = r_mag / self.radius\n        core[r_mag > self.radius] = 1\n\n        # The below einsum operation is equivalent to:\n        # self.current * np.sum(core * self.d_l.T / r_mag, axis=0) / (4 * np.pi)\n        return np.einsum(\n            \"i, ji, ... -> j\", core, self.d_l / r_mag[None], ONE_4PI * self.current\n        )\n\n    @process_xyz_array\n    def field(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate the field due to the arbitrarily shaped Coordinates.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the field\n        y:\n            The y coordinate(s) of the points at which to calculate the field\n        z:\n            The z coordinate(s) of the points at which to calculate the field\n\n        Returns\n        -------\n        The field at the point(s) due to the arbitrarily shaped Coordinates\n\n        Notes\n        -----\n        \\t:math:`\\\\dfrac{\\\\mu_{0}}{4\\\\pi}\\\\oint \\\\dfrac{Idl \\\\times\\\\mathbf{r^{'}}}{|\\\\mathbf{r^{'}}|^{3}}`\n\n        This is the original Biot-Savart equation, without centre-averaged\n        smoothing. Do not use for values near the coil current centreline.\n        \"\"\"  # noqa :W505\n        point = np.array([x, y, z])\n        r = point - self.mid_points\n        r3 = np.linalg.norm(r, axis=1) ** 3\n\n        ds = np.cross(self.d_l, r)\n\n        # Coil core correction\n        d_l_hat = self.d_l_hat[:, None]\n        ds_mag = np.linalg.norm(ds / d_l_hat, axis=1)\n        ds_mag = np.tile(ds_mag, (3, 1)).T\n        ds_mag[ds_mag < EPS] = EPS\n        core = ds_mag**2 / self.radius**2\n        core[ds_mag > self.radius] = 1\n        return MU_0_4PI * self.current * np.sum(core * ds / r3[:, np.newaxis], axis=0)\n\n    def inductance(self) -> float:\n        \"\"\"\n        Calculate the total inductance of the BiotSavartFilament.\n\n        Returns\n        -------\n        The total inductance (including self-inductance of reference Coordinates) [H]\n\n        Notes\n        -----\n        \\t:math:`\\\\dfrac{\\\\mu_{0}}{4\\\\pi}\\\\oint \\\\dfrac{d\\\\mathbf{x_{1}} \\\\cdot d\\\\mathbf{r_{x}}}{|\\\\mathbf{x_{1}}-\\\\mathbf{x_{2}}|}`\n\n        https://arxiv.org/pdf/1204.1486.pdf\n\n        You probably shouldn't use this if you are actually interested in the\n        inductance of an arbitrarily shaped Coordinates...\n        \"\"\"  # noqa :W505\n        # TODO: Validate inductance calculate properly and compare stored\n        # energy of systems\n        inductance = 0\n        for i, (x1, dx1) in enumerate(zip(self.ref_mid_points, self.ref_d_l)):\n            # We create a mask to drop the point where x1 == x2\n            r = x1 - self.mid_points\n            mask = np.sum(r**2, axis=1) > self.radius\n            inductance += np.sum(\n                np.dot(dx1, self.d_l[mask].T) / np.linalg.norm(r[mask], axis=1)\n            )\n\n        # Self-inductance correction (Y = 0.5 for homogenous current distribution)\n        inductance += (\n            2 * self.length * (np.log(2 * self.length_scale / self.radius) + 0.25)\n        )\n\n        return MU_0_4PI * inductance\n\n    def rotate(self, angle: float, axis: Union[str, np.ndarray]):\n        \"\"\"\n        Rotate the CurrentSource about an axis.\n\n        Parameters\n        ----------\n        angle:\n            The rotation degree [degree]\n        axis:\n            The axis of rotation\n        \"\"\"\n        r = rotation_matrix(np.deg2rad(angle), axis).T\n        self.points = self.points @ r\n        self.d_l = self.d_l @ r\n        self.mid_points = self.mid_points @ r\n        self.ref_d_l = self.ref_d_l @ r\n        self.ref_mid_points = self.ref_mid_points @ r\n        self._arrays = [array @ r for array in self._arrays]\n\n    def plot(self, ax: Optional[Axes] = None, show_coord_sys: bool = False):\n        \"\"\"\n        Plot the CurrentSource.\n\n        Parameters\n        ----------\n        ax:\n            The matplotlib axes to plot on\n        show_coord_sys:\n            Whether or not to plot the coordinate systems\n        \"\"\"\n        if ax is None:\n            ax = Plot3D()\n            # If no ax provided, we assume that we want to plot only this source,\n            # and thus set aspect ratio equality on this term only\n            # Invisible bounding box to set equal aspect ratio plot\n            xbox, ybox, zbox = BoundingBox.from_xyz(*self.points.T).get_box_arrays()\n            ax.plot(1.1 * xbox, 1.1 * ybox, 1.1 * zbox, \"s\", alpha=0)\n\n        for array in self._arrays:\n            ax.plot(*array.T, color=\"b\", linewidth=1)\n\n        # Plot local coordinate system\n        if show_coord_sys:\n            origin = [0, 0, 0]\n            dcm = np.eye(3)\n            ax.scatter([0, 0, 0], color=\"k\")\n            ax.quiver(*origin, *dcm[0], length=self.length_scale, color=\"r\")\n            ax.quiver(*origin, *dcm[1], length=self.length_scale, color=\"r\")\n            ax.quiver(*origin, *dcm[2], length=self.length_scale, color=\"r\")",
  "def __init__(\n        self,\n        arrays: Union[Coordinates, np.ndarray, List[Coordinates], List[np.ndarray]],\n        radius: float,\n        current: float = 1.0,\n    ):\n        if not isinstance(arrays, list):\n            # Handle single Coordinates/array\n            arrays = [arrays]\n        arrays = [process_coords_array(array) for array in arrays]\n\n        # Handle list of Coordinates/arrays (potentially of different sizes)\n        d_ls, mids_points = [], []\n        points = []\n        for i, xyz in enumerate(arrays):\n            d_l = np.diff(xyz, axis=0)\n            self._check_discretisation(d_l)\n\n            mid_points = xyz[:-1, :] + 0.5 * d_l\n            d_ls.append(d_l)\n            points.append(xyz[:-1, :])\n            mids_points.append(mid_points)\n            if i == 0:\n                # Take the first Coordinates as a reference for inductance calculation\n                self.ref_mid_points = mid_points\n                self.ref_d_l = d_l\n\n                lengths = np.sqrt(np.sum(d_l**2, axis=1))\n                self.length = np.sum(lengths)\n                self.length_scale = np.min(lengths)\n\n        # Assemble arrays and vector\n        self.d_l = np.vstack(d_ls)\n        self.d_l_hat = np.linalg.norm(self.d_l, axis=1)\n        self.mid_points = np.vstack(mids_points)\n        self.points = np.vstack(points)\n        self._arrays = arrays\n        self.radius = radius\n        self.current = current",
  "def _check_discretisation(self, d_l: np.ndarray):\n        \"\"\"\n        Check the discretisation of the array.\n        \"\"\"\n        lengths = np.sqrt(np.sum(d_l**2, axis=1))\n        total = np.sum(lengths)\n        max_d_l = np.max(lengths)\n        if max_d_l > 0.03 * total:\n            bluemira_warn(\"Biot-Savart discretisation possibly insufficient.\")",
  "def potential(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate the vector potential of an arbitrarily shaped Coordinates.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the potential\n        y:\n            The y coordinate(s) of the points at which to calculate the potential\n        z:\n            The z coordinate(s) of the points at which to calculate the potential\n\n\n        Returns\n        -------\n        The vector potential at the point due to the arbitrarily shaped Coordinates\n        \"\"\"\n        point = np.array([x, y, z])\n        r = point - self.points\n        r_mag = tools.norm(r, axis=1)\n        r_mag[r_mag < EPS] = EPS\n        core = r_mag / self.radius\n        core[r_mag > self.radius] = 1\n\n        # The below einsum operation is equivalent to:\n        # self.current * np.sum(core * self.d_l.T / r_mag, axis=0) / (4 * np.pi)\n        return np.einsum(\n            \"i, ji, ... -> j\", core, self.d_l / r_mag[None], ONE_4PI * self.current\n        )",
  "def field(\n        self,\n        x: Union[float, np.ndarray],\n        y: Union[float, np.ndarray],\n        z: Union[float, np.ndarray],\n    ) -> np.ndarray:\n        \"\"\"\n        Calculate the field due to the arbitrarily shaped Coordinates.\n\n        Parameters\n        ----------\n        x:\n            The x coordinate(s) of the points at which to calculate the field\n        y:\n            The y coordinate(s) of the points at which to calculate the field\n        z:\n            The z coordinate(s) of the points at which to calculate the field\n\n        Returns\n        -------\n        The field at the point(s) due to the arbitrarily shaped Coordinates\n\n        Notes\n        -----\n        \\t:math:`\\\\dfrac{\\\\mu_{0}}{4\\\\pi}\\\\oint \\\\dfrac{Idl \\\\times\\\\mathbf{r^{'}}}{|\\\\mathbf{r^{'}}|^{3}}`\n\n        This is the original Biot-Savart equation, without centre-averaged\n        smoothing. Do not use for values near the coil current centreline.\n        \"\"\"  # noqa :W505\n        point = np.array([x, y, z])\n        r = point - self.mid_points\n        r3 = np.linalg.norm(r, axis=1) ** 3\n\n        ds = np.cross(self.d_l, r)\n\n        # Coil core correction\n        d_l_hat = self.d_l_hat[:, None]\n        ds_mag = np.linalg.norm(ds / d_l_hat, axis=1)\n        ds_mag = np.tile(ds_mag, (3, 1)).T\n        ds_mag[ds_mag < EPS] = EPS\n        core = ds_mag**2 / self.radius**2\n        core[ds_mag > self.radius] = 1\n        return MU_0_4PI * self.current * np.sum(core * ds / r3[:, np.newaxis], axis=0)",
  "def inductance(self) -> float:\n        \"\"\"\n        Calculate the total inductance of the BiotSavartFilament.\n\n        Returns\n        -------\n        The total inductance (including self-inductance of reference Coordinates) [H]\n\n        Notes\n        -----\n        \\t:math:`\\\\dfrac{\\\\mu_{0}}{4\\\\pi}\\\\oint \\\\dfrac{d\\\\mathbf{x_{1}} \\\\cdot d\\\\mathbf{r_{x}}}{|\\\\mathbf{x_{1}}-\\\\mathbf{x_{2}}|}`\n\n        https://arxiv.org/pdf/1204.1486.pdf\n\n        You probably shouldn't use this if you are actually interested in the\n        inductance of an arbitrarily shaped Coordinates...\n        \"\"\"  # noqa :W505\n        # TODO: Validate inductance calculate properly and compare stored\n        # energy of systems\n        inductance = 0\n        for i, (x1, dx1) in enumerate(zip(self.ref_mid_points, self.ref_d_l)):\n            # We create a mask to drop the point where x1 == x2\n            r = x1 - self.mid_points\n            mask = np.sum(r**2, axis=1) > self.radius\n            inductance += np.sum(\n                np.dot(dx1, self.d_l[mask].T) / np.linalg.norm(r[mask], axis=1)\n            )\n\n        # Self-inductance correction (Y = 0.5 for homogenous current distribution)\n        inductance += (\n            2 * self.length * (np.log(2 * self.length_scale / self.radius) + 0.25)\n        )\n\n        return MU_0_4PI * inductance",
  "def rotate(self, angle: float, axis: Union[str, np.ndarray]):\n        \"\"\"\n        Rotate the CurrentSource about an axis.\n\n        Parameters\n        ----------\n        angle:\n            The rotation degree [degree]\n        axis:\n            The axis of rotation\n        \"\"\"\n        r = rotation_matrix(np.deg2rad(angle), axis).T\n        self.points = self.points @ r\n        self.d_l = self.d_l @ r\n        self.mid_points = self.mid_points @ r\n        self.ref_d_l = self.ref_d_l @ r\n        self.ref_mid_points = self.ref_mid_points @ r\n        self._arrays = [array @ r for array in self._arrays]",
  "def plot(self, ax: Optional[Axes] = None, show_coord_sys: bool = False):\n        \"\"\"\n        Plot the CurrentSource.\n\n        Parameters\n        ----------\n        ax:\n            The matplotlib axes to plot on\n        show_coord_sys:\n            Whether or not to plot the coordinate systems\n        \"\"\"\n        if ax is None:\n            ax = Plot3D()\n            # If no ax provided, we assume that we want to plot only this source,\n            # and thus set aspect ratio equality on this term only\n            # Invisible bounding box to set equal aspect ratio plot\n            xbox, ybox, zbox = BoundingBox.from_xyz(*self.points.T).get_box_arrays()\n            ax.plot(1.1 * xbox, 1.1 * ybox, 1.1 * zbox, \"s\", alpha=0)\n\n        for array in self._arrays:\n            ax.plot(*array.T, color=\"b\", linewidth=1)\n\n        # Plot local coordinate system\n        if show_coord_sys:\n            origin = [0, 0, 0]\n            dcm = np.eye(3)\n            ax.scatter([0, 0, 0], color=\"k\")\n            ax.quiver(*origin, *dcm[0], length=self.length_scale, color=\"r\")\n            ax.quiver(*origin, *dcm[1], length=self.length_scale, color=\"r\")\n            ax.quiver(*origin, *dcm[2], length=self.length_scale, color=\"r\")",
  "def process_xyz_array(func):\n    \"\"\"\n    Decorator for coordinate input handling in array-return functions and methods.\n    \"\"\"\n\n    def wrapper(cls, x, y, z):\n        x = np.atleast_1d(x)\n        y = np.atleast_1d(y)\n        z = np.atleast_1d(z)\n\n        if not len(x) == len(y) == len(z):\n            raise MagnetostaticsError(\"Coordinate vector lengths must be equal.\")\n\n        if len(x) == 1:\n            # Float handling\n            return func(cls, x[0], y[0], z[0])\n        elif len(x.shape) == 1:\n            # 1-D array handling\n            return np.array([func(cls, xi, yi, zi) for xi, yi, zi in zip(x, y, z)]).T\n        elif len(x.shape) == 2:\n            # 2-D array handling\n            m, n = x.shape\n            result = np.zeros((3, m, n))\n            for i in range(m):\n                for j in range(n):\n                    result[:, i, j] = np.array([func(cls, x[i, j], y[i, j], z[i, j])])\n            return result\n\n        else:\n            raise MagnetostaticsError(\n                \"This operation only supports floats and 1-D and 2-D arrays.\"\n            )\n\n    return wrapper",
  "def process_coords_array(shape: Union[np.ndarray, Coordinates]) -> np.ndarray:\n    \"\"\"\n    Parse Coordinates or array to an array.\n\n    Parameters\n    ----------\n    shape:\n        The Coordinates or array to make into a coordinate array\n\n    Returns\n    -------\n    Array in proper dimensions\n    \"\"\"\n    if isinstance(shape, np.ndarray):\n        pass\n\n    elif isinstance(shape, Coordinates):\n        shape = shape.T\n\n    else:\n        raise MagnetostaticsError(\n            f\"Cannot make a CurrentSource from an object of type: {type(shape)}.\"\n        )\n\n    return shape",
  "def process_to_coordinates(shape: Union[np.ndarray, dict, Coordinates]) -> Coordinates:\n    \"\"\"\n    Parse input to Coordinates\n\n    Raises\n    ------\n    CoordinatesError: if the type could not be parsed, or if the input was bad.\n    \"\"\"\n    if isinstance(shape, Coordinates):\n        return shape\n    else:\n        return Coordinates(shape)",
  "def jit_llc7(f_integrand: Callable) -> LowLevelCallable:\n    \"\"\"\n    Decorator for 6-argument integrand function to a low-level callable.\n\n    Parameters\n    ----------\n    f_integrand:\n        The integrand function\n\n    Returns\n    -------\n    The decorated integrand function as a LowLevelCallable\n    \"\"\"\n    f_jitted = nb.jit(f_integrand, nopython=True, cache=True)\n\n    @nb.cfunc(float64(intc, CPointer(float64)))\n    def wrapped(n, xx):  # noqa: U100\n        return f_jitted(xx[0], xx[1], xx[2], xx[3], xx[4], xx[5], xx[6])\n\n    return LowLevelCallable(wrapped.ctypes)",
  "def jit_llc5(f_integrand: Callable) -> LowLevelCallable:\n    \"\"\"\n    Decorator for 4-argument integrand function to a low-level callable.\n\n    Parameters\n    ----------\n    f_integrand:\n        The integrand function\n\n    Returns\n    -------\n    The decorated integrand function as a LowLevelCallable\n    \"\"\"\n    f_jitted = nb.jit(f_integrand, nopython=True, cache=True)\n\n    @nb.cfunc(float64(intc, CPointer(float64)))\n    def wrapped(n, xx):  # noqa: U100\n        return f_jitted(xx[0], xx[1], xx[2], xx[3], xx[4])\n\n    return LowLevelCallable(wrapped.ctypes)",
  "def jit_llc4(f_integrand: Callable) -> LowLevelCallable:\n    \"\"\"\n    Decorator for 3-argument integrand function to a low-level callable.\n\n    Parameters\n    ----------\n    f_integrand:\n        The integrand function\n\n    Returns\n    -------\n    The decorated integrand function as a LowLevelCallable\n    \"\"\"\n    f_jitted = nb.jit(f_integrand, nopython=True, cache=True)\n\n    @nb.cfunc(float64(intc, CPointer(float64)))\n    def wrapped(n, xx):  # noqa: U100\n        return f_jitted(xx[0], xx[1], xx[2], xx[3])\n\n    return LowLevelCallable(wrapped.ctypes)",
  "def jit_llc3(f_integrand: Callable) -> LowLevelCallable:\n    \"\"\"\n    Decorator for 2-argument integrand function to a low-level callable.\n\n    Parameters\n    ----------\n    f_integrand:\n        The integrand function\n\n    Returns\n    -------\n    The decorated integrand function as a LowLevelCallable\n    \"\"\"\n    f_jitted = nb.jit(f_integrand, nopython=True, cache=True)\n\n    @nb.cfunc(float64(intc, CPointer(float64)))\n    def wrapped(n, xx):  # noqa: U100\n        return f_jitted(xx[0], xx[1], xx[2])\n\n    return LowLevelCallable(wrapped.ctypes)",
  "def integrate(\n    func: Callable, args: Iterable, bound1: Union[float, int], bound2: Union[float, int]\n) -> float:\n    \"\"\"\n    Utility for integration of a function between bounds. Easier to refactor\n    integration methods.\n\n    Parameters\n    ----------\n    func:\n        The function to integrate. The integration variable should be the last\n        argument of this function.\n    args:\n        The iterable of static arguments to the function.\n    bound1:\n        The lower integration bound\n    bound2:\n        The upper integration bound\n\n    Returns\n    -------\n    The value of the integral of the function between the bounds\n    \"\"\"\n    warnings.filterwarnings(\"error\", category=IntegrationWarning)\n    try:\n        result = quad(func, bound1, bound2, args=args)[0]\n    except IntegrationWarning:\n        # First attempt at fixing the integration problem\n        points = [\n            0.25 * (bound2 - bound1),\n            0.5 * (bound2 - bound1),\n            0.75 * (bound2 - bound1),\n        ]\n        try:\n            result = quad(func, bound1, bound2, args=args, points=points, limit=200)[0]\n        except IntegrationWarning as error:\n            raise MagnetostaticsIntegrationError from error\n\n    warnings.filterwarnings(\"default\", category=IntegrationWarning)\n    return result",
  "def n_integrate(\n    func: Callable, args: Iterable, bounds: List[Iterable[Union[int, float]]]\n) -> float:\n    \"\"\"\n    Utility for n-dimensional integration of a function between bounds. Easier\n    to refactor integration methods.\n\n    Parameters\n    ----------\n    func:\n        The function to integrate. The integration variable should be the last\n        argument of this function.\n    args:\n        The iterable of static arguments to the function.\n    bounds:\n        The list of lower and upper integration bounds applied to x[0], x[1], ..\n\n    Returns\n    -------\n    The value of the integral of the function between the bounds\n    \"\"\"\n    return nquad(func, bounds, args=args)[0]",
  "def wrapper(cls, x, y, z):\n        x = np.atleast_1d(x)\n        y = np.atleast_1d(y)\n        z = np.atleast_1d(z)\n\n        if not len(x) == len(y) == len(z):\n            raise MagnetostaticsError(\"Coordinate vector lengths must be equal.\")\n\n        if len(x) == 1:\n            # Float handling\n            return func(cls, x[0], y[0], z[0])\n        elif len(x.shape) == 1:\n            # 1-D array handling\n            return np.array([func(cls, xi, yi, zi) for xi, yi, zi in zip(x, y, z)]).T\n        elif len(x.shape) == 2:\n            # 2-D array handling\n            m, n = x.shape\n            result = np.zeros((3, m, n))\n            for i in range(m):\n                for j in range(n):\n                    result[:, i, j] = np.array([func(cls, x[i, j], y[i, j], z[i, j])])\n            return result\n\n        else:\n            raise MagnetostaticsError(\n                \"This operation only supports floats and 1-D and 2-D arrays.\"\n            )",
  "def wrapped(n, xx):  # noqa: U100\n        return f_jitted(xx[0], xx[1], xx[2], xx[3], xx[4], xx[5], xx[6])",
  "def wrapped(n, xx):  # noqa: U100\n        return f_jitted(xx[0], xx[1], xx[2], xx[3], xx[4])",
  "def wrapped(n, xx):  # noqa: U100\n        return f_jitted(xx[0], xx[1], xx[2], xx[3])",
  "def wrapped(n, xx):  # noqa: U100\n        return f_jitted(xx[0], xx[1], xx[2])",
  "class GeoMeshable(meshing.Meshable):\n    \"\"\"\n    Extended Meshable class for BluemiraGeo objects.\n    \"\"\"\n\n    def remove_mesh_options(self, recursive: bool = False):\n        \"\"\"\n        Remove mesh options for this object.\n        \"\"\"\n        super().remove_mesh_options()\n        if hasattr(self, \"boundary\"):\n            for obj in self.boundary:\n                if isinstance(obj, GeoMeshable):\n                    obj.remove_mesh_options(recursive=True)\n\n    def print_mesh_options(self, recursive: bool = True):\n        \"\"\"\n        Print the mesh options for this object.\n        \"\"\"\n        # TODO: improve the output of this function\n        output = []\n        output.append(self.mesh_options)\n        if hasattr(self, \"boundary\"):\n            for obj in self.boundary:\n                if isinstance(obj, GeoMeshable):\n                    output.append(obj.print_mesh_options(True))\n        return output",
  "class _Orientation(enum.Enum):\n    FORWARD = \"Forward\"\n    REVERSED = \"Reversed\"",
  "class BluemiraGeo(ABC, GeoMeshable):\n    \"\"\"\n    Abstract base class for geometry.\n\n    Parameters\n    ----------\n    boundary:\n        shape's boundary\n    label:\n        identification label for the shape\n    boundary_classes:\n        list of allowed class types for shape's boundary\n    \"\"\"\n\n    def __init__(\n        self,\n        boundary: Union[BluemiraGeo, List[BluemiraGeo]],\n        label: str = \"\",\n        boundary_classes: Optional[BluemiraGeo] = None,\n    ):\n        super().__init__()\n        self._boundary_classes = boundary_classes\n        self.__orientation = _Orientation.FORWARD\n        self.label = label\n        self._set_boundary(boundary)\n\n    @property\n    def _orientation(self):\n        return self.__orientation\n\n    @_orientation.setter\n    def _orientation(self, value):\n        self.__orientation = _Orientation(value)\n\n    def _check_reverse(self, obj):\n        if self._orientation != _Orientation(obj.Orientation):\n            obj.reverse()\n            self._orientation = _Orientation(obj.Orientation)\n        return obj\n\n    @staticmethod\n    def _converter(func):\n        \"\"\"\n        Function used in __getattr__ to modify the added functions.\n        \"\"\"\n        return func\n\n    def _check_boundary(self, objs):\n        \"\"\"\n        Check if objects objs can be used as boundaries.\n\n        Note: empty BluemiraGeo are allowed in case of objs == None.\n        \"\"\"\n        if objs is None:\n            return objs\n\n        if not hasattr(objs, \"__len__\"):\n            objs = [objs]\n\n        check = False\n        for c in self._boundary_classes:\n            # # in case of obj = [], this check returns True instead of False\n            # check = check or (all(isinstance(o, c) for o in objs))\n            for o in objs:\n                check = check or isinstance(o, c)\n            if check:\n                return objs\n        raise TypeError(\n            f\"Only {self._boundary_classes} objects can be used for {self.__class__}\"\n        )\n\n    @property\n    def boundary(self) -> tuple:\n        \"\"\"\n        The shape's boundary.\n        \"\"\"\n        return tuple(self._boundary)\n\n    def _set_boundary(self, objs, replace_shape: bool = True):\n        self._boundary = self._check_boundary(objs)\n        if replace_shape:\n            if self._boundary is None:\n                self._set_shape(None)\n            else:\n                self._set_shape(self._create_shape())\n\n    @abstractmethod\n    def _create_shape(self):\n        \"\"\"\n        Create the shape from the boundary\n        \"\"\"\n        # Note: this is the \"hidden\" connection with primitive shapes\n        pass\n\n    @property\n    def shape(self) -> cadapi.apiShape:\n        \"\"\"\n        The primitive shape of the object.\n        \"\"\"\n        # Note: this is the \"hidden\" connection with primitive shapes\n        return self._shape\n\n    def _set_shape(self, value: cadapi.apiShape):\n        self._shape = value\n\n    @property\n    def length(self) -> float:\n        \"\"\"\n        The shape's length.\n        \"\"\"\n        return cadapi.length(self.shape)\n\n    @property\n    def area(self) -> float:\n        \"\"\"\n        The shape's area.\n        \"\"\"\n        return cadapi.area(self.shape)\n\n    @property\n    def volume(self) -> float:\n        \"\"\"\n        The shape's volume.\n        \"\"\"\n        return cadapi.volume(self.shape)\n\n    @property\n    def center_of_mass(self) -> np.ndarray:\n        \"\"\"\n        The shape's center of mass.\n        \"\"\"\n        return cadapi.center_of_mass(self.shape)\n\n    @property\n    def bounding_box(self) -> BoundingBox:\n        \"\"\"\n        The bounding box of the shape.\n\n        Notes\n        -----\n        If your shape is complicated, this has the potential to not be very accurate.\n        Consider using :meth:`~get_optimal_bounding_box`.\n        \"\"\"\n        x_min, y_min, z_min, x_max, y_max, z_max = cadapi.bounding_box(self.shape)\n        return BoundingBox(x_min, x_max, y_min, y_max, z_min, z_max)\n\n    def get_optimal_bounding_box(self, tolerance: float = 1.0) -> BoundingBox:\n        \"\"\"\n        Get the optimised bounding box of the shape, via tesselation of the underlying\n        geometry.\n\n        Parameters\n        ----------\n        tolerance:\n            Tolerance with which to tesselate the BluemiraGeo before calculating the\n            bounding box.\n        \"\"\"\n        auto_copy = self.deepcopy()\n        auto_copy._tessellate(tolerance)\n        return auto_copy.bounding_box\n\n    def is_null(self) -> bool:\n        \"\"\"\n        Check if the shape is null.\n        \"\"\"\n        return cadapi.is_null(self.shape)\n\n    def is_closed(self) -> bool:\n        \"\"\"\n        Check if the shape is closed.\n        \"\"\"\n        return cadapi.is_closed(self.shape)\n\n    def is_valid(self) -> bool:\n        \"\"\"\n        Check if the shape is valid.\n        \"\"\"\n        return cadapi.is_valid(self.shape)\n\n    def is_same(self, obj: BluemiraGeo) -> bool:\n        \"\"\"\n        Check if obj has the same shape as self\n        \"\"\"\n        return cadapi.is_same(self.shape, obj.shape)\n\n    def search(self, label: str) -> List[BluemiraGeo]:\n        \"\"\"\n        Search for a shape with the specified label\n\n        Parameters\n        ----------\n        label:\n            Shape label\n\n        Returns\n        -------\n        List of shapes that have the specified label\n        \"\"\"\n        output = []\n        if self.label == label:\n            output.append(self)\n        for o in self.boundary:\n            if isinstance(o, BluemiraGeo):\n                output += o.search(label)\n        return output\n\n    def scale(self, factor: float) -> None:\n        \"\"\"\n        Apply scaling with factor to this object. This function modifies the self\n        object.\n\n        Note\n        ----\n        The operation is made on shape and boundary in order to maintain the consistency.\n        Shape is then not reconstructed from boundary (in order to reduce the\n        computational time and avoid problems due to api objects orientation).\n        \"\"\"\n        for o in self.boundary:\n            if isinstance(o, BluemiraGeo):\n                o.scale(factor)\n            else:\n                cadapi.scale_shape(o, factor)\n        cadapi.scale_shape(self.shape, factor)\n\n    def _tessellate(self, tolerance: float = 1.0) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Tessellate the geometry object.\n\n        Parameters\n        ----------\n        tolerance:\n            Tolerance with which to tessellate the geometry\n\n        Returns\n        -------\n        vertices:\n            Array of the vertices (N, 3, dtype=float) from the tesselation operation\n        indices:\n            Array of the indices (M, 3, dtype=int) from the tesselation operation\n\n        Notes\n        -----\n        Once tesselated, an object's properties may change. Tesselation cannot be\n        reverted to a previous lower value, but can be increased (irreversibly).\n        \"\"\"\n        return cadapi.tessellate(self.shape, tolerance)\n\n    def translate(self, vector: Tuple[float, float, float]) -> None:\n        \"\"\"\n        Translate this shape with the vector. This function modifies the self\n        object.\n\n        Note\n        ----\n        The operation is made on shape and boundary in order to maintain the consistency.\n        Shape is then not reconstructed from boundary (in order to reduce the\n        computational time and avoid problems due to api objects orientation).\n        \"\"\"\n        for o in self.boundary:\n            if isinstance(o, BluemiraGeo):\n                o.translate(vector)\n            else:\n                cadapi.translate_shape(o, vector)\n        cadapi.translate_shape(self.shape, vector)\n\n    def rotate(\n        self,\n        base: Tuple[float, float, float] = (0.0, 0.0, 0.0),\n        direction: Tuple[float, float, float] = (0.0, 0.0, 1.0),\n        degree: float = 180,\n    ):\n        \"\"\"\n        Rotate this shape.\n\n        Parameters\n        ----------\n        base:\n            Origin location of the rotation\n        direction:\n            The direction vector\n        degree:\n            rotation angle\n\n        Note\n        ----\n        The operation is made on shape and boundary in order to maintain the consistency.\n        Shape is then not reconstructed from boundary (in order to reduce the\n        computational time and avoid problems due to api objects orientation).\n        \"\"\"\n        for o in self.boundary:\n            if isinstance(o, BluemiraGeo):\n                o.rotate(base, direction, degree)\n            else:\n                cadapi.rotate_shape(o, base, direction, degree)\n        cadapi.rotate_shape(self.shape, base, direction, degree)\n\n    def change_placement(self, placement: BluemiraPlacement) -> None:\n        \"\"\"\n        Change the placement of self\n        Note\n        ----\n        The operation is made on shape and boundary in order to maintain the consistency.\n        Shape is then not reconstructed from boundary (in order to reduce the\n        computational time and avoid problems due to api objects orientation).\n        \"\"\"\n        for o in self.boundary:\n            if isinstance(o, BluemiraGeo):\n                o.change_placement(placement)\n            else:\n                cadapi.change_placement(o, placement._shape)\n        cadapi.change_placement(self.shape, placement._shape)\n\n    def __repr__(self) -> str:  # noqa D105\n        new = []\n        new.append(f\"([{type(self).__name__}] = Label: {self.label}\")\n        new.append(f\" length: {self.length}\")\n        new.append(f\" area: {self.area}\")\n        new.append(f\" volume: {self.volume}\")\n        new.append(\")\")\n        return \", \".join(new)\n\n    def copy(self, label: Optional[str] = None):\n        \"\"\"\n        Make a copy of the BluemiraGeo.\n        \"\"\"\n        geo_copy = copy.copy(self)\n        if label is not None:\n            geo_copy.label = label\n        else:\n            geo_copy.label = self.label\n        return geo_copy\n\n    def deepcopy(self, label: Optional[str] = None):\n        \"\"\"\n        Make a deepcopy of the BluemiraGeo.\n        \"\"\"\n        geo_copy = copy.deepcopy(self)\n        if label is not None:\n            geo_copy.label = label\n        else:\n            geo_copy.label = self.label\n        return geo_copy\n\n    @property\n    @abstractmethod\n    def vertexes(self) -> Coordinates:\n        \"\"\"\n        The vertexes of the BluemiraGeo.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def edges(self) -> tuple:\n        \"\"\"\n        The edges of the BluemiraGeo.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def wires(self) -> tuple:\n        \"\"\"\n        The wires of the BluemiraGeo.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def faces(self) -> tuple:\n        \"\"\"\n        The faces of the BluemiraGeo.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def shells(self) -> tuple:\n        \"\"\"\n        The shells of the BluemiraGeo.\n        \"\"\"\n        pass\n\n    @property\n    @abstractmethod\n    def solids(self) -> tuple:\n        \"\"\"\n        The solids of the BluemiraGeo.\n        \"\"\"\n        pass",
  "def remove_mesh_options(self, recursive: bool = False):\n        \"\"\"\n        Remove mesh options for this object.\n        \"\"\"\n        super().remove_mesh_options()\n        if hasattr(self, \"boundary\"):\n            for obj in self.boundary:\n                if isinstance(obj, GeoMeshable):\n                    obj.remove_mesh_options(recursive=True)",
  "def print_mesh_options(self, recursive: bool = True):\n        \"\"\"\n        Print the mesh options for this object.\n        \"\"\"\n        # TODO: improve the output of this function\n        output = []\n        output.append(self.mesh_options)\n        if hasattr(self, \"boundary\"):\n            for obj in self.boundary:\n                if isinstance(obj, GeoMeshable):\n                    output.append(obj.print_mesh_options(True))\n        return output",
  "def __init__(\n        self,\n        boundary: Union[BluemiraGeo, List[BluemiraGeo]],\n        label: str = \"\",\n        boundary_classes: Optional[BluemiraGeo] = None,\n    ):\n        super().__init__()\n        self._boundary_classes = boundary_classes\n        self.__orientation = _Orientation.FORWARD\n        self.label = label\n        self._set_boundary(boundary)",
  "def _orientation(self):\n        return self.__orientation",
  "def _orientation(self, value):\n        self.__orientation = _Orientation(value)",
  "def _check_reverse(self, obj):\n        if self._orientation != _Orientation(obj.Orientation):\n            obj.reverse()\n            self._orientation = _Orientation(obj.Orientation)\n        return obj",
  "def _converter(func):\n        \"\"\"\n        Function used in __getattr__ to modify the added functions.\n        \"\"\"\n        return func",
  "def _check_boundary(self, objs):\n        \"\"\"\n        Check if objects objs can be used as boundaries.\n\n        Note: empty BluemiraGeo are allowed in case of objs == None.\n        \"\"\"\n        if objs is None:\n            return objs\n\n        if not hasattr(objs, \"__len__\"):\n            objs = [objs]\n\n        check = False\n        for c in self._boundary_classes:\n            # # in case of obj = [], this check returns True instead of False\n            # check = check or (all(isinstance(o, c) for o in objs))\n            for o in objs:\n                check = check or isinstance(o, c)\n            if check:\n                return objs\n        raise TypeError(\n            f\"Only {self._boundary_classes} objects can be used for {self.__class__}\"\n        )",
  "def boundary(self) -> tuple:\n        \"\"\"\n        The shape's boundary.\n        \"\"\"\n        return tuple(self._boundary)",
  "def _set_boundary(self, objs, replace_shape: bool = True):\n        self._boundary = self._check_boundary(objs)\n        if replace_shape:\n            if self._boundary is None:\n                self._set_shape(None)\n            else:\n                self._set_shape(self._create_shape())",
  "def _create_shape(self):\n        \"\"\"\n        Create the shape from the boundary\n        \"\"\"\n        # Note: this is the \"hidden\" connection with primitive shapes\n        pass",
  "def shape(self) -> cadapi.apiShape:\n        \"\"\"\n        The primitive shape of the object.\n        \"\"\"\n        # Note: this is the \"hidden\" connection with primitive shapes\n        return self._shape",
  "def _set_shape(self, value: cadapi.apiShape):\n        self._shape = value",
  "def length(self) -> float:\n        \"\"\"\n        The shape's length.\n        \"\"\"\n        return cadapi.length(self.shape)",
  "def area(self) -> float:\n        \"\"\"\n        The shape's area.\n        \"\"\"\n        return cadapi.area(self.shape)",
  "def volume(self) -> float:\n        \"\"\"\n        The shape's volume.\n        \"\"\"\n        return cadapi.volume(self.shape)",
  "def center_of_mass(self) -> np.ndarray:\n        \"\"\"\n        The shape's center of mass.\n        \"\"\"\n        return cadapi.center_of_mass(self.shape)",
  "def bounding_box(self) -> BoundingBox:\n        \"\"\"\n        The bounding box of the shape.\n\n        Notes\n        -----\n        If your shape is complicated, this has the potential to not be very accurate.\n        Consider using :meth:`~get_optimal_bounding_box`.\n        \"\"\"\n        x_min, y_min, z_min, x_max, y_max, z_max = cadapi.bounding_box(self.shape)\n        return BoundingBox(x_min, x_max, y_min, y_max, z_min, z_max)",
  "def get_optimal_bounding_box(self, tolerance: float = 1.0) -> BoundingBox:\n        \"\"\"\n        Get the optimised bounding box of the shape, via tesselation of the underlying\n        geometry.\n\n        Parameters\n        ----------\n        tolerance:\n            Tolerance with which to tesselate the BluemiraGeo before calculating the\n            bounding box.\n        \"\"\"\n        auto_copy = self.deepcopy()\n        auto_copy._tessellate(tolerance)\n        return auto_copy.bounding_box",
  "def is_null(self) -> bool:\n        \"\"\"\n        Check if the shape is null.\n        \"\"\"\n        return cadapi.is_null(self.shape)",
  "def is_closed(self) -> bool:\n        \"\"\"\n        Check if the shape is closed.\n        \"\"\"\n        return cadapi.is_closed(self.shape)",
  "def is_valid(self) -> bool:\n        \"\"\"\n        Check if the shape is valid.\n        \"\"\"\n        return cadapi.is_valid(self.shape)",
  "def is_same(self, obj: BluemiraGeo) -> bool:\n        \"\"\"\n        Check if obj has the same shape as self\n        \"\"\"\n        return cadapi.is_same(self.shape, obj.shape)",
  "def search(self, label: str) -> List[BluemiraGeo]:\n        \"\"\"\n        Search for a shape with the specified label\n\n        Parameters\n        ----------\n        label:\n            Shape label\n\n        Returns\n        -------\n        List of shapes that have the specified label\n        \"\"\"\n        output = []\n        if self.label == label:\n            output.append(self)\n        for o in self.boundary:\n            if isinstance(o, BluemiraGeo):\n                output += o.search(label)\n        return output",
  "def scale(self, factor: float) -> None:\n        \"\"\"\n        Apply scaling with factor to this object. This function modifies the self\n        object.\n\n        Note\n        ----\n        The operation is made on shape and boundary in order to maintain the consistency.\n        Shape is then not reconstructed from boundary (in order to reduce the\n        computational time and avoid problems due to api objects orientation).\n        \"\"\"\n        for o in self.boundary:\n            if isinstance(o, BluemiraGeo):\n                o.scale(factor)\n            else:\n                cadapi.scale_shape(o, factor)\n        cadapi.scale_shape(self.shape, factor)",
  "def _tessellate(self, tolerance: float = 1.0) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Tessellate the geometry object.\n\n        Parameters\n        ----------\n        tolerance:\n            Tolerance with which to tessellate the geometry\n\n        Returns\n        -------\n        vertices:\n            Array of the vertices (N, 3, dtype=float) from the tesselation operation\n        indices:\n            Array of the indices (M, 3, dtype=int) from the tesselation operation\n\n        Notes\n        -----\n        Once tesselated, an object's properties may change. Tesselation cannot be\n        reverted to a previous lower value, but can be increased (irreversibly).\n        \"\"\"\n        return cadapi.tessellate(self.shape, tolerance)",
  "def translate(self, vector: Tuple[float, float, float]) -> None:\n        \"\"\"\n        Translate this shape with the vector. This function modifies the self\n        object.\n\n        Note\n        ----\n        The operation is made on shape and boundary in order to maintain the consistency.\n        Shape is then not reconstructed from boundary (in order to reduce the\n        computational time and avoid problems due to api objects orientation).\n        \"\"\"\n        for o in self.boundary:\n            if isinstance(o, BluemiraGeo):\n                o.translate(vector)\n            else:\n                cadapi.translate_shape(o, vector)\n        cadapi.translate_shape(self.shape, vector)",
  "def rotate(\n        self,\n        base: Tuple[float, float, float] = (0.0, 0.0, 0.0),\n        direction: Tuple[float, float, float] = (0.0, 0.0, 1.0),\n        degree: float = 180,\n    ):\n        \"\"\"\n        Rotate this shape.\n\n        Parameters\n        ----------\n        base:\n            Origin location of the rotation\n        direction:\n            The direction vector\n        degree:\n            rotation angle\n\n        Note\n        ----\n        The operation is made on shape and boundary in order to maintain the consistency.\n        Shape is then not reconstructed from boundary (in order to reduce the\n        computational time and avoid problems due to api objects orientation).\n        \"\"\"\n        for o in self.boundary:\n            if isinstance(o, BluemiraGeo):\n                o.rotate(base, direction, degree)\n            else:\n                cadapi.rotate_shape(o, base, direction, degree)\n        cadapi.rotate_shape(self.shape, base, direction, degree)",
  "def change_placement(self, placement: BluemiraPlacement) -> None:\n        \"\"\"\n        Change the placement of self\n        Note\n        ----\n        The operation is made on shape and boundary in order to maintain the consistency.\n        Shape is then not reconstructed from boundary (in order to reduce the\n        computational time and avoid problems due to api objects orientation).\n        \"\"\"\n        for o in self.boundary:\n            if isinstance(o, BluemiraGeo):\n                o.change_placement(placement)\n            else:\n                cadapi.change_placement(o, placement._shape)\n        cadapi.change_placement(self.shape, placement._shape)",
  "def __repr__(self) -> str:  # noqa D105\n        new = []\n        new.append(f\"([{type(self).__name__}] = Label: {self.label}\")\n        new.append(f\" length: {self.length}\")\n        new.append(f\" area: {self.area}\")\n        new.append(f\" volume: {self.volume}\")\n        new.append(\")\")\n        return \", \".join(new)",
  "def copy(self, label: Optional[str] = None):\n        \"\"\"\n        Make a copy of the BluemiraGeo.\n        \"\"\"\n        geo_copy = copy.copy(self)\n        if label is not None:\n            geo_copy.label = label\n        else:\n            geo_copy.label = self.label\n        return geo_copy",
  "def deepcopy(self, label: Optional[str] = None):\n        \"\"\"\n        Make a deepcopy of the BluemiraGeo.\n        \"\"\"\n        geo_copy = copy.deepcopy(self)\n        if label is not None:\n            geo_copy.label = label\n        else:\n            geo_copy.label = self.label\n        return geo_copy",
  "def vertexes(self) -> Coordinates:\n        \"\"\"\n        The vertexes of the BluemiraGeo.\n        \"\"\"\n        pass",
  "def edges(self) -> tuple:\n        \"\"\"\n        The edges of the BluemiraGeo.\n        \"\"\"\n        pass",
  "def wires(self) -> tuple:\n        \"\"\"\n        The wires of the BluemiraGeo.\n        \"\"\"\n        pass",
  "def faces(self) -> tuple:\n        \"\"\"\n        The faces of the BluemiraGeo.\n        \"\"\"\n        pass",
  "def shells(self) -> tuple:\n        \"\"\"\n        The shells of the BluemiraGeo.\n        \"\"\"\n        pass",
  "def solids(self) -> tuple:\n        \"\"\"\n        The solids of the BluemiraGeo.\n        \"\"\"\n        pass",
  "class BluemiraPlacement:\n    \"\"\"\n    Bluemira Placement class.\n\n    Parameters\n    ----------\n    base:\n        Placement origin\n    axis:\n        vector describing the axis of rotation\n    angle:\n        angle of rotation in degree\n    label:\n        Label of the placement\n    \"\"\"\n\n    def __init__(\n        self,\n        base: Iterable[float] = [0.0, 0.0, 0.0],\n        axis: Iterable[float] = [0.0, 0.0, 1.0],\n        angle: float = 0.0,\n        label: str = \"\",\n    ):\n        self._shape = cadapi.make_placement(base, axis, angle)\n        self.label = label\n\n    @classmethod\n    def from_3_points(\n        cls,\n        point_1: Iterable[float],\n        point_2: Iterable[float],\n        point_3: Iterable[float],\n        label: str = \"\",\n    ):\n        \"\"\"\n        Instantiate a BluemiraPlacement from three points.\n\n        Parameters\n        ----------\n        point_1:\n            First point\n        point_2:\n            Second Point\n        point_3:\n            Third point\n        label:\n            Label of the placement\n        \"\"\"\n        p1 = np.array(point_1)\n        p2 = np.array(point_2)\n        p3 = np.array(point_3)\n        v1, v2 = p3 - p1, p2 - p1\n        v3 = np.cross(v2, v1)\n        if np.all(v3 == 0):\n            raise GeometryError(\"Cannot make a BluemiraPlacement from co-linear points.\")\n\n        normal = v3 / np.sqrt(v3.dot(v3))\n        return cls(point_1, normal, 0.0, label=label)\n\n    @classmethod\n    def from_matrix(cls, matrix: np.ndarray, label: str = \"\"):\n        \"\"\"\n        Instantiate a BluemiraPlacement from a 4 x 4 matrix\n\n        Parameters\n        ----------\n        matrix:\n            4 x 4 matrix from which to make the placement\n        label:\n            Label of the placement\n        \"\"\"\n        obj = cls.__new__(cls)\n        obj._shape = cadapi.make_placement_from_matrix(matrix)\n        obj.label = label\n        return obj\n\n    @property\n    def base(self) -> np.ndarray:\n        \"\"\"Placement's local origin\"\"\"\n        return cadapi.vector_to_numpy(self._shape.Base)\n\n    @base.setter\n    def base(self, value: Iterable[float]):\n        \"\"\"\n        Set a new placement base\n\n        Parameters\n        ----------\n        value:\n            Base vector\n        \"\"\"\n        self._shape.Base = cadapi.Base.Vector(value)\n\n    @property\n    def axis(self) -> np.ndarray:\n        \"\"\"Placement's rotation matrix\"\"\"\n        return self._shape.Rotation.Axis\n\n    @axis.setter\n    def axis(self, value: Iterable[float]):\n        \"\"\"\n        Set a new placement axis\n\n        Parameters\n        ----------\n        value:\n            Axis vector\n        \"\"\"\n        self._shape.Axis = cadapi.Base.Vector(value)\n\n    @property\n    def angle(self) -> float:\n        \"\"\"Placement's angle of rotation\"\"\"\n        return np.rad2deg(self._shape.Rotation.Angle)\n\n    @angle.setter\n    def angle(self, value: float):\n        \"\"\"\n        Set a new placement angle of rotation\n\n        Parameters\n        ----------\n        value:\n            Angle value in degree\n        \"\"\"\n        self._shape.Angle = value\n\n    def to_matrix(self) -> np.ndarray:\n        \"\"\"Returns a matrix (quaternion) representing the Placement's transformation\"\"\"\n        return np.array(self._shape.Matrix.A).reshape(4, 4)\n\n    def inverse(self) -> BluemiraPlacement:\n        \"\"\"Returns the inverse placement\"\"\"\n        return BluemiraPlacement._create(\n            self._shape.inverse(), label=self.label + \"_inverse\"\n        )\n\n    def move(self, vector: Iterable[float]):\n        \"\"\"Moves the Placement along the given vector\"\"\"\n        cadapi.move_placement(self._shape, vector)\n\n    def __repr__(self):  # noqa D105\n        new = []\n        new.append(f\"([{type(self).__name__}] = Label: {self.label}\")\n        new.append(f\" base: {self.base}\")\n        new.append(f\" axis: {self.axis}\")\n        new.append(f\" angle: {self.angle}\")\n        new.append(\")\")\n        return \", \".join(new)\n\n    def copy(self, label: Optional[str] = None):\n        \"\"\"Make a copy of the BluemiraPlacement\"\"\"\n        placement_copy = BluemiraPlacement(self.base, self.axis, self.angle)\n        if label is not None:\n            placement_copy.label = label\n        else:\n            placement_copy.label = self.label\n        return placement_copy\n\n    def deepcopy(self, label: Optional[str] = None):\n        \"\"\"Make a deepcopy of the BluemiraPlacement\"\"\"\n        return self.copy()\n\n    @classmethod\n    def _create(cls, obj: cadapi.apiPlacement, label: str = \"\") -> BluemiraPlacement:\n        \"\"\"Create a placement from a cadapi Placement\"\"\"\n        if isinstance(obj, cadapi.apiPlacement):\n            placement = BluemiraPlacement(label=label)\n            placement._shape = obj\n            return placement\n\n        raise TypeError(\n            f\"Only Base.Placement objects can be used to create a {cls} instance\"\n        )\n\n    def mult_vec(self, vec: Iterable[float]) -> np.ndarray:\n        \"\"\"Transform a vector into the local placement\"\"\"\n        return cadapi.vector_to_numpy(self._shape.multVec(cadapi.Base.Vector(vec)))\n\n    def extract_plane(\n        self, v1: Iterable[float], v2: Iterable[float], base: Optional[float] = None\n    ) -> BluemiraPlane:\n        \"\"\"\n        Return a plane identified by two vector given in the self placement\n\n        Parameters\n        ----------\n        v1:\n            first reference vector\n        v2:\n            second reference vector\n        base:\n            output plane origin\n\n        Returns\n        -------\n        A BluemiraPlane\n        \"\"\"\n        if base is None:\n            base = self.base\n\n        p1 = self.mult_vec(v1)\n        p2 = self.mult_vec(v2)\n\n        return BluemiraPlane.from_3_points(base, p1, p2)\n\n    def xy_plane(self):\n        \"\"\"Returns the corresponding placement xy plane\"\"\"\n        return self.extract_plane(v1=np.array([1, 0, 0]), v2=np.array([0, 1, 0]))\n\n    def yz_plane(self):\n        \"\"\"Returns the corresponding placement yz plane\"\"\"\n        return self.extract_plane(v1=np.array([0, 1, 0]), v2=np.array([0, 0, 1]))\n\n    def xz_plane(self):\n        \"\"\"Returns the corresponding placement xz plane\"\"\"\n        return self.extract_plane(v1=np.array([1, 0, 0]), v2=np.array([0, 0, 1]))",
  "def __init__(\n        self,\n        base: Iterable[float] = [0.0, 0.0, 0.0],\n        axis: Iterable[float] = [0.0, 0.0, 1.0],\n        angle: float = 0.0,\n        label: str = \"\",\n    ):\n        self._shape = cadapi.make_placement(base, axis, angle)\n        self.label = label",
  "def from_3_points(\n        cls,\n        point_1: Iterable[float],\n        point_2: Iterable[float],\n        point_3: Iterable[float],\n        label: str = \"\",\n    ):\n        \"\"\"\n        Instantiate a BluemiraPlacement from three points.\n\n        Parameters\n        ----------\n        point_1:\n            First point\n        point_2:\n            Second Point\n        point_3:\n            Third point\n        label:\n            Label of the placement\n        \"\"\"\n        p1 = np.array(point_1)\n        p2 = np.array(point_2)\n        p3 = np.array(point_3)\n        v1, v2 = p3 - p1, p2 - p1\n        v3 = np.cross(v2, v1)\n        if np.all(v3 == 0):\n            raise GeometryError(\"Cannot make a BluemiraPlacement from co-linear points.\")\n\n        normal = v3 / np.sqrt(v3.dot(v3))\n        return cls(point_1, normal, 0.0, label=label)",
  "def from_matrix(cls, matrix: np.ndarray, label: str = \"\"):\n        \"\"\"\n        Instantiate a BluemiraPlacement from a 4 x 4 matrix\n\n        Parameters\n        ----------\n        matrix:\n            4 x 4 matrix from which to make the placement\n        label:\n            Label of the placement\n        \"\"\"\n        obj = cls.__new__(cls)\n        obj._shape = cadapi.make_placement_from_matrix(matrix)\n        obj.label = label\n        return obj",
  "def base(self) -> np.ndarray:\n        \"\"\"Placement's local origin\"\"\"\n        return cadapi.vector_to_numpy(self._shape.Base)",
  "def base(self, value: Iterable[float]):\n        \"\"\"\n        Set a new placement base\n\n        Parameters\n        ----------\n        value:\n            Base vector\n        \"\"\"\n        self._shape.Base = cadapi.Base.Vector(value)",
  "def axis(self) -> np.ndarray:\n        \"\"\"Placement's rotation matrix\"\"\"\n        return self._shape.Rotation.Axis",
  "def axis(self, value: Iterable[float]):\n        \"\"\"\n        Set a new placement axis\n\n        Parameters\n        ----------\n        value:\n            Axis vector\n        \"\"\"\n        self._shape.Axis = cadapi.Base.Vector(value)",
  "def angle(self) -> float:\n        \"\"\"Placement's angle of rotation\"\"\"\n        return np.rad2deg(self._shape.Rotation.Angle)",
  "def angle(self, value: float):\n        \"\"\"\n        Set a new placement angle of rotation\n\n        Parameters\n        ----------\n        value:\n            Angle value in degree\n        \"\"\"\n        self._shape.Angle = value",
  "def to_matrix(self) -> np.ndarray:\n        \"\"\"Returns a matrix (quaternion) representing the Placement's transformation\"\"\"\n        return np.array(self._shape.Matrix.A).reshape(4, 4)",
  "def inverse(self) -> BluemiraPlacement:\n        \"\"\"Returns the inverse placement\"\"\"\n        return BluemiraPlacement._create(\n            self._shape.inverse(), label=self.label + \"_inverse\"\n        )",
  "def move(self, vector: Iterable[float]):\n        \"\"\"Moves the Placement along the given vector\"\"\"\n        cadapi.move_placement(self._shape, vector)",
  "def __repr__(self):  # noqa D105\n        new = []\n        new.append(f\"([{type(self).__name__}] = Label: {self.label}\")\n        new.append(f\" base: {self.base}\")\n        new.append(f\" axis: {self.axis}\")\n        new.append(f\" angle: {self.angle}\")\n        new.append(\")\")\n        return \", \".join(new)",
  "def copy(self, label: Optional[str] = None):\n        \"\"\"Make a copy of the BluemiraPlacement\"\"\"\n        placement_copy = BluemiraPlacement(self.base, self.axis, self.angle)\n        if label is not None:\n            placement_copy.label = label\n        else:\n            placement_copy.label = self.label\n        return placement_copy",
  "def deepcopy(self, label: Optional[str] = None):\n        \"\"\"Make a deepcopy of the BluemiraPlacement\"\"\"\n        return self.copy()",
  "def _create(cls, obj: cadapi.apiPlacement, label: str = \"\") -> BluemiraPlacement:\n        \"\"\"Create a placement from a cadapi Placement\"\"\"\n        if isinstance(obj, cadapi.apiPlacement):\n            placement = BluemiraPlacement(label=label)\n            placement._shape = obj\n            return placement\n\n        raise TypeError(\n            f\"Only Base.Placement objects can be used to create a {cls} instance\"\n        )",
  "def mult_vec(self, vec: Iterable[float]) -> np.ndarray:\n        \"\"\"Transform a vector into the local placement\"\"\"\n        return cadapi.vector_to_numpy(self._shape.multVec(cadapi.Base.Vector(vec)))",
  "def extract_plane(\n        self, v1: Iterable[float], v2: Iterable[float], base: Optional[float] = None\n    ) -> BluemiraPlane:\n        \"\"\"\n        Return a plane identified by two vector given in the self placement\n\n        Parameters\n        ----------\n        v1:\n            first reference vector\n        v2:\n            second reference vector\n        base:\n            output plane origin\n\n        Returns\n        -------\n        A BluemiraPlane\n        \"\"\"\n        if base is None:\n            base = self.base\n\n        p1 = self.mult_vec(v1)\n        p2 = self.mult_vec(v2)\n\n        return BluemiraPlane.from_3_points(base, p1, p2)",
  "def xy_plane(self):\n        \"\"\"Returns the corresponding placement xy plane\"\"\"\n        return self.extract_plane(v1=np.array([1, 0, 0]), v2=np.array([0, 1, 0]))",
  "def yz_plane(self):\n        \"\"\"Returns the corresponding placement yz plane\"\"\"\n        return self.extract_plane(v1=np.array([0, 1, 0]), v2=np.array([0, 0, 1]))",
  "def xz_plane(self):\n        \"\"\"Returns the corresponding placement xz plane\"\"\"\n        return self.extract_plane(v1=np.array([1, 0, 0]), v2=np.array([0, 0, 1]))",
  "class BluemiraWire(BluemiraGeo):\n    \"\"\"\n    Bluemira Wire class.\n\n    Parameters\n    ----------\n    boundary:\n        List of wires from which to make the BluemiraWire\n    label:\n        Label to assign to the wire\n    \"\"\"\n\n    def __init__(\n        self, boundary: List[Union[cadapi.apiWire, BluemiraWire]], label: str = \"\"\n    ):\n        boundary_classes = [self.__class__, cadapi.apiWire]\n        super().__init__(boundary, label, boundary_classes)\n        self._check_orientations()\n\n    def _check_orientations(self):\n        orientations = []\n        for boundary in self.boundary:\n            if isinstance(boundary, cadapi.apiWire):\n                orient = boundary.Orientation\n            elif isinstance(boundary, self.__class__):\n                orient = boundary.shape.Orientation\n            orientations.append(orient)\n\n        if orientations.count(orientations[0]) != len(orientations):\n            raise MixedOrientationWireError(\n                f\"Cannot make a BluemiraWire from wires of mixed orientations: {orientations}\"\n            )\n        self._orientation = orientations[0]\n        if self._orientation != _Orientation(self.shape.Orientation):\n            self.shape.reverse()\n\n    @staticmethod\n    def _converter(func):\n        def wrapper(*args, **kwargs):\n            output = func(*args, **kwargs)\n            if isinstance(output, cadapi.apiWire):\n                output = BluemiraWire(output)\n            return output\n\n        return wrapper\n\n    def _create_shape(self) -> cadapi.apiWire:\n        \"\"\"apiWire: shape of the object as a single wire\"\"\"\n        return self._create_wire()\n\n    def _create_wire(self, check_reverse: bool = True):\n        wire = cadapi.apiWire(self._get_wires())\n        if check_reverse:\n            return self._check_reverse(wire)\n        else:\n            return wire\n\n    def _get_wires(self) -> List[cadapi.apiWire]:\n        \"\"\"list(apiWire): list of wires of which the shape consists of.\"\"\"\n        wires = []\n        for o in self.boundary:\n            if isinstance(o, cadapi.apiWire):\n                for w in o.Wires:\n                    wire = cadapi.apiWire(w.OrderedEdges)\n                    if self._orientation != _Orientation(wire.Orientation):\n                        wire.reverse()\n                    wires += [wire]\n            else:\n                wires += o._get_wires()\n        return wires\n\n    def __add__(self, other: BluemiraWire) -> BluemiraWire:\n        \"\"\"Add two wires\"\"\"\n        output = None\n        if isinstance(other, BluemiraWire):\n            output = BluemiraWire([self, other])\n        else:\n            raise TypeError(f\"{type(other)} is not an instance of BluemiraWire.\")\n        return output\n\n    def close(self, label: str = \"\") -> None:\n        \"\"\"\n        Close the shape with a line segment between shape's end and start point.\n        This function modifies the object boundary.\n        \"\"\"\n        if not self.is_closed():\n            closure = BluemiraWire(cadapi.wire_closure(self.shape), label)\n            self._boundary.append(closure)\n            self._set_boundary(self.boundary)\n\n        # check that the new boundary is closed\n        if not self.is_closed():\n            raise NotClosedWire(\"The open boundary has not been closed.\")\n\n    def discretize(\n        self, ndiscr: int = 100, byedges: bool = False, dl: Optional[float] = None\n    ) -> Coordinates:\n        \"\"\"\n        Discretize the wire in ndiscr equidistant points or with a reference dl\n        segment step.\n\n        Parameters\n        ----------\n        ndiscr:\n            Number of points to discretize to\n        byedges:\n            Whether or not to discretise by edges. If True, each edge is\n            discretized separately using an approximated distance\n            (wire.Length/ndiscr) or the specified dl. If True, it is\n            possible that ndiscr is larger than specified.\n        dl:\n            Discretise by length, overriding ndiscr\n\n        Returns\n        -------\n        Coordinates of the discretized points.\n        \"\"\"\n        if byedges:\n            points = cadapi.discretize_by_edges(self.shape, ndiscr=ndiscr, dl=dl)\n        else:\n            points = cadapi.discretize(self.shape, ndiscr=ndiscr, dl=dl)\n        return Coordinates(points.T)\n\n    def value_at(\n        self, alpha: Optional[float] = None, distance: Optional[float] = None\n    ) -> np.ndarray:\n        \"\"\"\n        Get a point along the wire at a given parameterised length or length.\n\n        Parameters\n        ----------\n        alpha:\n            Parameterised distance along the wire length, in the range [0 .. 1]\n        distance:\n            Physical distance along the wire length\n\n        Returns\n        -------\n        Point coordinates (w.r.t. BluemiraWire's BluemiraPlacement)\n        \"\"\"\n        if alpha is None and distance is None:\n            raise GeometryError(\"Must specify one of alpha or distance.\")\n        if alpha is not None and distance is not None:\n            raise GeometryError(\"Must specify either alpha or distance, not both.\")\n\n        if distance is None:\n            if alpha < 0.0:\n                bluemira_warn(\n                    f\"alpha must be between 0 and 1, not: {alpha}, setting to 0.0\"\n                )\n                alpha = 0\n            elif alpha > 1.0:\n                bluemira_warn(\n                    f\"alpha must be between 0 and 1, not: {alpha}, setting to 1.0\"\n                )\n                alpha = 1.0\n            distance = alpha * self.length\n\n        return cadapi.wire_value_at(self.shape, distance)\n\n    def parameter_at(\n        self, vertex: Iterable[float], tolerance: float = EPS * 10\n    ) -> float:\n        \"\"\"\n        Get the parameter value at a vertex along a wire.\n\n        Parameters\n        ----------\n        vertex:\n            Vertex for which to get the parameter\n        tolerance:\n            Tolerance within which to get the parameter\n\n        Returns\n        -------\n        Parameter value along the wire at the vertex\n\n        Raises\n        ------\n        GeometryError:\n            If the vertex is further away to the wire than the specified tolerance\n        \"\"\"\n        try:\n            return cadapi.wire_parameter_at(\n                self.shape, vertex=vertex, tolerance=tolerance\n            )\n        except FreeCADError as e:\n            raise GeometryError(e.args[0])\n\n    def start_point(self) -> Coordinates:\n        \"\"\"\n        Get the coordinates of the start of the wire.\n        \"\"\"\n        return Coordinates(cadapi.start_point(self.shape))\n\n    def end_point(self) -> Coordinates:\n        \"\"\"\n        Get the coordinates of the end of the wire.\n        \"\"\"\n        return Coordinates(cadapi.end_point(self.shape))\n\n    @property\n    def vertexes(self) -> Coordinates:\n        \"\"\"\n        The ordered vertexes of the wire.\n        \"\"\"\n        vertexes = cadapi.ordered_vertexes(self.shape)\n        if len(vertexes) == 3:\n            LOGGER.disabled = True\n            coords = Coordinates(vertexes.T)\n            LOGGER.disabled = False\n            return coords\n\n        return Coordinates(vertexes)\n\n    @property\n    def edges(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The ordered edges of the wire.\n        \"\"\"\n        return tuple(\n            [BluemiraWire(cadapi.apiWire(o)) for o in cadapi.ordered_edges(self.shape)]\n        )\n\n    @property\n    def wires(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The wires of the wire. By definition a tuple of itself.\n        \"\"\"\n        return tuple([self])\n\n    @property\n    def faces(self) -> tuple:\n        \"\"\"\n        The faces of the wire. By definition an empty tuple.\n        \"\"\"\n        return ()\n\n    @property\n    def shells(self) -> tuple:\n        \"\"\"\n        The shells of the wire. By definition an empty tuple.\n        \"\"\"\n        return ()\n\n    @property\n    def solids(self) -> tuple:\n        \"\"\"\n        The solids of the wire. By definition an empty tuple.\n        \"\"\"\n        return ()",
  "def __init__(\n        self, boundary: List[Union[cadapi.apiWire, BluemiraWire]], label: str = \"\"\n    ):\n        boundary_classes = [self.__class__, cadapi.apiWire]\n        super().__init__(boundary, label, boundary_classes)\n        self._check_orientations()",
  "def _check_orientations(self):\n        orientations = []\n        for boundary in self.boundary:\n            if isinstance(boundary, cadapi.apiWire):\n                orient = boundary.Orientation\n            elif isinstance(boundary, self.__class__):\n                orient = boundary.shape.Orientation\n            orientations.append(orient)\n\n        if orientations.count(orientations[0]) != len(orientations):\n            raise MixedOrientationWireError(\n                f\"Cannot make a BluemiraWire from wires of mixed orientations: {orientations}\"\n            )\n        self._orientation = orientations[0]\n        if self._orientation != _Orientation(self.shape.Orientation):\n            self.shape.reverse()",
  "def _converter(func):\n        def wrapper(*args, **kwargs):\n            output = func(*args, **kwargs)\n            if isinstance(output, cadapi.apiWire):\n                output = BluemiraWire(output)\n            return output\n\n        return wrapper",
  "def _create_shape(self) -> cadapi.apiWire:\n        \"\"\"apiWire: shape of the object as a single wire\"\"\"\n        return self._create_wire()",
  "def _create_wire(self, check_reverse: bool = True):\n        wire = cadapi.apiWire(self._get_wires())\n        if check_reverse:\n            return self._check_reverse(wire)\n        else:\n            return wire",
  "def _get_wires(self) -> List[cadapi.apiWire]:\n        \"\"\"list(apiWire): list of wires of which the shape consists of.\"\"\"\n        wires = []\n        for o in self.boundary:\n            if isinstance(o, cadapi.apiWire):\n                for w in o.Wires:\n                    wire = cadapi.apiWire(w.OrderedEdges)\n                    if self._orientation != _Orientation(wire.Orientation):\n                        wire.reverse()\n                    wires += [wire]\n            else:\n                wires += o._get_wires()\n        return wires",
  "def __add__(self, other: BluemiraWire) -> BluemiraWire:\n        \"\"\"Add two wires\"\"\"\n        output = None\n        if isinstance(other, BluemiraWire):\n            output = BluemiraWire([self, other])\n        else:\n            raise TypeError(f\"{type(other)} is not an instance of BluemiraWire.\")\n        return output",
  "def close(self, label: str = \"\") -> None:\n        \"\"\"\n        Close the shape with a line segment between shape's end and start point.\n        This function modifies the object boundary.\n        \"\"\"\n        if not self.is_closed():\n            closure = BluemiraWire(cadapi.wire_closure(self.shape), label)\n            self._boundary.append(closure)\n            self._set_boundary(self.boundary)\n\n        # check that the new boundary is closed\n        if not self.is_closed():\n            raise NotClosedWire(\"The open boundary has not been closed.\")",
  "def discretize(\n        self, ndiscr: int = 100, byedges: bool = False, dl: Optional[float] = None\n    ) -> Coordinates:\n        \"\"\"\n        Discretize the wire in ndiscr equidistant points or with a reference dl\n        segment step.\n\n        Parameters\n        ----------\n        ndiscr:\n            Number of points to discretize to\n        byedges:\n            Whether or not to discretise by edges. If True, each edge is\n            discretized separately using an approximated distance\n            (wire.Length/ndiscr) or the specified dl. If True, it is\n            possible that ndiscr is larger than specified.\n        dl:\n            Discretise by length, overriding ndiscr\n\n        Returns\n        -------\n        Coordinates of the discretized points.\n        \"\"\"\n        if byedges:\n            points = cadapi.discretize_by_edges(self.shape, ndiscr=ndiscr, dl=dl)\n        else:\n            points = cadapi.discretize(self.shape, ndiscr=ndiscr, dl=dl)\n        return Coordinates(points.T)",
  "def value_at(\n        self, alpha: Optional[float] = None, distance: Optional[float] = None\n    ) -> np.ndarray:\n        \"\"\"\n        Get a point along the wire at a given parameterised length or length.\n\n        Parameters\n        ----------\n        alpha:\n            Parameterised distance along the wire length, in the range [0 .. 1]\n        distance:\n            Physical distance along the wire length\n\n        Returns\n        -------\n        Point coordinates (w.r.t. BluemiraWire's BluemiraPlacement)\n        \"\"\"\n        if alpha is None and distance is None:\n            raise GeometryError(\"Must specify one of alpha or distance.\")\n        if alpha is not None and distance is not None:\n            raise GeometryError(\"Must specify either alpha or distance, not both.\")\n\n        if distance is None:\n            if alpha < 0.0:\n                bluemira_warn(\n                    f\"alpha must be between 0 and 1, not: {alpha}, setting to 0.0\"\n                )\n                alpha = 0\n            elif alpha > 1.0:\n                bluemira_warn(\n                    f\"alpha must be between 0 and 1, not: {alpha}, setting to 1.0\"\n                )\n                alpha = 1.0\n            distance = alpha * self.length\n\n        return cadapi.wire_value_at(self.shape, distance)",
  "def parameter_at(\n        self, vertex: Iterable[float], tolerance: float = EPS * 10\n    ) -> float:\n        \"\"\"\n        Get the parameter value at a vertex along a wire.\n\n        Parameters\n        ----------\n        vertex:\n            Vertex for which to get the parameter\n        tolerance:\n            Tolerance within which to get the parameter\n\n        Returns\n        -------\n        Parameter value along the wire at the vertex\n\n        Raises\n        ------\n        GeometryError:\n            If the vertex is further away to the wire than the specified tolerance\n        \"\"\"\n        try:\n            return cadapi.wire_parameter_at(\n                self.shape, vertex=vertex, tolerance=tolerance\n            )\n        except FreeCADError as e:\n            raise GeometryError(e.args[0])",
  "def start_point(self) -> Coordinates:\n        \"\"\"\n        Get the coordinates of the start of the wire.\n        \"\"\"\n        return Coordinates(cadapi.start_point(self.shape))",
  "def end_point(self) -> Coordinates:\n        \"\"\"\n        Get the coordinates of the end of the wire.\n        \"\"\"\n        return Coordinates(cadapi.end_point(self.shape))",
  "def vertexes(self) -> Coordinates:\n        \"\"\"\n        The ordered vertexes of the wire.\n        \"\"\"\n        vertexes = cadapi.ordered_vertexes(self.shape)\n        if len(vertexes) == 3:\n            LOGGER.disabled = True\n            coords = Coordinates(vertexes.T)\n            LOGGER.disabled = False\n            return coords\n\n        return Coordinates(vertexes)",
  "def edges(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The ordered edges of the wire.\n        \"\"\"\n        return tuple(\n            [BluemiraWire(cadapi.apiWire(o)) for o in cadapi.ordered_edges(self.shape)]\n        )",
  "def wires(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The wires of the wire. By definition a tuple of itself.\n        \"\"\"\n        return tuple([self])",
  "def faces(self) -> tuple:\n        \"\"\"\n        The faces of the wire. By definition an empty tuple.\n        \"\"\"\n        return ()",
  "def shells(self) -> tuple:\n        \"\"\"\n        The shells of the wire. By definition an empty tuple.\n        \"\"\"\n        return ()",
  "def solids(self) -> tuple:\n        \"\"\"\n        The solids of the wire. By definition an empty tuple.\n        \"\"\"\n        return ()",
  "def wrapper(*args, **kwargs):\n            output = func(*args, **kwargs)\n            if isinstance(output, cadapi.apiWire):\n                output = BluemiraWire(output)\n            return output",
  "def coordinates_to_pyclippath(coordinates: Coordinates) -> np.ndarray:\n    \"\"\"\n    Transforms a bluemira Coordinates object into a Path for use in pyclipper\n\n    Parameters\n    ----------\n    coordinates:\n        The Coordinates to be used in pyclipper\n\n    Returns\n    -------\n    The vertex polygon path formatting required by pyclipper\n    \"\"\"\n    return scale_to_clipper(coordinates.xz.T)",
  "def pyclippath_to_coordinates(path: np.ndarray) -> Coordinates:\n    \"\"\"\n    Transforms a pyclipper path into a bluemira Coordinates object\n\n    Parameters\n    ----------\n    path:\n        The vertex polygon path formatting used in pyclipper\n\n    Returns\n    -------\n    The Coordinates from the path object\n    \"\"\"\n    p2 = scale_from_clipper(np.array(path).T)\n    return Coordinates({\"x\": p2[0], \"y\": 0, \"z\": p2[1]})",
  "def pyclippolytree_to_coordinates(polytree: List[np.ndarray]) -> List[Coordinates]:\n    \"\"\"\n    Converts a ClipperLib PolyTree into a list of Coordinates\n\n    Parameters\n    ----------\n    polytree:\n        The polytree to convert to Coordinates\n    \"\"\"\n    paths = PolyTreeToPaths(polytree)\n    return [pyclippath_to_coordinates(path) for path in paths]",
  "class PyclipperMixin:\n    \"\"\"\n    Mixin class for typical pyclipper operations and processing\n    \"\"\"\n\n    name = NotImplemented\n\n    def perform(self):\n        \"\"\"\n        Perform the pyclipper operation\n        \"\"\"\n        raise NotImplementedError\n\n    def raise_warning(self):\n        \"\"\"\n        Raise a warning if None is to be returned.\n        \"\"\"\n        bluemira_warn(f\"{self.name} operation on 2-D polygons returning None.\\n\")\n\n    def handle_solution(self, solution: Tuple[np.ndarray]) -> List[Coordinates]:\n        \"\"\"\n        Handles the output of the Pyclipper.Execute(*) algorithms, turning them\n        into Coordaintes objects. NOTE: These are closed by default.\n\n        Parameters\n        ----------\n        solution:\n            The tuple of tuple of tuple of path vertices\n\n        Returns\n        -------\n        The list of Coordinates objects produced by the pyclipper operations\n        \"\"\"\n        if not solution:\n            self.raise_warning()\n            return None\n        else:\n            coords = []\n            if isinstance(solution, PyPolyNode):\n                coords = pyclippolytree_to_coordinates(solution)\n            else:\n                for path in solution:\n                    c = pyclippath_to_coordinates(path)\n                    c.close()\n                    coords.append(c)\n\n            # Sort open coordinates by length\n            return sorted(coords, key=lambda x: -x.length)",
  "class OffsetOperationManager(PyclipperMixin):\n    \"\"\"\n    Abstract base class for offset operations\n\n    Parameters\n    ----------\n    coordinates:\n        The Coordinates upon which to perform the offset operation\n    \"\"\"\n\n    method = NotImplemented\n    closed_method = ET_CLOSEDPOLYGON\n    open_method = NotImplementedError\n\n    def __init__(self, coordinates: Coordinates):\n        self.tool = PyclipperOffset()\n        path = coordinates_to_pyclippath(coordinates)\n        self._scale = self._calculate_scale(path, coordinates)  # Store scale\n\n        if coordinates.closed:\n            co_method = self.closed_method\n        else:\n            co_method = self.open_method\n\n        self.tool.AddPath(path, self.method, co_method)\n\n    def perform(self, delta: float):\n        \"\"\"\n        Perform the offset operation.\n\n        Parameters\n        ----------\n        delta:\n            The value of the offset [m]. Positive for increasing size, negative for\n            decreasing\n        \"\"\"\n        delta = int(round(delta * self._scale))  # approximation\n        solution = self.tool.Execute(delta)\n        return self.handle_solution(solution)\n\n    @staticmethod\n    def _calculate_scale(path: np.ndarray, coordinates: Coordinates):\n        \"\"\"\n        Calculate the pyclipper scaling to integers\n        \"\"\"\n        # Find the first non-zero dimension (low number of iterations)\n        for i in range(len(path) - 1):\n            if path[i][0] != 0:\n                return path[i][0] / coordinates.x[i]\n            if path[i][1] != 0:\n                return path[i][1] / coordinates.z[i]",
  "class RoundOffset(OffsetOperationManager):\n    \"\"\"\n    Offset class for rounded offsets.\n    \"\"\"\n\n    name = \"Round Offset\"\n    method = JT_ROUND\n    open_method = ET_OPENROUND",
  "class SquareOffset(OffsetOperationManager):\n    \"\"\"\n    Offset class for squared offsets.\n    \"\"\"\n\n    name = \"Square Offset\"\n    method = JT_SQUARE\n    open_method = ET_OPENSQUARE",
  "class MiterOffset(OffsetOperationManager):\n    \"\"\"\n    Offset class for mitered offsets.\n    \"\"\"\n\n    name = \"Miter Offset\"\n    method = JT_MITER\n    open_method = ET_OPENROUND\n\n    def __init__(self, coordinates: Coordinates, miter_limit: float = 2.0):\n        super().__init__(coordinates)\n\n        self.tool.MiterLimit = miter_limit",
  "def offset_clipper(\n    coordinates: Coordinates,\n    delta: float,\n    method: str = \"square\",\n    miter_limit: float = 2.0,\n) -> Coordinates:\n    \"\"\"\n    Carries out an offset operation on the Coordinates using the ClipperLib library.\n    Only supports closed Coordinates.\n\n    Parameters\n    ----------\n    coordinates:\n        The Coordinates upon which to perform the offset operation\n    delta:\n        The value of the offset [m]. Positive for increasing size, negative for\n        decreasing\n    method:\n        The type of offset to perform ['square', 'round', 'miter']\n    miter_limit:\n        The ratio of delta to use when mitering acute corners. Only used if\n        method == 'miter'\n\n    Returns\n    -------\n    The offset Coordinates result\n\n    Raises\n    ------\n    GeometryError:\n        If the Coordinates are not planar\n        If the Coordinates are not closed\n    \"\"\"\n    if not coordinates.is_planar:\n        raise GeometryError(\"Cannot offset non-planar coordinates.\")\n\n    if not coordinates.closed:\n        raise GeometryError(\"Open Coordinates are not supported by offset_clipper.\")\n\n    # Transform coordinates to x-z plane\n    coordinates = deepcopy(coordinates)\n    com = coordinates.center_of_mass\n\n    t_coordinates = transform_coordinates_to_xz(\n        coordinates, -np.array(com), (0.0, 1.0, 0.0)\n    )\n\n    if method == \"square\":\n        tool = SquareOffset(t_coordinates)\n    elif method == \"round\":\n        bluemira_warn(\"I don't know why, but this is very slow...\")\n        tool = RoundOffset(t_coordinates)\n    elif method == \"miter\":\n        tool = MiterOffset(t_coordinates, miter_limit=miter_limit)\n    else:\n        raise GeometryError(\n            \"Please choose an offset method from:\\n round \\n square \\n miter\"\n        )\n\n    result = tool.perform(delta)\n    if result is None:\n        raise GeometryError(\n            f\"Offset operation with delta={delta} resulted in no geometry.\"\n        )\n\n    if len(result) > 1:\n        bluemira_warn(\n            f\"Offset operation with delta={delta} has produced multiple 'islands'; only returning the biggest one!\"\n        )\n\n    result = result[0]\n\n    # Transform offset coordinates back to original plane\n    result = transform_coordinates_to_original(result, com, coordinates.normal_vector)\n    return result",
  "def transform_coordinates_to_xz(\n    coordinates: Coordinates, base: np.ndarray, direction: np.ndarray\n) -> Coordinates:\n    \"\"\"\n    Rotate coordinates to the x-z plane.\n    \"\"\"\n    coordinates.translate(base)\n    if abs(coordinates.normal_vector[1]) == 1.0:\n        return coordinates\n\n    r = rotation_matrix_v1v2(coordinates.normal_vector, np.array(direction))\n    x, y, z = r.T @ coordinates\n\n    coordinates = Coordinates({\"x\": x, \"y\": y, \"z\": z})\n    return coordinates",
  "def transform_coordinates_to_original(\n    coordinates: Coordinates, base: np.ndarray, original_normal: np.ndarray\n) -> Coordinates:\n    \"\"\"\n    Rotate coordinates back to original plane\n    \"\"\"\n    r = rotation_matrix_v1v2(coordinates.normal_vector, np.array(original_normal))\n    x, y, z = r.T @ coordinates\n    coordinates = Coordinates({\"x\": x, \"y\": y, \"z\": z})\n    coordinates.translate(base)\n    return coordinates",
  "def perform(self):\n        \"\"\"\n        Perform the pyclipper operation\n        \"\"\"\n        raise NotImplementedError",
  "def raise_warning(self):\n        \"\"\"\n        Raise a warning if None is to be returned.\n        \"\"\"\n        bluemira_warn(f\"{self.name} operation on 2-D polygons returning None.\\n\")",
  "def handle_solution(self, solution: Tuple[np.ndarray]) -> List[Coordinates]:\n        \"\"\"\n        Handles the output of the Pyclipper.Execute(*) algorithms, turning them\n        into Coordaintes objects. NOTE: These are closed by default.\n\n        Parameters\n        ----------\n        solution:\n            The tuple of tuple of tuple of path vertices\n\n        Returns\n        -------\n        The list of Coordinates objects produced by the pyclipper operations\n        \"\"\"\n        if not solution:\n            self.raise_warning()\n            return None\n        else:\n            coords = []\n            if isinstance(solution, PyPolyNode):\n                coords = pyclippolytree_to_coordinates(solution)\n            else:\n                for path in solution:\n                    c = pyclippath_to_coordinates(path)\n                    c.close()\n                    coords.append(c)\n\n            # Sort open coordinates by length\n            return sorted(coords, key=lambda x: -x.length)",
  "def __init__(self, coordinates: Coordinates):\n        self.tool = PyclipperOffset()\n        path = coordinates_to_pyclippath(coordinates)\n        self._scale = self._calculate_scale(path, coordinates)  # Store scale\n\n        if coordinates.closed:\n            co_method = self.closed_method\n        else:\n            co_method = self.open_method\n\n        self.tool.AddPath(path, self.method, co_method)",
  "def perform(self, delta: float):\n        \"\"\"\n        Perform the offset operation.\n\n        Parameters\n        ----------\n        delta:\n            The value of the offset [m]. Positive for increasing size, negative for\n            decreasing\n        \"\"\"\n        delta = int(round(delta * self._scale))  # approximation\n        solution = self.tool.Execute(delta)\n        return self.handle_solution(solution)",
  "def _calculate_scale(path: np.ndarray, coordinates: Coordinates):\n        \"\"\"\n        Calculate the pyclipper scaling to integers\n        \"\"\"\n        # Find the first non-zero dimension (low number of iterations)\n        for i in range(len(path) - 1):\n            if path[i][0] != 0:\n                return path[i][0] / coordinates.x[i]\n            if path[i][1] != 0:\n                return path[i][1] / coordinates.z[i]",
  "def __init__(self, coordinates: Coordinates, miter_limit: float = 2.0):\n        super().__init__(coordinates)\n\n        self.tool.MiterLimit = miter_limit",
  "class MixedFaceAreaError(GeometryError):\n    \"\"\"\n    An error to raise when the area of a mixed face does not give a good match to the\n    area enclosed by the original coordinates.\n    \"\"\"\n\n    pass",
  "def _segment_lengths(x: np.ndarray, y: np.ndarray, z: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns the length of each individual segment in a set of coordinates\n\n    Parameters\n    ----------\n    x:\n        x coordinates [m]\n    y:\n        y coordinates [m]\n    z:\n        z coordinates [m]\n\n    Returns\n    -------\n    The array of the length of each individual segment in the coordinates\n    \"\"\"\n    return np.sqrt(np.diff(x) ** 2 + np.diff(y) ** 2 + np.diff(z) ** 2)",
  "def _side_vector(polygon_array: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculates the side vectors of an anti-clockwise polygon\n\n    Parameters\n    ----------\n    polygon_array:\n        The 2-D array of polygon point coordinates\n\n    Returns\n    -------\n    sides:\n        The 2-D array of the polygon side vectors\n    \"\"\"\n    return polygon_array - np.roll(polygon_array, 1)",
  "def offset(\n    x: np.ndarray, z: np.ndarray, offset_value: float\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Get a square-based offset of the coordinates (no splines). N-sized output\n\n    Parameters\n    ----------\n    x:\n        The x coordinate vector\n    z:\n        The x coordinate vector\n    offset_value:\n        The offset value [m]\n\n    Returns\n    -------\n    xo:\n        The x offset coordinates\n    zo:\n        The z offset coordinates\n    \"\"\"\n    # check numpy arrays:\n    x, z = np.array(x), np.array(z)\n    # check closed:\n    if (x[-2:] == x[:2]).all() and (z[-2:] == z[:2]).all():\n        closed = True\n    elif x[0] == x[-1] and z[0] == z[-1]:\n        closed = True\n        # Need to \"double lock\" it for closed curves\n        x = np.append(x, x[1])\n        z = np.append(z, z[1])\n    else:\n        closed = False\n    p = np.array([np.array(x), np.array(z)])\n    # Normal vectors for each side\n    v = normal_vector(_side_vector(p))\n    # Construct points offset\n    off_p = np.column_stack(p + offset_value * v)\n    off_p2 = np.column_stack(np.roll(p, 1) + offset_value * v)\n    off_p = np.array([off_p[:, 0], off_p[:, 1]])\n    off_p2 = np.array([off_p2[:, 0], off_p2[:, 1]])\n    ox = np.empty((off_p2[0].size + off_p2[0].size,))\n    oz = np.empty((off_p2[1].size + off_p2[1].size,))\n    ox[0::2], ox[1::2] = off_p2[0], off_p[0]\n    oz[0::2], oz[1::2] = off_p2[1], off_p[1]\n    off_s = np.array([ox[2:], oz[2:]]).T\n    pnts = []\n    for i in range(len(off_s[:, 0]) - 2)[0::2]:\n        pnts.append(vector_intersect(off_s[i], off_s[i + 1], off_s[i + 3], off_s[i + 2]))\n    pnts.append(pnts[0])\n    pnts = np.array(pnts)[:-1][::-1]  # sorted ccw nicely\n    if closed:\n        pnts = np.concatenate((pnts, [pnts[0]]))  # Closed\n    else:  # Add end points\n        pnts = np.concatenate((pnts, [off_s[0]]))\n        pnts = np.concatenate(([off_s[-1]], pnts))\n    # sorted ccw nicely - i know looks weird but.. leave us kids alone\n    # drop nan values\n    return pnts[~np.isnan(pnts).any(axis=1)][::-1].T",
  "def make_circle_arc(\n    radius: float,\n    x_centre: float = 0,\n    y_centre: float = 0,\n    angle: float = 2 * np.pi,\n    n_points: int = 200,\n    start_angle: float = 0,\n) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Make a circle arc of a specified radius and angle at a given location.\n\n    Parameters\n    ----------\n    radius:\n        The radius of the circle arc\n    x_centre:\n        The x coordinate of the circle arc centre\n    y_centre:\n        The y coordinate of the circle arc centre\n    angle:\n        The angle of the circle arc [radians]\n    n_points:\n        The number of points on the circle\n    start_angle:\n        The starting angle of the circle arc\n\n    Returns\n    -------\n    x:\n        The x coordinates of the circle arc\n    y:\n        The y coordinates of the circle arc\n    \"\"\"\n    n = np.linspace(start_angle, start_angle + angle, n_points)\n    x = x_centre + radius * np.cos(n)\n    y = y_centre + radius * np.sin(n)\n    if angle == 2 * np.pi:\n        # Small number correction (close circle exactly)\n        x[-1] = x[0]\n        y[-1] = y[0]\n    return x, y",
  "def convert_coordinates_to_wire(\n    x: np.ndarray,\n    y: np.ndarray,\n    z: np.ndarray,\n    label: str = \"\",\n    method: str = \"mixed\",\n    **kwargs: Dict[str, Any],\n) -> BluemiraWire:\n    \"\"\"\n    Converts the provided coordinates into a BluemiraWire using the specified method.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates of points to be converted to a BluemiraWire object\n    y:\n        The y coordinates of points to be converted to a BluemiraWire object\n    z:\n        The z coordinates of points to be converted to a BluemiraWire object\n    method:\n        The conversion method to be used:\n\n            - mixed (default): results in a mix of splines and polygons\n            - polygon: pure polygon representation\n            - spline: pure spline representation\n\n    label:\n        The label for the resulting BluemiraWire object\n    kwargs:\n        Any other arguments for the conversion method, see e.g. make_mixed_face\n\n    Returns\n    -------\n    The resulting BluemiraWire from the conversion\n    \"\"\"\n    method_map = {\n        \"mixed\": make_mixed_wire,\n        \"polygon\": partial(make_wire, spline=False),\n        \"spline\": partial(make_wire, spline=True),\n    }\n    wire = method_map[method](x, y, z, label=label, **kwargs)\n    return wire",
  "def convert_coordinates_to_face(\n    x: np.ndarray,\n    y: np.ndarray,\n    z: np.ndarray,\n    method: str = \"mixed\",\n    label: str = \"\",\n    **kwargs: Dict[str, Any],\n) -> BluemiraFace:\n    \"\"\"\n    Converts the provided coordinates into a BluemiraFace using the specified method.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates of points to be converted to a BluemiraFace object\n    y:\n        The y coordinates of points to be converted to a BluemiraFace object\n    z:\n        The z coordinates of points to be converted to a BluemiraFace object\n    method: str\n        The conversion method to be used:\n\n            - mixed (default): results in a mix of splines and polygons\n            - polygon: pure polygon representation\n            - spline: pure spline representation\n\n    label:\n        The label for the resulting BluemiraFace object\n    kwargs:\n        Any other arguments for the conversion method, see e.g. make_mixed_face\n\n    Returns\n    -------\n    The resulting BluemiraFace from the conversion\n    \"\"\"\n    method_map = {\n        \"mixed\": make_mixed_face,\n        \"polygon\": partial(make_face, spline=False),\n        \"spline\": partial(make_face, spline=True),\n    }\n    face = method_map[method](x, y, z, label=label, **kwargs)\n    return face",
  "def make_mixed_wire(\n    x: np.ndarray,\n    y: np.ndarray,\n    z: np.ndarray,\n    label: str = \"\",\n    *,\n    median_factor: float = 2.0,\n    n_segments: int = 4,\n    a_acute: float = 150.0,\n    cleaning_atol: float = 1e-6,\n    allow_fallback: bool = True,\n    debug: bool = False,\n) -> BluemiraWire:\n    \"\"\"\n    Construct a BluemiraWire object from the provided coordinates using a combination of\n    polygon and spline wires. Polygons are determined by having a median length larger\n    than the threshold or an angle that is more acute than the threshold.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates of points to be converted to a BluemiraWire object\n    y:\n        The y coordinates of points to be converted to a BluemiraWire object\n    z:\n        The z coordinates of points to be converted to a BluemiraWire object\n    label:\n        The label for the resulting BluemiraWire object\n\n    Other Parameters\n    ----------------\n    median_factor:\n        The factor of the median for which to filter segment lengths\n        (below median_factor*median_length --> spline)\n    n_segments:\n        The minimum number of segments for a spline\n    a_acute:\n        The angle [degrees] between two consecutive segments deemed to be too\n        acute to be fit with a spline.\n    cleaning_atol:\n        If a point lies within this distance [m] of the previous point then it will be\n        treated as a duplicate and removed. This can stabilise the conversion in cases\n        where the point density is too high for a wire to be constructed as a spline.\n        By default this is set to 1e-6.\n    allow_fallback:\n        If True then a failed attempt to make a mixed wire will fall back to a polygon\n        wire, else an exception will be raised. By default True.\n    debug:\n        Whether or not to print debugging information\n\n    Returns\n    -------\n    The BluemiraWire of the mixed polygon/spline coordinates\n    \"\"\"\n    mfm = MixedFaceMaker(\n        x,\n        y,\n        z,\n        label=label,\n        median_factor=median_factor,\n        n_segments=n_segments,\n        a_acute=a_acute,\n        cleaning_atol=cleaning_atol,\n        debug=debug,\n    )\n    try:\n        mfm.build()\n\n    except RuntimeError as e:\n        if allow_fallback:\n            bluemira_warn(\n                f\"CAD: MixedFaceMaker failed with error {e} \"\n                \"- falling back to a polygon wire.\"\n            )\n            return make_wire(x, y, z, label=label)\n        else:\n            raise\n\n    return mfm.wire",
  "def make_mixed_face(\n    x: np.ndarray,\n    y: np.ndarray,\n    z: np.ndarray,\n    label: str = \"\",\n    *,\n    median_factor: float = 2.0,\n    n_segments: int = 4,\n    a_acute: float = 150.0,\n    cleaning_atol: float = 1e-6,\n    area_rtol: float = 5e-2,\n    allow_fallback: bool = True,\n    debug: bool = False,\n) -> BluemiraFace:\n    \"\"\"\n    Construct a BluemiraFace object from the provided coordinates using a combination of\n    polygon and spline wires. Polygons are determined by having a median length larger\n    than the threshold or an angle that is more acute than the threshold.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates of points to be converted to a BluemiraFace object\n    y:\n        The y coordinates of points to be converted to a BluemiraFace object\n    z:\n        The z coordinates of points to be converted to a BluemiraFace object\n    label:\n        The label for the resulting BluemiraFace object\n\n    Other Parameters\n    ----------------\n    median_factor:\n        The factor of the median for which to filter segment lengths\n        (below median_factor*median_length --> spline)\n    n_segments:\n        The minimum number of segments for a spline\n    a_acute:\n        The angle [degrees] between two consecutive segments deemed to be too\n        acute to be fit with a spline.\n    cleaning_atol:\n        If a point lies within this distance [m] of the previous point then it will be\n        treated as a duplicate and removed. This can stabilise the conversion in cases\n        where the point density is too high for a wire to be constructed as a spline.\n        By default this is set to 1e-6.\n    area_rtol:\n        If the area of the resulting face deviates by this relative value from the area\n        enclosed by the provided coordinates then the conversion will fail and either\n        fall back to a polygon-like face or raise an exception, depending on the setting\n        of `allow_fallback`.\n    allow_fallback:\n        If True then a failed attempt to make a mixed face will fall back to a polygon\n        wire, else an exception will be raised. By default True.\n    debug:\n        Whether or not to print debugging information\n\n    Returns\n    -------\n    The BluemiraFace of the mixed polygon/spline coordinates\n    \"\"\"\n    mfm = MixedFaceMaker(\n        x,\n        y,\n        z,\n        label=label,\n        median_factor=median_factor,\n        n_segments=n_segments,\n        a_acute=a_acute,\n        cleaning_atol=cleaning_atol,\n        debug=debug,\n    )\n    try:\n        mfm.build()\n\n    except RuntimeError as e:\n        if allow_fallback:\n            bluemira_warn(\n                f\"CAD: MixedFaceMaker failed with error {e} \"\n                \"- falling back to a polygon face.\"\n            )\n            return make_face(x, y, z, label=label)\n        else:\n            raise\n\n    # Sometimes there won't be a RuntimeError, and you get a free SIGSEGV for your\n    # troubles.\n    face_area = mfm.face.area\n    coords_area = get_area(x, y, z)\n    if np.isclose(coords_area, face_area, rtol=area_rtol):\n        return mfm.face\n    else:\n        if allow_fallback:\n            bluemira_warn(\n                f\"CAD: MixedFaceMaker resulted in a face with area {face_area} \"\n                f\"but the provided coordinates enclosed an area of {coords_area} \"\n                \"- falling back to a polygon face.\"\n            )\n            return make_face(x, y, z, label=label)\n        else:\n            raise MixedFaceAreaError(\n                f\"MixedFaceMaker resulted in a face with area {face_area} \"\n                f\"but the provided coordinates enclosed an area of {coords_area}.\"\n            )",
  "def make_wire(\n    x: np.ndarray, y: np.ndarray, z: np.ndarray, label: str = \"\", spline: bool = False\n) -> BluemiraWire:\n    \"\"\"\n    Makes a wire from a set of coordinates.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates of points to be converted to a BluemiraWire object\n    y:\n        The y coordinates of points to be converted to a BluemiraWire object\n    z:\n        The z coordinates of points to be converted to a BluemiraWire object\n    label:\n        The label for the resulting BluemiraWire object\n    spline:\n        If True then creates the BluemiraWire using a Bezier spline curve, by default\n        False\n\n    Returns\n    -------\n    The BluemiraWire bound by the coordinates\n    \"\"\"\n    wire_func = cadapi.interpolate_bspline if spline else cadapi.make_polygon\n    return BluemiraWire(wire_func(np.array([x, y, z]).T), label=label)",
  "def make_face(\n    x: np.ndarray, y: np.ndarray, z: np.ndarray, label: str = \"\", spline: bool = False\n) -> BluemiraFace:\n    \"\"\"\n    Makes a face from a set of coordinates.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates of points to be converted to a BluemiraFace object\n    y:\n        The y coordinates of points to be converted to a BluemiraFace object\n    z:\n        The z coordinates of points to be converted to a BluemiraFace object\n    label:\n        The label for the resulting BluemiraFace object\n    spline:\n        If True then creates the BluemiraFace using a Bezier spline curve, by default\n        False\n\n    Returns\n    -------\n    The BluemiraFace bound by the coordinates\n    \"\"\"\n    wire = make_wire(x, y, z, label=label, spline=spline)\n    return BluemiraFace(wire, label=label)",
  "class MixedFaceMaker:\n    \"\"\"\n    Utility class for the creation of Faces that combine splines and polygons.\n\n    Polygons are detected by median length and turning angle.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates of points to be converted to a BluemiraFace object\n    y:\n        The y coordinates of points to be converted to a BluemiraFace object\n    z:\n        The z coordinates of points to be converted to a BluemiraFace object\n    label:\n        The label for the resulting BluemiraFace object\n\n    Other Parameters\n    ----------------\n    median_factor:\n        The factor of the median for which to filter segment lengths\n        (below median_factor*median_length --> spline)\n    n_segments:\n        The minimum number of segments for a spline\n    a_acute:\n        The angle [degrees] between two consecutive segments deemed to be too\n        acute to be fit with a spline.\n    cleaning_atol:\n        If a point lies within this distance [m] of the previous point then it will be\n        treated as a duplicate and removed. This can stabilise the conversion in cases\n        where the point density is too high for a wire to be constructed as a spline.\n        By default this is set to 1e-6.\n    debug:\n        Whether or not to print debugging information\n    \"\"\"\n\n    def __init__(\n        self,\n        x: np.ndarray,\n        y: np.ndarray,\n        z: np.ndarray,\n        label: str = \"\",\n        *,\n        median_factor: float = 2.0,\n        n_segments: int = 4,\n        a_acute: float = 150.0,\n        cleaning_atol: float = 1e-6,\n        debug: bool = False,\n    ):\n        _validate_coordinates(x, y, z)\n        self.x = np.copy(x)\n        self.y = np.copy(y)\n        self.z = np.copy(z)\n        self.num_points = len(x)\n\n        self.label = label\n\n        self.median_factor = median_factor\n        self.n_segments = n_segments\n        self.a_acute = a_acute\n        self.cleaning_atol = cleaning_atol\n        self.debug = debug\n\n        # Constructors\n        self.edges = None\n        self.wire = None\n        self.face = None\n        self.polygon_loops = None\n        self.spline_loops = None\n        self.flag_spline_first = None\n        self._debugger = None\n\n    def build(self):\n        \"\"\"\n        Carry out the MixedFaceMaker sequence to make a Face\n        \"\"\"\n        # Get the vertices of polygon-like segments\n        p_vertices = self._find_polygon_vertices()\n\n        if len(p_vertices) > 0:\n            # identify sequences of polygon indices\n            p_sequences = self._get_polygon_sequences(p_vertices)\n\n            if (\n                len(p_sequences) == 1\n                and p_sequences[0][0] == 0\n                and p_sequences[0][-1] == len(p_vertices) - 1\n            ):\n                # All vertices are pure polygon-like so just make the wire\n                self.wires = make_wire(self.x, self.y, self.z, spline=False)\n            else:\n                # Get the (negative) of the polygon sequences to get spline sequences\n                s_sequences = self._get_spline_sequences(p_sequences)\n\n                if self.debug:\n                    print(\"p_sequences :\", p_sequences)\n                    print(\"s_sequences :\", s_sequences)\n\n                # Make coordinates for all the segments\n                self._make_subcoordinates(p_sequences, s_sequences)\n\n                # Make the wires for each of the sub-coordinates, and daisychain them\n                self._make_subwires()\n        else:\n            # All vertices are pure spline-like so just make the wire\n            self.wires = make_wire(self.x, self.y, self.z, spline=True)\n\n        # Finally, make the OCC face from the wire formed from the boundary wires\n        self._make_wire()\n        self.face = BluemiraFace(self.wire, label=self.label)\n\n    def _find_polygon_vertices(self) -> np.ndarray:\n        \"\"\"\n        Finds all vertices in the Coordinates which belong to polygon-like edges\n\n        Returns\n        -------\n        The vertices of the coordinates which are polygon-like (dtype=int)\n        \"\"\"\n        seg_lengths = _segment_lengths(self.x, self.y, self.z)\n        median = np.median(seg_lengths)\n\n        long_indices = np.where(seg_lengths > self.median_factor * median)[0]\n\n        # find sharp angle indices\n        angles = np.zeros(len(self.x) - 2)\n        for i in range(len(self.x) - 2):\n            angles[i] = get_angle_between_points(\n                [self.x[i], self.y[i], self.z[i]],\n                [self.x[i + 1], self.y[i + 1], self.z[i + 1]],\n                [self.x[i + 2], self.y[i + 2], self.z[i + 2]],\n            )\n        if (\n            self.x[0] == self.x[-1]\n            and self.y[0] == self.y[-1]\n            and self.z[0] == self.z[-1]\n        ):\n            # Get the angle over the closed joint\n            join_angle = get_angle_between_points(\n                [self.x[-2], self.y[-2], self.z[-2]],\n                [self.x[0], self.y[0], self.z[0]],\n                [self.x[1], self.y[1], self.z[1]],\n            )\n            angles = np.append(angles, join_angle)\n\n        angles = np.rad2deg(angles)\n        sharp_indices = np.where((angles <= self.a_acute) & (angles != 0))[0]\n        # Convert angle numbering to segment numbering (both segments of angle)\n        sharp_edge_indices = []\n        for index in sharp_indices:\n            sharp_edges = [index + 1, index + 2]\n            sharp_edge_indices.extend(sharp_edges)\n        sharp_edge_indices = np.array(sharp_edge_indices)\n\n        # build ordered set of polygon edge indices\n        indices = np.unique(np.append(long_indices, sharp_edge_indices))\n\n        # build ordered set of polygon vertex indices\n        vertices = []\n        for index in indices:\n            if index == self.num_points:\n                # If it is the last index, do not overshoot\n                vertices.extend([index])\n            else:\n                vertices.extend([index, index + 1])\n        vertices = np.unique(np.array(vertices, dtype=int))\n        return vertices\n\n    def _get_polygon_sequences(self, vertices: np.ndarray) -> List[List[float]]:\n        \"\"\"\n        Gets the sequences of polygon segments\n\n        Parameters\n        ----------\n        vertices:\n            The vertices of the lcoordinates which are polygon-like\n\n        Returns\n        -------\n        The list of start and end tuples of the polygon segments\n        list([start, end], [start, end])\n        \"\"\"\n        sequences = []\n\n        if len(vertices) == 0:\n            return sequences\n\n        start = vertices[0]\n        for i, vertex in enumerate(vertices[:-1]):\n            delta = vertices[i + 1] - vertex\n\n            if i == len(vertices) - 2:\n                # end of coordinates clean-up\n                end = vertices[i + 1]\n                sequences.append([start, end])\n                break\n\n            if delta <= self.n_segments:\n                # Spline would be too short, so stitch polygons together\n                continue\n            else:\n                end = vertex\n                sequences.append([start, end])\n                start = vertices[i + 1]  # reset start index\n\n        if not sequences:\n            raise GeometryError(\"Not a good candidate for a mixed face ==> spline\")\n\n        if (\n            len(sequences) == 1\n            and sequences[0][0] == 0\n            and sequences[0][1] == len(vertices) - 1\n        ):\n            # Shape is a pure polygon\n            return sequences\n\n        # Now check the start and end of the coordinates, to see if a polygon segment\n        # bridges the join\n        first_p_vertex = sequences[0][0]\n        last_p_vertex = sequences[-1][1]\n\n        if first_p_vertex <= self.n_segments:\n            if self.num_points - last_p_vertex <= self.n_segments:\n                start_offset = self.n_segments - first_p_vertex\n                end_offset = (self.num_points - last_p_vertex) + self.n_segments\n                total = start_offset + end_offset\n                if total <= self.n_segments:\n                    start = sequences[-1][0]\n                    end = sequences[0][1]\n                    # Remove first sequence\n                    sequences = sequences[1:]\n                    # Replace last sequence with bridged sequence\n                    sequences[-1] = [start, end]\n\n        last_p_vertex = sequences[-1][1]\n        if self.num_points - last_p_vertex <= self.n_segments:\n            # There is a small spline section at the end of the coordinates, that\n            # needs to be bridged\n            if sequences[0][0] == 0:\n                # There is no bridge -> take action\n                start = sequences[-1][0]\n                end = sequences[0][1]\n                sequences = sequences[1:]\n                sequences[-1] = [start, end]\n\n        return sequences\n\n    def _get_spline_sequences(self, polygon_sequences: np.ndarray) -> List[List[float]]:\n        \"\"\"\n        Gets the sequences of spline segments\n\n        Parameters\n        ----------\n        polygon_sequences:\n            The list of start and end tuples of the polygon segments\n\n        Returns\n        -------\n        The list of start and end tuples of the spline segments\n        list([start, end], [start, end])\n        \"\"\"\n        spline_sequences = []\n\n        # Catch the start, if polygon doesn't start at zero, and there is no\n        # bridge\n        last = polygon_sequences[-1]\n        if last[0] > last[1]:  # there is a polygon bridge\n            pass  # Don't add a spline at the start\n        else:\n            # Check that the first polygon segment doesn't start at zero\n            first = polygon_sequences[0]\n            if first[0] == 0:\n                pass\n            else:  # It doesn't start at zero and there is no bridge: catch\n                spline_sequences.append([0, first[0]])\n\n        for i, seq in enumerate(polygon_sequences[:-1]):\n            start = seq[1]\n            end = polygon_sequences[i + 1][0]\n            spline_sequences.append([start, end])\n\n        # Catch the end, if polygon doesn't end at end\n        if last[1] == self.num_points:\n            # NOTE: if this is true, there can't be a polygon bridge\n            pass\n        else:\n            if last[0] > last[1]:  # there is a polygon bridge\n                spline_sequences.append([last[1], polygon_sequences[0][0]])\n            else:\n                spline_sequences.append([last[1], self.num_points])\n\n        # Check if we need to make a spline bridge\n        spline_first = spline_sequences[0][0]\n        spline_last = spline_sequences[-1][1]\n        if (spline_first == 0) and (spline_last == self.num_points):\n            # Make a spline bridge\n            start = spline_sequences[-1][0]\n            end = spline_sequences[0][1]\n            spline_sequences = spline_sequences[1:]\n            spline_sequences[-1] = [start, end]\n\n        if spline_sequences[0][0] == 0:\n            self.flag_spline_first = True\n        else:\n            self.flag_spline_first = False\n\n        return spline_sequences\n\n    def _clean_coordinates(self, coords: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Clean the provided coordinates by removing any values that are closer than the\n        instance's cleaning_atol value.\n\n        Parameters\n        ----------\n        coords:\n            3D array of coordinates to be cleaned.\n\n        Returns\n        -------\n        3D array of cleaned coordinates.\n        \"\"\"\n        mask = ~np.isclose(_segment_lengths(*coords), 0, atol=self.cleaning_atol)\n        mask = np.insert(mask, 0, True)\n        return coords[:, mask]\n\n    def _make_subcoordinates(\n        self, polygon_sequences: np.ndarray, spline_sequences: np.ndarray\n    ):\n        polygon_coords = []\n        spline_coords = []\n\n        for sequence, s_coords in [\n            [polygon_sequences, polygon_coords],\n            [spline_sequences, spline_coords],\n        ]:\n            for seg in sequence:\n                if seg[0] > seg[1]:\n                    # There is a bridge\n                    coords = np.hstack(\n                        (\n                            np.array(\n                                [self.x[seg[0] :], self.y[seg[0] :], self.z[seg[0] :]]\n                            ),\n                            np.array(\n                                [\n                                    self.x[0 : seg[1] + 1],\n                                    self.y[0 : seg[1] + 1],\n                                    self.z[0 : seg[1] + 1],\n                                ]\n                            ),\n                        )\n                    )\n                else:\n                    coords = np.array(\n                        [\n                            self.x[seg[0] : seg[1] + 1],\n                            self.y[seg[0] : seg[1] + 1],\n                            self.z[seg[0] : seg[1] + 1],\n                        ]\n                    )\n                clean_coords = self._clean_coordinates(coords)\n                if all(shape >= 2 for shape in clean_coords.shape):\n                    s_coords.append(clean_coords)\n\n        self.spline_coords = spline_coords\n        self.polygon_coords = polygon_coords\n\n    def _make_subwires(self):\n        # First daisy-chain correctly...\n        coords_order = []\n        if self.flag_spline_first:\n            set1, set2 = self.spline_coords, self.polygon_coords\n        else:\n            set2, set1 = self.spline_coords, self.polygon_coords\n        for i, (a, b) in enumerate(zip_longest(set1, set2)):\n            if a is not None:\n                coords_order.append(set1[i])\n            if b is not None:\n                coords_order.append(set2[i])\n\n        for i, coords in enumerate(coords_order[:-1]):\n            if not (coords[:, -1] == coords_order[i + 1][:, 0]).all():\n                coords_order[i + 1] = coords_order[i + 1][:, ::-1]\n                if i == 0:\n                    if not (coords[:, -1] == coords_order[i + 1][:, 0]).all():\n                        coords = coords[:, ::-1]\n                        if not (coords[:, -1] == coords_order[i + 1][:, 0]).all():\n                            coords_order[i + 1] = coords_order[i + 1][:, ::-1]\n\n        if self.flag_spline_first:\n            set1 = [\n                make_wire(*spline_coord, spline=True)\n                for spline_coord in self.spline_coords\n            ]\n            set2 = [\n                make_wire(*polygon_coord, spline=False)\n                for polygon_coord in self.polygon_coords\n            ]\n        else:\n            set2 = [\n                make_wire(*spline_coord, spline=True)\n                for spline_coord in self.spline_coords\n            ]\n            set1 = [\n                make_wire(*polygon_coord, spline=False)\n                for polygon_coord in self.polygon_coords\n            ]\n\n        wires = []\n        for i, (a, b) in enumerate(zip_longest(set1, set2)):\n            if a is not None:\n                wires.append(a)\n\n            if b is not None:\n                wires.append(b)\n\n        self.wires = list(flatten_iterable(wires))\n        self._debugger = coords_order\n\n    def _make_wire(self):\n        self.wire = BluemiraWire(self.wires)\n\n    def _make_face(self):\n        self.face = BluemiraFace(self.wire)",
  "def __init__(\n        self,\n        x: np.ndarray,\n        y: np.ndarray,\n        z: np.ndarray,\n        label: str = \"\",\n        *,\n        median_factor: float = 2.0,\n        n_segments: int = 4,\n        a_acute: float = 150.0,\n        cleaning_atol: float = 1e-6,\n        debug: bool = False,\n    ):\n        _validate_coordinates(x, y, z)\n        self.x = np.copy(x)\n        self.y = np.copy(y)\n        self.z = np.copy(z)\n        self.num_points = len(x)\n\n        self.label = label\n\n        self.median_factor = median_factor\n        self.n_segments = n_segments\n        self.a_acute = a_acute\n        self.cleaning_atol = cleaning_atol\n        self.debug = debug\n\n        # Constructors\n        self.edges = None\n        self.wire = None\n        self.face = None\n        self.polygon_loops = None\n        self.spline_loops = None\n        self.flag_spline_first = None\n        self._debugger = None",
  "def build(self):\n        \"\"\"\n        Carry out the MixedFaceMaker sequence to make a Face\n        \"\"\"\n        # Get the vertices of polygon-like segments\n        p_vertices = self._find_polygon_vertices()\n\n        if len(p_vertices) > 0:\n            # identify sequences of polygon indices\n            p_sequences = self._get_polygon_sequences(p_vertices)\n\n            if (\n                len(p_sequences) == 1\n                and p_sequences[0][0] == 0\n                and p_sequences[0][-1] == len(p_vertices) - 1\n            ):\n                # All vertices are pure polygon-like so just make the wire\n                self.wires = make_wire(self.x, self.y, self.z, spline=False)\n            else:\n                # Get the (negative) of the polygon sequences to get spline sequences\n                s_sequences = self._get_spline_sequences(p_sequences)\n\n                if self.debug:\n                    print(\"p_sequences :\", p_sequences)\n                    print(\"s_sequences :\", s_sequences)\n\n                # Make coordinates for all the segments\n                self._make_subcoordinates(p_sequences, s_sequences)\n\n                # Make the wires for each of the sub-coordinates, and daisychain them\n                self._make_subwires()\n        else:\n            # All vertices are pure spline-like so just make the wire\n            self.wires = make_wire(self.x, self.y, self.z, spline=True)\n\n        # Finally, make the OCC face from the wire formed from the boundary wires\n        self._make_wire()\n        self.face = BluemiraFace(self.wire, label=self.label)",
  "def _find_polygon_vertices(self) -> np.ndarray:\n        \"\"\"\n        Finds all vertices in the Coordinates which belong to polygon-like edges\n\n        Returns\n        -------\n        The vertices of the coordinates which are polygon-like (dtype=int)\n        \"\"\"\n        seg_lengths = _segment_lengths(self.x, self.y, self.z)\n        median = np.median(seg_lengths)\n\n        long_indices = np.where(seg_lengths > self.median_factor * median)[0]\n\n        # find sharp angle indices\n        angles = np.zeros(len(self.x) - 2)\n        for i in range(len(self.x) - 2):\n            angles[i] = get_angle_between_points(\n                [self.x[i], self.y[i], self.z[i]],\n                [self.x[i + 1], self.y[i + 1], self.z[i + 1]],\n                [self.x[i + 2], self.y[i + 2], self.z[i + 2]],\n            )\n        if (\n            self.x[0] == self.x[-1]\n            and self.y[0] == self.y[-1]\n            and self.z[0] == self.z[-1]\n        ):\n            # Get the angle over the closed joint\n            join_angle = get_angle_between_points(\n                [self.x[-2], self.y[-2], self.z[-2]],\n                [self.x[0], self.y[0], self.z[0]],\n                [self.x[1], self.y[1], self.z[1]],\n            )\n            angles = np.append(angles, join_angle)\n\n        angles = np.rad2deg(angles)\n        sharp_indices = np.where((angles <= self.a_acute) & (angles != 0))[0]\n        # Convert angle numbering to segment numbering (both segments of angle)\n        sharp_edge_indices = []\n        for index in sharp_indices:\n            sharp_edges = [index + 1, index + 2]\n            sharp_edge_indices.extend(sharp_edges)\n        sharp_edge_indices = np.array(sharp_edge_indices)\n\n        # build ordered set of polygon edge indices\n        indices = np.unique(np.append(long_indices, sharp_edge_indices))\n\n        # build ordered set of polygon vertex indices\n        vertices = []\n        for index in indices:\n            if index == self.num_points:\n                # If it is the last index, do not overshoot\n                vertices.extend([index])\n            else:\n                vertices.extend([index, index + 1])\n        vertices = np.unique(np.array(vertices, dtype=int))\n        return vertices",
  "def _get_polygon_sequences(self, vertices: np.ndarray) -> List[List[float]]:\n        \"\"\"\n        Gets the sequences of polygon segments\n\n        Parameters\n        ----------\n        vertices:\n            The vertices of the lcoordinates which are polygon-like\n\n        Returns\n        -------\n        The list of start and end tuples of the polygon segments\n        list([start, end], [start, end])\n        \"\"\"\n        sequences = []\n\n        if len(vertices) == 0:\n            return sequences\n\n        start = vertices[0]\n        for i, vertex in enumerate(vertices[:-1]):\n            delta = vertices[i + 1] - vertex\n\n            if i == len(vertices) - 2:\n                # end of coordinates clean-up\n                end = vertices[i + 1]\n                sequences.append([start, end])\n                break\n\n            if delta <= self.n_segments:\n                # Spline would be too short, so stitch polygons together\n                continue\n            else:\n                end = vertex\n                sequences.append([start, end])\n                start = vertices[i + 1]  # reset start index\n\n        if not sequences:\n            raise GeometryError(\"Not a good candidate for a mixed face ==> spline\")\n\n        if (\n            len(sequences) == 1\n            and sequences[0][0] == 0\n            and sequences[0][1] == len(vertices) - 1\n        ):\n            # Shape is a pure polygon\n            return sequences\n\n        # Now check the start and end of the coordinates, to see if a polygon segment\n        # bridges the join\n        first_p_vertex = sequences[0][0]\n        last_p_vertex = sequences[-1][1]\n\n        if first_p_vertex <= self.n_segments:\n            if self.num_points - last_p_vertex <= self.n_segments:\n                start_offset = self.n_segments - first_p_vertex\n                end_offset = (self.num_points - last_p_vertex) + self.n_segments\n                total = start_offset + end_offset\n                if total <= self.n_segments:\n                    start = sequences[-1][0]\n                    end = sequences[0][1]\n                    # Remove first sequence\n                    sequences = sequences[1:]\n                    # Replace last sequence with bridged sequence\n                    sequences[-1] = [start, end]\n\n        last_p_vertex = sequences[-1][1]\n        if self.num_points - last_p_vertex <= self.n_segments:\n            # There is a small spline section at the end of the coordinates, that\n            # needs to be bridged\n            if sequences[0][0] == 0:\n                # There is no bridge -> take action\n                start = sequences[-1][0]\n                end = sequences[0][1]\n                sequences = sequences[1:]\n                sequences[-1] = [start, end]\n\n        return sequences",
  "def _get_spline_sequences(self, polygon_sequences: np.ndarray) -> List[List[float]]:\n        \"\"\"\n        Gets the sequences of spline segments\n\n        Parameters\n        ----------\n        polygon_sequences:\n            The list of start and end tuples of the polygon segments\n\n        Returns\n        -------\n        The list of start and end tuples of the spline segments\n        list([start, end], [start, end])\n        \"\"\"\n        spline_sequences = []\n\n        # Catch the start, if polygon doesn't start at zero, and there is no\n        # bridge\n        last = polygon_sequences[-1]\n        if last[0] > last[1]:  # there is a polygon bridge\n            pass  # Don't add a spline at the start\n        else:\n            # Check that the first polygon segment doesn't start at zero\n            first = polygon_sequences[0]\n            if first[0] == 0:\n                pass\n            else:  # It doesn't start at zero and there is no bridge: catch\n                spline_sequences.append([0, first[0]])\n\n        for i, seq in enumerate(polygon_sequences[:-1]):\n            start = seq[1]\n            end = polygon_sequences[i + 1][0]\n            spline_sequences.append([start, end])\n\n        # Catch the end, if polygon doesn't end at end\n        if last[1] == self.num_points:\n            # NOTE: if this is true, there can't be a polygon bridge\n            pass\n        else:\n            if last[0] > last[1]:  # there is a polygon bridge\n                spline_sequences.append([last[1], polygon_sequences[0][0]])\n            else:\n                spline_sequences.append([last[1], self.num_points])\n\n        # Check if we need to make a spline bridge\n        spline_first = spline_sequences[0][0]\n        spline_last = spline_sequences[-1][1]\n        if (spline_first == 0) and (spline_last == self.num_points):\n            # Make a spline bridge\n            start = spline_sequences[-1][0]\n            end = spline_sequences[0][1]\n            spline_sequences = spline_sequences[1:]\n            spline_sequences[-1] = [start, end]\n\n        if spline_sequences[0][0] == 0:\n            self.flag_spline_first = True\n        else:\n            self.flag_spline_first = False\n\n        return spline_sequences",
  "def _clean_coordinates(self, coords: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Clean the provided coordinates by removing any values that are closer than the\n        instance's cleaning_atol value.\n\n        Parameters\n        ----------\n        coords:\n            3D array of coordinates to be cleaned.\n\n        Returns\n        -------\n        3D array of cleaned coordinates.\n        \"\"\"\n        mask = ~np.isclose(_segment_lengths(*coords), 0, atol=self.cleaning_atol)\n        mask = np.insert(mask, 0, True)\n        return coords[:, mask]",
  "def _make_subcoordinates(\n        self, polygon_sequences: np.ndarray, spline_sequences: np.ndarray\n    ):\n        polygon_coords = []\n        spline_coords = []\n\n        for sequence, s_coords in [\n            [polygon_sequences, polygon_coords],\n            [spline_sequences, spline_coords],\n        ]:\n            for seg in sequence:\n                if seg[0] > seg[1]:\n                    # There is a bridge\n                    coords = np.hstack(\n                        (\n                            np.array(\n                                [self.x[seg[0] :], self.y[seg[0] :], self.z[seg[0] :]]\n                            ),\n                            np.array(\n                                [\n                                    self.x[0 : seg[1] + 1],\n                                    self.y[0 : seg[1] + 1],\n                                    self.z[0 : seg[1] + 1],\n                                ]\n                            ),\n                        )\n                    )\n                else:\n                    coords = np.array(\n                        [\n                            self.x[seg[0] : seg[1] + 1],\n                            self.y[seg[0] : seg[1] + 1],\n                            self.z[seg[0] : seg[1] + 1],\n                        ]\n                    )\n                clean_coords = self._clean_coordinates(coords)\n                if all(shape >= 2 for shape in clean_coords.shape):\n                    s_coords.append(clean_coords)\n\n        self.spline_coords = spline_coords\n        self.polygon_coords = polygon_coords",
  "def _make_subwires(self):\n        # First daisy-chain correctly...\n        coords_order = []\n        if self.flag_spline_first:\n            set1, set2 = self.spline_coords, self.polygon_coords\n        else:\n            set2, set1 = self.spline_coords, self.polygon_coords\n        for i, (a, b) in enumerate(zip_longest(set1, set2)):\n            if a is not None:\n                coords_order.append(set1[i])\n            if b is not None:\n                coords_order.append(set2[i])\n\n        for i, coords in enumerate(coords_order[:-1]):\n            if not (coords[:, -1] == coords_order[i + 1][:, 0]).all():\n                coords_order[i + 1] = coords_order[i + 1][:, ::-1]\n                if i == 0:\n                    if not (coords[:, -1] == coords_order[i + 1][:, 0]).all():\n                        coords = coords[:, ::-1]\n                        if not (coords[:, -1] == coords_order[i + 1][:, 0]).all():\n                            coords_order[i + 1] = coords_order[i + 1][:, ::-1]\n\n        if self.flag_spline_first:\n            set1 = [\n                make_wire(*spline_coord, spline=True)\n                for spline_coord in self.spline_coords\n            ]\n            set2 = [\n                make_wire(*polygon_coord, spline=False)\n                for polygon_coord in self.polygon_coords\n            ]\n        else:\n            set2 = [\n                make_wire(*spline_coord, spline=True)\n                for spline_coord in self.spline_coords\n            ]\n            set1 = [\n                make_wire(*polygon_coord, spline=False)\n                for polygon_coord in self.polygon_coords\n            ]\n\n        wires = []\n        for i, (a, b) in enumerate(zip_longest(set1, set2)):\n            if a is not None:\n                wires.append(a)\n\n            if b is not None:\n                wires.append(b)\n\n        self.wires = list(flatten_iterable(wires))\n        self._debugger = coords_order",
  "def _make_wire(self):\n        self.wire = BluemiraWire(self.wires)",
  "def _make_face(self):\n        self.face = BluemiraFace(self.wire)",
  "class BluemiraPlane:\n    \"\"\"\n    Bluemira Plane class.\n\n    Parameters\n    ----------\n    base:\n        Plane reference point\n    axis:\n        normal vector dto the plane\n    label:\n        Label of the plane\n    \"\"\"\n\n    def __init__(\n        self,\n        base: Tuple[float, float, float] = (0.0, 0.0, 0.0),\n        axis: Tuple[float, float, float] = (0.0, 0.0, 1.0),\n        label: str = \"\",\n    ):\n        if np.allclose(np.array(axis), np.array([0, 0, 0])):\n            raise ValueError(\"Axis must to be a vector with non zero norm.\")\n        self._shape = cadapi.make_plane(base, axis)\n        self.label = label\n\n    @classmethod\n    def from_3_points(\n        cls,\n        point_1: Iterable[float],\n        point_2: Iterable[float],\n        point_3: Iterable[float],\n        label: str = \"\",\n    ):\n        \"\"\"\n        Instantiate a BluemiraPlane from three points.\n\n        Parameters\n        ----------\n        point_1:\n            First point\n        point_2:\n            Second Point\n        point_3:\n            Third point\n        label:\n            Label of the plane\n        \"\"\"\n        plane = BluemiraPlane()\n        plane._shape = cadapi.make_plane_from_3_points(point_1, point_2, point_3)\n        plane.label = label\n        return plane\n\n    @property\n    def base(self) -> np.ndarray:\n        \"\"\"Plane's reference point\"\"\"\n        return cadapi.vector_to_numpy(self._shape.Position)\n\n    @base.setter\n    def base(self, value: Iterable[float]):\n        \"\"\"\n        Set a new plane base\n\n        Parameters\n        ----------\n        value:\n            Base vector\n        \"\"\"\n        self._shape.Position = cadapi.Base.Vector(value)\n\n    @property\n    def axis(self) -> np.ndarray:\n        \"\"\"Plane's normal vector\"\"\"\n        return cadapi.vector_to_numpy(self._shape.Axis)\n\n    @axis.setter\n    def axis(self, value: Iterable[float]):\n        \"\"\"\n        Set a new plane axis\n\n        Parameters\n        ----------\n        value:\n            Axis vector\n        \"\"\"\n        self._shape.Axis = cadapi.Base.Vector(value)\n\n    def move(self, vector: Iterable[float]):\n        \"\"\"Moves the Plane along the given vector\"\"\"\n        self.base = self.base + np.array(vector)\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Plane __repr__\n        \"\"\"\n        return (\n            f\"([{type(self).__name__}] = Label: {self.label},\"\n            f\" base: {self.base},\"\n            f\" axis: {self.axis})\"\n        )\n\n    def copy(self, label: Optional[str] = None):\n        \"\"\"\n        Make a copy of the BluemiraGeo.\n        \"\"\"\n        plane_copy = copy.copy(self)\n        if label is not None:\n            plane_copy.label = label\n        else:\n            plane_copy.label = self.label\n        return plane_copy\n\n    def deepcopy(self, label: Optional[str] = None):\n        \"\"\"Make a deepcopy of the BluemiraPlane\"\"\"\n        plane_copy = BluemiraPlane(self.base, self.axis)\n        if label is not None:\n            plane_copy.label = label\n        else:\n            plane_copy.label = self.label\n        return plane_copy\n\n    def to_face(\n        self, width: float = VERY_BIG, height: float = VERY_BIG, label: str = \"\"\n    ) -> BluemiraFace:\n        \"\"\"\n        Convert the plane to a face with dimension (width, height) and centred into\n        the plane base position.\n        \"\"\"\n        face = cadapi.face_from_plane(self._shape, width, height)\n        bmface = BluemiraFace._create(face, label)\n        return bmface\n\n    def to_placement(self) -> BluemiraPlacement:\n        \"\"\"\n        Convert the plane into a placement\n        \"\"\"\n        from bluemira.geometry.placement import BluemiraPlacement\n\n        return BluemiraPlacement._create(cadapi.placement_from_plane(self._shape))",
  "def __init__(\n        self,\n        base: Tuple[float, float, float] = (0.0, 0.0, 0.0),\n        axis: Tuple[float, float, float] = (0.0, 0.0, 1.0),\n        label: str = \"\",\n    ):\n        if np.allclose(np.array(axis), np.array([0, 0, 0])):\n            raise ValueError(\"Axis must to be a vector with non zero norm.\")\n        self._shape = cadapi.make_plane(base, axis)\n        self.label = label",
  "def from_3_points(\n        cls,\n        point_1: Iterable[float],\n        point_2: Iterable[float],\n        point_3: Iterable[float],\n        label: str = \"\",\n    ):\n        \"\"\"\n        Instantiate a BluemiraPlane from three points.\n\n        Parameters\n        ----------\n        point_1:\n            First point\n        point_2:\n            Second Point\n        point_3:\n            Third point\n        label:\n            Label of the plane\n        \"\"\"\n        plane = BluemiraPlane()\n        plane._shape = cadapi.make_plane_from_3_points(point_1, point_2, point_3)\n        plane.label = label\n        return plane",
  "def base(self) -> np.ndarray:\n        \"\"\"Plane's reference point\"\"\"\n        return cadapi.vector_to_numpy(self._shape.Position)",
  "def base(self, value: Iterable[float]):\n        \"\"\"\n        Set a new plane base\n\n        Parameters\n        ----------\n        value:\n            Base vector\n        \"\"\"\n        self._shape.Position = cadapi.Base.Vector(value)",
  "def axis(self) -> np.ndarray:\n        \"\"\"Plane's normal vector\"\"\"\n        return cadapi.vector_to_numpy(self._shape.Axis)",
  "def axis(self, value: Iterable[float]):\n        \"\"\"\n        Set a new plane axis\n\n        Parameters\n        ----------\n        value:\n            Axis vector\n        \"\"\"\n        self._shape.Axis = cadapi.Base.Vector(value)",
  "def move(self, vector: Iterable[float]):\n        \"\"\"Moves the Plane along the given vector\"\"\"\n        self.base = self.base + np.array(vector)",
  "def __repr__(self) -> str:\n        \"\"\"\n        Plane __repr__\n        \"\"\"\n        return (\n            f\"([{type(self).__name__}] = Label: {self.label},\"\n            f\" base: {self.base},\"\n            f\" axis: {self.axis})\"\n        )",
  "def copy(self, label: Optional[str] = None):\n        \"\"\"\n        Make a copy of the BluemiraGeo.\n        \"\"\"\n        plane_copy = copy.copy(self)\n        if label is not None:\n            plane_copy.label = label\n        else:\n            plane_copy.label = self.label\n        return plane_copy",
  "def deepcopy(self, label: Optional[str] = None):\n        \"\"\"Make a deepcopy of the BluemiraPlane\"\"\"\n        plane_copy = BluemiraPlane(self.base, self.axis)\n        if label is not None:\n            plane_copy.label = label\n        else:\n            plane_copy.label = self.label\n        return plane_copy",
  "def to_face(\n        self, width: float = VERY_BIG, height: float = VERY_BIG, label: str = \"\"\n    ) -> BluemiraFace:\n        \"\"\"\n        Convert the plane to a face with dimension (width, height) and centred into\n        the plane base position.\n        \"\"\"\n        face = cadapi.face_from_plane(self._shape, width, height)\n        bmface = BluemiraFace._create(face, label)\n        return bmface",
  "def to_placement(self) -> BluemiraPlacement:\n        \"\"\"\n        Convert the plane into a placement\n        \"\"\"\n        from bluemira.geometry.placement import BluemiraPlacement\n\n        return BluemiraPlacement._create(cadapi.placement_from_plane(self._shape))",
  "def inscribed_rect_in_poly(\n    x_poly: np.ndarray,\n    z_poly: np.ndarray,\n    x_point: float,\n    z_point: float,\n    aspectratio: float = 1.0,\n    *,\n    convex: bool = True,\n    rtol: float = 1e-06,\n    atol: float = 1e-08,\n) -> Tuple[float, float]:\n    \"\"\"\n    Find largest inscribed rectangle in a given polygon.\n\n    Parameters\n    ----------\n    x_poly:\n        x coordinates of the polygon\n    z_poly:\n        z coordinates of the polygon\n    x_point:\n        x coordinate of the centroid of the\n    z_point:\n        z coordinate of the centroid of the rectangle\n    aspectratio:\n        aspect ratio of rectangle\n    convex:\n        treat the loop as convex default:True\n    rtol:\n        The relative tolerance parameter (see Notes)\n    atol:\n        The absolute tolerance parameter (see Notes)\n\n    Returns\n    -------\n    dx:\n        half width of inscribed rectangle\n    dz:\n        half height of inscribed rectangle\n\n    Notes\n    -----\n    See notes of https://numpy.org/doc/stable/reference/generated/numpy.isclose.html\n    for an explanation of relative and absolute tolerances.\n    The tolerances only affects non convex loops in certain complex situations.\n    Setting either value to a very small value could cause the function to hang.\n    \"\"\"\n    coordinates = Coordinates({\"x\": x_poly, \"z\": z_poly})\n    if not coordinates.closed:\n        coordinates.close()\n\n    if not in_polygon(x_point, z_point, coordinates.xz.T, include_edges=False):\n        return 0, 0\n\n    x, z = x_point, z_point\n\n    angle_r = np.rad2deg(np.arctan(1 / aspectratio))\n\n    # Set up \"Union Jack\" intersection Planes\n    xx = Coordinates([[x, 0, z], [x + 1, 0, z], [x, 1, z], [0, 0, 0]])\n    zz = Coordinates([[x, 0, z], [x, 0, z + 1], [x, 1, z], [0, 0, 0]])\n\n    xo, rot_p = [x, 0, z], [0, 1, 0]\n\n    xx_plane = BluemiraPlane.from_3_points(*xx.points[:3])\n    zz_plane = BluemiraPlane.from_3_points(*zz.points[:3])\n\n    xx_rot = deepcopy(xx)\n    xx_rot.rotate(base=xo, direction=rot_p, degree=angle_r)\n    xz_plane = BluemiraPlane.from_3_points(*xx_rot.points[:3])\n\n    zz_rot = deepcopy(xx)\n    zz_rot.rotate(base=xo, direction=rot_p, degree=-angle_r)\n    zx_plane = BluemiraPlane.from_3_points(*zz_rot.points[:3])\n\n    # Set up distance calculation\n    getdxdz = _GetDxDz(\n        coordinates,\n        [x_point, z_point],\n        aspectratio,\n        convex,\n        [xx_plane, zz_plane, xz_plane, zx_plane],\n    )\n\n    dx, dz = getdxdz()\n\n    if convex or all(\n        [not i.size for i in get_intersect(_rect(x, z, dx, dz).xz, coordinates.xz)]\n    ):\n        return dx, dz\n\n    left, right = 0, dx\n\n    while not np.isclose(right, left, rtol=rtol, atol=atol):\n        dx = (left + right) / 2\n        dz = dx / aspectratio\n\n        if all(\n            [not i.size for i in get_intersect(_rect(x, z, dx, dz).xz, coordinates.xz)]\n        ):\n            left = dx  # increase the dx\n        else:\n            right = dx  # decrease the dx\n    return dx, dz",
  "class _GetDxDz:\n    \"\"\"\n    Calculate dx and dz of nearest edge intersection.\n\n    Parameters\n    ----------\n    coords:\n        Region coordinates\n    point:\n        central point of rectangle\n    aspectratio:\n        Aspect ratio of rectangle\n    convex:\n        convex region boolean\n    planes:\n        list of intersection planes\n    \"\"\"\n\n    def __init__(\n        self,\n        coords: Coordinates,\n        point: Tuple[float, float],\n        aspectratio: float,\n        convex: bool,\n        planes: List[BluemiraPlane],\n    ):\n        self.vec_arr_x = np.zeros((9, 2))\n        self.vec_arr_x[0] = point\n\n        self.point = point\n        self.coords = coords\n        self.planes = planes\n\n        self.n_p = 2 * len(planes)\n\n        self.aspectratio = aspectratio\n\n        self.elements = np.arange(1, self.n_p + 1)[0::2]\n\n        self.check = self.approx if convex else self.precise\n\n    def approx(self, n: int, lpi: np.ndarray):\n        \"\"\"\n        Approximate nearest intersection (for convex shapes).\n        \"\"\"\n        self.vec_arr_x[n : n + 2] = lpi[0, [0, 2]], lpi[-1, [0, 2]]\n\n    def precise(self, n, lpi):\n        \"\"\"\n        Precise nearest intersection.\n        \"\"\"\n        for i2, i in enumerate(lpi[:-1], start=1):\n            int_s1, int_s2 = i[[0, 2]], lpi[i2, [0, 2]]\n            # if point between intersection points\n            if np.allclose(\n                np.linalg.norm(int_s1 - self.point)\n                + np.linalg.norm(self.point - int_s2),\n                np.linalg.norm(int_s1 - int_s2),\n            ):\n                self.vec_arr_x[n : n + 2] = int_s1, int_s2\n                break\n\n    def __call__(self) -> Tuple[float, float]:\n        \"\"\"\n        Get dx and dz.\n\n        Returns\n        -------\n        dx:\n            maximum width/2 of rectangle\n        dz:\n            maximum height/2 of rectangle\n        \"\"\"\n        for n, plane in zip(self.elements, self.planes):\n            lpi = coords_plane_intersect(self.coords, plane)\n            self.check(n, lpi)\n\n        self.vec_arr_z = self.vec_arr_x.copy()\n        self.vec_arr_x[:, 1] = self.point[1]\n        self.vec_arr_z[:, 0] = self.point[0]\n\n        dist = np.array(\n            [\n                pdist(self.vec_arr_x, \"euclidean\")[: self.n_p],\n                pdist(self.vec_arr_z, \"euclidean\")[: self.n_p],\n            ]\n        )\n\n        # Find minimum distance\n        # this is loopy indexing TODO cleanup\n        # a1= [xz], a2= intersections, a3=staight/diagonal\n        dist = dist.reshape((2, -1, 2), order=\"F\")\n        amin = np.argmin(np.sum(dist, axis=0), axis=0)\n\n        (dx1, dz1), (dx2, dz2) = dist[:, amin[0], 0], dist[:, amin[1], 1]\n        if dx1 == 0:\n            dx1 = dz1 * self.aspectratio\n        elif dz1 == 0:\n            dz1 = dx1 / self.aspectratio\n\n        return (dx2, dz2) if dx2 < dx1 or dz2 < dz1 else (dx1, dz1)",
  "def _rect(x: float, z: float, dx: float, dz: float) -> Coordinates:\n    \"\"\"\n    Helper function to create a rectangular loop at a given point.\n\n    Parameters\n    ----------\n    x: float\n        central x coordinate\n    z: float\n        central z coordinate\n    dx: float\n        width/2 of rectangle\n    dz: float\n        height/2 of rectangle\n\n    Returns\n    -------\n    Rectangular closed set of coordinates\n    \"\"\"\n    return Coordinates(\n        {\n            \"x\": x + np.array([-dx, dx, dx, -dx, -dx]),\n            \"z\": z + np.array([-dz, -dz, dz, dz, -dz]),\n        }\n    )",
  "def __init__(\n        self,\n        coords: Coordinates,\n        point: Tuple[float, float],\n        aspectratio: float,\n        convex: bool,\n        planes: List[BluemiraPlane],\n    ):\n        self.vec_arr_x = np.zeros((9, 2))\n        self.vec_arr_x[0] = point\n\n        self.point = point\n        self.coords = coords\n        self.planes = planes\n\n        self.n_p = 2 * len(planes)\n\n        self.aspectratio = aspectratio\n\n        self.elements = np.arange(1, self.n_p + 1)[0::2]\n\n        self.check = self.approx if convex else self.precise",
  "def approx(self, n: int, lpi: np.ndarray):\n        \"\"\"\n        Approximate nearest intersection (for convex shapes).\n        \"\"\"\n        self.vec_arr_x[n : n + 2] = lpi[0, [0, 2]], lpi[-1, [0, 2]]",
  "def precise(self, n, lpi):\n        \"\"\"\n        Precise nearest intersection.\n        \"\"\"\n        for i2, i in enumerate(lpi[:-1], start=1):\n            int_s1, int_s2 = i[[0, 2]], lpi[i2, [0, 2]]\n            # if point between intersection points\n            if np.allclose(\n                np.linalg.norm(int_s1 - self.point)\n                + np.linalg.norm(self.point - int_s2),\n                np.linalg.norm(int_s1 - int_s2),\n            ):\n                self.vec_arr_x[n : n + 2] = int_s1, int_s2\n                break",
  "def __call__(self) -> Tuple[float, float]:\n        \"\"\"\n        Get dx and dz.\n\n        Returns\n        -------\n        dx:\n            maximum width/2 of rectangle\n        dz:\n            maximum height/2 of rectangle\n        \"\"\"\n        for n, plane in zip(self.elements, self.planes):\n            lpi = coords_plane_intersect(self.coords, plane)\n            self.check(n, lpi)\n\n        self.vec_arr_z = self.vec_arr_x.copy()\n        self.vec_arr_x[:, 1] = self.point[1]\n        self.vec_arr_z[:, 0] = self.point[0]\n\n        dist = np.array(\n            [\n                pdist(self.vec_arr_x, \"euclidean\")[: self.n_p],\n                pdist(self.vec_arr_z, \"euclidean\")[: self.n_p],\n            ]\n        )\n\n        # Find minimum distance\n        # this is loopy indexing TODO cleanup\n        # a1= [xz], a2= intersections, a3=staight/diagonal\n        dist = dist.reshape((2, -1, 2), order=\"F\")\n        amin = np.argmin(np.sum(dist, axis=0), axis=0)\n\n        (dx1, dz1), (dx2, dz2) = dist[:, amin[0], 0], dist[:, amin[1], 1]\n        if dx1 == 0:\n            dx1 = dz1 * self.aspectratio\n        elif dz1 == 0:\n            dz1 = dx1 / self.aspectratio\n\n        return (dx2, dz2) if dx2 < dx1 or dz2 < dz1 else (dx1, dz1)",
  "def xyz_process(func):\n    \"\"\"\n    Decorator for parsing x, y, z coordinates to numpy float arrays and dimension\n    checking.\n    \"\"\"\n\n    def wrapper(x, y, z=None):\n        _validate_coordinates(x, y, z)\n        x = np.ascontiguousarray(x, dtype=np.float_)\n        y = np.ascontiguousarray(y, dtype=np.float_)\n        if z is not None:\n            z = np.ascontiguousarray(z, dtype=np.float_)\n\n        return func(x, y, z)\n\n    return wrapper",
  "def _validate_coordinates(x, y, z=None):\n    if z is None:\n        if len(x) != len(y):\n            raise CoordinatesError(\n                \"All coordinates must have the same length but \"\n                f\"got len(x) = {len(x)}, len(y) = {len(y)}\"\n            )\n    else:\n        if not len(x) == len(y) == len(z):\n            raise CoordinatesError(\n                \"All coordinates must have the same length but \"\n                f\"got len(x) = {len(x)}, len(y) = {len(y)}, len(z) = {len(z)}\"\n            )",
  "def vector_lengthnorm(\n    x: np.ndarray, y: np.ndarray, z: Optional[np.ndarray] = None\n) -> np.ndarray:\n    \"\"\"\n    Get a normalised 1-D parameterisation of a set of x-y(-z) coordinates.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates\n    y:\n        The y coordinates\n    z:\n        The z coordinates. If None, carries out the operation in 2-D\n\n    Returns\n    -------\n    The normalised length vector\n    \"\"\"\n    coords = [x, y] if z is None else [x, y, z]\n    dl_vectors = np.sqrt(np.sum([np.diff(ci) ** 2 for ci in coords], axis=0))\n    length_ = np.append(0, np.cumsum(dl_vectors))\n    return length_ / length_[-1]",
  "def interpolate_points(\n    x: np.ndarray, y: np.ndarray, z: np.ndarray, n_points: int\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Interpolate points.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates\n    y:\n        The y coordinates\n    z:\n        The z coordinates\n    n_points:\n        number of points\n\n    Returns\n    -------\n    x:\n        The interpolated x coordinates\n    y:\n        The interpolated y coordinates\n    z:\n        The interpolated z coordinates\n    \"\"\"\n    ll = vector_lengthnorm(x, y, z)\n    linterp = np.linspace(0, 1, int(n_points))\n    x = interp1d(ll, x)(linterp)\n    y = interp1d(ll, y)(linterp)\n    z = interp1d(ll, z)(linterp)\n    return x, y, z",
  "def interpolate_midpoints(\n    x: np.ndarray,\n    y: np.ndarray,\n    z: np.ndarray,\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Interpolate the points adding the midpoint of each segment to the points.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates\n    y:\n        The y coordinates\n    z:\n        The z coordinates\n\n    Returns\n    -------\n    x:\n        The interpolated x coordinates\n    y:\n        The interpolated y coordinates\n    z:\n        The interpolated z coordinates\n    \"\"\"\n    xyz = np.c_[x, y, z]\n    xyz_new = xyz[:, :-1] + np.diff(xyz) / 2\n    xyz_new = np.insert(xyz_new, np.arange(len(x) - 1), xyz[:, :-1], axis=1)\n    xyz_new = np.append(xyz_new, xyz[:, -1].reshape(3, 1), axis=1)\n    return xyz_new[0], xyz_new[1], xyz_new[2]",
  "def get_normal_vector(x: np.ndarray, y: np.ndarray, z: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Calculate the normal vector from a series of planar points.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates\n    y:\n        The y coordinates\n    z:\n        The z coordinates\n\n    Returns\n    -------\n    The normalised normal vector\n    \"\"\"\n    if len(x) < 3:\n        raise CoordinatesError(\n            \"Cannot get a normal vector for a set of points with length less than 3.\"\n        )\n\n    if not (len(x) == len(y) == len(z)):\n        raise CoordinatesError(\"Point coordinate vectors must be of equal length.\")\n\n    n_hat = np.array([0.0, 0.0, 0.0])  # Force numba to type to floats\n    p1 = np.array([x[0], y[0], z[0]])\n    p2 = np.array([x[1], y[1], z[1]])\n    v1 = p2 - p1\n\n    # Force length 3 vectors to access index 2 without raising IndexErrors elsewhere\n    i_max = max(3, len(x) - 1)\n    for i in range(2, i_max):\n        p3 = np.array([x[i], y[i], z[i]])\n        v2 = p3 - p2\n\n        if np.all(np.abs(v2) < EPS):  # np.allclose not available in numba\n            v2 = p3 - p1\n            if np.all(np.abs(v2) < EPS):\n                continue\n\n        n_hat[:] = np.cross(v1, v2)\n\n        if not np.all(np.abs(n_hat) < EPS):\n            break\n    else:\n        raise CoordinatesError(\"Unable to find a normal vector from set of points.\")\n\n    return n_hat / np.linalg.norm(n_hat)",
  "def get_perimeter(x: np.ndarray, y: np.ndarray, z: Optional[np.ndarray] = None) -> float:\n    \"\"\"\n    Calculate the perimeter of a set of coordinates.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates\n    y:\n        The y coordinates\n    z:\n        The z coordinates\n\n    Returns\n    -------\n    The perimeter of the coordinates\n    \"\"\"\n    if z is None:\n        return get_perimeter_2d(x, y)\n    else:\n        return get_perimeter_3d(x, y, z)",
  "def get_perimeter_2d(x: np.ndarray, y: np.ndarray) -> float:\n    \"\"\"\n    Calculate the perimeter of a 2-D set of coordinates.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates\n    y:\n        The y coordinates\n\n    Returns\n    -------\n    The perimeter of the coordinates\n    \"\"\"\n    dx = x[1:] - x[:-1]\n    dy = y[1:] - y[:-1]\n    return np.sum(np.sqrt(dx**2 + dy**2))",
  "def get_perimeter_3d(x: np.ndarray, y: np.ndarray, z: np.ndarray) -> float:\n    \"\"\"\n    Calculate the perimeter of a set of 3-D coordinates.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates\n    y:\n        The y coordinates\n    z:\n        The z coordinates\n\n    Returns\n    -------\n    The perimeter of the coordinates\n    \"\"\"\n    dx = x[1:] - x[:-1]\n    dy = y[1:] - y[:-1]\n    dz = z[1:] - z[:-1]\n    return np.sum(np.sqrt(dx**2 + dy**2 + dz**2))",
  "def get_area(x: np.ndarray, y: np.ndarray, z: Optional[np.ndarray] = None) -> float:\n    \"\"\"\n    Calculate the area inside a closed polygon with x, y coordinate vectors.\n    `Link Shoelace method <https://en.wikipedia.org/wiki/Shoelace_formula>`_\n\n    Parameters\n    ----------\n    x:\n        The first set of coordinates [m]\n    y:\n        The second set of coordinates [m]\n    z:\n        The third set of coordinates or None (for a 2-D polygon)\n\n    Returns\n    -------\n    The area of the polygon [m^2]\n    \"\"\"\n    if z is None:\n        return get_area_2d(x, y)\n    else:\n        return get_area_3d(x, y, z)",
  "def get_area_2d(x: np.ndarray, y: np.ndarray) -> float:\n    \"\"\"\n    Calculate the area inside a closed polygon with x, y coordinate vectors.\n    `Link Shoelace method <https://en.wikipedia.org/wiki/Shoelace_formula>`_\n\n    Parameters\n    ----------\n    x:\n        The first set of coordinates [m]\n    y:\n        The second set of coordinates [m]\n\n    Returns\n    -------\n    The area of the polygon [m^2]\n    \"\"\"\n    # No np.roll in numba\n    x = np.ascontiguousarray(x)\n    y = np.ascontiguousarray(y)\n    x1 = np.append(x[-1], x[:-1])\n    y1 = np.append(y[-1], y[:-1])\n    return 0.5 * np.abs(np.dot(x, y1) - np.dot(y, x1))",
  "def get_area_3d(x: np.ndarray, y: np.ndarray, z: np.ndarray) -> float:\n    \"\"\"\n    Calculate the area inside a closed polygon.\n    `Link Shoelace method <https://en.wikipedia.org/wiki/Shoelace_formula>`_\n\n    Parameters\n    ----------\n    x:\n        The first set of coordinates [m]\n    y:\n        The second set of coordinates [m]\n    z:\n        The third set of coordinates [m]\n\n    Returns\n    -------\n    The area of the polygon [m^2]\n    \"\"\"\n    if np.all(x == x[0]) and np.all(y == y[0]) and np.all(z == z[0]):\n        # Basically a point, but avoid getting the normal vector..\n        return 0\n\n    v3 = get_normal_vector(x, y, z)\n    m = np.zeros((3, len(x)))\n    m[0, :] = x\n    m[1, :] = y\n    m[2, :] = z\n    a = np.array([0.0, 0.0, 0.0])\n    for i in range(len(z)):\n        a += np.cross(m[:, i], m[:, (i + 1) % len(z)])\n    a *= 0.5\n    return abs(np.dot(a, v3))",
  "def check_ccw(x: np.ndarray, z: np.ndarray) -> bool:\n    \"\"\"\n    Check that a set of x, z coordinates are counter-clockwise.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates of the polygon\n    z:\n        The z coordinates of the polygon\n\n    Returns\n    -------\n    True if polygon counterclockwise\n    \"\"\"\n    a = 0\n    for n in range(len(x) - 1):\n        a += (x[n + 1] - x[n]) * (z[n + 1] + z[n])\n    return a < 0",
  "def check_ccw_3d(\n    x: np.ndarray, y: np.ndarray, z: np.ndarray, normal: np.ndarray\n) -> bool:\n    \"\"\"\n    Check if a set of coordinates is counter-clockwise w.r.t a normal vector.\n\n    Parameters\n    ----------\n    x:\n        The first set of coordinates [m]\n    y:\n        The second set of coordinates [m]\n    z:\n        The third set of coordinates [m]\n    normal:\n        The normal vector about which to check for CCW\n\n    Returns\n    -------\n    Whether or not the set is CCW about the normal vector\n    \"\"\"\n    # Translate to centroid\n    dx, dy, dz = get_centroid_3d(x, y, z)\n    x, y, z = x - dx, y - dy, z - dz\n    # Rotate to x-y plane\n    r = rotation_matrix_v1v2([0, 0, 1], normal)\n    x, y, z = r.T @ np.array([x, y, z])\n    # Check projected x-y is CCW\n    return check_ccw(x, y)",
  "def get_centroid(\n    x: np.ndarray, y: np.ndarray, z: Optional[np.ndarray] = None\n) -> np.ndarray:\n    \"\"\"\n    Calculate the centroid of a non-self-intersecting 2-D counter-clockwise polygon.\n\n    Parameters\n    ----------\n    x:\n        x coordinates of the coordinates to calculate on\n    y:\n        y coordinates of the coordinates to calculate on\n    z:\n        z coordinates of the coordinates to calculate on\n\n    Returns\n    -------\n    The x, y, [z] coordinates of the centroid [m]\n    \"\"\"\n    if z is None:\n        return get_centroid_2d(x, y)\n    else:\n        return get_centroid_3d(x, y, z)",
  "def get_centroid_2d(x: np.ndarray, z: np.ndarray) -> List[float]:\n    \"\"\"\n    Calculate the centroid of a non-self-intersecting 2-D counter-clockwise polygon.\n\n    Parameters\n    ----------\n    x:\n        x coordinates of the coordinates to calculate on\n    z:\n        z coordinates of the coordinates to calculate on\n\n    Returns\n    -------\n    The x, z coordinates of the centroid [m]\n    \"\"\"\n    if not check_ccw(x, z):\n        x = np.ascontiguousarray(x[::-1])\n        z = np.ascontiguousarray(z[::-1])\n    area = get_area_2d(x, z)\n\n    cx, cz = 0, 0\n    for i in range(len(x) - 1):\n        a = x[i] * z[i + 1] - x[i + 1] * z[i]\n        cx += (x[i] + x[i + 1]) * a\n        cz += (z[i] + z[i + 1]) * a\n\n    if area != 0:\n        # Zero division protection\n        cx /= 6 * area\n        cz /= 6 * area\n\n    return [cx, cz]",
  "def get_centroid_3d(x: np.ndarray, y: np.ndarray, z: np.ndarray) -> List[float]:\n    \"\"\"\n    Calculate the centroid of a non-self-intersecting counterclockwise polygon\n    in 3-D.\n\n    Parameters\n    ----------\n    x:\n        The x coordinates\n    y:\n        The y coordinates\n    z:\n        The z coordinates\n\n    Returns\n    -------\n    The x, y, z coordinates of the centroid [m]\n    \"\"\"\n    cx, cy = get_centroid_2d(x, y)\n    if np.allclose(z, z[0]):\n        return [cx, cy, z[0]]\n    cx2, cz = get_centroid_2d(x, z)\n    if np.allclose(y, y[0]):\n        return [cx2, y[0], cz]\n    cy2, cz2 = get_centroid_2d(y, z)\n    if np.allclose(x, x[0]):\n        return [x[0], cy2, cz2]\n\n    # The following is an \"elegant\" but computationally more expensive way of\n    # dealing with the 0-area edge cases\n    # (of which there are more than you think)\n    cx = np.array([cx, cx2])\n    cy = np.array([cy, cy2])\n    cz = np.array([cz, cz2])\n\n    def get_rational(i, array):\n        \"\"\"\n        Gets rid of infinity and nan coordinates\n        \"\"\"\n        args = np.argwhere(np.isfinite(array))\n        if len(args) == 0:\n            # 2-D shape with a simple axis offset\n            # Get the first value of the coordinate set which is equal to the\n            # offset\n            return [x, y, z][i][0]\n        elif len(args) == 1:\n            return array[args[0][0]]\n        else:\n            if all(np.isclose(array, 0)):\n                return 0\n            elif any(np.isclose(array, 0)):\n                # Occasionally the two c values are not the same, and one is 0\n                return array[np.argmax(np.abs(array))]\n            else:\n                return array[0]\n\n    return [get_rational(i, c) for i, c in enumerate([cx, cy, cz])]",
  "def get_angle_between_points(p0: np.ndarray, p1: np.ndarray, p2: np.ndarray) -> float:\n    \"\"\"\n    Angle between points. P1 is vertex of angle. ONly tested in 2d\n    \"\"\"\n    if not all(isinstance(p, np.ndarray) for p in [p0, p1, p2]):\n        p0, p1, p2 = np.array(p0), np.array(p1), np.array(p2)\n    ba = p0 - p1\n    bc = p2 - p1\n    return get_angle_between_vectors(ba, bc)",
  "def get_angle_between_vectors(\n    v1: np.ndarray, v2: np.ndarray, signed: bool = False\n) -> float:\n    \"\"\"\n    Angle between vectors. Will return the signed angle if specified.\n\n    Parameters\n    ----------\n    v1:\n        The first vector\n    v2:\n        The second vector\n    signed:\n        Whether or not to calculate the signed angle\n\n    Returns\n    -------\n    The angle between the vectors [radians]\n    \"\"\"\n    if not all(isinstance(p, np.ndarray) for p in [v1, v2]):\n        v1, v2 = np.array(v1), np.array(v2)\n    v1n = v1 / np.linalg.norm(v1)\n    v2n = v2 / np.linalg.norm(v2)\n    cos_angle = np.dot(v1n, v2n)\n    # clip to dodge a NaN\n    angle = np.arccos(np.clip(cos_angle, -1, 1))\n    sign = 1\n    if signed:\n        det = np.linalg.det(np.stack((v1n[-2:], v2n[-2:])))\n        if det == 0:\n            # Vectors parallel\n            sign = 1\n        else:\n            sign = np.sign(det)\n\n    return sign * angle",
  "def rotation_matrix(theta: float, axis: Union[str, np.ndarray] = \"z\") -> np.ndarray:\n    \"\"\"\n    Old-fashioned rotation matrix: :math:`\\\\mathbf{R_{u}}(\\\\theta)`\n    \\t:math:`\\\\mathbf{x^{'}}=\\\\mathbf{R_{u}}(\\\\theta)\\\\mathbf{x}`\n\n    \\t:math:`\\\\mathbf{R_{u}}(\\\\theta)=cos(\\\\theta)\\\\mathbf{I}+sin(\\\\theta)[\\\\mathbf{u}]_{\\\\times}(1-cos(\\\\theta))(\\\\mathbf{u}\\\\otimes\\\\mathbf{u})`\n\n    Parameters\n    ----------\n    theta:\n        The rotation angle [radians] (counter-clockwise about axis!)\n    axis:\n        The rotation axis (specified by axis label or vector)\n\n    Returns\n    -------\n    The (active) rotation matrix about the axis for an angle theta\n    \"\"\"\n    if isinstance(axis, str):\n        # I'm leaving all this in here, because it is easier to understand\n        # what is going on, and that these are just \"normal\" rotation matrices\n        if axis == \"z\":\n            r_matrix = np.array(\n                [\n                    [np.cos(theta), -np.sin(theta), 0],\n                    [np.sin(theta), np.cos(theta), 0],\n                    [0, 0, 1],\n                ]\n            )\n        elif axis == \"y\":\n            r_matrix = np.array(\n                [\n                    [np.cos(theta), 0, np.sin(theta)],\n                    [0, 1, 0],\n                    [-np.sin(theta), 0, np.cos(theta)],\n                ]\n            )\n        elif axis == \"x\":\n            r_matrix = np.array(\n                [\n                    [1, 0, 0],\n                    [0, np.cos(theta), -np.sin(theta)],\n                    [0, np.sin(theta), np.cos(theta)],\n                ]\n            )\n        else:\n            raise CoordinatesError(\n                f\"Incorrect rotation axis: {axis}\\n\"\n                \"please select from: ['x', 'y', 'z']\"\n            )\n    else:\n        # Cute, but hard to understand!\n        axis = np.array(axis) / np.linalg.norm(axis)  # Unit vector\n        cos = np.cos(theta)\n        sin = np.sin(theta)\n        x, y, z = axis\n        u_x = np.array([[0, -z, y], [z, 0, -x], [-y, x, 0]])\n        u_o_u = np.outer(axis, axis)\n        r_matrix = cos * np.eye(3) + sin * u_x + (1 - cos) * u_o_u\n    return r_matrix",
  "def rotation_matrix_v1v2(v1: np.ndarray, v2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Get a rotation matrix based off two vectors.\n    \"\"\"\n    v1 /= np.linalg.norm(v1)\n    v2 /= np.linalg.norm(v2)\n\n    cos_angle = np.dot(v1, v2)\n    d = np.cross(v1, v2)\n    sin_angle = np.linalg.norm(d)\n\n    if sin_angle == 0:\n        matrix = np.identity(3) if cos_angle > 0.0 else -np.identity(3)\n    else:\n        d /= sin_angle\n\n        eye = np.eye(3)\n        ddt = np.outer(d, d)\n        skew = np.array(\n            [[0, d[2], -d[1]], [-d[2], 0, d[0]], [d[1], -d[0], 0]], dtype=np.float64\n        )\n\n        matrix = ddt + cos_angle * (eye - ddt) + sin_angle * skew\n\n    return matrix",
  "def project_point_axis(point: np.ndarray, axis: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Project a 3-D point onto a 3-D axis.\n    \\t:math:`\\\\mathbf{p_{proj}} = \\\\dfrac{\\\\mathbf{p}\\\\cdot\\\\mathbf{a}}{\\\\mathbf{a}\\\\cdot\\\\mathbf{a}}\\\\mathbf{a}`\n\n    Parameters\n    ----------\n    point:\n        The point to project onto the axis\n    axis:\n        The axis onto which to project the point\n\n    Returns\n    -------\n    The coordinates of the projected point\n    \"\"\"  # noqa: W505\n    point = np.array(point)\n    axis = np.array(axis)\n    return axis * np.dot(point, axis) / np.dot(axis, axis)",
  "def principal_components(xyz_array: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Principal component analysis.\n    \"\"\"\n    mean = np.mean(xyz_array, axis=1)\n    xyz_shift = xyz_array - mean.reshape((3, 1))\n\n    cov = np.cov(xyz_shift)\n    eigenvalues, eigenvectors = np.linalg.eig(cov)\n\n    sort = eigenvalues.argsort()[::-1]\n    eigenvalues = eigenvalues[sort]\n    eigenvectors = eigenvectors[:, sort]\n    return eigenvalues, eigenvectors",
  "def check_linesegment(\n    point_a: np.ndarray, point_b: np.ndarray, point_c: np.ndarray\n) -> bool:\n    \"\"\"\n    Check that point C is on the line between points A and B.\n\n    Parameters\n    ----------\n    point_a:\n        The first line segment 2-D point\n    point_b:\n        The second line segment 2-D point\n    point_c:\n        The 2-D point which to check is on A--B\n\n    Returns\n    -------\n    True: if C on A--B, else False\n    \"\"\"\n    # Do some protection of numba against integers and lists\n    a_c = np.array([point_c[0] - point_a[0], point_c[1] - point_a[1]], dtype=np.float_)\n    a_b = np.array([point_b[0] - point_a[0], point_b[1] - point_a[1]], dtype=np.float_)\n\n    distance = np.sqrt(np.sum(a_b**2))\n    # Numba doesn't like doing cross-products of things with size 2\n    cross = cross2d(a_b, a_c)\n    if np.abs(cross) > CROSS_P_TOL * distance:\n        return False\n    k_ac = np.dot(a_b, a_c)\n    k_ab = np.dot(a_b, a_b)\n    if k_ac < 0:\n        return False\n    elif k_ac > k_ab:\n        return False\n    else:\n        return True",
  "def in_polygon(\n    x: float, z: float, poly: np.ndarray, include_edges: bool = False\n) -> bool:\n    \"\"\"\n    Determine if a point (x, z) is inside a 2-D polygon.\n\n    Parameters\n    ----------\n    x:\n        Point x coordinate\n    z:\n        Point z coordinate\n    poly:\n        The 2-D array of polygon point coordinates\n    include_edges:\n        Whether or not to return True if a point is on the perimeter of the\n        polygon\n\n    Returns\n    -------\n    Whether or not the point is in the polygon\n    \"\"\"\n    n = len(poly)\n    inside = False\n    x1, z1, x_inter = 0, 0, 0\n    x0, z0 = poly[0]\n    for i in range(n + 1):\n        x1, z1 = poly[i % n]\n\n        if x == x1 and z == z1:\n            return include_edges\n\n        if z > min(z0, z1) and z <= max(z0, z1) and x <= max(x0, x1):\n            if z0 != z1:\n                x_inter = (z - z0) * (x1 - x0) / (z1 - z0) + x0\n                if x == x_inter:\n                    return include_edges\n            if x0 == x1 or x <= x_inter:\n                inside = not inside  # Beautiful\n        elif z == min(z0, z1) and z0 == z1 and (x <= max(x0, x1)) and (x >= min(x0, x1)):\n            return include_edges\n\n        x0, z0 = x1, z1\n    return inside",
  "def polygon_in_polygon(\n    poly1: np.ndarray, poly2: np.ndarray, include_edges: bool = False\n) -> np.ndarray:\n    \"\"\"\n    Determine what points of a 2-D polygon are inside another 2-D polygon.\n\n    Parameters\n    ----------\n    poly1:\n        The array of 2-D polygon1 point coordinates\n    poly2:\n        The array of 2-D polygon2 point coordinates\n    include_edges:\n        Whether or not to return True if a point is on the perimeter of the\n        polygon\n\n    Returns\n    -------\n    The array of boolean values per index of polygon1\n    \"\"\"\n    inside_array = np.empty(len(poly1), dtype=np.bool_)\n    for i in range(len(poly1)):\n        inside_array[i] = in_polygon(\n            poly1[i][0], poly1[i][1], poly2, include_edges=include_edges\n        )\n    return inside_array",
  "def on_polygon(x: float, z: float, poly: np.ndarray) -> bool:\n    \"\"\"\n    Determine if a point (x, z) is on the perimeter of a closed 2-D polygon.\n\n    Parameters\n    ----------\n    x:\n        Point x coordinate\n    z:\n        Point z coordinate\n    poly:\n        The array of 2-D polygon point coordinates\n\n    Returns\n    -------\n    Whether or not the point is on the perimeter of the polygon\n    \"\"\"\n    on_edge = False\n    for i, (point_a, point_b) in enumerate(zip(poly[:-1], poly[1:])):\n        c = check_linesegment(np.array(point_a), np.array(point_b), np.array([x, z]))\n\n        if c is True:\n            return True\n    return on_edge",
  "def normal_vector(side_vectors: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Find the anti-clockwise normal vector to the given side vectors.\n\n    Parameters\n    ----------\n    side_vectors:\n        The side vectors of a polygon (shape: (N, 2)).\n\n    Returns\n    -------\n    The array of 2-D normal vectors of each side of a polygon\n    (shape: (2, N)).\n    \"\"\"\n    a = -np.array([-side_vectors[1], side_vectors[0]]) / np.sqrt(\n        side_vectors[0] ** 2 + side_vectors[1] ** 2\n    )\n    nan = np.isnan(a)\n    a[nan] = 0\n    return a",
  "def vector_intersect(\n    p1: np.ndarray, p2: np.ndarray, p3: np.ndarray, p4: np.ndarray\n) -> np.ndarray:\n    \"\"\"\n    Get the intersection point between two 2-D vectors.\n\n    Parameters\n    ----------\n    p1:\n        The first point on the first vector (shape: (2,)).\n    p2:\n        The second point on the first vector (shape: (2,)).\n    p3:\n        The first point on the second vector (shape: (2,)).\n    p4:\n        The second point on the second vector (shape: (2,)).\n\n    Returns\n    -------\n    The point of the intersection between the two vectors (shape: (2,)).\n    \"\"\"\n    da = p2 - p1\n    db = p4 - p3\n\n    if np.isclose(np.cross(da, db), 0):  # vectors parallel\n        # NOTE: careful modifying this, different behaviour required...\n        point = p2\n    else:\n        dp = p1 - p3\n        dap = normal_vector(da)\n        denom = np.dot(dap, db)\n        num = np.dot(dap, dp)\n        point = num / denom.astype(float) * db + p3\n    return point",
  "def _parse_to_xyz_array(xyz_array):\n    \"\"\"\n    Make a 3, N xyz array out of just about anything.\n    \"\"\"\n    if isinstance(xyz_array, np.ndarray):\n        xyz_array = _parse_array(xyz_array)\n    elif isinstance(xyz_array, dict):\n        xyz_array = _parse_dict(xyz_array)\n    elif isinstance(xyz_array, Iterable):\n        # We temporarily set the dtype to object to avoid a VisibleDeprecationWarning\n        xyz_array = np.array(xyz_array, dtype=object)\n        xyz_array = _parse_array(xyz_array)\n    else:\n        raise CoordinatesError(f\"Cannot instantiate Coordinates with: {type(xyz_array)}\")\n    return xyz_array",
  "def _parse_array(xyz_array):\n    try:\n        xyz_array = np.array(np.atleast_2d(np.squeeze(xyz_array)), dtype=np.float64)\n    except ValueError:\n        raise CoordinatesError(\n            \"Cannot instantiate Coordinates with a ragged (3, N | M) array.\"\n        )\n\n    shape = xyz_array.shape\n    if len(shape) > 2:\n        raise NotImplementedError\n\n    n, m = shape\n    if n == 3:\n        if m == 3:\n            bluemira_warn(\n                \"You are creating Coordinates with a (3, 3) array, defaulting to (3, N).\"\n            )\n\n    elif m == 3:\n        xyz_array = xyz_array.T\n\n    else:\n        raise CoordinatesError(\n            \"Cannot instantiate Coordinates where either n or m != 3.\"\n        )\n\n    if not np.allclose([len(xyz_array[i]) for i in range(3)], len(xyz_array[0])):\n        raise CoordinatesError(\n            \"Cannot instantiate Coordinates with a ragged (3, N | M) array.\"\n        )\n\n    return xyz_array",
  "def _parse_dict(xyz_dict):\n    x = np.atleast_1d(xyz_dict.get(\"x\", 0))\n    y = np.atleast_1d(xyz_dict.get(\"y\", 0))\n    z = np.atleast_1d(xyz_dict.get(\"z\", 0))\n\n    shape_lengths = np.array([len(c.shape) for c in [x, y, z]])\n\n    if np.any(shape_lengths > 1):\n        raise CoordinatesError(\n            \"Cannot instantiate Coordinates from dict with coordinate vectors that are not 1-D.\"\n        )\n\n    lengths = [len(c) for c in [x, y, z]]\n    if np.all(np.array(lengths) <= 1):\n        # Vertex detected\n        return np.array([x, y, z])\n\n    usable_lengths = []\n    for length in lengths:\n        if length != 1:\n            usable_lengths.append(length)\n\n    if not np.allclose(usable_lengths, usable_lengths[0]):\n        raise CoordinatesError(\n            \"Cannot instantiate Coordinate from dict with a ragged set of vectors.\"\n        )\n\n    # Backfill single-value coordinates\n    actual_length = usable_lengths[0]\n    if len(x) == 1:\n        x = x[0] * np.ones(actual_length)\n    if len(y) == 1:\n        y = y[0] * np.ones(actual_length)\n    if len(z) == 1:\n        z = z[0] * np.ones(actual_length)\n\n    return np.array([x, y, z])",
  "class Coordinates:\n    \"\"\"\n    Coordinates object for storing ordered sets of coordinates.\n\n    An array shape of (3, N) is enforced.\n\n    Counter-clockwise direction can be set relative to a normal vector.\n\n    Notes\n    -----\n    This is a utility class for dealing with sets of coordinates in a number of different\n    contexts. It should not be used for the creation of CAD geometries.\n    \"\"\"\n\n    __slots__ = (\"_array\", \"_is_planar\", \"_normal_vector\")\n    # =============================================================================\n    # Instantiation\n    # =============================================================================\n\n    def __init__(self, xyz_array: Union[np.ndarray, Dict, Iterable[Iterable]]):\n        self._array = _parse_to_xyz_array(xyz_array)\n        self._is_planar = None\n        self._normal_vector = None\n\n    @classmethod\n    def from_json(cls, filename: str):\n        \"\"\"\n        Load a Coordinates object from a JSON file.\n\n        Parameters\n        ----------\n        filename:\n            Full path file name of the data\n        \"\"\"\n        try:\n            with open(filename, \"r\") as data:\n                xyz_dict = json.load(data)\n        except json.JSONDecodeError:\n            raise CoordinatesError(\n                f\"Could not read the file: {filename}\"\n                + \"\\n Please ensure it is a JSON file.\"\n            )\n\n        # NOTE: Stabler than **xyz_dict\n        x = xyz_dict.get(\"x\", 0)\n        y = xyz_dict.get(\"y\", 0)\n        z = xyz_dict.get(\"z\", 0)\n        return cls({\"x\": x, \"y\": y, \"z\": z})\n\n    # =============================================================================\n    # Checks\n    # =============================================================================\n\n    def _set_plane_props(self):\n        \"\"\"\n        Set the planar properties of the Coordinates.\n        \"\"\"\n        if self._is_planar is None and self._normal_vector is None:\n            self._update_plane_props()\n\n    def _update_plane_props(self):\n        if len(self) > 3:\n            eigenvalues, eigenvectors = principal_components(self._array)\n\n            if np.isclose(eigenvalues[-1], 0.0):\n                self._is_planar = True\n            else:\n                self._is_planar = False\n\n            self._normal_vector = eigenvectors[:, -1]\n        else:\n            bluemira_warn(\"Cannot set planar properties on Coordinates with length < 3.\")\n            self._is_planar = False\n            self._normal_vector = None\n\n    @property\n    def is_planar(self) -> bool:\n        \"\"\"\n        Whether or not the Coordinates are planar.\n        \"\"\"\n        self._set_plane_props()\n        return self._is_planar\n\n    @property\n    def normal_vector(self) -> np.ndarray:\n        \"\"\"\n        The normal vector of the best-fit plane of the Coordinates.\n        \"\"\"\n        self._set_plane_props()\n        return self._normal_vector\n\n    def check_ccw(self, axis: Optional[np.ndarray] = None) -> bool:\n        \"\"\"\n        Whether or not the Coordinates are ordered in the counter-clockwise direction\n        about a specified axis. If None is specified, the Coordinates normal vector will\n        be used.\n        \"\"\"\n        if len(self) < 3:\n            return False\n\n        if axis is None:\n            axis = self.normal_vector\n        else:\n            axis = np.array(axis, dtype=float)\n            if axis.size != 3:\n                raise CoordinatesError(\"Base vector must be of size 3.\")\n            axis /= np.linalg.norm(axis)\n\n        return check_ccw_3d(self.x, self.y, self.z, axis)\n\n    def set_ccw(self, axis: Optional[np.ndarray] = None):\n        \"\"\"\n        Set the Coordinates to be counter-clockwise about a specified axis. If None is\n        specified, the Coordinates normal vector will be used.\n        \"\"\"\n        if len(self) < 3:\n            bluemira_warn(\"Cannot set Coordinates of length < 3 to CCW.\")\n            return\n\n        if not self.check_ccw(axis=axis):\n            self.reverse()\n\n    def distance_to(self, point: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Calculates the distances from each point in the Coordinates to the point.\n\n        Parameters\n        ----------\n        point:\n            The point (3-D) to which to calculate the distances\n\n        Returns\n        -------\n        The vector of distances of the Coordinates to the point\n        \"\"\"\n        point = np.array(point)\n        point = point.reshape(3, 1).T\n        return cdist(self.xyz.T, point, \"euclidean\")\n\n    def argmin(self, point: np.ndarray) -> int:\n        \"\"\"\n        Parameters\n        ----------\n        point:\n            The 3-D point to which to calculate the distances\n\n        Returns\n        -------\n        The index of the closest point\n        \"\"\"\n        return np.argmin(self.distance_to(point))\n\n    # =============================================================================\n    # Property access\n    # =============================================================================\n\n    @property\n    def x(self) -> np.ndarray:\n        \"\"\"\n        The x coordinate vector\n        \"\"\"\n        return self._array[0]\n\n    @property\n    def y(self) -> np.ndarray:\n        \"\"\"\n        The y coordinate vector\n        \"\"\"\n        return self._array[1]\n\n    @property\n    def z(self) -> np.ndarray:\n        \"\"\"\n        The z coordinate vector\n        \"\"\"\n        return self._array[2]\n\n    @property\n    def xy(self) -> np.ndarray:\n        \"\"\"\n        The x-y coordinate array\n        \"\"\"\n        return self._array[[0, 1], :]\n\n    @property\n    def xz(self) -> np.ndarray:\n        \"\"\"\n        The x-z coordinate array\n        \"\"\"\n        return self._array[[0, 2], :]\n\n    @property\n    def yz(self) -> np.ndarray:\n        \"\"\"\n        The y-z coordinate array\n        \"\"\"\n        return self._array[[1, 2], :]\n\n    @property\n    def xyz(self) -> np.ndarray:\n        \"\"\"\n        The x-y-z coordinate array\n        \"\"\"\n        return self._array\n\n    @property\n    def points(self) -> List[np.ndarray]:\n        \"\"\"\n        A list of the individual points of the Coordinates.\n        \"\"\"\n        return list(self.T)\n\n    # =========================================================================\n    # Conversions\n    # =========================================================================\n\n    def as_dict(self) -> Dict[str, np.ndarray]:\n        \"\"\"\n        Cast the Coordinates as a dictionary.\n\n        Returns\n        -------\n        d: dict\n            Dictionary with {'x': [], 'y': [], 'z':[]}\n        \"\"\"\n        return {\"x\": self.x, \"y\": self.y, \"z\": self.z}\n\n    def to_json(self, filename: str, **kwargs: Dict[str, Any]) -> str:\n        \"\"\"\n        Save the Coordinates as a JSON file.\n        \"\"\"\n        d = self.as_dict()\n        filename = os.path.splitext(filename)[0]\n        filename += \".json\"\n        return json_writer(d, filename, **kwargs)\n\n    # =============================================================================\n    # Useful properties\n    # =============================================================================\n\n    @property\n    def closed(self) -> bool:\n        \"\"\"\n        Whether or not this is a closed set of Coordinates.\n        \"\"\"\n        if len(self) > 2:\n            if np.allclose(self[:, 0], self[:, -1], rtol=0, atol=EPS):\n                return True\n        return False\n\n    @property\n    def length(self) -> float:\n        \"\"\"\n        Perimeter length of the coordinates.\n        \"\"\"\n        return get_perimeter_3d(*self._array)\n\n    @property\n    def center_of_mass(self) -> Tuple[float, float, float]:\n        \"\"\"\n        Geometrical centroid of the Coordinates.\n        \"\"\"\n        # [sic] coordinates do not have a \"mass\", but named such for consistency with\n        # other geometry objects.\n        if len(self) == 1:\n            return self.xyz.T[0]\n\n        elif len(self) == 2:\n            return np.average(self.xyz.T)\n\n        return tuple(get_centroid_3d(*self._array))\n\n    # =============================================================================\n    # Array-like behaviour\n    # =============================================================================\n\n    @property\n    def T(self) -> np.ndarray:  # noqa :N802\n        \"\"\"\n        Transpose of the Coordinates\n        \"\"\"\n        return self._array.T\n\n    @property\n    def shape(self) -> Tuple[int, int]:\n        \"\"\"\n        Shape of the Coordinates\n        \"\"\"\n        return self._array.shape\n\n    # =============================================================================\n    # Modification\n    # =============================================================================\n    def reverse(self):\n        \"\"\"\n        Reverse the direction of the Coordinates.\n        \"\"\"\n        self._array = self._array[:, ::-1]\n\n    def open(self):\n        \"\"\"\n        Open the Coordinates (if they are closed)\n        \"\"\"\n        if len(self) < 3:\n            bluemira_warn(f\"Cannot open Coordinates of length {len(self)}\")\n            return\n\n        if self.closed:\n            self._array = self._array[:, :-1]\n\n    def insert(self, point: np.ndarray, index: int = 0):\n        \"\"\"\n        Insert a point to the Coordinates.\n\n        Parameters\n        ----------\n        point:\n            The 3-D point to insert into the Coordinates\n        index:\n            The position of the point in the Coordinates (order index)\n        \"\"\"\n        if index > len(self):\n            bluemira_warn(\n                \"Inserting a point in Coordinates at an index greater than the number of points.\"\n            )\n            index = -1\n        if not np.isclose(self.xyz.T, point).all(axis=1).any():\n            point = np.array(point).reshape((3, 1))\n            if index == -1:\n                self._array = np.hstack((self._array, point))\n            else:\n                self._array = np.hstack(\n                    (self._array[:, :index], point, self._array[:, index:])\n                )\n\n    def close(self):\n        \"\"\"\n        Close the Coordinates (if they are open)\n        \"\"\"\n        if len(self) < 3:\n            bluemira_warn(f\"Cannot close Coordinates of length {len(self)}\")\n            return\n\n        if not self.closed:\n            self._array = np.vstack((self._array.T, self._array[:, 0])).T\n\n    def rotate(\n        self,\n        base: Tuple[float, float, float] = (0, 0, 0),\n        direction: Tuple[float, float, float] = (0, 0, 1),\n        degree: float = 0.0,\n    ):\n        \"\"\"\n        Rotate the Coordinates.\n\n        Parameters\n        ----------\n        base:\n            Origin location of the rotation\n        direction:\n            The direction vector\n        degree:\n            rotation angle [degrees]\n        \"\"\"\n        if degree == 0.0:\n            return\n\n        base = np.array(base, dtype=float)\n        if base.size != 3:\n            raise CoordinatesError(\"Base vector must be of size 3.\")\n\n        direction = np.array(direction, dtype=float)\n        if direction.size != 3:\n            raise CoordinatesError(\"Direction vector must be of size 3.\")\n        direction /= np.linalg.norm(direction)\n\n        points = self._array - base.reshape(3, 1)\n        quart = Quaternion(axis=direction, angle=np.deg2rad(degree))\n        r_matrix = quart.rotation_matrix\n        new_array = points.T @ r_matrix.T + base\n        self._array = new_array.T\n\n        self._update_plane_props()\n\n    def translate(self, vector: Tuple[float, float, float] = (0, 0, 0)):\n        \"\"\"\n        Translate this shape with the vector. This function modifies the self\n        object.\n        \"\"\"\n        vector = np.array(vector)\n        if vector.size != 3:\n            raise CoordinatesError(\"Translation vector must be of size 3.\")\n\n        self._array += vector.reshape(3, 1)\n        self._update_plane_props()\n\n    # =============================================================================\n    # Dunders (with different behaviour to array)\n    # =============================================================================\n\n    def __eq__(self, other: Coordinates) -> bool:\n        \"\"\"\n        Check the Coordinates for equality with other Coordinates.\n\n        Parameters\n        ----------\n        other:\n            The other Coordinates to compare against\n\n        Returns\n        -------\n        Whether or not the Coordinates are identical\n\n        Notes\n        -----\n        Coordinates with identical coordinates but different orderings will not be\n        counted as identical.\n        \"\"\"\n        if isinstance(other, self.__class__):\n            return np.all(np.allclose(self._array, other._array, rtol=0, atol=EPS))\n        return False\n\n    def __len__(self) -> int:\n        \"\"\"\n        The number of points in the Coordinates.\n        \"\"\"\n        return self.shape[1]\n\n    # =============================================================================\n    # Array-like dunders\n    # =============================================================================\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Representation of the Coordinates.\n        \"\"\"\n        r = self._array.__repr__()\n        return f\"{self.__class__.__name__}{r[5:]}\"\n\n    def __getitem__(self, *args, **kwargs):\n        \"\"\"\n        Array-like indexing and slicing.\n        \"\"\"\n        return self._array.__getitem__(*args, **kwargs)\n\n    def __iter__(self):\n        \"\"\"\n        Array-like unpacking.\n        \"\"\"\n        return self._array.__iter__()",
  "def vector_intersect_3d(\n    p_1: np.ndarray, p_2: np.ndarray, p_3: np.ndarray, p_4: np.ndarray\n) -> np.ndarray:\n    \"\"\"\n    Get the intersection point between two 3-D vectors.\n\n    Parameters\n    ----------\n    p1:\n        The first point on the first vector\n    p2:\n        The second point on the first vector\n    p3:\n        The first point on the second vector\n    p4:\n        The second point on the second vector\n\n    Returns\n    -------\n    The point of the intersection between the two vectors\n\n    Raises\n    ------\n    CoordinatesError\n        If there is no intersection between the points\n\n    Notes\n    -----\n    Credit: Paul Bourke at\n    http://paulbourke.net/geometry/pointlineplane/#:~:text=The%20shortest%20line%20between%20two%20lines%20in%203D\n    \"\"\"\n    p_13 = p_1 - p_3\n    p_43 = p_4 - p_3\n\n    if np.linalg.norm(p_13) < EPS:\n        raise CoordinatesError(\"No intersection between 3-D lines.\")\n    p_21 = p_2 - p_1\n    if np.linalg.norm(p_21) < EPS:\n        raise CoordinatesError(\"No intersection between 3-D lines.\")\n\n    d1343 = np.dot(p_13, p_43)\n    d4321 = np.dot(p_43, p_21)\n    d1321 = np.dot(p_13, p_21)\n    d4343 = np.dot(p_43, p_43)\n    d2121 = np.dot(p_21, p_21)\n\n    denom = d2121 * d4343 - d4321 * d4321\n\n    if np.abs(denom) < EPS:\n        raise CoordinatesError(\"No intersection between 3-D lines.\")\n\n    numer = d1343 * d4321 - d1321 * d4343\n\n    mua = numer / denom\n    intersection = p_1 + mua * p_21\n    return intersection",
  "def coords_plane_intersect(\n    coords: Coordinates, plane: BluemiraPlane\n) -> Union[np.ndarray, None]:\n    \"\"\"\n    Calculate the intersection of Coordinates with a plane.\n\n    Parameters\n    ----------\n    coords:\n        The coordinates to calculate the intersection on\n    plane:\n        The plane to calculate the intersection with\n\n    Returns\n    -------\n    The xyz coordinates (3, n_intersections) of the intersections with the Coordinates.\n    Returns None if there are no intersections detected\n    \"\"\"\n    out = _coords_plane_intersect(coords.xyz.T[:-1], plane.base, plane.axis)\n    if not out:\n        return None\n    else:\n        return np.unique(out, axis=0)",
  "def _coords_plane_intersect(\n    array: np.ndarray, p1: np.ndarray, vec2: np.ndarray\n) -> np.ndarray:\n    # JIT compiled utility of the above\n    out = []\n    for i in range(len(array)):\n        vec1 = array[i + 1] - array[i]\n        dot = np.dot(vec1, vec2)\n        if abs(dot) > DOT_P_TOL:\n            w = array[i] - p1\n            fac = -(np.dot(vec2, w)) / dot\n            if (fac >= 0) and (fac <= 1):\n                out.append(array[i] + fac * vec1)\n    return out",
  "def get_intersect(xy1: np.ndarray, xy2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Calculates the intersection points between two sets of 2-D coordinates. Will return\n    a unique list of x, z intersections (no duplicates in x-z space).\n\n    Parameters\n    ----------\n    xy1:\n        The 2-D coordinates between which intersection points should be calculated\n    xy2:\n        The 2-D coordinates between which intersection points should be calculated\n\n    Returns\n    -------\n    xi:\n        The x coordinates of the intersection points\n    zi:\n        The z coordinates of the intersection points#\n\n    Notes\n    -----\n    D. Schwarz, <https://uk.mathworks.com/matlabcentral/fileexchange/11837-fast-and-robust-curve-intersections>\n    \"\"\"  # noqa :W505\n    x1, y1 = xy1\n    x2, y2 = xy2\n\n    def inner_inter(x_1, x_2):\n        n1, n2 = x_1.shape[0] - 1, x_2.shape[0] - 1\n        xx1 = np.c_[x_1[:-1], x_1[1:]]\n        xx2 = np.c_[x_2[:-1], x_2[1:]]\n        return (\n            np.less_equal(\n                np.tile(xx1.min(axis=1), (n2, 1)).T, np.tile(xx2.max(axis=1), (n1, 1))\n            ),\n            np.greater_equal(\n                np.tile(xx1.max(axis=1), (n2, 1)).T, np.tile(xx2.min(axis=1), (n1, 1))\n            ),\n        )\n\n    x_x = inner_inter(x1, x2)\n    z_z = inner_inter(y1, y2)\n    m, k = np.nonzero(x_x[0] & x_x[1] & z_z[0] & z_z[1])\n    n = len(m)\n    a_m, xz, b_m = np.zeros((4, 4, n)), np.zeros((4, n)), np.zeros((4, n))\n    a_m[0:2, 2, :] = -1\n    a_m[2:4, 3, :] = -1\n    a_m[0::2, 0, :] = np.diff(np.c_[x1, y1], axis=0)[m, :].T\n    a_m[1::2, 1, :] = np.diff(np.c_[x2, y2], axis=0)[k, :].T\n    b_m[0, :] = -x1[m].ravel()\n    b_m[1, :] = -x2[k].ravel()\n    b_m[2, :] = -y1[m].ravel()\n    b_m[3, :] = -y2[k].ravel()\n    for i in range(n):\n        try:\n            xz[:, i] = np.linalg.solve(a_m[:, :, i], b_m[:, i])\n        except np.linalg.LinAlgError:\n            # Parallel segments. Will raise numpy RuntimeWarnings\n            xz[0, i] = np.nan\n    in_range = (xz[0, :] >= 0) & (xz[1, :] >= 0) & (xz[0, :] <= 1) & (xz[1, :] <= 1)\n    xz = xz[2:, in_range].T\n    x, z = xz[:, 0], xz[:, 1]\n    if len(x) > 0:\n        x, z = np.unique([x, z], axis=1)\n    return x, z",
  "def _intersect_count(\n    x_inter: np.ndarray, z_inter: np.ndarray, x2: np.ndarray, z2: np.ndarray\n) -> np.ndarray:\n    args = []\n    for i in range(len(x_inter)):\n        for j in range(len(x2) - 1):\n            if check_linesegment(\n                np.array([x2[j], z2[j]]),\n                np.array([x2[j + 1], z2[j + 1]]),\n                np.array([x_inter[i], z_inter[i]]),\n            ):\n                args.append(j)\n                break\n    return np.array(args)",
  "def join_intersect(\n    coords1: Coordinates, coords2: Coordinates, get_arg: bool = False\n) -> Optional[List[int]]:\n    \"\"\"\n    Add the intersection points between coords1 and coords2 to coords1.\n\n    Parameters\n    ----------\n    coords1:\n        The Coordinates to which the intersection points should be added\n    coords2:\n        The intersecting Coordinates\n    get_arg:\n        Whether or not to return the intersection arguments\n\n    Returns\n    -------\n    The arguments of coords1 in which the intersections were added (if get_arg is True)\n\n    Notes\n    -----\n    Modifies coords1\n    \"\"\"\n    x_inter, z_inter = get_intersect(coords1.xz, coords2.xz)\n    args = _intersect_count(x_inter, z_inter, coords1.x, coords1.z)\n\n    orderr = args.argsort()\n    x_int = x_inter[orderr]\n    z_int = z_inter[orderr]\n\n    args = _intersect_count(x_int, z_int, coords1.x, coords1.z)\n\n    # TODO: Check for duplicates and order correctly based on distance\n    # u, counts = np.unique(args, return_counts=True)\n\n    count = 0\n    for i, arg in enumerate(args):\n        if i > 0 and args[i - 1] == arg:\n            # Two intersection points, one after the other\n            bump = 0\n        else:\n            bump = 1\n        if not np.isclose(coords1.xyz.T, [x_int[i], 0, z_int[i]]).all(axis=1).any():\n            # Only increment counter if the intersection isn't already in the Coordinates\n            coords1.insert([x_int[i], 0, z_int[i]], index=arg + count + bump)\n            count += 1\n\n    if get_arg:\n        args = []\n        for x, z in zip(x_inter, z_inter):\n            args.append(coords1.argmin([x, 0, z]))\n        return list(set(args))",
  "def wrapper(x, y, z=None):\n        _validate_coordinates(x, y, z)\n        x = np.ascontiguousarray(x, dtype=np.float_)\n        y = np.ascontiguousarray(y, dtype=np.float_)\n        if z is not None:\n            z = np.ascontiguousarray(z, dtype=np.float_)\n\n        return func(x, y, z)",
  "def get_rational(i, array):\n        \"\"\"\n        Gets rid of infinity and nan coordinates\n        \"\"\"\n        args = np.argwhere(np.isfinite(array))\n        if len(args) == 0:\n            # 2-D shape with a simple axis offset\n            # Get the first value of the coordinate set which is equal to the\n            # offset\n            return [x, y, z][i][0]\n        elif len(args) == 1:\n            return array[args[0][0]]\n        else:\n            if all(np.isclose(array, 0)):\n                return 0\n            elif any(np.isclose(array, 0)):\n                # Occasionally the two c values are not the same, and one is 0\n                return array[np.argmax(np.abs(array))]\n            else:\n                return array[0]",
  "def __init__(self, xyz_array: Union[np.ndarray, Dict, Iterable[Iterable]]):\n        self._array = _parse_to_xyz_array(xyz_array)\n        self._is_planar = None\n        self._normal_vector = None",
  "def from_json(cls, filename: str):\n        \"\"\"\n        Load a Coordinates object from a JSON file.\n\n        Parameters\n        ----------\n        filename:\n            Full path file name of the data\n        \"\"\"\n        try:\n            with open(filename, \"r\") as data:\n                xyz_dict = json.load(data)\n        except json.JSONDecodeError:\n            raise CoordinatesError(\n                f\"Could not read the file: {filename}\"\n                + \"\\n Please ensure it is a JSON file.\"\n            )\n\n        # NOTE: Stabler than **xyz_dict\n        x = xyz_dict.get(\"x\", 0)\n        y = xyz_dict.get(\"y\", 0)\n        z = xyz_dict.get(\"z\", 0)\n        return cls({\"x\": x, \"y\": y, \"z\": z})",
  "def _set_plane_props(self):\n        \"\"\"\n        Set the planar properties of the Coordinates.\n        \"\"\"\n        if self._is_planar is None and self._normal_vector is None:\n            self._update_plane_props()",
  "def _update_plane_props(self):\n        if len(self) > 3:\n            eigenvalues, eigenvectors = principal_components(self._array)\n\n            if np.isclose(eigenvalues[-1], 0.0):\n                self._is_planar = True\n            else:\n                self._is_planar = False\n\n            self._normal_vector = eigenvectors[:, -1]\n        else:\n            bluemira_warn(\"Cannot set planar properties on Coordinates with length < 3.\")\n            self._is_planar = False\n            self._normal_vector = None",
  "def is_planar(self) -> bool:\n        \"\"\"\n        Whether or not the Coordinates are planar.\n        \"\"\"\n        self._set_plane_props()\n        return self._is_planar",
  "def normal_vector(self) -> np.ndarray:\n        \"\"\"\n        The normal vector of the best-fit plane of the Coordinates.\n        \"\"\"\n        self._set_plane_props()\n        return self._normal_vector",
  "def check_ccw(self, axis: Optional[np.ndarray] = None) -> bool:\n        \"\"\"\n        Whether or not the Coordinates are ordered in the counter-clockwise direction\n        about a specified axis. If None is specified, the Coordinates normal vector will\n        be used.\n        \"\"\"\n        if len(self) < 3:\n            return False\n\n        if axis is None:\n            axis = self.normal_vector\n        else:\n            axis = np.array(axis, dtype=float)\n            if axis.size != 3:\n                raise CoordinatesError(\"Base vector must be of size 3.\")\n            axis /= np.linalg.norm(axis)\n\n        return check_ccw_3d(self.x, self.y, self.z, axis)",
  "def set_ccw(self, axis: Optional[np.ndarray] = None):\n        \"\"\"\n        Set the Coordinates to be counter-clockwise about a specified axis. If None is\n        specified, the Coordinates normal vector will be used.\n        \"\"\"\n        if len(self) < 3:\n            bluemira_warn(\"Cannot set Coordinates of length < 3 to CCW.\")\n            return\n\n        if not self.check_ccw(axis=axis):\n            self.reverse()",
  "def distance_to(self, point: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Calculates the distances from each point in the Coordinates to the point.\n\n        Parameters\n        ----------\n        point:\n            The point (3-D) to which to calculate the distances\n\n        Returns\n        -------\n        The vector of distances of the Coordinates to the point\n        \"\"\"\n        point = np.array(point)\n        point = point.reshape(3, 1).T\n        return cdist(self.xyz.T, point, \"euclidean\")",
  "def argmin(self, point: np.ndarray) -> int:\n        \"\"\"\n        Parameters\n        ----------\n        point:\n            The 3-D point to which to calculate the distances\n\n        Returns\n        -------\n        The index of the closest point\n        \"\"\"\n        return np.argmin(self.distance_to(point))",
  "def x(self) -> np.ndarray:\n        \"\"\"\n        The x coordinate vector\n        \"\"\"\n        return self._array[0]",
  "def y(self) -> np.ndarray:\n        \"\"\"\n        The y coordinate vector\n        \"\"\"\n        return self._array[1]",
  "def z(self) -> np.ndarray:\n        \"\"\"\n        The z coordinate vector\n        \"\"\"\n        return self._array[2]",
  "def xy(self) -> np.ndarray:\n        \"\"\"\n        The x-y coordinate array\n        \"\"\"\n        return self._array[[0, 1], :]",
  "def xz(self) -> np.ndarray:\n        \"\"\"\n        The x-z coordinate array\n        \"\"\"\n        return self._array[[0, 2], :]",
  "def yz(self) -> np.ndarray:\n        \"\"\"\n        The y-z coordinate array\n        \"\"\"\n        return self._array[[1, 2], :]",
  "def xyz(self) -> np.ndarray:\n        \"\"\"\n        The x-y-z coordinate array\n        \"\"\"\n        return self._array",
  "def points(self) -> List[np.ndarray]:\n        \"\"\"\n        A list of the individual points of the Coordinates.\n        \"\"\"\n        return list(self.T)",
  "def as_dict(self) -> Dict[str, np.ndarray]:\n        \"\"\"\n        Cast the Coordinates as a dictionary.\n\n        Returns\n        -------\n        d: dict\n            Dictionary with {'x': [], 'y': [], 'z':[]}\n        \"\"\"\n        return {\"x\": self.x, \"y\": self.y, \"z\": self.z}",
  "def to_json(self, filename: str, **kwargs: Dict[str, Any]) -> str:\n        \"\"\"\n        Save the Coordinates as a JSON file.\n        \"\"\"\n        d = self.as_dict()\n        filename = os.path.splitext(filename)[0]\n        filename += \".json\"\n        return json_writer(d, filename, **kwargs)",
  "def closed(self) -> bool:\n        \"\"\"\n        Whether or not this is a closed set of Coordinates.\n        \"\"\"\n        if len(self) > 2:\n            if np.allclose(self[:, 0], self[:, -1], rtol=0, atol=EPS):\n                return True\n        return False",
  "def length(self) -> float:\n        \"\"\"\n        Perimeter length of the coordinates.\n        \"\"\"\n        return get_perimeter_3d(*self._array)",
  "def center_of_mass(self) -> Tuple[float, float, float]:\n        \"\"\"\n        Geometrical centroid of the Coordinates.\n        \"\"\"\n        # [sic] coordinates do not have a \"mass\", but named such for consistency with\n        # other geometry objects.\n        if len(self) == 1:\n            return self.xyz.T[0]\n\n        elif len(self) == 2:\n            return np.average(self.xyz.T)\n\n        return tuple(get_centroid_3d(*self._array))",
  "def T(self) -> np.ndarray:  # noqa :N802\n        \"\"\"\n        Transpose of the Coordinates\n        \"\"\"\n        return self._array.T",
  "def shape(self) -> Tuple[int, int]:\n        \"\"\"\n        Shape of the Coordinates\n        \"\"\"\n        return self._array.shape",
  "def reverse(self):\n        \"\"\"\n        Reverse the direction of the Coordinates.\n        \"\"\"\n        self._array = self._array[:, ::-1]",
  "def open(self):\n        \"\"\"\n        Open the Coordinates (if they are closed)\n        \"\"\"\n        if len(self) < 3:\n            bluemira_warn(f\"Cannot open Coordinates of length {len(self)}\")\n            return\n\n        if self.closed:\n            self._array = self._array[:, :-1]",
  "def insert(self, point: np.ndarray, index: int = 0):\n        \"\"\"\n        Insert a point to the Coordinates.\n\n        Parameters\n        ----------\n        point:\n            The 3-D point to insert into the Coordinates\n        index:\n            The position of the point in the Coordinates (order index)\n        \"\"\"\n        if index > len(self):\n            bluemira_warn(\n                \"Inserting a point in Coordinates at an index greater than the number of points.\"\n            )\n            index = -1\n        if not np.isclose(self.xyz.T, point).all(axis=1).any():\n            point = np.array(point).reshape((3, 1))\n            if index == -1:\n                self._array = np.hstack((self._array, point))\n            else:\n                self._array = np.hstack(\n                    (self._array[:, :index], point, self._array[:, index:])\n                )",
  "def close(self):\n        \"\"\"\n        Close the Coordinates (if they are open)\n        \"\"\"\n        if len(self) < 3:\n            bluemira_warn(f\"Cannot close Coordinates of length {len(self)}\")\n            return\n\n        if not self.closed:\n            self._array = np.vstack((self._array.T, self._array[:, 0])).T",
  "def rotate(\n        self,\n        base: Tuple[float, float, float] = (0, 0, 0),\n        direction: Tuple[float, float, float] = (0, 0, 1),\n        degree: float = 0.0,\n    ):\n        \"\"\"\n        Rotate the Coordinates.\n\n        Parameters\n        ----------\n        base:\n            Origin location of the rotation\n        direction:\n            The direction vector\n        degree:\n            rotation angle [degrees]\n        \"\"\"\n        if degree == 0.0:\n            return\n\n        base = np.array(base, dtype=float)\n        if base.size != 3:\n            raise CoordinatesError(\"Base vector must be of size 3.\")\n\n        direction = np.array(direction, dtype=float)\n        if direction.size != 3:\n            raise CoordinatesError(\"Direction vector must be of size 3.\")\n        direction /= np.linalg.norm(direction)\n\n        points = self._array - base.reshape(3, 1)\n        quart = Quaternion(axis=direction, angle=np.deg2rad(degree))\n        r_matrix = quart.rotation_matrix\n        new_array = points.T @ r_matrix.T + base\n        self._array = new_array.T\n\n        self._update_plane_props()",
  "def translate(self, vector: Tuple[float, float, float] = (0, 0, 0)):\n        \"\"\"\n        Translate this shape with the vector. This function modifies the self\n        object.\n        \"\"\"\n        vector = np.array(vector)\n        if vector.size != 3:\n            raise CoordinatesError(\"Translation vector must be of size 3.\")\n\n        self._array += vector.reshape(3, 1)\n        self._update_plane_props()",
  "def __eq__(self, other: Coordinates) -> bool:\n        \"\"\"\n        Check the Coordinates for equality with other Coordinates.\n\n        Parameters\n        ----------\n        other:\n            The other Coordinates to compare against\n\n        Returns\n        -------\n        Whether or not the Coordinates are identical\n\n        Notes\n        -----\n        Coordinates with identical coordinates but different orderings will not be\n        counted as identical.\n        \"\"\"\n        if isinstance(other, self.__class__):\n            return np.all(np.allclose(self._array, other._array, rtol=0, atol=EPS))\n        return False",
  "def __len__(self) -> int:\n        \"\"\"\n        The number of points in the Coordinates.\n        \"\"\"\n        return self.shape[1]",
  "def __repr__(self) -> str:\n        \"\"\"\n        Representation of the Coordinates.\n        \"\"\"\n        r = self._array.__repr__()\n        return f\"{self.__class__.__name__}{r[5:]}\"",
  "def __getitem__(self, *args, **kwargs):\n        \"\"\"\n        Array-like indexing and slicing.\n        \"\"\"\n        return self._array.__getitem__(*args, **kwargs)",
  "def __iter__(self):\n        \"\"\"\n        Array-like unpacking.\n        \"\"\"\n        return self._array.__iter__()",
  "def inner_inter(x_1, x_2):\n        n1, n2 = x_1.shape[0] - 1, x_2.shape[0] - 1\n        xx1 = np.c_[x_1[:-1], x_1[1:]]\n        xx2 = np.c_[x_2[:-1], x_2[1:]]\n        return (\n            np.less_equal(\n                np.tile(xx1.min(axis=1), (n2, 1)).T, np.tile(xx2.max(axis=1), (n1, 1))\n            ),\n            np.greater_equal(\n                np.tile(xx1.max(axis=1), (n2, 1)).T, np.tile(xx2.min(axis=1), (n1, 1))\n            ),\n        )",
  "class BoundingBox:\n    \"\"\"\n    Bounding box class\n\n    Parameters\n    ----------\n    x_min:\n        Minimum x coordinate\n    x_max:\n        Maximum x coordinate\n    y_min:\n        Minimum y coordinate\n    y_max:\n        Maximum y coordinate\n    z_min:\n        Minimum z coordinate\n    z_max:\n        Maximum z coordinate\n    \"\"\"\n\n    x_min: float\n    x_max: float\n    y_min: float\n    y_max: float\n    z_min: float\n    z_max: float\n\n    def __post_init__(self):\n        \"\"\"\n        Perform some silent sanity checks.\n        \"\"\"\n        if self.x_min > self.x_max:\n            self.x_min, self.x_max = self.x_max, self.x_min\n        if self.y_min > self.y_max:\n            self.y_min, self.y_max = self.y_max, self.y_min\n        if self.z_min > self.z_max:\n            self.z_min, self.z_max = self.z_max, self.z_min\n\n    @classmethod\n    def from_xyz(cls, x: np.ndarray, y: np.ndarray, z: np.ndarray):\n        \"\"\"\n        Create a BoundingBox from a set of coordinates\n\n        Parameters\n        ----------\n        x:\n            x coordinates from which to create the bounding box\n        y:\n            y coordinates from which to create the bounding box\n        z:\n            z coordinates from which to create the bounding box\n        \"\"\"\n        x_max, x_min = np.max(x), np.min(x)\n        y_max, y_min = np.max(y), np.min(y)\n        z_max, z_min = np.max(z), np.min(z)\n        return cls(x_min, x_max, y_min, y_max, z_min, z_max)\n\n    def get_box_arrays(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Get the x, y, z arrays of the BoundingBox in space.\n\n        Returns\n        -------\n        x_b:\n            x coordinates of the BoundingBox in space\n        y_b:\n            y coordinates of the BoundingBox in space\n        z_b:\n            z coordinates of the BoundingBox in space\n        \"\"\"\n        size = max(\n            [self.x_max - self.x_min, self.y_max - self.y_min, self.z_max - self.z_min]\n        )\n\n        x_b = 0.5 * size * np.array([-1, -1, -1, -1, 1, 1, 1, 1]) + 0.5 * (\n            self.x_max + self.x_min\n        )\n        y_b = 0.5 * size * np.array([-1, -1, 1, 1, -1, -1, 1, 1]) + 0.5 * (\n            self.y_max + self.y_min\n        )\n        z_b = 0.5 * size * np.array([-1, 1, -1, 1, -1, 1, -1, 1]) + 0.5 * (\n            self.z_max + self.z_min\n        )\n        return x_b, y_b, z_b",
  "def __post_init__(self):\n        \"\"\"\n        Perform some silent sanity checks.\n        \"\"\"\n        if self.x_min > self.x_max:\n            self.x_min, self.x_max = self.x_max, self.x_min\n        if self.y_min > self.y_max:\n            self.y_min, self.y_max = self.y_max, self.y_min\n        if self.z_min > self.z_max:\n            self.z_min, self.z_max = self.z_max, self.z_min",
  "def from_xyz(cls, x: np.ndarray, y: np.ndarray, z: np.ndarray):\n        \"\"\"\n        Create a BoundingBox from a set of coordinates\n\n        Parameters\n        ----------\n        x:\n            x coordinates from which to create the bounding box\n        y:\n            y coordinates from which to create the bounding box\n        z:\n            z coordinates from which to create the bounding box\n        \"\"\"\n        x_max, x_min = np.max(x), np.min(x)\n        y_max, y_min = np.max(y), np.min(y)\n        z_max, z_min = np.max(z), np.min(z)\n        return cls(x_min, x_max, y_min, y_max, z_min, z_max)",
  "def get_box_arrays(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"\n        Get the x, y, z arrays of the BoundingBox in space.\n\n        Returns\n        -------\n        x_b:\n            x coordinates of the BoundingBox in space\n        y_b:\n            y coordinates of the BoundingBox in space\n        z_b:\n            z coordinates of the BoundingBox in space\n        \"\"\"\n        size = max(\n            [self.x_max - self.x_min, self.y_max - self.y_min, self.z_max - self.z_min]\n        )\n\n        x_b = 0.5 * size * np.array([-1, -1, -1, -1, 1, 1, 1, 1]) + 0.5 * (\n            self.x_max + self.x_min\n        )\n        y_b = 0.5 * size * np.array([-1, -1, 1, 1, -1, -1, 1, 1]) + 0.5 * (\n            self.y_max + self.y_min\n        )\n        z_b = 0.5 * size * np.array([-1, 1, -1, 1, -1, 1, -1, 1]) + 0.5 * (\n            self.z_max + self.z_min\n        )\n        return x_b, y_b, z_b",
  "class BluemiraShell(BluemiraGeo):\n    \"\"\"\n    Bluemira Shell class.\n\n    Parameters\n    ----------\n    boundary:\n        List of faces from which to make the BluemiraShell\n    label:\n        Label to assign to the shell\n    \"\"\"\n\n    def __init__(self, boundary: List[BluemiraFace], label: str = \"\"):\n        boundary_classes = [BluemiraFace]\n        super().__init__(boundary, label, boundary_classes)\n\n    def _create_shell(self, check_reverse: bool = True):\n        \"\"\"Creation of the shell\"\"\"\n        faces = [f._create_face(check_reverse=True) for f in self.boundary]\n        shell = cadapi.apiShell(faces)\n\n        if check_reverse:\n            return self._check_reverse(shell)\n        else:\n            return shell\n\n    def _create_shape(self):\n        \"\"\"Part.Shell: shape of the object as a primitive shell\"\"\"\n        return self._create_shell()\n\n    @classmethod\n    def _create(cls, obj: cadapi.apiShell, label=\"\"):\n        if isinstance(obj, cadapi.apiShell):\n            faces = obj.Faces\n            bmfaces = []\n            for face in faces:\n                bmfaces.append(BluemiraFace._create(face))\n\n            bmshell = BluemiraShell(None, label=label)\n            bmshell._set_shape(obj)\n            bmshell._set_boundary(bmfaces, False)\n            bmshell._orientation = obj.Orientation\n            return bmshell\n        raise TypeError(\n            f\"Only Part.Shell objects can be used to create a {cls} instance\"\n        )\n\n    @property\n    def vertexes(self) -> Coordinates:\n        \"\"\"\n        The vertexes of the shell.\n        \"\"\"\n        return Coordinates(cadapi.vertexes(self.shape))\n\n    @property\n    def edges(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The edges of the shell.\n        \"\"\"\n        return tuple([BluemiraWire(cadapi.apiWire(o)) for o in cadapi.edges(self.shape)])\n\n    @property\n    def wires(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The wires of the shell.\n        \"\"\"\n        return tuple([BluemiraWire(o) for o in cadapi.wires(self.shape)])\n\n    @property\n    def faces(self) -> Tuple[BluemiraFace]:\n        \"\"\"\n        The faces of the shell.\n        \"\"\"\n        return tuple([BluemiraFace._create(o) for o in cadapi.faces(self.shape)])\n\n    @property\n    def shells(self) -> tuple:\n        \"\"\"\n        The shells of the shell. By definition a tuple of itself.\n        \"\"\"\n        return tuple([self])\n\n    @property\n    def solids(self) -> tuple:\n        \"\"\"\n        The solids of the shell. By definition an empty tuple.\n        \"\"\"\n        return ()",
  "def __init__(self, boundary: List[BluemiraFace], label: str = \"\"):\n        boundary_classes = [BluemiraFace]\n        super().__init__(boundary, label, boundary_classes)",
  "def _create_shell(self, check_reverse: bool = True):\n        \"\"\"Creation of the shell\"\"\"\n        faces = [f._create_face(check_reverse=True) for f in self.boundary]\n        shell = cadapi.apiShell(faces)\n\n        if check_reverse:\n            return self._check_reverse(shell)\n        else:\n            return shell",
  "def _create_shape(self):\n        \"\"\"Part.Shell: shape of the object as a primitive shell\"\"\"\n        return self._create_shell()",
  "def _create(cls, obj: cadapi.apiShell, label=\"\"):\n        if isinstance(obj, cadapi.apiShell):\n            faces = obj.Faces\n            bmfaces = []\n            for face in faces:\n                bmfaces.append(BluemiraFace._create(face))\n\n            bmshell = BluemiraShell(None, label=label)\n            bmshell._set_shape(obj)\n            bmshell._set_boundary(bmfaces, False)\n            bmshell._orientation = obj.Orientation\n            return bmshell\n        raise TypeError(\n            f\"Only Part.Shell objects can be used to create a {cls} instance\"\n        )",
  "def vertexes(self) -> Coordinates:\n        \"\"\"\n        The vertexes of the shell.\n        \"\"\"\n        return Coordinates(cadapi.vertexes(self.shape))",
  "def edges(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The edges of the shell.\n        \"\"\"\n        return tuple([BluemiraWire(cadapi.apiWire(o)) for o in cadapi.edges(self.shape)])",
  "def wires(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The wires of the shell.\n        \"\"\"\n        return tuple([BluemiraWire(o) for o in cadapi.wires(self.shape)])",
  "def faces(self) -> Tuple[BluemiraFace]:\n        \"\"\"\n        The faces of the shell.\n        \"\"\"\n        return tuple([BluemiraFace._create(o) for o in cadapi.faces(self.shape)])",
  "def shells(self) -> tuple:\n        \"\"\"\n        The shells of the shell. By definition a tuple of itself.\n        \"\"\"\n        return tuple([self])",
  "def solids(self) -> tuple:\n        \"\"\"\n        The solids of the shell. By definition an empty tuple.\n        \"\"\"\n        return ()",
  "class GeometryError(BluemiraError):\n    \"\"\"\n    Error class for use in the geometry module\n    \"\"\"\n\n    pass",
  "class NotClosedWire(BluemiraError):\n    \"\"\"\n    Not Closed Wire Error\n    \"\"\"\n\n    pass",
  "class MixedOrientationWireError(BluemiraError):\n    \"\"\"\n    Mixed Orientation Wire Error\n    \"\"\"\n\n    pass",
  "class DisjointedFace(BluemiraError):\n    \"\"\"\n    Disjointed Face Error\n    \"\"\"\n\n    pass",
  "class DisjointedSolid(BluemiraError):\n    \"\"\"\n    Disjointed Solid Error\n    \"\"\"\n\n    pass",
  "class GeometryParameterisationError(GeometryError):\n    \"\"\"\n    Error class for parametric shapes.\n    \"\"\"\n\n    pass",
  "class CoordinatesError(GeometryError):\n    \"\"\"\n    Error class for use in Coordinates\n    \"\"\"\n\n    pass",
  "class BluemiraCompound(BluemiraGeo):\n    \"\"\"\n    Bluemira Compound class.\n\n    Parameters\n    ----------\n    boundary:\n        List of BluemiraGeo objects to include in the compound\n    label:\n        Label to assign to the compound\n    \"\"\"\n\n    def __init__(self, boundary: List[BluemiraGeo], label: str = \"\"):\n        boundary_classes = [BluemiraGeo]\n        super().__init__(boundary, label, boundary_classes)\n\n    def _create_shape(self) -> cadapi.apiCompound:\n        \"\"\"apiCompound: shape of the object as a single compound\"\"\"\n        return cadapi.apiCompound([s.shape for s in self.boundary])\n\n    @classmethod\n    def _create(cls, obj: cadapi.apiCompound, label=\"\"):\n        if not isinstance(obj, cadapi.apiCompound):\n            raise TypeError(\n                f\"Only apiCompound objects can be used to create a {cls} instance\"\n            )\n        if not obj.isValid():\n            raise GeometryError(f\"Compound {obj} is not valid.\")\n\n        bm_solids = [BluemiraSolid._create(solid) for solid in cadapi.solids(obj)]\n        bm_shells = [BluemiraShell._create(shell) for shell in cadapi.shells(obj)]\n        bm_faces = [BluemiraFace._create(face) for face in cadapi.faces(obj)]\n        bm_wires = [BluemiraWire(wire) for wire in cadapi.wires(obj)]\n\n        return cls(bm_solids + bm_shells + bm_faces + bm_wires, label=label)\n\n    @property\n    def vertexes(self) -> Coordinates:\n        \"\"\"\n        The vertexes of the compound.\n        \"\"\"\n        return Coordinates(cadapi.vertexes(self.shape))\n\n    @property\n    def edges(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The edges of the compound.\n        \"\"\"\n        return tuple([BluemiraWire(cadapi.apiWire(o)) for o in cadapi.edges(self.shape)])\n\n    @property\n    def wires(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The wires of the compound.\n        \"\"\"\n        return tuple([BluemiraWire(o) for o in cadapi.wires(self.shape)])\n\n    @property\n    def faces(self) -> Tuple[BluemiraFace]:\n        \"\"\"\n        The faces of the compound.\n        \"\"\"\n        return tuple([BluemiraFace._create(o) for o in cadapi.faces(self.shape)])\n\n    @property\n    def shells(self) -> Tuple[BluemiraShell]:\n        \"\"\"\n        The shells of the compound.\n        \"\"\"\n        return tuple([BluemiraShell._create(o) for o in cadapi.shells(self.shape)])\n\n    @property\n    def solids(self) -> Tuple[BluemiraSolid]:\n        \"\"\"\n        The solids of the compound.\n        \"\"\"\n        return tuple([BluemiraSolid._create(o) for o in cadapi.solids(self.shape)])",
  "def __init__(self, boundary: List[BluemiraGeo], label: str = \"\"):\n        boundary_classes = [BluemiraGeo]\n        super().__init__(boundary, label, boundary_classes)",
  "def _create_shape(self) -> cadapi.apiCompound:\n        \"\"\"apiCompound: shape of the object as a single compound\"\"\"\n        return cadapi.apiCompound([s.shape for s in self.boundary])",
  "def _create(cls, obj: cadapi.apiCompound, label=\"\"):\n        if not isinstance(obj, cadapi.apiCompound):\n            raise TypeError(\n                f\"Only apiCompound objects can be used to create a {cls} instance\"\n            )\n        if not obj.isValid():\n            raise GeometryError(f\"Compound {obj} is not valid.\")\n\n        bm_solids = [BluemiraSolid._create(solid) for solid in cadapi.solids(obj)]\n        bm_shells = [BluemiraShell._create(shell) for shell in cadapi.shells(obj)]\n        bm_faces = [BluemiraFace._create(face) for face in cadapi.faces(obj)]\n        bm_wires = [BluemiraWire(wire) for wire in cadapi.wires(obj)]\n\n        return cls(bm_solids + bm_shells + bm_faces + bm_wires, label=label)",
  "def vertexes(self) -> Coordinates:\n        \"\"\"\n        The vertexes of the compound.\n        \"\"\"\n        return Coordinates(cadapi.vertexes(self.shape))",
  "def edges(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The edges of the compound.\n        \"\"\"\n        return tuple([BluemiraWire(cadapi.apiWire(o)) for o in cadapi.edges(self.shape)])",
  "def wires(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The wires of the compound.\n        \"\"\"\n        return tuple([BluemiraWire(o) for o in cadapi.wires(self.shape)])",
  "def faces(self) -> Tuple[BluemiraFace]:\n        \"\"\"\n        The faces of the compound.\n        \"\"\"\n        return tuple([BluemiraFace._create(o) for o in cadapi.faces(self.shape)])",
  "def shells(self) -> Tuple[BluemiraShell]:\n        \"\"\"\n        The shells of the compound.\n        \"\"\"\n        return tuple([BluemiraShell._create(o) for o in cadapi.shells(self.shape)])",
  "def solids(self) -> Tuple[BluemiraSolid]:\n        \"\"\"\n        The solids of the compound.\n        \"\"\"\n        return tuple([BluemiraSolid._create(o) for o in cadapi.solids(self.shape)])",
  "class GeometryParameterisation(abc.ABC, Generic[OptVariablesFrameT]):\n    \"\"\"\n    A geometry parameterisation class facilitating geometry optimisation.\n\n    Notes\n    -----\n    Subclass this base class when making a new GeometryParameterisation, adding a set of\n    variables with initial values, and override the create_shape method.\n    \"\"\"\n\n    __slots__ = (\"name\", \"_variables\")\n\n    def __init__(self, variables: OptVariablesFrameT):\n        \"\"\"\n        Parameters\n        ----------\n        variables:\n            Set of optimisation variables of the GeometryParameterisation\n        \"\"\"\n        self.name = self.__class__.__name__\n        self._variables = variables\n\n    @property\n    def n_ineq_constraints(self) -> int:\n        \"\"\"Number of inequality constraints in the GeometryParameterisation\"\"\"\n        return 0\n\n    @property\n    def variables(self) -> OptVariablesFrameT:\n        \"\"\"The variables of the GeometryParameterisation\"\"\"\n        return self._variables\n\n    def adjust_variable(\n        self,\n        name: str,\n        value: Optional[float] = None,\n        lower_bound: Optional[float] = None,\n        upper_bound: Optional[float] = None,\n    ):\n        \"\"\"\n        Adjust a variable in the GeometryParameterisation.\n\n        Parameters\n        ----------\n        name:\n            Name of the variable to adjust\n        value:\n            Value of the variable to set\n        lower_bound:\n            Value of the lower bound to set\n        upper_bound:\n            Value of the upper to set\n        \"\"\"\n        self.variables.adjust_variable(name, value, lower_bound, upper_bound)\n\n    def fix_variable(self, name: str, value: Optional[float] = None):\n        \"\"\"\n        Fix a variable in the GeometryParameterisation, removing it from optimisation\n        but preserving a constant value.\n\n        Parameters\n        ----------\n        name:\n            Name of the variable to fix\n        value:\n            Value at which to fix the variable (will default to present value)\n        \"\"\"\n        self.variables.fix_variable(name, value)\n\n    def shape_ineq_constraints(\n        self, constraint: np.ndarray, x: np.ndarray, grad: np.ndarray\n    ):\n        \"\"\"\n        Inequality constraint function for the variable vector of the geometry\n        parameterisation. This is used when internal consistency between different\n        un-fixed variables is required.\n\n        Parameters\n        ----------\n        constraint:\n            Constraint vector (assign in place)\n        x:\n            Normalised vector of free variables\n        grad:\n            Gradient matrix of the constraint (assign in place)\n\n        Notes\n        -----\n        Deprecated please use `f_ineq_constraint` and `df_ineq_constraint`\n        \"\"\"\n        warnings.warn(\n            \"Use of 'shape_ineq_constraints' method is \"\n            \"deprecated and it will be removed in version 2.0.0.\\n\"\n            \"See \"\n            \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n            \"optimisation.html \"\n            \"for documentation of the new optimisation module.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        self.f_ineq_constraint()\n\n    def f_ineq_constraint(self):\n        \"\"\"\n        Inequality constraint function for the variable vector of the geometry\n        parameterisation. This is used when internal consistency between different\n        un-fixed variables is required.\n\n        \"\"\"\n        if self.n_ineq_constraints < 1:\n            raise GeometryParameterisationError(\n                f\"Cannot apply shape_ineq_constraints to {type(self).__name__}: it\"\n                \"has no inequality constraints.\"\n            )\n\n    @property\n    def tolerance(self) -> npt.NDArray:\n        \"\"\"\n        Optimisation tolerance for the geometry parameterisation.\n        \"\"\"\n        return np.array([np.finfo(float).eps])\n\n    def get_x_norm_index(self, name: str) -> int:\n        \"\"\"\n        Get the index of a variable name in the modified-length x_norm vector\n\n        Parameters\n        ----------\n        variables:\n            Bounded optimisation variables\n        name:\n            Variable name for which to get the index\n\n        Returns\n        -------\n        Index of the variable name in the modified-length x_norm vector\n        \"\"\"\n        fixed_idx = self.variables._fixed_variable_indices\n        idx_actual = self.variables.names.index(name)\n\n        if not fixed_idx:\n            return idx_actual\n\n        count = 0\n        for idx_fx in fixed_idx:\n            if idx_actual > idx_fx:\n                count += 1\n        return idx_actual - count\n\n    def process_x_norm_fixed(self, x_norm: np.ndarray) -> List[float]:\n        \"\"\"\n        Utility for processing a set of free, normalised variables, and folding the fixed\n        un-normalised variables back into a single list of all actual values.\n\n        Parameters\n        ----------\n        variables:\n            Bounded optimisation variables\n        x_norm:\n            Normalised vector of variable values\n\n        Returns\n        -------\n        List of ordered actual (un-normalised) values\n        \"\"\"\n        fixed_idx = self.variables._fixed_variable_indices\n\n        # Note that we are dealing with normalised values when coming from the optimiser\n        x_actual = list(self.variables.get_values_from_norm(x_norm))\n\n        if fixed_idx:\n            x_fixed = self.variables.values\n            for i in fixed_idx:\n                x_actual.insert(i, x_fixed[i])\n        return x_actual\n\n    @abc.abstractmethod\n    def create_shape(self, label: str = \"\", **kwargs: Dict[str, Any]) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the geometry.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        pass\n\n    def to_json(self, file: str):\n        \"\"\"\n        Write the json representation of the GeometryParameterisation to a file.\n\n        Parameters\n        ----------\n        file:\n            The path to the file.\n        \"\"\"\n        self.variables.to_json(file)\n\n    @classmethod\n    def from_json(cls, file: Union[str, TextIO]) -> GeometryParameterisation:\n        \"\"\"\n        Create the GeometryParameterisation from a json file.\n\n        Parameters\n        ----------\n        file:\n            The path to the file, or an open file handle that supports reading.\n        \"\"\"\n        if isinstance(file, str):\n            with open(file, \"r\") as fh:\n                return cls.from_json(fh)\n\n        var_dict = json.load(file)\n        return cls(var_dict)\n\n    def _annotator(self, ax, key: str, xy1: Tuple, xy2: Tuple, xy3: Tuple):\n        \"\"\"\n        Create annotation arrow with label\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis instance\n        key:\n            label of annotation\n        xy1:\n            Tuple for first arrow point\n        xy2:\n            Tuple for second arrow point\n        xy3:\n            Tuple for arrow label location\n\n        \"\"\"\n        ax.annotate(\n            \"\",\n            xy=xy1,\n            xycoords=\"data\",\n            xytext=xy2,\n            textcoords=\"data\",\n            arrowprops={\n                \"arrowstyle\": \"<|-|>\",\n                \"edgecolor\": \"k\",\n                \"facecolor\": \"k\",\n                \"shrinkA\": 0,\n                \"shrinkB\": 0,\n            },\n        )\n        ax.annotate(\n            r\"$\\it{\" f\"{str_to_latex(key).strip('$')}\" \"}$\",\n            xy=xy3,\n            xycoords=\"data\",\n            xytext=(0, 5),\n            textcoords=\"offset points\",\n        )\n\n    def _label_function(self, ax, shape: BluemiraWire):\n        \"\"\"\n        Adds labels to parameterisation plots\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis instance\n        shape:\n            parameterisation wire\n\n        \"\"\"\n        offset_ar_x = 0\n        offset_ar_z = 0\n        for v in self.variables:\n            if v.name.startswith(\"x\"):\n                self._annotator(\n                    ax,\n                    v.name,\n                    (0, offset_ar_x),\n                    (v.value, offset_ar_x),\n                    (v.value * 0.4, offset_ar_x),\n                )\n                ax.plot([0, 0], [0, offset_ar_x], color=\"k\")\n                ax.plot([v.value, v.value], [0, offset_ar_x], color=\"k\")\n                offset_ar_x += 2\n            elif v.name.startswith(\"z\") or v.name[1] == \"z\":\n                xcor = shape.center_of_mass[0] + offset_ar_z\n                self._annotator(\n                    ax,\n                    v.name,\n                    (xcor, 0),\n                    (xcor, v.value),\n                    (xcor, v.value * 0.4),\n                )\n                ax.plot([shape.center_of_mass[0], xcor], [0, 0], color=\"k\")\n                ax.plot(\n                    [shape.center_of_mass[0], xcor],\n                    [v.value, v.value],\n                    color=\"k\",\n                )\n                offset_ar_z += 1.5\n        return offset_ar_x, offset_ar_z\n\n    def plot(self, ax=None, labels=False, **kwargs):\n        \"\"\"\n        Plot the geometry parameterisation\n\n        Parameters\n        ----------\n        ax: Optional[Axes]\n            Matplotlib axes object\n        labels: bool\n            Label variables on figure\n        kwargs: Dict\n            Passed to matplotlib Axes.plot function\n        \"\"\"\n        if ax is None:\n            _, ax = plt.subplots()\n        shape = self.create_shape()\n\n        if labels:\n            self._label_function(ax, shape)\n        ndiscr = kwargs.pop(\"ndiscr\") if \"ndiscr\" in kwargs else 200\n        plot_2d(shape, ax=ax, show=False, ndiscr=ndiscr, **kwargs)\n        return ax",
  "class PrincetonDOptVariables(OptVariablesFrame):\n    x1: OptVariable = ov(\n        \"x1\", 4, lower_bound=2, upper_bound=6, description=\"Inboard limb radius\"\n    )\n    x2: OptVariable = ov(\n        \"x2\",\n        14,\n        lower_bound=10,\n        upper_bound=18,\n        description=\"Outboard limb radius\",\n    )\n    dz: OptVariable = ov(\n        \"dz\",\n        0,\n        lower_bound=-0.5,\n        upper_bound=0.5,\n        description=\"Vertical offset from z=0\",\n    )",
  "class PrincetonD(GeometryParameterisation[PrincetonDOptVariables]):\n    \"\"\"\n    Princeton D geometry parameterisation.\n\n    Parameters\n    ----------\n    var_dict:\n        Dictionary with which to update the default values of the parameterisation.\n\n    Notes\n    -----\n    .. plot::\n\n        from bluemira.geometry.parameterisations import PrincetonD\n        PrincetonD().plot(labels=True)\n\n    The dictionary keys in var_dict are:\n\n    x1: float\n        Radial position of inner limb [m]\n    x2: float\n        Radial position of outer limb [m]\n    dz: float\n        Vertical offset from z=0 [m]\n\n    \"\"\"\n\n    __slots__ = ()\n    n_ineq_constraints: int = 1\n\n    def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = PrincetonDOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)\n\n    def create_shape(self, label: str = \"\", n_points: int = 2000) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the Princeton D.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n        n_points:\n            The number of points to use when calculating the geometry of the Princeton\n            D.\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        x, z = self._princeton_d(\n            self.variables.x1.value,\n            self.variables.x2.value,\n            self.variables.dz.value,\n            n_points,\n        )\n        xyz = np.array([x, np.zeros(len(x)), z])\n\n        outer_arc = interpolate_bspline(\n            xyz.T,\n            label=\"outer_arc\",\n            # start_tangent=[0, 0, 1],\n            # end_tangent=[0, 0, -1],\n        )\n        # TODO: Enforce tangency of this bspline... causing issues with offsetting\n        # TODO: The real irony is that tangencies don't solve the problem..\n        straight_segment = wire_closure(outer_arc, label=\"straight_segment\")\n        return BluemiraWire([outer_arc, straight_segment], label=label)\n\n    def shape_ineq_constraints(\n        self, constraint: np.ndarray, x_norm: np.ndarray, grad: np.ndarray\n    ) -> np.ndarray:\n        \"\"\"\n        Inequality constraint function for the variable vector of the geometry\n        parameterisation. This is used when internal consistency between different\n        un-fixed variables is required.\n\n        Parameters\n        ----------\n        constraint:\n            Constraint vector (assign in place)\n        x:\n            Normalised vector of free variables\n        grad:\n            Gradient matrix of the constraint (assign in place)\n\n        Notes\n        -----\n        Deprecated please use `f_ineq_constraint` and `df_ineq_constraint`\n        \"\"\"\n        warnings.warn(\n            \"Use of 'shape_ineq_constraints' method is \"\n            \"deprecated and it will be removed in version 2.0.0.\\n\"\n            \"See \"\n            \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n            \"optimisation.html \"\n            \"for documentation of the new optimisation module.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        constraint[:] = self.f_ineq_constraint()\n        grad[:] = self.df_ineq_constraint()\n\n        return constraint\n\n    def f_ineq_constraint(self) -> np.ndarray:\n        \"\"\"Inequality constraint for PrincetonD.\"\"\"\n        free_vars = self.variables.get_normalised_values()\n        x1, x2, _ = self.process_x_norm_fixed(free_vars)\n        return np.array([x1 - x2])\n\n    def df_ineq_constraint(self) -> np.ndarray:\n        \"\"\"Inequality constraint gradient for PrincetonD.\"\"\"\n        opt_vars = self.variables\n        free_vars = opt_vars.get_normalised_values()\n        grad = np.zeros((1, len(free_vars)))\n        if not self.variables.x1.fixed:\n            grad[0][self.get_x_norm_index(\"x1\")] = 1\n        if not self.variables.x2.fixed:\n            grad[0][self.get_x_norm_index(\"x2\")] = -1\n        return grad\n\n    @staticmethod\n    def _princeton_d(\n        x1: float, x2: float, dz: float, npoints: int = 2000\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Princeton D shape calculation (e.g. Gralnick and Tenney, 1976, or\n        File, Mills, and Sheffield, 1971)\n\n        Parameters\n        ----------\n        x1:\n            The inboard centreline radius of the Princeton D\n        x2:\n            The outboard centreline radius of the Princeton D\n        dz:\n            The vertical offset (from z=0)\n        npoints: int (default = 2000)\n            The size of the x, z coordinate sets to return\n\n        Returns\n        -------\n        x:\n            The x coordinates of the Princeton D shape\n        z:\n            The z coordinates of the Princeton D shape\n\n        Notes\n        -----\n        Returns an open set of coordinates\n\n        :math:`x = X_{0}e^{ksin(\\\\theta)}`\n        :math:`z = X_{0}k\\\\Bigg[\\\\theta I_{1}(k)+\\\\sum_{n=1}^{\\\\infty}{\\\\frac{i}{n}\n        e^{\\\\frac{in\\\\pi}{2}}\\\\bigg(e^{-in\\\\theta}-1\\\\bigg)\\\\bigg(1+e^{in(\\\\theta+\\\\pi)}\n        \\\\bigg)\\\\frac{I_{n-1}(k)+I_{n+1}(k)}{2}}\\\\Bigg]`\n\n        Where:\n            :math:`X_{0} = \\\\sqrt{x_{1}x_{2}}`\n            :math:`k = \\\\frac{ln(x_{2}/x_{1})}{2}`\n\n        Where:\n            :math:`I_{n}` is the n-th order modified Bessel function\n            :math:`x_{1}` is the inner radial position of the shape\n            :math:`x_{2}` is the outer radial position of the shape\n        \"\"\"  # noqa :W505\n        if x2 <= x1:\n            raise GeometryParameterisationError(\n                \"Princeton D parameterisation requires an x2 value \"\n                f\"greater than x1: {x1} >= {x2}\"\n            )\n\n        xo = np.sqrt(x1 * x2)\n        k = 0.5 * np.log(x2 / x1)\n        theta = np.linspace(-0.5 * np.pi, 1.5 * np.pi, npoints)\n        s = np.zeros(npoints, dtype=\"complex128\")\n        n = 0\n        while True:  # sum convergent series\n            n += 1\n\n            ds = 1j / n * (np.exp(-1j * n * theta) - 1)\n            ds *= 1 + np.exp(1j * n * (theta + np.pi))\n            ds *= np.exp(1j * n * np.pi / 2)\n            ds *= (bessel(n - 1, k) + bessel(n + 1, k)) / 2\n            s += ds\n            if np.max(abs(ds)) < 1e-14:\n                break\n\n        z = abs(xo * k * (bessel(1, k) * theta + s))\n        x = xo * np.exp(k * np.sin(theta))\n        z -= np.mean(z)\n        z += dz  # vertical shift\n        return x, z",
  "class TripleArcOptVaribles(OptVariablesFrame):\n    x1: OptVariable = ov(\n        \"x1\", 4.486, lower_bound=4, upper_bound=5, description=\"Inner limb radius\"\n    )\n    dz: OptVariable = ov(\n        \"dz\",\n        0,\n        lower_bound=-1,\n        upper_bound=1,\n        description=\"Vertical offset from z=0\",\n    )\n    sl: OptVariable = ov(\n        \"sl\", 6.428, lower_bound=5, upper_bound=10, description=\"Straight length\"\n    )\n    f1: OptVariable = ov(\n        \"f1\", 3, lower_bound=2, upper_bound=12, description=\"rs == f1*z small\"\n    )\n    f2: OptVariable = ov(\n        \"f2\", 4, lower_bound=2, upper_bound=12, description=\"rm == f2*rs mid\"\n    )\n\n    a1: OptVariable = ov(\n        \"a1\",\n        20,\n        lower_bound=5,\n        upper_bound=120,\n        description=\"Small arc angle [degrees]\",\n    )\n    a2: OptVariable = ov(\n        \"a2\",\n        40,\n        lower_bound=10,\n        upper_bound=120,\n        description=\"Middle arc angle [degrees]\",\n    )",
  "class TripleArc(GeometryParameterisation[TripleArcOptVaribles]):\n    \"\"\"\n    Triple-arc up-down symmetric geometry parameterisation.\n\n    Parameters\n    ----------\n    var_dict:\n        Dictionary with which to update the default values of the parameterisation.\n\n    Notes\n    -----\n    .. plot::\n\n        from bluemira.geometry.parameterisations import TripleArc\n        TripleArc().plot(labels=True)\n\n    The dictionary keys in var_dict are:\n\n    x1: float\n        Radial position of inner limb [m]\n    dz: float\n        Vertical offset from z=0 [m]\n    sl: float\n        Length of inboard straigh section [m]\n    f1: float\n        rs == f1*z small\n    f2: float\n        rm == f2*rs mid\n    a1: float\n        Small arc angle [degrees]\n    a2: float\n        Middle arc angle [degrees]\n\n    \"\"\"\n\n    __slots__ = ()\n    n_ineq_constraints: int = 1\n\n    def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = TripleArcOptVaribles()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)\n\n    def shape_ineq_constraints(\n        self, constraint: np.ndarray, x_norm: np.ndarray, grad: np.ndarray\n    ) -> np.ndarray:\n        \"\"\"\n        Inequality constraint function for the variable vector of the geometry\n        parameterisation. This is used when internal consistency between different\n        un-fixed variables is required.\n\n        Parameters\n        ----------\n        constraint:\n            Constraint vector (assign in place)\n        x:\n            Normalised vector of free variables\n        grad:\n            Gradient matrix of the constraint (assign in place)\n\n        Notes\n        -----\n        Deprecated please use `f_ineq_constraint` and `df_ineq_constraint`\n        \"\"\"\n        warnings.warn(\n            \"Use of 'shape_ineq_constraints' method is \"\n            \"deprecated and it will be removed in version 2.0.0.\\n\"\n            \"See \"\n            \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n            \"optimisation.html \"\n            \"for documentation of the new optimisation module.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        constraint[:] = self.f_ineq_constraint()\n        grad[:] = self.df_ineq_constraint()\n\n        return constraint\n\n    def f_ineq_constraint(self) -> np.ndarray:\n        \"\"\"\n        Inequality constraint for TripleArc.\n\n        Constrain such that a1 + a2 is less than or equal to 180 degrees.\n        \"\"\"\n        norm_vals = self.variables.get_normalised_values()\n        x_actual = self.process_x_norm_fixed(norm_vals)\n        _, _, _, _, _, a1, a2 = x_actual\n        return np.array([a1 + a2 - 180])\n\n    def df_ineq_constraint(self) -> np.ndarray:\n        \"\"\"Inequality constraint gradient for TripleArc.\"\"\"\n        free_vars = self.variables.get_normalised_values()\n        g = np.zeros((1, len(free_vars)))\n        if not self.variables.a1.fixed:\n            idx_a1 = self.get_x_norm_index(\"a1\")\n            g[0][idx_a1] = 1\n        if not self.variables.a2.fixed:\n            idx_a2 = self.get_x_norm_index(\"a2\")\n            g[0][idx_a2] = 1\n        return g\n\n    def create_shape(self, label: str = \"\") -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the triple arc.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        x1, dz, sl, f1, f2, a1, a2 = self.variables.values\n        a1, a2 = np.deg2rad(a1), np.deg2rad(a2)\n\n        z1 = 0.5 * sl\n        # Upper half\n        p1 = [x1, 0, z1]\n        atot = a1 + a2\n        a15 = 0.5 * a1\n        p15 = [x1 + f1 * (1 - np.cos(a15)), 0, z1 + f1 * np.sin(a15)]\n        p2 = [x1 + f1 * (1 - np.cos(a1)), 0, z1 + f1 * np.sin(a1)]\n\n        a25 = a1 + 0.5 * a2\n        p25 = [\n            p2[0] + f2 * (np.cos(a1) - np.cos(a25)),\n            0,\n            p2[2] + f2 * (np.sin(a25) - np.sin(a1)),\n        ]\n        p3 = [\n            p2[0] + f2 * (np.cos(a1) - np.cos(atot)),\n            0,\n            p2[2] + f2 * (np.sin(atot) - np.sin(a1)),\n        ]\n        rl = p3[2] / np.sin(np.pi - atot)\n\n        a35 = 0.5 * atot\n        p35 = [\n            p3[0] + rl * (np.cos(a35) - np.cos(np.pi - atot)),\n            0,\n            p3[2] - rl * (np.sin(atot) - np.sin(a35)),\n        ]\n        p4 = [\n            p3[0] + rl * (1 - np.cos(np.pi - atot)),\n            0,\n            p3[2] - rl * np.sin(atot),\n        ]\n\n        # Symmetric lower half\n        p45 = [p35[0], 0, -p35[2]]\n        p5 = [p3[0], 0, -p3[2]]\n        p55 = [p25[0], 0, -p25[2]]\n        p6 = [p2[0], 0, -p2[2]]\n        p65 = [p15[0], 0, -p15[2]]\n        p7 = [p1[0], 0, -p1[2]]\n\n        wires = [\n            make_circle_arc_3P(p1, p15, p2, label=\"upper_inner_arc\"),\n            make_circle_arc_3P(p2, p25, p3, label=\"upper_mid_arc\"),\n            make_circle_arc_3P(p3, p35, p4, label=\"upper_outer_arc\"),\n            make_circle_arc_3P(p4, p45, p5, label=\"lower_outer_arc\"),\n            make_circle_arc_3P(p5, p55, p6, label=\"lower_mid_arc\"),\n            make_circle_arc_3P(p6, p65, p7, label=\"lower_inner_arc\"),\n        ]\n\n        if sl != 0.0:\n            straight_segment = wire_closure(\n                BluemiraWire(wires), label=\"straight_segment\"\n            )\n            wires.append(straight_segment)\n\n        wire = BluemiraWire(wires, label=label)\n        wire.translate((0, 0, dz))\n        return wire\n\n    def _label_function(self, ax, shape: BluemiraWire):\n        \"\"\"\n        Adds labels to parameterisation plots\n\n        TODO add labels for sl f1 f2 a1 a2\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis instance\n        shape:\n            parameterisation wire\n\n        \"\"\"\n        offset_x, offset_z = super()._label_function(ax, shape)",
  "class SextupleArcOptVariables(OptVariablesFrame):\n    x1: OptVariable = ov(\n        \"x1\",\n        4.486,\n        lower_bound=4,\n        upper_bound=5,\n        description=\"Inner limb radius\",\n    )\n    z1: OptVariable = ov(\n        \"z1\",\n        5,\n        lower_bound=0,\n        upper_bound=10,\n        description=\"Inboard limb height\",\n    )\n    r1: OptVariable = ov(\n        \"r1\", 4, lower_bound=4, upper_bound=12, description=\"1st arc radius\"\n    )\n    r2: OptVariable = ov(\n        \"r2\", 5, lower_bound=4, upper_bound=12, description=\"2nd arc radius\"\n    )\n    r3: OptVariable = ov(\n        \"r3\", 6, lower_bound=4, upper_bound=12, description=\"3rd arc radius\"\n    )\n    r4: OptVariable = ov(\n        \"r4\", 7, lower_bound=4, upper_bound=12, description=\"4th arc radius\"\n    )\n    r5: OptVariable = ov(\n        \"r5\", 8, lower_bound=4, upper_bound=12, description=\"5th arc radius\"\n    )\n    a1: OptVariable = ov(\n        \"a1\",\n        45,\n        lower_bound=5,\n        upper_bound=50,\n        description=\"1st arc angle [degrees]\",\n    )\n    a2: OptVariable = ov(\n        \"a2\",\n        60,\n        lower_bound=10,\n        upper_bound=80,\n        description=\"2nd arc angle [degrees]\",\n    )\n\n    a3: OptVariable = ov(\n        \"a3\",\n        90,\n        lower_bound=10,\n        upper_bound=100,\n        description=\"3rd arc angle [degrees]\",\n    )\n    a4: OptVariable = ov(\n        \"a4\",\n        40,\n        lower_bound=10,\n        upper_bound=80,\n        description=\"4th arc angle [degrees]\",\n    )\n    a5: OptVariable = ov(\n        \"a5\",\n        30,\n        lower_bound=10,\n        upper_bound=80,\n        description=\"5th arc angle [degrees]\",\n    )",
  "class SextupleArc(GeometryParameterisation[SextupleArcOptVariables]):\n    \"\"\"\n    Sextuple-arc up-down asymmetric geometry parameterisation.\n\n    Parameters\n    ----------\n    var_dict:\n        Dictionary with which to update the default values of the parameterisation.\n\n    Notes\n    -----\n    .. plot::\n\n        from bluemira.geometry.parameterisations import SextupleArc\n        SextupleArc().plot(labels=True)\n\n    The dictionary keys in var_dict are:\n\n    x1: float\n        Radial position of inner limb [m]\n    z1: float\n        Inboard limb height [m]\n    r1 - r5: float\n        arc radius [m]\n    a1 - a5: float\n        arc angle [degrees]\n    \"\"\"\n\n    __slots__ = ()\n    n_ineq_constraints: int = 1\n\n    def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = SextupleArcOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)\n\n    def shape_ineq_constraints(\n        self, constraint: np.ndarray, x_norm: np.ndarray, grad: np.ndarray\n    ) -> np.ndarray:\n        \"\"\"\n        Inequality constraint function for the variable vector of the geometry\n        parameterisation. This is used when internal consistency between different\n        un-fixed variables is required.\n\n        Parameters\n        ----------\n        constraint:\n            Constraint vector (assign in place)\n        x:\n            Normalised vector of free variables\n        grad:\n            Gradient matrix of the constraint (assign in place)\n\n        Notes\n        -----\n        Deprecated please use `f_ineq_constraint` and `df_ineq_constraint`\n        \"\"\"\n        warnings.warn(\n            \"Use of 'shape_ineq_constraints' method is \"\n            \"deprecated and it will be removed in version 2.0.0.\\n\"\n            \"See \"\n            \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n            \"optimisation.html \"\n            \"for documentation of the new optimisation module.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        constraint[:] = self.f_ineq_constraint()\n        grad[:] = self.df_ineq_constraint()\n\n        return constraint\n\n    def f_ineq_constraint(self) -> np.ndarray:\n        \"\"\"\n        Inequality constraint for TripleArc.\n\n        Constrain such that sum of the 5 angles is less than or equal to 360\n        degrees.\n        \"\"\"\n        x_norm = self.variables.get_normalised_values()\n        x_actual = self.process_x_norm_fixed(x_norm)\n        _, _, _, _, _, _, _, a1, a2, a3, a4, a5 = x_actual\n        return np.array([a1 + a2 + a3 + a4 + a5 - 360])\n\n    def df_ineq_constraint(self) -> np.ndarray:\n        \"\"\"Inequality constraint gradient for TripleArc.\"\"\"\n        x_norm = self.variables.get_normalised_values()\n        gradient = np.zeros((1, len(x_norm)))\n        for var in [\"a1\", \"a2\", \"a3\", \"a4\", \"a5\"]:\n            if not self.variables[var].fixed:\n                var_idx = self.get_x_norm_index(var)\n                gradient[0][var_idx] = 1\n        return gradient\n\n    @staticmethod\n    def _project_centroid(xc, zc, xi, zi, ri):\n        vec = np.array([xi - xc, zi - zc])\n        vec /= np.linalg.norm(vec)\n        xc = xi - vec[0] * ri\n        zc = zi - vec[1] * ri\n        return xc, zc, vec\n\n    def create_shape(self, label: str = \"\") -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the sextuple arc.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        variables = self.variables.values\n        x1, z1 = variables[:2]\n        r_values = variables[2:7]\n        a_values = np.deg2rad(variables[7:])\n\n        wires = []\n        a_start = 0\n        xi, zi = x1, z1\n        xc = x1 + r_values[0]\n        zc = z1\n        for i, (ai, ri) in enumerate(zip(a_values, r_values)):\n            if i > 0:\n                xc, zc, _ = self._project_centroid(xc, zc, xi, zi, ri)\n\n            a = np.pi - a_start - ai\n            xi = xc + ri * np.cos(a)\n            zi = zc + ri * np.sin(a)\n\n            start_angle = np.rad2deg(np.pi - a_start)\n            end_angle = np.rad2deg(a)\n\n            arc = make_circle(\n                ri,\n                center=[xc, 0, zc],\n                start_angle=end_angle,\n                end_angle=start_angle,\n                axis=[0, -1, 0],\n                label=f\"arc_{i+1}\",\n            )\n\n            wires.append(arc)\n\n            a_start += ai\n\n        xc, zc, vec = self._project_centroid(xc, zc, xi, zi, ri)\n\n        # Retrieve last arc (could be bad...)\n        r6 = (xi - x1) / (1 + vec[0])\n        xc6 = xi - r6 * vec[0]\n        z7 = zc6 = zi - r6 * vec[1]\n\n        closing_arc = make_circle(\n            r6,\n            center=[xc6, 0, zc6],\n            start_angle=180,\n            end_angle=np.rad2deg(np.pi - a_start),\n            axis=[0, -1, 0],\n            label=\"arc_6\",\n        )\n\n        wires.append(closing_arc)\n\n        if not np.isclose(z1, z7):\n            straight_segment = wire_closure(\n                BluemiraWire(wires), label=\"straight_segment\"\n            )\n            wires.append(straight_segment)\n\n        return BluemiraWire(wires, label=label)\n\n    def _label_function(self, ax, shape: BluemiraWire):\n        \"\"\"\n        Adds labels to parameterisation plots\n\n        TODO add labels for r1-5 a1-5\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis instance\n        shape:\n            parameterisation wire\n\n        \"\"\"\n        offset_x, offset_z = super()._label_function(ax, shape)",
  "class PolySplineOptVariables(OptVariablesFrame):\n    x1: OptVariable = ov(\n        \"x1\",\n        4.3,\n        lower_bound=4,\n        upper_bound=5,\n        description=\"Inner limb radius\",\n    )\n    x2: OptVariable = ov(\n        \"x2\",\n        16.56,\n        lower_bound=5,\n        upper_bound=25,\n        description=\"Outer limb radius\",\n    )\n    z2: OptVariable = ov(\n        \"z2\",\n        0.03,\n        lower_bound=-2,\n        upper_bound=2,\n        description=\"Outer note vertical shift\",\n    )\n    height: OptVariable = ov(\n        \"height\",\n        15.5,\n        lower_bound=10,\n        upper_bound=50,\n        description=\"Full height\",\n    )\n    top: OptVariable = ov(\n        \"top\",\n        0.52,\n        lower_bound=0.2,\n        upper_bound=1,\n        description=\"Horizontal shift\",\n    )\n    upper: OptVariable = ov(\n        \"upper\",\n        0.67,\n        lower_bound=0.2,\n        upper_bound=1,\n        description=\"Vertical shift\",\n    )\n    dz: OptVariable = ov(\n        \"dz\",\n        -0.6,\n        lower_bound=-5,\n        upper_bound=5,\n        description=\"Vertical offset\",\n    )\n    flat: OptVariable = ov(\n        \"flat\",\n        0,\n        lower_bound=0,\n        upper_bound=1,\n        description=\"Fraction of straight outboard leg\",\n    )\n    tilt: OptVariable = ov(\n        \"tilt\",\n        4,\n        lower_bound=-45,\n        upper_bound=45,\n        description=\"Outboard angle [degrees]\",\n    )\n    bottom: OptVariable = ov(\n        \"bottom\",\n        0.4,\n        lower_bound=0,\n        upper_bound=1,\n        description=\"Lower horizontal shift\",\n    )\n    lower: OptVariable = ov(\n        \"lower\",\n        0.67,\n        lower_bound=0.2,\n        upper_bound=1,\n        description=\"Lower vertical shift\",\n    )\n    l0s: OptVariable = ov(\n        \"l0s\",\n        0.8,\n        lower_bound=0.1,\n        upper_bound=1.9,\n        description=\"Tension variable first segment start\",\n    )\n    l1s: OptVariable = ov(\n        \"l1s\",\n        0.8,\n        lower_bound=0.1,\n        upper_bound=1.9,\n        description=\"Tension variable second segment start\",\n    )\n    l2s: OptVariable = ov(\n        \"l2s\",\n        0.8,\n        lower_bound=0.1,\n        upper_bound=1.9,\n        description=\"Tension variable third segment start\",\n    )\n    l3s: OptVariable = ov(\n        \"l3s\",\n        0.8,\n        lower_bound=0.1,\n        upper_bound=1.9,\n        description=\"Tension variable fourth segment start\",\n    )\n    l0e: OptVariable = ov(\n        \"l0e\",\n        0.8,\n        lower_bound=0.1,\n        upper_bound=1.9,\n        description=\"Tension variable first segment end\",\n    )\n    l1e: OptVariable = ov(\n        \"l1e\",\n        0.8,\n        lower_bound=0.1,\n        upper_bound=1.9,\n        description=\"Tension variable second segment end\",\n    )\n    l2e: OptVariable = ov(\n        \"l2e\",\n        0.8,\n        lower_bound=0.1,\n        upper_bound=1.9,\n        description=\"Tension variable third segment end\",\n    )\n    l3e: OptVariable = ov(\n        \"l3e\",\n        0.8,\n        lower_bound=0.1,\n        upper_bound=1.9,\n        description=\"Tension variable fourth segment end\",\n    )",
  "class PolySpline(GeometryParameterisation[PolySplineOptVariables]):\n    \"\"\"\n    Simon McIntosh's Poly-B\u00e9zier-spline geometry parameterisation (19 variables).\n\n    Parameters\n    ----------\n    var_dict:\n        Dictionary with which to update the default values of the parameterisation.\n\n    Notes\n    -----\n    .. plot::\n\n        from bluemira.geometry.parameterisations import PolySpline\n        PolySpline().plot(labels=True)\n\n    The dictionary keys in var_dict are:\n\n    x1: float\n        Radial position of inner limb [m]\n    x2: float\n        Radial position of outer limb [m]\n    z2: float\n        Outer note vertical shift [m]\n    height: float\n        Full height [m]\n    top: float\n        Horizontal shift [m]\n    upper: float\n        Vertical shift [m]\n    dz: float\n        Vertical offset [m]\n    flat: float\n        Fraction of straight outboard leg []\n    tilt: float\n        Outboard angle [degrees]\n    bottom: float\n        Lower horizontal shift [m]\n    lower: float\n        Lower vertical shift [m]\n    l0s - l3s: float\n        Tension variable segment start\n    l0e - l3e: float\n        Tension variable segment end\n\n    \"\"\"\n\n    __slots__ = ()\n\n    def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = PolySplineOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)\n\n    def create_shape(self, label: str = \"\") -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the poly spline.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        variables = self.variables.values\n        (\n            x1,\n            x2,\n            z2,\n            height,\n            top,\n            upper,\n            dz,\n            flat,\n            tilt,\n            bottom,\n            lower,\n        ) = variables[:11]\n        l_start = variables[11:15]\n        l_end = variables[15:]\n\n        tilt = np.deg2rad(tilt)\n        height = 0.5 * height\n        ds_z = flat * height * np.cos(tilt)\n        ds_x = flat * height * np.sin(tilt)\n\n        # Vertices\n        x = [x1, x1 + top * (x2 - x1), x2 + ds_x, x2 - ds_x, x1 + bottom * (x2 - x1), x1]\n        z = [\n            upper * height + dz,\n            height + dz,\n            z2 * height + ds_z + dz,\n            z2 * height - ds_z + dz,\n            -height + dz,\n            -lower * height + dz,\n        ]\n        theta = [\n            0.5 * np.pi,\n            0,\n            -0.5 * np.pi - tilt,\n            -0.5 * np.pi - tilt,\n            -np.pi,\n            0.5 * np.pi,\n        ]\n\n        wires = []\n        for i, j in zip([0, 1, 2, 3], [0, 1, 3, 4]):\n            k = j + 1\n            p0 = [x[j], 0, z[j]]\n            p3 = [x[k], 0, z[k]]\n            p1, p2 = self._make_control_points(\n                p0, p3, theta[j], theta[k] - np.pi, l_start[i], l_end[i]\n            )\n            wires.append(make_bezier([p0, p1, p2, p3], label=f\"segment_{i}\"))\n\n        if flat != 0:\n            outer_straight = make_polygon(\n                [[x[2], 0, z[2]], [x[3], 0, z[3]]], label=\"outer_straight\"\n            )\n            wires.insert(2, outer_straight)\n\n        straight_segment = wire_closure(BluemiraWire(wires), label=\"inner_straight\")\n        wires.append(straight_segment)\n\n        return BluemiraWire(wires, label=label)\n\n    @staticmethod\n    def _make_control_points(p0, p3, theta0, theta3, l_start, l_end):\n        \"\"\"\n        Make 2 B\u00e9zier spline control points between two vertices.\n        \"\"\"\n        dl = np.sqrt(np.sum((np.array(p3) - np.array(p0)) ** 2))\n\n        p1, p2 = np.zeros(3), np.zeros(3)\n        for point, control_point, angle, tension in zip(\n            [p0, p3], [p1, p2], [theta0, theta3], [l_start, l_end]\n        ):\n            d_tension = 0.5 * dl * tension\n            control_point[0] = point[0] + d_tension * np.cos(angle)\n            control_point[2] = point[2] + d_tension * np.sin(angle)\n\n        return p1, p2\n\n    def _label_function(self, ax, shape: BluemiraWire):\n        \"\"\"\n        Adds labels to parameterisation plots\n\n        TODO add labels for:\n\n            height top upper dz flat tilt bottom lower l0s - l3s l0e - l3e\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis instance\n        shape:\n            parameterisation wire\n\n        \"\"\"\n        offset_x, offset_z = super()._label_function(ax, shape)",
  "class PictureFrameTools:\n    \"\"\"\n    Tools Class containing methods to produce various PictureFrame variant limbs.\n\n    \"\"\"\n\n    @staticmethod\n    def _make_domed_leg(\n        x_out: float,\n        x_curve_start: float,\n        x_mid: float,\n        z_top: float,\n        z_mid: float,\n        ri: float,\n        axis: Iterable[float] = (0, -1, 0),\n        flip: bool = False,\n    ) -> BluemiraWire:\n        \"\"\"\n        Makes smooth dome for CP coils. This includes a initial straight section\n        and a main curved dome section, with a transitioning 'joint' between them,\n        producing smooth tangent curves.\n\n        Parameters\n        ----------\n        x_out:\n            Radial position of outer edge of limb [m]\n        x_curve start:\n            Radial position of straight-curve transition of limb [m]\n        x_mid:\n            Radial position of inner edge of  upper/lower limb [m]\n        z_top:\n            Vertical position of top of limb dome [m]\n        z_mid:\n            Vertical position of flat section [m]\n        ri:\n            Radius of inner corner transition. Nominally 0 [m]\n        axis:\n            [x,y,z] vector normal to plane of parameterisation\n        flip:\n            True if limb is lower limb of section, False if upper\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        # Define the basic main curve (with no joint or transitions curves)\n        alpha = np.arctan(0.5 * (x_out - x_curve_start) / abs(z_top - z_mid))\n        theta_leg_basic = 2 * (np.pi - 2 * alpha)\n        r_leg = 0.5 * (x_out - x_curve_start) / np.sin(theta_leg_basic * 0.5)\n\n        # Transitioning Curves\n        sin_a = np.sin(theta_leg_basic * 0.5)\n        cos_a = np.cos(theta_leg_basic * 0.5)\n\n        # Joint Curve\n        r_j = min(x_curve_start - x_mid, 0.8)\n        theta_j = np.arccos((r_leg * cos_a + r_j) / (r_leg + r_j))\n        deg_theta_j = np.rad2deg(theta_j)\n\n        # Corner Transitioning Curve\n        theta_trans = np.arccos((r_j - r_leg * sin_a) / (r_j - r_leg))\n        deg_theta_trans = np.rad2deg(theta_trans)\n\n        # Main leg curve angle\n        leg_angle = 90 + deg_theta_j\n\n        # Labels\n        if flip:\n            label = \"bottom\"\n            z_top_r_leg = z_top + r_leg\n            z_mid_r_j = z_mid - r_j\n            z_trans_diff = -(r_leg - r_j)\n            z_corner = z_mid + ri\n            corner_angle_s = 90\n            corner_angle_e = 180\n            joint_angle_s = 90 - deg_theta_j\n            joint_angle_e = 90\n            leg_angle_s = tc_angle_e = deg_theta_trans\n            leg_angle_e = leg_angle\n            tc_angle_s = 0\n            ind = slice(None, None, -1)\n        else:\n            label = \"top\"\n            z_top_r_leg = z_top - r_leg\n            z_mid_r_j = z_mid + r_j\n            z_trans_diff = r_leg - r_j\n            z_corner = z_mid - ri\n            corner_angle_s = 180\n            corner_angle_e = 270\n            joint_angle_s = -90\n            joint_angle_e = deg_theta_j - 90\n            leg_angle_s = -leg_angle\n            leg_angle_e = tc_angle_s = -deg_theta_trans\n            tc_angle_e = 0\n            ind = slice(None)\n\n        # Basic main curve centre\n        leg_centre = (x_out - 0.5 * (x_out - x_curve_start), 0, z_top_r_leg)\n\n        # Joint curve centre\n        joint_curve_centre = (\n            leg_centre[0] - (r_leg + r_j) * np.sin(theta_j),\n            0,\n            z_mid_r_j,\n        )\n\n        # Transition curve centre\n        x_trans = leg_centre[0] + (r_leg - r_j) * np.cos(theta_trans)\n        z_trans = leg_centre[2] + z_trans_diff * np.sin(theta_trans)\n\n        # Inner Corner\n        corner_in = make_circle(\n            ri,\n            [x_mid + ri, 0.0, z_corner],\n            start_angle=corner_angle_s,\n            end_angle=corner_angle_e,\n            axis=[0, 1, 0],\n            label=f\"inner_{label}_corner\",\n        )\n\n        # Build straight section of leg\n        p1 = [x_mid + ri, 0, z_mid]\n        p2 = [leg_centre[0] - (r_leg + r_j) * np.sin(theta_j), 0, z_mid]\n        straight_section = make_polygon([p2, p1] if flip else [p1, p2])\n\n        # Dome-inboard section transition curve\n        joint_curve = make_circle(\n            radius=r_j,\n            center=joint_curve_centre,\n            start_angle=joint_angle_s,\n            end_angle=joint_angle_e,\n            axis=axis,\n            label=f\"{label}_limb_joint\",\n        )\n\n        # Main leg curve\n        leg_curve = make_circle(\n            radius=r_leg,\n            center=leg_centre,\n            start_angle=leg_angle_s,\n            end_angle=leg_angle_e,\n            axis=[0, 1, 0],\n            label=f\"{label}_limb_dome\",\n        )\n\n        # Outboard corner transition curve\n        transition_curve = make_circle(\n            radius=r_j,\n            center=[x_trans, 0, z_trans],\n            start_angle=tc_angle_s,\n            end_angle=tc_angle_e,\n            axis=[0, 1, 0],\n            label=f\"{label}_limb_corner\",\n        )\n\n        return BluemiraWire(\n            [corner_in, straight_section, joint_curve, leg_curve, transition_curve][ind],\n            label=f\"{label}_limb\",\n        )\n\n    @staticmethod\n    def _make_flat_leg(\n        x_in: float,\n        x_out: float,\n        z: float,\n        r_i: float,\n        r_o: float,\n        axis: Iterable[float] = (0, 1, 0),\n        flip: bool = False,\n    ) -> BluemiraWire:\n        \"\"\"\n        Makes a flat leg (top/bottom limb) with the option of one end rounded.\n\n        Parameters\n        ----------\n        x_in:\n            Radial position of inner edge of limb [m]\n        x_out:\n            Radial position of outer edge of limb [m]\n        z:\n            Vertical position of limb [m]\n        r_i:\n            Radius of inner corner [m]\n        r_o:\n            Radius of outer corner [m]\n        axis:\n            [x,y,z] vector normal to plane of parameterisation\n        flip:\n            True if limb is lower limb of section, False if upper\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        wires = []\n        label = \"bottom\" if flip else \"top\"\n\n        # Set corner radius centres\n        c_i = [x_in + r_i, 0.0, z + r_i if flip else z - r_i]\n        c_o = [x_out - r_o, 0.0, z + r_o if flip else z - r_o]\n\n        # Inner Corner\n        if r_i != 0.0:\n            wires.append(\n                make_circle(\n                    r_i,\n                    c_i,\n                    start_angle=90 if flip else 180,\n                    end_angle=180 if flip else 270,\n                    axis=axis,\n                    label=f\"inner_{label}_corner\",\n                )\n            )\n        # Straight Section\n        p1 = [x_in + r_i, 0.0, z]\n        p2 = [x_out - r_o, 0.0, z]\n        wires.append(make_polygon([p2, p1] if flip else [p1, p2], label=f\"{label}_limb\"))\n\n        # Outer corner\n        if r_o != 0.0:\n            wires.append(\n                make_circle(\n                    r_o,\n                    c_o,\n                    start_angle=0 if flip else 270,\n                    end_angle=90 if flip else 0,\n                    axis=axis,\n                    label=f\"outer_{label}_corner\",\n                )\n            )\n\n        if flip:\n            wires.reverse()\n\n        return BluemiraWire(wires, label=f\"{label}_limb\")\n\n    @staticmethod\n    def _make_tapered_inner_leg(\n        x_in: float,\n        x_mid: float,\n        z_in: float,\n        z1: float,\n        z2: float,\n        axis: Iterable[float] = (0, 1, 0),\n    ) -> BluemiraWire:\n        \"\"\"\n        Makes a tapered inboard leg using a circle arc taper, symmetric about the\n        midplane with the tapering beginning at a certain height and reaching a\n        maximum taper at the midplane.\n\n        Parameters\n        ----------\n        x_in:\n            Radial position of innermost point of limb [m]\n        x_mid:\n            Radial position of outer edge of limb [m]\n        z_in:\n            Vertical position of start of tapering [m]\n        z1:\n            Vertical position of top of limb [m]\n        z2:\n            Vertical position of bottom of limb [m]\n        axis:\n            [x,y,z] vector normal to plane of parameterisation\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        # Bottom straight section\n        p1 = [x_mid, 0, -z_in]\n        p2 = [x_mid, 0, z2]\n        bot_straight = make_polygon([p2, p1], label=\"inner_limb_mid_down\")\n\n        # Curved taper radius\n        x_t = x_mid - x_in\n        alpha = np.arctan(z_in / (x_t))\n        theta_t = np.pi - 2 * alpha\n        r_taper = z_in / np.sin(theta_t)\n\n        # Curved taper angle\n        angle = np.rad2deg(np.arcsin(z_in / r_taper))\n        ct_angle = make_circle(\n            radius=r_taper,\n            center=(x_in + r_taper, 0, 0),\n            start_angle=180 - angle,\n            end_angle=180 + angle,\n            axis=axis,\n            label=\"inner_limb\",\n        )\n\n        # Top straight section\n        p3 = [x_mid, 0, z_in]\n        p4 = [x_mid, 0, z1]\n        top_straight = make_polygon([p3, p4], label=\"inner_limb_mid_up\")\n\n        return BluemiraWire([bot_straight, ct_angle, top_straight], label=\"inner_limb\")\n\n    def _connect_to_outer_limb(self, top, bottom, top_curve=False, bot_curve=False):\n        return self._outer_limb(\n            top.discretize(100, byedges=True)[:, -1] if top_curve else top,\n            bottom.discretize(100, byedges=True)[:, 0] if bot_curve else bottom,\n        )\n\n    def _connect_straight_to_inner_limb(self, top, bottom):\n        return self._inner_limb(top, bottom)\n\n    @staticmethod\n    def _inner_limb(p1, p2):\n        return make_polygon([p1, p2], label=\"inner_limb\")\n\n    @staticmethod\n    def _outer_limb(p1, p2):\n        return make_polygon([p1, p2], label=\"outer_limb\")",
  "class PFrameSection(Enum):\n    \"\"\"\n    Picture Frame sections\n    \"\"\"\n\n    CURVED = partial(PictureFrameTools._make_domed_leg)\n    FLAT = partial(PictureFrameTools._make_flat_leg)\n    TAPERED_INNER = partial(PictureFrameTools._make_tapered_inner_leg)\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"\n        Call linked function on access\n        \"\"\"\n        return self.value(*args, **kwargs)",
  "class PictureFrameOptVariables(OptVariablesFrame):\n    x1: OptVariable = ov(\n        \"x1\",\n        0.4,\n        lower_bound=0.3,\n        upper_bound=0.5,\n        description=\"Inner limb radius\",\n    )\n    x2: OptVariable = ov(\n        \"x2\",\n        9.5,\n        lower_bound=9.4,\n        upper_bound=9.8,\n        description=\"Outer limb radius\",\n    )\n    z1: OptVariable = ov(\n        \"z1\",\n        9.5,\n        lower_bound=8,\n        upper_bound=10.5,\n        description=\"Upper limb height\",\n    )\n    z2: OptVariable = ov(\n        \"z2\",\n        -9.5,\n        lower_bound=-10.5,\n        upper_bound=-8,\n        description=\"Lower limb height\",\n    )\n    ri: OptVariable = ov(\n        \"ri\",\n        0.1,\n        lower_bound=0,\n        upper_bound=2,\n        description=\"Inboard corner radius\",\n    )\n    ro: OptVariable = ov(\n        \"ro\",\n        2,\n        lower_bound=1,\n        upper_bound=5,\n        description=\"Outboard corner radius\",\n    )\n    x3: OptVariable = ov(\n        \"x3\",\n        2.5,\n        lower_bound=2.4,\n        upper_bound=2.6,\n        description=\"Curve start radius\",\n    )\n    z1_peak: OptVariable = ov(\n        \"z1_peak\",\n        11,\n        lower_bound=6,\n        upper_bound=12,\n        description=\"Upper limb curve height\",\n    )\n    z2_peak: OptVariable = ov(\n        \"z2_peak\",\n        -11,\n        lower_bound=-12,\n        upper_bound=-6,\n        description=\"Lower limb curve height\",\n    )\n    x4: OptVariable = ov(\n        \"x4\",\n        1.1,\n        lower_bound=1,\n        upper_bound=1.3,\n        description=\"Middle limb radius\",\n    )\n    z3: OptVariable = ov(\n        \"z3\",\n        6.5,\n        lower_bound=6,\n        upper_bound=8,\n        description=\"Taper angle stop height\",\n    )\n\n    def configure(\n        self,\n        upper: Union[str, PFrameSection],\n        lower: Union[str, PFrameSection],\n        inner: Optional[Union[str, PFrameSection]],\n    ):\n        \"\"\"Fix variables based on the upper, lower and inner limbs.\"\"\"\n        if upper is PFrameSection.CURVED and lower is PFrameSection.CURVED:\n            self.ro.fixed = True\n        elif upper is PFrameSection.FLAT and lower is PFrameSection.FLAT:\n            self.z1_peak.fixed = True\n            self.z2_peak.fixed = True\n            self.x3.fixed = True\n        if inner is not PFrameSection.TAPERED_INNER:\n            self.x4.fixed = True\n            self.z3.fixed = True",
  "class PictureFrame(\n    GeometryParameterisation[PictureFrameOptVariables], PictureFrameTools\n):\n    \"\"\"\n    Picture-frame geometry parameterisation.\n\n    Parameters\n    ----------\n    var_dict:\n        Dictionary with which to update the default values of the parameterisation.\n\n    Notes\n    -----\n    .. plot::\n\n        from bluemira.geometry.parameterisations import PictureFrame\n        PictureFrame(\n                     inner=\"TAPERED_INNER\",\n                     upper=\"FLAT\",\n                     lower=\"CURVED\",\n                     var_dict={'ri': {'value': 1}}\n        ).plot(labels=True)\n\n    The base dictionary keys in var_dict are:\n\n    x1: float\n        Radial position of inner limb [m]\n    x2: float\n        Radial position of outer limb [m]\n    z1: float\n        Vertical position of top limb [m]\n    z2: float\n        Vertical position of top limb [m]\n    ri: float\n        Radius of inner corners [m]\n    ro: float\n        Radius of outer corners [m]\n\n    For curved pictures frames 'ro' is ignored on curved sections but there\n    are additional keys:\n\n    z1_peak: float\n        Vertical position of top of limb dome [m]\n    z2_peak: float\n        Vertical position of top of limb dome [m]\n    x3: float\n        The radius to start the dome curve [m]\n\n    For tapered inner leg the additional keys are:\n\n    x4: float\n        Radial position of outer limb [m]\n    z3: float\n        Vertical position of top of tapered section [m]\n\n    \"\"\"\n\n    __slots__ = tuple(\n        [\n            f\"{leg}{var}\"\n            for leg in [\"inner\", \"upper\", \"lower\", \"outer\"]\n            for var in [\"\", \"_vars\"]\n        ]\n    )\n\n    def __init__(\n        self,\n        var_dict: Optional[VarDictT] = None,\n        *,\n        upper: Union[str, PFrameSection] = PFrameSection.FLAT,\n        lower: Union[str, PFrameSection] = PFrameSection.FLAT,\n        inner: Optional[Union[str, PFrameSection]] = None,\n    ):\n        self.upper = upper if isinstance(upper, PFrameSection) else PFrameSection[upper]\n        self.lower = lower if isinstance(lower, PFrameSection) else PFrameSection[lower]\n\n        if isinstance(inner, str):\n            inner = PFrameSection[inner]\n        self.inner = inner\n\n        variables = PictureFrameOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        variables.configure(self.upper, self.lower, self.inner)\n        super().__init__(variables)\n\n    def __deepcopy__(self, memo) -> PictureFrame:\n        \"\"\"Picture Frame deepcopy\"\"\"\n        cls = type(self)\n        result = cls.__new__(cls)\n        memo[id(self)] = result\n        for k in (*self.__slots__, *super().__slots__):\n            with suppress(AttributeError):\n                v = getattr(self, k)\n                setattr(\n                    result,\n                    k,\n                    v if isinstance(v, PFrameSection) else copy.deepcopy(v, memo),\n                )\n        return result\n\n    def create_shape(self, label: str = \"\") -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the picture frame.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n\n        Returns\n        -------\n        CAD Wire of the Picture Frame geometry\n        \"\"\"\n        inb_leg = self._make_inb_leg()\n        top_leg = self._make_upper_lower_leg(make_upper_section=True, flip=False)\n        bot_leg = self._make_upper_lower_leg(make_upper_section=False, flip=True)\n        out_leg = self._make_out_leg(top_leg, bot_leg)\n\n        return BluemiraWire([inb_leg, top_leg, out_leg, bot_leg], label=label)\n\n    def _make_inb_leg(self):\n        v = self.variables\n        if isinstance(self.inner, PFrameSection):\n            if self.inner is not PFrameSection.TAPERED_INNER:\n                raise ValueError(f\"The inner leg cannot be {self.inner}\")\n            return self.inner(\n                v.x1.value,\n                v.x4.value,\n                v.z3.value,\n                v.z1 - v.ri,\n                v.z2 + v.ri,\n            )\n        elif self.inner is None:\n            return self._connect_straight_to_inner_limb(\n                [v.x1.value, 0, v.z2 + v.ri],\n                [v.x1.value, 0, v.z1 - v.ri],\n            )\n\n    def _make_upper_lower_leg(self, make_upper_section: bool, flip: bool):\n        v = self.variables\n        section_func: PFrameSection = self.upper if make_upper_section else self.lower\n        if section_func == PFrameSection.CURVED:\n            return section_func(\n                v.x2.value,\n                v.x3.value,\n                v.x4.value if self.inner is PFrameSection.TAPERED_INNER else v.x1.value,\n                v.z1_peak.value if make_upper_section else v.z2_peak.value,\n                v.z1.value if make_upper_section else v.z2.value,\n                v.ri.value,\n                flip=flip,\n            )\n        elif section_func == PFrameSection.FLAT:\n            return section_func(\n                v.x4.value if self.inner is PFrameSection.TAPERED_INNER else v.x1.value,\n                v.x2.value,\n                v.z1.value if make_upper_section else v.z2.value,\n                v.ri.value,\n                v.ro.value,\n                flip=flip,\n            )\n        else:\n            raise ValueError(f\"The leg cannot be {section_func}\")\n\n    def _make_out_leg(self, top_leg, bot_leg):\n        v = self.variables\n        return self._connect_to_outer_limb(\n            top_leg\n            if self.upper is PFrameSection.CURVED\n            else [v.x2.value, 0, v.z1 - v.ro],\n            bot_leg\n            if self.lower is PFrameSection.CURVED\n            else [v.x2.value, 0, v.z2 + v.ro],\n            self.upper is PFrameSection.CURVED,\n            self.lower is PFrameSection.CURVED,\n        )\n\n    def _label_function(self, ax, shape):\n        super()._label_function(ax, shape)\n        ro = self.variables.ro\n        ri = self.variables.ri\n        z = self.variables.z1\n        x_in = (\n            self.variables.x4\n            if self.inner is PFrameSection.TAPERED_INNER\n            else self.variables.x1\n        )\n\n        x_out = self.variables.x2\n        _r1 = ri * (1 - np.sqrt(0.5))\n        _r2 = ro * (1 - np.sqrt(0.5))\n        self._annotator(\n            ax,\n            \"ri\",\n            (x_in + ri, z - ri),\n            (x_in + _r1, z - _r1),\n            ((x_in + ri) * 0.8, z - 6 * _r1),\n        )\n        self._annotator(\n            ax,\n            \"ro\",\n            (x_out - ro, z - ro),\n            (x_out - _r2, z - _r2),\n            ((x_out + ro) * 0.6, z - 3 * _r2),\n        )\n\n        xmin, xmax = ax.get_xlim()\n        ax.set_xlim(xmin, xmax * 1.1)",
  "def __init__(self, variables: OptVariablesFrameT):\n        \"\"\"\n        Parameters\n        ----------\n        variables:\n            Set of optimisation variables of the GeometryParameterisation\n        \"\"\"\n        self.name = self.__class__.__name__\n        self._variables = variables",
  "def n_ineq_constraints(self) -> int:\n        \"\"\"Number of inequality constraints in the GeometryParameterisation\"\"\"\n        return 0",
  "def variables(self) -> OptVariablesFrameT:\n        \"\"\"The variables of the GeometryParameterisation\"\"\"\n        return self._variables",
  "def adjust_variable(\n        self,\n        name: str,\n        value: Optional[float] = None,\n        lower_bound: Optional[float] = None,\n        upper_bound: Optional[float] = None,\n    ):\n        \"\"\"\n        Adjust a variable in the GeometryParameterisation.\n\n        Parameters\n        ----------\n        name:\n            Name of the variable to adjust\n        value:\n            Value of the variable to set\n        lower_bound:\n            Value of the lower bound to set\n        upper_bound:\n            Value of the upper to set\n        \"\"\"\n        self.variables.adjust_variable(name, value, lower_bound, upper_bound)",
  "def fix_variable(self, name: str, value: Optional[float] = None):\n        \"\"\"\n        Fix a variable in the GeometryParameterisation, removing it from optimisation\n        but preserving a constant value.\n\n        Parameters\n        ----------\n        name:\n            Name of the variable to fix\n        value:\n            Value at which to fix the variable (will default to present value)\n        \"\"\"\n        self.variables.fix_variable(name, value)",
  "def shape_ineq_constraints(\n        self, constraint: np.ndarray, x: np.ndarray, grad: np.ndarray\n    ):\n        \"\"\"\n        Inequality constraint function for the variable vector of the geometry\n        parameterisation. This is used when internal consistency between different\n        un-fixed variables is required.\n\n        Parameters\n        ----------\n        constraint:\n            Constraint vector (assign in place)\n        x:\n            Normalised vector of free variables\n        grad:\n            Gradient matrix of the constraint (assign in place)\n\n        Notes\n        -----\n        Deprecated please use `f_ineq_constraint` and `df_ineq_constraint`\n        \"\"\"\n        warnings.warn(\n            \"Use of 'shape_ineq_constraints' method is \"\n            \"deprecated and it will be removed in version 2.0.0.\\n\"\n            \"See \"\n            \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n            \"optimisation.html \"\n            \"for documentation of the new optimisation module.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        self.f_ineq_constraint()",
  "def f_ineq_constraint(self):\n        \"\"\"\n        Inequality constraint function for the variable vector of the geometry\n        parameterisation. This is used when internal consistency between different\n        un-fixed variables is required.\n\n        \"\"\"\n        if self.n_ineq_constraints < 1:\n            raise GeometryParameterisationError(\n                f\"Cannot apply shape_ineq_constraints to {type(self).__name__}: it\"\n                \"has no inequality constraints.\"\n            )",
  "def tolerance(self) -> npt.NDArray:\n        \"\"\"\n        Optimisation tolerance for the geometry parameterisation.\n        \"\"\"\n        return np.array([np.finfo(float).eps])",
  "def get_x_norm_index(self, name: str) -> int:\n        \"\"\"\n        Get the index of a variable name in the modified-length x_norm vector\n\n        Parameters\n        ----------\n        variables:\n            Bounded optimisation variables\n        name:\n            Variable name for which to get the index\n\n        Returns\n        -------\n        Index of the variable name in the modified-length x_norm vector\n        \"\"\"\n        fixed_idx = self.variables._fixed_variable_indices\n        idx_actual = self.variables.names.index(name)\n\n        if not fixed_idx:\n            return idx_actual\n\n        count = 0\n        for idx_fx in fixed_idx:\n            if idx_actual > idx_fx:\n                count += 1\n        return idx_actual - count",
  "def process_x_norm_fixed(self, x_norm: np.ndarray) -> List[float]:\n        \"\"\"\n        Utility for processing a set of free, normalised variables, and folding the fixed\n        un-normalised variables back into a single list of all actual values.\n\n        Parameters\n        ----------\n        variables:\n            Bounded optimisation variables\n        x_norm:\n            Normalised vector of variable values\n\n        Returns\n        -------\n        List of ordered actual (un-normalised) values\n        \"\"\"\n        fixed_idx = self.variables._fixed_variable_indices\n\n        # Note that we are dealing with normalised values when coming from the optimiser\n        x_actual = list(self.variables.get_values_from_norm(x_norm))\n\n        if fixed_idx:\n            x_fixed = self.variables.values\n            for i in fixed_idx:\n                x_actual.insert(i, x_fixed[i])\n        return x_actual",
  "def create_shape(self, label: str = \"\", **kwargs: Dict[str, Any]) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the geometry.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        pass",
  "def to_json(self, file: str):\n        \"\"\"\n        Write the json representation of the GeometryParameterisation to a file.\n\n        Parameters\n        ----------\n        file:\n            The path to the file.\n        \"\"\"\n        self.variables.to_json(file)",
  "def from_json(cls, file: Union[str, TextIO]) -> GeometryParameterisation:\n        \"\"\"\n        Create the GeometryParameterisation from a json file.\n\n        Parameters\n        ----------\n        file:\n            The path to the file, or an open file handle that supports reading.\n        \"\"\"\n        if isinstance(file, str):\n            with open(file, \"r\") as fh:\n                return cls.from_json(fh)\n\n        var_dict = json.load(file)\n        return cls(var_dict)",
  "def _annotator(self, ax, key: str, xy1: Tuple, xy2: Tuple, xy3: Tuple):\n        \"\"\"\n        Create annotation arrow with label\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis instance\n        key:\n            label of annotation\n        xy1:\n            Tuple for first arrow point\n        xy2:\n            Tuple for second arrow point\n        xy3:\n            Tuple for arrow label location\n\n        \"\"\"\n        ax.annotate(\n            \"\",\n            xy=xy1,\n            xycoords=\"data\",\n            xytext=xy2,\n            textcoords=\"data\",\n            arrowprops={\n                \"arrowstyle\": \"<|-|>\",\n                \"edgecolor\": \"k\",\n                \"facecolor\": \"k\",\n                \"shrinkA\": 0,\n                \"shrinkB\": 0,\n            },\n        )\n        ax.annotate(\n            r\"$\\it{\" f\"{str_to_latex(key).strip('$')}\" \"}$\",\n            xy=xy3,\n            xycoords=\"data\",\n            xytext=(0, 5),\n            textcoords=\"offset points\",\n        )",
  "def _label_function(self, ax, shape: BluemiraWire):\n        \"\"\"\n        Adds labels to parameterisation plots\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis instance\n        shape:\n            parameterisation wire\n\n        \"\"\"\n        offset_ar_x = 0\n        offset_ar_z = 0\n        for v in self.variables:\n            if v.name.startswith(\"x\"):\n                self._annotator(\n                    ax,\n                    v.name,\n                    (0, offset_ar_x),\n                    (v.value, offset_ar_x),\n                    (v.value * 0.4, offset_ar_x),\n                )\n                ax.plot([0, 0], [0, offset_ar_x], color=\"k\")\n                ax.plot([v.value, v.value], [0, offset_ar_x], color=\"k\")\n                offset_ar_x += 2\n            elif v.name.startswith(\"z\") or v.name[1] == \"z\":\n                xcor = shape.center_of_mass[0] + offset_ar_z\n                self._annotator(\n                    ax,\n                    v.name,\n                    (xcor, 0),\n                    (xcor, v.value),\n                    (xcor, v.value * 0.4),\n                )\n                ax.plot([shape.center_of_mass[0], xcor], [0, 0], color=\"k\")\n                ax.plot(\n                    [shape.center_of_mass[0], xcor],\n                    [v.value, v.value],\n                    color=\"k\",\n                )\n                offset_ar_z += 1.5\n        return offset_ar_x, offset_ar_z",
  "def plot(self, ax=None, labels=False, **kwargs):\n        \"\"\"\n        Plot the geometry parameterisation\n\n        Parameters\n        ----------\n        ax: Optional[Axes]\n            Matplotlib axes object\n        labels: bool\n            Label variables on figure\n        kwargs: Dict\n            Passed to matplotlib Axes.plot function\n        \"\"\"\n        if ax is None:\n            _, ax = plt.subplots()\n        shape = self.create_shape()\n\n        if labels:\n            self._label_function(ax, shape)\n        ndiscr = kwargs.pop(\"ndiscr\") if \"ndiscr\" in kwargs else 200\n        plot_2d(shape, ax=ax, show=False, ndiscr=ndiscr, **kwargs)\n        return ax",
  "def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = PrincetonDOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)",
  "def create_shape(self, label: str = \"\", n_points: int = 2000) -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the Princeton D.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n        n_points:\n            The number of points to use when calculating the geometry of the Princeton\n            D.\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        x, z = self._princeton_d(\n            self.variables.x1.value,\n            self.variables.x2.value,\n            self.variables.dz.value,\n            n_points,\n        )\n        xyz = np.array([x, np.zeros(len(x)), z])\n\n        outer_arc = interpolate_bspline(\n            xyz.T,\n            label=\"outer_arc\",\n            # start_tangent=[0, 0, 1],\n            # end_tangent=[0, 0, -1],\n        )\n        # TODO: Enforce tangency of this bspline... causing issues with offsetting\n        # TODO: The real irony is that tangencies don't solve the problem..\n        straight_segment = wire_closure(outer_arc, label=\"straight_segment\")\n        return BluemiraWire([outer_arc, straight_segment], label=label)",
  "def shape_ineq_constraints(\n        self, constraint: np.ndarray, x_norm: np.ndarray, grad: np.ndarray\n    ) -> np.ndarray:\n        \"\"\"\n        Inequality constraint function for the variable vector of the geometry\n        parameterisation. This is used when internal consistency between different\n        un-fixed variables is required.\n\n        Parameters\n        ----------\n        constraint:\n            Constraint vector (assign in place)\n        x:\n            Normalised vector of free variables\n        grad:\n            Gradient matrix of the constraint (assign in place)\n\n        Notes\n        -----\n        Deprecated please use `f_ineq_constraint` and `df_ineq_constraint`\n        \"\"\"\n        warnings.warn(\n            \"Use of 'shape_ineq_constraints' method is \"\n            \"deprecated and it will be removed in version 2.0.0.\\n\"\n            \"See \"\n            \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n            \"optimisation.html \"\n            \"for documentation of the new optimisation module.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        constraint[:] = self.f_ineq_constraint()\n        grad[:] = self.df_ineq_constraint()\n\n        return constraint",
  "def f_ineq_constraint(self) -> np.ndarray:\n        \"\"\"Inequality constraint for PrincetonD.\"\"\"\n        free_vars = self.variables.get_normalised_values()\n        x1, x2, _ = self.process_x_norm_fixed(free_vars)\n        return np.array([x1 - x2])",
  "def df_ineq_constraint(self) -> np.ndarray:\n        \"\"\"Inequality constraint gradient for PrincetonD.\"\"\"\n        opt_vars = self.variables\n        free_vars = opt_vars.get_normalised_values()\n        grad = np.zeros((1, len(free_vars)))\n        if not self.variables.x1.fixed:\n            grad[0][self.get_x_norm_index(\"x1\")] = 1\n        if not self.variables.x2.fixed:\n            grad[0][self.get_x_norm_index(\"x2\")] = -1\n        return grad",
  "def _princeton_d(\n        x1: float, x2: float, dz: float, npoints: int = 2000\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Princeton D shape calculation (e.g. Gralnick and Tenney, 1976, or\n        File, Mills, and Sheffield, 1971)\n\n        Parameters\n        ----------\n        x1:\n            The inboard centreline radius of the Princeton D\n        x2:\n            The outboard centreline radius of the Princeton D\n        dz:\n            The vertical offset (from z=0)\n        npoints: int (default = 2000)\n            The size of the x, z coordinate sets to return\n\n        Returns\n        -------\n        x:\n            The x coordinates of the Princeton D shape\n        z:\n            The z coordinates of the Princeton D shape\n\n        Notes\n        -----\n        Returns an open set of coordinates\n\n        :math:`x = X_{0}e^{ksin(\\\\theta)}`\n        :math:`z = X_{0}k\\\\Bigg[\\\\theta I_{1}(k)+\\\\sum_{n=1}^{\\\\infty}{\\\\frac{i}{n}\n        e^{\\\\frac{in\\\\pi}{2}}\\\\bigg(e^{-in\\\\theta}-1\\\\bigg)\\\\bigg(1+e^{in(\\\\theta+\\\\pi)}\n        \\\\bigg)\\\\frac{I_{n-1}(k)+I_{n+1}(k)}{2}}\\\\Bigg]`\n\n        Where:\n            :math:`X_{0} = \\\\sqrt{x_{1}x_{2}}`\n            :math:`k = \\\\frac{ln(x_{2}/x_{1})}{2}`\n\n        Where:\n            :math:`I_{n}` is the n-th order modified Bessel function\n            :math:`x_{1}` is the inner radial position of the shape\n            :math:`x_{2}` is the outer radial position of the shape\n        \"\"\"  # noqa :W505\n        if x2 <= x1:\n            raise GeometryParameterisationError(\n                \"Princeton D parameterisation requires an x2 value \"\n                f\"greater than x1: {x1} >= {x2}\"\n            )\n\n        xo = np.sqrt(x1 * x2)\n        k = 0.5 * np.log(x2 / x1)\n        theta = np.linspace(-0.5 * np.pi, 1.5 * np.pi, npoints)\n        s = np.zeros(npoints, dtype=\"complex128\")\n        n = 0\n        while True:  # sum convergent series\n            n += 1\n\n            ds = 1j / n * (np.exp(-1j * n * theta) - 1)\n            ds *= 1 + np.exp(1j * n * (theta + np.pi))\n            ds *= np.exp(1j * n * np.pi / 2)\n            ds *= (bessel(n - 1, k) + bessel(n + 1, k)) / 2\n            s += ds\n            if np.max(abs(ds)) < 1e-14:\n                break\n\n        z = abs(xo * k * (bessel(1, k) * theta + s))\n        x = xo * np.exp(k * np.sin(theta))\n        z -= np.mean(z)\n        z += dz  # vertical shift\n        return x, z",
  "def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = TripleArcOptVaribles()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)",
  "def shape_ineq_constraints(\n        self, constraint: np.ndarray, x_norm: np.ndarray, grad: np.ndarray\n    ) -> np.ndarray:\n        \"\"\"\n        Inequality constraint function for the variable vector of the geometry\n        parameterisation. This is used when internal consistency between different\n        un-fixed variables is required.\n\n        Parameters\n        ----------\n        constraint:\n            Constraint vector (assign in place)\n        x:\n            Normalised vector of free variables\n        grad:\n            Gradient matrix of the constraint (assign in place)\n\n        Notes\n        -----\n        Deprecated please use `f_ineq_constraint` and `df_ineq_constraint`\n        \"\"\"\n        warnings.warn(\n            \"Use of 'shape_ineq_constraints' method is \"\n            \"deprecated and it will be removed in version 2.0.0.\\n\"\n            \"See \"\n            \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n            \"optimisation.html \"\n            \"for documentation of the new optimisation module.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        constraint[:] = self.f_ineq_constraint()\n        grad[:] = self.df_ineq_constraint()\n\n        return constraint",
  "def f_ineq_constraint(self) -> np.ndarray:\n        \"\"\"\n        Inequality constraint for TripleArc.\n\n        Constrain such that a1 + a2 is less than or equal to 180 degrees.\n        \"\"\"\n        norm_vals = self.variables.get_normalised_values()\n        x_actual = self.process_x_norm_fixed(norm_vals)\n        _, _, _, _, _, a1, a2 = x_actual\n        return np.array([a1 + a2 - 180])",
  "def df_ineq_constraint(self) -> np.ndarray:\n        \"\"\"Inequality constraint gradient for TripleArc.\"\"\"\n        free_vars = self.variables.get_normalised_values()\n        g = np.zeros((1, len(free_vars)))\n        if not self.variables.a1.fixed:\n            idx_a1 = self.get_x_norm_index(\"a1\")\n            g[0][idx_a1] = 1\n        if not self.variables.a2.fixed:\n            idx_a2 = self.get_x_norm_index(\"a2\")\n            g[0][idx_a2] = 1\n        return g",
  "def create_shape(self, label: str = \"\") -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the triple arc.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        x1, dz, sl, f1, f2, a1, a2 = self.variables.values\n        a1, a2 = np.deg2rad(a1), np.deg2rad(a2)\n\n        z1 = 0.5 * sl\n        # Upper half\n        p1 = [x1, 0, z1]\n        atot = a1 + a2\n        a15 = 0.5 * a1\n        p15 = [x1 + f1 * (1 - np.cos(a15)), 0, z1 + f1 * np.sin(a15)]\n        p2 = [x1 + f1 * (1 - np.cos(a1)), 0, z1 + f1 * np.sin(a1)]\n\n        a25 = a1 + 0.5 * a2\n        p25 = [\n            p2[0] + f2 * (np.cos(a1) - np.cos(a25)),\n            0,\n            p2[2] + f2 * (np.sin(a25) - np.sin(a1)),\n        ]\n        p3 = [\n            p2[0] + f2 * (np.cos(a1) - np.cos(atot)),\n            0,\n            p2[2] + f2 * (np.sin(atot) - np.sin(a1)),\n        ]\n        rl = p3[2] / np.sin(np.pi - atot)\n\n        a35 = 0.5 * atot\n        p35 = [\n            p3[0] + rl * (np.cos(a35) - np.cos(np.pi - atot)),\n            0,\n            p3[2] - rl * (np.sin(atot) - np.sin(a35)),\n        ]\n        p4 = [\n            p3[0] + rl * (1 - np.cos(np.pi - atot)),\n            0,\n            p3[2] - rl * np.sin(atot),\n        ]\n\n        # Symmetric lower half\n        p45 = [p35[0], 0, -p35[2]]\n        p5 = [p3[0], 0, -p3[2]]\n        p55 = [p25[0], 0, -p25[2]]\n        p6 = [p2[0], 0, -p2[2]]\n        p65 = [p15[0], 0, -p15[2]]\n        p7 = [p1[0], 0, -p1[2]]\n\n        wires = [\n            make_circle_arc_3P(p1, p15, p2, label=\"upper_inner_arc\"),\n            make_circle_arc_3P(p2, p25, p3, label=\"upper_mid_arc\"),\n            make_circle_arc_3P(p3, p35, p4, label=\"upper_outer_arc\"),\n            make_circle_arc_3P(p4, p45, p5, label=\"lower_outer_arc\"),\n            make_circle_arc_3P(p5, p55, p6, label=\"lower_mid_arc\"),\n            make_circle_arc_3P(p6, p65, p7, label=\"lower_inner_arc\"),\n        ]\n\n        if sl != 0.0:\n            straight_segment = wire_closure(\n                BluemiraWire(wires), label=\"straight_segment\"\n            )\n            wires.append(straight_segment)\n\n        wire = BluemiraWire(wires, label=label)\n        wire.translate((0, 0, dz))\n        return wire",
  "def _label_function(self, ax, shape: BluemiraWire):\n        \"\"\"\n        Adds labels to parameterisation plots\n\n        TODO add labels for sl f1 f2 a1 a2\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis instance\n        shape:\n            parameterisation wire\n\n        \"\"\"\n        offset_x, offset_z = super()._label_function(ax, shape)",
  "def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = SextupleArcOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)",
  "def shape_ineq_constraints(\n        self, constraint: np.ndarray, x_norm: np.ndarray, grad: np.ndarray\n    ) -> np.ndarray:\n        \"\"\"\n        Inequality constraint function for the variable vector of the geometry\n        parameterisation. This is used when internal consistency between different\n        un-fixed variables is required.\n\n        Parameters\n        ----------\n        constraint:\n            Constraint vector (assign in place)\n        x:\n            Normalised vector of free variables\n        grad:\n            Gradient matrix of the constraint (assign in place)\n\n        Notes\n        -----\n        Deprecated please use `f_ineq_constraint` and `df_ineq_constraint`\n        \"\"\"\n        warnings.warn(\n            \"Use of 'shape_ineq_constraints' method is \"\n            \"deprecated and it will be removed in version 2.0.0.\\n\"\n            \"See \"\n            \"https://bluemira.readthedocs.io/en/latest/optimisation/\"\n            \"optimisation.html \"\n            \"for documentation of the new optimisation module.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n        constraint[:] = self.f_ineq_constraint()\n        grad[:] = self.df_ineq_constraint()\n\n        return constraint",
  "def f_ineq_constraint(self) -> np.ndarray:\n        \"\"\"\n        Inequality constraint for TripleArc.\n\n        Constrain such that sum of the 5 angles is less than or equal to 360\n        degrees.\n        \"\"\"\n        x_norm = self.variables.get_normalised_values()\n        x_actual = self.process_x_norm_fixed(x_norm)\n        _, _, _, _, _, _, _, a1, a2, a3, a4, a5 = x_actual\n        return np.array([a1 + a2 + a3 + a4 + a5 - 360])",
  "def df_ineq_constraint(self) -> np.ndarray:\n        \"\"\"Inequality constraint gradient for TripleArc.\"\"\"\n        x_norm = self.variables.get_normalised_values()\n        gradient = np.zeros((1, len(x_norm)))\n        for var in [\"a1\", \"a2\", \"a3\", \"a4\", \"a5\"]:\n            if not self.variables[var].fixed:\n                var_idx = self.get_x_norm_index(var)\n                gradient[0][var_idx] = 1\n        return gradient",
  "def _project_centroid(xc, zc, xi, zi, ri):\n        vec = np.array([xi - xc, zi - zc])\n        vec /= np.linalg.norm(vec)\n        xc = xi - vec[0] * ri\n        zc = zi - vec[1] * ri\n        return xc, zc, vec",
  "def create_shape(self, label: str = \"\") -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the sextuple arc.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        variables = self.variables.values\n        x1, z1 = variables[:2]\n        r_values = variables[2:7]\n        a_values = np.deg2rad(variables[7:])\n\n        wires = []\n        a_start = 0\n        xi, zi = x1, z1\n        xc = x1 + r_values[0]\n        zc = z1\n        for i, (ai, ri) in enumerate(zip(a_values, r_values)):\n            if i > 0:\n                xc, zc, _ = self._project_centroid(xc, zc, xi, zi, ri)\n\n            a = np.pi - a_start - ai\n            xi = xc + ri * np.cos(a)\n            zi = zc + ri * np.sin(a)\n\n            start_angle = np.rad2deg(np.pi - a_start)\n            end_angle = np.rad2deg(a)\n\n            arc = make_circle(\n                ri,\n                center=[xc, 0, zc],\n                start_angle=end_angle,\n                end_angle=start_angle,\n                axis=[0, -1, 0],\n                label=f\"arc_{i+1}\",\n            )\n\n            wires.append(arc)\n\n            a_start += ai\n\n        xc, zc, vec = self._project_centroid(xc, zc, xi, zi, ri)\n\n        # Retrieve last arc (could be bad...)\n        r6 = (xi - x1) / (1 + vec[0])\n        xc6 = xi - r6 * vec[0]\n        z7 = zc6 = zi - r6 * vec[1]\n\n        closing_arc = make_circle(\n            r6,\n            center=[xc6, 0, zc6],\n            start_angle=180,\n            end_angle=np.rad2deg(np.pi - a_start),\n            axis=[0, -1, 0],\n            label=\"arc_6\",\n        )\n\n        wires.append(closing_arc)\n\n        if not np.isclose(z1, z7):\n            straight_segment = wire_closure(\n                BluemiraWire(wires), label=\"straight_segment\"\n            )\n            wires.append(straight_segment)\n\n        return BluemiraWire(wires, label=label)",
  "def _label_function(self, ax, shape: BluemiraWire):\n        \"\"\"\n        Adds labels to parameterisation plots\n\n        TODO add labels for r1-5 a1-5\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis instance\n        shape:\n            parameterisation wire\n\n        \"\"\"\n        offset_x, offset_z = super()._label_function(ax, shape)",
  "def __init__(self, var_dict: Optional[VarDictT] = None):\n        variables = PolySplineOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        super().__init__(variables)",
  "def create_shape(self, label: str = \"\") -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the poly spline.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        variables = self.variables.values\n        (\n            x1,\n            x2,\n            z2,\n            height,\n            top,\n            upper,\n            dz,\n            flat,\n            tilt,\n            bottom,\n            lower,\n        ) = variables[:11]\n        l_start = variables[11:15]\n        l_end = variables[15:]\n\n        tilt = np.deg2rad(tilt)\n        height = 0.5 * height\n        ds_z = flat * height * np.cos(tilt)\n        ds_x = flat * height * np.sin(tilt)\n\n        # Vertices\n        x = [x1, x1 + top * (x2 - x1), x2 + ds_x, x2 - ds_x, x1 + bottom * (x2 - x1), x1]\n        z = [\n            upper * height + dz,\n            height + dz,\n            z2 * height + ds_z + dz,\n            z2 * height - ds_z + dz,\n            -height + dz,\n            -lower * height + dz,\n        ]\n        theta = [\n            0.5 * np.pi,\n            0,\n            -0.5 * np.pi - tilt,\n            -0.5 * np.pi - tilt,\n            -np.pi,\n            0.5 * np.pi,\n        ]\n\n        wires = []\n        for i, j in zip([0, 1, 2, 3], [0, 1, 3, 4]):\n            k = j + 1\n            p0 = [x[j], 0, z[j]]\n            p3 = [x[k], 0, z[k]]\n            p1, p2 = self._make_control_points(\n                p0, p3, theta[j], theta[k] - np.pi, l_start[i], l_end[i]\n            )\n            wires.append(make_bezier([p0, p1, p2, p3], label=f\"segment_{i}\"))\n\n        if flat != 0:\n            outer_straight = make_polygon(\n                [[x[2], 0, z[2]], [x[3], 0, z[3]]], label=\"outer_straight\"\n            )\n            wires.insert(2, outer_straight)\n\n        straight_segment = wire_closure(BluemiraWire(wires), label=\"inner_straight\")\n        wires.append(straight_segment)\n\n        return BluemiraWire(wires, label=label)",
  "def _make_control_points(p0, p3, theta0, theta3, l_start, l_end):\n        \"\"\"\n        Make 2 B\u00e9zier spline control points between two vertices.\n        \"\"\"\n        dl = np.sqrt(np.sum((np.array(p3) - np.array(p0)) ** 2))\n\n        p1, p2 = np.zeros(3), np.zeros(3)\n        for point, control_point, angle, tension in zip(\n            [p0, p3], [p1, p2], [theta0, theta3], [l_start, l_end]\n        ):\n            d_tension = 0.5 * dl * tension\n            control_point[0] = point[0] + d_tension * np.cos(angle)\n            control_point[2] = point[2] + d_tension * np.sin(angle)\n\n        return p1, p2",
  "def _label_function(self, ax, shape: BluemiraWire):\n        \"\"\"\n        Adds labels to parameterisation plots\n\n        TODO add labels for:\n\n            height top upper dz flat tilt bottom lower l0s - l3s l0e - l3e\n\n        Parameters\n        ----------\n        ax:\n            Matplotlib axis instance\n        shape:\n            parameterisation wire\n\n        \"\"\"\n        offset_x, offset_z = super()._label_function(ax, shape)",
  "def _make_domed_leg(\n        x_out: float,\n        x_curve_start: float,\n        x_mid: float,\n        z_top: float,\n        z_mid: float,\n        ri: float,\n        axis: Iterable[float] = (0, -1, 0),\n        flip: bool = False,\n    ) -> BluemiraWire:\n        \"\"\"\n        Makes smooth dome for CP coils. This includes a initial straight section\n        and a main curved dome section, with a transitioning 'joint' between them,\n        producing smooth tangent curves.\n\n        Parameters\n        ----------\n        x_out:\n            Radial position of outer edge of limb [m]\n        x_curve start:\n            Radial position of straight-curve transition of limb [m]\n        x_mid:\n            Radial position of inner edge of  upper/lower limb [m]\n        z_top:\n            Vertical position of top of limb dome [m]\n        z_mid:\n            Vertical position of flat section [m]\n        ri:\n            Radius of inner corner transition. Nominally 0 [m]\n        axis:\n            [x,y,z] vector normal to plane of parameterisation\n        flip:\n            True if limb is lower limb of section, False if upper\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        # Define the basic main curve (with no joint or transitions curves)\n        alpha = np.arctan(0.5 * (x_out - x_curve_start) / abs(z_top - z_mid))\n        theta_leg_basic = 2 * (np.pi - 2 * alpha)\n        r_leg = 0.5 * (x_out - x_curve_start) / np.sin(theta_leg_basic * 0.5)\n\n        # Transitioning Curves\n        sin_a = np.sin(theta_leg_basic * 0.5)\n        cos_a = np.cos(theta_leg_basic * 0.5)\n\n        # Joint Curve\n        r_j = min(x_curve_start - x_mid, 0.8)\n        theta_j = np.arccos((r_leg * cos_a + r_j) / (r_leg + r_j))\n        deg_theta_j = np.rad2deg(theta_j)\n\n        # Corner Transitioning Curve\n        theta_trans = np.arccos((r_j - r_leg * sin_a) / (r_j - r_leg))\n        deg_theta_trans = np.rad2deg(theta_trans)\n\n        # Main leg curve angle\n        leg_angle = 90 + deg_theta_j\n\n        # Labels\n        if flip:\n            label = \"bottom\"\n            z_top_r_leg = z_top + r_leg\n            z_mid_r_j = z_mid - r_j\n            z_trans_diff = -(r_leg - r_j)\n            z_corner = z_mid + ri\n            corner_angle_s = 90\n            corner_angle_e = 180\n            joint_angle_s = 90 - deg_theta_j\n            joint_angle_e = 90\n            leg_angle_s = tc_angle_e = deg_theta_trans\n            leg_angle_e = leg_angle\n            tc_angle_s = 0\n            ind = slice(None, None, -1)\n        else:\n            label = \"top\"\n            z_top_r_leg = z_top - r_leg\n            z_mid_r_j = z_mid + r_j\n            z_trans_diff = r_leg - r_j\n            z_corner = z_mid - ri\n            corner_angle_s = 180\n            corner_angle_e = 270\n            joint_angle_s = -90\n            joint_angle_e = deg_theta_j - 90\n            leg_angle_s = -leg_angle\n            leg_angle_e = tc_angle_s = -deg_theta_trans\n            tc_angle_e = 0\n            ind = slice(None)\n\n        # Basic main curve centre\n        leg_centre = (x_out - 0.5 * (x_out - x_curve_start), 0, z_top_r_leg)\n\n        # Joint curve centre\n        joint_curve_centre = (\n            leg_centre[0] - (r_leg + r_j) * np.sin(theta_j),\n            0,\n            z_mid_r_j,\n        )\n\n        # Transition curve centre\n        x_trans = leg_centre[0] + (r_leg - r_j) * np.cos(theta_trans)\n        z_trans = leg_centre[2] + z_trans_diff * np.sin(theta_trans)\n\n        # Inner Corner\n        corner_in = make_circle(\n            ri,\n            [x_mid + ri, 0.0, z_corner],\n            start_angle=corner_angle_s,\n            end_angle=corner_angle_e,\n            axis=[0, 1, 0],\n            label=f\"inner_{label}_corner\",\n        )\n\n        # Build straight section of leg\n        p1 = [x_mid + ri, 0, z_mid]\n        p2 = [leg_centre[0] - (r_leg + r_j) * np.sin(theta_j), 0, z_mid]\n        straight_section = make_polygon([p2, p1] if flip else [p1, p2])\n\n        # Dome-inboard section transition curve\n        joint_curve = make_circle(\n            radius=r_j,\n            center=joint_curve_centre,\n            start_angle=joint_angle_s,\n            end_angle=joint_angle_e,\n            axis=axis,\n            label=f\"{label}_limb_joint\",\n        )\n\n        # Main leg curve\n        leg_curve = make_circle(\n            radius=r_leg,\n            center=leg_centre,\n            start_angle=leg_angle_s,\n            end_angle=leg_angle_e,\n            axis=[0, 1, 0],\n            label=f\"{label}_limb_dome\",\n        )\n\n        # Outboard corner transition curve\n        transition_curve = make_circle(\n            radius=r_j,\n            center=[x_trans, 0, z_trans],\n            start_angle=tc_angle_s,\n            end_angle=tc_angle_e,\n            axis=[0, 1, 0],\n            label=f\"{label}_limb_corner\",\n        )\n\n        return BluemiraWire(\n            [corner_in, straight_section, joint_curve, leg_curve, transition_curve][ind],\n            label=f\"{label}_limb\",\n        )",
  "def _make_flat_leg(\n        x_in: float,\n        x_out: float,\n        z: float,\n        r_i: float,\n        r_o: float,\n        axis: Iterable[float] = (0, 1, 0),\n        flip: bool = False,\n    ) -> BluemiraWire:\n        \"\"\"\n        Makes a flat leg (top/bottom limb) with the option of one end rounded.\n\n        Parameters\n        ----------\n        x_in:\n            Radial position of inner edge of limb [m]\n        x_out:\n            Radial position of outer edge of limb [m]\n        z:\n            Vertical position of limb [m]\n        r_i:\n            Radius of inner corner [m]\n        r_o:\n            Radius of outer corner [m]\n        axis:\n            [x,y,z] vector normal to plane of parameterisation\n        flip:\n            True if limb is lower limb of section, False if upper\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        wires = []\n        label = \"bottom\" if flip else \"top\"\n\n        # Set corner radius centres\n        c_i = [x_in + r_i, 0.0, z + r_i if flip else z - r_i]\n        c_o = [x_out - r_o, 0.0, z + r_o if flip else z - r_o]\n\n        # Inner Corner\n        if r_i != 0.0:\n            wires.append(\n                make_circle(\n                    r_i,\n                    c_i,\n                    start_angle=90 if flip else 180,\n                    end_angle=180 if flip else 270,\n                    axis=axis,\n                    label=f\"inner_{label}_corner\",\n                )\n            )\n        # Straight Section\n        p1 = [x_in + r_i, 0.0, z]\n        p2 = [x_out - r_o, 0.0, z]\n        wires.append(make_polygon([p2, p1] if flip else [p1, p2], label=f\"{label}_limb\"))\n\n        # Outer corner\n        if r_o != 0.0:\n            wires.append(\n                make_circle(\n                    r_o,\n                    c_o,\n                    start_angle=0 if flip else 270,\n                    end_angle=90 if flip else 0,\n                    axis=axis,\n                    label=f\"outer_{label}_corner\",\n                )\n            )\n\n        if flip:\n            wires.reverse()\n\n        return BluemiraWire(wires, label=f\"{label}_limb\")",
  "def _make_tapered_inner_leg(\n        x_in: float,\n        x_mid: float,\n        z_in: float,\n        z1: float,\n        z2: float,\n        axis: Iterable[float] = (0, 1, 0),\n    ) -> BluemiraWire:\n        \"\"\"\n        Makes a tapered inboard leg using a circle arc taper, symmetric about the\n        midplane with the tapering beginning at a certain height and reaching a\n        maximum taper at the midplane.\n\n        Parameters\n        ----------\n        x_in:\n            Radial position of innermost point of limb [m]\n        x_mid:\n            Radial position of outer edge of limb [m]\n        z_in:\n            Vertical position of start of tapering [m]\n        z1:\n            Vertical position of top of limb [m]\n        z2:\n            Vertical position of bottom of limb [m]\n        axis:\n            [x,y,z] vector normal to plane of parameterisation\n\n        Returns\n        -------\n        CAD Wire of the geometry\n        \"\"\"\n        # Bottom straight section\n        p1 = [x_mid, 0, -z_in]\n        p2 = [x_mid, 0, z2]\n        bot_straight = make_polygon([p2, p1], label=\"inner_limb_mid_down\")\n\n        # Curved taper radius\n        x_t = x_mid - x_in\n        alpha = np.arctan(z_in / (x_t))\n        theta_t = np.pi - 2 * alpha\n        r_taper = z_in / np.sin(theta_t)\n\n        # Curved taper angle\n        angle = np.rad2deg(np.arcsin(z_in / r_taper))\n        ct_angle = make_circle(\n            radius=r_taper,\n            center=(x_in + r_taper, 0, 0),\n            start_angle=180 - angle,\n            end_angle=180 + angle,\n            axis=axis,\n            label=\"inner_limb\",\n        )\n\n        # Top straight section\n        p3 = [x_mid, 0, z_in]\n        p4 = [x_mid, 0, z1]\n        top_straight = make_polygon([p3, p4], label=\"inner_limb_mid_up\")\n\n        return BluemiraWire([bot_straight, ct_angle, top_straight], label=\"inner_limb\")",
  "def _connect_to_outer_limb(self, top, bottom, top_curve=False, bot_curve=False):\n        return self._outer_limb(\n            top.discretize(100, byedges=True)[:, -1] if top_curve else top,\n            bottom.discretize(100, byedges=True)[:, 0] if bot_curve else bottom,\n        )",
  "def _connect_straight_to_inner_limb(self, top, bottom):\n        return self._inner_limb(top, bottom)",
  "def _inner_limb(p1, p2):\n        return make_polygon([p1, p2], label=\"inner_limb\")",
  "def _outer_limb(p1, p2):\n        return make_polygon([p1, p2], label=\"outer_limb\")",
  "def __call__(self, *args, **kwargs):\n        \"\"\"\n        Call linked function on access\n        \"\"\"\n        return self.value(*args, **kwargs)",
  "def configure(\n        self,\n        upper: Union[str, PFrameSection],\n        lower: Union[str, PFrameSection],\n        inner: Optional[Union[str, PFrameSection]],\n    ):\n        \"\"\"Fix variables based on the upper, lower and inner limbs.\"\"\"\n        if upper is PFrameSection.CURVED and lower is PFrameSection.CURVED:\n            self.ro.fixed = True\n        elif upper is PFrameSection.FLAT and lower is PFrameSection.FLAT:\n            self.z1_peak.fixed = True\n            self.z2_peak.fixed = True\n            self.x3.fixed = True\n        if inner is not PFrameSection.TAPERED_INNER:\n            self.x4.fixed = True\n            self.z3.fixed = True",
  "def __init__(\n        self,\n        var_dict: Optional[VarDictT] = None,\n        *,\n        upper: Union[str, PFrameSection] = PFrameSection.FLAT,\n        lower: Union[str, PFrameSection] = PFrameSection.FLAT,\n        inner: Optional[Union[str, PFrameSection]] = None,\n    ):\n        self.upper = upper if isinstance(upper, PFrameSection) else PFrameSection[upper]\n        self.lower = lower if isinstance(lower, PFrameSection) else PFrameSection[lower]\n\n        if isinstance(inner, str):\n            inner = PFrameSection[inner]\n        self.inner = inner\n\n        variables = PictureFrameOptVariables()\n        variables.adjust_variables(var_dict, strict_bounds=False)\n        variables.configure(self.upper, self.lower, self.inner)\n        super().__init__(variables)",
  "def __deepcopy__(self, memo) -> PictureFrame:\n        \"\"\"Picture Frame deepcopy\"\"\"\n        cls = type(self)\n        result = cls.__new__(cls)\n        memo[id(self)] = result\n        for k in (*self.__slots__, *super().__slots__):\n            with suppress(AttributeError):\n                v = getattr(self, k)\n                setattr(\n                    result,\n                    k,\n                    v if isinstance(v, PFrameSection) else copy.deepcopy(v, memo),\n                )\n        return result",
  "def create_shape(self, label: str = \"\") -> BluemiraWire:\n        \"\"\"\n        Make a CAD representation of the picture frame.\n\n        Parameters\n        ----------\n        label:\n            Label to give the wire\n\n        Returns\n        -------\n        CAD Wire of the Picture Frame geometry\n        \"\"\"\n        inb_leg = self._make_inb_leg()\n        top_leg = self._make_upper_lower_leg(make_upper_section=True, flip=False)\n        bot_leg = self._make_upper_lower_leg(make_upper_section=False, flip=True)\n        out_leg = self._make_out_leg(top_leg, bot_leg)\n\n        return BluemiraWire([inb_leg, top_leg, out_leg, bot_leg], label=label)",
  "def _make_inb_leg(self):\n        v = self.variables\n        if isinstance(self.inner, PFrameSection):\n            if self.inner is not PFrameSection.TAPERED_INNER:\n                raise ValueError(f\"The inner leg cannot be {self.inner}\")\n            return self.inner(\n                v.x1.value,\n                v.x4.value,\n                v.z3.value,\n                v.z1 - v.ri,\n                v.z2 + v.ri,\n            )\n        elif self.inner is None:\n            return self._connect_straight_to_inner_limb(\n                [v.x1.value, 0, v.z2 + v.ri],\n                [v.x1.value, 0, v.z1 - v.ri],\n            )",
  "def _make_upper_lower_leg(self, make_upper_section: bool, flip: bool):\n        v = self.variables\n        section_func: PFrameSection = self.upper if make_upper_section else self.lower\n        if section_func == PFrameSection.CURVED:\n            return section_func(\n                v.x2.value,\n                v.x3.value,\n                v.x4.value if self.inner is PFrameSection.TAPERED_INNER else v.x1.value,\n                v.z1_peak.value if make_upper_section else v.z2_peak.value,\n                v.z1.value if make_upper_section else v.z2.value,\n                v.ri.value,\n                flip=flip,\n            )\n        elif section_func == PFrameSection.FLAT:\n            return section_func(\n                v.x4.value if self.inner is PFrameSection.TAPERED_INNER else v.x1.value,\n                v.x2.value,\n                v.z1.value if make_upper_section else v.z2.value,\n                v.ri.value,\n                v.ro.value,\n                flip=flip,\n            )\n        else:\n            raise ValueError(f\"The leg cannot be {section_func}\")",
  "def _make_out_leg(self, top_leg, bot_leg):\n        v = self.variables\n        return self._connect_to_outer_limb(\n            top_leg\n            if self.upper is PFrameSection.CURVED\n            else [v.x2.value, 0, v.z1 - v.ro],\n            bot_leg\n            if self.lower is PFrameSection.CURVED\n            else [v.x2.value, 0, v.z2 + v.ro],\n            self.upper is PFrameSection.CURVED,\n            self.lower is PFrameSection.CURVED,\n        )",
  "def _label_function(self, ax, shape):\n        super()._label_function(ax, shape)\n        ro = self.variables.ro\n        ri = self.variables.ri\n        z = self.variables.z1\n        x_in = (\n            self.variables.x4\n            if self.inner is PFrameSection.TAPERED_INNER\n            else self.variables.x1\n        )\n\n        x_out = self.variables.x2\n        _r1 = ri * (1 - np.sqrt(0.5))\n        _r2 = ro * (1 - np.sqrt(0.5))\n        self._annotator(\n            ax,\n            \"ri\",\n            (x_in + ri, z - ri),\n            (x_in + _r1, z - _r1),\n            ((x_in + ri) * 0.8, z - 6 * _r1),\n        )\n        self._annotator(\n            ax,\n            \"ro\",\n            (x_out - ro, z - ro),\n            (x_out - _r2, z - _r2),\n            ((x_out + ro) * 0.6, z - 3 * _r2),\n        )\n\n        xmin, xmax = ax.get_xlim()\n        ax.set_xlim(xmin, xmax * 1.1)",
  "def convert(apiobj: cadapi.apiShape, label: str = \"\") -> BluemiraGeo:\n    \"\"\"Convert a FreeCAD shape into the corresponding BluemiraGeo object.\"\"\"\n    if isinstance(apiobj, cadapi.apiWire):\n        output = BluemiraWire(apiobj, label)\n    elif isinstance(apiobj, cadapi.apiFace):\n        output = BluemiraFace._create(apiobj, label)\n    elif isinstance(apiobj, cadapi.apiShell):\n        output = BluemiraShell._create(apiobj, label)\n    elif isinstance(apiobj, cadapi.apiSolid):\n        output = BluemiraSolid._create(apiobj, label)\n    elif isinstance(apiobj, cadapi.apiCompound):\n        output = BluemiraCompound._create(apiobj, label)\n    else:\n        raise ValueError(f\"Cannot convert {type(apiobj)} object into a BluemiraGeo.\")\n    return output",
  "class BluemiraGeoEncoder(json.JSONEncoder):\n    \"\"\"\n    JSON Encoder for BluemiraGeo.\n    \"\"\"\n\n    def default(self, obj: Union[BluemiraGeo, np.ndarray, Any]):\n        \"\"\"\n        Override the JSONEncoder default object handling behaviour for BluemiraGeo.\n        \"\"\"\n        if isinstance(obj, BluemiraGeo):\n            return serialize_shape(obj)\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        return super().default(obj)",
  "def _reconstruct_function_call(signature, *args, **kwargs) -> dict:\n    \"\"\"\n    Reconstruct the call of a function with inputs arguments and defaults.\n    \"\"\"\n    data = {}\n\n    # Inspect the function call and reconstruct defaults\n    for i, key in enumerate(signature.parameters.keys()):\n        if i < len(args):\n            data[key] = args[i]\n        else:\n            if key not in kwargs:\n                value = signature.parameters[key].default\n                if value != inspect._empty:\n                    data[key] = value\n            else:\n                data[key] = kwargs[key]\n\n    # Catch any kwargs not in signature\n    for k, v in kwargs.items():\n        if k not in data:\n            data[k] = v\n    return data",
  "def _make_debug_file(name: str) -> str:\n    \"\"\"\n    Make a new file in the geometry debugging folder.\n    \"\"\"\n    path = get_bluemira_path(\"generated_data/naughty_geometry\", subfolder=\"\")\n    now = datetime.datetime.now()\n    timestamp = now.strftime(\"%m-%d-%Y-%H-%M\")\n    fmt_string = \"{}-{}{}.json\"\n    name = fmt_string.format(name, timestamp, \"\")\n    filename = os.path.join(path, name)\n\n    i = 0\n    while os.path.isfile(filename):\n        i += 1\n        increment = f\"_{i}\"\n        name = fmt_string.format(name, timestamp, increment)\n        filename = os.path.join(path, name)\n    return filename",
  "def log_geometry_on_failure(func):\n    \"\"\"\n    Decorator for debugging of failed geometry operations.\n    \"\"\"\n    signature = inspect.signature(func)\n    func_name = func.__name__\n\n    def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except cadapi.FreeCADError as error:\n            data = _reconstruct_function_call(signature, *args, **kwargs)\n            filename = _make_debug_file(func_name)\n\n            # Dump the data in the file\n            try:\n                with open(filename, \"w\") as file:\n                    json.dump(data, file, indent=4, cls=BluemiraGeoEncoder)\n\n                bluemira_debug(\n                    f\"Function call {func_name} failed. Debugging information was saved to: {filename}\"\n                )\n            except Exception:\n                bluemira_warn(\n                    f\"Failed to save the failed geometry operation {func_name} to JSON.\"\n                )\n\n            raise error\n\n    return wrapper",
  "def fallback_to(fallback_func, exception):\n    \"\"\"\n    Decorator for a fallback to an alternative geometry operation.\n    \"\"\"\n\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            try:\n                return func(*args, **kwargs)\n            except exception:\n                bluemira_warn(\n                    f\"{func.__name__} failed, falling back to {fallback_func.__name__}.\"\n                )\n                return fallback_func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator",
  "def _make_vertex(point: Iterable[float]) -> cadapi.apiVertex:\n    \"\"\"\n    Make a vertex.\n\n    Parameters\n    ----------\n    point:\n        Coordinates of the point\n\n    Returns\n    -------\n    Vertex at the point\n    \"\"\"\n    if len(point) != 3:\n        raise GeometryError(\"Points must be of dimension 3.\")\n\n    return cadapi.apiVertex(*point)",
  "def closed_wire_wrapper(drop_closure_point: bool):\n    \"\"\"\n    Decorator for checking / enforcing closures on wire creation functions.\n    \"\"\"\n\n    def decorator(func: Callable):\n        def wrapper(\n            points: Union[list, np.ndarray, Dict], label: str = \"\", closed: bool = False\n        ):\n            points = Coordinates(points)\n            if points.closed:\n                if closed is False:\n                    bluemira_warn(\n                        f\"{func.__name__}: input points are closed but closed=False, defaulting to closed=True.\"\n                    )\n                closed = True\n                if drop_closure_point:\n                    points = Coordinates(points.xyz[:, :-1])\n            wire = func(points, label=label, closed=closed)\n            if closed:\n                wire = cadapi.close_wire(wire)\n            return BluemiraWire(wire, label=label)\n\n        wrapper.__doc__ = func.__doc__\n        return wrapper\n\n    return decorator",
  "def make_polygon(\n    points: Union[list, np.ndarray], label: str = \"\", closed: bool = False\n) -> BluemiraWire:\n    \"\"\"\n    Make a polygon from a set of points.\n\n    Parameters\n    ----------\n    points:\n        list of points. It can be given as a list of 3D tuples, a 3D numpy array,\n        or similar.\n    label:\n        Object's label\n    closed:\n        if True, the first and last points will be connected in order to form a\n        closed polygon. Defaults to False.\n\n    Returns\n    -------\n    BluemiraWire of the polygon\n\n    Notes\n    -----\n    If the input points are closed, but closed is False, the returned BluemiraWire will\n    be closed.\n    \"\"\"\n    return cadapi.make_polygon(points.T)",
  "def make_bezier(\n    points: Union[list, np.ndarray], label: str = \"\", closed: bool = False\n) -> BluemiraWire:\n    \"\"\"Make a bspline from a set of points.\n\n    Parameters\n    ----------\n    points:\n        list of points. It can be given as a list of 3D tuples, a 3D numpy array,\n        or similar.\n    label:\n        Object's label\n    closed:\n        if True, the first and last points will be connected in order to form a\n        closed bspline. Defaults to False.\n\n    Returns\n    -------\n    BluemiraWire that contains the bspline\n\n    Notes\n    -----\n    If the input points are closed, but closed is False, the returned BluemiraWire will\n    be closed.\n    \"\"\"\n    return cadapi.make_bezier(points.T)",
  "def make_bspline(\n    poles: Union[list, np.ndarray],\n    mults: Union[list, np.ndarray],\n    knots: Union[list, np.ndarray],\n    periodic: bool,\n    degree: int,\n    weights: Union[list, np.ndarray],\n    check_rational: bool,\n    label: str = \"\",\n) -> BluemiraWire:\n    \"\"\"\n    Builds a B-Spline by a lists of Poles, Mults, Knots\n\n    Parameters\n    ----------\n    poles:\n        list of poles.\n    mults:\n        list of integers for the multiplicity\n    knots:\n        list of knots\n    periodic:\n        Whether or not the spline is periodic (same curvature at start and end points)\n    degree: int\n        bspline degree\n    weights:\n        sequence of float\n    check_rational:\n        Whether or not to check if the BSpline is rational\n\n    Returns\n    -------\n    BluemiraWire of the spline\n    \"\"\"\n    return BluemiraWire(\n        cadapi.make_bspline(\n            poles, mults, knots, periodic, degree, weights, check_rational\n        ),\n        label=label,\n    )",
  "def _make_polygon_fallback(points, label=\"\", closed=False, **kwargs) -> BluemiraWire:\n    \"\"\"\n    Overloaded function signature for fallback option from interpolate_bspline\n    \"\"\"\n    return make_polygon(points, label, closed)",
  "def interpolate_bspline(\n    points: Union[list, np.ndarray],\n    label: str = \"\",\n    closed: bool = False,\n    start_tangent: Optional[Iterable] = None,\n    end_tangent: Optional[Iterable] = None,\n) -> BluemiraWire:\n    \"\"\"\n    Make a bspline from a set of points.\n\n    Parameters\n    ----------\n    points:\n        list of points. It can be given as a list of 3D tuples, a 3D numpy array,\n        or similar.\n    label:\n        Object's label\n    closed:\n        if True, the first and last points will be connected in order to form a\n        closed bspline. Defaults to False.\n    start_tangent:\n        Tangency of the BSpline at the first pole. Must be specified with end_tangent\n    end_tangent:\n        Tangency of the BSpline at the last pole. Must be specified with start_tangent\n\n    Returns\n    -------\n    Bluemira wire that contains the bspline\n    \"\"\"\n    points = Coordinates(points)\n    return BluemiraWire(\n        cadapi.interpolate_bspline(points.T, closed, start_tangent, end_tangent),\n        label=label,\n    )",
  "def force_wire_to_spline(\n    wire: BluemiraWire,\n    n_edges_max: int = 200,\n    l2_tolerance: float = 5e-3,\n) -> BluemiraWire:\n    \"\"\"\n    Force a wire to be a spline wire.\n\n    Parameters\n    ----------\n    wire:\n        The BluemiraWire to be turned into a splined wire\n    n_edges_max:\n        The maximum number of edges in the wire, below which this operation\n        does nothing\n    l2_tolerance:\n        The L2-norm difference w.r.t. the original wire, above which this\n        operation will warn that the desired tolerance was not achieved.\n\n    Returns\n    -------\n    A new spline version of the wire\n\n    Notes\n    -----\n    This is intended for use with wires that consist of large polygons, often resulting\n    from operations that failed with primitives and fallback methods making use of\n    of polygons. This can be relatively stubborn to transform back to splines.\n    \"\"\"\n    original_n_edges = len(wire.edges)\n    if original_n_edges < n_edges_max:\n        bluemira_debug(\n            f\"Wire already has {original_n_edges} < {n_edges_max=}. No point forcing to a spline.\"\n        )\n        return wire\n\n    original_points = wire.discretize(ndiscr=2 * original_n_edges, byedges=False)\n\n    for n_discr in np.array(original_n_edges * np.linspace(0.8, 0.1, 8), dtype=int):\n        points = wire.discretize(ndiscr=int(n_discr), byedges=False)\n        try:\n            wire = BluemiraWire(\n                cadapi.interpolate_bspline(points.T, closed=wire.is_closed()),\n                label=wire.label,\n            )\n            break\n        except cadapi.FreeCADError:\n            continue\n\n    new_points = wire.discretize(ndiscr=2 * original_n_edges, byedges=False)\n\n    delta = np.linalg.norm(original_points.xyz - new_points.xyz, ord=2)\n    if delta > l2_tolerance:\n        bluemira_warn(\n            f\"Forcing wire to spline with {n_discr} interpolation points did not achieve the desired tolerance: {delta} > {l2_tolerance}\"\n        )\n\n    return wire",
  "def make_circle(\n    radius: float = 1.0,\n    center: Tuple[float, float, float] = (0.0, 0.0, 0.0),\n    start_angle: float = 0.0,\n    end_angle: float = 360.0,\n    axis: Tuple[float, float, float] = (0.0, 0.0, 1.0),\n    label: str = \"\",\n) -> BluemiraWire:\n    \"\"\"\n    Create a circle or arc of circle object with given parameters.\n\n    Parameters\n    ----------\n    radius:\n        Radius of the circle\n    center:\n        Center of the circle\n    start_angle:\n        Start angle of the arc [degrees]\n    end_angle:\n        End angle of the arc [degrees]. If start_angle == end_angle, a circle is created,\n        otherwise a circle arc is created\n    axis:\n        Normal vector to the circle plane. It defines the clockwise/anticlockwise\n        circle orientation according to the right hand rule.\n    label:\n        object's label\n\n    Returns\n    -------\n    Bluemira wire that contains the arc or circle\n    \"\"\"\n    output = cadapi.make_circle(radius, center, start_angle, end_angle, axis)\n    return BluemiraWire(output, label=label)",
  "def make_circle_arc_3P(  # noqa: N802\n    p1: Iterable[float], p2: Iterable[float], p3: Iterable[float], label: str = \"\"\n):\n    \"\"\"\n    Create an arc of circle object given three points.\n\n    Parameters\n    ----------\n    p1:\n        Starting point of the circle arc\n    p2:\n        Middle point of the circle arc\n    p3:\n        End point of the circle arc\n\n    Returns\n    -------\n    Bluemira wire that contains the arc or circle\n    \"\"\"\n    # TODO: check what happens when the 3 points are in a line\n    output = cadapi.make_circle_arc_3P(p1, p2, p3)\n    return BluemiraWire(output, label=label)",
  "def make_ellipse(\n    center: Tuple[float, float, float] = (0.0, 0.0, 0.0),\n    major_radius: float = 2.0,\n    minor_radius: float = 1.0,\n    major_axis: Tuple[float, float, float] = (1, 0, 0),\n    minor_axis: Tuple[float, float, float] = (0, 1, 0),\n    start_angle: float = 0.0,\n    end_angle: float = 360.0,\n    label: str = \"\",\n) -> BluemiraWire:\n    \"\"\"\n    Create an ellipse or arc of ellipse object with given parameters.\n\n    Parameters\n    ----------\n    center:\n        Center of the ellipse\n    major_radius:\n        Major radius of the ellipse\n    minor_radius:\n        Minor radius of the ellipse (float). Default to 2.\n    major_axis:\n        Major axis direction\n    minor_axis:\n        Minor axis direction\n    start_angle:\n        Start angle of the arc [degrees]\n    end_angle:\n        End angle of the arc [degrees].  if start_angle == end_angle, an ellipse is\n        created, otherwise a ellipse arc is created\n    label:\n        Object's label\n\n    Returns\n    -------\n    Bluemira wire that contains the arc or ellipse\n    \"\"\"\n    output = cadapi.make_ellipse(\n        center,\n        major_radius,\n        minor_radius,\n        major_axis,\n        minor_axis,\n        start_angle,\n        end_angle,\n    )\n    return BluemiraWire(output, label=label)",
  "def wire_closure(bmwire: BluemiraWire, label=\"closure\") -> BluemiraWire:\n    \"\"\"\n    Close this wire with a line segment\n\n    Parameters\n    ----------\n    bmwire:\n        supporting wire for the closure\n    label:\n        Object's label\n\n    Returns\n    -------\n    Closure wire\n    \"\"\"\n    wire = bmwire.shape\n    closure = BluemiraWire(cadapi.wire_closure(wire), label=label)\n    return closure",
  "def _offset_wire_discretised(\n    wire,\n    thickness,\n    /,\n    join: str = \"intersect\",\n    open_wire: bool = True,\n    label=\"\",\n    *,\n    fallback_method=\"square\",\n    byedges=True,\n    ndiscr=200,\n    **fallback_kwargs,\n) -> BluemiraWire:\n    \"\"\"\n    Fallback function for discretised offsetting\n\n    Raises\n    ------\n    GeometryError\n        If the wire is not closed. This function cannot handle the offet of an open\n        wire.\n    \"\"\"\n    from bluemira.geometry._pyclipper_offset import offset_clipper\n\n    if not wire.is_closed() and not open_wire:\n        wire = wire.deepcopy()\n        wire.close()\n\n    if not wire.is_closed() and open_wire:\n        raise GeometryError(\n            \"Fallback function _offset_wire_discretised cannot handle open wires.\"\n        )\n\n    coordinates = wire.discretize(byedges=byedges, ndiscr=ndiscr)\n\n    result = offset_clipper(\n        coordinates, thickness, method=fallback_method, **fallback_kwargs\n    )\n    return make_polygon(result, label=label, closed=True)",
  "def offset_wire(\n    wire: BluemiraWire,\n    thickness: float,\n    /,\n    join: str = \"intersect\",\n    open_wire: bool = True,\n    label: str = \"\",\n    *,\n    fallback_method=\"square\",\n    byedges=True,\n    ndiscr=400,\n    **fallback_kwargs,\n) -> BluemiraWire:\n    \"\"\"\n    Make a planar offset from a planar wire.\n\n    Parameters\n    ----------\n    wire:\n        Wire to offset from\n    thickness:\n        Offset distance. Positive values outwards, negative values inwards\n    join:\n        Offset method. \"arc\" gives rounded corners, and \"intersect\" gives sharp corners\n    open_wire:\n        For open wires (counter-clockwise default) whether or not to make an open offset\n        wire, or a closed offset wire that encompasses the original wire. This is\n        disabled for closed wires.\n\n    Other Parameters\n    ----------------\n    byedges:\n        Whether or not to discretise the wire by edges\n    ndiscr:\n        Number of points to discretise the wire to\n    fallback_method:\n        Method to use in discretised offsetting, will default to `square` as `round`\n        is know to be very slow\n\n    Notes\n    -----\n    If primitive offsetting failed, will fall back to a discretised offset\n    implementation, where the fallback kwargs are used. Discretised offsetting is\n    only supported for closed wires.\n\n    Returns\n    -------\n    Offset wire\n    \"\"\"\n    return BluemiraWire(\n        cadapi.offset_wire(wire.shape, thickness, join, open_wire), label=label\n    )",
  "def convex_hull_wires_2d(\n    wires: Sequence[BluemiraWire], ndiscr: int, plane: str = \"xz\"\n) -> BluemiraWire:\n    \"\"\"\n    Perform a convex hull around the given wires and return the hull\n    as a new wire.\n\n    The operation performs discretisations on the input wires.\n\n    Parameters\n    ----------\n    wires:\n        The wires to draw a hull around.\n    ndiscr:\n        The number of points to discretise each wire into.\n    plane:\n        The plane to perform the hull in. One of: 'xz', 'xy', 'yz'.\n        Default is 'xz'.\n\n    Returns\n    -------\n    A wire forming a convex hull around the input wires in the given\n    plane.\n    \"\"\"\n    if not wires:\n        raise ValueError(\"Must have at least one wire to draw a hull around.\")\n    if plane == \"xz\":\n        plane_idxs = (0, 2)\n    elif plane == \"xy\":\n        plane_idxs = (0, 1)\n    elif plane == \"yz\":\n        plane_idxs = (1, 2)\n    else:\n        raise ValueError(f\"Invalid plane: '{plane}'. Must be one of 'xz', 'xy', 'yz'.\")\n\n    shape_discretizations = []\n    for wire in wires:\n        discretized_points = wire.discretize(byedges=True, ndiscr=ndiscr)\n        shape_discretizations.append(getattr(discretized_points, plane))\n    coords = np.hstack(shape_discretizations)\n\n    hull = ConvexHull(coords.T)\n    hull_coords = np.zeros((3, len(hull.vertices)))\n    hull_coords[plane_idxs, :] = coords[:, hull.vertices]\n    return make_polygon(hull_coords, closed=True)",
  "def revolve_shape(\n    shape: BluemiraGeo,\n    base: Tuple[float, float, float] = (0.0, 0.0, 0.0),\n    direction: Tuple[float, float, float] = (0.0, 0.0, 1.0),\n    degree: float = 180,\n    label: str = \"\",\n) -> BluemiraGeo:\n    \"\"\"\n    Apply the revolve (base, dir, degree) to this shape\n\n    Parameters\n    ----------\n    shape:\n        The shape to be revolved\n    base:\n        Origin location of the revolution\n    direction:\n        The direction vector\n    degree:\n        revolution angle\n\n    Returns\n    -------\n    The revolved shape.\n    \"\"\"\n    if degree > 360:\n        bluemira_warn(\"Cannot revolve a shape by more than 360 degrees.\")\n        degree = 360\n\n    if degree == 360:\n        # We split into two separate revolutions of 180 degree and fuse them\n        if isinstance(shape, BluemiraWire):\n            shape = BluemiraFace(shape).shape\n            flag_shell = True\n        else:\n            shape = shape.shape\n            flag_shell = False\n\n        shape_1 = cadapi.revolve_shape(shape, base, direction, degree=180)\n        shape_2 = deepcopy(shape_1)\n        shape_2 = cadapi.rotate_shape(shape_2, base, direction, degree=-180)\n        result = cadapi.boolean_fuse([shape_1, shape_2], remove_splitter=False)\n\n        if flag_shell:\n            result = result.Shells[0]\n\n        return convert(result, label)\n\n    return convert(cadapi.revolve_shape(shape.shape, base, direction, degree), label)",
  "def extrude_shape(\n    shape: BluemiraGeo, vec: Tuple[float, float, float], label=\"\"\n) -> BluemiraSolid:\n    \"\"\"\n    Apply the extrusion along vec to this shape\n\n    Parameters\n    ----------\n    shape:\n        The shape to be extruded\n    vec:\n        The vector along which to extrude\n    label:\n        label of the output shape\n\n    Returns\n    -------\n    The extruded shape.\n    \"\"\"\n    if not label:\n        label = shape.label\n\n    return convert(cadapi.extrude_shape(shape.shape, vec), label)",
  "def sweep_shape(\n    profiles: Union[BluemiraWire, Iterable[BluemiraWire]],\n    path: BluemiraWire,\n    solid: bool = True,\n    frenet: bool = True,\n    label: str = \"\",\n) -> Union[BluemiraSolid, BluemiraShell]:\n    \"\"\"\n    Sweep a profile along a path.\n\n    Parameters\n    ----------\n    profiles:\n        Profile(s) to sweep\n    path:\n        Path along which to sweep the profiles\n    solid:\n        Whether or not to create a Solid\n    frenet:\n        If true, the orientation of the profile(s) is calculated based on local curvature\n        and tangency. For planar paths, should not make a difference.\n\n    Returns\n    -------\n    Swept geometry object\n    \"\"\"\n    if not isinstance(profiles, Iterable):\n        profiles = [profiles]\n\n    profile_shapes = [p.shape for p in profiles]\n\n    result = cadapi.sweep_shape(profile_shapes, path.shape, solid, frenet)\n\n    return convert(result, label=label)",
  "def fillet_chamfer_decorator(chamfer: bool):\n    \"\"\"\n    Decorator for fillet and chamfer operations, checking for validity of wire\n    and radius.\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(wire, radius):\n            edges = wire.shape.OrderedEdges\n            func_name = \"chamfer\" if chamfer else \"fillet\"\n            if len(edges) < 2:\n                raise GeometryError(f\"Cannot {func_name} a wire with less than 2 edges!\")\n            if not cadapi._wire_is_planar(wire.shape):\n                raise GeometryError(f\"Cannot {func_name} a non-planar wire!\")\n            if radius == 0:\n                return wire.deepcopy()\n            if radius < 0:\n                raise GeometryError(\n                    f\"Cannot {func_name} a wire with a negative {radius=}\"\n                )\n            return func(wire, radius)\n\n        return wrapper\n\n    return decorator",
  "def fillet_wire_2D(wire: BluemiraWire, radius: float) -> BluemiraWire:\n    \"\"\"\n    Fillet all edges of a wire\n\n    Parameters\n    ----------\n    wire:\n        Wire to fillet\n    radius:\n        Radius of the fillet operation\n\n    Returns\n    -------\n    The filleted wire\n    \"\"\"\n    return BluemiraWire(cadapi.fillet_wire_2D(wire.shape, radius))",
  "def chamfer_wire_2D(wire: BluemiraWire, radius: float):\n    \"\"\"\n    Chamfer all edges of a wire\n\n    Parameters\n    ----------\n    wire:\n        Wire to chamfer\n    radius:\n        Radius of the chamfer operation\n\n    Returns\n    -------\n    The chamfered wire\n    \"\"\"\n    return BluemiraWire(cadapi.fillet_wire_2D(wire.shape, radius, chamfer=True))",
  "def distance_to(\n    geo1: Union[Iterable[float], BluemiraGeo], geo2: Union[Iterable[float], BluemiraGeo]\n) -> Tuple[float, List[Tuple[float, float, float]]]:\n    \"\"\"\n    Calculate the distance between two BluemiraGeos.\n\n    Parameters\n    ----------\n    geo1:\n        Reference shape. If an iterable of length 3, converted to a point.\n    geo2:\n        Target shape. If an iterable of length 3, converted to a point.\n\n    Returns\n    -------\n    dist:\n        Minimum distance\n    vectors:\n        List of tuples corresponding to the nearest points between geo1 and geo2. The\n        distance between those points is the minimum distance given by dist.\n    \"\"\"\n    # Check geometry for vertices\n    if isinstance(geo1, Iterable):\n        shape1 = _make_vertex(geo1)\n    else:\n        shape1 = geo1.shape\n    if isinstance(geo2, Iterable):\n        shape2 = _make_vertex(geo2)\n    else:\n        shape2 = geo2.shape\n    return cadapi.dist_to_shape(shape1, shape2)",
  "def split_wire(\n    wire: BluemiraWire, vertex: Iterable[float], tolerance: float = EPS * 10\n) -> Tuple[Union[None, BluemiraWire], Union[None, BluemiraWire]]:\n    \"\"\"\n    Split a wire at a given vertex.\n\n    Parameters\n    ----------\n    wire:\n        Wire to be split\n    vertex:\n        Vertex at which to split the wire\n    tolerance:\n        Tolerance within which to find the closest vertex on the wire\n\n    Returns\n    -------\n    wire_1:\n        First half of the wire. Will be None if the vertex is the start point of the wire\n    wire_2:\n        Last half of the wire. Will be None if the vertex is the start point of the wire\n\n    Raises\n    ------\n    GeometryError:\n        If the vertex is further away to the wire than the specified tolerance\n    \"\"\"\n    wire_1, wire_2 = cadapi.split_wire(wire.shape, vertex, tolerance=tolerance)\n    if wire_1:\n        wire_1 = BluemiraWire(wire_1)\n    if wire_2:\n        wire_2 = BluemiraWire(wire_2)\n    return wire_1, wire_2",
  "def slice_shape(\n    shape: BluemiraGeo, plane: BluemiraPlane\n) -> Union[List[np.ndarray], None, List[BluemiraWire]]:\n    \"\"\"\n    Calculate the plane intersection points with an object\n\n    Parameters\n    ----------\n    shape:\n        Shape to intersect with a plane\n    plane:\n        Plane to intersect with\n\n    Returns\n    -------\n    Wire: Union[List[np.ndarray], None]\n        returns array of intersection points\n    Face, Solid, Shell: Union[List[BluemiraWire], None]\n        list of intersections lines\n\n    Notes\n    -----\n    Degenerate cases such as tangets to solid or faces do not return intersections\n    if the shape and plane are acting at the Plane base.\n    Further investigation needed.\n\n    \"\"\"\n    _slice = cadapi.slice_shape(shape.shape, plane.base, plane.axis)\n\n    if isinstance(_slice, np.ndarray) and _slice.size > 0:\n        return _slice\n\n    _slice = [convert(obj) for obj in _slice]\n\n    if len(_slice) > 0:\n        return _slice",
  "def circular_pattern(\n    shape: BluemiraGeo,\n    origin: Tuple[float, float, float] = (0, 0, 0),\n    direction: Tuple[float, float, float] = (0, 0, 1),\n    degree: float = 360,\n    n_shapes: int = 10,\n) -> List[BluemiraGeo]:\n    \"\"\"\n    Make a equally spaced circular pattern of shapes.\n\n    Parameters\n    ----------\n    shape:\n        Shape to pattern\n    origin:\n        Origin vector of the circular pattern\n    direction:\n        Direction vector of the circular pattern\n    degree:\n        Angle range of the patterning\n    n_shapes:\n        Number of shapes to pattern\n\n    Returns\n    -------\n    List of patterned shapes, the first element is the original shape\n    \"\"\"\n    angle = degree / n_shapes\n\n    shapes = [shape]\n    for i in range(1, n_shapes):\n        new_shape = shape.deepcopy()\n        new_shape.rotate(origin, direction, i * angle)\n        shapes.append(new_shape)\n    return shapes",
  "def mirror_shape(\n    shape: BluemiraGeo, base: tuple, direction: tuple, label=\"\"\n) -> BluemiraGeo:\n    \"\"\"\n    Get a mirrored copy of a shape about a plane.\n\n    Parameters\n    ----------\n    shape:\n        Shape to mirror\n    base:\n        Mirror plane base\n    direction:\n        Mirror plane normal direction\n\n    Returns\n    -------\n    The mirrored shape\n\n    Raises\n    ------\n    GeometryError: if the norm of the direction tuple is <= 3*EPS\n    \"\"\"\n    if np.linalg.norm(direction) <= 3 * EPS:\n        raise GeometryError(\"Direction vector cannot have a zero norm.\")\n    return convert(cadapi.mirror_shape(shape.shape, base, direction), label=label)",
  "def save_as_STP(\n    shapes: Union[BluemiraGeo, Iterable[BluemiraGeo]],\n    filename: str,\n    unit_scale: str = \"metre\",\n    **kwargs,\n):\n    \"\"\"\n    Saves a series of Shape objects as a STEP assembly\n\n    Parameters\n    ----------\n    shapes:\n        List of shape objects to be saved\n    filename:\n        Full path filename of the STP assembly\n    unit_scale:\n        The scale in which to save the Shape objects\n    \"\"\"\n    filename = force_file_extension(filename, [\".stp\", \".step\"])\n\n    if not isinstance(shapes, list):\n        shapes = [shapes]\n\n    cadapi.save_as_STP([s.shape for s in shapes], filename, unit_scale, **kwargs)",
  "def save_cad(\n    shapes: Union[BluemiraGeo, List[BluemiraGeo]],\n    filename: str,\n    cad_format: Union[str, cadapi.CADFileType] = \"stp\",\n    names: Optional[Union[str, List[str]]] = None,\n    **kwargs,\n):\n    \"\"\"\n    Save the CAD of a component (eg a reactor) or a list of components\n\n    Parameters\n    ----------\n    shapes:\n        shapes to save\n    filename:\n        Full path filename of the STP assembly\n    cad_format:\n        file format to save as\n    names:\n        Names of shapes to save\n    kwargs:\n        arguments passed to cadapi save function\n    \"\"\"\n    if kw_formatt := kwargs.pop(\"formatt\", None):\n        warn(\n            \"Using kwarg 'formatt' is no longer supported. Use cad_format instead.\",\n            category=DeprecationWarning,\n        )\n        cad_format = kw_formatt\n\n    if not isinstance(shapes, list):\n        shapes = [shapes]\n    if names is not None and not isinstance(names, list):\n        names = [names]\n\n    cadapi.save_cad(\n        [s.shape for s in shapes],\n        filename,\n        cad_format=cad_format,\n        labels=names,\n        **kwargs,\n    )",
  "def _nb_dot_2D(v_1, v_2):\n    \"\"\"\n    Numba 2-D dot product\n    \"\"\"\n    return v_1[0] * v_2[0] + v_1[1] * v_2[1]",
  "def _nb_clip(val, a_min, a_max):\n    \"\"\"\n    Numba 1-D clip\n    \"\"\"\n    return a_min if val < a_min else a_max if val > a_max else val",
  "def _signed_distance_2D(point: np.ndarray, polygon: np.ndarray) -> float:\n    \"\"\"\n    2-D function for the signed distance from a point to a polygon. The return value is\n    negative if the point is outside the polygon, and positive if the point is inside the\n    polygon.\n\n    Parameters\n    ----------\n    point:\n        2-D point\n    polygon:\n        2-D set of points (closed)\n\n    Returns\n    -------\n    Signed distance value of the point to the polygon\n\n    Notes\n    -----\n    Credit: Inigo Quilez (https://www.iquilezles.org/)\n    \"\"\"\n    sign = -1.0\n    point = np.asfarray(point)\n    polygon = np.asfarray(polygon)\n    n = len(polygon)\n\n    d = _nb_dot_2D(point - polygon[0], point - polygon[0])\n\n    for i in range(n - 1):\n        j = i + 1\n        e = polygon[j] - polygon[i]\n        w = point - polygon[i]\n        b = w - e * _nb_clip(_nb_dot_2D(w, e) / _nb_dot_2D(e, e), 0.0, 1.0)\n        d_new = _nb_dot_2D(b, b)\n        if d_new < d:\n            d = d_new\n\n        cond = np.array(\n            [\n                point[1] >= polygon[i][1],\n                point[1] < polygon[j][1],\n                e[0] * w[1] > e[1] * w[0],\n            ]\n        )\n        if np.all(cond) or np.all(~cond):\n            sign = -sign\n\n    return sign * np.sqrt(d)",
  "def signed_distance_2D_polygon(\n    subject_poly: np.ndarray, target_poly: np.ndarray\n) -> np.ndarray:\n    \"\"\"\n    2-D vector-valued signed distance function from a subject polygon to a target\n    polygon. The return values are negative for points outside the target polygon, and\n    positive for points inside the target polygon.\n\n    Parameters\n    ----------\n    subject_poly:\n        Subject 2-D polygon\n    target_poly:\n        Target 2-D polygon (closed polygons only)\n\n    Returns\n    -------\n    Signed distances from the vertices of the subject polygon to the target polygon\n\n    Notes\n    -----\n    This can used as a keep-out-zone constraint, in which the target polygon would\n    be the keep-out-zone, and the subject polygon would be the shape which must\n    be outsize of the keep-out-zone.\n\n    The target polygon must be closed.\n    \"\"\"\n    m = len(subject_poly)\n    d = np.zeros(m)\n\n    for i in range(m):\n        d[i] = _signed_distance_2D(subject_poly[i], target_poly)\n\n    return d",
  "def signed_distance(wire_1: BluemiraWire, wire_2: BluemiraWire) -> float:\n    \"\"\"\n    Single-valued signed \"distance\" function between two wires. Will return negative\n    values if wire_1 does not touch or intersect wire_2, 0 if there is one intersection,\n    and a positive estimate of the intersection length if there are overlaps.\n\n    Parameters\n    ----------\n    wire_1:\n        Subject wire\n    wire_2:\n        Target wire\n\n    Returns\n    -------\n    Signed distance from wire_1 to wire_2\n\n    Notes\n    -----\n    This is not a pure implementation of a distance function, as for overlapping wires a\n    metric of the quantity of overlap is returned (a positive value). This nevertheless\n    enables the use of such a function as a constraint in gradient-based optimisers.\n    \"\"\"\n    d, vectors = distance_to(wire_1, wire_2)\n\n    if d == 0.0:  # Intersections are exactly 0.0\n        if len(vectors) <= 1:\n            # There is only one intersection: the wires are touching but not overlapping\n            return 0.0\n        else:\n            # There are multiple intersections: the wires are overlapping\n            # For now, without boolean operations, get an estimate of the intersection\n            # length\n            length = 0\n            for i in range(1, len(vectors)):\n                p1 = vectors[i - 1][0]\n                p2 = vectors[i][0]\n\n                length += np.sqrt(\n                    (p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2 + (p2[2] - p1[2]) ** 2\n                )\n\n            # TODO: Use a boolean difference operation to get the lengths of the\n            # overlapping wire segment(s)\n            return length\n    else:\n        # There are no intersections, return minimum distance\n        return -d",
  "def boolean_fuse(shapes: Iterable[BluemiraGeo], label: str = \"\") -> BluemiraGeo:\n    \"\"\"\n    Fuse two or more shapes together. Internal splitter are removed.\n\n    Parameters\n    ----------\n    shapes:\n        List of shape objects to be saved\n    label:\n        Label for the resulting shape\n\n    Returns\n    -------\n    Result of the boolean operation.\n\n    Raises\n    ------\n    error: GeometryError\n        In case the boolean operation fails.\n    \"\"\"\n    if not isinstance(shapes, list):\n        raise ValueError(f\"{shapes} is not a list.\")\n\n    if len(shapes) < 2:\n        raise ValueError(\"At least 2 shapes must be given\")\n\n    # check that all the shapes are of the same time\n    _type = type(shapes[0])\n    if not all(isinstance(s, _type) for s in shapes):\n        raise ValueError(f\"All instances in {shapes} must be of the same type.\")\n\n    api_shapes = [s.shape for s in shapes]\n    try:\n        merged_shape = cadapi.boolean_fuse(api_shapes)\n        return convert(merged_shape, label)\n\n    except Exception as e:\n        raise GeometryError(f\"Boolean fuse operation failed: {e}\")",
  "def boolean_cut(\n    shape: BluemiraGeo, tools: Iterable[BluemiraGeo]\n) -> Iterable[BluemiraGeo]:\n    \"\"\"\n    Difference of shape and a given (list of) topo shape cut(tools)\n\n    Parameters\n    ----------\n    shape:\n        the reference object\n    tools:\n        List of BluemiraGeo shape objects to be used as tools.\n\n    Returns\n    -------\n    Result of the boolean cut operation.\n\n    Raises\n    ------\n    error: GeometryError\n        In case the boolean operation fails.\n    \"\"\"\n    apishape = shape.shape\n    if not isinstance(tools, list):\n        tools = [tools]\n    apitools = [t.shape for t in tools]\n    cut_shape = cadapi.boolean_cut(apishape, apitools)\n\n    if isinstance(cut_shape, Iterable):\n        return [convert(obj, shape.label) for obj in cut_shape]\n\n    return convert(cut_shape, shape.label)",
  "def boolean_fragments(\n    shapes: List[BluemiraSolid], tolerance: float = 0.0\n) -> Tuple[BluemiraCompound, List[List[BluemiraSolid]]]:\n    \"\"\"\n    Split a list of shapes into their Boolean fragments.\n\n    Parameters\n    ----------\n    shapes:\n        List of BluemiraSolids to be split into Boolean fragments\n    tolerance:\n        Tolerance with which to perform the operation\n\n    Returns\n    -------\n    compound:\n        A compound of the unique fragments\n    fragment_map:\n        An ordered list of groups of solid Boolean fragments (ordered in terms of\n        input ordering)\n\n    Notes\n    -----\n    Labelling will be lost.\n    This function is only tested on solids.\n    \"\"\"\n    compound, fragment_map = cadapi.boolean_fragments(\n        [s.shape for s in shapes], tolerance\n    )\n    converted = []\n    for group in fragment_map:\n        converted.append([convert(s) for s in group])\n\n    return convert(compound), converted",
  "def point_inside_shape(point: Iterable[float], shape: BluemiraGeo) -> bool:\n    \"\"\"\n    Check whether or not a point is inside a shape.\n\n    Parameters\n    ----------\n    point:\n        Coordinates of the point\n    shape:\n        Geometry to check with\n\n    Returns\n    -------\n    Whether or not the point is inside the shape\n    \"\"\"\n    return cadapi.point_inside_shape(point, shape.shape)",
  "def point_on_plane(\n    point: Iterable[float], plane: BluemiraPlane, tolerance: float = D_TOLERANCE\n) -> bool:\n    \"\"\"\n    Check whether or not a point is on a plane.\n\n    Parameters\n    ----------\n    point:\n        Coordinates of the point\n    plane:\n        Plane to check\n    tolerance:\n        Tolerance with which to check\n\n    Returns\n    -------\n    Whether or not the point is on the plane\n    \"\"\"\n    return (\n        abs(\n            cadapi.apiVector(point).distanceToPlane(\n                plane.shape.Position, plane.shape.Axis\n            )\n        )\n        < tolerance\n    )",
  "def serialize_shape(shape: BluemiraGeo):\n    \"\"\"\n    Serialize a BluemiraGeo object.\n    \"\"\"\n    type_ = type(shape)\n\n    output = []\n    if isinstance(shape, BluemiraGeo):\n        sdict = {\"label\": shape.label, \"boundary\": output}\n        for obj in shape.boundary:\n            output.append(serialize_shape(obj))\n            if isinstance(shape, GeoMeshable) and shape.mesh_options is not None:\n                if shape.mesh_options.lcar is not None:\n                    sdict[\"lcar\"] = shape.mesh_options.lcar\n                if shape.mesh_options.physical_group is not None:\n                    sdict[\"physical_group\"] = shape.mesh_options.physical_group\n        return {str(type(shape).__name__): sdict}\n    elif isinstance(shape, cadapi.apiWire):\n        return cadapi.serialize_shape(shape)\n    else:\n        raise NotImplementedError(f\"Serialization non implemented for {type_}\")",
  "def deserialize_shape(buffer: dict):\n    \"\"\"\n    Deserialize a BluemiraGeo object obtained from serialize_shape.\n\n    Parameters\n    ----------\n    buffer:\n        Object serialization as stored by serialize_shape\n\n    Returns\n    -------\n    The deserialized BluemiraGeo object.\n    \"\"\"\n    supported_types = [BluemiraWire, BluemiraFace, BluemiraShell]\n\n    def _extract_mesh_options(shape_dict: dict):\n        mesh_options = None\n        if \"lcar\" in shape_dict:\n            mesh_options = meshing.MeshOptions()\n            mesh_options.lcar = shape_dict[\"lcar\"]\n        if \"physical_group\" in shape_dict:\n            mesh_options = mesh_options or meshing.MeshOptions()\n            mesh_options.physical_group = shape_dict[\"physical_group\"]\n        return mesh_options\n\n    def _extract_shape(shape_dict: dict, shape_type: Type[BluemiraGeo]):\n        label = shape_dict[\"label\"]\n        boundary = shape_dict[\"boundary\"]\n\n        temp_list = []\n        for item in boundary:\n            if issubclass(shape_type, BluemiraWire):\n                for k in item:\n                    if k == shape_type.__name__:\n                        shape = deserialize_shape(item)\n                    else:\n                        shape = cadapi.deserialize_shape(item)\n                    temp_list.append(shape)\n            else:\n                temp_list.append(deserialize_shape(item))\n\n        mesh_options = _extract_mesh_options(shape_dict)\n\n        shape = shape_type(label=label, boundary=temp_list)\n        if mesh_options is not None:\n            shape.mesh_options = mesh_options\n        return shape\n\n    for type_, v in buffer.items():\n        for supported_types in supported_types:\n            if type_ == supported_types.__name__:\n                return _extract_shape(v, BluemiraWire)\n\n        raise NotImplementedError(f\"Deserialization non implemented for {type_}\")",
  "def get_shape_by_name(shape: BluemiraGeo, name: str) -> List[BluemiraGeo]:\n    \"\"\"\n    Search through the boundary of the shape and get any shapes with a label\n    corresponding to the provided name. Includes the shape itself if the name matches\n    its label.\n\n    Parameters\n    ----------\n    shape:\n        The shape to search for the provided name.\n    name:\n        The name to search for.\n\n    Returns\n    -------\n    The shapes known to the provided shape that correspond to the provided name.\n    \"\"\"\n    shapes = []\n    if hasattr(shape, \"label\") and shape.label == name:\n        shapes.append(shape)\n    if hasattr(shape, \"boundary\"):\n        for o in shape.boundary:\n            shapes += get_shape_by_name(o, name)\n    return shapes",
  "def find_clockwise_angle_2d(base: np.ndarray, vector: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Find the clockwise angle between the 2D vectors ``base`` and\n    ``vector`` in the range [0\u00b0, 360\u00b0).\n\n    Parameters\n    ----------\n    base:\n        The vector to start the angle from.\n    vector:\n        The vector to end the angle at.\n\n    Returns\n    -------\n    The clockwise angle between the two vectors in degrees.\n    \"\"\"\n    if not isinstance(base, np.ndarray) or not isinstance(vector, np.ndarray):\n        raise TypeError(\n            f\"Input vectors must have type np.ndarray, found '{type(base)}' and \"\n            f\"'{type(vector)}'.\"\n        )\n    if base.shape[0] != 2 or vector.shape[0] != 2:\n        raise ValueError(\n            f\"Input vectors' axis 0 length must be 2, found shapes '{base.shape}' and \"\n            f\"'{vector.shape}'.\"\n        )\n    det = base[1] * vector[0] - base[0] * vector[1]\n    dot = np.dot(base, vector)\n    # Convert to array here in case arctan2 returns a scalar\n    angle = np.array(np.arctan2(det, dot))\n    angle[angle < 0] += 2 * np.pi\n    return np.degrees(angle)",
  "def default(self, obj: Union[BluemiraGeo, np.ndarray, Any]):\n        \"\"\"\n        Override the JSONEncoder default object handling behaviour for BluemiraGeo.\n        \"\"\"\n        if isinstance(obj, BluemiraGeo):\n            return serialize_shape(obj)\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        return super().default(obj)",
  "def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except cadapi.FreeCADError as error:\n            data = _reconstruct_function_call(signature, *args, **kwargs)\n            filename = _make_debug_file(func_name)\n\n            # Dump the data in the file\n            try:\n                with open(filename, \"w\") as file:\n                    json.dump(data, file, indent=4, cls=BluemiraGeoEncoder)\n\n                bluemira_debug(\n                    f\"Function call {func_name} failed. Debugging information was saved to: {filename}\"\n                )\n            except Exception:\n                bluemira_warn(\n                    f\"Failed to save the failed geometry operation {func_name} to JSON.\"\n                )\n\n            raise error",
  "def decorator(func):\n        def wrapper(*args, **kwargs):\n            try:\n                return func(*args, **kwargs)\n            except exception:\n                bluemira_warn(\n                    f\"{func.__name__} failed, falling back to {fallback_func.__name__}.\"\n                )\n                return fallback_func(*args, **kwargs)\n\n        return wrapper",
  "def decorator(func: Callable):\n        def wrapper(\n            points: Union[list, np.ndarray, Dict], label: str = \"\", closed: bool = False\n        ):\n            points = Coordinates(points)\n            if points.closed:\n                if closed is False:\n                    bluemira_warn(\n                        f\"{func.__name__}: input points are closed but closed=False, defaulting to closed=True.\"\n                    )\n                closed = True\n                if drop_closure_point:\n                    points = Coordinates(points.xyz[:, :-1])\n            wire = func(points, label=label, closed=closed)\n            if closed:\n                wire = cadapi.close_wire(wire)\n            return BluemiraWire(wire, label=label)\n\n        wrapper.__doc__ = func.__doc__\n        return wrapper",
  "def decorator(func):\n        @functools.wraps(func)\n        def wrapper(wire, radius):\n            edges = wire.shape.OrderedEdges\n            func_name = \"chamfer\" if chamfer else \"fillet\"\n            if len(edges) < 2:\n                raise GeometryError(f\"Cannot {func_name} a wire with less than 2 edges!\")\n            if not cadapi._wire_is_planar(wire.shape):\n                raise GeometryError(f\"Cannot {func_name} a non-planar wire!\")\n            if radius == 0:\n                return wire.deepcopy()\n            if radius < 0:\n                raise GeometryError(\n                    f\"Cannot {func_name} a wire with a negative {radius=}\"\n                )\n            return func(wire, radius)\n\n        return wrapper",
  "def _extract_mesh_options(shape_dict: dict):\n        mesh_options = None\n        if \"lcar\" in shape_dict:\n            mesh_options = meshing.MeshOptions()\n            mesh_options.lcar = shape_dict[\"lcar\"]\n        if \"physical_group\" in shape_dict:\n            mesh_options = mesh_options or meshing.MeshOptions()\n            mesh_options.physical_group = shape_dict[\"physical_group\"]\n        return mesh_options",
  "def _extract_shape(shape_dict: dict, shape_type: Type[BluemiraGeo]):\n        label = shape_dict[\"label\"]\n        boundary = shape_dict[\"boundary\"]\n\n        temp_list = []\n        for item in boundary:\n            if issubclass(shape_type, BluemiraWire):\n                for k in item:\n                    if k == shape_type.__name__:\n                        shape = deserialize_shape(item)\n                    else:\n                        shape = cadapi.deserialize_shape(item)\n                    temp_list.append(shape)\n            else:\n                temp_list.append(deserialize_shape(item))\n\n        mesh_options = _extract_mesh_options(shape_dict)\n\n        shape = shape_type(label=label, boundary=temp_list)\n        if mesh_options is not None:\n            shape.mesh_options = mesh_options\n        return shape",
  "def wrapper(*args, **kwargs):\n            try:\n                return func(*args, **kwargs)\n            except exception:\n                bluemira_warn(\n                    f\"{func.__name__} failed, falling back to {fallback_func.__name__}.\"\n                )\n                return fallback_func(*args, **kwargs)",
  "def wrapper(\n            points: Union[list, np.ndarray, Dict], label: str = \"\", closed: bool = False\n        ):\n            points = Coordinates(points)\n            if points.closed:\n                if closed is False:\n                    bluemira_warn(\n                        f\"{func.__name__}: input points are closed but closed=False, defaulting to closed=True.\"\n                    )\n                closed = True\n                if drop_closure_point:\n                    points = Coordinates(points.xyz[:, :-1])\n            wire = func(points, label=label, closed=closed)\n            if closed:\n                wire = cadapi.close_wire(wire)\n            return BluemiraWire(wire, label=label)",
  "def wrapper(wire, radius):\n            edges = wire.shape.OrderedEdges\n            func_name = \"chamfer\" if chamfer else \"fillet\"\n            if len(edges) < 2:\n                raise GeometryError(f\"Cannot {func_name} a wire with less than 2 edges!\")\n            if not cadapi._wire_is_planar(wire.shape):\n                raise GeometryError(f\"Cannot {func_name} a non-planar wire!\")\n            if radius == 0:\n                return wire.deepcopy()\n            if radius < 0:\n                raise GeometryError(\n                    f\"Cannot {func_name} a wire with a negative {radius=}\"\n                )\n            return func(wire, radius)",
  "class BluemiraFace(BluemiraGeo):\n    \"\"\"\n    Bluemira Face class.\n\n    Parameters\n    ----------\n    boundary:\n        List of BluemiraWires to use to make the face\n    label:\n        Label to assign to the BluemiraFace\n    \"\"\"\n\n    def __init__(self, boundary: List[BluemiraWire], label: str = \"\"):\n        boundary_classes = [BluemiraWire]\n        super().__init__(boundary, label, boundary_classes)\n\n    @staticmethod\n    def _converter(func):\n        def wrapper(*args, **kwargs):\n            output = func(*args, **kwargs)\n            if isinstance(output, cadapi.apiWire):\n                output = BluemiraWire(output)\n            if isinstance(output, cadapi.apiFace):\n                output = BluemiraFace._create(output)\n            return output\n\n        return wrapper\n\n    def copy(self):\n        \"\"\"Make a copy of the BluemiraFace\"\"\"\n        return BluemiraFace(self.boundary, self.label)\n\n    def deepcopy(self, label: Optional[str] = None):\n        \"\"\"Make a copy of the BluemiraFace\"\"\"\n        boundary = []\n        for o in self.boundary:\n            boundary += [o.deepcopy(o.label)]\n        geo_copy = BluemiraFace(boundary)\n        if label is not None:\n            geo_copy.label = label\n        else:\n            geo_copy.label = self.label\n        return geo_copy\n\n    def _check_boundary(self, objs):\n        \"\"\"Check if objects in objs are of the correct type for this class\"\"\"\n        if objs is None:\n            return objs\n\n        if not hasattr(objs, \"__len__\"):\n            objs = [objs]\n        check = False\n        for c in self._boundary_classes:\n            for o in objs:\n                check = check or isinstance(o, c)\n            if check:\n                if all(o.is_closed() for o in objs):\n                    return objs\n                else:\n                    raise NotClosedWire(\"Only closed BluemiraWire are accepted.\")\n        raise TypeError(\n            f\"Only {self._boundary_classes} objects can be used for {self.__class__}\"\n        )\n\n    def _create_face(self, check_reverse: bool = True):\n        \"\"\"Create the primitive face\"\"\"\n        external: BluemiraWire = self.boundary[0]\n        face = cadapi.apiFace(external._create_wire(check_reverse=False))\n\n        if len(self.boundary) > 1:\n            fholes = [cadapi.apiFace(h.shape) for h in self.boundary[1:]]\n            face = face.cut(fholes)\n            if len(face.Faces) == 1:\n                face = face.Faces[0]\n            else:\n                raise DisjointedFace(\"Any or more than one face has been created.\")\n\n        if check_reverse:\n            return self._check_reverse(face)\n        else:\n            return face\n\n    def _create_shape(self) -> cadapi.apiFace:\n        \"\"\"Part.Face: shape of the object as a primitive face\"\"\"\n        return self._create_face()\n\n    @classmethod\n    def _create(cls, obj: cadapi.apiFace, label=\"\") -> BluemiraFace:\n        if isinstance(obj, cadapi.apiFace):\n            bmwires = []\n            for w in obj.Wires:\n                w_orientation = w.Orientation\n                bm_wire = BluemiraWire(w)\n                bm_wire._orientation = w_orientation\n                if cadapi.is_closed(w):\n                    bm_wire.close()\n                bmwires += [bm_wire]\n\n            bmface = cls(None, label=label)\n            bmface._set_shape(obj)\n            bmface._boundary = bmwires\n            bmface._orientation = obj.Orientation\n\n            return bmface\n\n        raise TypeError(f\"Only Part.Face objects can be used to create a {cls} instance\")\n\n    def discretize(\n        self, ndiscr: int = 100, byedges: bool = False, dl: float = None\n    ) -> np.ndarray:\n        \"\"\"\n        Make an array of the geometry.\n\n        Parameters\n        ----------\n        ndiscr:\n            Number of points in the array\n        byedges:\n            Whether or not to discretise by edges\n        dl:\n            Optional length discretisation (overrides ndiscr)\n\n        Returns\n        -------\n        (M, (3, N)) array of point coordinates where M is the number of boundaries\n        and N the number of discretization points.\n        \"\"\"\n        points = []\n        for w in self.shape.Wires:\n            if byedges:\n                points.append(cadapi.discretize_by_edges(w, ndiscr=ndiscr, dl=dl))\n            else:\n                points.append(cadapi.discretize(w, ndiscr=ndiscr, dl=dl))\n        return points\n\n    def normal_at(self, alpha_1: float = 0.0, alpha_2: float = 0.0) -> np.ndarray:\n        \"\"\"\n        Get the normal vector of the face at a parameterised point in space. For\n        planar faces, the normal is the same everywhere.\n        \"\"\"\n        return cadapi.normal_at(self.shape, alpha_1, alpha_2)\n\n    @property\n    def vertexes(self) -> Coordinates:\n        \"\"\"\n        The vertexes of the face.\n        \"\"\"\n        return Coordinates(cadapi.vertexes(self.shape))\n\n    @property\n    def edges(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The edges of the face.\n        \"\"\"\n        return tuple([BluemiraWire(cadapi.apiWire(o)) for o in cadapi.edges(self.shape)])\n\n    @property\n    def wires(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The wires of the face.\n        \"\"\"\n        return tuple([BluemiraWire(o) for o in cadapi.wires(self.shape)])\n\n    @property\n    def faces(self) -> Tuple[BluemiraFace]:\n        \"\"\"\n        The faces of the face. By definition a tuple of itself.\n        \"\"\"\n        return tuple([self])\n\n    @property\n    def shells(self) -> tuple:\n        \"\"\"\n        The shells of the face. By definition an empty tuple.\n        \"\"\"\n        return ()\n\n    @property\n    def solids(self) -> tuple:\n        \"\"\"\n        The solids of the face. By definition an empty tuple.\n        \"\"\"\n        return ()",
  "def __init__(self, boundary: List[BluemiraWire], label: str = \"\"):\n        boundary_classes = [BluemiraWire]\n        super().__init__(boundary, label, boundary_classes)",
  "def _converter(func):\n        def wrapper(*args, **kwargs):\n            output = func(*args, **kwargs)\n            if isinstance(output, cadapi.apiWire):\n                output = BluemiraWire(output)\n            if isinstance(output, cadapi.apiFace):\n                output = BluemiraFace._create(output)\n            return output\n\n        return wrapper",
  "def copy(self):\n        \"\"\"Make a copy of the BluemiraFace\"\"\"\n        return BluemiraFace(self.boundary, self.label)",
  "def deepcopy(self, label: Optional[str] = None):\n        \"\"\"Make a copy of the BluemiraFace\"\"\"\n        boundary = []\n        for o in self.boundary:\n            boundary += [o.deepcopy(o.label)]\n        geo_copy = BluemiraFace(boundary)\n        if label is not None:\n            geo_copy.label = label\n        else:\n            geo_copy.label = self.label\n        return geo_copy",
  "def _check_boundary(self, objs):\n        \"\"\"Check if objects in objs are of the correct type for this class\"\"\"\n        if objs is None:\n            return objs\n\n        if not hasattr(objs, \"__len__\"):\n            objs = [objs]\n        check = False\n        for c in self._boundary_classes:\n            for o in objs:\n                check = check or isinstance(o, c)\n            if check:\n                if all(o.is_closed() for o in objs):\n                    return objs\n                else:\n                    raise NotClosedWire(\"Only closed BluemiraWire are accepted.\")\n        raise TypeError(\n            f\"Only {self._boundary_classes} objects can be used for {self.__class__}\"\n        )",
  "def _create_face(self, check_reverse: bool = True):\n        \"\"\"Create the primitive face\"\"\"\n        external: BluemiraWire = self.boundary[0]\n        face = cadapi.apiFace(external._create_wire(check_reverse=False))\n\n        if len(self.boundary) > 1:\n            fholes = [cadapi.apiFace(h.shape) for h in self.boundary[1:]]\n            face = face.cut(fholes)\n            if len(face.Faces) == 1:\n                face = face.Faces[0]\n            else:\n                raise DisjointedFace(\"Any or more than one face has been created.\")\n\n        if check_reverse:\n            return self._check_reverse(face)\n        else:\n            return face",
  "def _create_shape(self) -> cadapi.apiFace:\n        \"\"\"Part.Face: shape of the object as a primitive face\"\"\"\n        return self._create_face()",
  "def _create(cls, obj: cadapi.apiFace, label=\"\") -> BluemiraFace:\n        if isinstance(obj, cadapi.apiFace):\n            bmwires = []\n            for w in obj.Wires:\n                w_orientation = w.Orientation\n                bm_wire = BluemiraWire(w)\n                bm_wire._orientation = w_orientation\n                if cadapi.is_closed(w):\n                    bm_wire.close()\n                bmwires += [bm_wire]\n\n            bmface = cls(None, label=label)\n            bmface._set_shape(obj)\n            bmface._boundary = bmwires\n            bmface._orientation = obj.Orientation\n\n            return bmface\n\n        raise TypeError(f\"Only Part.Face objects can be used to create a {cls} instance\")",
  "def discretize(\n        self, ndiscr: int = 100, byedges: bool = False, dl: float = None\n    ) -> np.ndarray:\n        \"\"\"\n        Make an array of the geometry.\n\n        Parameters\n        ----------\n        ndiscr:\n            Number of points in the array\n        byedges:\n            Whether or not to discretise by edges\n        dl:\n            Optional length discretisation (overrides ndiscr)\n\n        Returns\n        -------\n        (M, (3, N)) array of point coordinates where M is the number of boundaries\n        and N the number of discretization points.\n        \"\"\"\n        points = []\n        for w in self.shape.Wires:\n            if byedges:\n                points.append(cadapi.discretize_by_edges(w, ndiscr=ndiscr, dl=dl))\n            else:\n                points.append(cadapi.discretize(w, ndiscr=ndiscr, dl=dl))\n        return points",
  "def normal_at(self, alpha_1: float = 0.0, alpha_2: float = 0.0) -> np.ndarray:\n        \"\"\"\n        Get the normal vector of the face at a parameterised point in space. For\n        planar faces, the normal is the same everywhere.\n        \"\"\"\n        return cadapi.normal_at(self.shape, alpha_1, alpha_2)",
  "def vertexes(self) -> Coordinates:\n        \"\"\"\n        The vertexes of the face.\n        \"\"\"\n        return Coordinates(cadapi.vertexes(self.shape))",
  "def edges(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The edges of the face.\n        \"\"\"\n        return tuple([BluemiraWire(cadapi.apiWire(o)) for o in cadapi.edges(self.shape)])",
  "def wires(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The wires of the face.\n        \"\"\"\n        return tuple([BluemiraWire(o) for o in cadapi.wires(self.shape)])",
  "def faces(self) -> Tuple[BluemiraFace]:\n        \"\"\"\n        The faces of the face. By definition a tuple of itself.\n        \"\"\"\n        return tuple([self])",
  "def shells(self) -> tuple:\n        \"\"\"\n        The shells of the face. By definition an empty tuple.\n        \"\"\"\n        return ()",
  "def solids(self) -> tuple:\n        \"\"\"\n        The solids of the face. By definition an empty tuple.\n        \"\"\"\n        return ()",
  "def wrapper(*args, **kwargs):\n            output = func(*args, **kwargs)\n            if isinstance(output, cadapi.apiWire):\n                output = BluemiraWire(output)\n            if isinstance(output, cadapi.apiFace):\n                output = BluemiraFace._create(output)\n            return output",
  "class BluemiraSolid(BluemiraGeo):\n    \"\"\"\n    Bluemira Solid class.\n\n    Parameters\n    ----------\n    boundary:\n        List of shells from  which to make the BluemiraSolid\n    label:\n        Label to assign to the solid\n    \"\"\"\n\n    def __init__(self, boundary: List[BluemiraShell], label: str = \"\"):\n        boundary_classes = [BluemiraShell]\n        super().__init__(boundary, label, boundary_classes)\n\n    def _create_solid(self, check_reverse: bool = True):\n        \"\"\"Creation of the solid\"\"\"\n        new_shell = self.boundary[0]._create_shell(check_reverse=False)\n        solid = cadapi.apiSolid(new_shell)\n\n        if len(self.boundary) > 1:\n            shell_holes = [cadapi.apiSolid(s.shape) for s in self.boundary[1:]]\n            solid = solid.cut(shell_holes)\n            if len(solid.Solids) == 1:\n                solid = solid.Solids[0]\n            else:\n                raise DisjointedSolid(\"Disjointed solids are not accepted.\")\n\n        if check_reverse:\n            return self._check_reverse(cadapi.apiSolid(solid))\n        else:\n            return solid\n\n    def _create_shape(self):\n        \"\"\"Part.Solid: shape of the object as a single solid\"\"\"\n        return self._create_solid()\n\n    @classmethod\n    def _create(cls, obj: cadapi.apiSolid, label: str = \"\"):\n        if isinstance(obj, cadapi.apiSolid):\n            if len(obj.Solids) > 1:\n                raise DisjointedSolid(\"Disjointed solids are not accepted.\")\n\n            if not obj.isValid():\n                # cadapi.save_as_STP(obj, \"object_not_valid\")\n                raise GeometryError(f\"Solid {obj} is not valid.\")\n\n            bm_shells = []\n            for shell in obj.Shells:\n                bm_shells.append(BluemiraShell._create(shell))\n\n            # create an empty BluemiraSolid\n            bmsolid = cls(None, label=label)\n            # assign shape, boundary, and orientation\n            bmsolid._set_shape(obj)\n            bmsolid._boundary = bm_shells\n            bmsolid._orientation = obj.Orientation\n            return bmsolid\n\n        raise TypeError(\n            f\"Only Part.Solid objects can be used to create a {cls} instance\"\n        )\n\n    @property\n    def vertexes(self) -> Coordinates:\n        \"\"\"\n        The vertexes of the solid.\n        \"\"\"\n        return Coordinates(cadapi.vertexes(self.shape))\n\n    @property\n    def edges(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The edges of the solid.\n        \"\"\"\n        return tuple([BluemiraWire(cadapi.apiWire(o)) for o in cadapi.edges(self.shape)])\n\n    @property\n    def wires(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The wires of the solid.\n        \"\"\"\n        return tuple([BluemiraWire(o) for o in cadapi.wires(self.shape)])\n\n    @property\n    def faces(self) -> Tuple[BluemiraFace]:\n        \"\"\"\n        The faces of the solid.\n        \"\"\"\n        return tuple([BluemiraFace._create(o) for o in cadapi.faces(self.shape)])\n\n    @property\n    def shells(self) -> Tuple[BluemiraShell]:\n        \"\"\"\n        The shells of the solid.\n        \"\"\"\n        return tuple([BluemiraShell._create(o) for o in cadapi.shells(self.shape)])\n\n    @property\n    def solids(self) -> Tuple[BluemiraSolid]:\n        \"\"\"\n        The solids of the solid. By definition a tuple of itself.\n        \"\"\"\n        return tuple([self])",
  "def __init__(self, boundary: List[BluemiraShell], label: str = \"\"):\n        boundary_classes = [BluemiraShell]\n        super().__init__(boundary, label, boundary_classes)",
  "def _create_solid(self, check_reverse: bool = True):\n        \"\"\"Creation of the solid\"\"\"\n        new_shell = self.boundary[0]._create_shell(check_reverse=False)\n        solid = cadapi.apiSolid(new_shell)\n\n        if len(self.boundary) > 1:\n            shell_holes = [cadapi.apiSolid(s.shape) for s in self.boundary[1:]]\n            solid = solid.cut(shell_holes)\n            if len(solid.Solids) == 1:\n                solid = solid.Solids[0]\n            else:\n                raise DisjointedSolid(\"Disjointed solids are not accepted.\")\n\n        if check_reverse:\n            return self._check_reverse(cadapi.apiSolid(solid))\n        else:\n            return solid",
  "def _create_shape(self):\n        \"\"\"Part.Solid: shape of the object as a single solid\"\"\"\n        return self._create_solid()",
  "def _create(cls, obj: cadapi.apiSolid, label: str = \"\"):\n        if isinstance(obj, cadapi.apiSolid):\n            if len(obj.Solids) > 1:\n                raise DisjointedSolid(\"Disjointed solids are not accepted.\")\n\n            if not obj.isValid():\n                # cadapi.save_as_STP(obj, \"object_not_valid\")\n                raise GeometryError(f\"Solid {obj} is not valid.\")\n\n            bm_shells = []\n            for shell in obj.Shells:\n                bm_shells.append(BluemiraShell._create(shell))\n\n            # create an empty BluemiraSolid\n            bmsolid = cls(None, label=label)\n            # assign shape, boundary, and orientation\n            bmsolid._set_shape(obj)\n            bmsolid._boundary = bm_shells\n            bmsolid._orientation = obj.Orientation\n            return bmsolid\n\n        raise TypeError(\n            f\"Only Part.Solid objects can be used to create a {cls} instance\"\n        )",
  "def vertexes(self) -> Coordinates:\n        \"\"\"\n        The vertexes of the solid.\n        \"\"\"\n        return Coordinates(cadapi.vertexes(self.shape))",
  "def edges(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The edges of the solid.\n        \"\"\"\n        return tuple([BluemiraWire(cadapi.apiWire(o)) for o in cadapi.edges(self.shape)])",
  "def wires(self) -> Tuple[BluemiraWire]:\n        \"\"\"\n        The wires of the solid.\n        \"\"\"\n        return tuple([BluemiraWire(o) for o in cadapi.wires(self.shape)])",
  "def faces(self) -> Tuple[BluemiraFace]:\n        \"\"\"\n        The faces of the solid.\n        \"\"\"\n        return tuple([BluemiraFace._create(o) for o in cadapi.faces(self.shape)])",
  "def shells(self) -> Tuple[BluemiraShell]:\n        \"\"\"\n        The shells of the solid.\n        \"\"\"\n        return tuple([BluemiraShell._create(o) for o in cadapi.shells(self.shape)])",
  "def solids(self) -> Tuple[BluemiraSolid]:\n        \"\"\"\n        The solids of the solid. By definition a tuple of itself.\n        \"\"\"\n        return tuple([self])",
  "class GeomOptimiserResult(Generic[_GeomT]):\n    \"\"\"Container for the result of a geometry optimisation.\"\"\"\n\n    # Note that the attributes here are duplicates of those in\n    # 'OptimiserResult`. This is because, until Python 3.10, you cannot\n    # extend dataclasses with default values through inheritance:\n    # https://stackoverflow.com/a/53085935.\n    # Once we're on Python 3.10, we can use `the `kw_only` argument of\n    # `dataclass` to tidy this up.\n    geom: _GeomT\n    \"\"\"The geometry parameterisation with optimised parameters.\"\"\"\n    f_x: float\n    \"\"\"The evaluation of the optimised parameterisation.\"\"\"\n    n_evals: int\n    \"\"\"The number of evaluations of the objective function in the optimisation.\"\"\"\n    history: List[Tuple[np.ndarray, float]] = field(repr=False)\n    \"\"\"The history of the parametrisation at each iteration.\"\"\"\n    constraints_satisfied: Union[bool, None] = None\n    \"\"\"\n    Whether all constraints have been satisfied to within the required tolerance.\n\n    Is ``None`` if constraints have not been checked.\n    \"\"\"",
  "class KeepOutZoneDict(TypedDict):\n    \"\"\"Typing for a dict representing a keep-out zone for a geometry optimisation.\"\"\"\n\n    wire: BluemiraWire\n    \"\"\"Closed wire defining the keep-out zone.\"\"\"\n    byedges: NotRequired[bool]\n    \"\"\"Whether to discretize the keep-out zone by edges or not.\"\"\"\n    dl: NotRequired[Optional[float]]\n    \"\"\"\n    The discretization length for the keep-out zone.\n\n    This overrides ``n_discr`` if given.\n    \"\"\"\n    n_discr: NotRequired[int]\n    \"\"\"The number of points to discretise the wire into.\"\"\"\n    shape_n_discr: NotRequired[int]\n    \"\"\"The number of points to discretise the keep-out zone into.\"\"\"\n    tol: NotRequired[float]\n    \"\"\"The number of points to discretise the geometry being optimised into.\"\"\"",
  "def optimise_geometry(\n    geom: _GeomT,\n    f_objective: GeomOptimiserObjective,\n    df_objective: Optional[GeomOptimiserCallable] = None,\n    *,\n    keep_out_zones: Iterable[Union[BluemiraWire, KeepOutZoneDict, KeepOutZone]] = (),\n    algorithm: AlgorithmType = Algorithm.SLSQP,\n    opt_conditions: Optional[Mapping[str, Union[int, float]]] = None,\n    opt_parameters: Optional[Mapping[str, Any]] = None,\n    eq_constraints: Iterable[GeomConstraintT] = (),\n    ineq_constraints: Iterable[GeomConstraintT] = (),\n    keep_history: bool = False,\n    check_constraints: bool = True,\n    check_constraints_warn: bool = True,\n) -> GeomOptimiserResult[_GeomT]:\n    r\"\"\"\n    Minimise the given objective function for a geometry parameterisation.\n\n    Parameters\n    ----------\n    geom:\n        The geometry to optimise the parameters of. The existing\n        parameterisation is used as the initial guess in the\n        optimisation.\n    f_objective:\n        The objective function to minimise. Must take as an argument a\n        ``GeometryParameterisation`` and return a ``float``.\n    df_objective:\n        The derivative of the objective function, by default ``None``.\n        If not given, an approximation of the derivative is made using\n        the 'central differences' method.\n        This argument is ignored if a non-gradient based algorithm is\n        used.\n    keep_out_zones:\n        An iterable of keep-out zones: closed wires that the geometry\n        must not intersect.\n        Each item can be given as a :class:`.KeepOutZone`, or a\n        dictionary with keys the same as the properties of the\n        `:class:`.KeepOutZone` class, or just a :class:`.BluemiraWire`.\n    algorithm:\n        The optimisation algorithm to use, by default :obj:`.Algorithm.SLSQP`.\n    opt_conditions:\n        The stopping conditions for the optimiser. Supported conditions\n        are:\n\n            * ftol_abs: float\n            * ftol_rel: float\n            * xtol_abs: float\n            * xtol_rel: float\n            * max_eval: int\n            * max_time: float\n            * stop_val: float\n\n        for defaults see\n        :class:`~bluemira.optimisation._algorithm.AlgorithmDefaultConditions`.\n    opt_parameters:\n        The algorithm-specific optimisation parameters.\n    eq_constraints:\n        The equality constraints for the optimiser.\n        A dict with keys:\n\n        * f_constraint: the constraint function.\n        * tolerance: the tolerances in each constraint dimension.\n        * df_constraint (optional): the derivative of the constraint\n            function. If not given, a numerical approximation of the\n            gradient is made (if a gradient is required).\n\n        The constraint is a vector-valued, non-linear, equality\n        constraint of the form :math:`f_{c}(g) = 0`.\n\n        The constraint function should have the form\n        :math:`f(g) \\rightarrow y`, where:\n\n            * :math:`g` is a geometry parameterisation.\n            * :math:`y` is a numpy array containing the values of the\n              constraint at :math:`g`, with size :math:`m`, where\n              :math:`m` is the dimensionality of the constraint.\n\n\n        The tolerance array must have the same dimensionality as the\n        constraint.\n\n        The gradient function should have the same form as the\n        constraint function, however its output should have size\n        :math:`n \\times m` where, again, :math:`m` is the dimensionality\n        of the constraint and :math:`n` is the number of parameters in\n        the geometry parameterisation.\n\n        Equality constraints are only supported by algorithms:\n\n            * SLSQP\n            * COBYLA\n            * ISRES\n\n    ineq_constraints:\n        The geometric inequality constraints for the optimiser.\n        This argument has the same form as the ``eq_constraint``\n        argument, but each constraint is of the form\n        :math:`f_{c}(g) \\le 0`.\n\n        Inequality constraints are only supported by algorithms:\n\n            * SLSQP\n            * COBYLA\n            * ISRES\n\n    keep_history:\n        Whether or not to record the history of the optimisation\n        parameters at each iteration. Note that this can significantly\n        impact the performance of the optimisation.\n        (default: ``False``)\n    check_constraints:\n        Whether to check all constraints have been satisfied at the end\n        of the optimisation, and warn if they have not. Note that, if\n        this is set to False, the result's ``constraints_satisfied``\n        attribute will be set to ``None``.\n    check_constraints_warn:\n        Whether to print a warning that constraints have not been\n        satisfied at the end of an optimisation. This argument has no\n        effect if ``check_constraints`` is ``False``.\n\n    Returns\n    -------\n    The result of the optimisation.\n    \"\"\"\n    geom = copy.deepcopy(geom)\n    dimensions = geom.variables.n_free_variables\n    f_obj = _tools.to_objective(f_objective, geom)\n    if df_objective is not None:\n        df_obj = _tools.to_optimiser_callable(df_objective, geom)\n    else:\n        df_obj = None\n    ineq_constraints_list = []\n    for constraint in ineq_constraints:\n        ineq_constraints_list.append(constraint)\n    for zone in keep_out_zones:\n        ineq_constraints_list.append(_tools.make_keep_out_zone_constraint(_to_koz(zone)))\n\n    ineq_constraints = _tools.get_shape_ineq_constraint(geom) + [\n        _tools.to_constraint(c, geom) for c in ineq_constraints_list\n    ]\n    result = optimise(\n        f_obj,\n        dimensions=dimensions,\n        x0=geom.variables.get_normalised_values(),\n        df_objective=df_obj,\n        algorithm=algorithm,\n        opt_conditions=opt_conditions,\n        opt_parameters=opt_parameters,\n        bounds=(np.zeros(dimensions), np.ones(dimensions)),\n        eq_constraints=[_tools.to_constraint(c, geom) for c in eq_constraints],\n        ineq_constraints=ineq_constraints,\n        keep_history=keep_history,\n        check_constraints=check_constraints,\n        check_constraints_warn=check_constraints_warn,\n    )\n    # Make sure we update the geometry with the result, the last\n    # geometry update may not have been with the optimum result\n    geom.variables.set_values_from_norm(result.x)\n\n    result_dict = asdict(result)\n    result_dict.pop(\"x\")\n    return GeomOptimiserResult(**result_dict, geom=geom)",
  "def _to_koz(koz: Union[BluemiraWire, KeepOutZoneDict, KeepOutZone]) -> KeepOutZone:\n    \"\"\"Convert ``koz`` to a ``KeepOutZone``.\"\"\"\n    if isinstance(koz, BluemiraWire):\n        return KeepOutZone(koz)\n    if isinstance(koz, Mapping):\n        return KeepOutZone(**koz)\n    if isinstance(koz, KeepOutZone):\n        return koz\n    raise TypeError(f\"Type '{type(koz).__name__}' is not a valid keep-out zone.\")",
  "def calculate_length(vector, parameterisation):\n    \"\"\"\n    Calculate the length of the parameterised shape for a given state vector.\n    \"\"\"\n    parameterisation.variables.set_values_from_norm(vector)\n    return parameterisation.create_shape().length",
  "def minimise_length(vector, grad, parameterisation, ad_args=None):\n    \"\"\"\n    Objective function for nlopt optimisation (minimisation) of length.\n\n    Parameters\n    ----------\n    vector: np.ndarray\n        State vector of the array of coil currents.\n    grad: np.ndarray\n        Local gradient of objective function used by LD NLOPT algorithms.\n        Updated in-place.\n    ad_args: Dict\n        Additional arguments to pass to the `approx_derivative` function.\n\n    Returns\n    -------\n    fom: Value of objective function (figure of merit).\n    \"\"\"\n    ad_args = ad_args if ad_args is not None else {}\n\n    length = calculate_length(vector, parameterisation)\n    if grad.size > 0:\n        grad[:] = approx_derivative(\n            calculate_length, vector, f0=length, args=(parameterisation,), **ad_args\n        )\n\n    return length",
  "def calculate_signed_distance(vector, parameterisation, n_shape_discr, koz_points):\n    \"\"\"\n    Calculate the signed distances from the parameterised shape to\n    the keep-out zone.\n    \"\"\"\n    parameterisation.variables.set_values_from_norm(vector)\n\n    shape = parameterisation.create_shape()\n    s = shape.discretize(ndiscr=n_shape_discr).xz\n    return signed_distance_2D_polygon(s.T, koz_points.T).T",
  "def constrain_koz(\n    constraint, vector, grad, parameterisation, n_shape_discr, koz_points, ad_args=None\n):\n    \"\"\"\n    Geometry constraint function to the keep-out-zone.\n    \"\"\"\n    constraint[:] = calculate_signed_distance(\n        vector, parameterisation, n_shape_discr, koz_points\n    )\n    if grad.size > 0:\n        grad[:] = approx_derivative(\n            calculate_signed_distance,\n            vector,\n            f0=constraint,\n            args=(parameterisation, n_shape_discr, koz_points),\n            **ad_args,\n        )\n    return constraint",
  "class GeometryOptimisationProblem(OptimisationProblem):\n    \"\"\"\n    Geometry optimisation problem class.\n\n    Parameters\n    ----------\n    parameterisation: GeometryParameterisation\n        Geometry parameterisation instance to use in the optimisation problem\n    optimiser: bluemira.utilities.optimiser.Optimiser\n        Optimiser instance to use in the optimisation problem\n    \"\"\"\n\n    def __init__(\n        self,\n        geometry_parameterisation: GeometryParameterisation,\n        optimiser: Optimiser = None,\n        objective: OptimisationObjective = None,\n        constraints: List[OptimisationConstraint] = None,\n    ):\n        super().__init__(geometry_parameterisation, optimiser, objective, constraints)\n\n        dimension = geometry_parameterisation.variables.n_free_variables\n        bounds = (np.zeros(dimension), np.ones(dimension))\n        self.set_up_optimiser(dimension, bounds)\n        self._objective._args[\"ad_args\"] = {\"bounds\": bounds}\n        if constraints:\n            for constraint in self._constraints:\n                constraint._args[\"ad_args\"] = {\"bounds\": bounds}\n\n    def apply_shape_constraints(self):\n        \"\"\"\n        Add shape constraints to the geometry parameterisation, if they exist.\n        \"\"\"\n        n_shape_ineq_cons = self._parameterisation.n_ineq_constraints\n        if n_shape_ineq_cons > 0:\n            self.opt.add_ineq_constraints(\n                self._parameterisation.shape_ineq_constraints,\n                EPS * np.ones(n_shape_ineq_cons),\n            )\n        else:\n            bluemira_warn(\n                f\"GeometryParameterisation {self._parameterisation.__class.__name__} does\"\n                \"not have any shape constraints.\"\n            )\n\n    def update_parameterisation(self, x):\n        \"\"\"\n        Update the GeometryParameterisation.\n        \"\"\"\n        self._parameterisation.variables.set_values_from_norm(x)\n        return self._parameterisation\n\n    def optimise(self, x0=None):\n        \"\"\"\n        Solve the GeometryOptimisationProblem.\n        \"\"\"\n        self._objective._args[\"parameterisation\"] = self._parameterisation\n        if x0 is None:\n            x0 = self._parameterisation.variables.get_normalised_values()\n        x_star = self.opt.optimise(x0)\n        return self.update_parameterisation(x_star)",
  "class MinimiseLengthGOP(GeometryOptimisationProblem):\n    \"\"\"\n    Optimiser to minimise the length of a geometry 2-D parameterisation\n    in the xz-plane, with optional constraints in the form of a\n    \"keep-out zone\".\n    \"\"\"\n\n    def __init__(\n        self,\n        parameterisation: GeometryParameterisation,\n        optimiser: Optimiser,\n        keep_out_zone: BluemiraWire = None,\n        n_koz_points: int = 100,\n        koz_con_tol: float = 1e-3,\n    ):\n        objective = OptimisationObjective(\n            minimise_length, {\"parameterisation\": parameterisation}\n        )\n        constraints = []\n        if keep_out_zone is not None:\n            koz_points = keep_out_zone.discretize(n_koz_points, byedges=True).xz\n            koz_constraint = OptimisationConstraint(\n                constrain_koz,\n                f_constraint_args={\n                    \"parameterisation\": parameterisation,\n                    \"n_shape_discr\": n_koz_points,\n                    \"koz_points\": koz_points,\n                },\n                tolerance=koz_con_tol * np.ones(n_koz_points),\n            )\n            constraints.append(koz_constraint)\n\n        super().__init__(parameterisation, optimiser, objective, constraints=constraints)",
  "def __init__(\n        self,\n        geometry_parameterisation: GeometryParameterisation,\n        optimiser: Optimiser = None,\n        objective: OptimisationObjective = None,\n        constraints: List[OptimisationConstraint] = None,\n    ):\n        super().__init__(geometry_parameterisation, optimiser, objective, constraints)\n\n        dimension = geometry_parameterisation.variables.n_free_variables\n        bounds = (np.zeros(dimension), np.ones(dimension))\n        self.set_up_optimiser(dimension, bounds)\n        self._objective._args[\"ad_args\"] = {\"bounds\": bounds}\n        if constraints:\n            for constraint in self._constraints:\n                constraint._args[\"ad_args\"] = {\"bounds\": bounds}",
  "def apply_shape_constraints(self):\n        \"\"\"\n        Add shape constraints to the geometry parameterisation, if they exist.\n        \"\"\"\n        n_shape_ineq_cons = self._parameterisation.n_ineq_constraints\n        if n_shape_ineq_cons > 0:\n            self.opt.add_ineq_constraints(\n                self._parameterisation.shape_ineq_constraints,\n                EPS * np.ones(n_shape_ineq_cons),\n            )\n        else:\n            bluemira_warn(\n                f\"GeometryParameterisation {self._parameterisation.__class.__name__} does\"\n                \"not have any shape constraints.\"\n            )",
  "def update_parameterisation(self, x):\n        \"\"\"\n        Update the GeometryParameterisation.\n        \"\"\"\n        self._parameterisation.variables.set_values_from_norm(x)\n        return self._parameterisation",
  "def optimise(self, x0=None):\n        \"\"\"\n        Solve the GeometryOptimisationProblem.\n        \"\"\"\n        self._objective._args[\"parameterisation\"] = self._parameterisation\n        if x0 is None:\n            x0 = self._parameterisation.variables.get_normalised_values()\n        x_star = self.opt.optimise(x0)\n        return self.update_parameterisation(x_star)",
  "def __init__(\n        self,\n        parameterisation: GeometryParameterisation,\n        optimiser: Optimiser,\n        keep_out_zone: BluemiraWire = None,\n        n_koz_points: int = 100,\n        koz_con_tol: float = 1e-3,\n    ):\n        objective = OptimisationObjective(\n            minimise_length, {\"parameterisation\": parameterisation}\n        )\n        constraints = []\n        if keep_out_zone is not None:\n            koz_points = keep_out_zone.discretize(n_koz_points, byedges=True).xz\n            koz_constraint = OptimisationConstraint(\n                constrain_koz,\n                f_constraint_args={\n                    \"parameterisation\": parameterisation,\n                    \"n_shape_discr\": n_koz_points,\n                    \"koz_points\": koz_points,\n                },\n                tolerance=koz_con_tol * np.ones(n_koz_points),\n            )\n            constraints.append(koz_constraint)\n\n        super().__init__(parameterisation, optimiser, objective, constraints=constraints)",
  "class GeomOptimisationProblem(abc.ABC, OptimisationProblemBase):\n    \"\"\"\n    Interface for a geometry optimisation problem.\n\n    This is an alternative to running a geometry optimisation using the\n    :func:`.optimise_geometry` function.\n    \"\"\"\n\n    @abc.abstractmethod\n    def objective(self, geom: _GeomT) -> float:\n        \"\"\"The objective function to minimise.\"\"\"\n\n    def df_objective(self, geom: _GeomT) -> np.ndarray:\n        \"\"\"\n        The derivative of the objective function.\n\n        If not overridden, an approximation of the derivative is made\n        using the 'central differences' method.\n        This method is ignored if a non-gradient based algorithm is\n        used when calling :meth:`.GeomOptimisationProblem.optimise`.\n        \"\"\"\n        raise NotImplementedError\n\n    def eq_constraints(self) -> List[GeomConstraintT]:\n        \"\"\"\n        List of equality constraints for the optimisation.\n\n        See :func:`.optimise_geometry` for a description of the form\n        these constraints should take.\n        \"\"\"\n        return []\n\n    def ineq_constraints(self) -> List[GeomConstraintT]:\n        \"\"\"\n        List of inequality constraints for the optimisation.\n\n        See :func:`.optimise_geometry` for a description of the form\n        these constraints should take.\n        \"\"\"\n        return []\n\n    def keep_out_zones(self) -> List[KeepOutZone]:\n        \"\"\"\n        List of geometric keep-out zones.\n\n        An iterable of keep-out zones: closed wires that the geometry\n        must not intersect.\n        \"\"\"\n        return []\n\n    def optimise(\n        self,\n        geom: _GeomT,\n        *,\n        algorithm: AlgorithmType = Algorithm.SLSQP,\n        opt_conditions: Optional[Mapping[str, Union[int, float]]] = None,\n        opt_parameters: Optional[Mapping[str, Any]] = None,\n        keep_history: bool = False,\n        check_constraints: bool = True,\n        check_constraints_warn: bool = True,\n    ) -> GeomOptimiserResult[_GeomT]:\n        \"\"\"\n        Run the geometry optimisation.\n\n        See :func:`.optimise_geometry` for a description of the\n        parameters.\n\n        Returns\n        -------\n        The result of the optimisation.\n        \"\"\"\n        df_objective = self._overridden_or_default(\n            self.df_objective, GeomOptimisationProblem, None\n        )\n        return optimise_geometry(\n            geom,\n            f_objective=self.objective,\n            df_objective=df_objective,\n            keep_out_zones=self.keep_out_zones(),\n            algorithm=algorithm,\n            opt_conditions=opt_conditions,\n            opt_parameters=opt_parameters,\n            eq_constraints=self.eq_constraints(),\n            ineq_constraints=self.ineq_constraints(),\n            keep_history=keep_history,\n            check_constraints=check_constraints,\n            check_constraints_warn=check_constraints_warn,\n        )",
  "def objective(self, geom: _GeomT) -> float:\n        \"\"\"The objective function to minimise.\"\"\"",
  "def df_objective(self, geom: _GeomT) -> np.ndarray:\n        \"\"\"\n        The derivative of the objective function.\n\n        If not overridden, an approximation of the derivative is made\n        using the 'central differences' method.\n        This method is ignored if a non-gradient based algorithm is\n        used when calling :meth:`.GeomOptimisationProblem.optimise`.\n        \"\"\"\n        raise NotImplementedError",
  "def eq_constraints(self) -> List[GeomConstraintT]:\n        \"\"\"\n        List of equality constraints for the optimisation.\n\n        See :func:`.optimise_geometry` for a description of the form\n        these constraints should take.\n        \"\"\"\n        return []",
  "def ineq_constraints(self) -> List[GeomConstraintT]:\n        \"\"\"\n        List of inequality constraints for the optimisation.\n\n        See :func:`.optimise_geometry` for a description of the form\n        these constraints should take.\n        \"\"\"\n        return []",
  "def keep_out_zones(self) -> List[KeepOutZone]:\n        \"\"\"\n        List of geometric keep-out zones.\n\n        An iterable of keep-out zones: closed wires that the geometry\n        must not intersect.\n        \"\"\"\n        return []",
  "def optimise(\n        self,\n        geom: _GeomT,\n        *,\n        algorithm: AlgorithmType = Algorithm.SLSQP,\n        opt_conditions: Optional[Mapping[str, Union[int, float]]] = None,\n        opt_parameters: Optional[Mapping[str, Any]] = None,\n        keep_history: bool = False,\n        check_constraints: bool = True,\n        check_constraints_warn: bool = True,\n    ) -> GeomOptimiserResult[_GeomT]:\n        \"\"\"\n        Run the geometry optimisation.\n\n        See :func:`.optimise_geometry` for a description of the\n        parameters.\n\n        Returns\n        -------\n        The result of the optimisation.\n        \"\"\"\n        df_objective = self._overridden_or_default(\n            self.df_objective, GeomOptimisationProblem, None\n        )\n        return optimise_geometry(\n            geom,\n            f_objective=self.objective,\n            df_objective=df_objective,\n            keep_out_zones=self.keep_out_zones(),\n            algorithm=algorithm,\n            opt_conditions=opt_conditions,\n            opt_parameters=opt_parameters,\n            eq_constraints=self.eq_constraints(),\n            ineq_constraints=self.ineq_constraints(),\n            keep_history=keep_history,\n            check_constraints=check_constraints,\n            check_constraints_warn=check_constraints_warn,\n        )",
  "class GeomOptimiserObjective(Protocol):\n    \"\"\"Form for a geometry optimisation objective function.\"\"\"\n\n    def __call__(self, geom: GeometryParameterisation) -> float:\n        \"\"\"Call the geometry optimiser objective function.\"\"\"\n        ...",
  "class GeomOptimiserCallable(Protocol):\n    \"\"\"Form for a geometry optimiser function (derivative, constraint, etc.).\"\"\"\n\n    def __call__(self, geom: GeometryParameterisation) -> np.ndarray:\n        \"\"\"Call the geometry optimiser function.\"\"\"\n        ...",
  "class GeomClsOptimiserCallable(Protocol):\n    \"\"\"Form for a geometry optimiser function (derivative, constraint, etc.).\"\"\"\n\n    def __call__(self) -> np.ndarray:\n        \"\"\"Call the geometry optimiser function.\"\"\"\n        ...",
  "class GeomConstraintT(TypedDict):\n    \"\"\"Typing for definition of a constraint.\"\"\"\n\n    f_constraint: GeomOptimiserCallable\n    tolerance: np.ndarray\n    df_constraint: NotRequired[Optional[GeomOptimiserCallable]]",
  "def __call__(self, geom: GeometryParameterisation) -> float:\n        \"\"\"Call the geometry optimiser objective function.\"\"\"\n        ...",
  "def __call__(self, geom: GeometryParameterisation) -> np.ndarray:\n        \"\"\"Call the geometry optimiser function.\"\"\"\n        ...",
  "def __call__(self) -> np.ndarray:\n        \"\"\"Call the geometry optimiser function.\"\"\"\n        ...",
  "class KeepOutZone:\n    \"\"\"Definition of a keep-out zone for a geometry optimisation.\"\"\"\n\n    wire: BluemiraWire\n    \"\"\"Closed wire defining the keep-out zone.\"\"\"\n    byedges: bool = True\n    \"\"\"Whether to discretize the keep-out zone by edges or not.\"\"\"\n    dl: Optional[float] = None\n    \"\"\"\n    The discretization length for the keep-out zone.\n\n    This overrides ``n_discr`` if given.\n    \"\"\"\n    n_discr: int = 100\n    \"\"\"The number of points to discretise the keep-out zone into.\"\"\"\n    shape_n_discr: int = 100\n    \"\"\"The number of points to discretise the geometry being optimised into.\"\"\"\n    tol: float = 1e-8\n    \"\"\"The tolerance for the keep-out zone constraint.\"\"\"",
  "def to_objective(\n    geom_objective: GeomOptimiserObjective, geom: GeometryParameterisation\n) -> ObjectiveCallable:\n    \"\"\"Convert a geometry objective function to a normal objective function.\"\"\"\n\n    def f(x):\n        geom.variables.set_values_from_norm(x)\n        return geom_objective(geom)\n\n    return f",
  "def to_optimiser_callable(\n    geom_callable: GeomOptimiserCallable,\n    geom: GeometryParameterisation,\n) -> OptimiserCallable:\n    \"\"\"\n    Convert a geometry optimiser function to a normal optimiser function.\n\n    For example, a gradient or constraint.\n    \"\"\"\n\n    def f(x):\n        geom.variables.set_values_from_norm(x)\n        return geom_callable(geom)\n\n    return f",
  "def to_optimiser_callable_from_cls(\n    geom_callable: GeomClsOptimiserCallable,\n    geom: GeometryParameterisation,\n) -> OptimiserCallable:\n    \"\"\"\n    Convert a geometry optimiser function to a normal optimiser function.\n\n    For example, a gradient or constraint.\n    \"\"\"\n\n    def f(x):\n        geom.variables.set_values_from_norm(x)\n        return geom_callable()\n\n    return f",
  "def to_constraint(\n    geom_constraint: GeomConstraintT, geom: GeometryParameterisation\n) -> ConstraintT:\n    \"\"\"Convert a geometry constraint to a normal one.\"\"\"\n    constraint: ConstraintT = {\n        \"f_constraint\": to_optimiser_callable(geom_constraint[\"f_constraint\"], geom),\n        \"df_constraint\": None,\n        \"tolerance\": geom_constraint[\"tolerance\"],\n    }\n    if df_constraint := geom_constraint.get(\"df_constraint\", None):\n        constraint[\"df_constraint\"] = to_optimiser_callable(df_constraint, geom)\n    return constraint",
  "def calculate_signed_distance(\n    parameterisation: GeometryParameterisation,\n    n_shape_discr: int,\n    zone_points: np.ndarray,\n):\n    \"\"\"\n    Signed distance from the parameterised shape to the keep-out/in zone.\n    \"\"\"\n    shape = parameterisation.create_shape()\n    # Note that we do not discretize by edges here, as the number of\n    # points must remain constant so the size of constraint vectors\n    # remain constant.\n    s = shape.discretize(n_shape_discr, byedges=False).xz\n    return signed_distance_2D_polygon(s.T, zone_points.T).T",
  "def make_keep_out_zone_constraint(koz: KeepOutZone) -> GeomConstraintT:\n    \"\"\"Make a keep-out zone inequality constraint from a wire.\"\"\"\n    if not koz.wire.is_closed():\n        raise GeometryOptimisationError(\n            f\"Keep-out zone with label '{koz.wire.label}' is not closed.\"\n        )\n    koz_points = koz.wire.discretize(koz.n_discr, byedges=koz.byedges, dl=koz.dl).xz\n    # Note that we do not allow discretization using 'dl' or 'byedges'\n    # for the shape being optimised. The size of the constraint cannot\n    # change within an optimisation loop (NLOpt will error) and these\n    # options do not guarantee a constant number of discretized points.\n    shape_n_discr = koz.shape_n_discr\n\n    def _f_constraint(geom: GeometryParameterisation) -> np.ndarray:\n        return calculate_signed_distance(\n            geom,\n            n_shape_discr=shape_n_discr,\n            zone_points=koz_points,\n        )\n\n    return {\"f_constraint\": _f_constraint, \"tolerance\": np.full(shape_n_discr, koz.tol)}",
  "def get_shape_ineq_constraint(geom: GeometryParameterisation) -> List[ConstraintT]:\n    \"\"\"\n    Retrieve the inequality constraints registered for the given parameterisation.\n\n    If no constraints are registered, return an empty list.\n    \"\"\"\n    if geom.n_ineq_constraints < 1:\n        return []\n    if df_constraint := getattr(geom, \"df_ineq_constraint\", None):\n        df_constraint = to_optimiser_callable_from_cls(df_constraint, geom)\n    return [\n        {\n            \"f_constraint\": to_optimiser_callable_from_cls(\n                getattr(geom, \"f_ineq_constraint\"), geom\n            ),\n            \"df_constraint\": df_constraint,\n            \"tolerance\": geom.tolerance,\n        }\n    ]",
  "def f(x):\n        geom.variables.set_values_from_norm(x)\n        return geom_objective(geom)",
  "def f(x):\n        geom.variables.set_values_from_norm(x)\n        return geom_callable(geom)",
  "def f(x):\n        geom.variables.set_values_from_norm(x)\n        return geom_callable()",
  "def _f_constraint(geom: GeometryParameterisation) -> np.ndarray:\n        return calculate_signed_distance(\n            geom,\n            n_shape_discr=shape_n_discr,\n            zone_points=koz_points,\n        )",
  "def debye_length(temperature: float, density: float) -> float:\n    \"\"\"\n    Debye length\n\n    Parameters\n    ----------\n    temperature:\n        Temperature [K]\n    density:\n        Density [m^-3]\n\n    Returns\n    -------\n    Debye length [m]\n    \"\"\"\n    return np.sqrt(EPS_0 * K_BOLTZMANN * temperature / (EV_TO_J**2 * density))",
  "def reduced_mass(mass_1: float, mass_2: float) -> float:\n    \"\"\"\n    Calculate the reduced mass of a two-particle system\n\n    Parameters\n    ----------\n    mass_1:\n        Mass of the first particle\n    mass_2:\n        Mass of the second particle\n\n    Returns\n    -------\n    Reduced mass\n    \"\"\"\n    return (mass_1 * mass_2) / (mass_1 + mass_2)",
  "def thermal_velocity(temperature: float, mass: float) -> float:\n    \"\"\"\n    Parameters\n    ----------\n    temperature:\n        Temperature [K]\n    mass:\n        Mass of the particle [kg]\n\n    Returns\n    -------\n    Thermal velocity [m/s]\n\n    Notes\n    -----\n    The sqrt(2) term is for a 3-dimensional system and the most probable velocity in\n    the particle velocity distribution.\n    \"\"\"\n    return np.sqrt(2) * np.sqrt(K_BOLTZMANN * temperature / mass)",
  "def de_broglie_length(velocity: float, mu_12: float) -> float:\n    \"\"\"\n    Calculate the de Broglie wavelength\n\n    Parameters\n    ----------\n    velocity:\n        Velocity [m/s]\n    mu_12:\n        Reduced mass [kg]\n\n    Returns\n    -------\n    De Broglie wavelength [m]\n    \"\"\"\n    return H_PLANCK / (2 * mu_12 * velocity)",
  "def impact_parameter_perp(velocity: float, mu_12: float):\n    \"\"\"\n    Calculate the perpendicular impact parameter, a.k.a. b90\n\n    Parameters\n    ----------\n    velocity:\n        Velocity [m/s]\n    mu_12:\n        Reduced mass [kg]\n\n    Returns\n    -------\n    Perpendicular impact parameter [m]\n    \"\"\"\n    return EV_TO_J**2 / (4 * np.pi * EPS_0 * mu_12 * velocity**2)",
  "def coulomb_logarithm(temperature: float, density: float) -> float:\n    \"\"\"\n    Calculate the value of the Coulomb logarithm for an electron hitting a proton.\n\n    Parameters\n    ----------\n    temperature:\n        Temperature [K]\n    density:\n        Density [1/m^3]\n\n    Returns\n    -------\n    Coulomb logarithm value\n    \"\"\"\n    lambda_debye = debye_length(temperature, density)\n    mu_12 = reduced_mass(ELECTRON_MASS, PROTON_MASS)\n    v = thermal_velocity(temperature, ELECTRON_MASS)\n    lambda_de_broglie = de_broglie_length(v, mu_12)\n    b_perp = impact_parameter_perp(v, mu_12)\n    b_min = max(lambda_de_broglie, b_perp)\n    return np.log(np.sqrt(1 + (lambda_debye / b_min) ** 2))",
  "def spitzer_conductivity(Z_eff: float, T_e: float, ln_lambda: float) -> float:\n    \"\"\"\n    Formula for electrical conductivity in a plasma as per L. Spitzer.\n\n    Parameters\n    ----------\n    Z_eff:\n        Effective charge [a.m.u.]\n    T_e:\n        Electron temperature on axis [eV]\n    ln_lambda:\n        Coulomb logarithm value\n\n    Returns\n    -------\n    Plasma resistivity [1/Ohm/m]\n\n    Notes\n    -----\n    Spitzer and Haerm, 1953\n\n    \\t:math:`\\\\sigma = 1.92e4 (2-Z_{eff}^{-1/3}) \\\\dfrac{T_{e}^{3/2}}{Z_{eff}ln\\\\Lambda}`\n    \"\"\"\n    return 1.92e4 * (2 - Z_eff ** (-1 / 3)) * T_e**1.5 / (Z_eff * ln_lambda)",
  "def E_DT_fusion() -> float:  # noqa :N802\n    \"\"\"\n    Calculates the total energy released from the D-T fusion reaction\n\n    Returns\n    -------\n    The energy released from the D-T fusion reaction [eV]\n\n    Notes\n    -----\n    .. math::\n        {^{2}_{1}H}+{^{3}_{1}H}~\\\\rightarrow~{^{4}_{2}He}~\n        (3.5~\\\\text{MeV})+\\\\text{n}^{0} (14.1 ~\\\\text{MeV})\\n\n        \\\\Delta E = \\\\Delta m c^2\n    \"\"\"\n    delta_m = (D_MOLAR_MASS + T_MOLAR_MASS) - (HE_MOLAR_MASS + NEUTRON_MOLAR_MASS)\n    return delta_m * C_LIGHT**2 * AMU_TO_KG * J_TO_EV",
  "def E_DD_fusion() -> float:  # noqa :N802\n    \"\"\"\n    Calculates the total energy released from the D-D fusion reaction\n\n    Returns\n    -------\n    The energy released from the D-D fusion reaction [eV]\n\n    Notes\n    -----\n    .. math::\n        {^{2}_{1}H}+{^{2}_{1}H}~\\\\rightarrow~{^{3}_{1}H}\n        (1.01 ~\\\\text{MeV})+\\\\text{p} (3.02~\\\\text{MeV})~~[50 \\\\textrm{\\\\%}]\n        ~~~~~~~~~~\\\\rightarrow~{^{3}_{2}He} (0.82~\\\\text{MeV})+\\\\text{n}^{0} (2.45~\\\\text{MeV})~~[50 \\\\text{\\\\%}]\\n\n        \\\\Delta E = \\\\Delta m c^2\n    \"\"\"  # noqa :W505\n    # NOTE: Electron mass must be included with proton mass\n    delta_m = np.array(\n        [\n            D_MOLAR_MASS\n            + D_MOLAR_MASS\n            - (T_MOLAR_MASS + PROTON_MOLAR_MASS + ELECTRON_MOLAR_MASS),\n            (D_MOLAR_MASS + D_MOLAR_MASS) - (HE3_MOLAR_MASS + NEUTRON_MOLAR_MASS),\n        ]\n    )\n    delta_m = np.average(delta_m)\n    return delta_m * C_LIGHT**2 * AMU_TO_KG * J_TO_EV",
  "def n_DT_reactions(p_fus: float) -> float:\n    \"\"\"\n    Calculates the number of D-T fusion reactions per s for a given D-T fusion\n    power\n\n    :math:`n_{reactions} = \\\\frac{P_{fus}[MW]}{17.58 [MeV]eV[J]} [1/s]`\n\n    Parameters\n    ----------\n    p_fus:\n        D-T fusion power [MW]\n\n    Returns\n    -------\n    Number of D-T reactions per second [1/s]\n    \"\"\"\n    e_dt = E_DT_fusion()\n    return raw_uc(p_fus, \"MW\", \"W\") / (e_dt * EV_TO_J)",
  "def n_DD_reactions(p_fus: float) -> float:  # noqa :N802\n    \"\"\"\n    Calculates the number of D-D fusion reactions per s for a given D-D fusion\n    power\n\n    :math:`n_{reactions} = \\\\frac{P_{fus}[MW]}{E_{DD} [MeV] eV[J]} [1/s]`\n\n    Parameters\n    ----------\n    p_fus:\n        D-D fusion power [W]\n\n    Returns\n    -------\n    Number of D-D reactions per second [1/s]\n    \"\"\"\n    e_dd = E_DD_fusion()\n    return p_fus / (e_dd * EV_TO_J)",
  "def r_T_burn(p_fus: float) -> float:  # noqa :N802\n    \"\"\"\n    Calculates the tritium burn rate for a given fusion power\n\n    :math:`\\\\dot{m_{b}} = \\\\frac{P_{fus}[MW]M_{T}[g/mol]}{17.58 [MeV]eV[J]N_{A}[1/mol]} [g/s]`\n\n    Parameters\n    ----------\n    p_fus:\n        D-T fusion power [MW]\n\n    Returns\n    -------\n    T burn rate in the plasma [g/s]\n    \"\"\"  # noqa :W505\n    return n_DT_reactions(p_fus) * T_MOLAR_MASS / N_AVOGADRO",
  "def r_D_burn_DT(p_fus: float) -> float:  # noqa :N802\n    \"\"\"\n    Calculates the deuterium burn rate for a given fusion power in D-T\n\n    Parameters\n    ----------\n    p_fus:\n        D-T fusion power [MW]\n\n    Returns\n    -------\n    D burn rate in the plasma [g/s]\n\n    Notes\n    -----\n    .. math::\n        \\\\dot{m_{b}} = \\\\frac{P_{fus}[MW]M_{D}[g/mol]}\n        {17.58 [MeV]eV[J]N_{A}[1/mol]} [g/s]\n    \"\"\"\n    return n_DT_reactions(p_fus) * D_MOLAR_MASS / N_AVOGADRO",
  "class Reactions(Enum):\n    \"\"\"\n    Reactions with support for reactivity.\n    \"\"\"\n\n    D_T = auto()  # D + T --> 4He + n reaction\n    D_D = auto()  # D + D --> 0.5 D-D1 + 0.5 D-D2\n    D_D1 = auto()  # D + D --> 3He + n reaction [50 %]\n    D_D2 = auto()  # D + D --> T + p reaction [50 %]\n    D_He3 = auto()",
  "class ReactivityMethod(Enum):\n    BOSCH_HALE = auto()\n    PLASMOD = auto()\n    JOHNER = auto()",
  "def reactivity(\n    temp_k: Union[float, np.ndarray],\n    reaction: Union[str, Reactions] = Reactions.D_T,\n    method: Union[str, ReactivityMethod] = ReactivityMethod.BOSCH_HALE,\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Calculate the thermal reactivity of a fusion reaction in Maxwellian plasmas,\n    \\\\t:math:`<\\\\sigma v>`\n\n    Parameters\n    ----------\n    temp_k:\n        Temperature [K]\n    reaction:\n        The fusion reaction\n    method:\n        The parameterisation to use when calculating the reactivity\n\n    Returns\n    -------\n    Reactivity of the reaction at the specified temperature(s) [m^3/s]\n    \"\"\"\n    if not isinstance(reaction, Reactions):\n        reaction = Reactions[reaction.replace(\"-\", \"_\")]\n    if not isinstance(method, ReactivityMethod):\n        method = ReactivityMethod[method.replace(\"-\", \"_\").upper()]\n    mapping = {\n        ReactivityMethod.BOSCH_HALE: _reactivity_bosch_hale,\n        ReactivityMethod.PLASMOD: _reactivity_plasmod,\n        ReactivityMethod.JOHNER: _reactivity_johner,\n    }\n\n    return mapping[method](raw_uc(temp_k, \"K\", \"keV\"), reaction)",
  "class BoschHale_DT_4Hen:\n    \"\"\"\n    Bosch-Hale parameterisation data for the reaction:\n\n    D + T --> 4He + n\n\n    H.-S. Bosch and G.M. Hale 1992 Nucl. Fusion 32 611\n    DOI 10.1088/0029-5515/32/4/I07\n    \"\"\"\n\n    t_min: float = 0.2  # [keV]\n    t_max: float = 100  # [keV]\n    bg: float = 34.3827  # [keV**0.5]\n    mrc2: float = 1.124656e6  # [keV]\n    c: npt.NDArray = field(\n        default_factory=lambda: np.array(\n            [\n                1.17302e-9,\n                1.51361e-2,\n                7.51886e-2,\n                4.60643e-3,\n                1.35000e-2,\n                -1.06750e-4,\n                1.36600e-5,\n            ]\n        )\n    )",
  "class BoschHale_DD_3Hen:\n    \"\"\"\n    Bosch-Hale parameterisation data for the reaction:\n\n    D + D --> 3He + n\n\n    H.-S. Bosch and G.M. Hale 1992 Nucl. Fusion 32 611\n    DOI 10.1088/0029-5515/32/4/I07\n    \"\"\"\n\n    t_min: float = 0.2  # [keV]\n    t_max: float = 100  # [keV]\n    bg: float = 31.3970  # [keV**0.5]\n    mrc2: float = 0.937814e6  # [keV]\n    c: npt.NDArray = field(\n        default_factory=lambda: np.array(\n            [\n                5.43360e-12,\n                5.85778e-3,\n                7.68222e-3,\n                0.0,\n                -2.96400e-6,\n                0.0,\n                0.0,\n            ]\n        )\n    )",
  "class BoschHale_DD_Tp:\n    \"\"\"\n    Bosch-Hale parameterisation data for the reaction:\n\n    D + D --> T + p\n\n    H.-S. Bosch and G.M. Hale 1992 Nucl. Fusion 32 611\n    DOI 10.1088/0029-5515/32/4/I07\n    \"\"\"\n\n    t_min: float = 0.2  # [keV]\n    t_max: float = 100  # [keV]\n    bg: float = 31.3970  # [keV**0.5]\n    mrc2: float = 0.937814e6  # [keV]\n    c: npt.NDArray = field(\n        default_factory=lambda: np.array(\n            [\n                5.65718e-12,\n                3.41267e-3,\n                1.99167e-3,\n                0.0,\n                1.05060e-5,\n                0.0,\n                0.0,\n            ]\n        )\n    )",
  "class BoschHale_DHe3_4Hep:\n    \"\"\"\n    Bosch-Hale parameterisation data for the reaction:\n\n    D + 3He --> 4He + p\n\n    H.-S. Bosch and G.M. Hale 1992 Nucl. Fusion 32 611\n    DOI 10.1088/0029-5515/32/4/I07\n    \"\"\"\n\n    t_min: float = 0.5  # [keV]\n    t_max: float = 190  # [keV]\n    bg: float = 68.7508  # [keV**0.5]\n    mrc2: float = 1.124572e6  # [keV]\n    c: npt.NDArray = field(\n        default_factory=lambda: np.array(\n            [\n                5.51036e-10,\n                6.41918e-3,\n                -2.02896e-3,\n                -1.91080e-5,\n                1.35776e-4,\n                0.0,\n                0.0,\n            ]\n        )\n    )",
  "def _reactivity_bosch_hale(\n    temp_kev: Union[float, np.ndarray], reaction: Reactions\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Bosch-Hale reactivity parameterisation for Maxwellian plasmas\n\n    Parameters\n    ----------\n    temp_kev:\n        Temperature [keV]\n    reaction:\n        The fusion reaction\n\n    Returns\n    -------\n    Reactivity of the reaction at the specified temperature(s) [m^3/s]\n\n    Notes\n    -----\n    H.-S. Bosch and G.M. Hale 1992 Nucl. Fusion 32 611\n    DOI 10.1088/0029-5515/32/4/I07\n    \"\"\"\n    if reaction == Reactions.D_D:\n        return 0.5 * (\n            _reactivity_bosch_hale(temp_kev, Reactions.D_D1)\n            + _reactivity_bosch_hale(temp_kev, Reactions.D_D2)\n        )\n    mapping = {\n        Reactions.D_T: BoschHale_DT_4Hen(),\n        Reactions.D_D1: BoschHale_DD_3Hen(),\n        Reactions.D_D2: BoschHale_DD_Tp(),\n        Reactions.D_He3: BoschHale_DHe3_4Hep(),\n    }\n    data = mapping[reaction]\n\n    if np.min(temp_kev) < data.t_min:\n        bluemira_warn(\n            f\"The Bosch-Hale parameterisation for reaction {reaction} is only valid \"\n            f\"between {data.t_min} and {data.t_max} keV, not {np.min(temp_kev)} keV.\"\n        )\n    if np.max(temp_kev) > data.t_max:\n        bluemira_warn(\n            f\"The Bosch-Hale parameterisation for reaction {reaction} is only valid \"\n            f\"between {data.t_min} and {data.t_max} keV, not {np.max(temp_kev)} keV.\"\n        )\n\n    frac = (\n        temp_kev\n        * (data.c[1] + temp_kev * (data.c[3] + temp_kev * data.c[5]))\n        / (1 + temp_kev * (data.c[2] + temp_kev * (data.c[4] + temp_kev * data.c[6])))\n    )\n    theta = temp_kev / (1 - frac)\n    chi = (data.bg**2 / (4 * theta)) ** (1 / 3)\n    return (\n        1e-6\n        * data.c[0]\n        * theta\n        * np.sqrt(chi / (data.mrc2 * temp_kev**3))\n        * np.exp(-3 * chi)\n    )",
  "def _reactivity_plasmod(\n    temp_kev: Union[float, np.ndarray], reaction: Reactions\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Reactivity equations used in PLASMOD (original source unknown)\n\n    Parameters\n    ----------\n    temp_kev:\n        Temperature [keV]\n    reaction:\n        The fusion reaction\n\n    Returns\n    -------\n    Reactivity of the reaction at the specified temperature(s) [m^3/s]\n    \"\"\"\n    if reaction == Reactions.D_T:\n        t3 = temp_kev ** (-1 / 3)\n\n        term_1 = 8.972 * np.exp(-19.9826 * t3) * t3**2\n        term_2 = (temp_kev + 1.0134) / (1 + 6.386e-3 * (temp_kev + 1.0134) ** 2)\n        term_3 = 1.877 * np.exp(-0.16176 * temp_kev * np.sqrt(temp_kev))\n        return 1e-19 * term_1 * (term_2 + term_3)\n\n    elif reaction == Reactions.D_D:\n        term_1 = (\n            0.16247 + 0.001741 * temp_kev - 0.029 * np.exp(-0.3843 * np.sqrt(temp_kev))\n        )\n        term_2 = np.exp(-18.8085 / (temp_kev ** (1 / 3))) / (temp_kev ** (1 / 3)) ** 2\n        return 1e-19 * term_1 * term_2\n    else:\n        raise ValueError(\n            f\"This function only supports D-D and D-T, not {reaction.name.replace('_','-')}\"\n        )",
  "def _reactivity_johner(\n    temp_kev: Union[float, np.ndarray], reaction: Reactions\n) -> Union[float, np.ndarray]:\n    \"\"\"\n    Johner's monomial fit for analytical calculations\n\n    Parameters\n    ----------\n    temp_kev:\n        Temperature [keV]\n    reaction:\n        The fusion reaction\n\n    Returns\n    -------\n    Reactivity of the reaction at the specified temperature(s) [m^3/s]\n\n    Notes\n    -----\n    Johner, Jean (2011). HELIOS: a zero-dimensional tool for next step and reactor\n    studies. Fusion Science and Technology, 59(2), 308-313. Appendix E.II\n    \"\"\"\n    if reaction != Reactions.D_T:\n        raise ValueError(\n            f\"This function only supports D-T, not {reaction.name.replace('_','-')}\"\n        )\n\n    if np.max(temp_kev) > 100:\n        bluemira_warn(\"The Johner parameterisation is not valid for T > 100 keV\")\n    if np.min(temp_kev) < 5.3:\n        bluemira_warn(\"The Johner parameterisation is not valid for T < 5.3 keV\")\n\n    sigma_v = np.zeros_like(temp_kev)\n    idx_1 = np.where((5.3 <= temp_kev) & (temp_kev <= 10.3))[0]\n    idx_2 = np.where((10.3 <= temp_kev) & (temp_kev <= 18.5))[0]\n    idx_3 = np.where((18.5 <= temp_kev) & (temp_kev <= 39.9))[0]\n    idx_4 = np.where((39.9 <= temp_kev) & (temp_kev <= 100.0))[0]\n    t1 = temp_kev[idx_1]\n    t2 = temp_kev[idx_2]\n    t3 = temp_kev[idx_3]\n\n    sigma_v[idx_1] = 1.15e-25 * t1**3\n    sigma_v[idx_2] = 1.18e-24 * t2**2\n    sigma_v[idx_3] = 2.18e-23 * t3\n    sigma_v[idx_4] = 8.69e-22\n    if isinstance(temp_kev, (float, int)):\n        return float(sigma_v)\n    return sigma_v",
  "class PowerLawScaling:\n    \"\"\"\n    Simple power law scaling object, of the form:\n\n    \\t:math:`c~\\\\pm~cerr \\\\times {a_{1}}^{n1\\\\pm err1}{a_{2}}^{n2\\\\pm err2}...`\n\n    Parameters\n    ----------\n    constant: float\n        The constant of the equation\n    constant_err: float\n        The error on the constant\n    exponents: Iterable\n        The ordered list of exponents\n    exp_errs: Union[np.ndarray, List, None]\n        The ordered list of errors of the exponents\n    \"\"\"  # noqa: W505\n\n    def __init__(\n        self,\n        constant: float,\n        constant_err: float,\n        exponents: Iterable[float],\n        exp_errs: Optional[Union[np.ndarray, List]] = None,\n    ):\n        self.c = constant\n        self.constant_err = constant_err\n        self.exponents = np.array(exponents)\n        if exp_errs is None:\n            self.errors = None\n        else:\n            self.errors = np.array(exp_errs)\n\n    def __call__(self, *args):\n        \"\"\"\n        Call the PowerLawScaling object for a set of arguments.\n        \"\"\"\n        if len(args) != len(self):\n            raise ValueError(\n                \"Number of arguments should be the same as the \"\n                f\"power law length. {len(args)} != {len(self)}\"\n            )\n        return self.calculate(*args)\n\n    def calculate(self, *args, constant=None, exponents=None):\n        \"\"\"\n        Call the PowerLawScaling object for a set of arguments.\n        \"\"\"\n        if constant is None:\n            constant = self.c\n        if exponents is None:\n            exponents = self.exponents\n        return constant * np.prod(np.power(args, exponents))\n\n    def calculate_range(self, *args) -> Tuple[float, float]:\n        \"\"\"\n        Calculate the range of the PowerLawScaling within the specified errors for a set\n        of arguments\n\n        Returns\n        -------\n        min_value:\n            Minimum value of the power law according to the specified errors\n        max_value:\n            Maximum value of the power law according to the specified errors\n        \"\"\"\n        if self.constant_err == 0.0 and self.errors is None:\n            raise ValueError(\n                \"No errors provided on PowerLawScaling, cannot calculate range.\"\n            )\n\n        constant_range = [self.c - self.constant_err, self.c + self.constant_err]\n\n        min_terms = np.zeros(len(self))\n        max_terms = np.zeros(len(self))\n        for i, (arg, exp, err) in enumerate(zip(args, self.exponents, self.errors)):\n            term_values = [arg ** (exp - err), arg ** (exp + err)]\n            min_terms[i] = min(term_values)\n            max_terms[i] = max(term_values)\n\n        return min(constant_range) * np.prod(min_terms), max(constant_range) * np.prod(\n            max_terms\n        )\n\n    def __len__(self) -> int:\n        \"\"\"\n        Get the length of the PowerLawScaling object.\n        \"\"\"\n        return len(self.exponents)",
  "def lambda_q(\n    B_t: float, q_cyl: float, p_sol: float, R_0: float, error: bool = False\n) -> Union[float, Tuple[float, float, float]]:\n    \"\"\"\n    Scrape-off layer power width scaling (Eich et al., 2011) [4]\n\n    Parameters\n    ----------\n    B_t:\n        Toroidal field [T]\n    q_cyl:\n        Cylindrical safety factor\n    p_sol:\n        Power in the scrape-off layer [W]\n    R_0:\n        Major radius [m]\n    method:\n        Scaling to use when calculating lambda_q\n    error:\n        Whether or not to report the value with +/- errors\n\n    Returns\n    -------\n    Scrape-off layer width at the outboard midplane [m]\n\n    Notes\n    -----\n    [4] Eich et al., 2011\n        <https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.107.215001>\n\n    \\t:math:`\\\\lambda_q=(0.73\\\\pm0.38)B_t^{-0.78\\\\pm0.25}q_{95}^{1.2\\\\pm0.27}P_{SOL}^{0.1\\\\pm0.11}R_{0}^{0.02\\\\pm0.2}`\n    \"\"\"  # noqa: W505\n    law = PowerLawScaling(\n        constant=0.73e-3,\n        constant_err=0.38e-3,\n        exponents=[-0.78, 1.2, 0.1, 0.02],\n        exp_errs=[0.25, 0.27, 0.11, 0.20],\n    )\n    p_sol = raw_uc(p_sol, \"W\", \"MW\")\n    value = law(B_t, q_cyl, p_sol, R_0)\n    if error:\n        min_value, max_value = law.calculate_range(B_t, q_cyl, p_sol, R_0)\n        return value, min_value, max_value\n    else:\n        return value",
  "def P_LH(  # noqa: N802\n    n_e: float, B_t: float, A: float, R_0: float, error: bool = False\n) -> Union[float, Tuple[float, float, float]]:\n    \"\"\"\n    Power requirement for accessing H-mode, Martin scaling [3]\n\n    Parameters\n    ----------\n    n_e:\n        Electron density [1/m^3]\n    B_t:\n        Toroidal field at the major radius [T]\n    A:\n        Plasma aspect ratio\n    R_0:\n        Plasma major radius [m]\n    error:\n        Whether or not to return error bar values\n\n    Returns\n    -------\n    Power required to access H-mode [W]\n\n    Notes\n    -----\n    [3] Martin et al., 2008,\n    <https://infoscience.epfl.ch/record/135655/files/1742-6596_123_1_012033.pdf>\n    equation (3)\n\n    \\t:math:`P_{LH}=2.15e^{\\\\pm 0.107}n_{e20}^{0.782 \\\\pm 0.037}`\n    \\t:math:`B_{T}^{0.772 \\\\pm 0.031}a^{0.975 \\\\pm 0.08}R_{0}^{0.999 \\\\pm 0.101}`\n    \"\"\"  # noqa :W505\n    law = PowerLawScaling(\n        constant=2.15e6,\n        constant_err=0.0,\n        exponents=[0, 0.782, 0.772, 0.975, 0.999],\n        exp_errs=[0.107, 0.037, 0.031, 0.08, 0.101],\n    )\n    leading_term = np.exp(1)\n    n_e20 = raw_uc(n_e, \"1/m^3\", \"1e20/m^3\")\n    a = R_0 / A\n    value = law(leading_term, n_e20, B_t, a, R_0)\n\n    if error:\n        min_value, max_value = law.calculate_range(leading_term, n_e20, B_t, a, R_0)\n        return value, min_value, max_value\n    else:\n        return value",
  "def IPB98y2(  # noqa: N802\n    I_p: float,\n    B_t: float,\n    p_sep: float,\n    n: float,\n    mass: float,\n    R_0: float,\n    A: float,\n    kappa: float,\n) -> float:\n    \"\"\"\n    ITER IPB98(y, 2) Confinement time scaling for ELMy H-mode [2]\n\n    Parameters\n    ----------\n    I_p:\n        Plasma current [A]\n    B_t:\n        Toroidal field at R_0 [T]\n    p_sep:\n        Separatrix power [W]  (a.k.a. loss power (corrected for charge exchange and\n        orbit losses))\n    n:\n        Line average plasma density [1/m^3]\n    mass:\n        Average ion mass [a.m.u.]\n    R_0:\n        Major radius [m]\n    A:\n        Aspect ratio\n    kappa:\n        Plasma elongation\n\n    Returns\n    -------\n    Energy confinement time [s]\n\n    Notes\n    -----\n    [2] ITER Physics Expert Group, Nucl. Fus. 39, 12, <https://iopscience.iop.org/article/10.1088/0029-5515/39/12/302/pdf>\n    equation (20)\n\n    \\t:math:`\\\\tau_{E}=0.0562I_p^{0.93}B_t^{0.15}P_{sep}^{-0.69}n^{0.41}M^{0.19}R_0^{1.97}A^{-0.58}\\\\kappa^{0.78}`\n    \"\"\"  # noqa :W505\n    I_p = raw_uc(I_p, \"A\", \"MA\")\n    p_sep = raw_uc(p_sep, \"W\", \"MW\")\n    n = raw_uc(n, \"1/m^3\", \"1e19/m^3\")\n\n    law = PowerLawScaling(\n        constant=0.0562,\n        constant_err=0.0,\n        exponents=[0.93, 0.15, -0.69, 0.41, 0.19, 1.97, -0.58, 0.78],\n    )\n    return law(I_p, B_t, p_sep, n, mass, R_0, A, kappa)",
  "def __init__(\n        self,\n        constant: float,\n        constant_err: float,\n        exponents: Iterable[float],\n        exp_errs: Optional[Union[np.ndarray, List]] = None,\n    ):\n        self.c = constant\n        self.constant_err = constant_err\n        self.exponents = np.array(exponents)\n        if exp_errs is None:\n            self.errors = None\n        else:\n            self.errors = np.array(exp_errs)",
  "def __call__(self, *args):\n        \"\"\"\n        Call the PowerLawScaling object for a set of arguments.\n        \"\"\"\n        if len(args) != len(self):\n            raise ValueError(\n                \"Number of arguments should be the same as the \"\n                f\"power law length. {len(args)} != {len(self)}\"\n            )\n        return self.calculate(*args)",
  "def calculate(self, *args, constant=None, exponents=None):\n        \"\"\"\n        Call the PowerLawScaling object for a set of arguments.\n        \"\"\"\n        if constant is None:\n            constant = self.c\n        if exponents is None:\n            exponents = self.exponents\n        return constant * np.prod(np.power(args, exponents))",
  "def calculate_range(self, *args) -> Tuple[float, float]:\n        \"\"\"\n        Calculate the range of the PowerLawScaling within the specified errors for a set\n        of arguments\n\n        Returns\n        -------\n        min_value:\n            Minimum value of the power law according to the specified errors\n        max_value:\n            Maximum value of the power law according to the specified errors\n        \"\"\"\n        if self.constant_err == 0.0 and self.errors is None:\n            raise ValueError(\n                \"No errors provided on PowerLawScaling, cannot calculate range.\"\n            )\n\n        constant_range = [self.c - self.constant_err, self.c + self.constant_err]\n\n        min_terms = np.zeros(len(self))\n        max_terms = np.zeros(len(self))\n        for i, (arg, exp, err) in enumerate(zip(args, self.exponents, self.errors)):\n            term_values = [arg ** (exp - err), arg ** (exp + err)]\n            min_terms[i] = min(term_values)\n            max_terms[i] = max(term_values)\n\n        return min(constant_range) * np.prod(min_terms), max(constant_range) * np.prod(\n            max_terms\n        )",
  "def __len__(self) -> int:\n        \"\"\"\n        Get the length of the PowerLawScaling object.\n        \"\"\"\n        return len(self.exponents)",
  "def estimate_loop_voltage(\n    R_0: float, B_t: float, Z_eff: float, T_e: float, n_e: float, q_0: float\n) -> float:\n    \"\"\"\n    A 0-D estimate of the loop voltage during burn\n\n    Parameters\n    ----------\n    R_0:\n        Major radius [m]\n    B_t:\n        Toroidal field on axis [T]\n    Z_eff:\n        Effective charge [a.m.u.]\n    T_e:\n        Electron temperature on axis [eV]\n    n_e:\n        Electron density [1/m^3]\n    q_0:\n        Safety factor on axis\n\n    Returns\n    -------\n    Loop voltage during burn [V]\n\n    Notes\n    -----\n    H. Zohm, W. Morris (2022)\n\n    \\t:math:`v_{loop}=2\\\\pi R_{0}\\\\dfrac{2\\\\pi B_{t}}{\\\\mu_{0}q_{0}\\\\sigma_{0}R_{0}}`\n\n    where :math:`\\\\sigma_{0}` is the Spitzer conductivity on axis:\n    \\t:math:`\\\\sigma_{0} = 1.92e4 (2-Z_{eff}^{-1/3}) \\\\dfrac{T_{e}^{3/2}}{Z_{eff}ln\\\\Lambda}`\n\n    Assumes no non-inductive current on axis\n\n    Assumes a circular cross-section on axis\n\n    There is no neo-classical resistivity on axis because there are no trapped particles\n    \"\"\"  # noqa: W505\n    ln_lambda = coulomb_logarithm(T_e * EV_TO_J / K_BOLTZMANN, n_e)\n    sigma = spitzer_conductivity(Z_eff, T_e, ln_lambda)\n\n    # Current density on axis\n    j_0 = 2 * B_t / (MU_0 * q_0 * R_0)\n    v_loop = 2 * np.pi * R_0 * j_0 / sigma\n    return v_loop",
  "def estimate_Le(A: float, kappa: float) -> float:  # noqa: N802\n    \"\"\"\n    Estimate the normalised external plasma self-inductance.\n\n    Parameters\n    ----------\n    A:\n        Last closed flux surface aspect ratio\n    kappa:\n        Last closed flux surface elongation\n\n    Returns\n    -------\n    Normalised plasma external inductance\n\n    Notes\n    -----\n    Hirshman and Neilson, 1986\n    https://pubs.aip.org/aip/pfl/article/29/3/790/944223/External-inductance-of-an-axisymmetric-plasma\n    Assuming a LCFS parameterisation as per:\n    :py:func:`bluemira.equilibria.shapes.flux_surface_hirshman`\n    \"\"\"\n    eps = 1 / A\n    sqrt_eps = np.sqrt(eps)\n\n    a = (\n        (1 + 1.81 * sqrt_eps + 2.05 * eps) * np.log(8 * A)\n        - 2.0\n        - 9.25 * sqrt_eps\n        + 1.21 * eps\n    )\n    b = 0.73 * sqrt_eps * (1 + 2 * eps**4 - 6 * eps**5 + 3.7 * eps**6)\n    return a * (1 - eps) / (1 - eps + b * kappa)",
  "def estimate_M(A: float, kappa: float) -> float:  # noqa: N802\n    \"\"\"\n    Estimate the plasma mutual inductance.\n\n    Parameters\n    ----------\n    A:\n        Last closed flux surface aspect ratio\n    kappa:\n        Last closed flux surface elongation\n\n    Returns\n    -------\n    Plasma mutual inductance\n\n    Notes\n    -----\n    Hirshman and Neilson, 1986\n    https://pubs.aip.org/aip/pfl/article/29/3/790/944223/External-inductance-of-an-axisymmetric-plasma\n    Assuming a LCFS parameterisation as per:\n    :py:func:`bluemira.equilibria.shapes.flux_surface_hirshman`\n    \"\"\"\n    eps = 1 / A\n\n    c = 1 + 0.98 * eps**2 + 0.49 * eps**4 + 1.47 * eps**6\n    d = 0.25 * eps * (1 + 0.84 * eps - 1.44 * eps**2)\n    return (1 - eps) ** 2 / ((1 - eps) ** 2 * c + d * np.sqrt(kappa))",
  "def calc_cyl_safety_factor(R_0: float, A: float, B_0: float, I_p: float) -> float:\n    \"\"\"\n    Calculate the cylindrical safety factor.\n\n    Parameters\n    ----------\n    R_0:\n        Plasma major radius [m]\n    A:\n        Plasma aspect ratio\n    B_0:\n        Toroidal field at major radius [T]\n    I_p:\n        Plasma current [A]\n\n    Returns\n    -------\n    Cylindrical safety factor\n\n    Notes\n    -----\n    Sometimes also written with :math:`\\\\dfrac{2\\\\pi}{\\\\mu_{0}} = 5` and I_p in [MA]\n    \"\"\"\n    a = R_0 / A\n    return 2 * np.pi * a**2 * B_0 / (MU_0 * R_0 * I_p)",
  "def calc_qstar_freidberg(\n    R_0: float, A: float, B_0: float, I_p: float, kappa: float\n) -> float:\n    \"\"\"\n    Calculate the kink safety factor at the plasma edge\n\n    \\t:math:`q_{*}=\\\\dfrac{2\\\\pi a^2 B_0}{\\\\mu_0 R_0 I_p}`\n    \\t:math:`\\\\bigg(\\\\dfrac{1+\\\\kappa^2}{2}\\\\bigg)`\n\n    Parameters\n    ----------\n    R_0:\n        Plasma major radius [m]\n    A:\n        Plasma aspect ratio\n    B_0:\n        Toroidal field at major radius [T]\n    I_p:\n        Plasma current [A]\n    kappa:\n        Plasma elongation\n\n    Returns\n    -------\n    Kink safety factor\n\n    Notes\n    -----\n    Freidberg, Ideal MHD, p 131\n    \"\"\"\n    shape_factor = 0.5 * (1 + kappa**2)\n    q_cyl = calc_cyl_safety_factor(R_0, A, B_0, I_p)\n    return q_cyl * shape_factor",
  "def calc_qstar_uckan(\n    R_0: float, A: float, B_0: float, I_p: float, kappa: float, delta: float\n) -> float:\n    \"\"\"\n    Calculate the cylindrical equivalent safety factor at the plasma edge\n\n    Parameters\n    ----------\n    R_0:\n        Plasma major radius [m]\n    A:\n        Plasma aspect ratio\n    B_0:\n        Toroidal field at major radius [T]\n    I_p:\n        Plasma current [A]\n    kappa:\n        Plasma elongation\n    delta:\n        Plasma triangularity\n\n    Returns\n    -------\n    Cylindrical equivalent safety factor\n\n    Notes\n    -----\n    Uckan et al., ITER Physics Design Guidelines, 1989, sec. 2.3\n    https://inis.iaea.org/search/search.aspx?orig_q=RN:21068960\n    \"\"\"\n    shape_factor = 0.5 + 0.5 * kappa**2 * (1 + 2 * delta**2 - 1.2 * delta**3)\n    q_cyl = calc_cyl_safety_factor(R_0, A, B_0, I_p)\n    return q_cyl * shape_factor",
  "def estimate_q95_uckan(\n    R_0: float, A: float, B_0: float, I_p: float, kappa: float, delta: float\n) -> float:\n    \"\"\"\n    Estimate safety factor at the 95th percentile flux surface based on an empirical fit.\n\n    Parameters\n    ----------\n    R_0:\n        Plasma major radius [m]\n    A:\n        Plasma aspect ratio\n    B_0:\n        Toroidal field at major radius [T]\n    I_p:\n        Plasma current [A]\n    kappa:\n        Plasma elongation\n    delta:\n        Plasma triangularity\n\n    Notes\n    -----\n    Uckan et al., ITER Physics Design Guidelines, 1989, sec. 2.3\n    https://inis.iaea.org/search/search.aspx?orig_q=RN:21068960\n    Ref [11] in the above does not appear to include the geometry factor\n    \"\"\"\n    eps = 1 / A\n    geometry_factor = (1.17 - 0.65 * eps) / (1 - eps**2) ** 2\n    q_star = calc_qstar_uckan(R_0, A, B_0, I_p, kappa, delta)\n    return q_star * geometry_factor",
  "def estimate_li_wesson(\n    q_star: float,\n    q_0: float = 1.0,\n) -> float:\n    \"\"\"\n    Estimate the normalised plasma internal inductance based on an empirical fit.\n\n    Parameters\n    ----------\n    q_star:\n        Cylindrical equivalent safety factor\n    q_0:\n        Safety factor on axis\n\n    Returns\n    -------\n    Normalised lasma internal inductance\n\n    Notes\n    -----\n    Wesson, Tokamaks 3rd edition, page 120\n\n    This appears to give high values for li, even when using q* at rho=0.95\n    \"\"\"\n    nu = q_star / q_0 - 1.0\n    return np.log(1.65 + 0.89 * nu)",
  "class Args:\n    \"\"\"Command line arguments.\"\"\"\n\n    examples_dir: str\n    exclude_pattern: List[str]\n    plotting_on: bool",
  "def parse_args(sys_args: List[str]) -> Args:\n    \"\"\"Parse command line arguments\"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument(\n        \"--examples-dir\",\n        default=EXAMPLES_ROOT,\n        help=f\"the directory in which to look for examples (default: {EXAMPLES_ROOT})\",\n    )\n    parser.add_argument(\n        \"-e\",\n        \"--exclude-pattern\",\n        action=\"append\",\n        default=EXCLUDE_PATTERNS,\n        help=(\n            \"do not run example files that contain this regex pattern. \"\n            \"This argument may be used more than once\"\n        ),\n    )\n    parser.add_argument(\n        \"--plotting-on\",\n        action=\"store_true\",\n        default=False,\n        help=\"enable interactive plotting windows\",\n    )\n    args = parser.parse_args(sys_args)\n    return Args(**vars(args))",
  "def find_python_files(examples_dir: str, exclude_patterns: List[str]) -> List[str]:\n    \"\"\"Glob for Python files in the given directory.\"\"\"\n    files = []\n    for path in Path(examples_dir).rglob(\"*.py\"):\n        if not any(re.search(p, str(path)) for p in exclude_patterns):\n            files.append(path)\n    return sorted(files)",
  "def run_example(file_path: str) -> bool:\n    \"\"\"Run the given Python file; return True if no errors, else False.\"\"\"\n    source = Path(file_path).read_text()\n    try:\n        exec(compile(source, file_path, \"exec\"), globals())  # noqa: S102\n    except Exception as e:\n        print(e, file=sys.stderr)\n        return False\n    finally:\n        plt.close(\"all\")\n    return True",
  "def run_examples(\n    example_files: List[str], plotting_on: bool = False\n) -> List[Tuple[str, bool]]:\n    \"\"\"\n    Run the given example files.\n\n    Returns the list of examples run, along with a boolean indicating\n    whether there were any errors when running the example (True\n    indicating no errors, and False the opposite).\n    \"\"\"\n    if not plotting_on:\n        mpl.use(\"Agg\")\n        # Disable CAD viewer by mocking out FreeCAD API's displayer.\n        # Note that if we use a new CAD backend, this must be changed.\n        mock.patch(\"bluemira.codes._freecadapi.show_cad\").start()\n\n    failed = []\n    for example in example_files:\n        display_path = Path(example).relative_to(args.examples_dir)\n        print(BANNER.format(display_path))\n        result = run_example(example)\n        # Flush stdout so we don't get un-flushed output from previous\n        # examples under this example's banner\n        sys.stdout.flush()\n        failed.append((display_path, result))\n    return failed",
  "class Warning:\n    \"\"\"Stores information from a Python warning.\"\"\"\n\n    message: str\n    category: str\n    when: str\n    filename: str\n    lineno: int\n\n    def __str__(self) -> str:\n        \"\"\"Convert to formatted string.\"\"\"\n        return f\"{self.filename}:{self.lineno}: {self.category}: {self.message}\"",
  "def parse_args(sys_args: List[str]) -> argparse.Namespace:\n    \"\"\"Parse command line options.\"\"\"\n    parser = argparse.ArgumentParser(PROG, description=__doc__)\n    parser.add_argument(\"report_file\", help=\"path to .report.json to parse\")\n    parser.add_argument(\n        \"--compare\",\n        default=None,\n        help=\"path to .report.json to compare warnings to\",\n        metavar=\"baseline_report_file\",\n    )\n    return parser.parse_args(sys_args)",
  "def load_warnings(file_path: str) -> Set[Warning]:\n    \"\"\"Load a set of warnings from file.\"\"\"\n    with open(file_path, \"r\") as f:\n        data = json.load(f)\n    try:\n        return set([Warning(**warning) for warning in data[WARNINGS_KEY]])\n    except KeyError:  # no warnings found\n        return set()",
  "def format_warnings_list(warnings: Iterable[Warning]) -> List[str]:\n    \"\"\"Format the list of warnings into lines of markdown.\"\"\"\n    whens: Dict[str, List[Warning]] = {}\n    for warning in warnings:\n        try:\n            whens[warning.when].append(warning)\n        except KeyError:\n            whens[warning.when] = [warning]\n    lines = []\n    for when, warns in whens.items():\n        lines.append(f\"#### On {when}\\n\")\n        for warn in warns:\n            lines.append(f\"- `{warn}`\")\n        lines.append(\"\")\n    return lines[:-1]",
  "def make_collapsable(md_lines: List[str], summary: str) -> List[str]:\n    \"\"\"Surround the given lines in html to make them collapsable.\"\"\"\n    lines = [\n        \"<details>\\n\",\n        f\"{' '*INDENT_SIZE}<summary>{summary}</summary>\\n\",\n    ]\n    lines.extend(md_lines)\n    lines.append(\"\\n</details>\")\n    return lines",
  "def elements_not_in(head: Iterable[Any], ref: Iterable[Any]) -> List:\n    \"\"\"Find the elements that are in head, but not ref.\"\"\"\n    not_in = []\n    for head_el in head:\n        if head_el not in ref:\n            not_in.append(head_el)\n    return not_in",
  "def compare_warnings(\n    head_warnings: Set[Warning], ref_warnings: Set[Warning]\n) -> Tuple[List[Warning], List[Warning]]:\n    \"\"\"Find new and fixed warnings in 'head' using 'ref' as baseline.\"\"\"\n    new_warnings = elements_not_in(head_warnings, ref_warnings)\n    fixed_warnings = elements_not_in(ref_warnings, head_warnings)\n    return new_warnings, fixed_warnings",
  "def format_warning_report(sys_args: List[str]) -> int:\n    \"\"\"Run the script.\"\"\"\n    inputs = parse_args(sys_args)\n    warnings = load_warnings(inputs.report_file)\n    exit_code = len(warnings)\n    report = [\"### \u26a0\ufe0f Warning Report\\n\"]\n    warning_list_md = format_warnings_list(warnings)\n    if inputs.compare is not None:\n        ref_warnings = load_warnings(inputs.compare)\n        new, fixed = compare_warnings(warnings, ref_warnings)\n        tada = \" \ud83c\udf89\" if len(new) == 0 else \"\"\n        report.append(\n            f\"Found {len(new)} new warning{'' if len(new) == 1 else 's'}, \"\n            f\"{len(fixed)} fixed warning{'' if len(fixed) == 1 else 's'}.{tada}\\n\"\n        )\n        if new:\n            warning_list = format_warnings_list(new)\n            report.extend(\n                make_collapsable(warning_list, f\"New warnings ({len(warnings)})\")\n            )\n        exit_code = len(new)\n    else:\n        plural = \"\" if len(warnings) == 1 else \"s\"\n        tada = \" \ud83c\udf89\" if len(warnings) == 0 else \"\"\n        report.append(f\"Found {len(warnings)} warning{plural}.{tada}\\n\")\n    if warnings:\n        report.extend(\n            make_collapsable(warning_list_md, f\"All warnings ({len(warnings)})\")\n        )\n    print(\"\\n\".join(report))\n    return exit_code",
  "def __str__(self) -> str:\n        \"\"\"Convert to formatted string.\"\"\"\n        return f\"{self.filename}:{self.lineno}: {self.category}: {self.message}\"",
  "def arguments():\n    \"\"\"\n    Parse arguments for copyright script\n    \"\"\"\n    parser = ArgumentParser(description=__doc__)\n    parser.add_argument(\n        \"files\",\n        metavar=\"files\",\n        type=str,\n        default=[],\n        nargs=\"*\",\n        help=\"python files to be updated\",\n    )\n    args = parser.parse_args()\n    return args.files",
  "def edit_files(files: List[str], copyright_line: str):\n    \"\"\"\n    Edit files in place\n    \"\"\"\n    for file in files:\n        with fileinput.FileInput(file, inplace=True) as fh:\n            for line in fh:\n                if line.startswith(r\"# Copyright\") and copyright_line not in line:\n                    print(line.replace(line.split(\" \", 4)[-2], copyright_line), end=\"\")\n                    yield file\n                elif (\n                    \"conf.py\" in file\n                    and line.startswith(r\"copyright\")\n                    and copyright_line not in line\n                ):\n                    print(\n                        line.replace(line.split(\" \", 4)[-2], f'\"{copyright_line},'),\n                        end=\"\",\n                    )\n                else:\n                    print(line, end=\"\")",
  "def main():\n    \"\"\"Run the copyright updater\"\"\"\n    edited = list(edit_files(arguments(), r\"2021-{}\".format(date.today().year)))\n\n    if edited != []:\n        for file in edited:\n            print(f\"Updated {file}\")\n        exit(1)",
  "def setup(app):\n    \"\"\"Setup function for sphinx\"\"\"\n    # https://stackoverflow.com/questions/14110790/numbered-math-equations-in-restructuredtext\n    app.add_css_file(\"css/custom.css\")\n    app.add_directive(\"params\", ParamsDirective)\n    app.connect(\"autoapi-skip-member\", SkipAlreadyDocumented())",
  "class ParamsDirective(Directive):\n    \"\"\"\n    Generates the default parameters table for the given analysis module and class.\n    \"\"\"\n\n    has_content = True\n\n    def run(self):\n        \"\"\"\n        Run the directive.\n        \"\"\"\n        tab_width = self.options.get(\"tab-width\", self.state.document.settings.tab_width)\n        source = self.state_machine.input_lines.source(\n            self.lineno - self.state_machine.input_offset - 1\n        )\n\n        try:\n            import importlib\n\n            analysis_module_name = self.content[0]\n            analysis_class_name = self.content[1]\n\n            analysis_module = importlib.import_module(analysis_module_name)\n            analysis_class = getattr(analysis_module, analysis_class_name)\n\n            text = analysis_class.default_params.tabulator(tablefmt=\"rst\")\n            lines = statemachine.string2lines(text, tab_width, convert_whitespace=True)\n            self.state_machine.insert_input(lines, source)\n            return []\n        except Exception:\n            return [\n                nodes.error(\n                    None,\n                    nodes.paragraph(\n                        text=\"Unable to generate parameter documentation at %s:%d:\"\n                        % (os.path.basename(source), self.lineno)\n                    ),\n                    nodes.paragraph(text=str(sys.exc_info()[1])),\n                )\n            ]",
  "class SkipAlreadyDocumented:\n    \"\"\"\n    Skip already documented items for autoapi.\n\n    For use with global variables that are defined twice\n    for instance in try..except import expressions and similar situations\n    \"\"\"\n\n    def __init__(self):\n        skip_list = [\n            \"bluemira.codes.process.api.ENABLED\",\n            \"bluemira.codes.process.api.PROCESS_DICT\",\n            \"bluemira.codes._nlopt_api.NLOPTOptimiser._opt_inputs_ready\",\n            \"bluemira.codes._polyscope.DefaultDisplayOptions.colour\",\n            \"bluemira.codes._freecadapi.DefaultDisplayOptions.colour\",\n        ]\n\n        self.skip_dict = {i: 0 for i in skip_list}\n\n    def __call__(self, app, what, name, obj, skip, options):\n        \"\"\"autoapi-skip-member definition\"\"\"\n        if name in self.skip_dict:\n            # Skip first occurrence\n            if self.skip_dict[name] < 1:\n                skip = True\n            self.skip_dict[name] += 1\n        return skip",
  "def html_visit_inheritance_diagram(self, node):\n    \"\"\"\n    Hacks the uri of the inheritance diagram if its an autoapi diagram\n\n    By default the refuri link is to ../../<expected file>.html whereas\n    the actual file lives at autoapi/bluemira/<expected file>.html.\n\n    refuri is used for parent classes outside of the current file.\n\n    The original function appends a further ../ to the refuri which has the\n    effect of returning to the root directory of the built documentation.\n\n    I havent found a method to set the default expected path and it seems to\n    be a slight incompatibility between autoapi and inheritance-diagram\n\n    This replaces the wrong path with a corrected path to the autoapi folder,\n    otherwise we get 404 links from the diagram links.\n    \"\"\"\n    current_filename = self.builder.current_docname + self.builder.out_suffix\n    if \"autoapi\" in current_filename:\n        for n in node:\n            refuri = n.get(\"refuri\")\n            if refuri is not None:\n                n[\"refuri\"] = f\"autoapi/bluemira/{refuri[6:]}\"\n\n    return _old_html_visit_inheritance_diagram(self, node)",
  "def new_parse_wrapper(parse):\n    \"\"\"Wrap `myst_nb.sphinx_.Parser.parse`\"\"\"\n\n    def wrapper(self, inputstring, document):\n        \"\"\"\n        Hacks links to other example notebooks written in py:percent format\n\n        The linking to other py:percent formatted examples only gets converted to an\n        html link if the extension is 'ipynb'. We replace '.ex.py' with '.ipynb' for\n        all text in the original file.\n\n        This could be made more robust but it is unlikely that '.ex.py' is used anywhere\n        else.\n        \"\"\"\n        inputstring = inputstring.replace(\".ex.py\", \".ipynb\")\n        return parse(self, inputstring, document)\n\n    return wrapper",
  "def run(self):\n        \"\"\"\n        Run the directive.\n        \"\"\"\n        tab_width = self.options.get(\"tab-width\", self.state.document.settings.tab_width)\n        source = self.state_machine.input_lines.source(\n            self.lineno - self.state_machine.input_offset - 1\n        )\n\n        try:\n            import importlib\n\n            analysis_module_name = self.content[0]\n            analysis_class_name = self.content[1]\n\n            analysis_module = importlib.import_module(analysis_module_name)\n            analysis_class = getattr(analysis_module, analysis_class_name)\n\n            text = analysis_class.default_params.tabulator(tablefmt=\"rst\")\n            lines = statemachine.string2lines(text, tab_width, convert_whitespace=True)\n            self.state_machine.insert_input(lines, source)\n            return []\n        except Exception:\n            return [\n                nodes.error(\n                    None,\n                    nodes.paragraph(\n                        text=\"Unable to generate parameter documentation at %s:%d:\"\n                        % (os.path.basename(source), self.lineno)\n                    ),\n                    nodes.paragraph(text=str(sys.exc_info()[1])),\n                )\n            ]",
  "def __init__(self):\n        skip_list = [\n            \"bluemira.codes.process.api.ENABLED\",\n            \"bluemira.codes.process.api.PROCESS_DICT\",\n            \"bluemira.codes._nlopt_api.NLOPTOptimiser._opt_inputs_ready\",\n            \"bluemira.codes._polyscope.DefaultDisplayOptions.colour\",\n            \"bluemira.codes._freecadapi.DefaultDisplayOptions.colour\",\n        ]\n\n        self.skip_dict = {i: 0 for i in skip_list}",
  "def __call__(self, app, what, name, obj, skip, options):\n        \"\"\"autoapi-skip-member definition\"\"\"\n        if name in self.skip_dict:\n            # Skip first occurrence\n            if self.skip_dict[name] < 1:\n                skip = True\n            self.skip_dict[name] += 1\n        return skip",
  "def wrapper(self, inputstring, document):\n        \"\"\"\n        Hacks links to other example notebooks written in py:percent format\n\n        The linking to other py:percent formatted examples only gets converted to an\n        html link if the extension is 'ipynb'. We replace '.ex.py' with '.ipynb' for\n        all text in the original file.\n\n        This could be made more robust but it is unlikely that '.ex.py' is used anywhere\n        else.\n        \"\"\"\n        inputstring = inputstring.replace(\".ex.py\", \".ipynb\")\n        return parse(self, inputstring, document)",
  "class ClassicalSNConstraints(MagneticConstraintSet):\n    def __init__(\n        self, R_0, A, kappa_upper, kappa_lower, delta_upper, delta_lower, n_points=40\n    ):\n        shape = flux_surface_johner(\n            R_0,\n            0,\n            R_0 / A,\n            kappa_upper,\n            kappa_lower,\n            delta_upper,\n            delta_lower,\n            psi_u_neg=180,\n            psi_u_pos=5,\n            psi_l_neg=-120,\n            psi_l_pos=30,\n            n=n_points,\n        )\n\n        isoflux = IsofluxConstraint(\n            x=shape.x, z=shape.z, ref_x=shape.x[0], ref_z=shape.z[0]\n        )\n        xpoint = FieldNullConstraint(\n            x=R_0 - delta_lower * R_0 / A, z=-kappa_lower * R_0 / A\n        )\n        super().__init__([isoflux, xpoint])",
  "def __init__(\n        self, R_0, A, kappa_upper, kappa_lower, delta_upper, delta_lower, n_points=40\n    ):\n        shape = flux_surface_johner(\n            R_0,\n            0,\n            R_0 / A,\n            kappa_upper,\n            kappa_lower,\n            delta_upper,\n            delta_lower,\n            psi_u_neg=180,\n            psi_u_pos=5,\n            psi_l_neg=-120,\n            psi_l_pos=30,\n            n=n_points,\n        )\n\n        isoflux = IsofluxConstraint(\n            x=shape.x, z=shape.z, ref_x=shape.x[0], ref_z=shape.z[0]\n        )\n        xpoint = FieldNullConstraint(\n            x=R_0 - delta_lower * R_0 / A, z=-kappa_lower * R_0 / A\n        )\n        super().__init__([isoflux, xpoint])",
  "class AngleAnnotation(Arc):\n    \"\"\"\n    Draws an arc between two vectors which appears circular in display space.\n\n    https://github.com/matplotlib/matplotlib/blob/main/examples/text_labels_and_annotations/angle_annotation.py\n    \"\"\"\n\n    def __init__(\n        self,\n        xy,\n        p1,\n        p2,\n        size=75,\n        unit=\"points\",\n        ax=None,\n        text=\"\",\n        textposition=\"inside\",\n        text_kw=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        xy, p1, p2 : tuple or array of two floats\n            Center position and two points. Angle annotation is drawn between\n            the two vectors connecting *p1* and *p2* with *xy*, respectively.\n            Units are data coordinates.\n\n        size : float\n            Diameter of the angle annotation in units specified by *unit*.\n\n        unit : str\n            One of the following strings to specify the unit of *size*:\n\n            * \"pixels\": pixels\n            * \"points\": points, use points instead of pixels to not have a\n              dependence on the DPI\n            * \"axes width\", \"axes height\": relative units of Axes width, height\n            * \"axes min\", \"axes max\": minimum or maximum of relative Axes\n              width, height\n\n        ax : `matplotlib.axes.Axes`\n            The Axes to add the angle annotation to.\n\n        text : str\n            The text to mark the angle with.\n\n        textposition : {\"inside\", \"outside\", \"edge\"}\n            Whether to show the text in- or outside the arc. \"edge\" can be used\n            for custom positions anchored at the arc's edge.\n\n        text_kw : dict\n            Dictionary of arguments passed to the Annotation.\n\n        **kwargs\n            Further parameters are passed to `matplotlib.patches.Arc`. Use this\n            to specify, color, linewidth etc. of the arc.\n\n        \"\"\"\n        self.ax = ax or plt.gca()\n        self._xydata = xy  # in data coordinates\n        self.vec1 = p1\n        self.vec2 = p2\n        self.size = size\n        self.unit = unit\n        self.textposition = textposition\n\n        super().__init__(\n            self._xydata,\n            size,\n            size,\n            angle=0.0,\n            theta1=self.theta1,\n            theta2=self.theta2,\n            **kwargs,\n        )\n\n        self.set_transform(IdentityTransform())\n        self.ax.add_patch(self)\n\n        self.kw = dict(\n            ha=\"center\",\n            va=\"center\",\n            xycoords=IdentityTransform(),\n            xytext=(0, 0),\n            textcoords=\"offset points\",\n            annotation_clip=True,\n        )\n        self.kw.update(text_kw or {})\n        self.text = ax.annotate(text, xy=self._center, **self.kw)\n\n    def get_size(self):  # noqa: D102\n        factor = 1.0\n        if self.unit == \"points\":\n            factor = self.ax.figure.dpi / 72.0\n        elif self.unit[:4] == \"axes\":\n            b = TransformedBbox(Bbox.unit(), self.ax.transAxes)\n            dic = {\n                \"max\": max(b.width, b.height),\n                \"min\": min(b.width, b.height),\n                \"width\": b.width,\n                \"height\": b.height,\n            }\n            factor = dic[self.unit[5:]]\n        return self.size * factor\n\n    def set_size(self, size):  # noqa: D102\n        self.size = size\n\n    def get_center_in_pixels(self):\n        \"\"\"Return center in pixels\"\"\"\n        return self.ax.transData.transform(self._xydata)\n\n    def set_center(self, xy):\n        \"\"\"Set center in data coordinates\"\"\"\n        self._xydata = xy\n\n    def get_theta(self, vec):  # noqa: D102\n        vec_in_pixels = self.ax.transData.transform(vec) - self._center\n        return np.rad2deg(np.arctan2(vec_in_pixels[1], vec_in_pixels[0]))\n\n    def get_theta1(self):  # noqa: D102\n        return self.get_theta(self.vec1)\n\n    def get_theta2(self):  # noqa: D102\n        return self.get_theta(self.vec2)\n\n    def set_theta(self, angle):  # noqa: D102\n        pass\n\n    # Redefine attributes of the Arc to always give values in pixel space\n    _center = property(get_center_in_pixels, set_center)\n    theta1 = property(get_theta1, set_theta)\n    theta2 = property(get_theta2, set_theta)\n    width = property(get_size, set_size)\n    height = property(get_size, set_size)\n\n    # The following two methods are needed to update the text position.\n    def draw(self, renderer):  # noqa: D102\n        self.update_text()\n        super().draw(renderer)\n\n    def update_text(self):  # noqa: D102\n        c = self._center\n        s = self.get_size()\n        angle_span = (self.theta2 - self.theta1) % 360\n        angle = np.deg2rad(self.theta1 + angle_span / 2)\n        r = s / 2\n        if self.textposition == \"inside\":\n            r = s / np.interp(angle_span, [60, 90, 135, 180], [3.3, 3.5, 3.8, 4])\n        self.text.xy = c + r * np.array([np.cos(angle), np.sin(angle)])\n        if self.textposition == \"outside\":\n\n            def R90(a, r, w, h):  # noqa: N802\n                if a < np.arctan(h / 2 / (r + w / 2)):\n                    return np.sqrt((r + w / 2) ** 2 + (np.tan(a) * (r + w / 2)) ** 2)\n                else:\n                    c = np.sqrt((w / 2) ** 2 + (h / 2) ** 2)\n                    T = np.arcsin(  # noqa: N806\n                        c * np.cos(np.pi / 2 - a + np.arcsin(h / 2 / c)) / r\n                    )\n                    xy = r * np.array([np.cos(a + T), np.sin(a + T)])\n                    xy += np.array([w / 2, h / 2])\n                    return np.sqrt(np.sum(xy**2))\n\n            def R(a, r, w, h):  # noqa: N802\n                aa = (a % (np.pi / 4)) * ((a % (np.pi / 2)) <= np.pi / 4) + (\n                    np.pi / 4 - (a % (np.pi / 4))\n                ) * ((a % (np.pi / 2)) >= np.pi / 4)\n                return R90(aa, r, *[w, h][:: int(np.sign(np.cos(2 * a)))])\n\n            bbox = self.text.get_window_extent()\n            X = R(angle, r, bbox.width, bbox.height)  # noqa: N806\n            trans = self.ax.figure.dpi_scale_trans.inverted()\n            offs = trans.transform(((X - s / 2), 0))[0] * 72\n            self.text.set_position([offs * np.cos(angle), offs * np.sin(angle)])",
  "def draw_brace(span, axis_offset, text, ax=None, vertical=False, sideswitch=False):\n    \"\"\"\n    Draws an annotated brace on the axes.\n\n    https://stackoverflow.com/questions/18386210/annotating-ranges-of-data-in-matplotlib/68180887#68180887\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(1, 1)\n        ax.set_aspect(\"equal\")\n\n    min_, max_ = span\n    span = max_ - min_\n\n    ax_xmin, ax_xmax = ax.get_xlim()\n    xax_span = ax_xmax - ax_xmin\n\n    ymin, ymax = ax.get_ylim()\n    yspan = ymax - ymin\n    resolution = int(span / xax_span * 100) * 2 + 1  # guaranteed uneven\n    beta = 300.0 / xax_span  # the higher this is, the smaller the radius\n\n    x = np.linspace(min_, max_, resolution)\n    x_half = x[: int(resolution / 2) + 1]\n    y_half_brace = 1 / (1.0 + np.exp(-beta * (x_half - x_half[0]))) + 1 / (\n        1.0 + np.exp(-beta * (x_half - x_half[-1]))\n    )\n    y = np.concatenate((y_half_brace, y_half_brace[-2::-1]))\n    y = axis_offset + (0.05 * y - 0.01) * yspan  # adjust vertical position\n\n    if vertical:\n        px = y\n        py = x\n\n        textx = axis_offset + 0.05 * xax_span\n        texty = (max_ + min_) / 2.0\n        ha = \"left\"\n        va = \"center\"\n    else:\n        px = x\n        py = y\n\n        textx = (max_ + min_) / 2.0\n        texty = axis_offset + 0.07 * yspan\n\n        va = \"bottom\"\n        ha = \"center\"\n\n    if sideswitch:\n        py = -py\n        if vertical:\n            textx = -(axis_offset + 0.10 * xax_span)\n        else:\n            texty = -(axis_offset + 0.17 * yspan)\n\n    ax.plot(px, py, color=\"black\", lw=1)\n\n    ax.text(textx, texty, text, ha=ha, va=va, math_fontfamily=\"cm\")\n\n    return ax",
  "def semi_circle_angle_fig(height=20, width=20, ax=None, x0=50, y0=0):\n    \"\"\"\n    Create semi circle chord figure\n    \"\"\"\n    x = np.linspace(-width + x0, width + x0, num=1000)\n    y = height * np.sqrt(1 - ((x - x0) / width) ** 2) + y0\n\n    tr_1 = np.array([[x0 - width, x0], [y0, y0 + width]])\n    tr_2 = np.array([[x0, x0 + width], [y0 + width, y0]])\n    tr_3 = np.array([[x0 - width, x0 + width], [y0, y0]])\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1)\n        ax.set_aspect(\"equal\")\n\n    ax.plot(x, y)\n    ax.plot(*tr_1, color=\"k\")\n    ax.plot(*tr_2, color=\"k\")\n    ax.plot(*tr_3, color=\"k\")\n    AngleAnnotation(\n        (x0, height),\n        tr_1[:, 0],\n        tr_2[:, 1],\n        ax=ax,\n        size=75,\n        text=r\"$2\\alpha$\",\n        edgecolor=\"k\",\n    )\n\n    return ax",
  "def annotated_figure():\n    \"\"\"\n    Create full figure\n    \"\"\"\n    fig, ax = plt.subplots(1, 1)\n    ax.set_aspect(\"equal\")\n    radius = 20\n    x0 = 50\n    y0 = 0\n    ax = semi_circle_angle_fig(ax=ax, width=radius, height=radius, x0=x0, y0=y0)\n    ax = draw_brace(\n        [x0 - radius, x0 + radius],\n        0,\n        r\"$\\mathrm{Chord\\ Width}\\ (w)$\",\n        ax=ax,\n        sideswitch=True,\n    )\n    ax = draw_brace(\n        [0, radius], x0 + radius, r\"$\\mathrm{Chord\\ Heigh}t\\ (h)$\", ax=ax, vertical=True\n    )\n\n    return fig, ax",
  "def main():\n    \"\"\"Main\"\"\"\n    fig, ax = annotated_figure()\n    ax.set_xlim(27, 80)\n    ax.set_ylim(-5, 21)\n    ax.axis(\"off\")",
  "def __init__(\n        self,\n        xy,\n        p1,\n        p2,\n        size=75,\n        unit=\"points\",\n        ax=None,\n        text=\"\",\n        textposition=\"inside\",\n        text_kw=None,\n        **kwargs,\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        xy, p1, p2 : tuple or array of two floats\n            Center position and two points. Angle annotation is drawn between\n            the two vectors connecting *p1* and *p2* with *xy*, respectively.\n            Units are data coordinates.\n\n        size : float\n            Diameter of the angle annotation in units specified by *unit*.\n\n        unit : str\n            One of the following strings to specify the unit of *size*:\n\n            * \"pixels\": pixels\n            * \"points\": points, use points instead of pixels to not have a\n              dependence on the DPI\n            * \"axes width\", \"axes height\": relative units of Axes width, height\n            * \"axes min\", \"axes max\": minimum or maximum of relative Axes\n              width, height\n\n        ax : `matplotlib.axes.Axes`\n            The Axes to add the angle annotation to.\n\n        text : str\n            The text to mark the angle with.\n\n        textposition : {\"inside\", \"outside\", \"edge\"}\n            Whether to show the text in- or outside the arc. \"edge\" can be used\n            for custom positions anchored at the arc's edge.\n\n        text_kw : dict\n            Dictionary of arguments passed to the Annotation.\n\n        **kwargs\n            Further parameters are passed to `matplotlib.patches.Arc`. Use this\n            to specify, color, linewidth etc. of the arc.\n\n        \"\"\"\n        self.ax = ax or plt.gca()\n        self._xydata = xy  # in data coordinates\n        self.vec1 = p1\n        self.vec2 = p2\n        self.size = size\n        self.unit = unit\n        self.textposition = textposition\n\n        super().__init__(\n            self._xydata,\n            size,\n            size,\n            angle=0.0,\n            theta1=self.theta1,\n            theta2=self.theta2,\n            **kwargs,\n        )\n\n        self.set_transform(IdentityTransform())\n        self.ax.add_patch(self)\n\n        self.kw = dict(\n            ha=\"center\",\n            va=\"center\",\n            xycoords=IdentityTransform(),\n            xytext=(0, 0),\n            textcoords=\"offset points\",\n            annotation_clip=True,\n        )\n        self.kw.update(text_kw or {})\n        self.text = ax.annotate(text, xy=self._center, **self.kw)",
  "def get_size(self):  # noqa: D102\n        factor = 1.0\n        if self.unit == \"points\":\n            factor = self.ax.figure.dpi / 72.0\n        elif self.unit[:4] == \"axes\":\n            b = TransformedBbox(Bbox.unit(), self.ax.transAxes)\n            dic = {\n                \"max\": max(b.width, b.height),\n                \"min\": min(b.width, b.height),\n                \"width\": b.width,\n                \"height\": b.height,\n            }\n            factor = dic[self.unit[5:]]\n        return self.size * factor",
  "def set_size(self, size):  # noqa: D102\n        self.size = size",
  "def get_center_in_pixels(self):\n        \"\"\"Return center in pixels\"\"\"\n        return self.ax.transData.transform(self._xydata)",
  "def set_center(self, xy):\n        \"\"\"Set center in data coordinates\"\"\"\n        self._xydata = xy",
  "def get_theta(self, vec):  # noqa: D102\n        vec_in_pixels = self.ax.transData.transform(vec) - self._center\n        return np.rad2deg(np.arctan2(vec_in_pixels[1], vec_in_pixels[0]))",
  "def get_theta1(self):  # noqa: D102\n        return self.get_theta(self.vec1)",
  "def get_theta2(self):  # noqa: D102\n        return self.get_theta(self.vec2)",
  "def set_theta(self, angle):  # noqa: D102\n        pass",
  "def draw(self, renderer):  # noqa: D102\n        self.update_text()\n        super().draw(renderer)",
  "def update_text(self):  # noqa: D102\n        c = self._center\n        s = self.get_size()\n        angle_span = (self.theta2 - self.theta1) % 360\n        angle = np.deg2rad(self.theta1 + angle_span / 2)\n        r = s / 2\n        if self.textposition == \"inside\":\n            r = s / np.interp(angle_span, [60, 90, 135, 180], [3.3, 3.5, 3.8, 4])\n        self.text.xy = c + r * np.array([np.cos(angle), np.sin(angle)])\n        if self.textposition == \"outside\":\n\n            def R90(a, r, w, h):  # noqa: N802\n                if a < np.arctan(h / 2 / (r + w / 2)):\n                    return np.sqrt((r + w / 2) ** 2 + (np.tan(a) * (r + w / 2)) ** 2)\n                else:\n                    c = np.sqrt((w / 2) ** 2 + (h / 2) ** 2)\n                    T = np.arcsin(  # noqa: N806\n                        c * np.cos(np.pi / 2 - a + np.arcsin(h / 2 / c)) / r\n                    )\n                    xy = r * np.array([np.cos(a + T), np.sin(a + T)])\n                    xy += np.array([w / 2, h / 2])\n                    return np.sqrt(np.sum(xy**2))\n\n            def R(a, r, w, h):  # noqa: N802\n                aa = (a % (np.pi / 4)) * ((a % (np.pi / 2)) <= np.pi / 4) + (\n                    np.pi / 4 - (a % (np.pi / 4))\n                ) * ((a % (np.pi / 2)) >= np.pi / 4)\n                return R90(aa, r, *[w, h][:: int(np.sign(np.cos(2 * a)))])\n\n            bbox = self.text.get_window_extent()\n            X = R(angle, r, bbox.width, bbox.height)  # noqa: N806\n            trans = self.ax.figure.dpi_scale_trans.inverted()\n            offs = trans.transform(((X - s / 2), 0))[0] * 72\n            self.text.set_position([offs * np.cos(angle), offs * np.sin(angle)])",
  "def R90(a, r, w, h):  # noqa: N802\n                if a < np.arctan(h / 2 / (r + w / 2)):\n                    return np.sqrt((r + w / 2) ** 2 + (np.tan(a) * (r + w / 2)) ** 2)\n                else:\n                    c = np.sqrt((w / 2) ** 2 + (h / 2) ** 2)\n                    T = np.arcsin(  # noqa: N806\n                        c * np.cos(np.pi / 2 - a + np.arcsin(h / 2 / c)) / r\n                    )\n                    xy = r * np.array([np.cos(a + T), np.sin(a + T)])\n                    xy += np.array([w / 2, h / 2])\n                    return np.sqrt(np.sum(xy**2))",
  "def R(a, r, w, h):  # noqa: N802\n                aa = (a % (np.pi / 4)) * ((a % (np.pi / 2)) <= np.pi / 4) + (\n                    np.pi / 4 - (a % (np.pi / 4))\n                ) * ((a % (np.pi / 2)) >= np.pi / 4)\n                return R90(aa, r, *[w, h][:: int(np.sign(np.cos(2 * a)))])"
]